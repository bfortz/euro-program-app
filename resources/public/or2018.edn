{:timeslots {1 {:schedule "Wednesday, 9:00-10:30", :day "W", :time "A", :sessions (231)}, 2 {:schedule "Wednesday, 11:00-12:40", :day "W", :time "B", :sessions (30 170 152 218 47 46 24 40 167 241 7 19 156 85 184 201 195)}, 3 {:schedule "Wednesday, 14:00-15:40", :day "W", :time "C", :sessions (32 212 153 84 50 222 45 171 166 217 8 91 160 2 186 202 196 225 389644)}, 4 {:schedule "Wednesday, 16:10-17:50", :day "W", :time "D", :sessions (33 210 165 80 203 158 214 173 89 220 9 145 157 175 187 48 197 226)}, 5 {:schedule "Thursday, 9:00-10:15", :day "T", :time "A", :sessions (211 172 154 221 68 159 25 207 155 52 228 20 192 181 188 200)}, 6 {:schedule "Thursday, 10:45-12:00", :day "T", :time "B", :sessions (36 179 164 206 204 227 26 208 389643 54 229 147 193 177 189 49 389645)}, 7 {:schedule "Thursday, 13:30-14:20", :day "T", :time "C", :sessions (236 239 235 234)}, 8 {:schedule "Thursday, 14:45-16:00", :day "T", :time "D", :sessions (37 163 151 62 66 230 149 209 180 87 194 42 83 176 190)}, 9 {:schedule "Thursday, 16:00-18:00", :day "T", :time "E", :sessions (389646)}, 10 {:schedule "Friday, 9:00-10:40", :day "F", :time "A", :sessions (216 44 168 71 205 161 67 174 169 242 38 223 162 182 191 198)}, 11 {:schedule "Friday, 11:10-12:00", :day "F", :time "B", :sessions (233 237 238 240)}, 12 {:schedule "Friday, 13:30-15:00", :day "F", :time "C", :sessions (232)}}, :streams {1 {:name "Business Track", :sessions (46)}, 2 {:name "Decision Theory and Multiple Criteria Decision Making", :sessions (85 2 175 177 176)}, 3 {:name "Business Analytics, Artificial Intelligence and Forecasting", :sessions (201 202 200 163)}, 4 {:name "Finance", :sessions (195 196 197 198)}, 5 {:name "Health Care Management", :sessions (170 171 173 172 174)}, 6 {:name "Traffic, Mobility and Passenger Transportation", :sessions (30 32 212 45 33 210 214 211 36 37 216 44)}, 7 {:name "Logistics and Freight Transportation", :sessions (152 167 153 166 165 154 155 164 151 168 169)}, 8 {:name "Energy and Environment", :sessions (7 8 9 192 193 194)}, 9 {:name "Discrete and Integer Optimization", :sessions (218 84 217 80 220 221 52 206 54 62 87 71)}, 10 {:name "Graphs and Networks", :sessions (228 229 230 38)}, 11 {:name "Software Applications and Modelling Systems", :sessions (47 50 48 68 49 66)}, 12 {:name "Pricing and Revenue Management", :sessions (89 179 180)}, 13 {:name "OR in Engineering", :sessions (24 25 26 83)}, 14 {:name "Project Management and Scheduling", :sessions (156 160 158 157 159 161 162)}, 15 {:name "Simulation and Statistical Modelling", :sessions (241 242)}, 16 {:name "Supply Chain Management", :sessions (40 225 226)}, 17 {:name "Production and Operations Management", :sessions (184 186 187 188 189 190 191)}, 18 {:name "Metaheuristics", :sessions (203 204 205)}, 19 {:name "Optimization under Uncertainty", :sessions (207 208 209)}, 20 {:name "Control Theory and Continuous Optimization", :sessions (181 182)}, 21 {:name "Game Theory and Experimental Economics", :sessions (19 91 145 20 147 149 42 67 223)}, 22 {:name "Plenaries and Semi-Plenaries", :sessions (231 236 239 235 234 233 237 238 240 232)}, 23 {:name "GOR Awards", :sessions (222 227)}, 25 {:name "Meetings", :sessions (389644 389643 389645 389646)}}, :sessions {2 {:name "Approximation and Representation in Multiobjective Optimization", :stream 2, :chairs (36955), :timeslot 3, :papers (36 314 316 671), :track 14}, 7 {:name "District heating systems and decentralized energy", :stream 8, :chairs (33684), :timeslot 2, :papers (515 697 756), :track 11}, 8 {:name "Decentralised multi-energy systems", :stream 8, :chairs (33684), :timeslot 3, :papers (327 651 308), :track 11}, 9 {:name "Uncertainty handling and bilevel problems in energy industry", :stream 8, :chairs (45164), :timeslot 4, :papers (277 566 436), :track 11}, 19 {:name "Behavioral Aspects in Project Management", :stream 21, :chairs (26634), :timeslot 2, :papers (274 272 273), :track 12}, 20 {:name "Behavioral Operations Management: Inventory and Innovation Management", :stream 21, :chairs (42203), :timeslot 5, :papers (397 101 571), :track 12}, 24 {:name "Technologies of Artificial Creativity", :stream 13, :chairs (39554), :timeslot 2, :papers (348 132 412), :track 7}, 25 {:name "Optimization of Technical Systems", :stream 13, :chairs (41758), :timeslot 5, :papers (189 352 149), :track 7}, 26 {:name "Modelling for Logistics with Technical Constraints", :stream 13, :chairs (59689), :timeslot 6, :papers (294 234 255), :track 7}, 30 {:name "Planning and Operating Metropolitan Passenger Transport Networks", :stream 6, :chairs (57043), :timeslot 2, :papers (705 748 462 751), :track 1}, 32 {:name "Travel Behaviour Impacts of Automated and Connected Vehicles", :stream 6, :chairs (54141), :timeslot 3, :papers (555 490), :track 1}, 33 {:name "Line Planning and Network Design in Passenger Transport ", :stream 6, :chairs (46228), :timeslot 4, :papers (283 287 408 578), :track 1}, 36 {:name "Models and algorithms for trip- and ride-sharing problems", :stream 6, :chairs (23971), :timeslot 6, :papers (466 763 557), :track 1}, 37 {:name "Models of adoption and diffusion of innovations in transport systems", :stream 6, :chairs (57456), :timeslot 8, :papers (563 744 618), :track 1}, 38 {:name "Graphs", :stream 10, :chairs (9301), :timeslot 10, :papers (205 323 750), :track 11}, 40 {:name "Economic Models in Supply Chain", :stream 16, :chairs (35390), :timeslot 2, :papers (291 567 304), :track 8}, 42 {:name "Behavioural Operations Management", :stream 21, :chairs (58916), :timeslot 8, :papers (391 656 681), :track 12}, 44 {:name "Crowd Modeling and Management", :stream 6, :chairs (59826), :timeslot 10, :papers (170 439 550), :track 2}, 45 {:name "Recent Concepts in Air Traffic Flow Management", :stream 6, :chairs (23312), :timeslot 3, :papers (505 568 191 711), :track 7}, 46 {:name "Business Track", :stream 1, :chairs (34301), :timeslot 2, :papers (517 242 500 93), :track 6}, 47 {:name "MIP Solvers", :stream 11, :chairs (29594), :timeslot 2, :papers (49 280 635 204), :track 5}, 48 {:name "Algebraic Modeling Languages: Deployment", :stream 11, :chairs (14898), :timeslot 4, :papers (445 210 248 724), :track 16}, 49 {:name "Nonlinear Optimization Software", :stream 11, :chairs (12336), :timeslot 6, :papers (45 147 584), :track 16}, 50 {:name "Integer Programming Techniques", :stream 11, :chairs (16880), :timeslot 3, :papers (376 717 741 295), :track 5}, 52 {:name "Advanced Linear(ized) MIP Formulations for Ordering and Assignment Problems", :stream 9, :chairs (49180), :timeslot 5, :papers (429 497 172), :track 10}, 54 {:name "Robust matchings and Steiner network problems", :stream 9, :chairs (28033), :timeslot 6, :papers (484 228 207), :track 10}, 62 {:name "HealthFaCT", :stream 9, :chairs (17092), :timeslot 8, :papers (420 434 425), :track 4}, 66 {:name "Recent Developments in Automatic Dantzig-Wolfe Decomposition", :stream 11, :chairs (33581 42315), :timeslot 8, :papers (235 240 695), :track 5}, 67 {:name "Bidding mechanism", :stream 21, :chairs (55333 59663), :timeslot 10, :papers (81 367 206 208), :track 7}, 68 {:name "Algebraic Modeling Languages", :stream 11, :chairs (10542), :timeslot 5, :papers (121 288 326), :track 5}, 71 {:name "Applications of Discrete and Integer Optimization", :stream 9, :chairs (2987), :timeslot 10, :papers (260 609 611 221), :track 4}, 80 {:name "Algorithms for Combinatorial Problems", :stream 9, :chairs (59498), :timeslot 4, :papers (236 252 313 558), :track 4}, 83 {:name "OR for Construction and Production", :stream 13, :chairs (16315), :timeslot 8, :papers (195 312 458), :track 13}, 84 {:name "Real-World Applications of Combinatorial Optimization 2", :stream 9, :chairs (45055), :timeslot 3, :papers (317 686 768 371), :track 4}, 85 {:name "Decision Theory and Analysis, Econometric Models", :stream 2, :chairs (59878), :timeslot 2, :papers (70 360 615), :track 14}, 87 {:name "TSP/VRP: Time-Windows, Forbidden Neighborhoods, and Multiple Salespersons", :stream 9, :chairs (49180), :timeslot 8, :papers (198 431 455), :track 10}, 89 {:name "Data Analytics in Revenue Management ", :stream 12, :chairs (59908), :timeslot 4, :papers (664 629 421), :track 9}, 91 {:name "Graphs and Equilibrium Computation", :stream 21, :chairs (44469), :timeslot 3, :papers (597 626 682 691), :track 12}, 145 {:name "Network Games", :stream 21, :chairs (59910), :timeslot 4, :papers (667 668 683 669), :track 12}, 147 {:name "Pricing", :stream 21, :chairs (52405), :timeslot 6, :papers (719 673 721), :track 12}, 149 {:name "Unknown Demands in Congestion Games", :stream 21, :chairs (59914), :timeslot 8, :papers (687 688 710), :track 7}, 151 {:name "TSP Variants", :stream 7, :chairs (2247), :timeslot 8, :papers (369 678), :track 3}, 152 {:name "Last-Mile Delivery and Arc Routing", :stream 7, :chairs (59674), :timeslot 2, :papers (338 345 396 226), :track 3}, 153 {:name "Vehicle Routing: Heuristic Methods", :stream 7, :chairs (59780), :timeslot 3, :papers (394 679 481 508), :track 3}, 154 {:name "Vehicle Routing: Exact Methods", :stream 7, :chairs (29571), :timeslot 5, :papers (596 453 700), :track 3}, 155 {:name "Railways", :stream 7, :chairs (59653), :timeslot 5, :papers (598 660 245), :track 9}, 156 {:name "Project Management and Timetabling", :stream 14, :chairs (49073), :timeslot 2, :papers (407 499 767 377), :track 13}, 157 {:name "Scheduling under Stochasticity", :stream 14, :chairs (23312), :timeslot 4, :papers (161 343 541 734), :track 13}, 158 {:name "Workforce planning and scheduling", :stream 14, :chairs (1658), :timeslot 4, :papers (622 624 692 67), :track 6}, 159 {:name "Scheduling in Manufacturing", :stream 14, :chairs (57474), :timeslot 5, :papers (399 495 502), :track 6}, 160 {:name "Project Scheduling and Resource Planning", :stream 14, :chairs (49145), :timeslot 3, :papers (264 267 290 296), :track 13}, 161 {:name "Scheduling I", :stream 14, :chairs (18193), :timeslot 10, :papers (96 232 299 474), :track 6}, 162 {:name "Scheduling II", :stream 14, :chairs (39141), :timeslot 10, :papers (251 447 452 501), :track 13}, 163 {:name "Optimization and Machine Learning", :stream 3, :chairs (7432 32497), :timeslot 8, :papers (758 760 761), :track 2}, 164 {:name "Warehousing", :stream 7, :chairs (55920), :timeslot 6, :papers (529 507 416), :track 3}, 165 {:name "Vehicle Routing X", :stream 7, :chairs (23979), :timeslot 4, :papers (579 136 428 703), :track 3}, 166 {:name "City Logistics", :stream 7, :chairs (39359), :timeslot 3, :papers (262 564 572 217), :track 9}, 167 {:name "Air Transportation", :stream 7, :chairs (15955), :timeslot 2, :papers (224 212 539 134), :track 9}, 168 {:name "Innovative transportation concepts", :stream 7, :chairs (13086), :timeslot 10, :papers (286 610 715 239), :track 3}, 169 {:name "Logistics Network Design", :stream 7, :chairs (26841), :timeslot 10, :papers (330 639 708 225), :track 9}, 170 {:name "Planning of Emergency Medical Services", :stream 5, :chairs (10057), :timeslot 2, :papers (438 720 727 229), :track 2}, 171 {:name "Staff Scheduling", :stream 5, :chairs (15060), :timeslot 3, :papers (503 58 55 108), :track 8}, 172 {:name "Appointment Scheduling", :stream 5, :chairs (41246), :timeslot 5, :papers (339 426 443), :track 2}, 173 {:name "Patient Admission and Transport Services", :stream 5, :chairs (1256), :timeslot 4, :papers (417 527 139 534), :track 8}, 174 {:name "Decision Support in Health Care", :stream 5, :chairs (22533), :timeslot 10, :papers (243 493 771 328), :track 8}, 175 {:name "Applications for Multiple Criteria Decision Making", :stream 2, :chairs (12591), :timeslot 4, :papers (625 433 698 745), :track 14}, 176 {:name "Optimization Techniques", :stream 2, :chairs (26181), :timeslot 8, :papers (357 565 115), :track 14}, 177 {:name "Multi Objective Location and Network Optimization", :stream 2, :chairs (59677), :timeslot 6, :papers (183 489 241), :track 14}, 179 {:name "Dynamic Pricing", :stream 12, :chairs (48742), :timeslot 6, :papers (215 603 220), :track 2}, 180 {:name "Revenue Management Applications", :stream 12, :chairs (59920), :timeslot 8, :papers (523 593 693), :track 9}, 181 {:name "Optimal Control and Games in Finance and Economics", :stream 20, :chairs (3524 29473), :timeslot 5, :papers (307 53 259), :track 14}, 182 {:name "Recent Advances on Emerging Problems of Continuous Optimization", :stream 20, :chairs (3524 23371), :timeslot 10, :papers (496 355 82 718), :track 14}, 184 {:name "Inventory Management and Control", :stream 17, :chairs (45941), :timeslot 2, :papers (263 48 193), :track 15}, 186 {:name "Planning of Production Lines", :stream 17, :chairs (59597), :timeslot 3, :papers (275 545 119), :track 15}, 187 {:name "Layout Planning", :stream 17, :chairs (39470), :timeslot 4, :papers (289 300 472), :track 15}, 188 {:name "Design and Control of Manufacturing Processes", :stream 17, :chairs (59686), :timeslot 5, :papers (645 419 246), :track 15}, 189 {:name "Production Planning and Lot Sizing", :stream 17, :chairs (55546), :timeslot 6, :papers (137 190 479), :track 15}, 190 {:name "Strategic and Tactical Production Planning", :stream 17, :chairs (39372), :timeslot 8, :papers (303 387 728), :track 15}, 191 {:name "Operations Planning in Warehouses and Cross Docks", :stream 17, :chairs (52268), :timeslot 10, :papers (56 488 510 144), :track 15}, 192 {:name "Demand Side Management", :stream 8, :chairs (28733), :timeslot 5, :papers (129 409 437), :track 13}, 193 {:name "Energy and CO2 reduction in manufacturing", :stream 8, :chairs (45164), :timeslot 6, :papers (528 552 468), :track 13}, 194 {:name "Optimization of utility and energy plants", :stream 8, :chairs (33684), :timeslot 8, :papers (520 509 52), :track 11}, 195 {:name "Financial Modeling I", :stream 4, :chairs (50802), :timeslot 2, :papers (75 258 306 124), :track 17}, 196 {:name "Financial Modeling II", :stream 4, :chairs (2236), :timeslot 3, :papers (736 385 504), :track 17}, 197 {:name "Banking and Finance", :stream 4, :chairs (57872), :timeslot 4, :papers (636 302 331 487), :track 17}, 198 {:name "Risk Analysis and Management", :stream 4, :chairs (54266), :timeslot 10, :papers (403 666 464), :track 17}, 200 {:name "Forecasting", :stream 3, :chairs (55835), :timeslot 5, :papers (632 772 432), :track 16}, 201 {:name "Business Analytics", :stream 3, :chairs (59761), :timeslot 2, :papers (271 435 556 561), :track 16}, 202 {:name "Machine Learning", :stream 3, :chairs (11028), :timeslot 3, :papers (38 586 498), :track 16}, 203 {:name "Automated Algorithm Design", :stream 18, :chairs (56608), :timeslot 4, :papers (723 631 628 731), :track 5}, 204 {:name "Swarm Intelligence", :stream 18, :chairs (31863), :timeslot 6, :papers (34 440 103), :track 5}, 205 {:name "Applications of Metaheuristics", :stream 18, :chairs (59942), :timeslot 10, :papers (91 347 620 735), :track 5}, 206 {:name "MI(N)LP", :stream 9, :chairs (50836), :timeslot 6, :papers (393 547), :track 4}, 207 {:name "Advanced methods", :stream 19, :chairs (56971), :timeslot 5, :papers (187 200 14), :track 8}, 208 {:name "Stochastic and Integer Programming", :stream 19, :chairs (55472), :timeslot 6, :papers (540 165 694), :track 8}, 209 {:name "Applications of Optimization under Uncertainty", :stream 19, :chairs (24368), :timeslot 8, :papers (665 197 725), :track 8}, 210 {:name "Scheduling in railway transportation systems", :stream 6, :chairs (52489), :timeslot 4, :papers (448 478 12 467), :track 2}, 211 {:name "Train timetabling", :stream 6, :chairs (47283), :timeslot 5, :papers (602 661 293), :track 1}, 212 {:name "Electric vehicles", :stream 6, :chairs (15178), :timeslot 3, :papers (146 411 648 712), :track 2}, 214 {:name "Urban mobility operations ", :stream 6, :chairs (31468), :timeslot 4, :papers (298 223 516), :track 7}, 216 {:name "Demand based optimization modeling in transportation", :stream 6, :chairs (50839), :timeslot 10, :papers (72 672 583 707), :track 1}, 217 {:name "Algorithmic Approaches for Challenging Discrete Optimization Problem", :stream 9, :chairs (58624), :timeslot 3, :papers (340 359 659 663), :track 10}, 218 {:name "Real-World Applications of Combinatorial and Discrete Optimization Problems", :stream 9, :chairs (55691), :timeslot 2, :papers (559 418 297), :track 4}, 220 {:name "New Mathematical Results on Relevant Discrete Optimization Tasks", :stream 9, :chairs (29393), :timeslot 4, :papers (569 353 406 199), :track 10}, 221 {:name "Mathematical Investigations of Combinatorial Optimization Problems", :stream 9, :chairs (59755), :timeslot 5, :papers (350 379 441), :track 4}, 222 {:name "GOR Dissertation Award", :stream 23, :chairs (1658), :specialroom "1g. Budapest", :timeslot 3, :papers (766 769 773 777), :track 6}, 223 {:name "Game Theory and Experimental Economics", :stream 21, :chairs (26950), :timeslot 10, :papers (713 749 753 757), :track 12}, 225 {:name "Supply chain network design", :stream 16, :chairs (24964), :timeslot 3, :papers (530 27 570 378), :track 18}, 226 {:name "Demand fulfillment", :stream 16, :chairs (9112), :timeslot 4, :papers (386 395 415 473), :track 18}, 227 {:name "GOR Master Award", :stream 23, :chairs (12666), :specialroom "1g. Budapest", :timeslot 6, :papers (774 775 776), :track 6}, 228 {:name "Graphs and Networks I", :stream 10, :chairs (5319), :timeslot 5, :papers (554 575 337), :track 11}, 229 {:name "Graphs and Networks II", :stream 10, :chairs (45244), :timeslot 6, :papers (362 634 646), :track 11}, 230 {:name "Graphs and Networks III", :stream 10, :chairs (51079), :timeslot 8, :papers (74 413 677), :track 6}, 231 {:name "Opening session - Plenary I. Ljubic", :stream 22, :chairs (1), :timeslot 1, :papers (51), :track 1}, 232 {:name "Closing session - Plenary H. Hoos", :stream 22, :chairs (1), :timeslot 12, :papers (765), :track 1}, 233 {:name "Semi-plenary: M. Anjos", :stream 22, :chairs (25372), :specialroom "1a. Europe a", :timeslot 11, :papers (608), :track 1}, 234 {:name "Semi-plenary: N. Brauner", :stream 22, :chairs (2987), :specialroom "2b. New Delhi", :timeslot 7, :papers (706), :track 4}, 235 {:name "Semi-plenary: R. Hartl", :stream 22, :chairs (23979), :specialroom "2a. Beijing", :timeslot 7, :papers (130), :track 3}, 236 {:name "Semi-plenary: H. Imhof", :stream 22, :chairs (12428), :specialroom "1a. Europe a", :timeslot 7, :papers (649), :track 1}, 237 {:name "Semi-plenary: A. Koster", :stream 22, :chairs (17092), :specialroom "1b. Europe b", :timeslot 11, :papers (587), :track 2}, 238 {:name "Semi-plenary: S. Pickl", :stream 22, :chairs (33475), :specialroom "2a. Beijing", :timeslot 11, :papers (538), :track 3}, 239 {:name "Semi-plenary: F. Saldanha-da-Gama", :stream 22, :chairs (5078), :specialroom "1b. Europe b", :timeslot 7, :papers (152), :track 2}, 240 {:name "Semi-plenary: G. Vanden Berghe", :stream 22, :chairs (7432), :specialroom "2b. New Delhi", :timeslot 11, :papers (621), :track 4}, 241 {:name "Simulation and Statistical Modelling I", :stream 15, :chairs (4796), :timeslot 2, :papers (370 392 171), :track 10}, 242 {:name "Simulation and Statistical Modelling II", :stream 15, :chairs (26200), :timeslot 10, :papers (588 506 699), :track 10}, 389643 {:name "GOR Working Groups meeting", :stream 25, :chairs (1601), :specialroom "!!! 10:15-12:15 !!! 1lm. London-Madrid", :timeslot 6, :papers nil, :track 9}, 389644 {:name "MMOR Editorial Board Meeting", :stream 25, :chairs (2795), :specialroom "1k. Lisbon", :timeslot 3, :papers nil, :track 19}, 389645 {:name "OR Spectrum Editorial Lunch", :stream 25, :chairs (829), :specialroom "!!! 12:00-14:00 !!! 1k. Lisbon", :timeslot 6, :papers nil, :track 19}, 389646 {:name "GOR General Meeting", :stream 25, :chairs (14715), :specialroom "1a. Europe a", :timeslot 9, :papers nil, :track 1}}, :rooms {1 {:room "1a. Europe a"}, 2 {:room "1b. Europe b"}, 3 {:room "2a. Beijing"}, 4 {:room "2b. New Delhi"}, 5 {:room "2c. Tokyo"}, 6 {:room "1g. Budapest"}, 7 {:room "1h. Copenhagen"}, 8 {:room "1i. Dublin"}, 9 {:room "1lm. London-Madrid"}, 10 {:room "1c. Amsterdam"}, 11 {:room "1d. Athens"}, 12 {:room "1e. Berlin"}, 13 {:room "1f. Brussels"}, 14 {:room "1n. Oslo"}, 15 {:room "1o. Paris"}, 16 {:room "1p. Prague"}, 17 {:room "1q. Rome"}, 18 {:room "1j. Geneva"}, 19 {:room "1k. Lisbon"}}, :keywords {2 {:name "Airline Applications", :sessions (167 45 89 157 180)}, 5 {:name "Artificial Intelligence", :sessions (203 230 242 238)}, 6 {:name "Auctions / Competitive Bidding", :sessions (46 40 195 153 196 147 235 67)}, 7 {:name "Capacity Planning", :sessions (30 7 195 166 160 158 172 189 163 42 190)}, 8 {:name "Combinatorial Optimization", :sessions (231 170 152 218 167 195 84 50 217 91 160 80 220 187 221 52 228 206 204 54 229 177 49 163 151 87 194 168 71 205 161 67 169 237 240)}, 13 {:name "Convex Optimization", :sessions (80 176 242 223 182)}, 14 {:name "Continuous Optimization", :sessions (204 49 182)}, 16 {:name "Cutting and Packing", :sessions (218 220 71 169)}, 17 {:name "Data Envelopment Analysis", :sessions (45 175)}, 18 {:name "Decision Support Systems", :sessions (170 167 84 214 211 20 188 193 180 83 44 67)}, 19 {:name "Decision Theory and Analysis", :sessions (19 85 175 20 42 176 242)}, 22 {:name "Disaster and Crisis Management", :sessions (152 222 226)}, 23 {:name "Dynamical Systems", :sessions (44 182)}, 25 {:name "Economic Modeling", :sessions (30 40 32 91 197 176 216)}, 27 {:name "Education and Distance Learning", :sessions (234)}, 28 {:name "Electrical Markets", :sessions (46 7 9 192 189 209 194)}, 29 {:name "Energy Policy and Planning", :sessions (7 212 8 9 175 192 193 37 194 233)}, 30 {:name "Enterprise Resource Planning Systems", :sessions (188)}, 31 {:name "Environmental Management", :sessions (166 155)}, 33 {:name "Facilities Planning and Design", :sessions (218 91 187 177 216)}, 34 {:name "Finance and Banking", :sessions (195 197)}, 35 {:name "Financial Modelling", :sessions (195 196 9 181 194 198)}, 36 {:name "Flexible Manufacturing Systems", :sessions (52 161)}, 37 {:name "Forecasting", :sessions (184 166 202 37 198)}, 38 {:name "Forestry Management", :sessions (84)}, 39 {:name "Fuzzy Sets and Systems", :sessions (202 214 9 176)}, 40 {:name "Game Theory", :sessions (40 156 91 145 20 147 149 216 67 223)}, 41 {:name "Global Optimization", :sessions (7 206 49 182)}, 42 {:name "Graphs and Networks", :sessions (84 8 91 80 220 197 159 228 227 26 54 229 147 177 230 149 71 38 223)}, 45 {:name "Health Care", :sessions (170 46 171 173 172 159 62 42 174)}, 47 {:name "Human Resources Management", :sessions (158 200 180)}, 48 {:name "Industrial Optimization", :sessions (186 48 68 25 193 194 83 205 162)}, 49 {:name "Interior Point Methods", :sessions (24 49)}, 53 {:name "Large Scale Optimization", :sessions (47 24 210 68 179)}, 54 {:name "Location", :sessions (212 217 225 165 220 193 239 62 190 216 169)}, 55 {:name "Management Information Systems", :sessions (188)}, 56 {:name "Marketing", :sessions (241 201)}, 57 {:name "Mathematical Programming", :sessions (231 47 24 217 2 158 48 197 154 151 209 182 233)}, 59 {:name "Metaheuristics", :sessions (30 153 166 160 186 33 165 203 187 52 36 204 227 163 151 209 216 205 162 191)}, 61 {:name "Modeling Systems and Languages", :sessions (48 68 49)}, 63 {:name "Multi-Objective Decision Making", :sessions (85 32 91 2 214 173 175 172 159 25 71)}, 65 {:name "Network Design", :sessions (30 24 225 165 145 228 54 229 149 169)}, 66 {:name "Non-smooth Optimization", :sessions (182)}, 67 {:name "Optimization in Financial Mathematics", :sessions (196)}, 72 {:name "OR in Sports", :sessions (208 205)}, 73 {:name "OR/MS and the Public Sector", :sessions (85 84)}, 74 {:name "Parallel Algorithms and Implementation", :sessions (48 68)}, 75 {:name "Production and Inventory Systems", :sessions (184 186 187 159 188 164 189 190 191)}, 86 {:name "Project Management and Scheduling", :sessions (19 156 160 157 159 188 162)}, 87 {:name "Quality Management", :sessions (40 205)}, 88 {:name "Queuing Systems", :sessions (242 191)}, 89 {:name "Reliability", :sessions (175)}, 91 {:name "Revenue Management and Pricing", :sessions (201 89 226 179 236 163 180 191)}, 92 {:name "Reverse Logistics / Remanufacturing", :sessions (225 226 169)}, 93 {:name "Risk Analysis and Management", :sessions (201 197 226 200 208 198)}, 94 {:name "Robust Optimization", :sessions (160 80 220 207 62 209 174 237)}, 95 {:name "Routing", :sessions (152 212 153 222 166 217 165 214 226 154 228 36 227 177 235 151 149 87 205 223 240)}, 96 {:name "Scheduling", :sessions (152 46 7 156 212 84 171 186 210 80 158 220 9 157 172 159 155 192 227 26 180 71 161 162 191)}, 97 {:name "Simulation", :sessions (30 167 241 32 173 157 172 36 62 180 42 216 44 71 198)}, 98 {:name "Software for OR/MS Analysis", :sessions (47 46 24 48 68 49)}, 99 {:name "Stochastic Models", :sessions (241 225 145 157 175 20 181 188 36 164 189 239 198)}, 100 {:name "Strategic Planning and Management", :sessions (241 195 196 33 193 190)}, 101 {:name "Supply Chain Management", :sessions (40 184 2 225 226 20 42 190)}, 102 {:name "Sustainable Development", :sessions (166 25 26 189)}, 103 {:name "System Dynamics and Theory", :sessions (42)}, 104 {:name "Telecommunications", :sessions (228)}, 105 {:name "Timetabling", :sessions (156 214 211 227)}, 108 {:name "Variational Problems", :sessions (223)}, 109 {:name "Warehouse Design, Planning, and Control", :sessions (164 205 162 191)}, 115 {:name "Problem Structuring Methods", :sessions (175)}, 120 {:name "Data Mining", :sessions (46 201 200 179 209)}, 121 {:name "Rostering", :sessions (170 46 171 158)}, 124 {:name "Machine Learning", :sessions (201 45 202 80 203 163 209 83 242 232)}, 126 {:name "Optimal Control", :sessions (241 45 8 181 209 182)}, 127 {:name "Agent Systems", :sessions (241 193 44)}, 133 {:name "Engineering Optimization", :sessions (24 8 25 26 83 162 233)}, 134 {:name "Equilibria", :sessions (91 145 197 208 147 149)}, 141 {:name "Managerial Accounting", :sessions (158)}, 143 {:name "Universities", :sessions (234)}, 149 {:name "Business Analytics", :sessions (156 201 45 202 238)}, 150 {:name "Decomposition Methods", :sessions (231 24 212 45 171 166 217 154 221 208 163 66 161 169)}, 151 {:name "Approximation Algorithms", :sessions (170 91 220 229 230 87 161 67 223)}, 152 {:name "Statistics", :sessions (241 89 200 204)}, 153 {:name "Computational Experiments", :sessions (50 217 187 208 66 83 71 161 67 182)}, 154 {:name "Computational Complexity", :sessions (2 147 161 38 237)}, 155 {:name "Constraint Programming", :sessions (196 80)}, 156 {:name "Dynamic Programming", :sessions (195 158 226 207 179 26 229 147 189 37 209 162)}, 157 {:name "Integer Programming", :sessions (170 152 47 46 156 84 50 166 217 210 214 220 157 221 159 206 208 54 66 230 87 194 190 168 71)}, 158 {:name "Mixed-Integer Programming", :sessions (218 47 46 24 7 184 84 50 222 171 217 8 160 2 186 225 33 210 157 187 48 172 25 207 155 52 206 26 193 177 49 151 87 83 190 216 168 71 169 232)}, 159 {:name "Linear Programming", :sessions (47 212 211 155 192 189 234 67 174)}, 161 {:name "Multi-Objective Programming", :sessions (85 84 2 177 176)}, 162 {:name "Nonlinear Programming", :sessions (24 222 217 220 52 206 189 49 163 194 176)}, 163 {:name "Quadratic Programming", :sessions (47)}, 164 {:name "Semidefinite Programming", :sessions (182)}, 165 {:name "Stochastic Programming", :sessions (157 226 207 181 179 208 194 169)}, 167 {:name "Predictive Analytics", :sessions (46 201 33)}, 169 {:name "Advanced Analytics", :sessions (236 242 223 238)}, 170 {:name "Matheuristics", :sessions (201 217 160 202)}, 172 {:name "Social Networks", :sessions (230)}, 173 {:name "Algorithm Analysis", :sessions (152 203 145 228 204 230 38 223 182 232)}, 174 {:name "Logistics", :sessions (170 152 167 153 222 45 166 214 226 221 155 164 227 239 151 87 190 168 67 169 162 191)}, 175 {:name "Transportation", :sessions (30 152 167 32 212 153 166 165 214 211 154 155 200 36 179 235 37 87 216 44 168 205 169)}, 176 {:name "Polyhedral Combinatorics", :sessions (80)}, 177 {:name "Prescriptive Analytics", :sessions (46 202)}, 178 {:name "Econometric Models", :sessions (85 32 37 216)}, 179 {:name "Time Series Analysis", :sessions (198)}, 180 {:name "Time Series Data Mining", :sessions (202 188 200)}, 181 {:name "Forecasting algorithms", :sessions (33)}, 182 {:name "Forecasting applications", :sessions (198)}, 183 {:name "Statistics with Big Data", :sessions (201 204 242)}, 185 {:name "Public Transport", :sessions (30 33 210 211 36)}, 186 {:name "Crew Scheduling", :sessions (170 210 204)}, 187 {:name "Vehicle Scheduling", :sessions (170 212 33 165 173 154 52 36 26 209 168 162 240)}, 188 {:name "Robustness", :sessions (30 167 36 54)}, 189 {:name "Mobility", :sessions (30 212 33 36 236 37 44)}}, :papers {12 {:keyword1 186, :keyword3 185, :abstract "Our work deals with collective scheduling of railway crews over multiple networks with constrained attendance rates, a problem arising at a German railway company. We describe the multiple-network problem and propose a new method based on a partitioning-and-recombination strategy along with a hybrid column generation and genetic algorithm approach.\r\n\r\nCurrently the company schedules crews for each individual network separately. Here, we test the hypothesis that scheduling crews collectively over multiple networks could realize savings in personnel cost.\r\nWe discuss characteristics of the multiple-network crew scheduling problem and briefly describe attendance rates for conductors, a special condition in German regional passenger rail services. The problem is then formulated as a set-covering problem with network-specific constraints.\r\n\r\nThe union of several different railway networks translate into one very large and complex network. To solve this very large-scale optimization problem, we apply and compare two solution approaches: 1) an existing hybrid column generation and genetic algorithm approach developed by Hoffmann et al., and 2) a novel two-phase optimization approach which partitions the problem into smaller instances using network information and subsequently feeds their solutions back into the procedure of the original problem.\r\n\r\nTests with a real one-day case of 12 networks show that the two-phase optimization approach performs best in both computational time and best solution found. Moreover, we show that the collective crew scheduling over multiple networks might cut personnel cost up to 3%.", :title "A solution approach to large-scale railway crew scheduling of multiple networks", :keyword2 53, :authors (56875), :session 210}, 14 {:keyword1 156, :keyword3 0, :abstract "The article proposes a normative model of dynamic choice in which an agent must sequentially choose actions in order to maximize her performance. Unlike in traditional models, the action sets are random. That is, for a given state history, instead of a known action set, there is a known probability distribution over action sets. For example, given the asset prices and portfolio history up to n-th period, the specific distributions of returns for the assets in the n+1-th period are known only after the n-th period. I prove that an optimal decision policy requires an agent to follow the maximum expected performance principle and that an optimal decision policy can be expressed as a function over state space, whose expected value the agent ought to maximize. I find necessary conditions for optimality in the general case, in a Markovian environment, and in a stationary environment. I also prove existence, uniqueness, and sufficient conditions for optimality under certain circumstances. I then apply these results to solve numerically three problems. The first is a portfolio allocation problem in which a future pensioner tries to maximize probability of having a certain portfolio value at the time of retirement or tries to obtain this value as quickly as possible. The second is an optimal-foraging problem. The third is a problem in which an artificial agent is trying to find the quickest route in a dynamically changing graph. ", :title "A sequential decision process with stochastic action sets", :keyword2 165, :authors (56971), :session 207}, 27 {:keyword1 101, :keyword3 0, :abstract "Fierce competition and declining profit margins often force transport companies to adopt a collaborative mind-set. Cooperating with fellow carriers can provide efficiency increasing strategies which are not available under an internal company focus. Due to its practical importance, collaborative logistics has developed into an active and growing research domain. Existing studies mainly focus on collaborative transport in order to increase the efficiency of vehicle fleet operations. Instead of optimising joint transport operations, carriers may also cooperate by sharing warehouses or distribution centres (DCs). In Verdonck et al. (2016), the cooperative carrier facility location problem is discussed. By jointly deciding on two types of decisions, namely, first which DCs to open, and, second how to allocate the quantity of product flows in the distribution network, partnering companies aim to minimise their total logistics cost. In addition, the carriers have to decide on a suitable distribution of the collaborative benefits while ensuring stability of the coalition. The majority of studies on collaborative logistics assume deterministic problem settings. Very few studies address how horizontal collaboration between carriers can work in a stochastic environment. As such, our research work investigates approaches to the stochastic optimisation of the cooperative carrier facility location problem. We can draw on past research on the facility location problem under uncertainty, but the context of horizontal carrier collaboration introduces additional challenges with respect to the assessment and sharing of risks, and the robustness of coalition stability. \r\n\r\nVerdonck L, Beullens P, Caris A, Ramaekers K, Janssens G (2016) Analysis of collaborative savings and cost allocation techniques for the cooperative carrier facility location problem. Journal of the Operational Research Society 67(6):853-871\r\n", :title "A stochastic approach to the cooperative carrier facility location problem ", :keyword2 99, :authors (35621 36610), :session 225}, 34 {:keyword1 59, :keyword3 173, :abstract "Ant algorithms are popular metaheuristics that have been widely used since the 90’s. Let f be an objective function to minimize. Generally, an ant is a constructive solution method able to build a solution s from scratch. At each step of the construction, each ant adds an element m to the current solution s based on a probability function PROB relying on two ingredient: the visibility V(m) and the trail T(m) of the element m. On the one hand, the visibility depends only on the involved ant (self-adaptation phase): the larger V(m) is, the smaller the increase of f is usually. On the other hand, the trail is an information based on the history of the search (cooperation phase): a large value of T(m) usually indicates that m is often part of good solutions that have been built previously by other ants. In other words, the probability function PROB is a tradeoff between the self-adaptation ability of the involved ant and the cooperation mechanism of the ant population.\r\n\r\nOther types of ant algorithms have recently emerged. Therefore, the common framework of the constructive ant algorithms does not limit the discussion. The present work has two goals. First, it shows that the main feature of the ant algorithm (i.e., PROB) is not efficient, in terms of both quality (i.e., the obtained solutions have poor values with respect to f) and speed (i.e., a cumbersome computational effort is often required to make a very simple decision). It leads to the following question: is it a good idea to use simultaneously two ingredients (namely visibility and trail) that are likely to be conflicting? Second, it highlights that a different formulation and use of PROB, combined with a redesigning of the ant paradigm, can lead to much better results. Problems of the following fields have been investigated to validate the proposed analysis: graph coloring, truck loading, location-distribution, and job scheduling.\r\n\r\nBuilding on that, the following questions are addressed for enlarging the ant paradigm. (1) Should an ant be different from a constructive heuristic, but without losing its two inherent elements (i.e., visibility and trail)? For instance, an ant might be a basic decision helper or a full metaheuristic. (2) Can we use the visibility and the trail at two different times of the decision process (i.e., do not confront these elements simultaneously)? (3) What should be the role of the trail among intensification (which is the usual role of the trail system) and diversification? (4) Can we accelerate the decision process, for instance, by reworking the nature of PROB (and not simply its frequency of use, as often observed in the literature)? (5) Should we use the visibility and trail features within another optimization framework (e.g., a well-established local search or another population-based method), instead of simply boosting the solutions provided by the ants with independent local search procedures (as often observed in the literature).", :title "Do ant algorithms really work?", :keyword2 8, :authors (55877), :session 204}, 36 {:keyword1 154, :keyword3 161, :abstract "This talk presents a novel approach to the problem of representing the solution of a multiobjective optimisation problem by a small, finite number of points. Starting from Bayesian belief probabilities about acceptance probabilities we derive a probability that at least one solution in a finite set of solutions is acceptable to a decision maker. \r\nThis maximisation of this probability over a set of limited size leads to a set consisting of Pareto optimal points. The computation of the probability, as the consequence of Fubini's law, is closely related to the calculation of the hypervolume indicator. It is, therefore, possible to transfer most complexity results on this indicator. The talk will detail complexity results for maximum volume subset selection, and volume computation.  We show that this changes, once a priori correlations between objectives are introduced, although specific properties, such as Pareto compliance, are maintained. Besides a theoretical treatise, we illustrate the usefulness of the method through applications in skyline queries.\r\n", :title "Generalized Hypervolume Indicator for the Finite Representation of Pareto Frontiers: Decision Theoretic Motivation and Computational Complexity", :keyword2 63, :authors (50868), :session 2}, 38 {:keyword1 39, :keyword3 0, :abstract "I introduce some new classes of contractive conditions on complete triangular intuitionistic fuzzy metric spaces and I give fixed point results for mappings satisfying these conditions. I establish also a stability result. My original contributions are three theorems, an example, a definition and a corollary.", :title "Fixed points of some new contractions on intuitionistic fuzzy metric spaces", :keyword2 170, :authors (58979), :session 202}, 45 {:keyword1 162, :keyword3 14, :abstract "Interior-point methods are known to be very efficient for the class of large-scale nonlinear programming. The extension to penalty-interior-point methods increases their robustness due to the regularization of the constraints caused by the penalty term and have enjoyed an increased popularity recently. In this talk we focus on an exact penalty-interior-point algorithm based on a modified barrier and a non-smooth l2-penalty function, which has been implemented in the nonlinear programming solver WORHP. This penalty-interior-point algorithm avoids the ill-conditioning of the linear equation system near the optimal solution which is a valuable property for a post-optimality parametric sensitivity analysis. Besides showing how to extract the sensitivity derivatives, we develop a sensitivity based warmstart procedure, which is able to approximate the perturbed optimal solution even under certain active-set changes just by iteratively applying cost efficient matrix-vector multiplications. This warmstarting technique has been added to WORHP and some numerical experiments will be reported.", :title "Refinement and Warmstarting Strategies for a Penalty-Interior-Point Algorithm", :keyword2 49, :authors (53961 24376), :session 49}, 48 {:keyword1 158, :keyword3 101, :abstract "Marine shrimp farming is an aquaculture business for the cultivation of marine shrimp or prawns for human consumption. Giant freshwater prawn farming is one of the most popular marine shrimp farming in Thailand: 90% of the prawn yield is for domestic consumption and the remaining is for export. Although the giant freshwater prawn farming has been developed during more than a century, the main farming operations are still traditional. These farming operations can be improved by applying modern farming techniques. This paper was motivated by a real problem in a large giant freshwater prawn farm located in the Western region of Thailand, which manages the whole prawn farming supply chain network. In this problem, the farmer tackles when and where prawns are to be cultured and harvested, and how the prawns are to be transported and stored at distribution centres, in order to maximize the supply chain profit. Because prawns are perishable products, the farmer cannot store the large amount of prawn at distribution centres for a long time. Therefore, the farmer needs an effective tool for production planning and inventory control, which maintains the quality (freshness) of the prawn under the constraints of supply resources capacities. Operations research (OR) models are designed to optimize a specific objective criterion subject to set of constraints. Recently, many studies on OR models were applied to agriculture food supply chain management. This paper extends our previous mixed-integer linear programming (MILP) for the prawn farming supply chain network by adding production planning and inventory control functions to consider the freshness of prawn. The farmer is concerned about the timing of cultivating and harvesting, the number of hiring labors, the volume of harvesting, the storage at distribution centres and selection of transportation methods, to achieve high freshness of delivered prawn. The production planning is applied to assist cultivating and harvesting scheduling under consideration of labor hiring, dispatching capacity and time limitation. The inventory controlling manages the volume of prawn stored at distribution centres such that the stored period is at most one week. As a result, the new model can maximize the farmer’s profit while improving the freshness of prawn.  The numerical results showed that the proposed model holds a potential to increase the total profit surplus by 4.71% when compared with farmer’s solution. The model can also be used to investigate the relationship between the revenue, total costs and the timing of operations, i.e., purchasing, cultivating, harvesting, storing and dispatching. Thus, the model becomes a valuable tool for the farmer to plan future resource requirements and production capacity as well as to identify potential bottlenecks in the supply chain network and to demonstrate the feasibility of smart marine shrimp assisted by OR techniques.", :title "Mixed-integer linear programming based approach for optimal production planning and inventory control of marine shrimp farming supply chain network", :keyword2 75, :authors (57094 59459 59460), :session 184}, 49 {:keyword1 57, :keyword3 53, :abstract "We present new developments in SAS/OR and SAS Optimization for Viya. The talk will focus on mixed integer programming related topics and will include improvements to modeling and the decomposition algorithm.", :title "New Developments in the SAS Optimization Products", :keyword2 158, :authors (9731), :session 47}, 51 {:keyword1 150, :keyword3 8, :abstract "In bilevel optimization there are two decision makers, commonly denoted as the leader and the follower, and decisions are made in a hierarchical manner: the leader makes the first move, and then the follower reacts optimally to the leader's action. It is assumed that the leader can anticipate the decisions of the follower, hence the leader optimization task is a nested optimization problem that takes into consideration the follower’s response.\r\n\r\nIn this talk we focus on new branch-and-cut (B&C) algorithms for dealing with mixed-integer bilevel linear programs (MIBLPs). We first address a general case in which intersection cuts are used to cut off infeasible solutions. We then focus on a subfamily of MIBLPs in which the leader and the follower share a set of items, and the leader can select some of the items to inhibit their usage by the follower.\r\nInterdiction Problems, Blocker Problems, Critical Node/Edge Detection Problems are some examples of optimization problems that satisfy the later condition. We show that, in case the follower subproblem satisfies monotonicity property, a family of \"interdiction-cuts\" can be derived resulting in a more efficient B&C scheme.\r\n\r\nThese new B&C algorithms consistently outperform (often by a large margin) alternative state-of-the-art methods from the literature, including methods that exploit problem specific information for special instance classes. ", :title "From Game Theory to Graph Theory: A Bilevel Journey", :keyword2 57, :authors (22042), :session 231}, 52 {:keyword1 165, :keyword3 35, :abstract "We consider a market at which electricity is produced from fuel. Several generators, fuel storage, and the related costs are considered. Based on stochastic optimization in Banach spaces, we derive a necessary and a sufficient no-arbitrage conditions and analyze them further in the context of (potentially nonlinearly) autoregressive price models. For this large class of statistical models, it is found that the necessary condition can be rejected only in very unrealistic cases. The sufficient condition, however, leads to a simple logical constraint that can be used for restricted parameter estimation and for testing the hypothesis of absence of arbitrage. Finally, we analyze the consequences of these findings for contract valuation and for tree construction in the stochastic optimization context.", :title "Arbitrage Conditions and Contract Valuation for Electricity Markets with Production and Storage", :keyword2 28, :authors (18480), :session 194}, 53 {:keyword1 126, :keyword3 35, :abstract "We contribute to modern OR by hybrid (continuous-discrete) dynamics of stochastic differential equations with jumps, their control and optimization. Those systems allow for the representation of random regime switches (or paradigm shifts), and are of growing importance in science, engineering, finance, economics, neuroscience and medicine. We present several new approaches to this area of stochastic optimal control, and give results. These are analytical, e.g., by optimality criteria, of closed-form or numerical approximations. We discuss the occurrence of delay, of partial information and stochastic games, provide findings and examples.", :title "Stochastic optimal control and games in finance, economics and medicine under regime switching, jumps and delay", :keyword2 165, :authors (3524 46349), :session 181}, 55 {:keyword1 45, :keyword3 96, :abstract "This research presents a new model for constructing annual schedules for medical residents based on the regulations of a German teaching hospital as well as the program restrictions of the German Medical Association. Since resident programs of physicians do not only vary between disciplines but also between countries, it is essential to evaluate the main characteristics of the program. The main difference between the already well-studied resident programs in the US and the one of this research is the task-related structure. Residents need to perform different interventions several times to become specialists. This study will focus on Germany since there was a judgment in 2015 that hospital management needs training schedules guaranteeing the success of the resident program in time. Therefore, a new formulation of a tactical resident scheduling problem is presented. The problem is formulated in two stages considering the total number of interventions, equal progress in training as well as continuity of care. As the second stage of our formulation is a quadratic program and even by linearization standard solvers are not able to generate high-quality solutions within 24 hours, a genetic algorithm using standard crossovers is developed for the second stage constructing annual schedules for an existing stock of residents. We evaluate our algorithm by comparing the solutions of the genetic algorithm and the solver with a real-world situation of a German training hospital from 2016.", :title "Annual scheduling for anesthesia medicine residents in task-related programs with a focus on continuity of care", :keyword2 121, :authors (55648), :session 171}, 56 {:keyword1 109, :keyword3 59, :abstract "To stay competitive and preserve high customer service levels, the focus of warehouses in today's supply chain is on fast and timely delivery of small and more frequent orders. To compete with other warehouses, companies accept late orders from customers, which results in additional pressure on order picking operations. Specifically, more orders need to be picked and sorted in shorter and more flexible time windows, which often results in workload peaks during the day. While previous order picking literature focusses on balancing the workload over order picking zones, shifts or days, this study goes beyond the current state-of-the-art by minimising the workload variation during a working day. The problem is defined as the operational workload balancing problem and formulated as a mixed integer programming model. \r\n\r\nThe operational workload balancing problem is motivated by an international warehouse located in Belgium. Shipping schedules are fixed at the operational level to provide a high customer service. These shipping schedules result in workload peaks during the day, as departure deadlines of shipping trucks are unevenly divided over the working day. Workload peaks in the order picking environment disturb other warehouse activities, because workers of these corresponding activities are assigned to pick orders whenever the required order throughput exceeds the available capacity of the order pickers. Furthermore, workload peaks result in a high probability of missing shipping deadlines as orders could not be picked before the deadline. \r\n\r\nThe objective of this study is to test multiple objective functions (e.g., range, variance, and Gini-coefficient) with the aim of balancing the workload during the day. Additionally, an iterated local search algorithm is provided to solve the operational workload balancing problem. The performance and practical applicability of the algorithm are shown by analysing and explaining a wide range of warehouse parameters. The proposed model provides schedules that show in which time slot (i.e., usually a single time slot for each hour) to pick orders of each shipping truck in order to minimise the workload variation for each time slot. The schedule provides insights for warehouse supervisors how to plan order pickers during the day, in this way, avoiding peaks in workload. Moreover, supervisors are able to improve the control on the order picking process, reducing the probability of missing deadlines. Therefore, the order picking performance is less depending on individual experience and judgement of supervisors. A balanced workload during the day results in a more stable order picking process, which ultimately results in more efficient warehouse operations. ", :title "Daily workload balancing in zoned order picking systems", :keyword2 96, :authors (47846 59516 23971 36613 23979), :session 191}, 58 {:keyword1 150, :keyword3 45, :abstract "Nurse schedules typically contain assignments over a month and are created multiple months in advance. These schedules are usually designed to cover demand forecasts based on historical observations. Workforce-related inputs include information about nurse availability, shift preferences and nurse qualifications. Such schedules do not incorporate possibilities of flexible reassignments of qualified nurses that allow daily readjustments in response to unexpected patient demand fluctuations.\r\nTo overcome this issue, a pool of float nurses could be implemented. This pool consists of experienced nurses who can be assigned to one of several medical departments on short notice. The scheduling task for these float nurses is to decide on their working shifts in advance.\r\nThe research questions are: How and when should the hospital take advantage of flexible nurse scheduling to reduce the negative effects of hospital overcrowding and demand fluctuations, while providing high quality patient care and consideration of nurse satisfaction? Also, how large must the float nurse pool be to be able to take advantage of additional flexibility?\r\nWe model the described problem as Multi-Stage Stochastic Problem and translate it into its' deterministic equivalent by discretization of possible patient demand realizations. To cope with the size of the resulting MIP, we decompose it into a Master Problem and a set of Subproblems according to Dantzig-Wolfe. This decomposition is solved using Branch-and-Price. A multifactorial test using real data is conducted and initial results are presented.\r\n\r\n", :title "A Column Generation Approach to Flexible Nurse Scheduling", :keyword2 121, :authors (55639 49216 15060), :session 171}, 67 {:keyword1 156, :keyword3 0, :abstract "Learning plays an important role in broadening employee competencies for higher productivity. Conversely, when employees leave a company, for example, these competencies might be lost and have to be rebuild. Therefore, it is of great importance to employ the learning potential by allowing allocating production tasks to employees so that learning curve effects can be leveraged in order to optimize related productivity gains.\r\nWe consider a setting where tasks arrive randomly over time for possible processing. Incoming tasks can be allocated to (human) resources, whose productivity depends on the number of tasks processed by the resource before (learning) and is impacted by changes in the workforce over time (forgetting). We formulate the task allocation problem as a weakly coupled stochastic dynamic programming problem, and use a Lagrangian Relaxation approach to derive heuristic allocation policies. We evaluate the flexibility and resilience that emerge from these policies, and analyze how various environmental factors impact performance. Our results indicate that learning eﬀects impact resource allocation dynamics and we show that higher productivity not just increases nominal capacity (measured in production outputs) but also improves costs of production.\r\n", :title "Dynamic Task Allocation With Learning And Forgetting", :keyword2 47, :authors (1658 1244), :session 158}, 70 {:keyword1 161, :keyword3 73, :abstract "Resource allocation problems are concerned with the allocation of limited resources among competing activities so as to achieve the best performances of all activities. Thus leading to a multiple criteria maximization problem with possible sum (mean) aggregation of individual outcomes, commonly used for efficient allocation solutions. However, in systems which serve many users  there is a need to respect some fairness rules while looking for the overall efficiency. The concepts of multiple criteria equitable optimization can effectively be used to generate various fair and efficient allocation schemes. The  bicriteria mean-equity approaches are widely applied, where the mean outcome is maximized while some inequality measures are minimized. Quantification of the equity in a scalar inequality measure is well appealing to system designers and not complicating too much the decision model. Unfortunately, for typical inequality measures, the mean-equity approach may lead to inferior conclusions with respect to the outcomes maximization. The class of preference models complying with the optimization of outcomes as well as with an equal consideration of the activities is mathematically formalized with the concept of equitable dominance. Solution concepts equitably consistent do not contradict the maximization of outcomes or the inequality minimization. Therefore, the achievement of equitable consistency by the mean-equity models has a paramount importance.\r\n\r\nThe Gini coefficient is a commonly used measure of inequity in income and wealth distribution. When applied to allocation models, equity is measured by the relative mean absolute difference of outcomes. In order to achieve equity, we aim to allocate resource such that outcomes are equitable. In order to achieve this goal, the best allocation scheme is defined as the one that minimizes the Gini coefficient of the outcomes. It was empirically found in real-life applications that this objective while equalizing the outcomes (fairness) it may simultaneously support their maximization (efficiency). Although it depends on the feasible set structure and there is no guarantee to achieve good equitable and efficient allocation scheme.\r\n\r\nIn this paper we show that when combined the reference point model the Gini coefficient minimization is consistent with equitable maximization preferences. When appropriate outcome shift is applied, then the Gini coefficient minimization is consistent both with inequity minimization and with outcomes maximization thus guaranteeing equitable allocation schemes. Similar results are shown for the Schutz index (relative mean absolute deviation measure) and some other relative inequality measures. The interval of appropriate target values depends on the allocation problem structure (feasible set). Although it can be find or adjusted during the optimization process without necessity of a special feasible set analysis.\r\n", :title "Fair Resource Allocation by Gini Index Minimization", :keyword2 19, :authors (12059 59890), :session 85}, 72 {:keyword1 54, :keyword3 175, :abstract "This paper presents a bi-objective model for determining the size and shape of a finite size facility. The objectives are to minimize both the closest and barrier distances. The former represents the accessibility of customers, whereas the latter represents the interference to travelers. The total closest and barrier distances are derived for a rectangular facility in a rectangular city where the distance is measured as the rectilinear distance. The analytical expressions for the total closest and barrier distances demonstrate how the size and shape of the facility affect the distances. The model focuses on the tradeoff between the closest and barrier distances, and the tradeoff curve provides alternatives for the size and shape of the facility.", :title "Bi-objective model for optimal size and shape of a rectangular facility", :keyword2 33, :authors (9293), :session 216}, 74 {:keyword1 42, :keyword3 151, :abstract "Graphs are used in many domains to visualize data and hence be able to perform analytical functions based on the understanding gained from the generated graphs. As the size of the graph increases, each step in the process of generating and learning the graphs comes at high computational cost. In this paper, algorithms based on spectral clustering are investigated to solve the problems inherent with large graphs. The primary objective of the paper is to identify the main bottlenecks to scaling up spectral clustering method and examine algorithms that solve them by making a comparative study on the complexity of the algorithms and results of application to a standard dataset.", :title "Large scale Spectral Clustering methods", :keyword2 173, :authors (59568), :session 230}, 75 {:keyword1 156, :keyword3 34, :abstract "We consider a decision-theoretic setting where a firm decide on capacity expansion---specifically, on when and by how much to expand its production capacity. In contrast to the canonical model of the “option to expand,” we allow for an endogenous choice of the investment lump. The firm's operating strategy consists of selecting a time of investment, namely a stopping time, as well as choosing the extra capacity lump added to its existing stock. This firm is not all equity-financed, but is partly financed by a novel type of debt instruments theorized and coined performance-sensitive debt (PSD) by Manso, Strulovici and Tchistyi (2010). Debt financing induces here the possibility for shareholders---to which benefits the management decides---to default on their debt obligations in the spirit of Leland (1994). Our intent is to investigate the impact of a debt-overhang on both the timing and the size of the investment.", :title "Real options and performance-sensitive debt", :keyword2 7, :authors (56054 7698), :session 195}, 81 {:keyword1 8, :keyword3 18, :abstract "Course assignment is a wide-spread problem in education. Often students have preferences for bundles of course seats or course schedules over the week, which need to be considered. First-Come First-Served (FCFS) is the most widely used assignment rule in practice, but recent research led to alternatives with attractive properties. Bundled Probabilistic Serial (BPS) is a randomized mechanism satisfying ordinal efficiency, envy-freeness, and weak strategy-proofness. This mechanism runs in polynomial time, which is important for larger problem instances. We report a first application of BPS in a large-scale course assignment application and discuss advantages over Random Serial Dictatorship with bundle bids (BRSD). This mechanism is used to simulate the wide-spread First-Come First-Served (FCFS) mechanism and it allows us to compare FCFS (BRSD) and BPS with respect to a number of metrics such as the size of the resulting matching, the average rank, the profile, and the popularity of the assignments, which matter in the selection of assignment mechanisms. The exponential number of possible course schedules is a central problem in the implementation of combinatorial assignment mechanisms. We propose a new way to elicit preferences which limits the number of parameters a student needs to provide. Together with BPS this yields a computationally very effective tool to solve course assignment problems with thousands of students in practice.", :title "Assigning Course Schedules: About Preference Elicitation, Fairness, and Truthfulness", :keyword2 153, :authors (59456 55333 59576), :session 67}, 82 {:keyword1 14, :keyword3 57, :abstract "We present a general framework to accelerate significantly the algorithms for nonnegative matrix factorization (NMF). This framework is inspired from the extrapolation scheme used to accelerate gradient methods in convex optimization. However, the use of extrapolation in the context of the two-block coordinate descent algorithms tackling the non-convex NMF problems is novel. We propose several effective strategies to tune the extrapolation parameters, and illustrate the performance of this approach on synthetic, image and document data sets.", :title "Accelerating Nonnegative Matrix Factorization Algorithms using Extrapolation", :keyword2 13, :authors (59578 47783), :session 182}, 91 {:keyword1 109, :keyword3 0, :abstract "In this paper we develop a heuristic based on adaptive large neighborhood search for the solution of a problem that is encountered in warehouses and distribution centers (DCs) operating in supply chain networks. The problem focuses on order picking operation carried out in a warehouse to satisfy orders placed by stores/retailers. The order picking process is executed based on a manual picker-to-parts system in which (human) pickers move to the storage location of the parts. Moreover, we consider a low-level picker-to-parts system operated under a pick-by-order picking policy, which is still common in DCs operated by major retailers in many countries.\r\nThis is the case in particular when the retailer owns geographically dispersed stores which are supplied from several mid-sized warehouses in a metropolitan city. In this study we investigate the simultaneous solution of the storage assignment problem and picker routing problem by assuming that the layout design and dimensioning of the storage system are assumed to be given. The problem that we refer to as the joint storage assignment and picker routing problem (JSAPRP) involves assigning items to storage locations (storage assignment problem) and deciding on the route of each picker (picker routing problem). The performance measure of interest is the\r\nminimization of the total travel distance of the pickers traversed for satisfying the orders during a given period. Since a mathematical model developed for the JSAPRP in a previous study cannot handle instances of realistic size, we opt for developing a heuristic solution method based on\r\nadaptive large neighborhood search. Computational results obtained on numerous experiments reveal that this heuristic outperforms some traditional heuristics suggested in the literature in terms of the total traveled distance. Furthermore, experiments performed on a real case study\r\nindicate that considerable savings can be achieved with respect to the current implementation.", :title "An Adaptive Large Neighborhood Search Heuristic for Jointly Solving Storage Location Assignment and Picker Routing Problem", :keyword2 59, :authors (23883 60168), :session 205}, 93 {:keyword1 96, :keyword3 45, :abstract "Any manager of nurses, guards, assembly line workers or any other type of employees that don’t work 9 to 5 will agree: shift rostering is difficult - and time consuming. Holidays affect the schedule, employees take PTO (or call in sick) and staffing requirements change regularly. Meanwhile the schedule must adhere to labor laws, without incurring extra staffing costs. At the same time, it should also fulfill employee requests, treating all employees fairly.\r\n\r\nIn this session, the lead and founder of OptaPlanner will explain the design and architecture of optashift-employee-rostering, an open source web application to assign employees to shifts under various constraints. He’ll also explain the technical nuances of hard and soft constraints, incremental score calculation and continuous planning.\r\n\r\nOptaPlanner is an open source constraint solver in Java that is used across the globe by governments, nonprofits and companies ranging from startups to Fortune 500 companies.\r\n", :title "Employee shift rostering optimization with OptaPlanner’s metaheuristics", :keyword2 121, :authors (34301), :session 46}, 96 {:keyword1 96, :keyword3 150, :abstract "We consider a flexible job shop scheduling problem with sequence-dependent setup times that incorporates heterogeneous machine operator qualifications by taking account of machine- and operator-dependent processing times. We analyze two objective functions, minimizing the makespan and minimizing the total tardiness, and present exact and heuristic decomposition based solution approaches. These approaches divide the scheduling problem into a vehicle routing problem with precedence constraints and an operator assignment problem, and connect these problems via logic inequalities. We assess the quality of our solution methods in an extensive computational study that is based on randomly generated as well as real-world problem instances.", :title "Exact and heuristic solution approaches for a flexible job shop scheduling problem incorporating machine operator restrictions", :keyword2 36, :authors (59590 29563 55993), :session 161}, 101 {:keyword1 101, :keyword3 99, :abstract "Human decision making in the newsvendor context has been analyzed intensively in laboratory experiments, where various decision biases have been identified. However, it is unclear whether these biases also exist in practice. We analyze the ordering decisions of a manufacturer who faces a multi-product newsvendor problem with an aggregate service level constraint. The manufacturer broadly exhibits the same biases as subjects do in the laboratory and is prone to another bias that has not been identified before, that is, group aggregation. The bias can be attributed to the multi-product problem of the manufacturer, and refers to the observation that the service levels are not optimized for individual products, but rather for product groups. Our data allows us to analyze the manufacturer's performance in detail and we find that he achieves target service levels effectively, but not efficiently. We provide rationales for the manufacturer's ordering behavior, discuss managerial implications, and quantify the financial benefits of de-biasing ordering decisions.", :title "An Analysis of Empirical Newsvendor Decisions", :keyword2 18, :authors (42203 19894 9112 14573), :session 20}, 103 {:keyword1 59, :keyword3 14, :abstract "The generalized gamma distribution proposed by Stacy in 1962 is extremely flexible and used in many fields such as health costs, civil engineering, economics and so on (Gomes et al. 2008). The probability density function (pdf) of a random variable X, which has a generalized gamma distribution is defined by shape parameters α, γ and scale parameter β (Carneiro et al. 2016; Stacy and Mihram, 1965; Chen, 2017). \r\n\r\nThe generalized gamma distribution contains many well-known distributions as special cases, such as the Exponential distribution, the Gamma distribution, the Rayleigh distribution, the Weibull distribution and The Levy distribution. The maximum likelihood method and the moments method have been used for parameter estimation of the generalized gamma distribution by various authors (Gomes et al. 2008; Stacy and Mihram, 1965). \r\n\r\nThe maximum likelihood (ML) method is a widely used method in order to estimate the parameters of a distribution. Because formation of the likelihood function to maximize for the parameter estimation of some distribution is a fairly difficult problem, heuristic optimization algorithms have been proposed to achieve better solutions. \r\n\r\nParticle swarm optimization (PSO) developed by Eberhart and Kennedy in 1995, is a population based heuristic optimization technique, which was inspired by social behaviour of bird flocking and fish schooling. Recently, various heuristic methods such as genetic algorithm (GA), simulated annealing (SA) and differential evolution algorithm (DE) were introduced for parameter estimation of some statistical distributions e.g. Weibull, Gompertz, Mixture, Log-normal. PSO algorithm is suitable for maximizing the likelihood function, because of its simplicity and easiness of implementation (Carneiro et al. 2016; Örkcü et al. 2015).\r\n\r\nIn this study, we carried out a simulation study to evaluate the performance of the maximum likelihood estimation (MLE) via PSO algorithm for different parameter settings and sample sizes of the generalized gamma distribution. The simulation results show that the PSO algorithm ensures proper estimations providing a rapid convergence to the maximum value of the likelihood function in less iterations.\r\n", :title "Particle Swarm Optimization for Parameter Estimation of the  Generalized Gamma Distribution", :keyword2 152, :authors (31863 52590), :session 204}, 108 {:keyword1 96, :keyword3 45, :abstract "The ongoing workforce shortage and the increasing expenditures in hospitals lead to difficult tasks for hospital management. Especially in personnel scheduling, it is crucial to utilize advanced approaches supported by operations research methodology, because an optimal schedule can increase service quality and reduce overtime as well as wage costs. In this study, we develop a combined shift design and workplace assignment problem that handles workstation rotation requirements. The goal is to find the optimal plan to minimize over- and understaffing for a given workforce. Due to the complexity of the program, we solve the problem with a column generation heuristic. We use real-world data from a radiology department and schedule medical radiation technicians. We provide insights how this approach can be beneficial for schedules with pre-defined shifts. Furthermore, the effects of allowing or requiring workstation switchovers are discussed and evaluated.", :title "Analysis and optimization of personnel scheduling planning for medical radiation technicians ", :keyword2 158, :authors (59605 55648 49216 15060), :session 171}, 115 {:keyword1 19, :keyword3 0, :abstract "This paper proposes a systematic extension of drift-diffusion model (DDM) with correspondence to the generalized nested logit model (GNLM). The DDM is a stochastic and discrete choice model considering clearly micro duration to make a decision. A basic and typical DDM is under binomial choice situation. We observe a chosen alternative and duration to make a decision, and estimate parameters of the model with these information. Using information of duration to make a decision, higher accuracy of choice probability can be expected with DDMs than with classical random utility models (e.g. Logit and Probit models). We usually choice multi-alternatives that have complex externalities among them in real marketing situations. Classic DDMs are extended to treat multi-alternatives by Krajbich and Rangel (2011). Many studies including Krajbich and Rangel (2011) conduct empirical analysis under control conditions, showing subjects alternatives in symmetric position on monitors. In real marketing situation, there are not only multi-alternatives but also similarities between these alternatives. When considering similarity between alternatives within choice models, we need to relax independent from irreverent alternatives (I.I.A.) property on choice models. However, classic DDMs satisfy I.I.A. property.\r\nWe propose a new hierarchical DDM using the correspondence relation between binominal logit model and DDM shown in Webb. We show choice probability in the proposed model is that in the specific GNLM that is extended from the binomial Logit model. In addition, we make an interpretation of our DDM process as a lexicographic choice process when we employ the nesting rule shown in Takahashi (2011).\r\n", :title "Relaxation of I.I.A. property on drift-diffusion models", :keyword2 25, :authors (26181), :session 176}, 119 {:keyword1 48, :keyword3 75, :abstract "We consider a representative linear production line of plastic water bottles for a major international company. We aim at maximizing the production rate of the line (over a planning horizon of a shift, which corresponds to 8 hours, typically). This optimization is strategic, as it can then be deployed to the other production lines of the company (hundreds of production lines in the world, with production rates up to thousands bottles per hour). Considering the needs of the company, a production-rate improvement is considered as significant if it reaches 2%.\r\n \r\nThe line consists of a sequence of seven machines, and with accumulation tables between each pair of machines. Each machine can run with up to four different speeds (including zero). The speed changes of a machine are triggered by sensors placed on the upstream/downstream accumulation tables. More precisely, a machine increases (resp. decreases) its speed when the upstream accumulation table reaches an upper (resp. lower) bound threshold, or when the downstream accumulation table reaches a lower (resp. upper) bound threshold. However, each machine faces some unplanned technical stoppages (e.g., a reel needs changing, an accumulation table is over-loaded, a technicality needs to be corrected, a small breakdown). The only technical constraints are the limitation of the machines (in terms of maximum speeds, reel length for the labeler machine, etc.). \r\n\r\nThe goal of this project is to tune the set of possible speeds of each machine of the line, along with the position of the sensors (corresponding to the above-mentioned thresholds) on the accumulation tables. This optimization is done while taking into account the possibility of unplanned stoppages for each machine. The probability distributions of such random events are deduced from historical data. From a practical standpoint, no machine should be stopped (i.e., having its speed fixed to zero), even if another machine suffers an unplanned stoppage. Indeed, restarting a machine results in a setup time. \r\n\r\nConsidering numerous breakdowns scenarios, we have first proposed a robust simulation tool that estimates the average production over a predefined planning horizon (typically a couple of hours). This simulation tool adapts the number of scenarios that it tests such that the average production rate is guaranteed to a certain precision. Next, we have designed a tabu-search metaheuristic to improve the production rate by changing the possible speed sets and the possible sensor positions. The objective function considered here is actually the average production rate minus its standard deviation. This helps avoiding solutions that slightly improve the average production rate but with a large increase of the standard deviation. The results show that a 5%-improvement can be expected.\r\n", :title "Enhancing the productivity of a bottle production line", :keyword2 59, :authors (59597 55877), :session 186}, 121 {:keyword1 61, :keyword3 48, :abstract "This talk reviews the development of modelling languages and tools for the formulation and solving of mathematical optimization problems since the 1980s when many of today's commercial tools were first published. \r\nWith the advent of more powerful processors and high-speed network connectivity the general usage patterns of OR tools have evolved over time and user expectations on modelling software include an increasingly large range of functionality.   \r\n\r\nOptimization models are more and more frequently deployed as distributed, multi-user solutions within company networks or in cloud-based environments.\r\nThis talk discusses the impact of these trends on modelling tools, including aspects such as data handling, support of concurrent and distributed computing, integration with analytic tools, and the role of visualization and user interaction including during the solving process.", :title "Modelling for Mathematical Optimization: Historical Notes and Current Trends", :keyword2 98, :authors (21574), :session 68}, 124 {:keyword1 8, :keyword3 35, :abstract "In traditional continuous-time asset exchange mechanisms, orders are typically collected in order books of two assets that are traded against each other. A trade happens whenever a buy order of one asset is met by a matching sell order, i.e., if there exists an exchange rate that satisfies the limit prices stated in the respective orders. In a setting of multiple tradeable assets, one separate order book is required for every asset pair. This may, however, significantly limit liquidity for less frequently traded asset pairs and lead to large bid-ask spreads and low trading volumes. Moreover, it enables arbitrage opportunities across asset pairs for professional traders.\r\n\r\nBy contrast, in our approach, we want to collect orders for a set of multiple assets in a single joint order book and compute exchange prices for all asset pairs simultaneously at the end of discrete time intervals (“multi-asset batch auction”). Trades between the same asset pairs are then all executed at the same exchange rate (“uniform clearing price”). This mechanism enables so-called ring trades, where orders are matched along cycles of assets. In order to exclude arbitrage opportunities as described above, we require prices to be consistent along such cycles, i.e., we want the exchange rates along every cycle of assets to multiply up to 1.\r\n\r\nIn this talk, we will present mathematical optimization models for determining uniform clearing prices in our multi-asset batch auction scenario, show some computational results, and give an outlook on possible extensions.", :title "Optimization models for multi-asset batch auctions with uniform clearing prices", :keyword2 6, :authors (50802), :session 195}, 129 {:keyword1 29, :keyword3 0, :abstract "The increased inclusion of regionally available renewable energies into the existing electricity system as well as the rise in energy demand of the ICT sector may cause infeasibilities in the load balancing problem of power grids. Resolving these by expanding the power transmission grid not only leads to high investment costs for network operators but often meets societal and environmental opposition. We present a model and an algorithmic framework that exploits flexible loads from geographically distributed data centers to improve grid stability in order to avoid grid expansions. In this we use coupled time-expanded networks to model the shifting of virtual machines (VMs) as well as to control the on-off status of servers. In the end, the arising discrete multi-commodity flow problems enable the integration of flexible loads into the classical Optimal-Power-Flow problem (OPF). Finally, we present first computational results based on simulated networks.", :title "Avoidance of Power Grid Expansion by Load Shifting", :keyword2 0, :authors (46464 17006), :session 192}, 130 {:keyword1 175, :keyword3 6, :abstract "Carrier collaboration is one of the big trends in transportation. Exchanging transportation requests between carriers can reduce inefficiencies and generate economic and ecologic benefits for the partners as well as for the society. In horizontal logistics collaboration, several companies exchange some of their transportation requests in order to execute them more efficiently. The forming of these coalitions is commonly realized by using auction-based exchange mechanisms. In combinatorial auctions, requests are not traded individually but are combined into packages, called bundles. The main reason for this is that a bundle might have a different (typically higher) value to the partners than the sum of the individual requests. We discuss the five typical phases in combinatorial transportation auctions: First, the carriers select request that they want to auction-off (request selection), then the auctioneer generates bundles of requests and offers them to the participants (bundling). These give their bids on offered bundles by calculating the marginal profit of each bundle (bidding). Finally, requests are allocated to carriers according to their bids, so that the total profit for the coalition is maximized (winner determination). Gained profits are distributed among the carriers (profit sharing). All five phases result in challenging optimization problems.", :title "Collaboration in Vehicle Routing", :keyword2 95, :authors (10538), :session 235}, 132 {:keyword1 162, :keyword3 49, :abstract "In this talk, the latest 11.0 release of the nonlinear solver Artelys Knitro is presented. Knitro 11.0 introduces a novel solver for optimization problems with conic constraints. It encompasses second-order cone programs (SOCPs) as well as more general nonlinear non-convex models with conic constraints. Encouraging numerical results are presented on standard SOCP benchmarks. Knitro 11.0 also introduces a new C API, which allows users to build complex optimization models piece by piece and to provide a lot of structure in their problem formulation. Conic constraints are covered by the new API. Finally, several other numerical improvements on convex programs as well as ill-conditioned problems are presented.", :title "Artelys Knitro 11.0, a new conic solver and other novelties", :keyword2 98, :authors (59617 31710 59618 59619 59620), :session 24}, 134 {:keyword1 2, :keyword3 188, :abstract "Tail assignment is the process of planning the assignment of aircraft to flights from the day of operations and a few days, or weeks, into the future. Schedule recovery is the process of deciding how to operate the aircraft at an airline when operational disruptions happen.  In  this presentation we will discuss how a combined tail assignment system and schedule recovery system gives benefits compared to using separate systems. We will also show how integration with crew tracking and flight planning can give additional benefits. Computational results on real-world data will be presented.", :title "Fleet operations - combining tail assignment and schedule recovery", :keyword2 18, :authors (52787), :session 167}, 136 {:keyword1 175, :keyword3 0, :abstract "In intermodal transport, vehicle routing problems for drayage operations are usually solved after long-haul routing decisions have been made. In current literature, the distance or travel time between each customer location and the available terminals is taken into account when solving the intermodal routing problem. Afterwards, pre- and end-haulage is arranged by combining given transport tasks between customer locations and terminals into routes.  Although an integrated view on these problems may provide cost savings and a better utilization of the long-haul transport capacity, both problems are often considered independently. \r\nThe aim of this research is to assign full-container requests to given, scheduled long-haul services and determine vehicle routes in order to minimize the total transport cost of the system, which consists of the rail transport cost and the truck routing costs. For each request, the customer pickup and delivery locations are known, while the terminals through which it travels depend on the selected service. Consequently, the delivery location for pre-haulage transport tasks and pickup location for end-haulage transport tasks are unknown in advance. The decision on the service selection influences the routes of trucks in a service region, and thus the total costs. Therefore, we present an integrated problem which considers both long-haul service selection and the local routing of trucks at the same time. The problem is based on a real-life case study from the viewpoint of the transport planning department of an intermodal service operator with a network of long-haul direct rail services between multiple terminals within two large-volume freight regions, operated based on weekly schedules. A mixed integer programming formulation is presented to solve the integrated intermodal routing problem. Preliminary experiments with small problem instances demonstrate the benefits of integrated decision-making. \r\n", :title "On the advantages of including local drayage costs into intermodal routing decisions", :keyword2 187, :authors (50435 23979 23971), :session 165}, 137 {:keyword1 156, :keyword3 99, :abstract "A production planning problem is studied under the assumption that the lifespan of a product unit is a random variable. As each product unit at a certain age can independently perish at the end of every period, the total number of perished product units is also a random variable that depends on the number of units placed into inventory in the previous periods. In this sense, the support of the random variable (i.e. the number of units that may perish at a certain age) depends on the decisions taken beforehand (i.e. how much to produce and, as a consequence, how much to store in inventory). In other words, this uncertainty is intrinsic rather than externally given. The production manager as usual wants to minimize the (expected) total cost due to setups, production, inventory holding, shortages and perished inventory. The trade-off between these different costs is complicated by the fact that there are different probabilistic consequences for every decision about the inventory volume and vice versa.\r\nIn every period, the total available time for producing different product types is a given value. Hence, this time is a common capacity restriction for the production decisions and needs to be allocated accordingly.\r\nSome interesting characters of the problem are explored by means illustrative examples, which can be solved by hand to show the hardness of the problem analysis. For example, it can be shown that inventory perishability is unavoidable in the optimal solution of the problem. Another beautiful case is to see by numerical example that the famous FIFO (i.e., First-In-First-Out) rule is not necessarily optimal – even for single product case – for picking inventories of different ages from the warehouse to satisfy customers’ demand.\r\n", :title "Multi-product production planning under inventory perishability", :keyword2 75, :authors (54544 15198), :session 189}, 139 {:keyword1 45, :keyword3 0, :abstract "The last couple of years, emergency department (ED) crowding has become a major international problem. Crowding is caused by an increase in the demand for emergency services in combination with a lack of sufficient resources to fulfil the demand. The aim is to improve ED efficiency by allocating the available capacities in the best possible way, while taking the interests of staff, patients and hospital management into account. In order to analyse and optimise ED operations, simulation techniques are frequently used. Simulation enables to capture the stochastic, complex and time-dependent nature of patient flow through an ED. As a result, a simulation model is capable of approximating real-life behaviour, and allows for reliable what-if analyses. \r\nThe aim of our research is to compare different improvement options and identify the most effective (combination) based on a realistic simulation model of a Belgian ED. Discrete-event simulation is used because of the ability of this simulation technique to model patient flow at the level of an individual patient. Furthermore, discrete-event simulation models the system on a microscopic level with a large amount of detail. These characteristics make this method particularly suitable for operational analysis, requiring a detailed model of the system to find specific improvement areas. Our discrete-event simulation model is based on the ED of a Belgian university hospital. As a result of using real-life input data extracted from the electronic health records of the ED under study, and because of a thorough analysis of these input data, the model provides a realistic and detailed representation of the actual patient flow through the ED. Furthermore, insights into possible problem areas within the ED are acquired through the input data analysis. The findings of this analysis are used along with the simulation output to identify possible areas for improvement. \r\nIn current ED simulation literature, an extensive amount of improvement options and key performance indicators (KPIs) are provided. A sensitivity analysis is executed to identify the most promising options to improve ED performance within different parts of patient flow. The improvement options are weighed against each other based on a set of KPIs, as covering all aspects of ED performance and the interests of all stakeholders within one KPI is impossible. In addition to evaluating single improvement options, the effect of the simultaneous introduction of improvements is also investigated. Improvement options are usually considered independently in ED simulation literature, but given the interdependency between sequential processes within the patient flow and the fact that improvements may have contradicting effects on different KPIs, this approach may lead to a suboptimal solution for the crowding problem. \r\n", :title "A comparative analysis of solutions for the emergency department crowding problem by use of discrete-event simulation", :keyword2 97, :authors (57080 23971 36613 36613), :session 173}, 144 {:keyword1 75, :keyword3 109, :abstract "Under highly competitive conditions in today's business environments, proper pricing policies for products and services can be considered as a competitive advantage for manufacturing and service firms. Since the main concern of most manufacturing and service institutions is to minimize inventory system costs, including ordering, holding, and purchasing costs, achieving this goal requires the use of scientific methods to provide models for determining the amount of economic order quantity. On the other hand, due to the competitive nature of the market, some vendors consider quantity-dependent discounts to encourage buyers. Accordingly, in this paper a quantitative model is presented which has declare the price for the first unit of sale that equals with vendor determination, and for the next purchased units up to Q0, presents price reduces in a shape of a decreasing  continuous line. In other words, the price in the interval (0, Q0) is linear, reducing and decremental; and for the Q=>Q0 price is constant and equals with C1. The purpose of this model is to determine the amount of economic order in determined conditions based on the purchase price of the goods, which can optimize the total cost of holding, ordering and purchasing. In the implementation of the model, it is firstly determined that the economic order quantity is placed in which of the intervals (0, Q0), or [Q, ∞).Then, if the economic order is within the range of (0, Q0), then the amount of economic order is obtained through the proposed model; Therefore, based on the determined economic order quantity, the unit purchase price for all of the purchased amounts in the range of C2 and C1 will be calculated. However, if Q*=>Q0, then Q* is in the range [Q, ∞), and the amount of the economic order quantity is obtained by the Wilson formula; also the price of each unit will be equal to C1.", :title "An Economic Order Quantity Model under the Terms of Continuous Discount", :keyword2 91, :authors (5392), :session 191}, 146 {:keyword1 96, :keyword3 0, :abstract "Electric vehicles (EVs) are on the rise. Their growing need for electricity poses a challenge for both local infrastructures and the energy grid as a whole. Undersized connection lines and a lack of charging stations limit the number of EVs which can be charged concurrently. Combined with peaking power demands there is a need for smart charging. In company fleets, EVs accumulate for long stays in one location and smart charging can utilize this planning flexibility.\r\n\r\nThe output of smart charging is a schedule which specifies which EVs may charge, when and at which current. Different objectives can be considered for smart charging. Cost minimization optimizes the schedule with respect to electricity costs while peak shaving ensures an even energy consumption over time. In this work we focus on cost minimization.\r\n\r\nSmart charging can be considered in different contexts such as the time of planning. Day-ahead planning uses complete information about energy prices and EV arrival times and considers day-ahead energy markets. Real-time planning manages individual EVs at their actual time of arrival and thus handles charging processes continuously. Here, we focus on real-time planning, making use of day-ahead planning as guiding information.\r\n\r\nFor day-ahead planning, we formulate a mixed integer programming (MIP) model which takes into account infrastructure and EV constraints. Standard MIP solvers find optimal solutions for this model, however with impractical computation times. In this work we use an assignment heuristic to fix most integer decision variables and then solve a submodel of the MIP.\r\n\r\nFor real-time planning, we describe and compare three approaches. The status quo approach schedules every EV for charging directly after arrival. The lookup approach retrieves the charging schedule for each EV from day-ahead planning and applies the schedule without reacting to any changes. Lastly, we propose a schedule guided heuristic approach which also looks up the charging schedule from day-ahead planning but then adapts it in case of changes such as unexpected EVs or deviating arrivals.\r\n\r\nSimulation is used to compare the real-time planning smart charging approaches. Historical data from a company fleet in Germany is used to generate a charging infrastructure and EVs for simulation. Experimental results show significant cost reductions of the guided heuristic compared to the status quo.\r\n\r\nTo summarize, we present a two-step approach to address the fleet charging problem. The first step consists of day-ahead planning. Resulting charging schedules are used as input for the second step where the proposed schedule guided heuristic is used for real-time planning. In conclusion, the two steps describe a real-time smart charging approach which introduces load balancing and reduces energy costs.", :title "Real-time Planning for Smart Charging of Electric Vehicle Fleets", :keyword2 29, :authors (56896 59636), :session 212}, 147 {:keyword1 8, :keyword3 98, :abstract "LocalSolver is a mathematical programming solver based on heuristics technics. Having modeled your optimization problem using common mathematical operators, LocalSolver provides you with high-quality solutions in short running times. \r\nCollection decisions have been introduced to LocalSolver formalism to simplify the modeling of some combinatorial problems. A Set in an unordered subset of integers from 0 to n-1 and can be used to model packing problems. A List is the ordered version of the Set and is useful to formulate routing problems. Constraints and objectives can be defined on collections by applying functions expressed with LocalSolver operators. The main advantage of these collections is keep the number of variables linear in the input size instead of quadratic with the classical Boolean formulation. \r\nThis presentation will show how this new kind of variables allows building very simple and effective models for several optimization problems, including routing and scheduling problems. Benchmarks on classical binpacking and vehicle routing problems will be presented.\r\n", :title "Solving packing, routing and scheduling problems with LocalSolver", :keyword2 61, :authors (60247 18585), :session 49}, 149 {:keyword1 133, :keyword3 158, :abstract "Many technical applications involve the heating and cooling of fluids. In technical terms, the corresponding systems are called thermofluid systems. These systems can be regarded as fluid systems with superimposed heat transfer. However, since both parts mutually depend on each other they have to be considered simultaneously. As an extension of previous research on fluid systems, we present a mathematical model for the algorithmic system design of thermofluid systems. This includes modeling the physical properties and system components related to heat transfer. Besides that, another issue arises if heat transfer is considered. While it can be reasonable for fluid systems to be assumed as quasi-stationary systems, this does not hold for most thermofluid systems. Although some can be regarded as quasi-stationary, most of them show dynamic behavior. A major reason for this is that when dealing with heat, storage tanks become important. Thus, an appropriate time representation must be found. For this purpose, we introduce a continuous-time approach based on a formulation.", :title "Modeling Thermofluid Systems - An Approach Customized for Optimization", :keyword2 48, :authors (55746 39554), :session 25}, 152 {:keyword1 174, :keyword3 99, :abstract "In the past decades Logistics network design has been a very active research field. This is an area where Facility Location and Logistics are strongly intertwined, which is explained by the fact that many researchers working in Logistics address very often location problems as part of the strategic/tactical logistics decisions. Despite all the work done, the economic globalization together with the emergence of new technologies and communication paradigms are posing new challenges when it comes to developing optimization models for supporting decision making in this area. Dealing with time and uncertainty has become unavoidable in many situations.\r\n\r\nIn this presentation, different modeling aspects related with the inclusion of time and uncertainty in facility location problems are discussed. Emphasis is given to multi-period stochastic programming models. The goal is to better understand problems that are at the core of more comprehensive ones in Logistics Network Design. By considering time explicitly in the models it becomes possible to capture some features of practical relevance that cannot be appropriately captured in a static setting. Additionally, by considering a stochastic modeling framework it is possible to build risk-aware models. Unfortunately, the resulting models are often too large and thus hard to tackle even when using specially tailored procedures. This raises a question: is there a clear gain when considering a more involved model instead of a simplified one (e.g. deterministic or static)? In search for an answer to this question, several measures are discussed that include the value of a multi-period solution and the value of a (multi-stage) stochastic solution. By considering adequate models it is possible to combine the above measures and to quantify the relevance of considering risk in Logistics Network Design. \r\n\r\nSome references:\r\n\r\nDunke, F., Nickel, S., Heckmann, I., Saldanha-da-Gama, F., \"Time Traps in Supply Chains: is Optimal Still Good Enough?\", EJOR 264 (2018), 813-829. \r\n\r\nAlbareda-Sambola, M., Fernández, E., Saldanha-da-Gama, F., \"Heuristic solutions to the Facility Location Problem with General Bernoulli Demands\", IJOC 29 (2017), 737-753.\r\n\r\nCastro, J., Nasini, S., Saldanha-da-Gama, F., \"A cutting-plane approach for large-scale capacitated multi-period facility location using a specialized interior-point method\", Mathematical Programming A 163 (2017), 411-444.\r\n\r\nHinojosa, Y., Puerto, J., Saldanha-da-Gama, F., \"A two-stage stochastic transportation problem with fixed handling costs and a priori selection of the distribution channels\", TOP 22 (2014), 1123-1147.\r\n\r\nNickel, S., Saldanha-da-Gama, F., Ziegler, H.-P., \"A multi-stage stochastic supply chain network design problem with financial decisions and risk management\", Omega 40 (2011), 511-524. \r\n\r\nMelo, M.T., Nickel, S., Saldanha-da-Gama, F., “Facility location and supply chain management – A review”, EJOR 196 (2009), 401–412.\r\n", :title "Logistics Network Design and Facility Location: The value of a multi-period stochastic solution", :keyword2 54, :authors (9684), :session 239}, 161 {:keyword1 86, :keyword3 158, :abstract "Regularly planned and scheduled maintenance is a critical requirement for keeping the equipment running at peak efficiency. Maintenance scheduling becomes complex when the machines are geographically distributed. In this case, in addition to assigning the maintenance operations to technicians, it is needed to find the best set of routes for technicians’ visits. In fact, it is necessary to study the maintenance and the routing decisions simultaneously. Such a joint decision problem is known as the maintenance-routing scheduling problems.\r\nTo the best of our knowledge, few studies attempted to investigate simultaneously maintenance scheduling and vehicle routing problem. In this study a mathematical model is proposed to determine optimized maintenance policy and routing policy, simultaneously. In this model, the objective function minimizes the total cost due to traveling, delay in start time of a Preventive Maintenance (PM) operation on customer’s machine and the wages of technicians for performing the PM operation. In this study, there is a system with some customers geographically distributed, where each customer has one machine that should be visited and repaired by technician in different cycles. The PM operations should be scheduled with a certain frequency to reduce the occurrence of unforeseen failure in the long term. The set of technicians visit the set of machines to perform the PM operation in order to prevent the system failure. The technicians are different in skills regarding required time to perform a maintenance operation; the more skillful a technician is, the more salary he gains. In the optimized schedule policy, it will be determined that which technician should be assigned to which customers and in which sequence technicians should visit and perform PM operations at each period.\r\nThere is also increasing pressure on companies from the governmental and non-governmental communities and more generally from public opinion to persuade them to consider safety and health of workers in their activities. For this purpose, regarding the noise regulation, the technician assignment in this model is based on the maximum noise exposure per day, called as Daily Noise Dosage (DND).\r\nFor the sake of applicability of framework, we address the uncertainty by considering fuzzy distributions for some parameters. Finally, we solve the proposed mixed-integer linear model using solver CPLEX v10.1 in the optimization software of “GAMS v22.2” and propose some managerial insights.  The obtained results show that consideration of the workers’ health in the proposed model has a huge impact on the configuration of routs, maintenance scheduling and total cost of the system.", :title "A Stochastic Maintenance-Routing Problem by considering workers’ health", :keyword2 96, :authors (52786 2519), :session 157}, 165 {:keyword1 165, :keyword3 134, :abstract "Two-stage stochastic programs and bilevel problems under stochastic uncertainty bear significant conceptual similarities. However, the step from the first to the latter mirrors the step from optimal values to optimal solutions and entails a loss of desirable analytical properties. The talk focuses on mean risk formulations of stochastic bilevel programs where the lower level problem is quadratic. Based on a growth condition, weak continuity of the objective function with respect to perturbations of the underlying measure is derived. Implications regarding stability for a comprehensive class of risk averse models are pointed out. Furthermore, extensive formulations for various notions of risk aversion under finite discrete uncertainty shall be discussed.", :title "Risk averse bilevel programming under uncertainty: Stability and extensive formulations", :keyword2 93, :authors (44979 59646 7687), :session 208}, 170 {:keyword1 175, :keyword3 23, :abstract "To further the degree of realism of a simulation model it is essential to calibrate it with empirical data. Initial steps to do so and most of the literature for pedestrian simulation models are based on average values (e.g. flow through a bottleneck) or distributions of basic input properties (e.g. free walking speeds) for this purpose.\r\n\r\nHere we report about a laboratory experiment and its results where we measured the distribution of dwell times of individuals in a room as part of a crowd that walked through a bottleneck with insufficient capacity, much like some previous experiments (Bukáček, Hrabák and Krbálek 2014). These results are compared with results of a Social Force Model simulation software (PTV Viswalk).\r\n\r\nIn summary the comparison of empirical results simulation results with mostly default parameters – minimum adjustments were made to match average travel times – shows a much sharper distribution of dwell times than the simulation results. Compared to the empirical results, simulation results peaked at smaller dwell times and the distribution extended to much higher dwell times for a small number of individuals.\r\n\r\nThis discrepancy could be reduced significantly by varying the value of Social Force Model parameter tau with the desired walking speed, whereas in standard settings (of the particular simulation software, but also various publications not related to that software) only walking speeds vary while the value of parameter tau is fixed.\r\n\r\nThe race|result measurement technology allows an identification of individuals when they entered as well as when they left the room. With this information it was possible to count the minimum number of overtaking events (when the sequence of two persons leaving was swapped compared to when they entered the room). The empirical data showed a much more peaked distribution then the simulated data and again the matching could be improved by varying the value of parameter tau with the desired speed.\r\nIn sum this indicates that Social Force Models tend to yield more realistic results and are easier to be calibrated if not desired speed and tau are set as independent variables, but desired speed and the ratio desired speed over tau – which one may call “base acceleration”.\r\n\r\nThis is particularly interesting insofar as model realism is discussed usually in terms of either model (algorithm resp. equations of motion) comparison or parameter value choice. Here it is the relation of parameter value distributions which makes for a significant difference.\r\n", :title "Validation and Calibration of a Model of Pedestrian Dynamics by Travel Time Distribution Analysis", :keyword2 127, :authors (59652), :session 44}, 171 {:keyword1 97, :keyword3 100, :abstract "These days, playing dirty is encouraged by the (assumed) anonymity of the internet and motivated by a plethora of new products or services competing in winner-take-all markets, which ultimately will be dominated by a single product or service (eBay or Amazon may serve as illustrative examples). For some rivals, spreading the infamous “fake news” or putting other forms of smear campaigns into practice might therefore appear an appealing option in an attempt to keep up with their superior opponents in the fight for market dominance in a globalized setting. Such measures that actively discredit competitors are called negative campaigning.\r\n\r\nOur contribution to the research in this field is twofold: first, we investigate the effect of negative campaigning on the emergence of a winner-take-all situation, and second, we analyze its effectiveness as opposed to traditional marketing promoting one’s own product.\r\n\r\nAs a method, we employ agent-based simulation by expanding a previous model (recently published in CEJOR) on the emergence of dominant designs. As a use case, this model looked at the emergence of dominant weapon designs in the fight of humans against vampires, that is, under which circumstances stakes, mirrors, garlic, or silver bullets (which obviously differ in effectivity) can become a dominant design. In this, admittedly, rather special application case, humans represent the customers, the weapons are the technologies competing for market dominance, and the vampires can be interpreted as the problem that is supposed to be solved by the technologies.\r\n\r\nThe results of our simulation experiments show that negative campaigning–though it leads to more extreme views–sometimes even slightly lowers the overall possibility of one single product “winning the market,” while traditional (positive) marketing in most instances increases it. This is due to the negative consequences for the discredited product counterbalancing the positive effect for the inferior weapons. Furthermore, although negative campaigning in principle can increase the probability of an inferior product becoming the dominant design if it is aimed at one of its superior competitors, positive marketing would still be more effective, as spreading negative news about the technologically best or second best weapon mostly benefits the second best or best weapon, respectively, instead of the underdog. On the bottom line, it usually does not pay for an inferior competitor to play dirty, though it may pay for the immediate market follower. However, this company would risk that such a campaign backfires (since the internet ultimately is not so anonymous at all). Still, it might occur, and if so, agent-based modeling also could be used to test proper countermeasures. This, however, is a different story…", :title "Fighting Fair? Evaluating Negative Campaigning with an Agent-Based Simulation", :keyword2 56, :authors (59377 4357), :session 241}, 172 {:keyword1 158, :keyword3 0, :abstract "Compact Linearization is a general linearization method designed for and known to work well with zero-one quadratic problems that comprise some assignment constraints, in particular the quadratic assignment problem itself. In this talk, we present necessary and sufficient criteria for a more general class of zero-one QPs to exhibit such a compact linearization. We start with new simple criteria for assignment constraints and show how to generate a compact linearization of a given such program automatically. Then, we develop under which circumstances the approach can also be used to linearize zero-one QPs with arbitrary linear equation constraints.", :title "Compact Linearization for Zero-One Quadratic Programs", :keyword2 162, :authors (49180), :session 52}, 183 {:keyword1 33, :keyword3 158, :abstract "The p-median problem is among the most popular problem types in facility location with a broad range of application areas in logistics and supply chain management. In the standard p-median problem, given a set of demand nodes and a set of locations on a network, the objective is to locate p facilities so as to minimize the total distance between the demand nodes and their nearest facilities. This paper studies a variant of the p-median problem, which incorporates frontier-based benchmarking into the location analysis. In the proposed problem – in addition to minimizing the spatial interaction among the facilities and the demand nodes – we aim at maximizing the overall efficiency of the entire network of the p chosen facilities. The problem of maximizing the overall efficiency of the chosen facilities is presented by a bilinear mixed-integer program. This paper further seeks to formulate its equivalent mixed-integer linear program, which substantially simplifies its implementation. Integrating the outcome of this step into the location analysis – which also optimizes the spatial interaction in the network – results in a multi-objective mixed-integer program. Features and properties of the proposed approach are illustrated theoretically and also with a comprehensive numerical example.", :title "A frontier-based facility location problem with a centralized control mechanism ", :keyword2 161, :authors (13000), :session 177}, 187 {:keyword1 165, :keyword3 0, :abstract "In this research, we investigate a stochastic-dynamic knapsack problem (SDKSP) and the benefit of a dynamic policy selection (DPS). DPS combines individual policies to solve the SDKSP.\r\nIn the SDKSP, we have to accept or reject items. Every item comes with a reward and a weight. The sum of accepted items’ weights must not exceed the knapsack’s capacity. The goal is to maximize the total reward of the accepted items. A sequence of items appears over a planning horizon. The rewards and weights are subject to a stochastic distribution. Future items are unknown until they appear. For every item, we immediately have to decide whether to accept or reject it.\r\nWe model the SDKSP as a Markov decision process (MDP). In the MDP, a decision point is induced when an item appears. The associated decision state’s parameters are the remaining capacity of the knapsack and the point in time of the planning horizon. If the item’s weight does not exceed the remaining capacity, one has to decide whether to accept or reject the current item. When the item is accepted, its reward adds up to the total reward of accepted items, and its weight reduces the remaining capacity of the knapsack. Additional decision points are induced until the sequence of items is processed.\r\nSince the SDKSP is NP-hard, we cannot solve large instances to optimality. Thus, we draw on heuristic policies of approximate dynamic programming. A policy returns a decision for every decision state. We define a set of individual policies:\r\n- A greedy policy ignores future items and accepts each item until the capacity is exhausted.\r\n- A cost-benefit policy accepts an item if the ratio of reward and weight exceeds a certain threshold.\r\n- A value function approximation (VFA) explicitly takes future items into account. In a priori simulations, the VFA learns the expected future reward of a state. In this way, future items can be anticipated. By considering the current item’s reward and the expected future reward.\r\nAt the beginning of the planning period, anticipation of future items is vital in order to distinguish “good” and “bad” items. In the end, when the remaining capacity is small and every item can be the last in the sequence, acceptance of any item might be reasonable. The DPS selects the most promising policy in each decision state. To learn the expected future reward of each policy in each decision state, we implement a non-parametric policy search realized by an additional VFA. In this way, it takes explicitly future policy selections into account and autonomously adapts to heterogeneous distributions of rewards and weights.\r\nComputational studies on different data sets point out that DPS leads to a higher solution quality compared to the usage of individual policies.\r\n", :title "Dynamic Policy Selection for a Stochastic-Dynamic Knapsack Problem", :keyword2 156, :authors (57098 46184 12952), :session 207}, 189 {:keyword1 133, :keyword3 63, :abstract "Despite a trend to paperless offices, the demand for paper products worldwide is still slightly rising. The raw material for papermaking worldwide consists of 59% paper for recycling. To produce new paper from this heterogeneous raw material, pre-processing is required. This treatment consists of various separation processes with the aim of removing as many contaminants as possible and obtaining valuable fibers.\r\nAdhesive contaminants in paper for recycling, so-called stickies, are particularly problematic: They lead to problems during the papermaking process, are difficult to remove and reduce the quality of the resulting paper-product. Fine screening systems, consisting of multiple interconnected pressure screens, are used to separate stickies from the pulp suspension. The design of such systems is highly complex, since many different system configurations are possible and conflicting objectives need to be considered. Therefore, this application is a typical example for industrial separation processes with several stages and many options for the process design.\r\nUp to now, the planning and operation of such systems in practice is based on expert knowledge and rules of thumb. Because of the inherent complexity, this approach can quickly lead to non-optimal systems. In 2014, Fügenschuh [1] used mathematical optimization methods to optimize not only operational parameters, but also the topology of such systems.\r\nIn this work, the entire process of the optimization – from data collection via fitting physical models to actual optimization and validation – is presented. The individual steps, as they are typically necessary for the optimization of systems in process engineering, and arising challenges are investigated.\r\nFirst, the data collection in a German paper recycling mill is presented. The system topology and operational parameters as well as the resulting system behavior are determined. The fibre and sticky concentration at different process stages and other parameters are measured. In addition, factory-specific constraints like maximum volume flow rates and suspension consistency are taken into account. The measured data is used to fit the physical model to the real system. This model is integrated into an optimization model. Depending on the scope of optimization, different parts of the system can be optimized. The operational parameters, the design parameters of each component and the overall system topology are optimized individually and in combination. Furthermore, an adaptation of the topology during operation is investigated. The potential of the different measures is estimated using pareto fronts and a cost function. Selected measures are put into practices and the model is validated by further measurements.\r\n\r\n [1]\tFügenschuh, A.; Hayn, C.; Michaels, D. (2014): Mixed-integer linear methods for layout optimization of screening systems in recovered paper production. Optim. Eng.  15 (2), 533–573\r\n", :title "Optimizing Pressure Screen Systems in Industry – From Data Collection to Actual Optimization ", :keyword2 158, :authors (59650 41758 59651 59660 42187), :session 25}, 190 {:keyword1 102, :keyword3 159, :abstract "A large number of current research focuses on the sustainable orientation of business processes. However, it is often neglected that, next to the ecological and economic dimension, the social dimension is also an important pillar of sustainability. Therefore, the intended contribution focuses on the integration of social aspects into the Master Production Scheduling and thus achieves a network between production planning and human resources requirements planning. The study shows that previous papers on production planning and control usually ignore the social dimension. Exceptions are works that take advantage of learning and forgetting effects at the lot-sizing and scheduling. In addition, there are various papers in the scheduling area which aim to reduce employee workload by optimizing resource allocation. Thus, however, only an optimal distribution of burden is achieved. Therefore, this paper presents a long-term management of the burden. To this end, the classic Master Production Scheduling, which has been statically limited in terms of capacity, whereby additional capacities have been used, will be expanded. At the same time, human resources requirements planning is based on assumptions regarding the expected capacity requirements. The created linear optimization model, addresses these weak points. A flexible available capacity is integrated on the basis of existing sales orders. It is making possible, to build up and reduce capacities, whereby technical restrictions (number of workplaces) and labor market conditions (number of available employees, qualification of employees and experience of employees) are also mapped. This represents a significant progress compared to previous models, whereby the target function minimizes costs. Further progress has been made in investigating the effects of exhaustion. The ratio of capacity requirements to available capacity was controlled externally as employee utilization and processing times dependent on the employee's utilization were taken into account. Subsequently, different utilization situations were examined under the assumption of different exhaustion and random demand patterns with the aim of determining an optimal employee utilization. A key finding of this study is that - contrary to common assumptions - achieving cost benefits is not necessarily associated with maximizing utilization, but rather with controlling employee utilization. An additional effect results from the reduction of the employee burden. However, the flexible capacity available does not limit the performance of the production system. In addition, we are currently working on the investigation of effects in a long-term planning horizon and of consequences for the downstream planning levels of production planning and control. Overall, the contribution presents an innovative research project that aims to integrate social aspects into production planning in order to make a contribution to truly sustainable models in the future.", :title "Master Production Scheduling with consideration of Social Aspects for networking with Human Resources Requirements Planning", :keyword2 7, :authors (59253 59669 31192), :session 189}, 191 {:keyword1 2, :keyword3 0, :abstract "One of the effects of increasing cost pressure in airline industry is that airlines strive to realize short turn-around times, i.e., to let the airplanes stay at the gates between flights only as long as necessary. Associated with this is the reduction of the airplane boarding time, which accounts for a large part of the turn-around time. Most of the scientific literature in this area assumes that the boarding process is on the critical path of the turn-around, at least in sufficiently many cases. The aim of the study at hand is to analyze this assumption empirically. In a field study, we manually collected data of short- and medium-haul flights at a large European airport and analyzed them by performing statistical hypothesis testing. Our results indicate that boarding is on the critical path of the airplane turn-around. Hence, when aiming to reduce airplane turn-around time, the focus on the boarding time is reasonable and airlines are recommended to optimize the processes that are related to the boarding procedure.", :title "Is the Boarding Process on the Critical Path of the Airplane Turnaround?", :keyword2 174, :authors (48187), :session 45}, 193 {:keyword1 75, :keyword3 0, :abstract "Although compound Poisson demand is a popular choice in the inventory control literature and practice, there exists hardly any guidance on obtaining its parameters from real demand data. Forecasting literature and software focus on predicting period or lead time demand, which does not yield consistent estimates for the parameters of a compound Poisson distribution. Standard statistical methods have severe biases in finite samples (method-of-moments) and/or are not available in closed form (maximum likelihood). The inaccuracies of current parameter estimators make inventory calculations flawed when a compound Poisson distribution is fitted to periodic demand data, leading to severe deviations from target service levels, and unnecessarily high inventory costs. We propose a new, intuitive, consistent, closed-form method-of-moments estimator that dominates in terms of estimation accuracy and achieved service level. The new method estimates the arrival rate using the fraction of periods without demand, and combines this with the average of period demand to estimate the mean demand size. We compare it to Croston's method, the standard method-of-moments estimator, and maximum likelihood in terms of estimation bias and variance and inventory control performance. The new method outperforms standard method-of-moments for intermittent demand patterns and achieves results similar to those of maximum likelihood. Croston-based order levels are dramatically too high and overshoot the target fill rate. Period forecasting techniques as implemented in software are therefore not suitable for inventory control based on compound Poisson demand, and doing so leads to severe biases and too high inventories.", :title "Forecasting and inventory control with compound Poisson demand using periodic demand data", :keyword2 37, :authors (45941 35181 37535 8798 48604), :session 184}, 195 {:keyword1 158, :keyword3 0, :abstract "Due to the emerging new technology of additive manufacturing (AM), certain mechanical components that are currently manufactured by metal cutting operations could be manufactured without substantial material removal by AM processes. As AM process we consider the so-called wire-arc additive manufacturing (WAAM) process in this work. The wire is melted using high temperatures produced by an electrical arc, and then transferred as droplets onto the workpiece. The component is built layer-wise, from bottom to top. In each layer, the welding torch deposits the molten wire droplet-by-droplet to the desired position. Path planning is crucial for process time and part quality. Deadheading is allowed, if the shape in a certain layer cannot be drawn continuously. The most critical restrictions are due to the enormous heat input to the workpiece from the electrical arc. The heat is critical in the process, since it leads to stress in the workpiece and thus is a potential source of deformations. For a single layer, we thus describe the optimization problem of how to partition a given traverse into continuous segments that are manufactured without intersection, and deadheading between two segments, such that deadheading is minimized in order to finish the WAAM process as fast as possible. As a further constraint of the optimization, the accumulated heat is tracked and the local amount of heat or the heat gradient between neighboring positions should be below a given threshold. A further variant of the problem considers not only a single layer, but several consecutive layers, in order to increase the stability of the component and to avoid certain problems that occur when simply extruding the single-layer solution into the third dimension. We give a formulation of these problems as a mixed-integer programming problems and demonstrate the applicability of standard mixed-integer solvers for their solution on a test-bed of components.", :title "Trajectory Optimization for Wire-Arc Additive Manufacturing", :keyword2 133, :authors (16315 45285 59729), :session 83}, 197 {:keyword1 156, :keyword3 126, :abstract "On most modern energy markets, electricity is traded in advance and a power producer has to commit to deliver a certain amount of electricity some time before the actual delivery. This is especially difficult for power producers with renewable energy sources that are stochastic (like wind and solar). Thus, short term electricity storages like batteries are used to avoid penalty payments due to transient shortages. By contrast, long term storages allow to exploit price fluctuations over time, but have a comparably bad efficiency over short periods of time.\r\n\r\nIn this presentation, we consider the decision problem of a power producer who sells electricity from wind turbines on the day-ahead market and possesses two storage devices: a battery and a hydrogen based storage system. The problem is solved with a novel backwards approximate dynamic programming algorithm with optimal computing budget allocation. Numerical results show the algorithm's high solution quality. Furthermore, tests on real-world data demonstrate the value of using both storage types and investigate the effect of the storage parameters on profit. ", :title "Backwards approximate dynamic programming for wind power plants with hybrid energy storage systems", :keyword2 28, :authors (59661 22994), :session 209}, 198 {:keyword1 95, :keyword3 174, :abstract "The capacitated Vehicle Routing Problem with structured Time Windows (cVRPsTW) is concerned with finding optimal tours for vehicles with given capacity constraints to deliver goods to customers within assigned time windows. In our problem variant these time windows have a special structure, namely they are non-overlapping and each time window holds several customers. This is a reasonable assumption for many Attended Home Delivery (AHD) problems, such as online grocery shopping services, as the special structure does not impose severe restrictions to the supplying company or to the customers.\r\n\r\nThe sweep algorithm has originally been proposed as a simple, yet effective heuristic for the classical capacitated Vehicle Routing Problem (cVRP). Belonging to the class of \"cluster-first, route-second\" methods, it divides the plane into radial sectors originating from the depot's location, such that a single vehicle can be routed through all customers of one sector.\r\n\r\nOur research deals with developing variants of the sweep algorithm that are able to exploit structured time windows. Due to the imposed structure the total number of time windows is quite small, which allows us to use window-dependent angles. We propose a total of four different methods to determine such angles. After obtaining a first feasible solution, improvement heuristics are applied, which try to improve the objective function by slightly altering these angles. The final routing step, as well as feasibility computations during the clustering step, are accomplished by a recently proposed MILP model for the Traveling Salesperson Problem with structured Time Windows (TSPsTW).\r\n\r\nFinally, we conduct an extensive computational study. For this purpose, we use a large variety of benchmark instances that have been carefully constructed such that they resemble real-world data. The experiments show that our approach is capable of finding good initial solutions for instances containing up to 2000 customers within a few seconds. Further, we demonstrate that the proposed improvement heuristics allow us to significantly improve the solution quality within a few minutes. We notice that the performance of the four variants is strongly dependent on the specific characteristics of an instance, e.g. whether vehicle capacities or time windows are the stronger restriction.", :title "Sweep Algorithms for the Capacitated Vehicle Routing Problem with Structured Time Windows", :keyword2 175, :authors (59599 30955 50997), :session 87}, 199 {:keyword1 94, :keyword3 157, :abstract "A robust design of an emergency service system operating on a real transportation network has to be resistant to randomly appearing failures in the network. To incorporate system resistance into an associated mathematical model, a finite set of failure scenarios is generated to cover the most fatal combinations of the failures. Then, the system is suggested in such way that the maximal detrimental impact of the individual scenarios is minimized, what means that the maximal value of objective functions corresponding with the individual scenarios is minimized. A simple emergency system design can be modelled as a weighted p-median problem. While a simple weighted p-median problem is easily solvable, the robust system design is hard to be solved for the following causes. The first one originates in the size of the resulting model. The second one consists in usage of min-max constraints, which link up the individual scenario objective functions to their common upper bound, which represents the objective function of the robust design problem. These min-max link-up constraints represent an undesirable workload of any integer-programming problem due to bad convergence of the branch-and-bound method. This paper deals with a way of scenario set generation to determine the most convenient size of disjoint scenario set to ensure both acceptable computational time and sufficient measure of robustness. As the set of detriment scenarios is not evaluated by probabilities of their occurrence, a question of robustness measure arises. Within the paper, we use previously introduced “price of robustness” to appraise deterioration of the standard objective function as a consequence of robustness improvement and “gain of robustness” to asset the robustness improvement. To generate the individual scenario sets, we follow up on our previous research aimed at revealing the transportation network arcs, which are critical from the point of proper functioning of the service system. We make use of complete arc characteristics to construct disjoint scenario set based on distribution of given amount of additional transportation performance. We perform the above mentioned research on set of generated robust problem instances to explore mutual relations among size of scenario set, computational time necessary to obtain the optimal design and robustness characteristics.", :title "Complexity and Scenario Robust Service System Design", :keyword2 54, :authors (29393 29390), :session 220}, 200 {:keyword1 94, :keyword3 0, :abstract "Solving robust versions of optimization problems is generally known to be an intrinsically hard task. For many robust optimization problems an iterative solution procedure is the preferred choice for solving them. We consider iterative approaches based on cutting planes for solving robust mixed-integer optimization problems.\r\nIterative approaches start by solving a reduced problem, called optimization problem, with a small, finite uncertainty set. In the next step, a new scenario is determined by some procedure, called pessimization problem, and added to the considered uncertainty set. This procedure is then repeated iteratively until an optimal solution (up to some tolerance) to the robust optimization problem is found.\r\nWe give a general enhancement to this iterative approach by investigating the concept of solving the optimization and/or pessimization problems only approximately. Solving a subproblem approximately means that we stop the solver for the respective subproblem if an incumbent solution is found whose objective value exceeds a specified bound.\r\nWe identify under which conditions this enhanced iterative approach still converges to an optimal solution and give bounds on the number of iterations. Furthermore we give a parameterization for choosing the degree of approximation for the optimization and pessimization problems and discuss reasonable bounds for these parameters. Finally we investigate in our computational experiments how different degrees of approximation impact the runtime of the algorithm when applied to robust mixed integer problems. Here we distinguish between hard and easy optimization problems and hard and easy pessimization problems where the latter depends on the structure of the uncertainty set. We give suggestions for good parameter choices. The computational results show that a good parameter choice can lead to significant speed-ups in the runtime of the iterative approach.", :title "Iterative Approaches for Exact Solutions to Robust Optimization Problems", :keyword2 158, :authors (52424 1601), :session 207}, 204 {:keyword1 157, :keyword3 159, :abstract "We will present what is new in the linear, mixed integer and non-linear programming solvers within the FICO Xpress Optimization Suite.\r\n\r\nThis includes a presentation of LP Folding which is a way to exploit symmetries in linear programming problems. It uses a structure called equitable partitions, which can be seen as a generalization of model symmetry in MIP solving. An equitable partition subdivides the problem such that for each block in the partitioned problem, all the bounds and costs are the same, and all row and column coefficients add up to the same value.\r\n\r\nLP Folding can significantly reduce the size of the problem to be solved and thereby speed up the solution process. It can be used with all three major LP algorithms: primal simplex, dual simplex and barrier.", :title "Recent developments in the FICO Xpress-Optimizer", :keyword2 98, :authors (16880), :session 47}, 205 {:keyword1 42, :keyword3 0, :abstract "Let G = (V, E) be an undirected graph. A subset D of V is said to be a dominating set if any vertex not in D admits a neighbour belonging to D.\r\nThis definition can be extended, for any integer r > 0, to r-dominating sets as follows: D is an r-dominating set if, for any vertex v, there exists an element of D whose distance to v is at most r; then domination and 1-domination are the same.\r\nThe usual combinatorial optimization problem dealing with domination in graphs consists in looking for a dominating set of minimum size. This problem is well-known to be NP-hard (more precisely, the associated decision problem is NP-complete), and remains so for any given value of r 0.\r\nWe consider here the complexity of several related problems, for any given r > 0:\r\n- the computation of the minimum size of an r-dominating set;\r\n- the computation of a minimum-sized r-dominating set;\r\n- the existence and the computation, if any, of a minimum-sized r-dominating set including a prescribed vertex (problem sometimes known as a membership problem).\r\nThe NP-completeness of the usual decision problem easily shows that these problems are NP-hard. Since NP-hardness only provides a kind of lower bound (the considered problem is at least as difficult as any problem belonging to NP), our aim is to locate these problems more precisely in the complexity classes linked to the polynomial hierarchy by providing an upper bound of their complexities (the considered problem belongs to the class) and thus is at most as difficult as depending on the class which it belongs to). In particular, we may precisely locate the membership problem by showing that it is K-complete for an appropriate class K related to the polynomial class (this class K contains NP and co-NP).\r\n\r\n", :title "Complexity of domination problems in graphs", :keyword2 0, :authors (11277), :session 38}, 206 {:keyword1 6, :keyword3 174, :abstract "The lack of coordination among carriers leads to substantial inefficiencies in logistics. Such coordination problems constitute fundamental problems in supply chain management for their computational and strategic complexity. We consider the problem of slot booking by independent carriers at an operator of several warehouses, and investigate recent developments in the design of electronic market mechanisms promising to address both types of complexity. Relax-and-round mechanisms describe a class of approximation mechanisms that is truthful in expectation and runs in polynomial time. While the solution quality of these mechanisms is low, we introduce a variant able to solve real-world problem sizes with high solution quality while still being incentive-compatible. We compare these mechanisms to core-selecting auctions that are not incentive-compatible, but provide stable outcomes with respect to the bids. In addition to a theoretical analysis, we report results from extensive numerical experiments based on field data. The experimental results yield a clear ranking of the mechanisms in terms of waiting time reductions and computation times.", :title "Electronic market mechanisms to increase efficiency in transportation logistics", :keyword2 40, :authors (48911 55333 9112), :session 67}, 207 {:keyword1 65, :keyword3 157, :abstract "The Steiner forest problem asks for a minimum weight forest that spans a given number of terminal sets. The problem has famous linear programming based 2-approximations whose bottleneck is the fact that the most natural formulation of the problem as an integer linear program (ILP) has an integrality gap of 2. We propose new cut-based ILP formulations the problem along with exact branch-and-bound based algorithms. While our new formulations cannot improve the integrality gap, we can prove that one of them yields stronger linear programming bounds than the two previous strongest formulations: The directed cut formulation and the advanced flow-based formulation by Magnanti and Raghavan. In an experimental\r\nevaluation, we show that the linear programming bounds of the new formulations are indeed strong on practical instances and that the new formulation is better suited for branch-and-bound than previous formulations.", :title "A new MIP formulation for the Steiner forest problem", :keyword2 8, :authors (28033 23913 7367), :session 54}, 208 {:keyword1 6, :keyword3 159, :abstract "Display ad auctions have become the predominant means to allocate user impressions on a web site to advertisers. These impressions are typically priced via a simple second-price rule. For single-item auctions, this Vickrey payment rule is known to be incentive-compatible. The situation is quite different when impressions arrive dynamically over time and valuations for individual impressions are not separable anymore. This might be the case, if there is an overall budget constraint or a campaign target beyond which bidders do not have a value for additional impressions anymore. The allocation process might not maximize welfare and the payments might differ substantially from those paid in an offline auction with a Vickrey-Clarke-Groves (VCG) payment rule or also competitive equilibrium prices. \r\nWe discuss the properties of the offline problem and present a binary program for the allocation problem. In numerical experiments, we find the welfare achieved in the online auction process with truthful bidders is high, but bidders pay substantially more on average compared to what they would need to pay in a corresponding offline auction in which all impressions are available at one point in time. This sets incentives for demand reduction and bid shading. Therefore, we evaluate non-truthful bidding strategy and compare the results to those obtained with truthful bidding.\r\n", :title "Are Truthful Bidders Paying too Much? Efficiency and Revenue in Display Ad Auctions", :keyword2 153, :authors (59663 35382 55333), :session 67}, 210 {:keyword1 74, :keyword3 158, :abstract "From a deterministic unit-commitment model (a MIP model written in GAMS), we developed a Monte Carlo version where the same model is run with 1000 different price scenarios. In order to parallelise the resolution we wrote a tool to launch the execution in the cloud, using 1000 different Amazon EC2 machines. Imposing a 1-hour time resolution to each scenario optimisation, we were able to complete the entire process in 1h30m, meaning that 30 minutes were enough for the whole overhead due to the parallelisation, upload and download of data, and the data obfuscation/deobfuscation required by the client.", :title "Launching 1000 machines on the cloud to solve a Monte Carlo optimisation model", :keyword2 48, :authors (59471), :session 48}, 212 {:keyword1 175, :keyword3 2, :abstract "Air cargo transportation involves handling operations in air cargo hubs. Cargo arrives at the hub from incoming flights or is delivered by ground transportation to the airport. It is received and (if necessary) deconsolidated as well as potentially stored in a buffer storage. The object of analysis are the build-up operations in the hub where individual shipments are consolidated on unit load devices (ULDs). Subsequently, ULDs are weighted and transported to the apron where they are loaded to the aircraft.\r\n\r\nThe presented work aims to reduce peaks in labor requirement occurring in air cargo handling. The air cargo hub under consideration is currently operated in a departure-triggered fashion. That is, build-up operations for flights are started at a predefined time prior to flight departure. Hence, peaks in aircraft departure lead to peaks in labor utilization.\r\nWe divide the research question into two aspects. First, we discuss two alternatives on how to generate build-up tasks. Second, we develop alternatives of when to start the build-up operations for a specific task and on how much manpower to allocate to each task.\r\n\r\nA task subsumes a number of ULDs for build-up, their availability time as well as the deadline when the build-up needs to be completed. Size-based and time-based approaches are tested to form task. The size-based approach predefines a number of ULDs that will be grouped together in one task. Only the last task of a flight can be smaller as there might not be sufficient cargo available. The time-based approach generates three tasks per flight on the basis of time intervals. All cargo for the flight that has arrived at the hub during the interval is allocated to the task. We show that in the empirical data that was analyzed the differences in generated tasks remain limited. However, discussion with the company highlighted that the time-based approach is more apt for their daily use.\r\n\r\nThe second aspect of the research question is when to start the build-up operations and how many workers to allocate to a task. We adapt the algorithm suggested by Emde et al. (2017) so that it creates a near-optimal task scheduling. As it appears unrealistic for the company to apply the algorithm on a regular basis, we develop four easily applied dispatching rules. In doing so, the most appropriate strategy is to start tasks as early as possible and allocated as few workers to the task that still ensure the deadline is met. We finally combine the algorithm and the dispatching rules such that the number of workers is limited based on the algorithm while the scheduling of the tasks is left to the dispatching rule. This combination provides feasible schedules with limited labor peaks and remains easily applicable at the same time.\r\n\r\n\r\nS. Emde, H. Abedinnia, A. Lange, Ch. Glock (2017): Scheduling personnel for the build-up of unit load devices at an air cargo terminal with limited space. Working Paper.", :title "Scheduling air cargo build-up operations", :keyword2 174, :authors (15955 54540), :session 167}, 215 {:keyword1 91, :keyword3 175, :abstract "Railway Revenue Management (RRM) offers great opportunities to increase revenues in practice but it received only little attention in research during the past decades. Due to the special structure of railway networks, traditional RM-approaches that have been applied in other transportation industries must be critically assessed and adjusted to the industry specific setting. In our talk, we present a mathematical model formulation for multi-product, multi-resource railway revenue management for dynamic pricing that incorporates heterogeneous customer choice behavior and railway specific constraints.  \r\nWe first give practical insights into the special business environment that railway companies are dealing with. This includes the motivation for the use of customer choice models. A train company typically offers multiple connections between two cities within a day (e.g. 37 between Frankfurt and Berlin for Deutsche Bahn) and therefore the demand for a specific train connection does not only depend on its own price but also on the price and quality of alternative connections. In addition, some practical business rules should be considered in a RRM-model, e.g. longer itineraries should be more expensive than shorter ones to avoid strategic customers. As a result of incorporating the characteristics mentioned above, the original mathematical problem formulation turns out be non-convex nonlinear with potentially many local optima, and is thus difficult to solve exactly. At the same time, problem instances in reality are typically large-scale and the allowable time to solve the problem in practice very limited.  Therefore, we present heuristics that make it possible to solve large-scale problem instances approximately in reasonable time. Finally, based on real data from the German Railway Company Deutsche Bahn we show first results with respect to solution quality and time and discuss chances and limits that arise in practice with a choice-based RM approach. \r\n", :title "Large-Scale Dynamic Network Pricing under Customer Choice Behavior for Railway Companies", :keyword2 53, :authors (59657 52290), :session 179}, 217 {:keyword1 175, :keyword3 150, :abstract "The transportation of goods in urban areas is a complex activity and essential to the economic and social life of any city. It is also, however, a major contributor to significant nuisances, e.g., congestion, emissions, noise, and excessive consumption of fossil fuels. The complexity and impact of freight transportation in cities is further amplified by two heavy trends observed word-wide: increasing urbanization and e-commerce.\r\n\r\nNew organization and business models are proposed to address these issues under the name of City Logistics. By consolidating flows in and also out of the city into the same vehicles, irrespective of the commercial transactions that generate them, City Logistics aims to improve the utilization of the means of transport and to reduce their presence within the city.\r\n\r\nWe introduce a new problem for selecting services in a tactical plan of a two-tier city logistics system. Compared to existing models, we consider not only a truck but also mass transportation with multiple compartments (e.g., trams) within one model. Moreover, we integrate inbound and outbound demands in the model and consider the used resources in the constraints. For defining the problem, we introduce a new integer programming formulation that has similarities to the well-known knapsack and bin packing problem. To efficiently solve this problem, we use this formulation in a Benders decomposition algorithm which is implemented in a Branch-and-Cut framework. We further improve the method by using pareto-optimal cuts, valid inequalities, and propose a new partial decomposition technique, which can be generalized to a broad class of deterministic problems. \r\n\r\nThe numerical results show significant run time improvements compared to the complete formulation ran using CPLEX. Furthermore, our results illustrate the benefits of using different transportation modes within one network. They show the benefits of the different transportation modes and how mass transportation can be used in City Logistics systems. The results further show how the integration of inbound and outbound flows into the planning reduces the number of operated services and increases the efficiency of the whole system.\r\n", :title "The Impact of Mass Transport on the Design of Multimodal Two-Tier City Logistics Systems", :keyword2 174, :authors (39359 45506 55434 25620), :session 166}, 220 {:keyword1 91, :keyword3 120, :abstract "In many markets, firms use data-driven dynamic pricing and ordering strategies to increase their profits. To successfully manage both inventory levels as well as offer prices is a highly challenging task as (i) demand is typically uncertain and (ii) optimized pricing and ordering decisions are mutually dependent. In this paper, we analyze stochastic dynamic joint pricing and ordering models for the sale of durable goods. In a first step, a data-driven approach is used to estimate demand intensities and to quantify sales probabilities. In a second step, we use a dynamic programming model to compute optimized feedback pricing and ordering strategies. Further, we study the impact of ordering costs, inventory holding costs, and a delay in delivery.", :title "Data-Driven Stochastic Dynamic Pricing and Ordering", :keyword2 156, :authors (48742), :session 179}, 221 {:keyword1 16, :keyword3 42, :abstract "Because of the sharp development of (commercial) MILP software and hardware components, pseudo-polynomial formulations have been established as a viable tool for solving cutting and packing problems in recent years. Constituting a natural (but independent) counterpart of the well-known cutting stock problem, the one-dimensional skiving stock problem (SSP) asks for the maximal number of large objects (specified by some threshold length) that can be obtained by recomposing a given inventory of smaller items. Such computations are of high relevance in many real-world application, particularly whenever an efficient and sustainable use of given resources is desired. For instance, some (not exhaustive) areas of applications are given by: stimulating economic activity (e.g., in periods of recession), efficient resource allocation in wireless communications, multiprocessor scheduling problems, or manufacturing and inventory plannings. Further scientific relevance of the SSP is given by the fact that it may also appear side-by-side within a holistic cutting-and-skiving scenario. \r\n\r\nAfter a short introduction to the skiving stock problem and some of its most important ILP formulations, this presentation introduces a new arcflow model for the SSP applying the idea of reflected arcs. The main novelty of this approach is to only consider half of the bin capacity (i.e., a significantly reduced set of vertices), so that any pattern is decomposed into two subpaths being connected by a reflected arc. Thereby, the number of arcs of the arcflow graph can be decreased considerably compared to the original formulation. In particular, this new model is shown to possess significantly fewer variables as well as a better numerical performance compared to the standard arcflow formulation.", :title "An Improved Arcflow Formulation for the Skiving Stock Problem", :keyword2 157, :authors (48992 55240 7965 16923), :session 71}, 223 {:keyword1 157, :keyword3 105, :abstract "The Hajj – the great pilgrimage to Mecca, Saudi Arabia – is one of the ﬁve pillars of Islam. Up to four million pilgrims perform the Hajj rituals every year. This makes it one of the largest pedestrian problems in the world. Ramy al-Jamarat – the symbolic stoning of the devil – is known to be a particularly crowded ritual. Up until 2006, it was repeatedly overshadowed by severe crowd disasters. To avoid such disasters, Saudi authorities initiated a comprehensive crowd management program. A novel contribution to these eﬀorts was the development of an optimized schedule for the pilgrims performing the stoning ritual. A pilgrim schedule prescribes speciﬁc routes and time slots for all registered pilgrim groups. Together, the assigned routes strictly enforce one-way ﬂows towards and from the ritual site. In our paper, we introduce a model and a solution approach to the Pilgrim Scheduling Problem. Our multi-stage procedure ﬁrst spatially smoothes the utilization of infrastructure capacity to avoid dangerous pedestrian densities in the network.  In the next optimization step, it minimizes overall dissatisfaction with the scheduled time slots. We solve the Pilgrim Scheduling Problem by a ﬁx-and-optimize heuristic and subsequently simulate the results to identify necessary modiﬁcations of the scheduling constraints. The scheduling approach was an integral part of the Hajj planning process in 2007–2014 and 2016–2017. No crowd disaster occurred in these years.\r\n", :title "A Pilgrim Scheduling Approach to Increase Safety during the Hajj", :keyword2 63, :authors (59671 16639 14588 52606), :session 214}, 224 {:keyword1 2, :keyword3 175, :abstract "Flight planning is the discipline of finding an efficient route between two airports. This route should adhere to international and domestic regulatory flight authorities’ rules, as well as adequate onboard fuel reserves, airspace rules and temporary airway closures in order to determine optimal speed and altitude at all points throughout the flight. At Jeppesen we are leaving the traditional approach of fixed routes behind, and instead optimize a route based on current wind and weather, payload, aircraft capabilities and latest airspace information. This talk will focus on the difficulties of flight planning as well as give an overview of how we have approached solving some of them.\r\n", :title "Flight Route and Trajectory Optimization", :keyword2 8, :authors (51077), :session 167}, 225 {:keyword1 174, :keyword3 8, :abstract "We consider a transport relation between a source and a sink where multiple items are transported in several loads on a daily basis, depending on orders from the sink directed to the source. At the beginning of the planning horizon, the operator of the sink places a set of orders for multiple items with the operator of the source including delivery due dates. The operator of the source needs to pack the items into the transport vehicle and deliver them to the sink. Due to limited storage space at the sink, only a small fraction of the order size can be advanced. Backlogging is not permitted. To determine a valid stowage plan for each transport vehicle, detailed loading constraints have to be met. Constraints concern weight, size, compatibility and bearing load of the load carriers. Several types of standardized load carriers are used to transport items to the sink. The problem is to find jointly a plan for the quantity delivered of multiple items in multiple periods and the corresponding loading plans for each transport vehicle so that the total cost consisting of fixed transport and variable holding costs is minimized subject to delivery due dates, capacity constraints of the sink´s storage area and detailed loading constraints of the transport vehicle.\r\nWe employ a two-step approach that relies on generation and combination of partial solutions. In a first step, an enumeration of load carrier combinations forming walls is performed. Combinations are generated within compatible groups of load carriers, which means these load carriers have the same width and length as well as the same stacking characteristics. In a second step, walls are combined into loads to fulfill the demand over the planning horizon without backlogging, complying with all loading constraints as well as with the limits of storage capacity at the sink. By advancing small quantities of the demanded items and storing them at the sink, holding costs occur. However, reduction of fixed cost per transport vehicle outweigh these holding costs by far.\r\nThe approach contributes to both the literature streams of multi-item order sizing by introducing detailed capacity constraints and to cutting and packing by integrating three-dimensional packing with dynamic modelling of demand. Relevance for practice comes with the potential to solve realistic cases from the industry near to optimality in reasonable time. We compare the results of the loading algorithm to a theoretical lower bound achieving a very small gap. Further results show promising potential for cost savings in the multi-period case.", :title "Integrated dynamic multi-item inbound order sizing and packing", :keyword2 16, :authors (56452 26368 26841), :session 169}, 226 {:keyword1 175, :keyword3 95, :abstract "The introduction of the minimum wage for print media deliveries in Germany in 2015 resulted in a change in the remuneration system. The remuneration of the deliverers is no longer due to the number of print media delivered, but based on the required delivery time for the entire delivery. This represents a change from piece wage to time-based pay. Since the concrete tour of the deliverer is related to the required delivery time, distribution companies of print media and labor unions now have an increased interest in the concrete design of the tours and the corresponding remuneration. Because the demands are supplied along the streets and the different deliverers start their tours at several depots as well as restrictions to working time and loading capacity appear, the routing corresponds to an arc-oriented routing problem called multi-depot capacitated arc routing problem (MD-CARP).\r\nThe MD-CARP generalises the well-known capacitated arc routing problem (CARP) by extending the single depot network to a multi-depot network. The CARP consists of designing a set of vehicle trips, so that each vehicle starts and ends at the single depot. The MD-CARP involves the assignment of edges, which have to be served, to depots and the determination of vehicle trips for each depot. While the locations of the depots are defined for the MD-CARP, they are determined by the location arc routing problem (LARP) as part of the optimization. Since print media distribution can be done with closed and open tours and the locations of the corresponding depots are related to the delivery time of each trip, this research focuses on extensions of the MD-CARP and LARP for print media deliveries.\r\nIn this talk, basic delivery concepts and specific characteristics of print media deliveries in Germany are considered. Especially location aspects of the depots or the storage locations of the print media as well as routing with open and closed tours with capacity restrictions are taken into account. Therefore new MIP models are presented and computational results on benchmark test instances are shown.", :title "Modelling variants of open and closed multiple depot capacitated arc routing problems for print media distribution with location issues", :keyword2 174, :authors (59674), :session 152}, 228 {:keyword1 42, :keyword3 157, :abstract "The Steiner tree problem with revenues, budgets and hop constraints (STPRBH) is a variant of the classical Steiner tree problem. This problem asks for a subtree with maximum revenues corresponding to its nodes, where its total edge costs respect the given budget, and the number of edges between each node and its root does not exceed the hop limit. We introduce a new binary linear program with polynomial size based on partial-ordering, which (up to our knowledge) for the first time solves all STPRBH instances from the DIMACS benchmark set. The set contains graphs with up to 500 nodes and 12,500 edges.", :title "A new ILP for the Steiner Tree Problem with Revenues, Budget and Hop Constraints", :keyword2 65, :authors (55334 14938), :session 54}, 229 {:keyword1 45, :keyword3 157, :abstract "In emergency medical services (EMS), the workforce is one of the most expensive resources. Attracting well-qualified personnel is becoming increasingly difficult. Therefore, it is important to take into account employee satisfaction in shift planning. Important preferences include the long-term predictability, off-duty weekends and the avoidance of undesirable shift sequences. Additionally, cyclical shift models can reduce the effort required for operational scheduling. In continuous operations with two daily shifts, the allowable and desirable shift sequences (stints) are strongly limited by legal and practical constraints. This work presents new integer programming formulations for cyclic shift scheduling using a stint-based modeling approach. Only stints that comply with the practical constraints and preferences are permitted. To hedge against unpredictable absence of paramedics, on-call duties are integrated in the scheduling process and model formulations. Focusing on the cyclical schedules, which are symmetric across shift groups, the problem complexity is greatly reduced and personnel are equally treated. Our symmetric model with on-call duties can be solved to optimality for reasonably large problem instances. The model formulations have been applied to the case of a large German ambulance service. The optimal shift schedule derived by our model is successfully implemented since January 2018. The benefits of the new shift scheduling convinced all stakeholders and satisfy their interests.", :title "Cyclic Shift Scheduling With On-Call Duties for Emergency Medical Services", :keyword2 121, :authors (52514 52508 10057), :session 170}, 232 {:keyword1 96, :keyword3 154, :abstract "We address the problem of scheduling n jobs that are partitioned into F families on a single processor. A setup operation is needed whenever a job of one family is succeeded by a job of another family. These setup operations are assumed to not require time but are associated with a fixed setup cost which is identical for all setup operations. Jobs must be completed no later than by a given deadline. The objective is to schedule all jobs such that the total setup cost is minimized. This objective is identical to minimizing the number of setup operations. We show that the considered problem is strongly NP-hard. Moreover, we present properties of optimal solutions and an O(n log n + nF) algorithm that approximates the cost of an optimal schedule by a factor of F. The algorithm is analyzed in computational tests.", :title "Complexity and approximation results for setup-minimal batch scheduling with deadlines on a single processor", :keyword2 151, :authors (29563 31567 10954 59590), :session 161}, 234 {:keyword1 158, :keyword3 42, :abstract "A touristic company that offers fly-in safaris is faced with the challenge to route and schedule its fleet of aircrafts in an optimal way. Over the course of one or two days several groups of tourists have to be picked up at an airport and flown to their destination within a certain time window. Furthermore the number of available seats, the consumption of fuel, the maximal takeoff weight, and restrictions on the detour of the individual groups have to be taken into account. The task of optimally scheduling the planes and tourist groups belongs to the class of vehicle routing problems with pickup and delivery and time-windows (VRP-PD-TW). A flow-over-flow formulation on the time expanded graph of the airports was used in the literature in order to model this problem as a mixed integer linear program. Most of the benchmark problems however could not be solved within a time limit of three hours. This was overcome by formulating the problem for a simplified (time-free) graph and the use of an incumbent callback for checking feasibility in the original graph. Taking this time-free formulation as a starting point, we further refine this approach by re-introducing time as flow variables on the time-free graph. Although solutions of this model still do not guarantee the existence of a feasible expansion this formulation allows for an effective construction of graphs which can be interpreted as intermediate graphs between the time-free and the (totally) time-expanded graph. Constructing these graphs based on known infeasible solutions guarantees that only the paths that are candidates for the optimal solution are expanded. On the benchmark set this not only lead to a decrease of the average computation time and the remaining optimality gaps, also previously unsolved instances were solved to optimality.", :title "A Time-Flow Approach for Scheduling and Routing of Fly-in Safari Airplanes", :keyword2 187, :authors (59678 16315), :session 26}, 235 {:keyword1 157, :keyword3 150, :abstract "A common technique used to solve specially structured integer programs is branch-and-price. In branch-and-price subproblems are typically solved using branch-and-cut or specialized combinatorial algorithms. However, related work indicates that for specific problems speedups can be achieved by applying branch-and-price to the subproblems as well. Hence, we aim at exploiting such nested decompositions in GCG, a generic branch-cut-and-price solver based on SCIP. GCG uses Dantzig-Wolfe decompositions relying on structures that are either provided by the user or detected by GCG itself. We extend GCG to apply branch-and-price recursively, where the nested structure is provided by the user. We present computational results comparing the recursive branch-and-price strategy with the standard technique on suitable problems. Future work includes employing problem specific detectors that reveal the underlying structure of a problem automatically. Moreover, we plan to generalize this idea by implementing a generic detection of nested structures.", :title "Computational Experiments with Nested Dantzig-Wolfe Decompositions", :keyword2 153, :authors (59662 14969 42315), :session 66}, 236 {:keyword1 8, :keyword3 96, :abstract "Our work relates to the Clique-Problem with Multiple-Choice constraints (CPMC), i.e. the clique problem on a graph with a given partition of the vertices, such that we have to choose exaclty one vertex from each subset in the partition. In general, this problem is NP-hard. However, on graphs with the so-called staircase property the problem is solvable in polynomial time using a totally unimodular dual-flow formulation of linear size. Under a given partition of the vertices this property requires total orderings on the vertices in each subset which have to fulfil certain conditions with respect to the edges present in the graph. This raises the question whether we can decide if such orderings exist for a given arbitrary graph with fixed partition.\r\n\r\nIn this talk, we give an overview of the staircase graph recognition problem with given partition. The task is to find total orderings fulfilling the necessary conditions, and we are able to show that this problem is itself NP-complete on general graphs. This implies that finding total orderings with a minimal number of violations is NP-hard.\r\n\r\nWe discuss the complexity of the above problem on different common graph classes and, in particular, present an algorithm to solve the problem on bipartite graphs in polynomial time. A second, linear-time algorithm allows us to determine whether a bipartite graph has the staircase property when the order on the vertices of one side is already fixed. These algorithms can be combined to heuristically produce orderings such that the graph is as staircase as possible.\r\n\r\nSince a graph with the staircase property allows using a totally unimodular dual-flow formulation to solve CPMC efficiently, we study the performance of this formulation on near-staircase graphs. This means graphs which fulfil the staircase property if a low number of edges is added. In this case, we consider staircase relaxations, which are constructed by adding edges to the graph such that it becomes staircase. We computationally evaluate our findings on different realistic instance sets from the field of scheduling problems.", :title "On recognizing staircase graphs and solving clique-problems on near-staircase graphs", :keyword2 42, :authors (55909 59498 36110), :session 80}, 239 {:keyword1 174, :keyword3 157, :abstract "An emerging concept of the sharing economy is the so-called item-sharing in which members of a sharing community can temporarily rent items from one another (peer-to-peer). This concept is particularly useful for items that are needed on rare or just temporal occasions like, for example, tools or leisure equipment. The matching of supplies and requests for such items is typically coordinated via on-line platforms. The actual forwarding poses a transportation challenge, as the peer-to-peer exchange needs to address the highly inefficient 'last mile' twice. Crowdshipping is another concept of the sharing economy that provides an innovative means of transport. Registered private drivers with upcoming planned trips by car, detour from their direct route within certain bounds to pick up an item at its current location and to deliver it to the location where it is requested. \r\n\tIt has been shown that the integration of the two concepts on a single platform has great potential in terms of profitability and service orientation. This result is, however, obtained in a setting with homogeneous items in which total compatibility exists between supplies and requests. Since sharing platforms usually serve as a market place for a wide range of products we investigate here how this finding is affected when heterogeneous items are considered. To this end, we generalize the problem setting such that items of different product types are shared among community members. We solve the resulting problem with an integrated framework of a label-setting algorithm and a set packing problem. Experiments are based on a case study for the city of Atlanta, Georgia. We distribute supply and request locations as well as origins and destinations of crowdshippers within this region and estimate travel times from the actual street network. In this setting, we consider a varying quantity of different product types. Since crowdshipping is expected to gain in importance as more product types are considered, we also vary the quantity of available crowdshippers and their willingness to detour. The goal is to obtain further insights into minimum requirements that allow for successful crowdshipping on a large scale. The results show that a high product variety reduces a platform's profit. Anyhow, the effect can be reduced to some extent if crowdshippers can be motivated to accept longer detouring. ", :title "Heterogeneous items in an integrated item-sharing and crowdshipping setting", :keyword2 175, :authors (51089 13086), :session 168}, 240 {:keyword1 157, :keyword3 150, :abstract "In Dantzig-Wolfe reformulation of an integer program one convexifies a subset of the constraints, leading to potentially stronger dual bounds from the respective linear programming relaxation. As the subset can be chosen arbitrarily, this includes the trivial cases of convexifying no and all constraints, resulting in a weakest and strongest reformulation, respectively.  Our computational study aims at better understanding of what happens in between these extremes. For a collection of integer programs with few constraints we compute, optimally solve, and evaluate the relaxations of all possible (exponentially many) Dantzig-Wolfe reformulations (with mild extensions to larger models from the MIPLIBs). We observe that only a tiny number of different dual bounds actually occur and that only a few inclusion-wise minimal representatives exist for each. This aligns with considerably different impacts of individual constraints on the strengthening the relaxation, some of which have almost no influence.  In contrast, types of constraints that are convexified in textbook reformulations have a larger effect. We relate our experiments to what could be called a hierarchy of Dantzig-Wolfe reformulations.", :title "A Computational Investigation on the Strength of Dantzig-Wolfe Reformulations", :keyword2 153, :authors (42315 33581 14969), :session 66}, 241 {:keyword1 8, :keyword3 95, :abstract "In this presentation, we investigate the single-source-single-destination \"shortest\" paths problem in graphs with ordinal weighted arc costs. In contrast to the single-criterion shortest path problem with numerical edge data we do not obtain a (single) \"shortest\" path by solving this problem, instead we compute a set of ordinal non-dominated paths which are incomparable. \r\nIn many practical applications one may have qualitative or ordinal information instead of numerical data available, e.g., in the case of demonstration marches the police staff may be able to assess different paths or paths segments as secure, insecure, or neutral respectively.\r\nThus, instead of assessing the value of a path as the sum of the values of its corresponding arcs, we evaluate a path as a vector containing the ordinal levels associated with this path. Hence, we compare different paths by their corresponding vectors of ordinal levels. \r\nIn order to achieve this, we define a preorder on the set of paths from source node s to destination node t and introduce the concepts of ordinal efficiency and dominance for paths and their associated ordinal levels, respectively. We show that the number of ordinal efficient s-t-paths may be exponential in the number of nodes while the number of non-dominated ordinal paths vectors from the source node to every other node in the graph is polynomially bounded.\r\nFurther, we propose a polynomial time labeling algorithm for solving the problem of finding the set of ordinal non-dominated paths vectors from source to sink. \r\nWe prove the correctness of the algorithm and the worst case running time complexity.\r\nThis research was partially supported by the Bundesministerium für Bildung und Forschung (BMBF) under Grant No. 13N14561.", :title "Shortest Paths with Ordinal Weights", :keyword2 42, :authors (59677 12666 53033 59682 59690), :session 177}, 242 {:keyword1 157, :keyword3 0, :abstract "TF1 is a major media group in Europe and the leading television group in France, with almost 20 % audience share and 45 % of the TV advertising market. Television ads slots are marketed according to the estimated viewing audience. Every month, the main channels open their reservation planning for a period of 60 days. Advertising companies then send their requests to channels. One or two weeks after TF1 returns its acceptance decision for each request. TF1 optimizes its decisions to globally maximize its revenue while satisfying packing constraints and mutual exclusions of competing products in each commercial break.\r\nSports events can attract many viewers (as an example, the 2006 world cup final represented 80% of the market share) and are massively requested by advertising companies. During the football world cup TF1 sells commercial breaks in packages. A package is composed of a given number of breaks in different matches, for instance 3 breaks distributed as follows: one during France-Australia, one break in Russia – Saudi Arabia or in Germany - Mexico and one last break in another group of matches. TF1 then decides to accept or decline each request but can also make a counter-proposal for an equivalent package or exchange a match in a package with another in the same group. These decisions are optimized to maximize the revenue of TF1 while satisfying packing constraints, mutual exclusions between competing products but also equity between advertisers, budget constraints, priorities and so on.\r\nThis talk presents the mathematical model designed to solve this combinatorial problem for TF1 using LocalSolver. ", :title "Planning football world cup commercials for TF1, the largest tv channel in France", :keyword2 98, :authors (18585 59684), :session 46}, 243 {:keyword1 45, :keyword3 0, :abstract "This study presents an innovative application of operational research in the field of clinical analysis laboratories. Clinical analysis laboratory is an organization composed of human and machinery resources to analyze patients’ samples such as blood. Basically, machines constitute the main core of a clinical laboratory and take up the most workload in the system. Rational selection of machines to equip a clinical laboratory not only optimize the investment costs on the strategic level but also leads to reasonable operational costs in operational level while configuring the selected analyzers. In this paper, machine selection for a clinical laboratory is described as a problem dealing with the specification of the number and type of both analyzers and non-analytical machines (such as centrifuge and sorter) to fulfil the average daily test demand with the aim of minimizing total machines purchase costs in the strategic level as well as total analyzers configuration costs in the operational level. In order to tackle this problem, a linear mathematical model is developed. The proposed model is solved optimally by Cplex solver in GAMS software for a laboratory which covers Immunology and Chemistry tests. The output results reveal the efficiency of the proposed model to aid decision makers selecting machines for clinical laboratories effectively and cleverly. To the best of our knowledge, this study is the first endeavor to address and tackle machine selection problem in clinical laboratories as an optimization problem with a glance to both strategic and operational costs.", :title "A mathematical model for machine selection problem in clinical laboratories", :keyword2 159, :authors (59685 2519 55079 59687), :session 174}, 245 {:keyword1 31, :keyword3 0, :abstract "Intermodal rail/road transportation combines advantages of both modes of transport and is often seen as an effective approach for reducing the environmental impact of freight transportation. Rail transportation is usually considered to emit less greenhouse gases than road transportation. The actual amounts of both modes depend on various factors like vehicle type, traction type, fuel emission factors, payload utilization, slope profile or traffic conditions. Still, comprehensive experimental results for estimating emission rates from heavy and voluminous goods in large-scale transportation systems are hardly available so far. \r\n\r\nThis study describes an intermodal rail/road network model that covers the majority of European countries. Formally, we model a multilayer network to handle road-only routings and intermodal rail/road routings. On this network, we apply a mesoscopic emission estimation model that estimates freight-related emissions relatively precisely from only a few input parameters of freight shipments. Results are presented for transports within and between all countries by conducting a large scale simulation of road transports and intermodal transports. Emission rates are measured by well-to-wheel carbon dioxide equivalents per ton-kilometer and provided for various simulation scenarios.\r\n\r\nOverall, our results indicate that the use of a single average emission rate for a large area like Europe can lead to substantial errors in the estimation of emissions for individual shipments or particular transport relations. Furthermore, we found that intermodal routings emit less greenhouse gases than road-only routings for over 90 % of the simulated shipments. However, this value varies among country pairs and is significantly lower for countries with many non-electrified rail tracks and high emission coefficients for their electricity.\r\n\r\nThe results of this study can be used to further facilitate research in areas, where emission rates serve as an input to environmentally oriented decision problems, such as location planning or routing problems. They might also be used for companies to benchmark the environmental performance of their processes. In addition, the detailed description of the European rail and road network can be used for other studies in the field of (intermodal) transportation.\r\n", :title "Simulation of Rail and Road Emissions in Europe", :keyword2 175, :authors (59653 13086), :session 155}, 246 {:keyword1 30, :keyword3 0, :abstract "Order release initializes the execution of planned production orders in such a way that relevant objectives will be fulfilled by utilizing resources that are available within a certain planning horizon. For make-to-order systems, different order release approaches have been developed based on the assumption of complete information about the order specification. In contrast to this, order release in an engineer-to-order environment is faced with specification uncertainty. That is, customer orders are accepted even though only a rough-cut specification of the product and information on the latest delivery date is available and further details of the specification have to be supplemented during the order fulfillment process. The rough-cut specification allows starting production of those components for which a complete specification is already available. For all other components information about a spectrum of possible production processes and possibly required resources can be used at this early point in time. More definite information is provided successively by interactive processes involving persons of both parties, customer and supplier. Hence, a complete specification will be available at a later point in time, but the time required for detailing is uncertain.\r\nIn our contribution, we review available approaches for optimization-based order release and identify modifications that become necessary in the engineer-to-order context. In order to handle the specification uncertainty efficiently, we propose a multi-step approach that focuses on production orders for components of the known customer orders. The steps are triggered as soon as either the specification of a further component is completed or a predefined release interval is elapsed. In each step, the release decision is made for the batch of completely specified, but not yet released components with respect to cost consequences for all customer orders in the system, irrespective of their components’ states (incompletely specified, completely specified, released, finished). Besides the inventory holding costs and lateness costs, in engineer-to-order systems processing costs become relevant too, since alternative processes and resources can be chosen for incompletely specified components. Furthermore, the specification uncertainty requires an adequate consideration of choice probabilities (processes, resources) and distributions of specification time. For supporting such release decisions by computers, we develop a basic optimization model (MILP) that is applied in each step. In order to study its behavior, we conduct a numerical study with a set of systematically generated problem instances and search for optimal solutions by means of a standard solver.", :title "Optimization-based order release in engineer-to-order systems - Basic model for a multi-step approach", :keyword2 86, :authors (59686 26613), :session 188}, 248 {:keyword1 61, :keyword3 0, :abstract "In many cases, using GAMS in the typical fashion - i.e. defining and solving models and evaluating the results within the given interfaces – presents a sufficient way to deploy optimization models. The underlying field of mathematical optimization, in which the focus is not so much on visualization as on the problem structure itself, has remained a kind of niche market to this day.\r\n\r\nIn the large and very extensive segment of business analytics, however, intuitive deployment and visualization are essential. Since these two areas are increasingly overlapping and in the context of the ever-increasing use of the Internet, interest in alternative deployment methods is also growing in the field of mathematical optimization. In this talk we will show how deployment options of GAMS models can look like.\r\n\r\nAs an example, we present a web interface which is based on an R package called \"Shiny\". We will show how a model that was written entirely in GAMS can be deployed with this WebUI on either a local machine or a remote server (e.g. to leverage parallel computing) in just a few steps.\r\n\r\nWhile data manipulation, scenario management and graphical evaluation of the optimization results can then be performed from within the WebUI, the model itself is not changed. Therefore, the Operations Research analyst can keep focusing on the structure of the optimization problem while planners have a powerful tool to plan and visualize the results.", :title "Model Deployment in GAMS", :keyword2 98, :authors (14898 10542 40519 14853 56010 59584), :session 48}, 251 {:keyword1 187, :keyword3 109, :abstract "In this presentation we study the scheduling of retrieval of unit loads from very narrow aisles with autonomous guided vehicles (AGV).  As AGV cannot pass each other in the aisles, the sequencing of aisle access is essential. We propose two access policies, present multiple complexity results and formulate a MIP model. We then present a large neighbourhood search that produces solutions within less than 2.5% of the optimum solution on average in a few minutes for instances with hundreds of jobs. We use our heuristic to derive insights into the best access policy, number of AGV, as well as the size and layout of the facility.", :title "Scheduling automated guided vehicles in very narrow aisle warehouses", :keyword2 59, :authors (57923 29815), :session 162}, 252 {:keyword1 96, :keyword3 8, :abstract "We consider the cumulative scheduling problem (CuSP) in which a set of non-preemptive multiprocessor jobs must be scheduled on parallel machines according to release and due dates. This problem occurs mainly as a subproblem in more complex scheduling environments, so the goal is rather to compute a feasible schedule or to prove that there exists none.\r\n\r\nSeveral propagation algorithms are known for the CuSP that strengthen the release and due dates of the jobs. We present a new technique that is based on an energetic single machine relaxation of the CuSP that improves the complexity and propagation strength of several state-of-the-art propagation algorithms for the CuSP. \r\n\r\nFirst computational results show the efficiency of the algorithms on common test instances for the resource-constrained project scheduling problem.\r\n", :title "Improving Energetic Propagations For Cumulative Scheduling", :keyword2 155, :authors (52827), :session 80}, 255 {:keyword1 133, :keyword3 102, :abstract "UN Sustainability Development Goal No.6 aims at ensuring access to water and sanitation for all people by 2030.\r\n\r\nWe address this goal in a multidisciplinary approach by applying mathematical optimization methods to design optimal water supply systems for slums within a mega city. Hereby, remote sensing-based slum mapping is used to derive the required spatial information on slum locations and sizes as input data for the decision problem. This problem is modeled as a mixed integer problem (MIP) and chooses between different central and decentral approaches which combine supply by motorized vehicles as well as installed pipe systems. The objective is to minimize the overall costs which include investment as well as operating costs. Furthermore, the MIP captures constraints such as flow conditions and water need requirements.\r\n\r\nThe solution of this MIP, the design of a low-cost water supply network, is presented and analyzed for a slum cluster in Rio de Janeiro with 525 identified slums patches, in Brazil also known as “favelas”.", :title "Designing a water supply network for slums in Rio de Janeiro using mixed integer programming", :keyword2 158, :authors (59689 55674 55684 59692 59693 41758 42187), :session 26}, 258 {:keyword1 35, :keyword3 0, :abstract "A way to model the clustering of jumps in asset prices consists in combining a diffusion process with a jump Hawkes process. This paper proposes a new alternative model based on regime switching processes, referred to as a self-excited switching jump diffusion model (SESJD). In this model, jumps in the asset prices are synchronized with changes of states of a hidden Markov chain. The matrix of transition probabilities of this chain is designed in order to approximate the dynamics of a Hawkes process. This model presents several advantages compared to other jump clustering models.\r\nFirstly, the SESJD model is easy to fit to time series since it can be performed with an enhanced Hamilton filter. Secondly, the model explains various forms of option volatility smiles. Thirdly, several properties about the hitting times of the SESJD model can be inferred by using a fluid embedding technique, which leads to closed form expressions for some financial derivatives, like perpetual binary options.\r\n", :title "A Self-Excited Switching Jump Diffusion: properties, calibration and hitting time.", :keyword2 0, :authors (9487 59698), :session 195}, 259 {:keyword1 35, :keyword3 126, :abstract "We study a problem of non-concave utility maximization under an equilibrium condition. The framework finds many applications in, for example, the optimal design of managerial compensation or equity-linked life insurance contracts. Deriving closed-form solutions, we observe that the equilibrium condition will reduce the riskiness of the optimal strategies substantially. In an extensive numerical section, we analyze innovative retirement products that adapt the investment strategy of the premium pool according to the policyholder's preferences, modeled as constant relative risk aversion (CRRA). Such products are a response to the loss of attractiveness of traditional life insurance contracts with guarantees that are negatively affected by increasing solvency requirements for return guarantees and a general decrease in interest rate levels. Taking into account that retirement products are usually tax-privileged, we find that fairly priced guarantee contracts that follow this optimal investment strategy lead to a higher expected utility level than asset investments.", :title "Constrained non-concave utility maximization: An application to life insurance contracts with guarantees", :keyword2 99, :authors (59696 59699 59700), :session 181}, 260 {:keyword1 96, :keyword3 0, :abstract "In this paper we present a new formulation for the identical parallel machine scheduling problem with weighted tardiness objective. This formulation is based on the structure of a Binary Decision Diagram that contains all the possible sequences of jobs that follow the rules that were devised by Baptiste and Sadykov (Naval Research Logistics, 2009). These rules don’t exclude the optimal solution of a given instance, but constrain the optimal solution to some canonical form. In order to define these rules we need to partition the planning horizon into periods (generally nonuniform). The new formulation has a large number of variables and constraints and hence we apply a Dantzig-Wolfe decomposition in order to compute the lower bound in reasonable time. We show that the lower bound is stronger than the lower bound that is computed with the classical time-indexed formulation. This is also the first time a formulation with a coarser time discretization than the time-indexed formulation is applied to a parallel machine scheduling problem. The experimental results also show, however, that the new formulation is weaker than the arc-time indexed formulation. The advantage over the arc-time indexed formulation is the running time of the column generation phase. To strengthen the LP relaxation of the new flow-based formulation, we introduce new cuts.", :title "A new flow-based formulation for parallel machine scheduling", :keyword2 157, :authors (51656 10607), :session 71}, 262 {:keyword1 7, :keyword3 37, :abstract "Urban delivery is a proper field for a sustainable implementation of electric mobility. For practical applications the range and economic efficiency of electric vehicles plays a crucial role. To this, new operational concepts for electric vehicles are necessary and, as a consequence, a redesign and optimization of the existing logistic chain. On one hand, this implies dispatching with new types of vehicles such as cargo cycles or mobile depots. On the other hand, new business models are necessary to extend the utilization of the vehicle capacity and operation time. Main goal of these new models has to be a spreading of the higher capital costs of electric vehicles on a greater number of heads and services to benefit from their lower operational costs, with the aim of minimizing the total costs of the provided services.\r\n\r\nThe field of sharing economy offers two promising approaches, so-called shared-use and cargo-sharing. The concept of shared-use is strongly related to the well-known concept of car-sharing. While in usual car-sharing models the user is an invididual person, shared-use is a cross-company sharing of vehicles for services of different branches with complementary operation times in subsequent shifts. Cargo-sharing aims to the problem of unused load capacities in urban-delivery and is also a result of a lack of information transparency between different service providers. In this context, cargo-sharing means the exploitation of available freight capacities of a vehicle belonging exclusively to one service provider with transport request from another one.\r\nThe major factors limiting the application of cargo-sharing are the load capacity of the vehicle, driving range (especially for electric vehicles) and the working time of the delivery agent.\r\n\r\nIn this talk we will describe estimators for the load capacity of the vehicle, distance and the operation time of each tour. These estimators are based on the actual delivery-waypoint on the tour route, elapsed operation time or current load capacity state. Then, these informations are included into an optimization model to add new incoming transport requests along the route trajectory in real-time to spread the fixed costs of the vehicle on more productive kilometers.", :title "Estimators for capacity, distance and operation time for cargo-sharing applications in urban delivery", :keyword2 102, :authors (52004), :session 166}, 263 {:keyword1 75, :keyword3 0, :abstract "Random yield occurs if production processes are imperfect and therefore produce defective items. Examples for such imperfect production processes can be found in every industry. Consider for example the production of curved glass for Samsung's cell phones, where the company had to deal with low yield rates of 50 %, meaning that half of all products had to be scrapped. This exemplarily shows that production systems with random yield cannot be neglected and are highly relevant in increasingly complex production processes as well as under high competition and shorter product life cycles. \r\nWe consider a multi-stage production system where the input of the production system is determined by the order quantity. An order can be placed by the warehouse to replenish stock and be able to satisfy stochastic customer demands. Because the optimal ordering policy is known to be very complex, a common linear inflation policy is used. To make sure that only products meeting the quality requirements are stocked in the warehouse and afterwards sold to the customers, an error-free quality inspection is located after the production process, sorting out all defective items. Defective items are either disposed of and leave the production system or are reworked. If defective items are reworked, they have afterwards the same quality as items that were perfect when first produced. Therefore, reworked items also enter the warehouse and are sold to the customers without any price discount.\r\nDifferent from most of the literature on make-to-stock production systems with random yield we consider positive production times during the production process because they are more realistic especially for highly sophisticated production systems as in the high-tech industry. Positive production times increase the complexity of the problem a lot because the decision maker in the warehouse has to place an order before knowing the exact amount of perfectly produced items leaving the production process in future periods. \r\nWe show how to set the policy parameters for such a multi-stage make-to-stock production system with random yield, positive lead times and either disposal or rework of defective items. Our approach requires low computation times even for larger production systems and leads to very good results.\r\n", :title "Inventory management in multi-stage production systems with random yield and positive production times", :keyword2 0, :authors (59701 47722), :session 184}, 264 {:keyword1 86, :keyword3 94, :abstract "When considering the resource-constrained project scheduling problem (RCPSP) with stochastic activity durations, the recent literature mainly considers two different approaches. On the one hand, researchers have focused on proactive and reactive project scheduling, where proactive planning attempts to build a stable project plan that takes the possible disruptions as much as possible into account, while the reactive planning procedures are called every time the disruption changes the baseline schedule such that it cannot be executed anymore as planned. On the other hand, a lot of research has been done on the stochastic RCPSP that introduces scheduling policies that decide at each of the stages of a multi-stage decision process which activities selected from the set of precedence and resource feasible activities have to be started. Recently, Davari and Demeulemeester have introduced an integrated proactive and reactive project scheduling problem for the RCPSP with uncertain durations and developed different Markov Decision Process models to solve this NP-hard problem. This means that not only a good baseline schedule is determined, but also several good continuations in case certain combinations of the activity durations occur that prohibit the baseline schedule or an already adapted schedule from being executed as planned. In this presentation, I will indicate in which cases of the problem truly optimal policies can be constructed and what can be learnt from these policies.", :title "Lessons learnt from solvable cases of determining optimal policies for the RCPSP with stochastic activity durations", :keyword2 8, :authors (41246), :session 160}, 267 {:keyword1 86, :keyword3 8, :abstract "The widely studied resource-constrained project-scheduling problem consists of determining the start times for a set of precedence-related project activities requiring time and scarce resources during execution such that the total project duration is minimized. In the literature, besides a large variety of problem-specific solution approaches, various mixed-integer linear programming (MILP) models have been proposed. We present a novel MILP model that is based on binary assignment variables, binary sequencing variables, and binary auxiliary variables linking the assignment and the sequencing variables. Our computational results for two standard test sets from the literature indicate that the novel model outperforms various state-of-the-art models in particular when the resource capacities are very scarce.", :title "A novel continuous-time model for the resource-constrained project scheduling problem RCPSP", :keyword2 158, :authors (125 39424), :session 160}, 271 {:keyword1 149, :keyword3 91, :abstract "Retail trades greatly benefit from price promotions (promos), i.e., temporary price reductions. The marketing literature on the topic is vast, mainly under the heading “Trade Promotion Optimization”,  but not much has been produced on the optimization of the schedule of promotions of brands or items on long time horizons. There is a rich offer of commercial packages to support these decisions, despite the rather poor coverage in the optimization literature of the many, intertwining operational constraints that characterize actual applications.\r\nThis work proposes a model for retailer chains, focused beyond transactional trade promotion management. It considers both manufacturers, who provide products to sell, and retailers, who are responsible for sales to the consumers. For each promotion, the manufacturer and the retailer define two discounts, the sell-in discount and the sell-out discount. The sell-in discount is the discount applied by the manufacturer to the retailer, whereas the sell-out discount is the discount applied by the retailer to the consumer.  Input data to the model are derived from statistic analytics based on historical data, and yields the expected baseline and the uplift (ratio between the average sales volume with and without a promotion) for each promo in each time period, together with the different contributions to the uplift: cannibalization, halo, promotional dip, forward buying, etc. Building on this, we propose a mathematical model of the effectiveness of a promotion plan in the horizon of interest.\r\nScheduling a promotional plan consists in establishing the calendar, the discounts, and the mechanics of promotions over the time horizon, where the mechanics are possible means to enhance the simple price reduction, such as leaflets, hostesses, gifts, extra-display, etc.\r\nA solution of the promotion scheduling problem determines the number of promotions in the plan, and for each promotion the starting and ending period, the sell-in and sell-out discounts, and its mechanics. A promo calendar specifies or permits to compute: sell in dates, sell in estimated volume, sell in promo price, promo mechanics, sell out dates, sell out estimated volume, retailer promo cost, retail price and retail margin.\r\nThe main constraints we included in the model are: minimum distance between promotions, maximum duration of each promotion, maximum number of promotions, minimum distance between promotions with the same discount or mechanics, maximum number of promotions with the same discount or mechanics, cost of the promotions in relation to the allocated budget, forbidden promotions in some periods.\r\nWe developed a full mathematical model and we compared  different solution methods to solve instances of the  promotion planning problem of real world complexity and size, including MIP, Dynamic Programming, Constraint Logic Programming and a matheuristic algorithm, namely a F&B heuristic, which is essentially an extension of beam search.", :title "Promotion planning optimization", :keyword2 170, :authors (30108 47964), :session 201}, 272 {:keyword1 86, :keyword3 0, :abstract "Project management practitioners increasingly rely on agile approaches, while there is hardly any scientific project management literature addressing these concepts. A central element of Scrum, the most widely used agile approach, is scheduling projects through fixed-cycle project phases, called Sprints. Each fixed-cycle project phase has got a precise ex-ante goal of what is to be achieved and an ex-post review for future improvement of the working team. Besides higher flexibility to project changes, very little is known about the underlying mechanisms of the fixed-cycle design leading to increased performance. Based on existing literature, we derive the hypothesis that three behavioral aspects in the fixed-cycle design related to time allocation, goal-setting, and interrelated learning are major drivers of an increased performance in Scrum: First, in flexible projects, which we define as projects with a fixed total duration but without enforced progression deadlines for every phase, people tend to spend too much time on early phases, leading to a shortage of time for late phases. Second, fixed-cycle projects with strict progression deadlines for every phase mitigate this effect. Third, performance increasing goal-setting and learning effects are reinforced by fixed-cycle project phases. We set up a controlled experimental study to address our research questions. In a fixed total duration all participants solve as many real-effort slider tasks of homogeneous difficulty as possible in ten sequential rounds, which represent ten stylized project phases. Each completed slider within a phase has got a decreasing incremental payoff consistent across phases to mirror a decreasing marginal value-add per invested effort within every phase. We employ a 2x2 treatment design distinguishing flexible project phase progression versus fixed-cycle project phase progression as well as goal-setting and learning versus no goal-setting and learning to decompose the behavioral aspects. In preliminary studies we have found support for our hypotheses. We provide systematic evidence of how fixed-cycle project management with phase-specific goals and interrelated learning impacts performance, thus creating a scientific validation of established assumptions among agile practitioners.", :title "Behavioral aspects in project management - improved performance through fixed-cycle project phases?", :keyword2 19, :authors (59606), :session 19}, 273 {:keyword1 86, :keyword3 0, :abstract "The underrepresentation of risky projects is a well-known issue in new product development/project management. To address this problem, the use of strategic buckets has been proposed in theory, supported by analytical models in the management science literature, and practice. However, a behavioral investigation of the effectiveness and efficiency of strategic buckets is still open. This experimental study discusses the portfolio selection of risky and non-risky projects. In line with the literature we show in a baseline treatment that peoples risk aversion leads to an underrepresentation of risky projects in a stylized project selection process. We consider several treatments to analyze whether strategic buckets, defined as a sub-budget for a specified class of projects, may help to overcome this issue. Our experimental studies show that a) the use of strategic buckets affect project selection decisions, b) voluntary strategic buckets achieve similar results, and c) buckets lead to naïve diversification biases. The latter effect could lead to unintended consequences in project selection. Thus, our study seeks to inform managers on the consequences of applying strategic buckets in project selection, and how the configuration of buckets can influence decisions.", :title "Strategic Buckets in Project Selection – A Behavioral Investigation", :keyword2 19, :authors (53427 26634), :session 19}, 274 {:keyword1 19, :keyword3 0, :abstract "Projects involving different decision makers for planning and execution are common, however, their interaction bears the risk of poor performance. Information asymmetry and the well-established phenomenon that work expands so as to fill the time available for its completion (Parkinson's Law) makes the project planning even more challenging. We study the impact of familiarity, which is known to improve project performance in numerous situations, on Parkinson's Law. To address our research question, we consider a model that reflects the interaction of a planner symbolizing the management of a company and of a worker symbolizing the project executors of the company. Based on this framework, we set up an experimental study providing support that, first not all time planned too long is exploited by workers, second this effect is more pronounced in a setting with familiarity than without, third managers in the familiarity treatment plan significantly longer durations compared to those without familiarity indicating higher trust levels towards the workers. However, in contrast to the treatment without familiarity managers seem to greatly underestimate exploitation in the familiarity treatment thus familiarity rather decreases performance.", :title "The effect of manager-worker familiarity on Parkinson's Law - A behavioral investigation", :keyword2 0, :authors (26634 53427), :session 19}, 275 {:keyword1 96, :keyword3 0, :abstract "Inspired by recent technological advances in factory digitalization, the automotive industry has started to investigate flexible layout alternatives to the widespread mixed-model assembly line. In such flexible layouts, the stations are neither arranged serially nor linked by a paced transportation system. Instead, automated guided vehicles are used to transport the vehicles between the stations. The sequence of tasks is not predetermined, but can differ for each vehicle (operation flexibility). Also, the same task can be performed at multiple stations (routing flexibility). Due to these flexibilities, the industry expects that flexible layouts improve the stations’ utilizations compared to mixed-model assembly lines, especially when assembling heterogeneous vehicles. The scheduling of the assembly tasks, on the other hand, is more complex in flexible layouts.\r\n\r\nIn this research, we develop a mixed-integer linear program for the problem of scheduling the assembly tasks of heterogeneous vehicles in flexible layouts. We design a decomposition-based solution approach and quantify the benefits of operation and routing flexibility. \r\n", :title "Scheduling in automotive flexible assembly layouts", :keyword2 158, :authors (55867 909), :session 186}, 277 {:keyword1 28, :keyword3 0, :abstract "As a consequence of the energy turnaround in Germany, there has been an increase in installed electrical capacities in the distribution grid in recent years, as more and more renewable energy sources (RES) have been connected to the distribution grid. Another fundamental change is the increasing sector coupling, which will mainly be implemented in the distribution grid. Consequently the potential of sector coupling for renewable integration is of special interest as well as how and to what extent distribution system operators (DSOs) can use this potential to improve their own grid operations. \r\n\r\nThis study examines the potential of the distribution network in the course of sector coupling in order to minimize the costs for congestion management for the DSO as well as for the TSO. The focus of the work is on the one hand on the analysis and detailed representation of the various technologies, such as heat pumps, electric mobility or decentralized battery storage. On the other hand, it is investigated which cooperation regimes between the network operators positively support the use of this potential. \r\nIn order to investigate different cooperation regimes, an equilibrium model is developed that takes into account all TSOs and DSOs in Germany - down to the high voltage level - and maps their responsible network areas. Different cooperation regimes of network operators are formulated as a Generalized Nash Equilibrium (GNE) and converted into a mixed complementarity problem by using a linearization approach in order to solve the problem. The network operators are represented as individual players. There are two different cases: firstly, the network operators interact on the basis of asymmetric information, i.e. the respective network operator only has information about the load flows in its own network area and only optimizes the re-dispatch use in its own network area without taking positive or negative effects in or from the other network areas into account. In the other case it is assumed that the network operators share the information, which leads to the network operators supporting each other with their re-dispatch measures. \r\n\r\nThe results show that the potential for cost reduction through increased sector coupling and the active integration of decentralized network congestion management tends to be low. Due to the approach with the equilibrium model, it can be shown that flexible consumers are a good local solution, but the potential in case of full cooperation between the players is limited. This is not due to the time availability of the respective technology, but because the costs for the use are relatively high and there are numerous other, more economical options. The importance of decentralized technologies increases significantly in the event of delayed network expansion or limited cooperation between network operators. \r\n", :title "Ancillary services from the distribution grid - potential of sector coupling and cooperation regimes of grid operators", :keyword2 29, :authors (45164 14876), :session 9}, 280 {:keyword1 53, :keyword3 0, :abstract "This talk will cover the latest developments in the CPLEX Optimizer. We will present some of the new features and algorithmic techniques recently added to CPLEX and provide benchmark results to assess the performance improvements achieved in the latest CPLEX version.", :title "Recent Improvements in IBM ILOG CPLEX Optimizer", :keyword2 0, :authors (51469), :session 47}, 283 {:keyword1 185, :keyword3 0, :abstract "The size of the high-speed railway network in China is increasing significantly these days. It is expected that together with this network growth also the number of passengers on the whole network will increase. Therefore, it is essential to make rational and efficient passenger transportation plans that meet passenger demand. A first step in this process is the line planning, the tactical stage in railway operations. The line plan fixes for each line in which stations the train will stop and with which frequency. The quality of the line plan has a direct impact on the willingness-to-pay of the passengers. This research focuses on the influence of different line plans on ticket sales revenues and operational costs, based on a given passenger demand.\r\nGiven a part of the Chinese high-speed railway network with 11 stations and the passenger OD matrix, this research constructs and evaluates different line plans on the condition that all the passenger demand should be served. In this regard, we assume that the ticket prices are decreased when the actual travel time is larger than a direct connection with a fast train. This can be caused by slower trains, required transfers or detours. However, we also assume that the relatively small changes in the ticket prices will not influence the demand or the route passengers will follow to their destination. In the evaluation process of different line plans, the line frequencies and the type of trains (including capacities and speed) are taken into account. The objective function is to maximize the railway operation profit, which corresponds to the ticket revenues minus the fixed and variable operational costs of each line. Therefore, a trade-off will have to be made between bringing passengers faster to their destination (more frequent, faster, larger and more direct trains) and reducing the fixed and variable operational cost (less, slower, smaller trains with more transfers and detours).\r\nBased on the preliminary experiments, some first conclusions can be drawn. First of all, the interaction between line frequency setting, determining the train type (speed and capacity) and line planning as a whole appears to be very complex. Optimizing the profit is thus far from evident. Nevertheless, the difference in profit between an initial line plan and an optimized line plan can easily be 9% or more for the small network considered. Another result is that passengers will always prefer, also for parts of their journey, the fast train over the slow train, even if this requires extra transfers.\r\nNext, we will develop a metaheuristic approach in order to design appropriate line plans for the whole Chinese high-speed railway network with 31 stations. The goal is to serve all demand in the most economical way, considering travel duration-dependent ticket prices and fixed and variable operational costs of the lines.", :title "Passenger demand-based line planning with a profit oriented objective", :keyword2 59, :authors (59702 46228), :session 33}, 286 {:keyword1 175, :keyword3 158, :abstract "Economic pressure as well as environmental considerations enabled through mobile technology and digitalization give rise to the Sharing Economy. An application of the Sharing Economy is crowdshipping, where occasional drivers share their time and excess capacity of their vehicle to ship parcels to the final destination.\r\n\r\nThe presentation considers a setting, in which a courier, express and parcel (CEP) service provider operates its own fleet of vehicles (regular drivers) to ship parcels from the central depot to customers. Besides the company uses a platform where occasional drivers offer their willingness to deliver some parcels, which are on or nearby their planned route. The origin and destination of the planned route of an occasional driver are transshipment points where another occasional driver or a regular driver hand over or take on, respectively, the fulfilment of the orders and the delivery of the parcels. The company seeks to minimize the entire costs, which arise from the compensation paid to occasional drivers and the distance travelled by regular drivers. The problem at hand is modelled as pickup and delivery problem with transhipments and occasional drivers (PDP-ToD), which leads to a mixed-integer programming (MIP) model. We develop a specialized heuristic solution approach, which solves practical-size problem instances in reasonable computation times. The presentation provides insights how the number and the location of transhipment points influences the cost-advantages achieved when occasional drivers taking part in the delivery process.\r\n", :title "Crowdsourced Logistics: The Pickup and Delivery Problem with Transshipments and Occasional Drivers", :keyword2 174, :authors (59666 1131), :session 168}, 287 {:keyword1 158, :keyword3 187, :abstract "We are a team of engineers working on a practical project of Mobility in Luxembourg.\r\nWe want to solve the problem of optimally determining the sequence of electric and hybrid electric buses, considering both service constraints (schedule adherence) and energy constraints (electric bus charging status, bus recharging scheduling in capacitated facilities) and at the same time ensure a high level of quality of service for the user satisfaction. \r\nThe problem is formulated as a Mixed Integer Linear Program, with the objective of minimizing the total operational cost for the bus lines in question. System dynamics are captured by twenty sets of constraints, ranging from scheduling adherence to discharge-recharge dynamics. \r\nIndividual operational costs at the bus level (cost of running an electric / non-electric bus per km, cost of recharging) and at the trip level (penalty due to failed schedule adherence) are fully parametrised, allowing an extensive sensitivity analysis.\r\nWe investigate a real-life case study based in the city of Luxembourg, where the objective is to reach the all-electric mode for principal urban buses network. \r\nThrough the model we investigate: the minimum amount of electric buses necessary to perform a day’s schedule for two currently partially electrified lines, without resorting to conventional internal combustion alternatives; the impact of electrifying two additional lines, specifically considering the trade-offs related to either adding new buses or new charging stations at the bus terminal.\r\nFinally, we studied how to best decompose the overall problem in several smaller problems, to be able to solve also realistic scenarios and using large real data sets from the Mobility Data owner of Luxembourg. We analysed and compared two kinds of decomposition: a bus line-based decomposition, and a time-based decomposition.\r\n", :title "Decomposition techniques for the electric-hybrid bus dispatching problem subject to energy supply constraints: a case study based on Luxembourg City", :keyword2 189, :authors (59708 36480 36484 57015), :session 33}, 288 {:keyword1 61, :keyword3 74, :abstract "Solving challenging optimization problems often involves algorithms that could exploit the massive parallel computation power of modern High-Performance Computing (HPC) Architectures.\r\nGAMS has several features that support different modes of parallelism for some time. Recently, HPC capabilities of GAMS have been extended significantly. \r\nA link to parallel interior solver PIPS-IPM for large-scale block structured Linear Programs has been implemented. This link requires the user to communicate the model's block structure by variable annotation to the solver. GAMS facilitates user friendly annotation capabilities on the language level.  Experimental implementations of parallel model generation for certain LPs illustrate additional speedup potential.\r\nFurthermore, the novel GAMS Embedded Code Facility, which extends the connectivity of GAMS to Python, allows the implementation of HPC applicable decomposition methods. Via packages like mpi4py the Message Passing Interface (MPI) standard can be used to implement efficient communication between master and worker processes as for example occurring in Benders Decomposition Approaches. \r\n", :title "GAMS and High-Performance Computing", :keyword2 53, :authors (40519 10542), :session 68}, 289 {:keyword1 75, :keyword3 158, :abstract "The current trend towards an increased number of models and variants in the automotive industry leads to a rising logistical effort to supply the mixed-model assembly lines in the right sequence and at the desired time. Therefore, the automotive manufacture set-up so-called supermarkets to feed their assembly lines by using certain JIT/JIS applications. One crucial, long term planning decision connected to these supermarkets is the allocation of product groups to these supermarket areas located inside the manufacturing plant, which minimizes the operational costs supplying the assembly lines. Several hundreds of different product groups have to be assigned to these areas considering the limited space of the storing and picking system, the mutual dependencies between product assignments, already predetermined assignments, the internal supply and transportation system, etc. In addition, the same supermarkets feed multiple assembly lines. The presentation provides a detailed description of the supermarket concept in multi-line automotive manufacturing plants and defines the considered decision problem. The problem at hand is modeled as a mixed-integer program, which is based on a specialized general assignment problem. In addition, an efficient solution heuristic is presented solving the model in reasonable time. A real case study demonstrates the applicability of the mathematical model and the solution approach proposed. A German premium car manufacturer provides the real world data set of the case study.", :title "JIT/JIS Supermarket Allocation for Multi-Line Automotive Production Facilities", :keyword2 33, :authors (56097 1131), :session 187}, 290 {:keyword1 7, :keyword3 158, :abstract "The resource loading problem arises in tactical capacity planning. It depicts a sketch of the usage of resources, and decides the execution intensity for the orders to be executed during the planning horizon, thus providing input for the detailed scheduling at the operational level. A portfolio of orders is to be executed over a time horizon that is discretized into periods, and a pre-specified quantity of regular resources is available in each of the periods. Each order comes with a time window for its execution, and an upper and lower bound on the intensity (fraction) to be executed in each period. The execution time of an order is therefore not fixed, but rather dependent on the resources assigned to it in each period of execution. The goal is to minimize the cost incurred by non-regular resource usage and order tardiness. \r\n    We propose different MIP formulations to solve the resource loading problem, and discuss their strength in terms of LP-relaxation. Computational experiments for these formulations are also presented, showing the different performance of the formulations for finding integer solutions.\r\n", :title "MIP formulations for the resource loading problem", :keyword2 86, :authors (55749 10607), :session 160}, 291 {:keyword1 6, :keyword3 101, :abstract "In this paper we investigate whether and when promoting more intense cost competition between suppliers can actually backfire on the buyer in form of lower quality supplied by the suppliers. We further look at how common sourcing strategies like dual sourcing or use of reservation prices can improve or worsen the quality problem. ", :title "Supplier cutting corners: Can excessive competition compromise quality", :keyword2 87, :authors (35390), :session 40}, 293 {:keyword1 185, :keyword3 175, :abstract "Train timetables are created such that small delays can be absorbed easily. However, in practice, unexpected events such as mechanic failure, can still lead to delays. Whenever one train starts deviating from its original schedule, it is possible that two trains require the same part of the infrastructure at the same time, i.e. a conflict. In practice, dispatchers need to make informed decisions when dealing with a conflict. Currently, advanced Traffic Management Systems (TMS) are already available in practice, capable of predicting train movements and detecting conflicts. However, an advanced Conflict Prevention Module (CPM) is not available in practice yet.  This research proposes such CPM that delivers fast conflict resolutions to complement an advanced TMS. If a conflict is detected by TMS, it is sent to our CPM to determine the best resolution. \r\nOur CPM consists of a rerouting optimization where trains are rerouted in station areas, and of a retiming heuristic. The retiming heuristic creates, for every (initial) conflict, a dynamic impact zone consisting of trains and conflicts that might be affected by the resolution of the initial conflict. This dynamic impact zone includes conflicts, determined offline beforehand, that are very likely to take place. Then, every possible conflict resolution is evaluated based on a simplified progress of all train movements. The resolution delivering the lowest value in either train or passenger delays, is chosen and returned to the TMS. \r\nPrevious research showed that this CPM is capable of delivering a resolution in 1s on average and reducing the train delays with 67% compared to a FCFS dispatching strategy. This research widens the previous approach by comparing the train delays to passenger delays when making simple assumptions on the passenger flows. Also, this research is extended by allowing passenger trains to be canceled. This increases the number of possible conflict resolutions. Of course, canceling a passenger train affects the passenger (and train) delays strongly, but it is difficult to estimate the direct impact of canceling a train. Therefore, different values of cancellation penalties are considered to examine the effect on the network. Previous research showed that only approximately 10% of all conflicts in the dynamic impact zone actually influence the progress evaluation. Hence, the number of conflicts considered is reduced by updating conflicts to the real-time situation as close as possible. This assures that conflicts that are not very likely to take place anymore due to current delays are no longer included in the dynamic impact zone. \r\nThe CPM with the new extensions is tested on a large study area of 11766 block sections (provinces of East- and West-Flanders in Belgium). The simulation horizon is set from 7 a.m. to 8 a.m. during which approximately 240 trains are considered. The CPM returns a conflict resolution in on average 1s and improves FCFS based on secondary delays by 55%.", :title "A conflict prevention strategy for large railway networks", :keyword2 18, :authors (47283 58406 46228), :session 211}, 294 {:keyword1 158, :keyword3 96, :abstract "   As a new orbital imaging platform, Agile Earth Observation Satellites (AEOS) have been widely used in many significant fields, such as sensing of natural resources and military reconnaissance. Due to the mobility of its imaging instrument, the AEOS can observe targets before or after their upright passes. This agility not only enhances its observing ability, but also present a challenge for its scheduling.\r\n   The goal of the scheduling is to select a subset of observation tasks with time windows among a set of candidates in order to gain a maximum profit. The difficulty of the scheduling can be summarized as three characteristics: the “time-dependent transition time”, the “time-dependent profit” and the “multiple time windows”. Firstly, for each pair of two consecutive observations, a transition time is required to maneuver the look angle of the imaging instrument. This transition time depends on their observation start times. Secondly, the quality of an image, i.e. the profit of an observation, also depends on the observation start time. Lastly, each target has multiple time windows, but only one of them can be chosen for observation.\r\n  According to these characteristics, the scheduling problem can be modeled as Time-Dependent Orienteering Problem with Time-Dependent Profit and Multiple Time Windows (TDOP-TDR-MTW). A difference is that the profit in the typical OP with time-dependent profits decreases over time during a whole day, while in our case, the maximal profit is typically collected at the middle of a time window. Up to now, the AEOS scheduling problem with time-dependent profits, or the TDOP-TDR-MTW, was not studied yet. However, a number of researchers have worked on closely related scheduling problems, leading to relevant insights and related benchmark instances.\r\n\r\nWe present a Mixed Integer Quadratic Programming (MIQP) model and develop an Iterated Local Search (ILS) algorithm integrated with a Dynamic Programming (DP) approach. Based on local evaluation metrics, a time-dependent insert procedure is specifically designed with a fast feasibility check of an insert move. The DP approach is presented to determine the best observation start time of each task in a solution and to evaluate the total profit for each move during the search. \r\nUnfortunately, no benchmark instances are available for the problem with time dependent profits. Therefore, the performance of the algorithm is first evaluated on benchmark instances without time dependent profits. On these instances, our algorithm performs on average 65.5% better than the state of the art algorithm.", :title "A Heuristic for the Agile Earth Observation Satellite Scheduling with Time-Dependent Profits", :keyword2 156, :authors (59710 46228), :session 26}, 295 {:keyword1 157, :keyword3 0, :abstract "Mixed integer programs arising from practical applications typically feature highly degenerate solutions to their LP relaxation. Consequently, these LPs have multiple optimal solutions, often both in the primal and the dual space. This degeneracy is arguably the main reason for performance variability of LP based MIP solvers.\r\n\r\nIn recent years, various authors have investigated different aspects of LP degeneracy in MIP solving. One line of research is to try to exploit degeneracy in order to improve the performance of MIP solvers or to reduce the solvers' variability. Examples are Zanette's, Fischetti's, and Balas' work on using the lexicographic simplex for Gomory cuts, the \"pump reduce\" step in CPLEX, or the \"degenerate reduced cost fixing\" implemented in the SAS/OR solver. Most recently, Bajgiran, Cire, and Rousseau presented a more systematic way to pick dual optimal LP solutions in order to improve reduced cost fixing.\r\n\r\nThis talk explains various methods implemented in Gurobi 8.0 to exploit LP degeneracy in order to speed-up the MIP solving process. Computational results assess the practical impact of the various techniques.\r\n", :title "Exploiting Degeneracy in Gurobi 8.0", :keyword2 158, :authors (12336), :session 50}, 296 {:keyword1 86, :keyword3 170, :abstract "In this talk, we present the results of computational experiments on a novel set of benchmark instances for the multi-mode resource investment problem (MRIP). The MRIP is a project scheduling problem with the goal of minimising the project’s resource costs while respecting a given project due date. Furthermore, a feasible schedule has to take into account both renewable and nonrenewable resource constraints as well as precedence relations among activities. In the multi-mode variant, the chosen mode of each activity determines the processing duration and resource requirements. The MRIP is an NP-hard problem but so far, no common benchmark instances are available. Hence, we host the website https://riplib.hsu-hh.de where our instances are accessible as well as a database with best-known solution values for each instance. We invite researchers to upload their solutions to this database.\r\nWe implemented several heuristic and metaheuristic procedures to evaluate their performance on these instances. For example, we used priority-rule based heuristic procedures as well as a metaheuristic approach that utilizes local search techniques and a perturbation component to overcome local optima. Finally, we also developed a hybrid metaheuristic that combines the large neighbourhood search metaheuristic with mathematical programming techniques. The computational experiments show that the instances are challenging and further research on the MRIP is needed.\r\n", :title "Testing heuristic and metaheuristic approaches on the RIPLib benchmark instance set for the multi-mode resource investment problem", :keyword2 59, :authors (49145), :session 160}, 297 {:keyword1 158, :keyword3 33, :abstract "The NP-hard Double-Row Facility Layout Problem (DRFLP) consists of a set of departments and pairwise transport weights between them and asks for a non-overlapping arrangement of the departments along both sides of a common path such that the weighted sum of the center-to-center distances between the departments is minimized.\r\nWe present combinatorial lower bounds for the DRFLP, which can be computed very fast. These bounds generalize the star inequalities of the Minimum Linear Arrangement Problem and use an approximation algorithm for the Parallel Identical Machine Scheduling Problem with Minimum Weighted Completion Time. Based on these combinatorial lower bounds we introduce a new distance-based integer linear programming model, which allows computing even stronger lower bounds via branch and cut within a short time limit. Furthermore, we extend this model to a formulation for the DRFLP. \r\nThe NP-hard Single-Row Facility Layout Problem (SRFLP) deals with a similar question as the DRFLP but the departments are arranged at only one row. We indicate the relation between the objective values of optimal single-row and optimal double-row layouts and show how to exploit this for a new DRFLP heuristic based on SRFLP solutions.\r\nWe compare the combinatorial lower bounds with lower bounds received via branch and cut within a given time limit for DRFLP formulations from the literature. Upper bounds are received via our new heuristic.", :title "Combinatorial Lower Bounds for the Double-Row Facility Layout Problem", :keyword2 8, :authors (55691 26471 16988 30955), :session 218}, 298 {:keyword1 18, :keyword3 175, :abstract "The  size of the Pareto set of a multicriteria multimodal shortest path problem can be exponential. Even approximation sets can remain quite large, while a multimodal trip planner app user would like to have only a few but relevant choices. Therefore, we need to select some of the alternatives and propose them to the user. Furthermore, since users can have different preferences (one likes walking, the other prefers the bus) and trip contexts (need to arrive quickly, etc.), the set of returned alternatives needs to be personalized.\r\nHence, this study started by wondering: How can we propose a reasonably small size set of “personally good” alternatives to the corresponding user?  For this aim, we need to find a way to model the users’ preferences, and then evaluate each alternative comparing to the others regarding the user’s preferences. \r\nIn the existing studies, the users’ preferences are mostly modelled by some weights for each criterion, which are given by the users and that enable to aggregate all the criteria into one single objective function. We think it’s difficult to describe one person’s feeling by a crisp number and that the Fuzzy logic is better suited in this situation. In this talk, we are proposing a Fuzzy system to rank the alternatives . \r\nOur system has three phases. In the first phase, we transform the users’ preferences and the alternatives’ criteria evaluation into fuzzy sets. For example, preference on the subways can be “Like” with a descriptive membership value  (obtained from user assessment of her preferences), the total duration of one alternative can be “Long” with its membership value  (read from its evaluation function). During the alternatives’ criteria transformation, we are proposing two novel methods of fuzzification according to the different types of criteria for setting the membership functions. The first method uses a parameter which is called the “tolerance” of the user for each criterion, while the second method is based on a clustering of the alternatives. In the second phase, a combination between user’s preferences and the rating of the alternatives for each criterion according to the membership functions allows to evaluate the user’s satisfaction on each criterion. The combination is realized by using a set of fuzzy rules. In the third phase, we propose a new defuzzification method, combining the different levels of satisfactions that we calculated in the second phase into a general satisfaction of the alternative. The general satisfaction is represented by a crisp number that is our ranking parameter. \r\nIn order to assess the method, we built a survey in which we asked people to rank alternatives, and we compared the surveys’ results with the results from our ranking system. \r\nThe PhD of Lizhi Wang is financed by the Region Auvergne Rhône-Alpes via the academic research community ARC7.\r\n", :title "Multimodal itineraries ranking using fuzzy logic", :keyword2 39, :authors (59607 59712 59713 11482), :session 214}, 299 {:keyword1 96, :keyword3 36, :abstract "The job sequencing and tool switching problem (SSP) is an NP-hard combinatorial optimization problem that arises in the context of metal working or semiconductor manufacturing industries, and most specifically in a flexible manufacturing environment. Tool switches denote the interchange of tools between the global tool storage and the local tool magazine of a machine since the tool magazine capacity of the machine is limited and cannot hold all tools necessary for processing all jobs. Tool switching has a major impact on the overall performance of the system by affecting total set-up time as well as machine and tool utilization. If the tools cannot be interchanged during job processing then switching time becomes especially crucial if it is significant in regard to the processing time of a job. Therefore, the objective of the SSP is to find the sequence of jobs that minimizes the number of tool switches for a given set of jobs. So far, mathematical formulations have been proposed for the single machine problem and for identical parallel machines and tandem machines. The presented work considers the SSP with non-identical parallel machines (SSP-NPM) for the different objectives minimizing the number of tool switches, minimizing makespan and minimizing total flowtime. As the problems are NP-hard, computational experiments for integer programming models have shown that only small problem instances can be solved to optimality. The formulations struggle even when considering instances with 15 jobs. In case of industrial problems, the mathematical formulations for the SSP for multiple machines yield CPU times beyond practical time limits. Therefore a simple and fast heuristic approach for the SSP-NPM is presented that, step-by-step, assigns jobs to machines and in the process determines the loading of the tools. The performance of the heuristics is analysed with respect to computation time and solution quality for different objectives. ", :title "Heuristics for solving the job sequencing and tool switching problem with non-identical parallel machines", :keyword2 8, :authors (57109 59711 19376), :session 161}, 300 {:keyword1 33, :keyword3 59, :abstract "The designer of a plant layout is faced with the arrangement of facilities to minimize the total material handling effort. Due to the planning complexity, most concepts for the facility layout problem are based on a sequential approach consisting of three steps:\r\n1. Arranging facilities within the plant layout\r\n2. Locating material handling points of facilities\r\n3. Designing the material handling system\r\nSince the path design is not considered in the first two steps, most approaches apply rectilinear distances to estimate the path length. However, flow paths of usual material handling systems must not overlap facilities and are forced to bypass blocking facilities. Hence, designing the paths within the arranged facilities can be difficult and the estimated distances can be exceeded significantly. Moreover, the designer needs to consider that generally 5% to 40% of the floor space is occupied by aisles. Since the location of aisles is unknown in the first step, the literature suggests boosting the areas of facilities to consider aisle areas later. Estimating a boosting coefficient is crucial, as a small value does not provide enough space to plan all aisles and a too large value leads to less layout density and long distances. Consequently, a sequential planning of these mutually dependent problems can lead to solutions that are far from optimum and might require costly replanning. Few approaches integrate the material handling network design and measure distances along the paths. However, they do not consider the required area of aisles.\r\nThis new approach applies a scatter search algorithm to concurrently design the unequal area facility layout problem, the material handling points and the aisle system based on distances along the travel paths. Therefore, the approach determines a preliminary block layout using a linear programming model and the relative locations known from a sequence pair coding. After transferring the block layout into a graph, material handling points are determined using the shortest paths. Knowing the location of paths, the linear programming model is adjusted to consider a clearance between facilities along the paths that represents the aisles. The performance of each layout is evaluated by the material handling effort using the travel distances calculated with Dijkstra’s algorithm. A superordinate scatter search algorithm aims to find the layout resulting in the lowest material handling effort.\r\nSince this integrated problem has not been solved before, there are no comparable solutions. Therefore, the approach is evaluated using the best known layout solutions with integrated path design in which we included the aisle area along the paths. The results indicate that layouts with aisle areas differ significantly when compared with layouts optimized without aisle areas. Although the impact is influenced by the required aisle width, this integrated approach can lead to considerable better layouts, even using narrow aisles.", :title "A Scatter Search Approach for the Integrated Facility Layout Problem with Material Handling Locations and Aisle Design based on Path Distances", :keyword2 153, :authors (59571), :session 187}, 302 {:keyword1 134, :keyword3 25, :abstract "When analyzing asset pricing with incomplete information on regimes, the role of different reference functions is already clarified (Ai (2010)). What is not equally well understood is, first, the effect of heterogeneous models of regimes and cash flows on the equity risk premium and, second, the nature of incomplete information as a second source of risk.\r\nWe show, first, that incomplete information as second source of risk contains systematic risk although it does not consist of 100% systematic risk. Moreover, there is no risk premium on noisy signal meaning that signals do not change the decomposition of total risk into systematic and unsystematic components. Second, when comparing complete and incomplete information risk premia the functional dependence of cash flows on regimes matter most: whenever there is a lagged influence of regimes on cash flows, incomplete information risk premia tend to be lower than complete information risk premia. However with a non-lagged influence the difference between incomplete and complete information risk premia can assume arbitrary signs.\r\n", :title "Equilibrium Asset Pricing with Incomplete Information on Regimes", :keyword2 34, :authors (54586 55580), :session 197}, 303 {:keyword1 100, :keyword3 0, :abstract "The advancing digitalization opens various opportunities for enterprises to expand or change their existing production processes and production program. In the latter case, besides \"classical\" products, digital products are increasingly becoming the focus of suppliers and consumers in many fields. From a strategic management perspective, there is a need for continuous clarification, in which kind of \"classical\" and digital product fields companies want to operate in the future.\r\nIn order to determine the optimal combination of “classical” and digital products, we propose a mixed integer program (MIP). Therefore, we extend a standard model for strategic production program decisions by adding components regarding the size and the composition of digital product fields. Since future data cannot be determined precisely, we additionally take uncertainty into account by considering data in different constellations and linking them to interval probabilities. The optimal solution of this MIP is robust to different future data constellations.\r\n", :title "Digital products: An optimal production program strategy", :keyword2 157, :authors (55858 2651), :session 190}, 304 {:keyword1 101, :keyword3 0, :abstract "While group purchasing amongst competing OEMs enables these to obtain rebates from the  supplier, it also requires regular interactions between the OEMs, which result in disclosure of private information such that OEMs might prefer individual purchasing to conceal their private  information. This paper investigates how information sharing dimension affects OEMs' motivations towards group purchasing, specifically in industries characterized by market demand and technology level uncertainties. Under Cournot competition, we find that group purchasing is preferred by OEMs when product technology strongly affects market demand, and that preference for group purchasing would depend on product substitutability, market demand variability and supplier rebate when influence of the product technology is low. We further find that group purchasing can benefit both the OEMs and the consumers.", :title "Cost of information sharing under group purchasing", :keyword2 40, :authors (59709 35390 9881), :session 40}, 306 {:keyword1 35, :keyword3 100, :abstract "This paper considers the valuation of sequential R&D projects. In particular we include all relevant options associated with the typical stages, such as the R&D stage itself with options to abandon and continue, and, once the R&D is finished, the following stage of commercialization with the option to market. A novel aspect of the paper is that we investigate how the staged R&D project is affected by the competitive environment thereby bridging research in the domain of strategic management, corporate finance and real options.", :title "Strategic R&D Valuation under Uncertainty, Irreversibility and Competitive Environments", :keyword2 156, :authors (59691 31822), :session 195}, 307 {:keyword1 126, :keyword3 0, :abstract "The present paper considers a type of multi-stage problem where a decision maker can optimally decide to switch between two alternating stages (regimes). In such a problem, either one of the two stages dominates in the long run or it is optimal to infinitely switch between stages. A point where such a phenomenon occurs with optimal switching time zero is called Zeno point.\r\n\r\nBy a reformulation of the multi-stage problem using an additional binary control to account for the alternating stages, the necessary matching conditions for optimal switching are derived. A relaxation with a linear control is considered to analyze the implications of the occurrence of a singular solution. In case of the control becoming singular, the matching conditions are fulfilled, i.e. it is optimal to switch between the stages. If the time derivative of the matching conditions is zero, it is shown that trajectories approaching this point are tangential to the switching curve. Furthermore, if the trajectories move into opposing directions, this implies Zeno behavior.\r\n\r\nA two-stage version of a standard capital accumulation problem is analyzed and a Zeno point is found analytically. Numerical calculations are performed to visualize the Zeno phenomenon. The economic relevance of the phenomenon is discussed.", :title "Zeno Points in Optimal Control Models with Endogenous Regime Switching", :keyword2 0, :authors (23371), :session 181}, 308 {:keyword1 158, :keyword3 133, :abstract "This paper presents an application-oriented comparison of optimization methods for online model-based control strategies in the context of a stationary hybrid storage system. \r\nThe exemplary storage system, considered in this paper, aims at improving the supply security of the intermittent renewable energy sources wind and photovoltaic. The hybrid storage system consists of a battery and a hydrogen storage including an electrolyzer and a fuel cell. Hybrid storage offers a complementary supply concerning high capacity provided by the hydrogen storage and high peak loads provided by the battery. Moreover, the hybridization gives an additional degree of freedom for optimal operation with respect to the system’s efficiency. We exploit this extra degree of freedom using a model-based control approach. The control decision of every time step is determined by means of an optimal control problem, using a simplified model of the system as controller internal prediction model. The comparison of results dependent on the formulation of the underling optimization problem is subject of this paper. \r\nThe trade-off between model accuracy and computational burden determines the class of the optimization problem for use in model-based control. On the one hand, linear models enable real-time applicable control algorithms but do not fully exploit the potentials of optimization-based approaches. On the other hand, nonlinear models represent reality quite well but can cause long calculation times or suboptimal solutions of the optimization problem depending on the solving algorithm. Mixed integer optimization (MIO) offers a good compromise in this field of tension; therefore, we assume it as the most appropriate approach for this problem. \r\nWe prove seven percent improvement of the hybrid discharging efficiency using MIO compared to linear optimization. The energy system is modeled via static efficiency curves extracted from experimental data. We regard real prognoses data of power consumption of the German grid operator 50Hertz. Finally, the MIO takes into account minimal loads and piecewise affine functions for the partial load behavior of battery and fuel cell. \r\nAs main implications of MIO, we identify a change of the operating states in terms of operating hours. By consideration of the partial load behavior, the operating hours of the battery are tripled. Furthermore, the number of hours increases strongly, when both components are active either in parallel or complementary operation. Thereby, the solving-time, required by the commercial solver gurobi, remains below 34 seconds. In average, the solving time is as low as 2 seconds. We define this solving time as sufficient compared to the 15 minutes sampling rate of market auctions of the electricity exchange market.   \r\nIn conclusion, we show the potential of mixed integer optimization in the model-based control approach for efficiency improvement with practicable solving times. \r\n", :title "Model-Based Control of Stationary Energy Storage Systems: A Comparison of Optimization Methods", :keyword2 126, :authors (59717 59736 45180), :session 8}, 312 {:keyword1 48, :keyword3 153, :abstract "In certain additive manufacturing (AM) processes of industrial interest, the task arises to build up structures layer-wise from bottom to top in a purely vertical manner. Such orthographic structures are of specific interest if the printed material is soft at the moment when it is applied, as for instance in wire-arc AM where molten wire is transferred in droplets during printing. However, the question arises how to construct in a convenient way a printed orthographic structure that is structurally as stable as possible. In this paper, we proceed in two stages towards that goal.\r\n\r\nIn the first stage, we consider the automatic construction of a honeycomb structure given the boundary shape of a structure. In doing this we employ Lloyd's algorithm in two different realizations. For computing the incorporated Voronoi tesselation, which is the central point of the method, we consider either the use of a Delaunay triangulation or the eikonal equation. We give an extensive comparison of these two methods that are methodically very different. While finding a Delaunay triangulation as the dual graph of the Voronoi diagram is based on geometric arguments, the eikonal based approach makes use of a discretization of the corresponding partial differential equation. Thereby the number of seed points used for constructing the Voronoi tesselation is a design parameter. This is important in practice since it yields a way to take into account for instance total weight of a planned structure in the design process.\r\n\r\nIn the second stage, we consider the arising graph of the computed honeycomb structure as input for a specific routing scheme. The routing is proposed in order to (i) allow a maximal time before revisiting the same point during printing, and (ii) traversing the structure in different ways when applying the material layer by layer.", :title "Computation of Stable Honeycomb Structures for Additive Manufacturing", :keyword2 133, :authors (59720 59724 59718 16315), :session 83}, 313 {:keyword1 124, :keyword3 8, :abstract "Domain experts in many different contexts solve optimization problems for different input data. Consider for example an expert at production scheduling: he receives the demand for each day and decides based on his domain knowledge when and on which machines to produce the required goods. We consider the setting where the specific domain knowledge lies in the objective function of the optimization problem to be solved, and where we are able to observe the input data and the decision maker’s corresponding decisions over multiple rounds. We assume that the true objective function is only known implicitly by the expert, as it is often the case in practice. Our goal is to find an objective function that allows us to emulate the expert’s decisions and thus to take equally good decisions with respect to the true objective. Previous work is in this context was based on KKT-system decomposition and dualization approaches and therefore only worked for convex decision domains. Our new approach is based on online learning techniques and works for arbitrary domains for which we have access to a linear optimization oracle. It works by relaxing the requirement to learn a single objective to learning a series of objective functions which on average perform as well as  the true objective function employed by the expert. We prove that the solution quality our algorithms achieve converges at a rate of O(1/sqrt(T)) in the number of rounds T and present an in-depth computational study which confirms the theoretical results for several combinatorial optimization problems.", :title "Learning objective functions from observed decisions for combinatorial optimization problems", :keyword2 13, :authors (52479 59498 52443 59722), :session 80}, 314 {:keyword1 101, :keyword3 158, :abstract "We present an approach for evaluating and proactively managing the vulnerability of a producing company to major disruptions in its (direct and 2nd-level) raw-material supply, due to e.g. earth quakes causing a long-term supplier-site shutdown.\r\n\r\nThe disruptions we consider are, each on its own, too unlikely to qualify for probabilistic analysis; yet they do occur from time to time, such that the company needs to consider such events in its business continuity planning (BCP) in order to avoid dramatic production shortfalls, leading to customer dissatisfaction and loss of share in the market.\r\n\r\nBecause precautionary measures, such as inventories or a large supply base, are typically expensive, cost is an important objective when aiming to reduce risk exposure. Yet it is practically impossible to formally quantify the cost of all potential counteractions in a large global supply chain, so that we intentionally avoid an explicit cost term in the mathematical model.\r\n\r\nInstead, our goal is to assist a decision-maker in cost-efficient risk management by allowing her to quickly assess the impact of user-defined actions, such as increasing an inventory or qualifying an additional supplier, on the overall risk exposition.\r\n\r\nTo that end, we have developed a decision-support tool for a global consumer goods manufacturer that computes the impact of a given set of disruptive scenarios to the company's global production. Each scenario is simulated by using a time-expanded flow network that contains the affected part of the supply chain as well as all relevant alternative suppliers, inventories, and 2nd-level supply information. The network is solved by a commercial mixed-integer programming solver that lexicographically minimizes several objectives. The resulting risk measure is again multi-dimensional, the two most important components being duration of shortage and time to first shortage. A large time to shortage is desirable because it generally increases the scope for creative remedies that are not covered by our model.\r\n\r\nThe resulting global risk profile can be explored at different levels of detail, the most aggregated of which is a boolean value that indicates whether the supply-chain meets a predefined acceptable level of risk. This aggregated risk profile further enables to compare and balance the risk across different raw-material supply chains, which is very important from a cost perspective.\r\n", :title "Business Continuity Planning for Supply-Chain Disruptions", :keyword2 63, :authors (59721 23161 59723 59714 15433), :session 2}, 316 {:keyword1 63, :keyword3 0, :abstract "Energy efficiency, minimization of electricity cost, compliance with the latest drinking water quality regulations and safety regulations for the storage of drinking water – these partly contradictory goals turn the design and the operation of drinking water supply systems into a multicriteria optimization problem. The coordination of transport pumps and well pumps as well as the storage of water allow the operator of the waterworks a variety of options. Consequently, optimal operation of drinking-water supply systems is difficult to achieve when technical support is missing. In the first part of this talk, an interactive decision support tool is presented which filters the set of good solution. It allows to modify existing solutions and to compare solutions persuading the planner of good choices.\r\n\r\nFrom a mathematical perspective, the operation problem is a discrete optimization problem. Options, such as the number of pumps, pump speed values and the number of operation points, increase the computational complexity exponentially. Smart tree traversal strategies and useful restriction policies have to be applied in order to find good solutions in adequate time. Due to the exponential growth of solutions, branch-and-bound algorithms have been implemented to dismiss inefficient operating states early and to save computational resources. \r\n\r\nContinuous pump speed options add even more complexity, which can be overcome by solving nonlinear multicriteria optimization problems. Last but not least, some work needs to be done to convince traditionally conservative waterworks that the usage of the new software tool leads to better operation strategies. \r\n\r\nIn the second part of the talk, the pump industry is discussed. It has great interest in designing a small portfolio of different pump sizes to cover the needs of most customers in the water distribution sector. That is also a discrete multicriteria optimization problem with an exponential number of feasible solutions but much higher computational effort. For this reason, heuristic approaches are combined with optimized modification steps to find optimal solutions or to improve existing alternatives.\r\n", :title "Multicriteria optimization in the water distribution sector", :keyword2 0, :authors (42548), :session 2}, 317 {:keyword1 96, :keyword3 0, :abstract "It is a very important issue to meet the customer orders on time in the real manufacturing environment. In the literature there, many papers about FFSP but most of them are about makespan or other objectives. This study addresses FFSP from the Customer Order perspective and presents a new time indexed mixed integer linear programming model (MILP) for the Customer Order Scheduling Problem (COSP) in flexible flowshop environment. In the problem, there are a number of customer orders having different due dates and priorities. There are products in various quantities from different product types in each order. In the shop, there are a number of stages and parallel machines in each stage. The objective is to minimize total weighted order tardiness. The model is defined and explained, test problems are generated and showed efficiency of the model in that test problems. It is showed that the proposed MILP model reach optimum solution for the small size problems and produces good lower bounds for the large scale problems.The results show that proposed MILP model efficient and can be used to obtain good lower bounds for the problem.", :title "A MILP Model for the Customer Order Scheduling Problem In Flexible Flowshop Environment", :keyword2 158, :authors (3614 25256), :session 84}, 323 {:keyword1 42, :keyword3 173, :abstract "The maximum Residual Flow Problem with Arc Destruction is posed as follows. Given a directed network G, find a maximum flow such that when k arcs are deleted from G the value of a maximum flow in the residual network is maximum. It is proved that the problem is polynomial time solvable for k = 1 whereas it shown to be N P -hard for k = 2.\r\n\r\nThe Adaptative Maximum Flow Problem was first adressed as an alternative to the robust maximum flow problem. In this model, the flow can be adjusted after the arc failures occurred. \r\nIn this presentation, we are concerned with the Adaptative Maximum Residual Flow Problem, that is the maximum Residual Flow Problem with Arc Destruction when the flow can be reoriented. We focus on three variants of the problem : the original problem in which the attacker may destroy a given number k of arcs ; a variant where some of the arcs cannot be destroyed ; and a last variant where each destruction is associated to a given cost and where the attacker has a given destruction budget. \r\nFor each of the three problems, we focus on complexity results. Those results depend on the maximum number of destructible arcs that can be found on a single path from the source to the sink. It has been proven that all the three problems are NP-Complete when this parameter is greater or equal to 4. We complete the results when we restrict the problem to instances where this parameter equals 2 or 3.  \r\n", :title "Maximum Residual Flow Problem with Arc Destruction", :keyword2 154, :authors (59725), :session 38}, 326 {:keyword1 61, :keyword3 0, :abstract "Though fundamentally declarative in design, optimization modeling languages are invariably implemented within larger modeling systems that provide a variety of programming options.  Although programming is not used to describe models, it facilitates the integration of models into broader algorithmic schemes and business applications.  This presentation surveys ways in which a programming interface can be useful, with examples from the AMPL modeling language and system.  The focus is on new APIs (application programming interfaces) for controlling AMPL from programs in Python and in R, and on new facilities for invoking Python programs from within AMPL.", :title "New Programming Interfaces for the AMPL Modeling Language", :keyword2 0, :authors (3753 57228), :session 68}, 327 {:keyword1 29, :keyword3 42, :abstract "Systems which provide active and passive energy services are under continual change in many countries. Many of these changes take place on the municipal level. Major drivers can be seen in the rising distributed energy resources, the increasing electrification, the way towards a carbon-neutral energy mix, the changing utility business models as well as the increasing customer engagement. These trends result in a changing market environment. Decision makers need to investigate under what conditions interventions lead to a sustainable future system. The development of strategies is a challenging task for the actors involved.\r\n\r\nExisting relationships between provision and utilization of energy services are necessary for representation of actor-related social and economic activities along the energy chain. Energy policy formation over a certain municipal area is a complicated exercise involving many issues between private and corporate interests. Commercial actors along the energy value chain might assess challenges and opportunities from different perspectives and various criteria of interest, since every single consumer and operator has a differing technology component process-mediated relationship. Common actors are households or communities, energy producers, energy suppliers, distribution system operator as well as government, policy makers and regulators. These actors are interdependent in the realization of their goals. To the greatest possible extent, existing energy system optimization models ignore the roles that different actors play in existing system architecture and the resulting impact they might have. Individual actors need to be modeled separately and thus likewise the spatially distributed load, storage and generation systems. Due to unbundling reasons the business units of an energy utility should also be individually modeled as sketched to cover the different goals.\r\n\r\nAn additional focus on activities of all involved actors allows the inclusion and adopting such behavior to a varying degree within the community. In this context, technical behavior no longer needs to be in the presence of one internal decision-maker as existent in most of the presented models. User acceptance is quite heterogeneous and needs to be considered. Actors hold bilateral contracts between each other that handle the business transactions. Thus, an integrated view requires the inclusion commercial association networks. \r\n\r\nThis research proposes a multi-level entity oriented optimization framework called Integrated Resource Planning and Optimization (IRPopt). The mixed-integer programming approach exhibits a novel formal interface between supply and demand side which merges technical and commercial aspects. This is achieved by explicit modeling of municipal market actors on one layer and state-of-the-art technology components on another layer as well as resource flow interrelations and service agreements mechanism among and between the different players. ", :title "Entity oriented multi-level energy system optimization modeling", :keyword2 158, :authors (59376 59726 41520), :session 8}, 328 {:keyword1 45, :keyword3 0, :abstract "Medical safety allows for the monitoring of users' health in their daily lives, improving their well-being and the quality of medical care, while reducing costs in the healthcare sector. Medical safety affects medical equipment that is exposed to many risks with respect to the safety of the medical data it contains; loss (theft or piracy) or modification (incorrect information). The ubiquitous nature of medical resources exposes the hospital information system to attacks (intrusions) that come from internal or external sources, which require protecting these medical resources from intruders and attacks. One of the most common techniques used to ensure the use of medical resources by legitimate users is intrusion detection systems (IDS); which allow to monitor and analyze a system, to detect and to correct any anomaly, modifications and misuse of the system. In this paper, we propose to develop an IDS for detection and identification of intrusions in ubiquitous medical systems. Our work aims to overcome intrusions problems by developing an intrusion detection system based on the use of authentication of legitimate users, signals and prevents intruders from intruding. The proposed model implements dual protection of users and ensures the safety of medical resources. In this solution, our goal is to explore the possibility of detecting intrusions (attacks) occurred in ubiquitous environments using genetic algorithm approach.", :title "Genetic Algorithm for Intrusion Detection System in Pervasive Medical Resource ", :keyword2 94, :authors (22533 45303 60321), :session 174}, 330 {:keyword1 54, :keyword3 150, :abstract "The design of hub-and-spoke transport networks is a strategic planning problem as the choice of hub locations has to remain unchanged for long time periods. However, the future transport volumes are not known in advance and can only be estimated by a stochastic distribution during the planning process whereas classical models for hub location problems assume fixed input data. Moreover, carriers observe significant fluctuation in demand over time. Therefore, it is important to include uncertainty in hub locations problems. In this talk we develop a two-stage stochastic optimization formulation for single allocation hub location problems \r\nwhere the allocations to the hubs are viewed as variable over time. \r\nThis allows to modify the routing in the hub-and-spoke transport network according to the current scenario, but also blows up the number of variables in the model and, thus, makes the problem much harder to solve.\r\nIn order to solve large-scale instances to proven optimality, the problem is decomposed into scenario-specific subproblem which are interlinked \r\nby generalized Benders cuts for a common choice of hub locations. \r\nThe decomposition also allows us to dissolve the inherent quadratic structure of the classical formulation of single allocation hub location problems. Embedded into a modern mixed-integer solver our decomposition approach is able to solve large instances under demand uncertainty. \r\n", :title "Demand uncertainty in single allocation hub location: A generalized Benders decomposition", :keyword2 165, :authors (52445 39380), :session 169}, 331 {:keyword1 34, :keyword3 42, :abstract "As a consequence of the increasing industrial digitalization not only humans, machines, materials and so on will be increasingly cross-linked but also the firm itself with its suppliers, customers and partners. Inversely, financial institutes need to ask for the relevance of the intensification of multi-firm co-operations within supply chains for their credit portfolios. To be in the position to adequately judge risks, financial institutes have to be up to describe and to analyze the networks of obligors for credit assessment and credit risk measurement. Credit risk not only depends on the quality of the single obligor but on a network of contributors with different credit ratings and weights in the supply chain. \r\nGiven these findings, the paper uses graph theory to model the above mentioned micro-structural relationships of obligors in credit portfolios. Graphs seem to be a suitable instrument to mirror the complex relations (edges) of obligors (knots). Established credit portfolio models usually neglect micro-structural relations and use highly aggregated information for modelling stochastic dependencies of obligor´s profit and loss variables. We suggest including graphs into the common models. This enables financial institutes fairly to take into account changes of an obligor´s situation affected by problems of a supplier or client. Analyzing the graph topology we can examine the implications on the credit portfolio and on the credit risk position if one obligor defaults who is numerously connected with other obligors within the same portfolio. In addition to that, information is provided on credit contagion and on risk concentration which the banking supervision demands. In summary we expect a significant improvement of credit risk models.\r\n", :title "Credit risk and graph-based modelling of obligor´s micro-structural relations", :keyword2 93, :authors (39455), :session 197}, 337 {:keyword1 42, :keyword3 95, :abstract "This paper concerns the Hamiltonian p-median problem defined on a directed graph, which consists of finding p mutually disjoint circuits of minimum total cost, such that each node of the graph is included in one of the circuits. Earlier formulations are based on viewing the problem as resulting from the intersection of two subproblems. The first subproblem states that at most p circuits are required, that are usually modelled by using subtour elimination constraints known from the traveling salesman problem. The second subproblem states that at least p circuits are required, for which this paper makes an explicit connection to the so-called path elimination constraints that arise in multi-depot/location-routing problems. A new extended formulation is proposed that builds on this connection, that allows the derivation of a stronger set of subtour elimination constraints for the first subproblem, and implies a stronger set of path elimination constraints for the second subproblem. The paper describes separation routines for the two sets of constraints that are used in a branch-and-cut algorithm to solve asymmetric instances with up to 150 nodes and symmetric instances with up to 100 nodes using the new formulation.", :title "A new formulation for the Hamiltonian p-median problem", :keyword2 8, :authors (5319 2435 46526), :session 228}, 338 {:keyword1 22, :keyword3 0, :abstract "In recent years more and more natural and man-made disasters occurred. Additionally, the amount of people affected by disasters is increasing. Not least because of this it is of great importance to arrange the relief operations efficiently in order to alleviate the suffering of the disaster victims. Immediately after the occurrence of a disaster there is an urgent need for delivery of relief goods to demand points and affected regions, respectively. Due to blocked or damaged roads by disaster debris some demand points may be cut-off in the road network and therefore the delivery of relief goods is hampered. This study investigates the basic problem of simultaneously detecting roads to unblock in order to make demand points accessible and determining specific deliveries of relief goods in order to satisfy the demands up to their individual due dates. A mixed-integer programming model is proposed to solve this problem. Moreover, an exact solution method based on a branch-and-bound approach is developed and a computational study is conducted.", :title "Simultaneous Planning for Disaster Road Clearance and Distribution of Relief Goods: A basic model and an exact solution method", :keyword2 0, :authors (59625 14715 5838), :session 152}, 339 {:keyword1 45, :keyword3 97, :abstract "As proven in recent review articles (Marynissen and Demeulemeester, 2018; Leeftink, et al., 2018), the (centralized) scheduling problem of patients who require multiple (and interrelated) appointments has gained recent attention in the healthcare literature. In this research, we try to extend this literature by studying a real-life diagnostic facility in which patients need to be scheduled on multiple diagnostic resources. The goal of this problem is to sequentially schedule all patients such that a weighted objective function is optimized. This objective function focuses on the in-hospital waiting time of patients, the number of days on which patients need to visit the hospital and provider idle time. Using a discrete-event simulation model, we measure the effect of different scheduling methodologies on the performance of the system. These scheduling methods include heuristics as well as optimal methods.", :title "Multi-appointment scheduling in a diagnostic facility", :keyword2 96, :authors (51992 41246), :session 172}, 340 {:keyword1 54, :keyword3 0, :abstract "We consider a model, called the CompFLP, that describes a decision-making process arising in the competitive location, where two parties open their facilities with the aim to capture customers and optimize own objective functions. The process is assumed to be organized in a Stackelberg game framework, where one of the parties open its facilities first, and the second party makes its decision when knowing the competitor’s one. Each customer follows a binary behavior rule and patronizes a single facility which is the most preferable for him or her. The parties’ objective functions are similar to those used in the classical facility location problem and represent the profit value computed as the income from serving the customers minus fixed cost of open facilities.\r\nThe model is formalized as a pessimistic bilevel program. Based on its relaxation, called a high-point problem, which is a single-level MIP obtained by removing a restriction on the lower-level variables to take their optimal values, we construct a series of strengthened estimating problems (SEP) approximating the initial bilevel one. Each consequent SEP is obtained from the previous one by adding a number of constraints that are shown to be satisfied by some optimal solution of the bilevel program Thus, each SEP provides a valid upper bound for the optimum of the model under consideration. \r\nThe constraints are taken from two reach families, called c-cuts and f-cuts. C-cuts “simulate” a rational behavior of the second party and force the lower-level location variables to take non-zero values for some profitable facilities. F-cuts utilize the idea to decompose the lower-level problem into several independent subproblems and memorize their optimal solutions to inherit them where it is possible.\r\nThe computation process aiming to find an optimal solution of the bilevel problem is organized as a cut generation procedure where c-cuts are generated on-the-fly and are introduced into the model by a callback provided to a MIP solver. F-cuts need a bilevel feasible solution to be computed and supplement the model after the lower bound computation.\r\nIn the numerical experiments with artificially generated data, we evaluate the performance of the scheme and compare it with previously suggested methods. We show that Instances of a relative problem, called Competitive prioritized set covering problem, which was previously solved in an optimistic formulation only, can be tackled by the scheme as well.", :title "Cut generation scheme for the competitive facility location problem", :keyword2 158, :authors (32723 22874), :session 217}, 343 {:keyword1 86, :keyword3 165, :abstract "In the conventional project scheduling, processing time is usually given definitively. When the processing time is fixed, scheduling is performed using PERT or CPM for the purpose of minimizing the make-span. In the case where the processing time varies, a method based on three pieces of data with regard the optimistic processing time, the most likely processing time, and the pessimistic processing time is used.\r\nThe problem to minimize make-span is formulated as combinatorial optimization. Palacio and Larrea (2017) presented a robust optimization model aimed at minimizing the risk of time fluctuations. It is not easy to proceed with the project as planned, as there are uncertain events in reality. If we cannot deal with uncertainty, it may cause major damage and penalty. \r\nZhu, Bird and Yu (2007) formulated the problem of project scheduling with uncertain processing time of job and presented its solution. The project scheduling problem with resource constraint is known a complicated and difficult problem.\r\nIn this paper, the fluctuation of each job is given as a random variable following beta distribution. We consider project scheduling problem including penalties due to fluctuation based on the framework of two stage stochastic programming problem. A penalty is defined in the case where the completion time of the actual job is later or earlier than the determined schedule. In the case where the uncertainty is high, it can be expected that a better objective value can be obtained than the conventional deterministic method.\r\nIn the formulation of this research, the decision variable is defined as the number of people engaged in each job. The processing time of each job can be reduced by adding the number of workers who engage in. As for the make-span, the upper limit is set as constraints. By these reformulation, the model can be extended from the simple resource-constrained project scheduling problem to the cost minimization of project scheduling problem considering time/cost trade off.\r\nIn the solution method, we attempted to reduce the size of the scenario tree representing the probability variation. The number of scenarios can be reduced using moment matching to satisfy statistical properties. Also, the L-shaped method based on the Benders decomposition was applied to solve the problem. This makes it possible to deal with large-scale complicated scheduling problems by reducing the problem.", :title "Solution Algorithm for Time/Cost Trade-off Stochastic Project Scheduling Problem", :keyword2 157, :authors (59647 39349), :session 157}, 345 {:keyword1 96, :keyword3 174, :abstract "The increasing growth rate of Courier Express Parcel (CEP) markets is a major challenge for the logistic industry worldwide. New innovative approaches and solutions are needed. For densely populated areas, so-called delivery robots are a promising solution. They drive autonomously on sidewalks or crosswalks, and have the size of a moving box with a small capacity inside. In the past few years, many startups were founded building these robots and tested them all over the world. We focus on the optimization of parcel delivery with autonomous robots. Assume are given a set of customers, robots and depots. Each robot has a capacity of one and each customer has ordered one parcel. An arrival due window is chosen by the customer in advance. The goal is to create a schedule involving robots and parcels such that the arrival time of each parcel is closest as possible to the chosen due window. One may distinguish the cases in which the assignment between robots and depots is fixed or flexible. If it is flexible, the robot can be reassigned after each delivery. In the case of a fixed assignment this problem can be transformed into a earliness and tardiness scheduling problem with unrelated parallel machines and machine dependent distinct due windows. The processing time of a job can be seen as the transport time from a depot to a customer and back plus some additional time for loading and unloading the robot. This problem is NP-hard since the weighted single machine scheduling problem with earliness and tardiness penalties and a common due date is already NP-hard. However, both problems can be represented by an integer programming formulation and solved to optimality. Solution finding can be improved by Lagrangian relaxation and Column generation. For large instances, even simple local search methods achieve good results.", :title "Delivery robots, a transport innovation for the last mile", :keyword2 157, :authors (59730), :session 152}, 347 {:keyword1 48, :keyword3 59, :abstract "High quality standards in the automotive industry require strict specifications to be propagated across the supply chain, from the carmaker companies down to the providers of raw materials. This challenge is exacerbated in domains where the quality of a product can be subjective, such as in automotive acoustics. In the current work, we direct our attention to a situation encountered in the daily operations of one of the world's leading steering system suppliers, ThyssenKrupp Presta AG, where requirements imposed on the vibroacoustic quality of the steering gear need to be passed down to its subcomponents. Furthermore, only one subcomponent, the ball nut assembly (BNA), is subject to an own vibroacoustical quality test, equivalent to the one of the steering gear.\r\nIn the current production setting, the vibrational signals of the BNA are transformed to the frequency domain and analyzed as order spectra. For each order spectrum curve, acoustic domain experts determine a set of order intervals and corresponding quality thresholds. Between the orders corresponding to the left and right boundaries of each interval, the maximum value of the order spectrum curve must lie between the upper and lower threshold. In case any threshold of any interval is violated, the BNA is marked as being qualitatively not ok and thus destined to be scrapped or reworked.\r\nIn this work we derive optimal order intervals and thresholds that result in a minimal number of incorrectly classified BNA parts. We pursue a multiobjective goal: the first objective function consists of the weighted sum of false positives and false negatives, while the second objective function aims to reduce the total number of employed order intervals. Given a training set consisting of vibroacoustic measurements of steering gear and BNA, we formulate a multiple change point problem for finding optimal intervals and thresholds. Since the first objective function cannot be written as a sum of subfunctions over the distinct order intervals, the optimization problem can not be tackled by classic approaches such as prunned exact linear time, binary segmentation or dynamic programming. We thus propose a stochastic optimization technique based on evolutionary algorithms that incorporates prior information on the correlation structure of BNA and steering gear vibroacoustics. This additional information has been gained in a previous work through neural network based canonical correlation analysis methods. Apart from speeding up computations, it offers the benefit of leading the mutations and crossover of the evolutionary algorithms towards order spectrum areas which are responsible for the correlation of the vibroacoustic behaviour of the BNA and of the assembled steering gear. The proposed approach is able to reduce the number of employed order intervals with respect to the current production setting and also reduce the costs arising from falsely classified BNA parts, ensuring thus a high practical relevance.", :title "Predicting the vibroacoustic quality of steering gears", :keyword2 87, :authors (52375 59732 30955), :session 205}, 348 {:keyword1 133, :keyword3 57, :abstract "The rapid development of Additive Manufacturing (AM) enables a high geometrical freedom for the production of lightweight cellular structures. Through the newly gained possibilities in individualization and complexity in the areas of design and construction, optimization and generation of the initial design becomes even more important.We discuss a mixed-integer linear program (MIP) to generate a three-dimensional construction of cellular structures for a static case of loading. Additionally, based on the optimized structures, an automated construction in a CAD system allowing a numerically simulation of nonlinear material behaviour is presented. The model is planned as a support tool for engineers.", :title "Design and Optimization for Additive Manufacturing of Cellular Structures using Linear Optimization", :keyword2 65, :authors (55751 50791 39554), :session 24}, 350 {:keyword1 8, :keyword3 0, :abstract "We show that the space of all unrooted binary trees (or phylogenies) for a finite set of taxa defines a lattice, which orders phylogenies by their imbalance. By representing phylogenies as path-length sequence collections, we show that the imbalance ordering is closely related to a majorization ordering on real-valued sequences, that correspond to discrete probability density functions. Furthermore, this imbalance ordering is a partial ordering that is consistent with the ordering induced by the entropy determined by the tree structure. On the imbalance lattice, specific functions of the path-length of a phylogeny (including, among others, the usual objective functions for Huffman coding in information theory and for the balanced minimum evolution problem in phylogenetics) may either enjoy combinatorial properties (such as submodularity) that prove useful in optimization or reveal new insights about the NP-hardness of some families of optimization problems in phylogenetics.", :title "Optimizing over lattices of unrooted binary trees", :keyword2 0, :authors (59733 16035 16034), :session 221}, 352 {:keyword1 133, :keyword3 102, :abstract "A decentralized design of pump stations can improve the overall efficiency of water supply systems significantly. However, it is a challenging task to compute the global optimal design for a given objective, if one considers (i) a construction kit of different pumps which can be placed in multiple locations in a network topology, (ii) different piping variants which connect the pumps. In this case, even a small number of different components in the construction kit leads to a high variety of possible system designs.\r\n \r\nIn this contribution, we show an iterative approach to compute promising primal solutions. In a first step, we use a primal heuristic to find candidate solutions for the design of the layout of the pipe network. In a second step, we formulate a MINLP to optimize the positioning and operation of pumps for the candidate network. As objectives, we consider investment costs and energy costs. The approach is shown based on the application example of a real-world high-rise building. ", :title "A heuristic approach for designing decentralized pump systems ", :keyword2 158, :authors (55675 41758), :session 25}, 353 {:keyword1 96, :keyword3 151, :abstract "We consider a model for single-machine scheduling under uncertainty. In this model, we assume that a set of jobs with processing times and deadlines arrive online, and there is no knowledge about the jobs that will arrive in the future. We focus on preemptive single-machine scheduling with the objective to maximize the total number of jobs completed on time and aim for worst-case guarantees. To circumvent known impossibility results, we assume that each job has some slack upon arrival, meaning that the job can be delayed by a certain amount of time relative to its processing time and still finish on time. Regarding the commitment of the scheduler, we distinguish three different cases: \r\ncommitment at the arrival of jobs, commitment at the start of jobs, and non-commited scheduling. If jobs can only be discarded at arrival, we prove that no online algorithm can achieve worst-case performance guarantees. For the remaining two cases, we analyze two variants of a simple combinatorial algorithm. For the setting where jobs admitted by the scheduler must be processed until completion, we derive the first nontrivial performance guarantee. For non-committed scheduling, we improve upon the currently known best upper bound on the worst-case ratio and provide a matching lower bound.", :title "New results on online throughput maximization", :keyword2 8, :authors (59719 52585 14975 52563 11178), :session 220}, 355 {:keyword1 126, :keyword3 23, :abstract "We investigate the value function of an infinite horizon variational problem in the setting of an infinite-dimensional generalized control system. Our primary concern here is to go beyond convexity, smoothness, and finite dimensionality aiming the possible applications to dynamic optimization in economic theory. The purpose of this paper is threefold. \r\n\r\nFirstly, we establish that in Banach spaces with Gateaux differentiable norm Gateaux subdifferentials of any lower semicontinuous extended function are nonempty on a dense subset of its  domain. Furthermore, we provide an upper estimate of the Gateaux subdifferential of the value function in terms of the Clarke subdifferential of the Lipschitz continuous integrand and the Clarke normal cone to the set-valued mapping describing dynamics. As a result, we obtain the strict differentiability of the value function under the Frechet differentiability of the integrand, which removes completely the convexity assumptions of the earlier works. Since the optimal economic growth models are identified with a specific form of the general equilibrium model with single consumer and single firm, we can deal with a rich class of commodity spaces for capital stock, which appears as a Sobolev space. \r\n\r\nSecondly, we derive a necessary condition for optimality in the form of an adjoint inclusion that grasps a connection between the Euler--Lagrange condition and the maximum principle. To deal with the adjoint variable in dual spaces, we introduce the Gelfand integrals of the Gateaux and Clarke subdifferential mappings, which is a new feature that does not arise in the context of finite-dimensional control systems. We also consider the relaxed variational problem, which is a suitable convexification of the original variational problem, and derive the necessary condition for optimality that narrows the class of candidates for optimality. Furthermore, we obtain the sufficient conditions for optimality under the convexity assumptions, which is an infinite-dimensional analogue of the \"support price theorem\". \r\n\r\nThirdly, as a byproduct of the necessary condition, we derive the transversality condition at infinity without assuming convexity and smoothness, which clarifies the role of the integrability condition on the Lipschitz moduli. We then examine the well-known failure of the transversality condition at infinity to reveal which hypothesis of our paper is violated in their counterexamples.", :title "Value Functions and Optimality Conditions for Nonconvex Variational Problems with an Infinite Horizon in Banach Spaces", :keyword2 66, :authors (9964 59737), :session 182}, 357 {:keyword1 39, :keyword3 13, :abstract "Herbert A. Simon states that modern managers wish to be satisfied by reaching their goals subject to the optimization of a single objective. In such situations, The new version of Multi-Choice Goal Programming (New-MCGP) model presented by Jadidi in 2015 is considered as a novel technique in Operational research and management science to help Modern Managers (MM) to solve multi-criteria management problems by using linear utility functions (LUFs). In other words, the new technique of MCGP with LUFs reflects a good approximation of these decisions making situations for modelling the fuzziness and the managers preferences. However, in practice, there are many situations where Modern Decision Makers (MDMs)/Modern Chief Executive Officer (MCEO) could not presented their preferred utility functions as linear in form. In this paper, an efficient methodology is presented using the technique of Quasi-concave Utility functions (Qu-UFs) in which the concept of Flexible GP (F-GP) is introduced for modelling the flexibility of (MDMs)/(MCEO)’s preferences instead of their classical crisp preferences (LUFs) to solve this type of problems. The formulated problem is treated as a nonlinear programming problem involving mixed flexible and crisp deviations. The proposed formulation provides (MDMs) with more flexibility of control over their preferences. Finally, an illustrative example is presented to demonstrate the effectiveness of our proposed model.", :title "Flexible Multi-choice Goal Programming ", :keyword2 161, :authors (52640 45477 59739), :session 176}, 359 {:keyword1 162, :keyword3 153, :abstract "Nonlinear unconstrained optimization in binary variables is a general class of problems encompassing a variety of applications in operations research, computer science and engineering, among other fields. A common approach to solve nonlinear binary optimization problems consists in defining first a linear or a quadratic reformulation of the objective function by introducing artificial variables and then using linear or quadratic integer programming techniques to optimize the reformulation. Not all reformulations are equally good; some desirable properties are: using a small number of auxiliary variables, having a small number of positive quadratic terms (as an empirical measure of submodularity) or capturing the underlying structure of the original nonlinear problem. \r\nWe consider several linear and quadratic reformulation techniques (also called linearizations and quadratizations, respectively) and aim at comparing their computational performance when using a commercial solver to optimize the reformulated problems. We assume that the nonlinear function to optimize is given by its unique multilinear expression on n binary variables, which consists of a sum of monomials with a positive coefficient (positive monomials) and monomials with a negative coefficient (negative monomials). \r\nConcerning linear reformulations, we consider the standard linearization, and a tighter version of the standard linearization obtained by adding class of valid inequalities that model interactions of pairs of monomials with a non-empty intersection. \r\nAs for quadratic reformulations we consider methods of two different types. The first class of methods is based on the idea that a quadratic reformulation of a multilinear polynomial can be defined by means of a quadratization for each monomial considered as a separate function. Negative monomials can be reformulated as a submodular quadratic function using a single variable. The case of positive monomials is more complex. In our experiments, we compare a previously known quadratization using roughly n/2 variables, and two quadratizations that we defined recently using approximately n/4 and O(log(n)) variables, which is the best lower bound. The second type of quadratizations is based on the idea of substituting subsets of variables that are common to several monomials by a same auxiliary variable. Several related ideas have been explored in the recent literature. We consider here three heuristic algorithms aimed at maximizing the number of common intersections between pairs of monomials that are accounted for. \r\nWe present the results of an extensive set of computational experiments on different classes of instances, containing random polynomials of low and high degree and instances inspired from the image restoration problem in computer vision. Preliminary results show that linear and quadratic reformulations preserving the structure of the original polynomial problem perform very well for some classes of polynomials.", :title "A computational comparison of linear and quadratic reformulations of nonlinear binary optimization problems", :keyword2 157, :authors (47336 2429 1344), :session 217}, 360 {:keyword1 19, :keyword3 0, :abstract "The aim of the presented research is to provide a thorough survey of classic and state-of-the-art approaches to weight specification, and systematize them into a referential model. The defined model classifies methods into three groups corresponding to direct weight derivation, indirect weight derivation, and readjustment of existing weights. The direct weight specification is further structured into ordinal and ratio based approaches, utility and bargaining related approaches, fuzzy averaging operators, dominance and optimality methods, as well as interactive procedures for transformation of qualitative subjective concepts into numerical values. The group of indirect weight derivation techniques includes regression on the set of referential alternatives, regression on correlations between preferential parameters, and structural modelling.\r\nBy utilizing a common framework for the evaluation of decision-making methods and systems, the characteristics of key types of weight specification methods are determined. Their advantages and weaknesses are exposed. The framework allows decision-makers to assess the suitability of different weight specification methods for various real life problem solving situations, and to select the most appropriate ones for application. Criteria of the proposed framework include the complexity of analysis, credibility of analysis, problem abstraction, and methodological foundations.\r\nSeveral use cases are described in the context of preference elicitation and aggregation procedures. In particular, the efficiency of relative versus absolute assessments in weight derivation is empirically studied. Methods that exhibit various levels of relativeness are evaluated with a simulation based model. Similarly, ratio based approaches to generate consistent or inconsistent pairwise comparison matrices, respectively, are treated with regard to the validity and reliability of derived weight vectors. Different transformation functions for the automatic construction of matrices are experimentally evaluated. They are based on either the linear or multiplicative scales, and exhibit various levels of consistency. It is shown that slightly inconsistent matrices can produce more accurate weights than consistent ones.", :title "A referential model for systematization and applicability assessment of weight specification methods in multi-criteria decision-making", :keyword2 0, :authors (29689), :session 85}, 362 {:keyword1 42, :keyword3 0, :abstract "A d-dimensional body-bar framework is a collection of d-dimensional rigid bodies connected by rigid bars. The framework is called rigid if every motion provides a framework isometric to the original one. A body-bar framework is expressed as a pair (G, p), consisting of a multigraph G = (V, E) and a mapping p from E to the d-dimensional real coordinate space (d-space, for short). Namely, a vertex v in V corresponds to a body and an edge uv in E corresponds to a bar which joins the two bodies corresponding to u and v. Then, G is said to be realized as a body-bar framework (G, p) in d-space, and is called a body-bar graph. It is known that the infinitesimal rigidity of a generic body-bar framework is determined only by its underlying graph G. So, a graph G is called rigid if G can be realized as a infinitesimally rigid body-bar framework in d-space, otherwise G is called flexible. G is called minimally rigid if G is rigid and removing any edge e in E makes G flexible.\r\n\r\nIn the literature, Tay [Structural Topology, 1991] provided a characterization of d-dimensional minimally rigid body-bar graphs by Henneberg's method. In more detail, Tay proved that a body-bar graph G is minimally rigid in d-space if and only if G is generated from a single vertex by a sequence of k-pinching operations with 0 =< k =< D (= d+1 choose 2), where a k-pinching operation is an operation removing k edges and adding a new vertex u which is joined by 2k edges to the endpoints of removed edges, and by another D–k edges to any vertices other than u itself.\r\n\r\nIn this paper, we consider characterizing minimally rigid body-bar graphs without proper rigid subgraphs in d-space. Such a characterization has application to generating a special class of body-bar Assur graphs introduced by Shai et al. [Discrete Applied Mathematics, 2013]. We prove that a body-bar graph G is minimally rigid and has no proper rigid subgraph in d-space if and only if G is generated from a graph with two vertices and D edges by a sequence of k-pinching operations with 1 =< k =< D-1, when d = 2. Note that a set of our operations is included in one by Tay. We also conjecture that our result can be extended to the case with d > 2.", :title "Characterizing minimally rigid body-bar graphs without proper rigid subgraphs", :keyword2 0, :authors (45244 59760 3297 59740 59781), :session 229}, 367 {:keyword1 151, :keyword3 153, :abstract "This talk is motivated by the procurement of links between different sites in the construction of a high-speed communication network. In the procurement environment, the costs of establishing a link is the private information of its supplier and each supplier can state a bid to the network operator, indicating the minimal payment for which she would establish the link. Each supplier wants to maximize their payoff, i.e., their bids minus their private costs for setting up the connection. The goal of the network operator is to connect a specific subset of sites (terminals) by purchasing links in a way that the total cost of purchased links is minimized. If the cost of all links is known, this is equivalent to the well-known Steiner Minimum Tree (SMT) problem. The SMT problem on graphs is one of the most well-known NP-complete problems, and central in various types of network design problems.\r\n  We analyze the corresponding mechanism design problem in which the trade between the network operator and suppliers is organized as an auction. In such an auction, the auctioneer wants to set incentives for bidders to reveal their costs truthfully. Blumrosen and Nisan showed that for single-minded bidders an algorithm with monotonic allocation allows for a strategyproof mechanism when using a critical payment scheme. This result serves us as a basis for finding strategyproof mechanisms based on approximation algorithms for the SMT problem.\r\n As collusion is an important issue in procurement, we also aim for group-strategyproofness. This desirable property is very rare in auction design, but Milgrom and Segal in 2014 provided a remarkable positive result for the class of deferred-acceptance auctions which led to very high levels of efficiency on average for the recent incentive auction by the US Federal Communications Commission.\r\n We show results in regard to strategyproofness and computational efficiency for deterministic approximation mechanisms and deferred-acceptance auctions.", :title "Network Procurement With Strategic Bidders", :keyword2 6, :authors (59741 35382 55333), :session 67}, 369 {:keyword1 174, :keyword3 57, :abstract "We present a Granular Skewed Variable Neighborhood Tabu Search (GSVNTS) for the Roaming Salesman Problem (RSP). RSP is a multi-period and selective version of the traveling salesman problem involving a set of cities with time-dependent rewards. It is defined over a fixed planning horizon referred to as the campaign period. Each city can be visited on any day for reward collection while a subset of cities can be visited multiple times, though with diminishing rewards after the first visit. The goal is to determine an optimal campaign schedule consisting of either open or closed daily tours that maximize the total net benefit while respecting the maximum tour duration and the necessity to return to the campaign base frequently. Here the term ‘net benefit’ implies the total rewards collected minus the total traveling costs incurred. RSP arises in several applications including touristic trip planning, planning of client visits by company representatives, and election logistics. A differentiating feature of the RSP is that there exist no fixed depots and daily tours do not have to start and end at the same city. We formulate RSP as a MILP in which we capture as many real-world aspects as possible. \r\nWe also present a hybrid metaheuristic algorithm which can be classified as a Variable Neighborhood Search (VNS) with Tabu Search (TS) conditions. The initial feasible solution is constructed via a novel matheuristic approach which decomposes the original problem into as many subproblems as the number of days. Next, this initial solution is improved using the proposed local search procedure. The concept of granularity is incorporated into the developed algorithm to prevent non-promising moves and thereby reduce the computing time of the neighborhood search. On the other hand, the concept of skewedness modifies the basic VNS so as to explore deeper neighborhoods of the current solution by accepting nonimproving moves which lead to far enough neighboring solutions. The neighborhood structures in our GSVNTS implementation are 1-Add, 1-Drop, 1-0 Relocate, 2-0 Relocate, 1-1 Swap, 2-2 Swap, 1-1-1 Swap (Triple Rotation) and 1-1-1-1 Swap (Quadruple Rotation). The first three neighborhoods reflect the selective nature of the problem; thus they are called City Selection Neighborhoods. The remaining neighborhoods are called Intra-Route Neighborhoods. At each iteration of the local search procedure, several feasibility checks are performed to ensure the validity of the solution. Therefore, the so-called chain feasibility of the solution is guaranteed at each iteration, which means the starting node of tomorrow’s tour must match the terminal node of today’s tour. \r\nWe consider a set of 95 cities and towns in Turkey and a campaign period of 40 days as our largest problem instance. Computational results using actual distance and travel time data show that the developed algorithm can find near-optimal solutions in a reasonable CPU time.\r\n", :title "A Granular Skewed Variable Neighborhood Tabu Search for the Roaming Salesman Problem", :keyword2 59, :authors (52600 3397), :session 151}, 370 {:keyword1 152, :keyword3 0, :abstract "Topics of renewal theory like the optimal adaptive replacement in a renewal process or the prediction of failure are of main interest in business administration and especially in manufacturing management systems. So consider the estimation of the rate of replacement based on a renewal process given by a sequence of random variables representing lifetimes of items being renewed. The variables are assumed to be positive having the same mean µ; they may be dependent and the common underlying distribution is unknown. As maximum likelihood methods are not applicable, the method of moments based upon substituting the nth sample mean for µ is implemented. But this method is unfortunately not suitable for the derivation of corresponding moments of 1/µ. Based on the limiting moment approach, we would then assume the well-known delta method for independent random variables, which involves estimation of moments. But it cannot be applied either because the rate 1/µ and its derivatives are unbounded. Therefore, we develop a nonparametric estimation of the replacement rate based on a delta method with weakened requirements on the global growth of the considered functions. Our method can also be extended to a wide range of reciprocal functions. It allows for dependent observations and unbounded functions. We present our theoretical results and illustrate the effectiveness of the proposed approach in simulations. Moreover, an outlook to the application of the presented delta method with weakened requirements to bivariate functions is given.", :title "Application of a delta method with weakened requirement to univariate functions of renewal theory", :keyword2 99, :authors (48339), :session 241}, 371 {:keyword1 18, :keyword3 8, :abstract "Electoral districts are of fundamental importance in several democratic parliamentary elections. Voters of each district elect a number of representatives into parliament. The districts form a partition of the electoral territory, thus each part of the territory and its population is represented in parliament.\r\nThe design, and in particular the re-design of electoral districts is a regular task in preparation for elections. Each district must have a certain level of population balance, so population shifts often trigger this re-design, enforced and restricted by laws and rules. The districting plan is frequently debated by politics and public. \r\nThe (re-)design of electoral districts can be formulated as a (multi-criteria) optimization problem -- the political districting problem (PDP). Depending on the application, different criteria are considered in PDP, e. g., continuity of the districting plan, conformity with administrative boundaries. Basic constraints of PDP are contiguity of each electoral district and range constraints for district's population. PDP is NP-hard in general.\r\nAfter mathematizing legal requirements and the quantification of their observance, we developed optimization-based methods for PDP using mixed-integer programming. Our solution methods are implemented in a ready-to-use decision support system based on a geographic information system. On the one hand, the presented software tool provides descriptive analytics together with the feature to modify electoral districts by hand. On the other hand, optimal decision alternatives are delivered by means of mathematical optimization and can be considered by the user of the geovisual decision support system. We report on what officials have to say about our software tool and how we actively participate in ongoing discussions regarding present districting issues. ", :title "Decision Support for Political Districting", :keyword2 73, :authors (45055 14969), :session 84}, 376 {:keyword1 158, :keyword3 0, :abstract "State-of-the-art solvers for mixed integer programs (MIP) govern a variety of algorithmic components. Ideally, the solver adaptively learns to concentrate its computational budget on those components that perform well on a particular problem, especially if they are time consuming.\r\nWe focus on three such algorithms, namely the classes of large neighborhood search and diving heuristics as well as Simplex pricing strategies.\r\nFor each class we propose a selection strategy that is updated based on the observed runtime behavior, aiming to ultimately select only the best algorithms for a given instance.\r\nWe review several common strategies for such a selection scenario under uncertainty, also known as Multi Armed Bandit Problem.\r\nIn order to apply those bandit strategies, we carefully design reward functions to rank and compare each individual heuristic or pricing algorithm within its respective class.\r\nFinally, we discuss the computational benefits of using the proposed adaptive selection within the \\scip Optimization Suite on publicly available MIP instances.\r\n", :title "Adaptive Algorithmic Behavior for Solving Mixed Integer Programs Using Bandit Algorithms", :keyword2 0, :authors (29594 32758 50134), :session 50}, 377 {:keyword1 96, :keyword3 157, :abstract "Many services can be interpreted as a series of discrete events scheduled over a certain period with time gaps in between. A part-time executive education program for example includes different courses taking place on extended weekends with breaks of several weeks between the courses. Following this logic, service design involves making decisions with regard to what events to include in the service offering and when to schedule them – taking into account participants’ multi-attribute preferences for e.g. contents and time. While each event has its own instant utility that a participant experiences during the respective event, there are also aggregate measures such as predicted (ex ante) and remembered (ex post) utility, which in turn determine customer choice, loyalty, repurchase, word-of-mouth, etc. Empirical research has shown that the aggregate function does not only depend on which events are included, but that the order of events plays an important role in a participant’s assessment of the service. \r\n\r\nWhile other studies focus on either remembered or predicted utility, we present an integrated framework hypothesizing about the relationship between the different forms of utility. Based on this framework, we develop an optimization model to determine a portfolio of scheduled events that maximizes the seller’s expectation of the participants’ remembered utility, while taking into account that potential participants make their purchase decision based on their predicted utility.  \r\n\r\nWe thereby make a contribution to the problem of designing service offerings that include experiential attributes with sequence effects. The problem has received growing attention in the operations literature recently. Our framework allows for multiple attributes, shows the interdependencies of different utility forms and also discusses the role of word-of-mouth for these constructs. Our approach can be applied to a variety of service industries like sports, entertainment or education. A case study of an Executive MBA program based on empirical data from a self-conducted conjoint study demonstrates real-world applicability of the approach.\r\n", :title "Bundling and Scheduling Service Encounters When Sequence Matters", :keyword2 149, :authors (49073 52290), :session 156}, 378 {:keyword1 54, :keyword3 158, :abstract "We address the problem of designing a supply chain network with four layers comprising suppliers, plants, warehouses and customer zones. Strategic decisions include the location of new plants and warehouses, and the choice of their capacity levels from a finite set of available options. Tactical decisions involve the selection of suppliers, the procurement of raw materials, and planning the production and distribution of end products to meet customer demands. Different transportation modes are available for raw material and end product distribution. Each mode is associated with a minimum shipment quantity, a maximum transportation capacity and a variable cost. A further distinctive feature of our problem is that each customer zone must be served by a single facility (either a plant or a warehouse).  Many companies strongly prefer single-sourcing deliveries as they make the management of the supply chain considerably simpler. Direct shipments from a plant to a customer zone are only permitted if at least a given quantity is distributed to the customer zone. Such a delivery scheme reduces transportation costs for large quantities. In addition, each raw material must be purchased from a single supplier by an operating plant. However, different raw materials may be procured from multiple suppliers by the same plant. This feature overcomes the disadvantages of single-supplier dependency. Furthermore, a strategic choice between in-house manufacturing, product outsourcing and a combination of both is also to be made. Outsourced products are consolidated at warehouses. Although product outsourcing incurs higher costs than in-house manufacturing, this option may be attractive when the cost of establishing a new facility to process given end items is higher than the cost of purchasing the products from an external source. We propose a mixed-integer linear programming (MILP) formulation to identify the network configuration with minimum total cost. We also develop a second MILP formulation for the special situation in which all products delivered to customers must be in-house manufactured but customer demands do not have to be completely satisfied. In this case, a minimum customer service level is guaranteed. Valid additional inequalities are developed to enhance both formulations. A computational study is performed to assess the impact of various problem characteristics on the ability of state-of-the-art optimization software to solve problem instances within a reasonable time limit. Using a set of randomly generated instances, valuable insights are provided on the trade-offs achieved by considering product outsourcing against a pure in-house manufacturing strategy, and the extent to which it may not be economically attractive to meet all demand requirements. ", :title "Multi-echelon supply chain network design with transportation mode selection,  product outsourcing and single-assignment requirements", :keyword2 65, :authors (1256 17147 19101), :session 225}, 379 {:keyword1 8, :keyword3 174, :abstract "One possibility of storing items is to pile them up in stacks. In that case, an item can only be retrieved if it is the topmost item of a stack. Consequently, an item can be blocked by other items stored above it. If an item to be retrieved is blocked, repositioning moves are necessary. Since these repositioning moves can be very time consuming, the objective is to minimize the total number of repositioning moves.\r\nIn this talk, an introduction to the blocks relocation problem is given. After a short overview of existing literature an exact solution method is presented.\r\n", :title "Sorting Last-In-First-Out Stacks", :keyword2 157, :authors (59745 14715), :session 221}, 385 {:keyword1 6, :keyword3 67, :abstract "In recent years, there has been a rapidly increasing number of countries adopting auctions for the allocation of permissions and financial support to renewable energy projects. The shift toward auction mechanisms has introduced competitive price discovery of financial support levels for new projects. In common auction mechanisms, project developers compete by specifying their required sales price per unit of electricity (in €/MWh) as well as a capacity to be installed (in MW) and only the most cost-competitive projects with the lowest required financial support are granted until the auction volume (in MW) is reached. An optimal bidding strategy for these mechanisms always depends on the country-specific auction design. Such strategies commonly propose to obscure the true cost of a project by adding certain premiums on top of the marginal cost in order to maximize the expected profit. \r\n\r\nConsequently, the starting point of finding an optimal bidding strategy must always be a reliable determination of the marginal cost, which is the minimum sales price per unit of electricity required to permit an economically viable project construction and operation at an acceptable level of risk. In this study, we thus focus on enhancing the strategic bidding by integrating a holistic financial modelling approach for a risk-adequate quantification of the marginal cost into a strategic bidding optimization model. The latter typically consider traditional discounted cash-flow models without incorporating project-specific risks and uncertainties and, thus, result in a biased and unprecise bidding strategy. We enhance current estimation approaches for the marginal cost by providing a derivative of the adjusted present value with respect to the sales price per unit of electricity. The adjusted present value is based on a state-of-the-art cash-flow calculation combined with a Monte Carlo simulation accounting for project risks. \r\n\r\nIn order to permit a proof-of-concept and in-depth understanding of our model enhancement, we conducted a simulation study of a wind farm in Lower Saxony, Germany with a prototypical implementation in Python. In particular, the simulation study focuses on the comparison of current estimation approaches and our enhanced approach incorporating the manifold risks and uncertainties into the estimation of cash-flows that determine the optimal bidding strategy to a large extend. The results show significant differences, with quantifiable advantages of our risk-considering adjusted present value method. As our modelling approach permits the direct quantitative incorporation of risks and uncertainties within strategic auction bids, we contribute to an enhanced strategic bidding optimization and comprehensive methodological support for project developers in competitive renewable energy auctions.", :title "Enhancing Strategic Bidding Optimization for Renewable Energy Auctions: A Risk-Adequate Marginal Cost Model", :keyword2 35, :authors (59664 52352 33554 19100), :session 196}, 386 {:keyword1 22, :keyword3 93, :abstract "In the time after a disaster strikes, both the government and companies try to provide goods to the population. However, the general objectives behind their actions differ significantly. While the state’s goal is to minimize the damage to the population at any costs, companies try to maximize the profit or – if possible to quantify it – a combination of profit and reputational improvements. Moreover, both actors are active during different periods. Before the disaster takes place, companies are the sole provider of goods while the state is monitoring the population’s supply passively. When a specific number of people is critically undersupplied, the state takes over as part of the government-mandated crisis management process.\r\nDue to these asymmetries in objectives and activity, it is necessary to define strategies that ensure efficient interactions between the state and the companies. However, previous disasters such as Hurricane Katrina proved that the already existing mechanism are rather inefficient. As a first step to identify more efficient collaboration strategies, a comparative simulation model was developed that allows for explicit consideration of different cooperation scenarios.\r\nThe Baseline-Scenario represents the case described above, where the state becomes the sole provider of goods in case a company is not able to supply the population properly. Here, the firm has to step back and wait until the state’s intervention is over (e.g. because of supply chain failure or legislative order). The state must purchase goods and warehouse space at high costs, while the firm can only act by adjusting order sizes and rerouting goods to save costs.\r\nIn addition to the Baseline-Scenario, the analysis of three different cooperation options follows. First, the State-Inform-Scenario includes the state as the sole provider of goods after the disaster. In contrast to the Baseline-Scenario, the company receives all necessary information from the state as early as possible. Second, the State-Dominance-Scenario represents a passive integration of the company into the state’s humanitarian supply chain. The state takes over a large part of the company’s logistical resources but pays a compensation. The model considers two compensation-schemes: a) the state covers the company’s opportunity cost, while in b) the state just compensates for the additional operating costs. Third, the Firm-Dominance-Scenario comprises that the firm stays in charge all the time while the state supports the delivery of goods in critical times.\r\nA comparison of the outcomes of the scenarios to the Baseline-Scenario in terms of constitution of the population and revenue for the firm concludes the study. The model is able to illustrate the interplay between commercial and humanitarian supply chain and thus contributes to higher crisis management performance. However, the chosen setup comprises many operational and legal challenges that need further investigation.\r\n", :title "Cooperation Between Public and Private Actors in the Delivery of Goods After Disasters", :keyword2 101, :authors (59744 52601 2675), :session 226}, 387 {:keyword1 7, :keyword3 158, :abstract "Faced with new challenges, the chemical industry strives for more diversified product portfolios. Product life cycles are becoming shorter and lead to an increased uncertainty in product demands with regard to volume, location and type. To efficiently cope with highly individual demands, modular production concepts are considered. Experiments with prototype plants have shown economic and technical opportunities for the individualized production of specialty chemicals. Modular plants can be installed in standard transportation containers and may operate at decentralized facilities in direct proximity to customers or suppliers. New modular plants can be added and existing plants can be relocated in the short-term to adapt to changing demand conditions. For an efficient utilization of the increased flexibility provided by modular plants, tactical planning must incorporate the new flexibility options.\r\nWe study the case of modular production concepts for a chemical company in the market of specialized polymers. The products vary, among other things, in colour, softening and their ability to resist ultraviolet light. The production process scales well to small-scale production with transportation containers. Production network planning has to determine the number and type of modular plants to be placed at production facilities each period, as well as the production and distribution of products to customers. During the planning horizon, adjustments to the network have to be made by relocating modular plants or reducing and expanding the number of plants at the decentralized facilities. We develop new mixed-integer programming formulations for the tactical planning of the modular plant specialty polymer production network. By varying key parameters, we discuss the influence of future developments in modular technology on the economic benefits of modular production concepts for specialty chemical production.", :title "Tactical Planning of Modular Production Networks in the Chemical Industry: A Case Study of Specialty Polymers", :keyword2 54, :authors (52508 59707 55849 10057), :session 190}, 391 {:keyword1 101, :keyword3 97, :abstract "Besides tasks related to the Newsvendor Problem, the Beer Distribution Game has widely been used to derive insights in Behavioural Operations Management. It is used as an experimental paradigm on which many studies are based. Mostly, such studies employing the Beer Distribution Game investigate the sub-optimal ordering behaviour of participants, leading to the well-known Bullwhip phenomenon. A variety of behavioural reasons for the occurrence of the phenomenon has been identified, including underweighting of the supply line, hoarding tendencies, and insufficient forecasting. Together with structural characteristics of the game, in particular material and information delays or opaqueness of demand, these behavioural reasons are shown to lead to inventory fluctuations that grow in amplitude upstream the supply line.\r\n\r\nRecently, some criticisms have been raised regarding the validity and usefulness of the Beer Distribution Game as an experimental paradigm. These included questions about the prevalence of the Bullwhip phenomenon in more complex supply networks, the relevance of the phenomenon in real industry given the ubiquity of advanced supply chain information systems, the weak theoretical foundation of the phenomenon, the emphasis on time pressure during game runs, the concentration on cost as performance indicators instead of profits, the usage of a quite specific demand pattern, and the missing communication possibilities during the game. Despite these issues, the Beer Distribution Game has some beneficial features that make it an interesting experimental tool: it has been used in a wide range of contexts and over an extended period of time, data for comparisons is available, its face validity is high, the rules of the game are simple, it adds mild randomness as well as strong dynamic complexity to the decision-making task, and it is a task that requires collaboration while also maintaining a certain degree of competitiveness.\r\n\r\nThe purpose of the presentation is to discuss the pros and cons of using the Beer Distribution Game in Behavioural Operations Management: common misunderstandings of game structure and rules are outlined; the ecological validity of the game is scrutinized; characteristics of the game are compared to alternatives. The presentation proposes a mixture of empirical and simulation-based investigation as proper methods to use the Beer Distribution Game in Behavioural Operations Management.\r\n", :title "The usefulness of the Beer Distribution Game as an experimental paradigm in Behavioural Operations", :keyword2 103, :authors (58916), :session 42}, 392 {:keyword1 97, :keyword3 126, :abstract "One of the main challenges for decision makers lies in optimizing an operating system’s overall performance respectively its resource utilization. This task is particularly challenging when it is about optimizing a complex adaptive system. These kinds of systems are composed of interacting, thoughtful entities and exhibit emergent behavior through learning and adaption. Complex adaptive systems are widespread phenomena in the OR context. Supply networks, workforce systems, and traffic control systems – just to name a few – are some examples with subject of interest to the OR community.   \r\n\r\nIn order to get control of complex adaptive systems and to optimize their behavioral patterns we introduce the concept of an OR control tower. The OR control tower resembles the control towers established at airports in order to control starts, landings, and air traffic by sending individual instructions to airplanes. In contrast to these towers, our OR control tower concept draws on the strengths of self adapting systems. Therefore, our control tower does not explicitly give commands to each entity of the network in form of full control. Instead, the OR control tower optimizes the system by adjusting policies, sending certain message to single entities, or reconfiguring the underlying structure. Thereby, the system’s behavior can be forced into an optimal direction without loosing the inherent capabilities of adaption and learning.\r\n\r\nOur OR control tower extends the control tower concepts that are beginning to emerge in supply chain management and logistics. In addition to a usually implemented observer component, which is limited to deliver information about the actual operating system’s state, the OR control tower includes an autonomous decision component. The latter can be equipped with an optimization algorithm. In a first step, we intend to take use of the OR control tower concept in a special simulation approach: A complex adaptive system is modeled with an agent-based approach. \r\n\r\nThe OR control tower extends the model population by a top-level decision maker. It sends policies information to the system’s entities and reconfigures the system. Hence, emergent behavior of the population can be transformed into optimal performance. ", :title "OR Control Towers: A Concept for Optimizing the Performance of Complex Adaptive Operating Systems", :keyword2 127, :authors (33475 4796), :session 241}, 393 {:keyword1 158, :keyword3 162, :abstract "Disjunctive sets arise in a variety of optimization models and much research has been devoted to obtain strong relaxations for them. We argue that in certain cases the branching possibilities (i.e. binary variables) of the usual formulations are unsuitable to obtain strong bounds early in the search process as they do not capture the overall shape of the entire disjunctive set. As a remedy, this paper proposes to exploit the shape of the disjunctive set via a hierarchy of approximate convex decompositions (ACDs). We introduce a method to compute such a hierarchy that yields tighter relaxations on each level. The main ingredient is a sweep-plane algorithm to analyze the geometric structure of the non-convex body and to find cuts which separate the disjunction into two parts that are closer to their respective convex hulls. We show how to use an ACD hierarchy to extend the optimization model to obtain improved branching behavior for both polyhedral and nonlinear disjunctive sets arising in gas network optimization.\r\n", :title "Improving branching for disjunctive models via approximate convex decompositions", :keyword2 41, :authors (14736 50802 59755), :session 206}, 394 {:keyword1 175, :keyword3 6, :abstract "Due to the increasing pressure of pricing on the transportation market, small- and medium-sized freight forwarders have to develop solutions to keep their competitive ability. In order to stay in the market, a possible and clever strategy is to affiliate in coalitions to collaborate in transportation planning. In such coalitions, the participating freight forwarders exchange uncomely transportation requests to reduce in the long term the total fulfillment costs. In order so organize the exchange process, a central procedure or a decentral collaboration framework (DCF) can be used. In a central framework, the overall information of all requests must be known, and a central entity optimizes the transportation plans over all participants of the coalition. Since the request information is a sensitive property for the acquiring freight forwarder, the common approach for the request exchange is a DCF in which each participant optimizes its transportation plan itself and decides which request shall be exchanged.\r\n\r\nIn this contribution, we consider less-than-truckload freight forwarders for the transportation planning that may have different vehicle capacities due to the considered company sizes. The capacitated vehicles must be routed to satisfy a set of transportation requests between origins and destinations. Each route starts and ends at an assigned depot and ensures pairing and precedence constraints for requests. Additionally, time windows respect the time at which pickup and delivery locations must be visited. Such a problem can be modelled as a Pick Up and Delivery Problem with Time Windows and Heterogeneous Vehicles (PDPTWHV). We present a DCF in which the transportation planning is done heuristically, whereas the winner determination for the combinatorial Vickrey auction will be solved exactly. To analyze our results, we use well-known PDPTW datasets, which we extend by the data of heterogeneous fleet sizes. For evaluation, we compare the solution of the DCF with the individually planned transportation plan as an upper bound and the central collaborative transportation plan, which is modelled as a Multi Depot PDPTWHV, as a lower bound.", :title "A Heuristic Approach for Collaborative Pick Up and Delivery Problems with Time Windows and Heterogeneous Vehicles", :keyword2 95, :authors (55197 9524), :session 153}, 395 {:keyword1 101, :keyword3 0, :abstract "We discuss how the integration of recycling material into the sourcing strategy impacts a manufacturer's economic and environmental performance. We therefore model a sustainable sourcing strategy of a manufacturer operating in a dual sourcing environment with one proactive supplier (a contract supplier) delivering recycled material with uncertain yield (due to issues in the recycling process the delivered quantity of the recycler to the manufacturer does not necessarily equal the reservation quantity) and a second reactive supplier delivering virgin material at an uncertain price reflecting the price volatility at the spot market. We consider a quantity reservation contract with an uncertain exercise price and develop a single-period inventory model. We take uncertainties of demand, prices and recycling quantities as well as potential dependencies between them into account, in particular the dependencies between prices for virgin and recycled materials and prices and demand. The manufacturer’s decision on capacity reservation has to reflect the uncertainties associated with the sourcing process as well as potential dependencies. The goal is to get insights into such a sustainable sourcing strategy.\r\n\r\nWe provide results on the optimal policy structure and obtain a closed form solution as a bound of the optimal procurement quantity. It gives us first insights on the effect of different economic parameters on the ordering decision. In an extensive numerical analysis we then study the impact of correlation on our results in order to derive managerial implications. We show that considering correlation when using such a sourcing strategy is especially important in environments with high demand uncertainty, high virgin material prices and yield uncertainty. Moreover, implementing a sustainable sourcing strategy contributes to the concept of circular economy as the input of virgin material can be (partly) replaced by recycling material. We show that sustainable sourcing with recycling contributes to an increase in the sustainability of supply chains.\r\n", :title "A Newsvendor Framework for Sustainable Sourcing including Capacity Reservation for Recycled Materials", :keyword2 92, :authors (37248 46997 2391), :session 226}, 396 {:keyword1 174, :keyword3 8, :abstract "In the aftermath of disasters, some roads may become impassible. Clouds and trees may obscure the view of the satellites, so that the state of the roads remains unknown for prolonged time. In this situation, drones may assist trucks in delivering medicine, food, and further necessity supplies to the population in the impacted area. For instance, a drone may investigate the passability of some important roads and take over some deliveries.\r\n\r\nIn this talk, we discuss delivery strategies for a truck and a drone with respect to the average makespan. We present some worst-case analysis of several intuitive algorithms, propose customized heuristic methods and illustrate their performance in elaborate simulation experiments.", :title "Routing a truck and a drone in disaster relief", :keyword2 173, :authors (35097 9412 59756), :session 152}, 397 {:keyword1 19, :keyword3 0, :abstract "The solution quality of an innovation tournament highly relies on the effort contestants expend in generating the solutions. It is therefore of tournament organizer's interest to implement a mechanism that helps induce the greatest effort exertion. Scholars in economics and innovation have devoted to find the effective mechanism. While extensive studies have focused on the effect of award structure, an emerging interest has shed light on the performance feedback as an incentive scheme for motivating the greatest effort exertion.\r\n  The studies of performance feedback are mostly theoretical work based on a two-period model. For instance, Ederer (2010) found that the effect of feedback mechanism is contingent on the form of effort cost functions and whether agent's ability enters the production function additively or multiplicatively; Mihm and Schlapp (2016) suggested that the optimal feedback policy in the innovation contests relies on the contest objective and the performance uncertainty. Even though the studies with a two-period model have generated meaningful insights, practical applications for innovation tournaments often suggest multiple periods (Terwiesch and Ulrich 2009). \r\n  From a game perspective, a multi-period game captures that the player's risk attitude reveals gradually through a sequence of information signals about the state of the world. In other words, in the context of multiple-period tournaments with uncertainties, interim performance evaluations allow contestants to timely formulate the competitive strategies, which response to their positions in the tournament and to take advantage of the chance events within the tournament. Hence, a two-period model may fall behind in evaluating the efficacy of feedback mechanism induced by competitive tournaments with multiple periods. This paper articulates the role of interim performance evaluations by looking into the dynamic tournament characterized by multiple periods. \r\n  In addition to theoretical analysis, we analyze behavioral decisions by laboratory experiments. Literature in behavioral economics have demonstrated that a model assuming full rationality cannot precisely predict actual decisions, because irrational factors (behavioral factors) commonly exist in practice. Nevertheless, the behavioral decisions have not been discussed in the study of feedback mechanism on competitive tournaments. \r\n  To summarize, we investigate the interplay between the performance feedback and behavioral factors over the contestants’ strategic effort choice in a tournament with multiple periods. Both a theoretical model and a behavioral model are developed to predict the effort choices. The models demonstrate that the merit of performance feedback is contingent on several factors (for instance, cost difference between the high effort and the normal effort) with a threshold beyond which the provision of interim performance evaluations can weaken a contestant's incentive to exert high effort. ", :title "The Role of Performance Feedback in a Dynamic Tournament: A Theoretical and Behavioral Investigation", :keyword2 40, :authors (59655 59774), :session 20}, 399 {:keyword1 96, :keyword3 42, :abstract "For the optimization of overall performance of production processes, it is oftentimes key to find a good ordering of jobs. This is particularly true, if the production involves sequence dependent set-up times or costs between different families of jobs. \r\n\r\nIn this talk, we introduce a new sequencing problem that emerges from a practical application in the production of glued laminated timber in sawmills. Here, jobs are pressing operations on timber boards of different height, and in order to minimize set-up time the goal is to minimize the number of height changes for neighboring pressing operations. However, jobs which belong to the same customer order need to be processed in a predefined, given sequence. Since the sequences inside order are unchangeable, it is sufficient to consider the problem of sequencing orders such that the end height of one order is equal to the starting height of the next. Furthermore, each customer can post several orders at once, and it is required that orders of one customer are produced one after the other, without interruption.\r\n\r\nThe Domino Sequencing Problem with Families is an abstraction of the above real world problem. Here, families of dominos, each domino with a specific start and end state, are given. In the application, each domino represents one customer order, where the start and end state represent the height of the first and last pressing operation in the order respectively. The families of dominos represent orders of the same customer. For a sequence of dominos to be feasible, we require that dominos of the same family appear one after the other, without interruption. If for a pair of neighboring dominos in a sequence, the end state of the first does not equal the start state of the second, this is called a mismatch. The goal is to find a feasible sequence of dominos, that minimizes the number of mismatches.\r\n\r\nWe first provide a polynomial algorithm which sequences dominos of only one family optimally. This problem can be seen as an Eulerian Extension Problem on graphs. Then we turn to the problem with an arbitrary number of families and show that finding an optimal feasible sequence of dominos is strongly NP-hard. This also implies that it is not sufficient to compute the optimal sequence for all single families and then glue them together (as both these single steps would be possible in polynomial time). \r\n\r\nFinally, we prove that the problem is fixed parameter tractable if the number of families is seen as a parameter. Indeed, the problem can be solved in a time quadratic in the number of dominos, if the number of families is fixed. We also show several possible extensions of our result to more general problems, where, for example, some of the dominos may be reversed.", :title "Playing Dominos to Optimize Production Plans", :keyword2 75, :authors (23161 59757), :session 159}, 403 {:keyword1 182, :keyword3 179, :abstract "We compare the suitability of short-memory (ARMA models), long-memory (ARFIMA models), and a GARCH model to describe the volatility of rare earth elements (REEs). We find strong support for the existence of long-memory effects. A simple long-memory ARFIMA(0,d,0) base model shows generally superior accuracy both in- and out-of-sample, and is robust for various subsamples and estimation windows. Volatility forecasts produced by the base model also convey material forward-looking information for companies in the REE industry. Thus, an active trading strategy based on REE volatility forecasts for these companies significantly outperforms a passive buy-and-hold strategy on both, an absolute and a risk-adjusted return basis.", :title "The economic importance of rare earth elements volatility forecasts", :keyword2 93, :authors (59762 59763 59764), :session 198}, 406 {:keyword1 16, :keyword3 0, :abstract "We consider the COMB-3D heuristic for the three-dimensional Strip Packing Problem. This heuristic combines an implementation of a First-Fit Decreasing- Height, called FFDH-3D heuristic, and the algorithm of Steinberg. Furthermore, it is known that the absolute worst-case performance ratio of this heuristic is at most 5.\r\nIn this presentation, we show an example which proves that this absolute worst-case performance bound is tight. It reveals that this absolute worst-case performance bound can only be reached by instances which fulfil a certain property. Using induction, we succeeded to prove an improved absolute worst-case performance bound for the case that this property is violated. Again we construct examples to show that this absolute worst-case performance bound is tight and is at least 4.5.\r\nFurthermore, we show that the absolute worst-case performance of the COMB-3D heuristic is at most 4.25 if the length of each item is not smaller than its width and the lengths of the container is not greater than its width. This conditions can be fulfilled for the z-oriented three-dimensional Strip Packing problem, where length and width of items can be interchanged but the height of the items is fixed. We also proved that this absolute worst-case performance bound improves to 4, if the container has a squared base area. This theorem is proved by a comprehensive case-by-case analysis and a special kind of induction, where the induction index i increases from i-1 to i or i+1.\r\nFurthermore, we show that if all items and the container have squared base area, the absolute worst-case performance ratio of the COMB-3D heuristic is at most 3.6875 and if all items are cubes the absolute worst-case performance of the COMB-3D heuristic is at most 3.561.\r\nFor proving these theorems we had to consider an unsolved problem for the two-dimensional Bin Packing Problem:\r\nCan a set of items of length and width at most 1/2 and total area at most 5/9 be packed into a bin of length and width 1?\r\nBy a comprehensive case-by-case analysis we proved that such a set of items can be packed into the bin if all items are squares. This result solves the problem for a special case and is also tight, which means that 5/9 is the maximum total area bound.\r\nFinally we show that all pattern of the COMB-3D heuristic have the guillotine-property. gg\r\n", :title "Upper Bounds for Heuristic Approaches to the three-dimensional Guillotine Strip Packing Problem", :keyword2 0, :authors (42140 16923), :session 220}, 407 {:keyword1 86, :keyword3 0, :abstract "A defender wants to detect as quickly as possible whether some attacker is secretly conducting a project that could harm the defender. The timely exposure of a terrorist plot, for example, is crucial for its successful prevention. Given that each activity of the project leads to discovery with a certain probability and that the defender has only a limited budget for increasing these probabilities, the defender's problem becomes: which activities to focus intelligence efforts on? The attacker, in turn, schedules his tasks so as to remain undiscovered as long as possible. Modelling the situation as a zero-sum game, we establish that it is a dominant strategy for the attacker to initiate each task as late as possible and derive a dynamic program that identifies the optimal set of tasks to focus intelligence efforts on. We measure the relative effectiveness of each task's intelligence effort by means of the Banzhaf value. This innovative use of cooperative game theory not only allows for performance evaluation of intelligence activity, it also identifies opportunities for further harm-reduction. We illustrate our methods on an example nuclear weapons development project.", :title "Timely exposure of a secret project: Which activities to monitor?", :keyword2 40, :authors (58371 40229 10607 59768), :session 156}, 408 {:keyword1 185, :keyword3 0, :abstract "The design of a public bus network often happens in several subsequent planning stages, one of these stages is the line planning. In line planning, a public transport provider will decide where their vehicles will drive and which bus stops they will serve. One of the challenges of the line planning problem is that evaluating a line plan has a large computational cost. Typically, you need to calculate the travel time of all passengers. This requires the knowledge of the route each passenger will take through the network. This passenger routing is the main cause of the computational burden. Even seemingly small changes to the bus network can have a large impact on the passengers’ routes.\r\nIn this research, local evaluation techniques are explored to lessen the computational cost of a line plan evaluation. The idea is that previous calculations can be reused when evaluating a change to a line plan. One of the core principles is that routes in the proximity of a change are more likely to be impacted. Closeness is here defined by either physical distance or reachability in a number of transfers. Another core principle is that transfer points are crucial to route choice. Once a passenger is on a certain bus line, he can only change to a different line in a transfer point.\r\nThe developed method reduces the size of the network that is considered during evaluation based on these two core principles. When a change to a line plan is made, the passenger routes will only be recalculated inside a cut of the network. The resulting routes can then be used to calculate the total travel time for the entire network. Passenger routes that previously would have entered (or left) the cut are assumed to still enter (or leave) the cut in the same place. This means that potential faster passenger routes that pass through the cut are not considered. Obviously this is an approximation. Therefore a tradeoff will have to be made between investing more calculation time and obtaining more accurate estimations. Nevertheless, the quality obtained with this faster method should still be sufficient.\r\nThe proposed method is tested with an iterated local search algorithm that creates a bus line planning from scratch and improves it by making small changes in each iteration. While specific types of changes allow for different ways to apply the core principles, the general idea behind the method remains the same. Because of the general nature of the method, it should be usable for nearly all meta-heuristics where a change to a line plan is calculated.\r\nThe method is extensively tested in a case study on the network of Leuven. This network has 106 possible bus stops and utilizes demand based on data provided by the department of Mobility and Public Works of the Flemish government. Preliminary experiments have shown that the ILS can be significantly sped up, resulting in higher quality line plans in the same amount of time.\r\nResearch funded by Research Foundation Flanders G.0853.16N.", :title "Speeding up the bus line planning process", :keyword2 59, :authors (46228 57758), :session 33}, 409 {:keyword1 29, :keyword3 28, :abstract "The fact that energy prices on spot markets are volatile opens up economic potentials for industrial companies, as they consider them in production planning processes. In practice, this means that energy costs can be saved by shifting orders to time intervals of low energy prices, which, however, affects other targets such as capacity utilization and cycle times. \r\nIn contrast to existing scheduling approaches of manufacturing control, which integrate the actual trend of the intra-day electricity price at an operating level, this contribution addresses\r\nthe effects of electricity price-oriented scheduling for planning periods of up to one month. This technical perspective allows decision makers to estimate future system operating costs, required fuel amounts, maintenance activities, utilization levels, (de-)investment requirements, or additional staff. We study a flow shop scheduling environment with one or more machines and energy intensive jobs. Applications can be found, for example, in the chemicals, paper, steel, cement industry.\r\n\r\nOn a tactical planning level, sufficient price information has to be available weeks before production start. In order to obtain a reliable electricity price indication for periods in the future, we conducted electricity price forecasts by using an artificial neural network approach. The results are used as an input for a mixed integer linear scheduling model that, on the one hand, accounts for energy costs and, on the other hand, measures the energy-based gross margin. By means of a computational study, we compare previously and on the basis of forecasted energy prices determined schedules to the actually occurred schedules. \r\nFurthermore, we study the difference between the energy costs of our electricity price-oriented schedules and the energy costs of schedules generated using alternative objectives like cycle time minimization.\r\nSmall-scale instances are solved with CPLEX. In order to solve medium and large-scale instances, further solution strategies and speed-up techniques are considered, as well as heuristic techniques such as fix-and-optimize procedures.\r\n", :title "Electricity Price-Oriented Scheduling Within Production Planning Stage", :keyword2 96, :authors (55881 9524), :session 192}, 411 {:keyword1 189, :keyword3 95, :abstract "Over the last decades, the discussion about “green” mobility has continued to increase. Hence, the promotion of sustainable and carbon free mobility alternatives becomes more and more popular. Bike-sharing has been introduced in many cities, often by municipalities and is nowadays an established alternative for other short-distance transport systems. However, in cities with high elevations, the usual bike-sharing systems face a severe problem. Resulting from an imbalance of demand, the number of bikes at stations at elevated locations decreases during the day, while it increases at stations at lower locations. This situation poses a challenge for the relocation process because high numbers of bicycles have to be transported to the stations at elevated locations in order to achieve a suitable starting point for the next period. With the usage of e-bike sharing-systems, this problem can be circumvented because e-bikes facilitate the mobility in elevated and steep terrains. \r\nWe consider an e-bike-sharing-system with given stations, demand and fleet size. We aim to optimize the station inventory at the beginning of every period by planning the route of trucks relocating the e-bikes. The relocation is active and dynamic. That is, in every period there can be relocation by trucks operated by the provider of the sharing system. ", :title "Optimization of an e-bike-sharing-system with dynamic relocation", :keyword2 159, :authors (56420 22994), :session 212}, 412 {:keyword1 150, :keyword3 158, :abstract "Energy systems consist of multiple units for energy supply and storage to transform secondary energy such as gas and electricity into the desired final energy demands of heat, cool or electricity. Due to the many units and energy forms, the optimal synthesis of such energy systems is a complex optimization problem. The synthesis is a two-stage problem requiring the simultaneous optimization of the design stage and the operation stage. The design stage determines the type and sizing of all units. The operational stage determines the on/off status and the load allocation for each unit in each time step. The operational stage typically depends on large time series increasing problem complexity further. In particular, the complexity increases strongly by time-coupling constraints, e.g., due to storage units. \r\nIn general, the synthesis of energy systems considers non-linear investment cost curves and non-linear part-load performance curves for each unit. Moreover, discrete decisions are required on both optimization stages, to consider existences of units and their on/off status. Thus, synthesis of energy systems typically results in large-scale mixed-integer non-linear programming problems. Typically, these non-linearities are linearized by piecewise linearization. Thus, synthesis problems often correspond to large-scale MILP optimizations. These large-scale synthesis problems are computationally challenging and often not solvable within reasonable computational time or memory limits.  \r\nHere, we propose the decomposition method RiSES3 (Rigorous Synthesis of Energy Supply and Storage Systems). RiSES3 exploits the two-stage character of the synthesis problem. The decomposition method employs time-series aggregation, linear relaxation and parallel computing for efficient solution of the sub-problems. Thereby, RiSES3 provides feasible solutions (upper bounds) with known optimality gap (lower bounds). For the upper bounds, we decompose the two-stage problem in an aggregated synthesis problem and an non-aggregated operational problem. We use time-series aggregation to obtain a feasible design for the energy system. For this feasible design, we subsequently solve the original operational problem yielding an upper bound. Lower bounds are obtained by two competitive approaches: linear programming relaxation and relaxation based on time-series aggregation. To tighten the bounds, we iteratively increase the resolution of the time-series aggregation and tighten the relaxation. \r\nRiSES3 is applied to the synthesis problem of two real-world industrial energy systems, encompassing large time series of prices and demands, time-coupling constraints and storage systems. We show that RiSES3 yields solutions of the original synthesis problem with excellent quality and fast convergence, outperforming commercial state-of-the-art solver by a factor of 100.\r\n", :title "RISES3: Decomposition method via time-series aggregation and relaxation  for optimal synthesis of energy systems", :keyword2 53, :authors (59586 49085 45242 45065), :session 24}, 413 {:keyword1 172, :keyword3 42, :abstract "Influence maximization problems aim to identify key players in (social) networks and are typically motivated from viral marketing. In this work, we introduce and study the Generalized Least Cost Influence Problem (GLCIP) that generalizes many previously considered problem variants and allows to overcome some of their limitations. A formulation that is based on the concept of activation functions is proposed together with strengthening inequalities. Exact and heuristic solution methods are developed and compared for the new problem. Our computational results also show that our approaches outperform the state-of-the-art on relevant, special cases of the GLCIP.", :title "Least cost influence propagation in (social) networks", :keyword2 157, :authors (26409 30921 57230 12046 2813), :session 230}, 415 {:keyword1 95, :keyword3 174, :abstract "In the competitive world of online retail, retailers usually offer a selection of time windows to fulfill customers’ expectations of on-time delivery. Creating a set of suitable and cost-efficient time windows for each customer is challenging. First, customers generally prefer short time windows over long time windows, which can increase delivery costs significantly. Second, demand information only becomes available incrementally over time, and the acceptance of an order request in a short time window can increase the logistics cost of accommodating future requests and/or restrict the ability to accommodate them significantly. Ideally, retailers would simultaneously consider the value of an order request as well as the impact of the proposed set of time windows on logistics costs.\r\n\r\nIn this presentation, we assume that retailers want to decide flexibly which time windows of which length to offer requesting customers. We present different ideas that ensure allocation of short time windows to those customers that are valuable but still do not restrict the flexibility of evolving route plans significantly. We consider information about the current route plan (e.g. current utilization and structure) and combine this with realistic customer’ choice behavior for different time window options (e.g. place and length) to create customer-individual time window offer sets. We analyze the effectiveness of our ideas in computational experiments given demand structure of real order data from an e-grocer in Berlin, Germany.\r\n", :title "Value-Based Flexible Time Window Management", :keyword2 91, :authors (16919 52669 27111 19297), :session 226}, 416 {:keyword1 109, :keyword3 0, :abstract "A-Frame systems are among the most efficient order picking devices. Stock keeping units are stockpiled in vertical channels successively arranged along an A-shaped frame and a dispenser automatically flips the bottom most item(s) of each channel into totes or shipping cartons that pass by under the frame on a conveyor belt. While order picking itself is fully automated, continuously replenishing hundreds of channels still remains a laborious task for human workers. We treat the research question whether the sequencing of picking orders on the A-Frame can facilitate the replenishment process. In many real-life applications, workers are assigned to fixed areas of successive channels which they have to timely replenish. Our sequencing approach, thus, aims to properly spread the replenishment events of each area over time, such that each worker has sufficient time to move from one replenishment event to the next. We formulate the resulting order sequencing problem, consider computational complexity, and suggest suited heuristic solution procedures.", :title "Sequencing of picking orders to facilitate the replenishment of A-Frame systems", :keyword2 174, :authors (55920 5934 55921), :session 164}, 417 {:keyword1 45, :keyword3 0, :abstract "Patient to room assignment is an important task in hospitals as it has a major impact on the degree of capacity utilisation and care quality. In the last years this problem has gained more and more attention in literature but is still far from being satisfactorily solved. The goal of patient to room assignment is to find an assignment that assigns every patient to exactly one room for every day of their stay respecting the room capacities and fundamental constraints such as necessary medical equipment or the specialism of the corresponding department. Naturally, this assignment should avoid transfers of patients between different rooms during their stay as much as possible. Furthermore, assignments of female and male patients to the same room at the same time are not desirable.\r\n\r\nWe propose a new interpretation of patient to room assignment as a multiobjective optimization problem, where we consider the suitability of an assignment, the total number of transfers and the total number of gender mixed room assignments as separate objective functions rather than combining them with predefined weights to a single objective function. This allows more flexibility in decision making than formulations that are based on predefined proportions of the different cost factors and goals.\r\n\r\nIn this talk, we present results on the complexitiy of this problem and some structural insights of the Pareto front. Furthermore, we compare different approaches to solve this multiobjective optimization problem such as scalarization approaches or heuristics for computing the Pareto front.", :title "A Multiobjective Approach to Hospital Patient to Room Assignment", :keyword2 63, :authors (59772 17092), :session 173}, 418 {:keyword1 158, :keyword3 0, :abstract "In cadastral data, buildings often are represented by their 2D footprints. However, 3D models of buildings are better suited for visualization, simulation, planning and taxation purposes. A standard approach to creating such 3D models is to combine 2D footprints with sparse airborne laser scanning point clouds. Within a footprint, data-driven algorithms fit plane segments with the points and combine segments to watertight roof models. Unfortunately, low resolution laser scanning data lead to noisy boundary structures that have to be straightened. We propose a mixed integer linear program that rectifies directions of such boundary edges according to directions of edges of the cadastral footprint. Under certain restrictions to ensure consistency and precision of the models, the goal is to establish as much parallel edges and right angles between edges as possible. We solve such a combinatorial optimization problem separately for all connected components of the planar graph that represents polygonal boundaries of roof facets. The proposed method is applicable within the generation of large scale 3D city models. ", :title "Beautification of City Models based on Mixed Integer Linear Programming", :keyword2 8, :authors (49079 55713), :session 218}, 419 {:keyword1 75, :keyword3 0, :abstract "During the design of a manufacturing system a planner decides amongst others on the locations and capacities of buffers. In case of stochastic processing times and unexpected disruptions they can increase the throughput of a system significantly by reducing starvation and blocking of machines. \r\nIn this paper we allow another instrument to raise the throughput of a system and focus on measures in the context of after sales service.  In order to avoid long downtimes of machines in case of unexpected failures spare parts are kept on stock to enable a repair-by-replacement policy. Since more spare parts lead to higher machine availability, they also have a positive effect on the throughput of the system. However, spare parts induce holding costs, similar as buffer places generate higher costs due to work-in-process inventory.\r\nIn our research we study the trade-off between costs for buffer places and spare parts, and the throughput for a flow-line. We investigate the interaction between spare parts inventory levels and buffer capacity and show how optimal system designs can be determined using a Markov Chain approach.  The optimal solution depends on the relation of costs for spare parts and workpieces and if standardized components are used, then also pooling effects can be observed. Our research reveals, that a joint optimization of buffer capacities and spare parts inventory levels can reduce costs and increase throughput significantly.\r\n", :title "The influence of spare parts provisioning on the design of manufacturing systems", :keyword2 99, :authors (47722), :session 188}, 420 {:keyword1 45, :keyword3 0, :abstract "In the health care sector, the efficient supply of medical care in emergency cases is a very important component and in steady need of optimization. It can be analyzed from both a strategical and an operational point of view.\r\n\r\nIn the operational analysis, it is important to regard the online aspects of the problem as times and places of emergencies become known at the moment of their appearance. In most cases it seems to be adequate to use a greedy approch to solve this problem. Nevertheless, an offline solution approach is required in every case to be able to conduct a competitive analysis.\r\n\r\nThe strategical aspect consists of locating emergency facilities and allocating resources. Due to the present uncertainties a robust appraoch is suitable here. Furthermore, the current cost situation in the health care sector and the demographic change have to be incorporated as well.\r\n\r\nWe present models and solution appraoches for a choice of the problems mentioned above.\r\n", :title "Medical Supply in Emergency Cases", :keyword2 94, :authors (55986 55946 19477), :session 62}, 421 {:keyword1 91, :keyword3 0, :abstract "Non-profit organizations receive money from a variety of sources. The opera theater in Japan has government grants, ticket revenue, theater rentals and private donations as revenue sources. The government grants and the ticket revenue especially account for a large fraction of its total revenue among others. Since it is pointed out that the government grants per attendance in Japan is much higher than that in foreign countries and the grants tend to be reduced every year, how the theater increases its ticket revenue is thought of as an important operational challenge. In this paper, we study pricing strategy of the theater and investigate whether the current ticket prices are optimal and how theater's ticket revenue would change if it re-optimizes the ticket prices. We first estimate the demand function by modeling the consumers' ticket purchasing behavior as discrete choice model. We use a novel data set combining ticket transaction data, seating capacity data and production cost data, provided by a particular opera theater in Japan. The data covers a total of 269 opera productions and 1,096 performances performed from 2001-2002 to 2016-2017 seasons. After estimating the demand function, we compute the optimal ticket price of each seat category for all performances in our data set based on the estimated demand parameters and the model of theater's price setting behavior. We find that the computed optimal prices are roughly close to the current prices except for the highest-quality seat category and the theater may increase its ticket revenue by raising the price of the highest-quality seat category. Moreover, we conduct additional counterfactual simulations in terms of the flexibility of theater's price setting behavior such as no price discrimination by seat category, charging different prices per performance of a particular production and dynamic pricing, and investigate their impacts on theater's ticket revenue.", :title "Pricing Strategy of Non-profit Organizations: A Case Study of the Opera Theater in Japan", :keyword2 0, :authors (56059 56080), :session 89}, 425 {:keyword1 45, :keyword3 0, :abstract "General practitioners (GPs) have an important guiding function in the German health care system. In order to smooth the practice workflow, we consider in this talk the appointment scheduling of patients. This topic becomes increasingly important also from a patient perspective since long waiting times are the most common reasons for patients' complaints. However, an appointment scheduling policy focusing solely on short waiting times is disadvantageous for practice owners since they strive for a more productive and effective workflow which requires high utilization or rather a balanced utilization of GPs.\r\nTo obtain a satisfactory trade-off for both patients and GPs, we develop a Mixed-Integer-Program which divides the GP's working time for chronic and regular patients with appointments as well as walk-ins. Furthermore, we introduce a concept of masks which provides templates to support decisions about the number of reserved appointments in advance for the corresponding patient type. Using this concept variation in treatment demands could be considered more easily by the practice employees. Finally, we test and evaluate our methods by means of simulation.", :title "Optimized Appointment Scheduling in General Practitioner Practices", :keyword2 0, :authors (59775 17092 52270), :session 62}, 426 {:keyword1 45, :keyword3 158, :abstract "Caused by the high degree of stochasticity, appointment scheduling problems are rarely solved with accurate methods like Branch-and-Bound or Branch-and-Cut in literature (Ahmadi-Javid et al. 2017). In the introduced model, surgery hours are partitioned in slots and the probability for patient’s presence after each slot is based on cumulative exponential distribution function. The probabilities of attendance of a single patient after each slot are used as parameters in a MIP to determine the probability of attendance of all patients scheduled during the surgery hours. Since all patients have to be treated during the surgery hours, every single patient gets an appointment at the beginning of a time slot. With usage of a Branch-and-Cut algorithm, each appointment is shifted to slots where the respective probabilities for patient’s presence is balanced concerning to the weighted idle, waiting and overtimes.", :title "A Branch-and-Cut algorithm to optimize probability-based appointment schedules", :keyword2 96, :authors (52430 15060), :session 172}, 428 {:keyword1 95, :keyword3 65, :abstract "In the last decades, the number of vehicles delivering products in city areas has increased enormously. Not only the shops and companies in the area require a delivery of their ordered goods, but also the residents of the city which ordered their new products online. All these customers require a fast delivery within a tight time window. These time windows for the customers are adding an extra complexity to the routing planning problem of the delivery companies. Besides that, these time windows will often lead to an increase in vehicle kilometers. For instance, when customers, which are located closely to each other, have very different time windows, the delivery company has to visit almost the same location twice, at different moments. This also leads to extra transportation costs for the delivery company.\r\nIn this research, we investigate the possible savings that can be obtained when a delivery company has the ability to discuss possible changes in time windows with their customers. By tuning the time windows of customers, which are located closely to each other, the delivery company can save transportation costs. However, if the company changes some of the time windows, it might lose some goodwill by its customers.\r\nTherefore, we present a new variant of the Vehicle Routing Problem with Time Windows (VRPTW), namely the Vehicle Routing Problem with Changing Time Windows (VRPCTW). The objective of this new problem is to determine the best fixed number of time windows changes, such that all customers are served at minimal total transportation cost. In this problem, a difference is made between large changes and small changes. By a large change, the time window of a customer is shifted to another part of the day, while by a small change, the time window is only shifted for a small number of time units.\r\nTo determine good candidates for a large change in the time window, the customers are clustered. Next, the time windows of the customers within a cluster are tuned to each other. For the case of small changes, a VRPTW with soft time windows is used to determine good candidates. Considering soft time windows means that customers can be served outside their given time window at a certain penalty cost. This penalty cost consists of a fixed part and a variable part, which is based on the deviation from the service time of the given time window. To construct routes for the vehicles, a Variable Neighborhood Search (VNS) is used. Customers where large penalty costs are incurred in the constructed routes, are good candidates for changes in their time windows.\r\nIn order to test the performance of the presented solution approach, two sets of benchmark instances are generated. The first set is based on known instances for the VRPTW, while the second set of instances is based on a real city road network. Preliminary results show that by changing only a small number of time windows, the total transportation costs for the vehicles can be decreased by around 3%.", :title "Changing Time Windows to Reduce Vehicle Kilometers in a City Area", :keyword2 59, :authors (46168 46228), :session 165}, 429 {:keyword1 8, :keyword3 187, :abstract "In general, operating a railway transport system is known to be very costly. Especially, the daily operation and maintenance of locomotives come at enormous cost. In this work, we focus on optimizing the utilization of a fleet of locomotives, where the transports that must be performed, are known a priori. Since railway timetables are typically planned a year in advance, the aim is to alter them such that the locomotive utilization is maximized. This task is computationally challenging, as there is a large number of dependencies and constraints to incorporate.\r\n\r\nIn this work we propose a Mixed-Integer Linear Program (MILP) that allows to model two different objective functions:\r\n(a) Minimize the number of locomotives needed, or\r\n(b) Minimize the total cost of empty runs.\r\nFurther, we aim to minimize the overall number of preventive maintenances within the fleet. Preventive maintenance of a locomotive is mandatory once it has completed a predefined distance. We describe the problem on a sparse weighted directed graph that defines the input variables for the MILP. Due to the problem size, we utilize a rolling-horizon approach. Finally, in an experimental evaluation, we demonstrate the efficiency of our approach on various benchmark instances.", :title "A Mixed-Integer Linear Program for Optimizing the Utilization of Locomotives with Maintenance Constraints", :keyword2 158, :authors (59727 51662 30955 60636), :session 52}, 431 {:keyword1 151, :keyword3 157, :abstract "In this work we examine an extension of the Traveling Salesperson Problem (TSP), the so called TSP with Forbidden Neighborhoods (TSPFN). The TSPFN is asking for a shortest Hamiltonian cycle of a given graph, where vertices traversed successively have a distance larger than a given radius. This problem is motivated by an application in mechanical engineering, more precisely in laser beam melting. This technology is used for building complex workpieces in several layers, similar to 3D printing. Recently, Fischer and Hungerländer, studied the TSPFN on regular 2D grids and determined closed-form solutions for the smallest reasonable forbidden neighborhoods. Furthermore they suggest an Integer Linear Program for determining optimal TSPFN solutions for small grid sizes but arbitrary forbidden neighborhoods.\r\n\r\nIn this work we suggest a heuristic for the TSPFN that is based on Warnsdorff's Rule for dealing with such instances where no closed-form solutions are known. The main differences to the original Warnsdorff's Rule can be summarized as follows:\r\n- Arbitrary step sizes are allowed, in contrast to the fixed step size of length square root of 5 in the original Warnsdorff's Rule.\r\n- The resulting solution must be a Hamiltonian cycle instead of a Hamiltonian path.\r\n- The step size is not fixed: if some squares are still unvisited but not reachable with the currently selected step size, our heuristic increases the step size such that the next square can be reached. \r\n\r\nWe implemented the heuristic and conducted a computational study for various neighborhoods. In particular the heuristic is able to find high quality TSPFN tours on 2D and 3D grids, for which optimal solutions are known.", :title "A Heuristic for the Traveling Salesperson Problem with Forbidden Neighborhoods on Regular 2D and 3D Grids", :keyword2 8, :authors (59738 30955 51662), :session 87}, 432 {:keyword1 120, :keyword3 152, :abstract "In 2015, 5 out of 100,000 people were killed by road accidents in Europe. In order to reduce this number, the circumstances of accidents and their change over time must be evaluated carefully. In this way, the police is enabled to decide upon actions to improve road safety, e.g. new speed limit reductions, stop signs or investments in walking and cycling infrastructure. To support this decision process, we propose a change detection framework based on frequent itemset mining (first step), time series evaluation (second step) and time series clustering (third step). Due to the layered structure of this framework, we are able to optimize the single steps individually by considering the results obtained in previous steps.\r\nFirstly, we apply frequent itemset mining on monthly road accident data to receive all attribute combinations that exist at least a minimum number of times (minimum support) in this month. In the provided statistical data, depicting ten years of road accidents that entailed personal injuries, there are about 70 attributes (e.g. age of driver, time of day, vehicle variant), each with 10 different values on average. This leads to billions of possibly interesting attribute combinations. A combination of attributes (frequent itemset) is interesting or valuable, if its relative frequency varies from one month to the other, where a slow inclining or declining trend, an arbitrary change of direction, or any other kind of instability may occur. Since frequent itemset mining methods lead to numerous potentially interesting attribute combinations, an automated change mining approach is needed in order to find the most interesting ones. In a second step, we separate itemsets that exhibit a trend (non-stable) from those that are non-changing (stable) using non-parametric statistical tests like Cox-Stuart and Chi-Squared. Consequently, we drastically reduce the number of attribute combinations to be studied and thus the number of time series that have to be evaluated. The resulting number of non-stable itemsets, that are assumed to provide revealing information, is still very large. Therefore, we cluster them by considering the time series shapes in a third step. Each cluster can then be analyzed further using trend detection methods.\r\nResults show hot spots concerning locations, traffic systems and target groups that help police analysts establishing further action plans to reduce road accidents in the future.", :title "Change Detection Framework for Road Safety Improvement", :keyword2 180, :authors (55835), :session 200}, 433 {:keyword1 29, :keyword3 0, :abstract "Energy scenarios describe possible future states or developments of energy systems, and are used to provide orientation for strategic decision making in the energy sector or in energy policy. In Germany, many scenarios are constructed, in which the energy system is modeled in detail for a single period. For example, in order to make an informed decision on which measures need to be taken into account to reach the emission reduction targets by the federal government in 2050, different energy systems for the year 2050 can be modelled in an energy scenario study. Multi-criteria decision analysis (MCDA) can help to transparently make conclusions from the results of energy system model calculations. For example, different configurations of the future energy system can be evaluated with regard to sustainability. In this context, there are three time-related challenges: Firstly, uncertainties associated with input parameters and results of energy system models increase significantly over time. Secondly, preferences of stakeholders can also vary over time. Thirdly, path dependencies can occur along the way. Hence, we present a multi-period multi-criteria (MP-MCDA) approach for the evaluation of transition pathways, which consist of alternatives in multiple periods (e.g., 2020, 2030, 2040, and 2050). The multi-period evaluation is based on the outranking method PROMETHEE and consists of a two-step procedure: In the first step, the alternatives are evaluated with PROMETHEE in each period and in the second step, the performance scores are aggregated along transition paths. Changes in stakeholders’ preferences and uncertainty can be modelled with different aggregation methods and path dependencies can be considered. The method is exemplary applied for planning the power generation system in a rural area in southern Lower Saxony, Germany.", :title "Multi-criteria evaluation of the transition of power generation systems", :keyword2 115, :authors (59778 24622), :session 175}, 434 {:keyword1 97, :keyword3 45, :abstract "The structure of ambulance stations has grown historically in Germany. Step-by-step, outdated ambulance stations have to be renovated or newly built. This arises the question: Is the current location optimal? We investigated this question for the ambulance station in Nierstein, Germany. Therefore we developed data-based methods for static and dynamic analyses of location scenarios which will be presented in this talk.\r\n\r\nBased on data of real rescue operations and a detailed road network, we estimated a specific speed profile for ambulances driving with blue lights and sirens. Using this speed profile, we calculated so-called isochrones for each potential ambulance location as well as all relevant ambulance locations around. By overlaying these isochrones, the estimated driving time of the fastest ambulance is known for each road segment – provided all ambulances are available at their station. This static analysis is important for the fulfillment of the legal regulation.\r\n\r\nIn the highly dynamic world of emergency services, the ambulances are often occupied or on their way back to their station. In order to regard this crucial point, we simulated for each location scenario the occurrence of the historic rescue operations over a couple of years. In this detailed simulation, all relevant ambulances were considered and ambulances could be alerted while driving empty. This dynamic analysis gives a realistic estimation of driving times and the workload of ambulances after a change in the location structure. \r\n", :title "Simulation-based location optimization of ambulance stations", :keyword2 54, :authors (59714 15197), :session 62}, 435 {:keyword1 149, :keyword3 120, :abstract "Advances in online shopping brought forward a research stream on the multichannel sales and marketing. Most of the research on the topic focuses on the effect of multichannel sales on customers, promotions, price and overall sales of the company. There are also some studies on the conversion of customers under the multichannel setting. In this study, we focus on the customer conversion from physical to online sales channel for Migros, one of the largest FMCG retailers in Turkey. Migros operates its online channel through selected physical stores in selected regions. We study the conversion patterns of customers from physical to online channel on Migros stores that start to operate online sales channel. We consider several stores that switch to multichannel settings in various cities. We discuss the effect of the variables related to customer’s shopping patterns from the store of interest, the penetration of product categories into customer baskets, discount propensity and purchases from private label products and other special product categories that may influence customer channel choice, such as baby products. Our results suggest that a customer’s probability of converting to online store increases as the shopping ratio from the store of interest, the number of product categories and the ratio of baby products in the basket increases.", :title "Who switches to the online sales channel?", :keyword2 56, :authors (10362 59797), :session 201}, 436 {:keyword1 28, :keyword3 96, :abstract "The development of an increasingly decentralized, renewable power supply requires new or refined planning approaches. Compared to unit commitment planning in regulated markets with a dominant share of dispatchable power generation, power systems with large shares of intermittent renewable power sources such as wind or photovoltaics are subject to uncertainties on the supply side in addition to uncertain load forecasts and prices. \r\nVirtual Power Plants have been developed to aggregate intermittent renewables with so-called flexibility options, which include dispatchable power plants, storage systems and flexible power consumers. Dispatchable power plants, such as biogas plants, are all those that can actively be committed to supply power in a time interval, independent of significant exogenous factors such as the weather. Storage systems, such as hydro pump storage, can store power in times of low prices and sell it again when prices are higher. Flexible power consumers, such as operators of electric vehicles, can attempt to use the potential time windows for loading the batteries to lower their power purchasing costs.\r\nIn the current German power market, power can be traded either in an auction at noon of the day before physical delivery (day-ahead auction), in another auction a few hours later (intraday auction), or on the day of physical delivery itself (continuous intraday trading). In order to determine optimal schedules for flexibility options in the context of day-ahead or intraday markets, a two-stage unit commitment model is presented to deal with the uncertainty of market prices resulting from the interplay of power generation in wind turbines and photovoltaic cells with power demand.\r\n", :title "Two-Stage Unit Commitment Modeling for Virtual Power Plants", :keyword2 29, :authors (28733), :session 9}, 437 {:keyword1 29, :keyword3 0, :abstract "Environmental protection and energy efficiency are major topics in seaport management. Serving as an interface of sea and landside, container terminals play an important role in global supply chains. On the one hand, the operators of container terminals are facing pressure on reaching a higher level of throughput by shipping companies, while on the other hand, port-authorities and governments ask for measures for energy saving and emission reduction. Therefore, many container terminals today strive to reduce emissions and energy consumption while maintaining or improving the current service level.\r\nThe highest share of emission reduction in a container terminal can be achieved by using electrically powered container handling equipment and renewable energy. The possible future electrification of equipment in container terminals will increase their power demand significantly. Energy Demand Management aims at modifying consumer demands to reduce energy consumption during peak-hours to benefit the power supply system as well as reducing energy costs for the terminal operator.\r\nIn this paper, we present a mixed-integer linear program for demand response in container terminals with electric rail-crane system and first results. The goal is to determine the cost-reduction potential by comparing energy costs with an optimal demand management and energy costs without demand management for small problems. We use the program to determine the most cost-efficient demand schedule in the planning horizon while the constraints guarantee sufficient power supply for normal operation. Since we are only interested in the cost reduction potential, we assume the future electricity prices in our model to be known. \r\n\r\n", :title "Evaluation of cost-reduction potentials in container terminals with electrified horizontal transport by using Energy Demand Management", :keyword2 159, :authors (59779 28733 24622), :session 192}, 438 {:keyword1 45, :keyword3 157, :abstract "The supply of pharmaceuticals is one important factor in a functioning health care system. In the German health care system, the chambers of pharmacists are legally obliged to ensure that every citizen can find an open pharmacy at any day and night time within an appropriate distance. To that end, the chambers of pharmacists cerate out-of-hours plans for a whole year in which every pharmacy has to take over some 24 hours shifts. These shifts are important for a reliable supply of pharmaceuticals in the case of an emergency. From a pharmaceutical perspective these shifts are however unprofitable and stressful. Therefore, an efficient planning that meets the needs of the citizens and reduces the load of shifts on the pharmacists is crucial. \r\n\r\nAn important group of customers using the out-of-hours service are emergency patients. Normally, they fist consult a physician before going to a pharmacy. The planning of the out-of-hours service currently does not guarantee that an emergency practice has an opened out-of-hours pharmacy in its vicinity. In this talk, we present a basic model that reflects the real world planning and extends it with different approaches for the integration of emergency practices. We compare the obtained out-of-hours plans regarding the reachability of out-of-hours pharmacies from emergency practices based on different measuring methods. Finally, we analyze the extra load of shifts on a few pharmacies due to the improved supply around emergency practices. \r\n", :title "Planning of out-of-hours service for pharmacies respecting emergency practices", :keyword2 8, :authors (17092 55847 12177), :session 170}, 439 {:keyword1 189, :keyword3 175, :abstract "With the current trend of increasing the number and length of trains on the existing railway networks up to saturation, the schedule adherence has become critical. The scope for delay is diminishing and delay propagation is a recurrent issue with saturated networks. One of the many possible sources for delay comes from the excess time induced by pedestrian congestion inside the train stations. Indeed, sufficient time must be planned in order to guarantee that connecting passengers can catch their connections. As to minimize the risk of cascading delay induced by the wait for passengers to change services, the train operators need reliable estimations of the walking times between platforms.\r\nThe transfer times required for pedestrians to change platform depend on the dynamics taking place inside the station. High spatio-temporal variability in congestion occurs as the trains alight their passengers. \r\nOn one hand, synchronizing the arrival of trains inside the station means many different connections are available, but on the other, when many trains arrive at the same time pedestrian congestion can occur, hence leading to a decreased level of service and higher travel times and travel time variability. As an increase in the time between train arrivals will likely decrease the attractiveness of the train network, keeping an acceptable level-of-service during these highly congested times is desirable.\r\nOne direction for achieving this objective is to influence the choices pedestrians make. This can be accomplished by implementing control and management strategies inside the infrastructure. As for vehicular traffic, various strategies can be conceived. They can influence different levels of decision-making, and be considered as soft strategies (like information or guidance) or hard ones (like physical barriers). In order to evaluate the effectiveness of two management strategies, a framework capable of simulating the impact of them is developed. The first strategy which is proposed is the usage of gates for controlling the flows of pedestrian entering sensitive areas like corridor intersections. The second strategy consists of a mechanism for separating opposing flows and therefore preventing counter-flow from occurring.\r\nThese strategies will be evaluated based on travel time derived indicators. Focus is given to the mean and variance of the travel times of the pedestrians with similar departure times. The expected results are a reduction in travel time variability and possibly a decrease in mean travel time as well. The results will be compared with empirical pedestrian tracking data to validate them.  Future work includes more advanced formulations of the management strategies and the development of a simulation-based optimization framework in order to calibrate the parameters of the management strategies.\r\n", :title "Reducing variability in passenger transfer times with two management  strategies inside transportation hubs", :keyword2 97, :authors (59777 59782 26236), :session 44}, 440 {:keyword1 59, :keyword3 183, :abstract "Since coordination and cooperation between teams are common preconditions to accomplish a task, synchronization problems arise in various contexts in which synchronization refers to the simultaneous execution of tasks required cooperation. Although it is a much noticed and well described problem, there is still a lack of heuristic solution methods in the literature. Furthermore, due to the usually high problem specifications, a meaningful comparison of the solution procedures presented is difficult. Therefore, we continue the approach of Hocke et al. (2017), whose modeling as Vehicle Routing Problem with Time Windows and Temporal Synchronization Constraints (VRPS) can map a variety of specifications. We expand the computational study with a Particle Swarm Optimization (PSO), which is described in this paper. This includes a parameter tuning for stochastically metaheuristic proposed and the statistical evaluation of several thousand benchmark computations resulting from the different parameter settings.\r\n\r\nHocke, Stephan; Gajewski, Christina and Kasper Mathias (2017): A Genetic Algorithm for the Vehicle Routing Problem with Temporal Synchronization Constraints. In: Diskussionsbeiträge aus dem Institut für Wirtschaft und Verkehr, (2/2017), 2017.\r\n", :title "A PSO and Parameter Tuning in the context of the VRPS", :keyword2 186, :authors (55873 52606), :session 204}, 441 {:keyword1 150, :keyword3 0, :abstract "Optimization models often feature disjunctions of polytopes as submodels. Such a disjunctive set is initially (at best) relaxed to its convex hull, which is then refined by branching.\r\n\r\nTo measure the error of the convex relaxation, the (relative) difference between the volume of the convex hull and the volume of the disjunctive set may be used. This requires a method to compute the volume of the disjunctive set. Naively, this can be done via inclusion/exclusion and leveraging the existing codes for the volume of polytopes. However, this is often inefficient. \r\n\r\nWe propose a revised variant of an old algorithm by Bieri and Nef (1983) for this purpose. The algorithm is using a sweep-plane to incrementally calculate the volume of the disjunctive set as a function of the offset parameter of the sweep-plane. This function describes how much volume has been \"passed\" by the sweep-plane for a given offset parameter. Analyzing this function can give further insights into the structure of the disjunctive set as it scans the change of volume when passing through the body similiar to a tomography. \r\n\r\nWe enhanced the original algorithm by separating it into two parts. In the first computationally expensive stage, a geometric data structure is set up that can be used to efficiently compute the above function of the volume for one or many sweep-planes in the second stage. These functions can then be used to find cuts which separate the disjunctive set into two parts that are closer to their respective convex hulls.\r\n", :title "A Sweep-Plane Algorithm for the Computation of the Volume of a Union of Polytopes", :keyword2 0, :authors (59755 14736), :session 221}, 443 {:keyword1 63, :keyword3 7, :abstract "General practitioners are responsible for diagnostic and curative services, often combined with disease prevention. In order to fulfill the requirements of several stakeholders, mainly patients of different types and different practitioners, it is important that the available scarce capacity is well utilized. In order to treat walk-ins who join the practice without notification, enough capacity should remain in addition to pre-booked appointments. Some patients prefer to take an appointment on a following day to avoid long waiting times in practice. By adequately offering prescheduled appointment slots, patient demand can be channeled to a certain extent; this opportunity applies for group practices in particular as demand can be channeled between weekdays and also between practitioners. Challenges arise when taking into account the interests of all practitioners.  We propose a generally applicable mixed integer linear optimization models with different goal functions. It is tactically decided on weekly appointment schedules for practices with multiple general practitioners. Dependent on different structural characteristics of a practice concerning patient type and patient preferences, typical appointment schedules are calculated and compared regarding multiple criteria. In a series of stochastic simulations, we further analyze the obtained solutions according to different evaluation criteria, when patient arrival, their willingness to wait and treatment duration are uncertain. Results allow recommendations for practices dependent on their respective structure and patient panel.", :title "Scheduling appointments for several practitioners in a medical group practice -  Challenges and opportunities", :keyword2 45, :authors (55807 52493 39462 10057), :session 172}, 445 {:keyword1 158, :keyword3 0, :abstract "Gurobi Instant Cloud is an easy to use cloud service to solve mixed integer optimization problems.  Except for setting a few parameters, using Gurobi Instant Cloud is transparent from a user application point of view, and all of Gurobi's APIs support cloud access.  In this talk we walk through the most important concepts and usage patterns.\r\n\r\nA central design challenge is the dynamic allocation of computing resources to submitted jobs.  We discuss our concept of \"pools\", differentiated by specific needs (large/small problems, development/deployment etc.), to which user applications submit jobs over HTTPS.  In our scheme each pool has associated with it a set of machines which execute the submitted jobs.  Pools can be instantly scaled up or down through a web application, by dynamically adding or removing machines in the pool.  The application further supports monitoring and controlling the job queue, accessing job history, and gaining detailed job information through a dashboard.\r\n\r\nWe also show how to manage jobs, pools and machines through a RESTful API, which allows you to create custom, automatic cloud environment control.\r\n\r\n", :title "Solving MIPs with Gurobi Instant Cloud", :keyword2 98, :authors (59783), :session 48}, 447 {:keyword1 48, :keyword3 96, :abstract "The batch-scheduling problem addressed in this research originates from a metal processing company. This company produces customer-specific easy shaped two-dimensional parts but also complex welded and bowed components used in various equipment and machines such as checkout facilities or enclosures of cash machines. The manufacturing process generally starts with the laser cutting of raw shapes out of metal slides. To avoid unnecessary setups and waste, raw shapes are grouped to batches, whereby each batch corresponds to one metal slide. Naturally, each metal slide has a limited capacity and only a limited amount of shapes with their individual size (area) can be placed on one metal slide. Due to the sequential cutting of the shapes assigned to a batch, the batch processing time is equal to the sum of the cutting (processing) times of the assigned shapes. Therefore, the batch-scheduling problem at hand is a serial-batch or s-batch scheduling problem. Depending on the customer order (job), the metal slides have specific characteristics, i.e., material (e.g., aluminum or steal) and thickness. In consequence, jobs cannot be grouped in the same batch if they have different characteristics and thus, we have to consider incompatible job families during batching. In addition, the cutting machine setup times depend on the sequence of batches (e.g., calibrating the machine from one material to another requires more time than just different thicknesses). Together with the objective of minimizing total tardiness, these problem characteristics formulate a scheduling problem not addressed in literature so far. \r\nMost solution methods tackling similar problems are based on a sequential or iterative combination of batching and sequencing decisions. In contrast, we propose a mixed-integer non-linear program addressing both decisions simultaneously. To analyze the solvability of the problem at hand, we use different standard solver (ANTIGONE, BARON, and DICOPT) and several instances inter alia varying in the number of jobs, number of incompatible job families, and the job to family assignment (e.g., jobs are evenly distributed to all families or one family contains most of the jobs). The computational results show that ANTIGONE and BARON clearly outperform DICOPT when solving instances with 15 jobs but DICOPT outperforms the other ones if the number of jobs is 30 (computation time is limited to ten minutes). Generally, we can report that specific instance characteristics have a noteworthy impact on the solution quality of all applied solution methods. Furthermore, we can state that the larger instances with more than 30 jobs are hardly solvable by the investigated standard solvers.\r\n", :title "Minimizing total tardiness on a serial-batch processing machine with incompatible job families defining sequence-dependent batch setup times", :keyword2 86, :authors (59770 27800 1609), :session 162}, 448 {:keyword1 185, :keyword3 0, :abstract "Line Planning is an important stage in public transport planning. This stage determines which lines should be operated with which frequencies. Several Integer programming models exist that provide solutions for the line planing problem. However, when solving real-world instances, integer optimization often falls short since it neglects objectives that are hard to measure, e.g., memorability of the system. Adaptions to known line planning models are hence necessary.\r\n\r\nIn this talk we analyze one such adaption, namely that the frequencies of all lines should be multiples of a fixed, but unknown, system headway. This is a common condition in practice and improves memorability and practicality of the designed line plan and the resulting timetable. We include the requirement of such a common system headway into several known integer programming models and compare line plans with and without this new requirement theoretically by investigating worst case bounds. We also prove that we only have to consider certain system headways, i.e., headways were the resulting frequency is a prime number. Additionally, we test the two approaches on virtual networks and close to real world instances and discuss the resulting lines as well as the corresponding timetables to decide whether such a constraint is beneficial.", :title "Real-World Line Planning: The Case of System Headways", :keyword2 157, :authors (52367 18296 59787 1601), :session 210}, 452 {:keyword1 96, :keyword3 174, :abstract "In this study, a generalized assignment problem for overhead cranes of a steel coil producer is examined. The aim is to minimize total material handling and to use storage area efficiently. In this case, storage area is within the production area and is used as work-in process buffer between production lines. There are multiple overhead cranes operating on the same area, hence crane collision should be strictly avoided. Overhead cranes are primarily responsible from placing incoming coils from other areas or the production lines and outgoing coils to next production line. There are other tasks such as taking packed and to be packed coils to their places and loading/ unloading trucks with secondary priority. All tasks have priority which changes according to crane used and number of coils waiting in front of lines. To cope with this dynamic structure of business environment we construct a dynamic sequencing model and develop a heuristic algorithm. Computational study and its results are presented.", :title "A Dynamic Generalized Assignment Model for Overhead Cranes of a Steel Coil Producer", :keyword2 133, :authors (53572 57195), :session 162}, 453 {:keyword1 95, :keyword3 0, :abstract "Increasing battery capacities and low maintenance costs foster the replacement of vehicles with combustion engines by (battery) electric vehicles (EVs). This trend also holds for company fleets in which vehicles may be (partly) replaced by EVs that can be conveniently recharged (overnight) using charging stations that are built at car parks of the respective company. Nevertheless, the use of EVs imposes additional challenges (compared to combustion engine vehicles) since time-demanding charging breaks during service may be necessary in the case of long trips and since their energy consumption heavily depends on the driving speed (among other factors). This article studies the use of EVs in the context of arc routing. Given a street network including a set of required edges and arcs, the electric arc routing problem (eARP) proposed in this work asks for a set of routes that visit all required edges and arcs with minimal total travel time and which do respect the energy usage constraints imposed by the use of EVs. While the use of EVs in arc routing has not been studied before, related works concerning node routing with EVs typically use several simplifying assumptions with respect to the battery consumption and / or charging functions. We address several of these shortcomings by considering speed dependent energy consumption values and nonlinear charging functions that depend on the battery state before traversing an arc and the charging time. Additionally, we study the possibility of inductive (wireless) charging along roads while driving (at a lower speed). We introduce the new problem and describe a mixed integer linear programming formulation for it including an exponential number of constraints. Several variants of a developed branch-and-cut algorithm are compared in a computational study.", :title "The electric arc routing problem", :keyword2 57, :authors (12046 1116 22042 26409), :session 154}, 455 {:keyword1 8, :keyword3 95, :abstract "In this work we analyze the multiple Traveling Salesperson Problem (mTSP) on regular grids. While the general mTSP is known to be NP-hard, the special structure of grids can be exploited to determine closed form solutions, so the problem can be solved in linear time.\r\n\r\nOur research is motivated by several real-world applications, like search and rescue operations or delivering goods with swarms of drones. Considering a grid structure enables to divide a large search area in several equal-sized squares. The area of a square is chosen as large as the coverage of a drone.\t\r\n\r\nFirst, we suggest a Mixed Integer Linear Program (MILP) for the mTSP on regular grids where we distinguish between two objective functions. The first one aims to minimize the total tour length of all salespersons, which is motivated by minimizing the average search time for a missing person. The second objective function minimizes the maximal tour length of a single salesperson, which is motivated by minimizing the maximal search time for a missing person.\r\n\r\nBased on the results of our MILP we provide lengths and construction schemes of optimal mTSP tours for our considered objective functions. With the help of combinatorial counting arguments, we establish lower bounds on the tour lengths and hence, we are able to prove the optimality of our closed form solutions. \r\n", :title "The Multiple Traveling Salesperson Problem on Regular Grids", :keyword2 158, :authors (59758 30955 51662 59766 59765 50992), :session 87}, 458 {:keyword1 133, :keyword3 18, :abstract "Large production volumes and competitive markets require products with a particularly cost-efficient design. To design new products optimally, engineers need to make a high number of interdependent design decisions within the development phase in order to achieve minimal cost while still complying with technical requirements. Multi-domain virtual prototyping provides product designers with a wide variety of tools such as FEM/FVM to assess the technical feasibility and cost of individual product designs. However, these tools often require substantial computational effort for only one design evaluation. Therefore, the usage of mathematical optimization methods is a promising alternative to engineering intuition and brute force methods. For being competitive in an industrial setting, the mathematical optimization methods have to use as little expensive design evaluations as possible. \r\nMetamodel-based optimization is a  black-box optimization approach with which one tries to maximize the usage of the information gained with each design evaluation by constructing a “fast-to-evaluate” data-driven surrogate model for the “slow-to-evaluate” simulation model. Promising designs are chosen by optimization on the metamodel and are evaluated on the ”slow-to-evaluate” simulation model. In our case, the results of this evaluation are used to iteratively update the metamodel, thus improving its quality in promising regions. This approach has been extensively investigated for single product design, and has significantly reduced the computational effort.\r\nIn this work, we apply this approach to the optimal design of platform-based product families. Such product families consist of a number of different product variants, which satisfy different customer requirements. They may share common platform parameters, which typically results in cost savings due to the beneficial use of common parts. In the joint product platform selection and design problem, the platform configuration (stating which parameter is identical for which product) and the value of these platform parameters are optimized simultaneously, resulting in a mixed integer problem.   \r\nWe compare the usage of different types of Gaussian process regression metamodels adapted from the domain of machine learning and combine them with an efficient metaheuristic to search for promising candidate designs for the whole product family. We illustrate our approach for an exemplary product family and investigate the trade-off between solution quality and computational overhead. \r\n", :title "Combining machine learning and metaheuristics for the black-box optimization of product families – a case-study investigating solution quality vs. computational overhead", :keyword2 124, :authors (55737 41758 45180), :session 83}, 462 {:keyword1 189, :keyword3 59, :abstract "During the operation of a bus service, unusual situations, where demand and congestion increase, frequently occur. Therefore, there is a clear need for a timely  response in order to keep  the service level provided to passengers under control.\r\n\r\nOperators tend to respond to high congestion levels or even road closures, designing, manually, alternative routes for bus lines in order to avoid the area and therefore reduce travel times. Sometimes, these solutions are accompanied by an adjustment of the frequencies of lines going towards the congestion area in order  to increase the offer and to serve the increased number of passengers towards this area.\r\n\r\nThis practice can be improved if the lines that should avoid the congested area are identified automatically, together with the lines whose routes must cross the area, but that might use a better route. In addition, if known which origins and destinations now have a higher demand, it is also possible to evaluate changes in the routes that would offer a faster service for this new demand. These changes can modify the route of a line within and outside the congested area, as long as the change makes it faster for passengers to reach their final destination.\r\n\r\nIt is desirable that the new routes are designed based on small changes to the usual routes, so that the understanding of the line plan remains easy and intuitive for the regular passengers. Having flexible lines like these, the total travel time is improved by incorporating a small number of the  best possible changes to the current routes. The selection and design of the new routes for the lines are made by comparing the usual line plan with a near optimal line plan designed specifically for the unusual situation.\r\n\r\nFor this purpose, a genetic algorithm has been designed that, based on a set of input parameters that describe a particular situation, evolves populations of individuals in order to look for the best possible line plan for the (new) situation. The line plan designed with the use of the genetic algorithm is compared with the usual line plan to know the similarities and differences between these solutions. In this way, a set of potential flexible lines is identified. The method has been tested in a small benchmark instance and a real network based on the city of Cuenca with 272 bus stops and 58 bus lines. Preliminary experiments have shown that flexible lines allow to improve the service during unusual situations, without making too much changes for the regular passengers.\r\n", :title "Flexible Bus Lines designed for unusual situations", :keyword2 65, :authors (59792 59793 59794 46228), :session 30}, 464 {:keyword1 93, :keyword3 35, :abstract "Within finance, model risk options valuation focuses on the effects of mispricing of illiquid exchange or over-the-counter contracts due to an incorrect price process. There is also a contrary operational risk consideration: that the inclusion of pricing model features may lead to software code that is unverified and cause misevaluated option valuations, particularly for options with multiple contract features.\r\nWe propose a statistical hypothesis test between the simple and more complex pricing models based on simulating the sensitivity of the convex combination of the respective Markov kernels. This technique requires less simulation of the more complex pricing model. The stochastic gradient representation of option model risk is general and can be applied to quantify the difference between two performance functions at multiple times.\r\nWe utilize this method to exemplify option model risk when investigating the inclusion of compound Poisson process jumps following an assumed jump amplitude distribution has a significant change in value to price diffusions. These results are compared to the standard hypothesis tests for evaluating the differences in equal means and is more \r\nThe presented hypothesis test is more sensitive than the two sample t-test for equal means for independently distributed quantities, as measured by the probability of rejection of the null hypothesis.  Similar performance is observed in the proposed test when common random numbers are introduced to evaluate both options.\r\n", :title "Detecting the Presence of Jumps in Pricing Options", :keyword2 97, :authors (54266), :session 198}, 466 {:keyword1 187, :keyword3 97, :abstract "The problem considered in this work stems from a non-profit organization in charge of transporting patients to medical appointment locations. The patient is picked up at home around half an hour before his appointment time and is then dropped at the appointment location (outward request). The patient may also ask to be picked up at the end of his appointment to be driven back home (return request). Some patients have specific requirements: they can require an accompanying person or to be transported in a wheelchair. The organization proposes door-to-door transportation services for these requests.\r\nThis problem is called a dial-a-ride problem (DARP) in the scientific literature. The DARP investigated in this application consists in determining a set of routes for a fleet of vehicles to satisfy the requests, taking into account several constraints: e.g. time window constraints (the pickups and the deliveries have to be achieved within given time intervals), maximum riding time constraints of patients, and vehicle capacity constraints. The objective function is composed of several aspects: minimizing the route length but also maximizing patient satisfaction (reduced waiting time or route duration).\r\nIn practice, an initial planning is generated in the evening for the following day.  This planning is composed of a routing and a schedule. The routing represents the set of routes, that is the ordered sequences of locations to be visited, for each vehicle.  The schedule is composed of the arrival and departure times for each route location, for each vehicle. The initial planning has to meet the set of constraints. However, in practice, even if patients have a fixed appointment time, the appointment duration may vary due to unforeseen circumstances. Thus, even if all requests are known in advance, it may happen that some transportation requests are modified, delayed or cancelled in real-time. For instance, the doctor can be late and thus the patient will be available later than expected. A patient can get sick and thus not able to attend his appointment. Hence, the associated requests are cancelled.  The aim of this work is to propose recourse actions to adapt the planning in order to manage these real-time disruptions. The planning should be modified quickly, while trying to minimize the changes to avoid confusion for the drivers and the patients. For this purpose, several operators are defined to be able to temporarily delete a request, to insert a previously deleted request or to definitely cancel a request. Moreover, in practice, several choices can be made and some politics are thus introduced to assess the impact of these choices on several quality indicators, such as the waiting time of the patients, their ride time or the route length. Finally, simulation techniques are used to create scenarios with real-time disruptions.\r\n", :title "Dial-a-ride with real-time disruptions", :keyword2 188, :authors (36600 1344 20524), :session 36}, 467 {:keyword1 157, :keyword3 0, :abstract "We consider multi-stage optimization problems consisting of several subproblems (also called stages) which depend on one another through coupling constraints. We assume that the overall problem is difficult to solve (due to its size and the coupling constraints) but that the subproblems can be be solved in reasonable time. That leads to various heuristic solution approaches where the most common one is to solve the subproblems sequentially. But the resulting sequential solution is seldom optimal for the overall problem, thus motivating to consider the price of sequentiality which measures how good a sequential solution is compared to an optimal solution for the overall problem. It is easy to see that sequential solutions can be arbitrarily bad, i.e., the price of sequentiality is infinite.\r\n\r\nTherefore, different solution approaches have to be applied. We investigate the influence of the selection of non-canonical subproblems and the order in which subproblems are solved on the overall solution quality as well as propose methods to modify subproblems by a Lagrangian approach such that they better represent the overall problem.\r\n\r\nAdditionally, we illustrate our findings on three important problems from public transportation planning, namely line planning, timetabling and vehicle routing which are usually solved sequentially but actually represent three stages of finding an optimal transportation system. We present an integrated formulation for all three problems and provide different solution approaches.", :title "Solving multi-stage optimization problems illustrated on public transportation planning", :keyword2 185, :authors (52489 1601), :session 210}, 468 {:keyword1 48, :keyword3 100, :abstract "Beside electric current, many industrial production processes require additional applied energy sources (AESs) like steam or pressure. Therefore, many manufacturing companies install and operate their own energy conversion units (CUs) to transform final energy sources (FES) into AES (e.g., a boiler transforms water into steam by firing natural gas). Most important parameters determining a CU´s overall degree of efficiency is its dimension (maximum load level) and its nominal load level at which a CU operates with maximum efficiency. The importance of both parameters is not least because of their interactions highly influencing part load efficiencies. Therefore, we present a new planning approach based on a multi-step truncated enumeration heuristic to minimize the total amount of required FES by simultaneously considering the dimension and the nominal load level of one or more CUs. Hereby, it is important to consider the non-linear growing reduction of part load efficiencies with increasing distance between part load and the nominal load. Generally, we follow the broadly accepted planning approach based on load duration curves (LDCs) used to anticipate future AES demands. Because the LDCs of manufacturing companies are inter alia the result of machine scheduling, we are not only considering LDCs resulting from scheduling with traditional economic objectives like makespan or total flow time but additionally an objective directly addressing the temporal course of the AES demand (and thus, the course of the LDC).\r\nIn the experimental analysis, we differentiate manufacturing companies by the number of machines, job size (i.e., mean processing times), and processing time variability and by the AES demand characteristics demand course and demand variability. Furthermore, we investigate the influence of the different scheduling objectives and different technical CU parameter settings (e.g., basic load efficiencies and range of operation). Without limiting the general applicability of our planning approach, we propose the combination of two types of CUs: one large scale CU (LCU) with a high efficient nominal load but a small range of operation and a flexible CU (FCU) with a large range of operation but less efficient. The results show, that a more efficient LCU with a smaller range of operation is superior to a LCU having a larger range of operation but a lower efficiency. A similar statement can be made for the FCU: a higher nominal load efficiency at the expense of high efficiency losses in part load regions is superior to a lower nominal load efficiency with smaller efficiency losses in part load regions. Both observations are independent of the scheduling objective and manufacturing company characteristics. With regard to the three scheduling objectives, we can report that the AES related objective achieves lowest FES demands on average but that the makespan objective achieves competitive or even better results for some company characteristics.\r\n", :title "Planning energy conversion units for manufacturing companies", :keyword2 29, :authors (59795 27800 1609), :session 193}, 472 {:keyword1 33, :keyword3 0, :abstract "A multi-site facility layout and product-to-site assignment problem\r\nJob shop production systems are characterized in general by a heterogeneous and complex material flow between production units, which perform different production operations. This is caused by the interdependencies of producing different products by means of the same production units according to different work schedules. Facility layout planning being based on such a material flow requires a compromise in placing the respective production units on the floor: The minimum total costs of material flows in the system can only be achieved by deviating from product-specific cost minimal material flows (heterogeneity costs).\r\nIn a company with more than one production site at its disposal, the sites can focus on smaller disjunctive product programs. In this context the decision field of facility layout planning is extended by two questions: (1) Which products are to be produced at which site, and (2) for which production unit redundancies are necessary? The first question enables the company to disentangle the material flows. That is, to group similar products together in order to achieve more homogeneous material flows at each site. This would relax necessities to deviate from product-specific cost minimal material flows so that heterogeneity costs and thus the total costs of material flows in the system can be reduced. The second question arises, since not only similar products are produced with the same production units. Hence, the effect of disentanglement can be increased by building up redundancies across the sites for production units required by products with heterogeneous material flow. That means, placing production units of the same type to different sites, enlarges the possibilities to achieve homogeneous material flows at the respective sites. In this extended situation the task of layout planning is to balance the trade-off between costs of heterogeneity and redundancy.\r\nThis contribution provides an extended optimization model (based on the quadratic assignment problem) that combines layout planning of multiple sites with the product-to-site assignment to a multi-site facility layout problem (MSFLP). In contrast to multi-floor facility layout problems, each product is explicitly assigned to one site only, and transports between the different sites are not allowed. By means of a numerical analysis the interaction between costs of heterogeneity and redundancy is investigated with respect to three factors: the kind of product-specific material flow, number of products and number of sites.\r\n", :title "A multi-site facility layout and product-to-site assignment problem", :keyword2 8, :authors (39470), :session 187}, 473 {:keyword1 101, :keyword3 156, :abstract "We study a demand fulfillment problem in a make-to-stock manufacturing system. To maximize profits, we take a revenue management approach. However, scheduled replenishments, backlogging and inventory holding differentiate our multi-period demand fulfillment problem from traditional revenue management. We formalize the multi-period problem as a two-stage stochastic dynamic program. The optimal solution balances the expected marginal profits of the customer classes in different demand periods. However, due to the curse of dimensionality and the complexity of the model, the exact problem is computationally intractable. We therefore propose an approximate dynamic programming heuristic. In numerical tests, the heuristic results in total profits close to the upper bound of an ex-post optimization. The proposed method also provides a basis for decentralization methods using clustering for hierarchical customer structures.", :title "A dynamic programming approach to demand fulfillment in make-to-stock manufacturing systems", :keyword2 165, :authors (49192 4229), :session 226}, 474 {:keyword1 96, :keyword3 154, :abstract "We study scheduling in a data gathering network consisting of a set of worker nodes and a single base station. The workers produce datasets that have to be sent to the base station for processing. Each dataset can be released at a different moment. The time required to transfer a dataset to the base station, and the time necessary to process it, are proportional to the dataset size. At most one worker can communicate with the base station at a time, and hence, the network works in a flow shop mode. A dataset transfer or processing can be preempted at any time and resumed later at no cost. Each dataset is assigned a due date by which it should be fully processed by the base station. The scheduling problem is to organize the communication and computation in the network so that the maximum dataset lateness is minimized.\r\n\r\nWe prove that this problem is strongly NP-hard, and show some special cases that can be solved in polynomial time. A branch-and-bound algorithm and several polynomial-time heuristics are proposed for the general version of the problem. The performance of the algorithms is tested in a series of computational experiments.", :title "Scheduling in a data gathering network to minimize maximum lateness", :keyword2 153, :authors (18193), :session 161}, 478 {:keyword1 96, :keyword3 185, :abstract "An important problem in railway management is to realise the train timetable with minimal resources, congestion, and satisfying (sometimes) complicated practical constraints. We address the rail scheduling problem with rolling stock optimization and incorporate practical constraints like headway, dwell, turnaround, symmetry, rake linkage constraints etc. We formulate the problem as Mixed Linear Integer Program (MILP). We extend the model to include platform availability, car shed and siding constraints at different stations.\r\n\r\nWe present a case study based on the suburban network of Mumbai, where we model both the periodic and an aperiodic versions of the timetabling problem. This timetabling activity is done after the number of services have been decided by line planning activities. The advantages and disadvantages of aperiodic and periodic timetables have been discussed.  While the focus of the periodic timetable has been on the periodicity of services and therefore quality, the aperiodic timetable is shown to better utilize the resources available without any significant degradation in quality.\r\n\r\nThe model permits experimentation in timetabling options which subsequently help to increase the number of services/throughput and identify the infrastructure bottlenecks.\r\n", :title "Rail Scheduling for commuter services with resource optimization - a case study on Mumbai suburban harbour line rail network", :keyword2 158, :authors (28300 57622 58460 58456 59799 58499), :session 210}, 479 {:keyword1 28, :keyword3 0, :abstract "The classical Unit Commitment problem (UC) can be essentially described as the problem of establishing the energy output of a set of generation units over a time horizon, in order to satisfy a demand for energy, while minimizing the cost of generation and  respecting technological restrictions of the units (e.g., minimum on/off times, ramp up/down constraints). The UC is typically modelled as a (large scale) mixed integer program and its deterministic version, namely the version not considering the presence of uncertain data, has been object of wide theoretical and applied studies over the years. \r\n\r\nTraditional (deterministic) models for the UC assume that the net demand for each period is perfectly known in advance, or in more recent and more realistic approaches, that a set of possible demand scenarios is known (leading to stochastic or robust optimization problems).\r\n\r\nHowever, in practice, the demand is dictated by the amounts that can be sold by the producer at given prices on the day-ahead market. One difficulty therefore arises if the optimal production dictated by the optimal solution to the UC problem cannot be sold at the producer's desired price on the market, leading to a possible loss. Another strategy could be to bid for additional quantities at a higher price to increase profit, but that could lead to infeasibilities in the production plan.\r\n\r\nOur aim is to model and solve the UC problem with a second level of decisions ensuring that the produced quantities are cleared at market equilibrium. In their simplest form, market equilibrium constraints are equivalent to the first-order optimality conditions of a linear program. The UC in contrast is usually a mixed-integer nonlinear program (MINLP), that is linearized and solved with traditional Mixed Integer (linear) Programming (MIP) solvers.  Taking a similar approach, we are faced to a bilevel optimization problem where the first level is a MIP and the second level linear.\r\n\r\nIn this talk, as a first approach to the problem, we assume that demand curves and offers of competitors in the market are known to the operator. This is a very strong and unrealistic hypothesis, but necessary to develop a first model.  Following the classical approach for these models, we present the transformation of the problem into a single-level program by rewriting and linearizing the first-order optimality conditions of the second level. Then we present some preliminary results on the performance of MIP solvers on this model. Our future research will focus on strengthening the model using its structure to include new valid inequalities or to propose alternative extended formulations, and then study a stochastic version of the problem where demand curves are uncertain.\r\n", :title "Unit Commitment under Market Equilibrium Constraints", :keyword2 162, :authors (55546 25372 1 53481), :session 189}, 481 {:keyword1 95, :keyword3 0, :abstract "We study a variant of the vehicle routing problem with multiple compartments in which compartment sizes are flexibly adjustable in discrete steps.  Additionally, a last-in-first-out unloading policy has to be considered since rearranging of cargo on the load bed is prohibited. This problem occurs as a special case at a German food retailer that has to supply a large number of hypermarkets on a daily basis. Transported products are divided into several categories based on the transport temperature. Due to these different temperatures, it is expedient to use trucks with multiple compartments. Moreover, the retailer engages various forwarders for transportation. Forwarders are paid according to pre-negotiated tariffs based on the different product categories. This leads to a cost function which differs a lot from the common distance minimization.\r\nWe propose an iterated tabu search with two different perturbation mechanisms to solve this challenging vehicle routing problem. Various computational experiments with real data from the retailer are performed to assess the performance of our algorithm. Comparisons with results obtained by employing a mixed integer program and solving this with a commercial solver show that the iterated tabu search consistently produces high quality solutions.\r\n", :title "An iterated tabu search for the vehicle routing problem with multiple compartments and last-in-first-out unloading", :keyword2 59, :authors (54047), :session 153}, 484 {:keyword1 8, :keyword3 188, :abstract "The matching preclusion number of a graph is the minimal number of edges whose removal destroys all perfect matchings. We provide algorithms and hardness results for the task of increasing the matching preclusion number from one to two in bipartite graphs at minimal cost. Our motivation is to make matchings of a graph robust against the failure of a single edge. Our methods rely on a close relationship to the classical strong connectivity augmentation problem. For the unit weight problem we provide a deterministic log n-factor approximation algorithm, as well as polynomial-time algorithms for graphs of bounded treewidth and chordal-bipartite graphs. For general weights we prove a dichotomy theorem characterizing minor-closed graph classes which allow for a polynomial-time algorithm.\r\n", :title "How to Secure Matchings Against Edge Failures", :keyword2 42, :authors (55372 49158 59800 59931), :session 54}, 487 {:keyword1 57, :keyword3 0, :abstract "The development of an optimal collateral allocation strategy constitutes a very important issue for financial institutions in the effort to estimate the actual risk they are exposed to. Following regulatory guidelines and rules, these institutions should reserve capital in order to be protected by expected and potential unexpected losses (estimated by means of prescribed formulas provided for by the regulators). In case of a given portfolio of exposures/loans, it is well-known that the main credit risk mitigation factor is the value and the quality of the associated set of collaterals. In the vast majority of cases, a many-to-many relationship exists between a given set of loans and the set of associated collaterals. Thus, utilizing the amount of the underlying collaterals efficiently has a major impact on the growth and strategy of the financial institutions in the sense that the lower the capital held because of regulatory requirements the more the capital available for running business. Various methods to minimize the regulatory capital via optimal allocation of collaterals have been proposed in the relevant literature. In our work, three different approaches are being examined: (i) a simple method based on a rule of proportional allocation, (ii) an integer linear programming formulation suggested by a researcher affiliated with a major investment bank (presented in a conference) (iii) a method developed by the authors of this work which is based on a variant of the well-known transportation problem. In the context of our approach, the relationships between collaterals and loans are represented by means of a bipartite graph, namely, the set of collaterals and that of loans form the disjoint sets of vertices of that graph. An arc between two vertices denotes that a collateral may be used for risk mitigation purposes regarding a loan/exposure. The connected components of this graph are extracted based on the given collateral-loan relationships in order to reduce the time needed for analysis and the complexity of the problem. Next, the level of capital that should be held for regulatory purposes is estimated using the aforementioned approaches in each cluster separately in order to obtain the total regulatory capital needed. Different synthetic datasets are being used along with randomly selected sub-portfolios from a major bank. Our implementations indicate that methodology proposed in the current work provides the lowest estimations. Finally, this work provides theoretical insight regarding the efficiency of the proposed methodology as well. ", :title "A mathematical programming approach for the optimal collateral allocation problem", :keyword2 93, :authors (57872 59801 59802), :session 197}, 488 {:keyword1 75, :keyword3 174, :abstract "The increasing vertical differentiation of supply chains as well as the steadily growing volume of sales of online shopping platforms are two major drivers for the demand of comprehensive logistics services. Despite the increasing demand, there is an intense competition among companies providing such services, exposing them to strong cost pressure. As a consequence, those companies try to  increase their resource utilization by forming transportation networks, transforming LTL to FTL at transshipment points or cross docking terminals. The efficient operation of those networks and consequently of the transshipment points are a crucial task.\r\n\r\nWhile cross-dock operations require extensive planning on various levels, for efficient resource utilization especially two important aspects need to be considered. On the one hand, an assignment of inbound trucks to dock doors decides on the cargo's availability to the transshipment process. However, on the other hand, allocation of limited transshipment resources like fork lifts or conveyor belts impacts the terminals’ overall efficiency with respect to transshipment time or throughput. Both decision problems are highly interdependent and need to be considered together. For example, a poor truck assignment may lead to parts of the terminal being congested, while resources at other parts of the terminal may not be utilized at all. However, a reasonable assignment of scarce transshipment resources may compensate a poor dock door schedule to a certain degree.\r\n\r\nSo far, extensive research has been conducted on the assignment of trucks to dock doors, addressing various problem settings and objectives like makespan. However, the impact of the transshipment process itself on the overall objective is usually only addressed in the form of a constant time delay. Some of the work introduces considerations on travel paths, but so far, there is hardly any work specifically integrating transshipment resource planning and truck scheduling.\r\n\r\nIn this work we present an integrated truck scheduling and transshipment resource allocation problem. We employ a space-time network to model cargo flows and scheduling decisions within the transshipment terminal. Since space-time networks grow very fast with an increasing planning horizon as well as level of detail, we decompose the problem into a scheduling and routing part and apply a Branch-And-Price Algorithm. The approach is evaluated in a comprehensive computational study.", :title "Integrated Truck Scheduling and Transshipment Resource Planning at Cross-Docking Terminals", :keyword2 109, :authors (52394 40497 59805), :session 191}, 489 {:keyword1 161, :keyword3 0, :abstract "Several exact solution methods to solve bi-objective mixed integer linear programming problems have been proposed recently. They mainly belong to two classes of methods: branch and bound methods and methods strongly based on MIP solver. A common point between all those methods is their genericity, i.e. the structure of the problem, when it is present, is not used.\r\n\r\nIn this work, we propose a method dedicated to the exact solution of bi-objective capacitated facility location problem with mixed 0-1 variables problem. The choice to open a facility or not is modeled by a binary variable. Next the opened facilities have a limited capacity and must fulfill the total demand of all the customers. For this purpose, the demand of a customer can be satisfied by several facilities. Hence, the fulfillment of the demand of a customer by facilities is modeled by continuous variables.\r\n\r\nHowever, to our knowledge, the published papers on bi-objective facility location problems deal with binary variables only.\r\n\r\nThe method we propose belongs to the class of the Two Phase Method [1]. First we compute a subset of extreme supported efficient solutions. This is done using Beasley's algorithm [2] to solve single objective capacitated facility location problem. Then as in [3], for each extreme supported efficient solutions we have obtained, the binary variables are fixed. The resulting sub-problems are known as bi-objective minimum cost flow problem. We solve those sub-problems to obtain a strong initialization. Each rectangle in objective space defined by two obtained consecutive supported extreme points, with respect to the first objective, are explored with a branch and bound algorithm. This algorithm is an extension to the bi-objective case of Beasley's algorithm.\r\n\r\nThe method has been implemented in C++ and tested on various instances. The experiments show that the computational time of our proposition is an order of magnitude faster than the full computation of extreme supported solutions.\r\n\r\nReferences:\r\n\r\n[1] E.L. Ulungu and J. Teghem, The two phases method: An efficient procedure to solve bi-objective combinatorial optimization problems. Foundations of Computing and Decision Sciences, 20:149–165, 1995. \r\n\r\n[2] J.E. Beasley, An algorithm for solving large capacitated warehouse location problems. European Journal of Operational Research, 33(3):314–325, 1988. \r\n\r\n[3] T. Vincent, F. Seipp, S. Ruzika, A. Przybylski and X. Gandibleux, Multiple objective branch and bound for mixed 0-1 linear programming:  Corrections and improvements for the biobjective case. Computers & Operations Research, 40(1):498–509, 2013.\r\n\r\n", :title "An algorithm for the exact solution of Bi-Objective Mixed 0-1 Capacitated Facility Location Problem", :keyword2 158, :authors (59598 3693 14848), :session 177}, 490 {:keyword1 175, :keyword3 178, :abstract "This paper proposes an optimisation model of the activity-travel behaviour in the Automated Vehicle (AV)–era and demonstrates how model parameters may be estimated using discrete choice techniques. Our approach improves on the most common approach in the travel behaviour literature, which reduces the size of a single travel time penalty (i.e., disutility parameter) to reflect a lower travel burden thanks to available on-board activities in the AV. However, a broad range of available on-board activities may lead not only to the reduction of travel burden but also to transfers of some activities from stationary locations to the AV. Such activity transfers would free time within the day, which could be used for more (or longer) activities and travel. Activity transfers may also reduce the total travel, if all activities of a given location can be performed on board. These possibilities cannot be captured by the travel time penalty approach.\r\nWe propose a mixed integer linear model (MILM) that captures possible activity re-arrangements in the AV-era. Individuals are assumed to maximise utility by selecting activities and activity locations (stationary or on board of the AV). The constraints ensure that activity-transfer and freed-time effects are captured: the time spent in stationary activities and associated travel should fit within a total time; the duration of on-board activities should not exceed the travel times. In this way, our model captures an interplay among stationary activities, on-board activities and travel: stationary activities (yielding utility) generate a need for travel (reducing utility); travel enables on-board activities (yielding utility); on-board activities may replace stationary activities.\r\nNext, we transform the MILM to enable the estimation of its parameters – the utility associated with different activities at different locations, disutility of travel, as well as the penalty for potential activity fragmentation (splitting any activity among several stationary and/or on-board locations). The transformation consists of converting the hard constraints of MILM into soft ones. This makes the model non-linear, but allows to write it in a single line – as maximisation of the utility function with penalties for constraint-violation. In this formulation, it is possible to use discrete choice techniques and the maximum-likelihood principle to estimate model parameters. In our presentation, we will illustrate the models with hard (MILM) and soft (MINLM) constraints, as well as explain the procedure of parameter estimation.\r\nBy combining techniques from micro-econometrics and operations research, our approach helps to address a crucial policy question associated with the introduction of the AVs: will more pleasant travel in the AVs lead to more kilometres travelled? Our model acknowledges that kilometres travelled is not an isolated indicator but a result of activity-travel patterns before and after the introduction of AVs.", :title "Activity-travel Behaviour in the Automated Vehicle–era: A Mixed Integer Linear Model and Its Estimation with Discrete Choice Techniques", :keyword2 25, :authors (57667 36404 59807 59809), :session 32}, 493 {:keyword1 45, :keyword3 0, :abstract "The budgetary allocation for public hospitals has been increased over the period by the government of developing countries being important segment of the economy. For this reason, it is, therefore, necessary to measure the efficiency of public hospitals. This research paper attempts to explore the technical efficiency of Pakistani public hospitals through a non-parametric technique called Data Envelopment Analysis. Researchers selected number of doctors and number of nurses as input variables while number of outpatients, number of indoor patients and number of major and minor surgery were taken as output variables. The sample of the study consist of 80 public Tehsil Headquarter hospitals of Punjab Province and data was collected for the period 2016-17 from the DHIS (District Health Information System) office of Director General Health Services, Punjab, Lahore. This research concluded that average efficiency of public Tehsil Headquarter hospitals in the Punjab Province was 0.53 during the period under analysis. Out of 80 hospitals, only 6 were performing on the efficient frontier with 1 efficiency score. The results of DEA technique reveals that there is urgent need to improve the delivery of health services at Tehsil Headquarter level. It is recommended that number of beds, number of doctors and paramedic staff should be increased according to the population catchment. An incentive system to attract the human resource in rural areas should be introduced and a proper monitoring system may also be launched to provide best health facilities to the public. The results of the present study are useful for health mangers, research scholars and policy makers.", :title "Measuring the technical efficiency of public hospitals: Empirical evidences from Punjab, Pakistan", :keyword2 0, :authors (59804 42334), :session 174}, 495 {:keyword1 96, :keyword3 63, :abstract "In modern pharmacy, cutting edge bio-medicine research allows for ever more effective treatment of many severe diseases. However, scaling the production of medicine arising from such research up to an industrial level offers unique challenges in strategic and operative planning and scheduling. In this talk, we attempt to consider these challenges both from a theoretical as well as a practical point of view.\r\n\r\nAt the heart of the industrial problem that we study, there lies a variant of a hybrid flow shop scheduling problem. The production process is split up in several stages, where each stage consists of one or more parallel machines. In each stage, the machines are identical, but in some stages machines may be able to process jobs in batches, rather than one job at a time. A job must be processed by the stages in order and is completed when its processing finishes on the last stage. Processing times are job independent, i.e. on one stage all jobs need the same amount of processing time (in traditional flow shop literature, this is sometimes called proportionate flow shop). We briefly give an overview over known easy and hard cases of this problem, before turning to the practical application.\r\n\r\nIn the real world problem, there are many additional challenges to solve, beyond the solution of the core problem from above. We can only name some of them in this abstract:\r\n•\tthe arrival time of jobs is no longer completely predictable, although some restrictions can be set by the decision maker, like the number of jobs that can arrive on a specific day; this leads to a ‘controlled’ variant of online scheduling \r\n•\tprocessing stages may, with a certain probability, cause errors, which make it necessary for the jobs to suffer a longer than normal processing time; some jobs even have to be returned to a previous stage in order to restart processing from there\r\n•\tapart from the processing of jobs, machines need a pre-processing step, in which they are prepared for use, and a post-processing step, in which they are cleaned; these need to be scheduled proactively, if possible, such that once a job arrives, processing can start immediately\r\n•\ttransportation of jobs between machines also has to be considered, since most of the processing needs to be done in sterilized rooms and transport between those rooms involves time-consuming locking steps\r\n\r\nIt is easy to see that these and other features provide significant scope for optimization, both in strategic planning (e.g. design of a new production site) as well as in the actual operation of the process. We will attempt to classify the features we observe and will provide a first insight in how to solve the resulting complex problem in practice, both conceptually and computationally.\r\n", :title "Planning Modern Pharmaceutical Production", :keyword2 45, :authors (59771 23161 59599 59808 19477), :session 159}, 496 {:keyword1 14, :keyword3 164, :abstract "In this talk, we consider nonlinear semi-infinite programs with semi-definite matrix constraints and infinitely many convex inequality constraints, called NSISDP for short. Although the NSISDP has important applications such as FIR filter design problems, robust beam forming problems, and so on, it has not been studied sufficiently so far. Our aim in this research is to design a new algorithm for the NSISDP. We actually propose an algorithm that follows central path consisting of barrier Karush-Kuhn-Tucker (KKT) points of the NSISDP. We show that a sequence generated by the algorithm weakly * converges to a KKT point under Slater's constraint qualification.\r\n\r\n Furthermore, to achieve rapid convergence, we incorporate the local reduction SQP method, which is one of classical methods developed for semi-infinite programs, into the above algorithm. Also, we find a dual optimal matrix solution associated to the semi-definite constraint by solving scaled Newton equations. We show that a sequence generated by the second algorithm converges to a KKT point two-step superlinearly under some regularity condition. Finally, we report some numerical results to demonstrate the efficiency of the proposed methods.\r\n\r\nThe proposed methods may be viewed as an extension of the primal-dual interior point method for the nonlinear SDPs proposed by Yamashita et al. (2012) (H. Yamashita, H. Yabe, and K. Harada, A primal–dual interior point method for nonlinear semi-definite programming, Mathematical Programming, 135 (2012), pp. 89–121). However, the extension is not straightforward due to the existence of the semi-infinite constraints. ", :title "A primal-dual path following method for nonlinear semi-infinite program with semi-definite constraints", :keyword2 173, :authors (24047 26135), :session 182}, 497 {:keyword1 36, :keyword3 59, :abstract "In this work, we introduce and analyze an extension of the Linear Ordering Problem (LOP). The LOP aims to find a simultaneous permutation of rows and columns of a given weight matrix such that the sum of the weights in the upper triangle is maximized. We propose the weighted Linear Ordering Problem (wLOP) that considers individual node weights in addition to pairwise weights. \r\n\r\nThe wLOP is both of theoretical and practical interest. First, we show that the wLOP generalizes the well-known Single Row Facility Layout Problem by allowing asymmetric cost structures. Additionally, we argue that in several applications of the LOP, the optimal ordering obtained by the wLOP is a worthwhile alternative to the optimal solution of the LOP. As an example, let us consider the arrangement of objects in a row. The pairwise object weights define the preference of arranging one object before another. Additionally, objects with high pairwise weights should be positioned far away from each other and accordingly objects with no or few pairwise weights should be placed in the middle part of the ordering. Modelling this problem as a wLOP allows to additionally consider the distances between the objects in the objective function through their assigned node weights.\r\n\r\nWe introduce an Integer Linear Programming formulation and well-performing heuristics for solving the wLOP. Finally, we provide a large benchmark library and demonstrate the efficiency of our exact and heuristic approaches on these instances in a computational study.", :title "The Weighted Linear Ordering Problem", :keyword2 158, :authors (59753 30955 59751 50992 59752), :session 52}, 498 {:keyword1 180, :keyword3 124, :abstract "Ensemble learning has shown its significance in many machine learning problems like computer vision applications, bioinformatics, finance and it has also great impact and bases in subfields of AI such as deep learning. In this study, we propose a novel ensemble learning model to classify financial status of banks in Turkey. The data set includes the 1997-2001 period when the Turkish banking system was undergoing a severe collapse and almost half the commercial banks were transferred to the SDIF (Savings and Deposits Insurance Fund). Support Vector Machine (SVM) is chosen as a base learner of the ensemble with linear, Gaussian, polynomial, and sigmoid kernel functions to provide diversity within the ensemble. The novelty of the proposed approach is attained with including a methodology of model selection by using functional margins on predictions by L1, L2, and L∞ norms to maintain accuracy and diversity dilemma in Ensemble Library. The predictions of each learner in the ensemble are aggregated by voting. The classification performance of the proposed ensemble learning is compared with single classifier SVM on a pooled data. ", :title "A Novel Approach for Generation of Ensemble Library by Using Functional Margins on Longitudinal Bankruptcy Data ", :keyword2 149, :authors (11028 22618 56578), :session 202}, 499 {:keyword1 86, :keyword3 0, :abstract "We study the Net Present Value (NPV) of a project with multiple stages that are executed in sequence. A cash flow (positive or negative) may be incurred at the start of each stage, and a payoff is obtained at the end of the project. The duration of a stage is a random variable with a general distribution function. For such projects, we obtain exact, closed-form expressions for the moments of the NPV, and develop a highly accurate closed-form approximation of the NPV distribution itself. In addition, we show that the optimal sequence of stages (that maximizes the expected NPV) can be obtained efficiently, and demonstrate that the problem of finding this optimal sequence is equivalent to the least cost fault detection problem. We also illustrate how our results can be applied to a general project scheduling problem where stages are not necessarily executed in series. Lastly, we prove two limit theorems that allow to approximate the NPV distribution. Our work has direct applications in the fields of project selection, project portfolio management, and project valuation.", :title "Moments and distribution of the NPV of a project", :keyword2 0, :authors (19453), :session 156}, 500 {:keyword1 120, :keyword3 177, :abstract "With the progressing digitalization in manufacturing continuously increasing amounts of data are being generated. This opens up various possibilities to utilize these data to improve production processes by supporting decision-making. The field of data analytics plays an important role in this context. Data analytics advances the acquisition of knowledge from data and, thus, decision-making in manufacturing and related processes such as maintenance.\r\n\r\nEven if the importance of data analytics in the manufacturing context is undisputed, manufacturing companies are still in the early stages of the implementation and also predominantly use backward-looking types of data analytics. Identifying the current status of data analytics in the manufacturing environment reveals potential in this area and builds the basis for future developments.\r\n\r\nThis paper presents a theory-driven maturity model for the classification of data analytics use cases in the context of data utilization for analytics in manufacturing. Furthermore, the model aims to offer a subcategorization of the vast and complex topic of data analytics for manufacturing purposes. Different types like descriptive, predictive and prescriptive data analytics are integrated into the model. Up to the level of predictive data analytics, data-driven approaches like data mining play a major role. The potential of decision support beyond predictive data analytics can be achieved through the integration of prescriptive data analytics and the combination of data-driven and model-driven approaches. By its very nature, model-driven approaches need a model of the analyzed problem beforehand. The knowledge derived from data analytics allows for enhancing model-driven approaches by using its insights as input, e.g. for the implementation of specific operations research models and methods. Based on this differentiation, the stages of the maturity model are derived.\r\n\r\nThe model is verified using the example of predictive maintenance in the laser application of TRUMPF GmbH & Co. KG. With TRUMPF Condition Monitoring, both algorithms and service experts monitor the conditions of customer laser devices for the purpose of reducing unplanned downtime and thus increasing availability and productivity of connected laser systems. If a laser is at risk of malfunction, e.g. due to a decreasing cooling water level or due to a polluted filter, a warning is given proactively.\r\n\r\nThe use case for Condition Monitoring of connected lasers in the manufacturing environment is examined and classified in the developed model. The major potential of predictive data analytics is highlighted and first ideas towards prescriptive data analytics are presented. However, the use case also emphasizes the importance of human experience and interaction, factors that still play a significant role in the process of generating knowledge and deriving decisions.", :title "A maturity model for the classification of real-world applications of data analytics in the manufacturing environment", :keyword2 167, :authors (59806 59811 59681 59812 59813 59814), :session 46}, 501 {:keyword1 156, :keyword3 0, :abstract "The goal of sequential testing is to discover the state of a system by testing its components one by one. We consider n-out-of-n systems, which function only if all n components work. The testing continues until the system state (up or down) is identified. The tests have known execution costs and failure probabilities and may be subject to precedence constraints. The objective is to find a sequence of tests that minimizes the total expected cost of the diagnosis. We show how to strengthen the precedence graph without losing all optimal solutions. We examine different formulations for the problem, and propose a dynamic-programming (DP) and a branch-and-price algorithm. Our computational results show that our DP noticeably outperforms the state of the art. Using a novel memory management technique, it significantly increases the size of the instances that can be solved to optimality under practical memory and time limits.", :title "Sequential testing of n-out-of-n systems: Precedence theorems and exact methods", :keyword2 96, :authors (39141 19453 10607), :session 162}, 502 {:keyword1 96, :keyword3 157, :abstract "In manufacturing industry, complex products often require a large list of intermediate products and resources to be produced, before the final product can be fabricated. In some areas, such as plant manufacturing, the production of these intermediate materials cannot be outsourced and is done by the companies themselves. This is the case, for example, if a specific quality is expected from the materials or if the know-how of the company actually lies in producing these intermediate materials, leading to a much better end product. For instance, when building a factory, a construction company may want to produce its own concrete, or its own doors, as special security features may be needed. \r\n\r\nThese intermediate products can be produced in large amounts at the same time, and then be used in further production steps of several different final products. Also, it is not necessarily clear from the beginning, or even when an intermediate product is produced, which end product it will be used for. Thus, the relation between producing and consuming jobs can no longer be modelled as simple precedence constraints, since a particular producing job cannot be assigned to a particular consuming job.\r\n\r\nThis motivates the definition of a new class of scheduling problems with prefabrication, where some jobs, called consumers, may start processing only if specified amounts of materials are available. These materials are produced by other jobs, called producers. In contrast to usual precedence constraints, the assignment of materials (and thereby producers) to consumers is part of the problem, resulting in what might be seen as dynamic precedence constraints.\r\n\r\nWe introduce the problem of scheduling with prefabrication in general and characterize different problem classes. In order to give a clear overview of the complexity of this problem, we focus on the version of the problem where only one material type is produced and consumed, and the production environment consists of only one machine. For this version, we identify NP-hard cases, and provide exact polynomial algorithms where possible.\r\n", :title "Scheduling with Prefabrication", :keyword2 86, :authors (57474 59721 32597 59771), :session 159}, 503 {:keyword1 45, :keyword3 96, :abstract "The current nursing shortage coupled with a continuously growing number of care-dependent patients necessitates efficient and effective planning and scheduling of available nursing staff. From a medical perspective, nurse staffing levels should be sufficiently high to assure adequate treatment. From a provider perspective, budget concerns and employee satisfaction need to be considered as well. In a large emergency department that faces highly volatile patient demand levels both in quantity and quality, matching supply and demand by means of scheduling becomes an especially challenging problem. Our modeling approach introduces an adjusted nurse-to-patient ratio (ANPR) to capture expected hourly nurse utilization rates in a shift assignment problem. Further incorporating legal work time and qualification constraints as well as employee shift requests, the model allows us to significantly improve on existing, manually generated schedules in one of Germany’s largest emergency departments with respect to balanced nurse utilization rates, granted shift requests, and higher expected ANPR minima. Finally, we also investigate the potential gains that could be achieved by redesigning the shift structure currently used at our practice partner.", :title "Emergency Department Nurse Scheduling in a German Hospital", :keyword2 158, :authors (49216 59836), :session 171}, 504 {:keyword1 155, :keyword3 100, :abstract "Many variables and type of considerations are involved in the question of when to stop marketing a given product and to initiate another lifecycle for that product. In this study financial aspects are addressed and modeled. The aspects of the consumers with respect to their motivation to replace a product is taken in consideration. The role of technology and the R&D period are considered as well. The financial criterion for success is to maximize the discounted net cash flow or the equivalent annuity stream for a given period of time, e.g. a year, a decade etc. The initiation of another cycle is independent of when the current cycle terminates, but is functionally related to its length. Managerial and operational constraints are included, as well as market share constraints. The problem is solved for various functional forms. The resulting rules are expressed in managerial terms, for example, as a function of peak of cash flow, cumulative cash flow, level of cash flow, and the length of the R&D period. Some numerical examples for all cases are provided to illustrate the rules resulting from the models.", :title "Financial Issues in Setting Optimal Product Life cycle Policy", :keyword2 35, :authors (2236 51498), :session 196}, 505 {:keyword1 2, :keyword3 0, :abstract "In this talk, we validate a data-driven approach to the extrapolation of airlines preferences in the European airspace. Consider an origin-destination airport couple: why does airline A typically fly a route different from the trajectory usually chosen by airline B? Using a range of data analytics machinery, we show how this question can be precisely formulated; we also outline an answer by demonstrating how to model airline preferences in the planning phase, i.e. up to three hours prior the flight departures.\r\nIncluding airline preferences in Air Traffic Flow Management (ATFM) mathematical models is becoming of high relevance. These models aim to reduce congestion (en-route and at both departure and destination airports) and maximize the Air Traffic Management (ATM) system efficiency by determining the best trajectory for each aircraft. In this framework, the a-priori selection of possible alternative trajectories for each flight plays a crucial role. \r\nIn selecting a route among a set of alternatives, one should consider factors like route length, duration, operation time, en-route charges, fuel consumption, etc.; some of these are not always fully known. Moreover, quite often the actual operated route is different from the planned one because of weather conditions, congestion, direct routes available at flight time etc. Our solution is to use, in an unsupervised machine learning context, initial trajectories queried from EUROCONTROL DDR2 data source. Trajectory clustering forms route groups that are homogeneous with respect to known (3D geometry of the trajectory, time) and partially known or unknown factors (en-route charges, fuel consumption, weather, etc.). Association between grouped trajectories and potential choice-determinants are successively explored and evaluated, and the predictive value of the determinants is finally validated. For a given origin-destination pair, this ultimately leads to determining a set of flight trajectories and information on related airline preference and priorities. \r\n", :title "Data analytics for trajectory selection and preference-model extrapolation in the European airspace", :keyword2 124, :authors (58072 18188 62522), :session 45}, 506 {:keyword1 5, :keyword3 19, :abstract "Classification is one of the most used tools from machine learning, one of its prominent applications is security, where a ``defender\" trains a model (classifier) from a classified data set and then uses this model to classify new data (feature vector) so as to detect attack, while a smart adaptive ``attacker\" can cover up his attacks by noising the feature. This offers a complex learning setting, where the ``defender\" uses classifier as the strategy to minimize the loss of the unsuccessful attack detection, while the ``attacker\" uses a noised feature vector as the strategy to minimize his cost in case of detection and optimize his reward in case of successful attack. The two optimization problems have coupled objective functions jointly constrained by a convex optimization problem (with parameter) involved in the training procedure, and this offers the so-called generalized Nash equilibrium problem. \r\n\r\nIn this talk we present a systematical investigation of this complex learning setting from an equilibrium perspective, which is different to the regular machine learning approach. We study the existence of the equilibrium solutions, propose a numerical method for computing the sparse solutions, which automatically make an efficient feature selection. Numerical results are also presented for supporting our theoretical analysis.\r\n\r\n", :title "Generalized Nash equilibrium problem with equilibrium constraint for modeling adversarial classification", :keyword2 13, :authors (55676 4796), :session 242}, 507 {:keyword1 174, :keyword3 0, :abstract "Efficient order picking requires a coordinated way of combining and utilizing three kinds of resources: articles customers are demanding, devices to pick articles according to customer orders, and operators working at the devices. The focus of this contribution is on warehouses where resources of each type are heterogeneous. Articles differ in their handling requirements, devices – in their degree of automation, and operators – in their qualification to work at certain devices. Hence, the decisions of assigning articles to devices and allocating manpower among devices are interdependent. Since the assortment of articles is subject to permanent adaptations, both decisions need to be adjusted and the problem has to be solved frequently for similar instances. Numerical analyses reveal that an exact approach would not be able to solve real-sized problem instances within the time span between two assortment changes. For this reason we propose a hybrid way of combining exact and heuristic solution approaches. The exact approach is utilized, though less frequently, to make the interdependent decisions simultaneously and to reset the system from time to time to an optimal state. In order to adjust the system setup to each assortment change, a heuristic approach featuring metamodel-based optimization is used: At first the manpower allocation is predicted inductively and then a general-purpose solver is applied to determine the article-to-device assignment. In this case, the metamodel maps the relation between the characteristics of both, articles and devices, observed for a large number of different assortments and the corresponding optimal manpower allocation determined by the exact approach. Since the workforce and the portfolio of devices in one warehouse are relatively stable, the response of this model to modified assortments represents an anticipated near-optimal manpower allocation.\r\nIn the planned contribution the way of decomposing the problem, selecting the metamodel type, building the metamodel and estimating it is substantiated by statistical results gained from a numerical study using sampled data of a pharmaceutical wholesaler. A comparison of exact and heuristic approaches with regard to solution quality and time for solving a set of out-of-sample instances reveals the benefit of combining both.\r\n", :title "Metamodel-based optimization of the article-to-device assignment and manpower allocation problem in order picking warehouses", :keyword2 109, :authors (26613 20832 29732), :session 164}, 508 {:keyword1 95, :keyword3 174, :abstract "Within an era of growing e-commerce and home deliveries, user-centered logistics that allow for a high customer satisfaction gain in importance. In this context, offering short and precise delivery time windows to customers remains one of the most critical issues that heavily affects the customer’s satisfaction. Herein, a goal conflict between a logistics provider’s operational flexibility and the offered time windows exists. To facilitate an optimal planning of a logistics fleet that operates within this context, an algorithmic framework that is capable of handling multiple time windows is necessary. Such a framework allows to allocate delivery time slots to customers and thus to reduce the customers’ latency at home.\r\nAgainst this background, we study the Vehicle Routing Problem with Multiple Time Windows (VRPMTW) that determines a set of optimal routes such that each customer is visited once within one out of several given time windows. Solving the VRPMTW helps to create feasible route plans for a logistics fleet and to estimate a convenient delivery time window for each customer. We present a large neighborhood search (LNS) based matheuristic which is enhanced by a dynamic programming (DP) procedure. Herein, the DP enhances our algorithm by a non-trivial optimal assignment of time windows for each customer on a route. Besides, we present computationally efficient move descriptors for the used (local) search operators. We evaluate the performance of our algorithm on the Belhaiza instance set and find new best known solutions for 20 out of 49 instances.\r\n", :title "A large neighborhood search metaheuristic for the vehicle routing problem with multiple time windows", :keyword2 59, :authors (59780 52258 19320 2650), :session 153}, 509 {:keyword1 29, :keyword3 8, :abstract "The nuclear reload pattern optimisation represents a complex and challenging task from mathematical perspective. Usually fuel assemblies are given and a suitable set of mutually different reload patterns is to be found. \r\n\r\nThis is important in particular in the case of multicycle optimisation which might be sensitive to small changes (perturbations) in the chain of reload patterns. \r\n\r\nWe first review some methods from literature and show their behaviour from practical point of view, i.e. regarding speed of convergence, quality of the solution and stability of optimisation process. \r\n\r\nWe discuss then an attempt to the design based on a deeper mathematical investigation of the solution space and by using parallel algorithms. Mainly we are interested in getting very good approximations during available (usually short) computational time.\r\n", :title "On a speed-up in finding multiple reload patterns for nuclear reactors of WWER type", :keyword2 162, :authors (36906), :session 194}, 510 {:keyword1 109, :keyword3 0, :abstract "In warehouse design, appropriately dimensioning the storage and retrieval system requires a reliable performance prediction of the system. Such an estimate can be obtained by analyzing the system throughput under steady-state conditions using simulation models or analytical approaches. The expected maximum system throughput is largely influenced by the storage and retrieval strategy, which defines the way in which storage and retrieval requests are executed during warehouse operation. Given a set of requests to be processed, the strategy partitions the set into operation cycles of the storage and retrieval system and allots appropriate storage locations to each request. The rule governing the allocation of storage locations to requests is referred to as storage assignment strategy. Disregarding the time savings achieved by operating the warehouse under an optimal storage assignment strategy may heavily bias the system throughput analysis.\r\nIn this paper, we investigate the performance of a storage and retrieval system executing single-command cycles to serve a random storage. We assume that storage and retrieval requests of different stock keeping units are released according to independent Poisson processes and are executed in the sequence of their arrivals. The system's performance is measured in terms of the expected maximum system throughput, which is obtained from the reciprocal expected cycle time. The storage assignment strategy considered in our work is the closest eligible location rule, which for each arriving storage or retrieval request selects a storage location allowing for a minimum total cycle time. Since this rule selects the eligible storage location with minimum sum of storage and retrieval cycle times, it is the optimum online storage assignment strategy for single-command cycles.\r\nFor the performance analysis, we propose a mathematical model relying on the theory of Gordon-Newell networks. We show how to construct a set of closed queueing networks whose steady state behaviors describe the long-run performance of a storage and retrieval system operating under the assumptions established above. Based on a stationary analysis of the queueing networks, we obtain closed-form expressions for the expected cycle time and further key performance indicators. In a numerical experiment including large-scale instances, we investigate characteristic curves of the expected cycle time and the obsolescence of inventory for varying number of stock keeping units. A comparative analysis with alternative approaches from the literature reveals that first, the existing methods may significantly underestimate the maximum system throughput, that second, the closest eligible location rule allows for significant savings in cycle times, and that third, in contrast to a conjecture issued in the literature, obsolescence of inventory should not be considered an obstacle to implementing the closest eligible location rule as the storage assignment strategy.", :title "A queueing approach for performance analysis of automated storage and retrieval systems under single-command cycles", :keyword2 88, :authors (52268 930), :session 191}, 515 {:keyword1 28, :keyword3 29, :abstract "We present a novel optimization-based bidding method for the participation of combined heat and power (CHP) units in the day-ahead electricity market. More specifically, we consider a district heating system where heat can be produced by CHP units or other heat-only units, e.g., gas or wood chip boilers. We use a mixed-integer linear program to determine the optimal operation of the portfolio of production units and storages connected to the district heating system on a daily basis. Based on the optimal production of subsets of the units, we can derive the bidding prices and amounts of electricity offered by the CHP units for the day-ahead market. The novelty about our approach is that the prices are derived by iteratively replacing the production of heat-only units through CHP production. Due to the limited capacity of the system, the offered production by CHP units is replacing heat production in hours with the highest electricity price forecast in the planning horizon. This results in an algorithm with a robust bidding strategy that does not increase the system costs even if the bids are not won. We analyze our method on a small realistic test case to illustrate our method and compare it with other bidding strategies from literature, which consider CHP units individually. The analysis shows that considering a portfolio of units in a district heating system and determining bids based on replacement of heat production of other units leads to better results.", :title "A novel optimization-based bidding method for combined heat and power units in district heating systems", :keyword2 158, :authors (45137 59815 53611 41082), :session 7}, 516 {:keyword1 175, :keyword3 95, :abstract "The potential use of light unmanned vehicles (typically drones or robots) to transport goods is currently gaining larger interest in both the industrial and academic communities. Directly inspired by an industrial application currently under development at a large European mobility provider, we evaluate in this contribution how vans and unmanned vehicles can be combined in the context of parcel delivery. In particular, we consider the situation where drones or robots are embedded into the delivery vans themselves. When it is efficient to do so, these light unmanned ressources can leave the vehicle with parcels to be delivered at customer locations, and thereafter come back to the van to be refilled and recharged. While drones and robots are cost efficient and more agile but suffer from low range as well as room space for parcel storage, vans are relatively more expensive and induce a larger ecological footprint but offer on the other hand larger autonomy and capacity. In a static day-ahead context, our dedicated metaheuristic generates solutions that allow to take advantage of the specific characterisitics of each of these transport modes. As a result, we show that, while autonomy and capacity issues prevent from implementing a delivery fleet consisting only of unmanned vehicles, synchronizing them efficiently with vans offers room for substantial cost savings in comparison to a classical fleet including vans only.", :title "Mixed Fleet of Vans and Embedded Autonomous Vehicles for Parcel Delivery", :keyword2 174, :authors (31468 55878 55877), :session 214}, 517 {:keyword1 28, :keyword3 158, :abstract "Power is traded in Europe within and across different regions and countries on multiple markets with different time horizons. Examples for such markets are the day-ahead market, the intraday market, and reserve markets. In the day-ahead market and the intraday market sellers and buyers can agree on the delivery of power for the next and the current day. The market participants are typically production and distribution companies and large consumers. In reserve markets, reserve power is offered to system operators in order to cope with imbalances on the power grid. Reserve markets differ by activation time of the reserve power, which includes automatic activation within seconds or manual activation. With the advent of electricity generation by wind and solar power the demand for reserve power is growing and the role of these auctions becomes increasingly important.\r\n\r\nMarket mechanisms consist of an allocation problem and a pricing problem and receive the bids of the buyers and sellers as input. The bids contain information about the bidding price and the volume that is requested or offered. Given the bids, the market mechanisms determine which bids are accepted to which amount and the value of the market prices. A common goal for the mechanisms is to optimize the welfare of the market participants but also other objectives are used in practice. The prices are typically the clearing prices for a region and period or the bidding prices.\r\n\r\nMarket participants in electricity markets face complex physical constraints that limit the set of feasible allocations. For instance, a power plant often cannot be started up and shut down from one period to the next. Thus, ramping constraints and block orders that model the dependencies between multiple periods have to be taken into consideration. These and other physical constraints create the need for complex bidding languages that support combinatorial bids, which leads to mixed integer problems.\r\n\r\nThe representation of the power grid is another important factor in the design of auction mechanisms for electricity markets. A sound mathematical model of the grid is needed to ensure that flows induced by trades satisfy all the physical limitations of the grid. However, since Kirchhoff’s circuit laws introduce non-convex constraints they often cannot be considered directly in the auction mechanisms. Instead, the power flow is usually expressed in form of linear models. The selection of a suitable model is crucial as it influences the outcomes of the auction mechanisms and prevents physically infeasible allocations. \r\n\r\nN-SIDE is developing auction mechanisms for transnational and local energy markets. Among the mechanisms developed by N-SIDE is the coupling algorithm for the European day-ahead market, which is used to determine the spot prices and volumes for 23 European countries. We will provide a brief introduction into some of these mechanisms and discuss the role of Operations Research in their design.", :title "Auction mechanisms for electricity markets", :keyword2 6, :authors (59816), :session 46}, 520 {:keyword1 8, :keyword3 48, :abstract "Electricity production via solar tower power plants is an important new technology in the renewable energy sector. A solar tower power plant consists of a receiver mounted atop of a central tower and a field of movable mirrors called heliostats. The heliostats reflect and concentrate the solar radiation onto the receiver where a fluid is heated to produce electricity in a conventional thermodynamic cycle.\r\n\r\nIn this talk, we consider aiming strategies for the heliostats. These strategies dictate the way in which the heliostats aim on different locations of the receiver surface. The objective is to maximize the heat transfer inside the tubes of the receiver. However, it has to be taken into account that the receiver surface can be permanently damaged from thermal overloading due to high heat flux densities or sharp heat flux gradients. Consequently, the aiming strategy affects the energy production of the entire power plant as well as the lifespan of the receiver materials.\r\n\r\nOur approach is to model this as a combinatorial optimization problem by only considering a discrete set of possible aiming points at the receiver surface. This allows us to precalculate the images on the receiver of each heliostat aiming at each discrete aiming point. Now, the total energy reaching the receiver induced by a certain aiming configuration can be obtained by linearly superposing the corresponding precalculated images. The originally highly nonlinear objective function becomes now a linear one on the discrete aiming points. Overall, we obtain a mixed integer linear programming (MIP) formulation for the optimization of heliostat aiming strategies.\r\n\r\nNext to the detailed description of the model, we present some preliminary computational results on the PS10 Solar Power Plant. This plant features 624 heliostats and is currently being operated in Spain.", :title "Aiming Strategies in Solar Tower Power Plants", :keyword2 157, :authors (55638 17092 59817), :session 194}, 523 {:keyword1 91, :keyword3 0, :abstract "The demand for cruises as a contemporary form of travel is steadily growing worldwide, as are the number of amenities and passenger capacities of cruise ships ordered and delivered. Hence, cruises not only constitute an increasingly important branch of the global hospitality and maritime industries, but also present a continuously growing revenue potential. However, as the lead time of shipyards limits capacity expansion, cruise lines are forced to use their existing capacities as efficiently as possible in order to maximize revenues – especially with the advent of more sustainable and eco-friendly but also more expensive marine propulsion systems. Thus, given high demand levels cruise lines can profit from the application of revenue management methods that support utilizing capacities efficiently.\r\n\r\nEven though the cruise industry shares some features with the airline, hotel, casino and container liner shipping industries, certain distinct characteristics require the development of customized revenue management approaches. For instance, routes and itineraries of cruises are similar in structure to those in container liner shipping, but the structure of capacity of cruise ships differs from that of container ships. In addition, cruise lines use passenger-based tariff schemes, and short-term as well as long-term customer values are of high importance, similar to the casino business. Most importantly, most customer arrivals are group arrivals, as passenger parties are to be accepted or denied completely and cannot be split up, which poses an additional challenge for the development of effective capacity control methods. Despite these special properties, which are presented briefly in this talk, literature on revenue management for the cruise industry from an OR perspective is still scarce and models encompassing most or all of the specifics are still lacking.\r\n\r\nBased on a simplified cruise network with fixed routes and itineraries, predefined tariff schemes and given customer segments, predictions on the expected passenger on-board revenue, as well as a given demand forecast, a deterministic mixed-integer linear programming model for capacity allocation and total revenue maximization is developed and presented. The resulting partitioned booking limits are nested for use in a capacity control policy for managing cruise sales. The performance of the developed policy is examined using a discrete event simulation and a case study based on publicly available data. The results are compared with the first-come first-served policy with respect to revenues generated and occupancy rates achieved, and the advantages of the new approach are discussed. Finally, implications for further extensions of the model formulation and the capacity control policy are derived from the results of the case study.", :title "Network Capacity Control for a Cruise Line Network", :keyword2 18, :authors (52308 20937), :session 180}, 527 {:keyword1 45, :keyword3 0, :abstract "In a hospital, the decision on how many patients to admit for surgery per week typically affects multiple organizational units. These include downstream resources such as the intensive care units (ICUs) and, in particular, the operating theater (OT).  In this talk, we will discuss how a more detailed consideration of the patients’ path through the OT and ICUs affects the decision on patient admission. We focus on admission planning, the OT and the ICUs and consider mutual effects. A simulation study with realistic data from a large German hospital for thoracic and cardiovascular surgery is applied to derive recommendations for practice. ", :title "An integrated approach for patient admission considering operating theater and intensive care unit scheduling", :keyword2 0, :authors (52493 17358 52549 10057), :session 173}, 528 {:keyword1 18, :keyword3 127, :abstract "To mitigate climate change, the European Union entailed mandatory thresholds on average annual fleet CO<sub>2</sub> emissions for car manufacturers.  These average fleet emissions are determined annually based on the CO<sub>2</sub> emissions of a manufacturer’s new vehicle sales. As the target is based on market sales, car manufacturers face a strategic planning problem that is partly out of their control. While manufacturers decide on internal factors such as offered vehicle portfolio and implemented emission reduction technologies, they are not able to (directly) control external market or policy related factors like customers’ buying behaviour, competitors’ strategic portfolio decisions, or municipality and governmental decisions, e.g., on buying premiums, driving bans or installation of electric vehicle charging infrastructure. Besides, the CO<sub>2</sub> emission threshold is only specified until the year 2025, while the threshold beyond 2025 is currently still subject to discussion. Consequently, manufacturers face a strategic planning problem with inherent interdependencies between internal decisions and (uncertain) market and policy induced external developments in a complex-dynamic environment.\r\n\r\nAgainst this background, we present a hybrid of a simulation environment and an optimization approach to capture both, external developments in the automotive market as well as the influence of optimal internal decisions of the manufacturer. Doing so, we provide decision support for car manufacturers to analyze and identify strategic decisions as well as resulting effects. This approach bases on the integration of an optimization model into a dynamic simulation model. Herein, the optimization model determines the optimal implementation of technology measures within the manufacturer’s car portfolio, while the simulation model accounts for external developments in customer behaviour, competition, infrastructure and legal requirements. Herein, we create a feedback loop providing decision-relevant results of the market simulation model (e.g. vehicle sales information, information on the compliance with the CO<sub>2</sub> threshold) to the optimization model. Vice versa, optimized decisions on the manufacturer’s technology portfolio affect the results of the simulation model in succeeding periods.\r\n\r\nTo verify and validate this modelling approach, we present an exemplary application case based on results from an industry cooperation with a large car manufacturer. Herein, we validated the model using official registration data from 2015 to 2017, and present first results as well as managerial insights.", :title "Towards fleet emission targets in the automotive industry: A hybrid simulation and optimization approach", :keyword2 158, :authors (56427 52258 2650), :session 193}, 529 {:keyword1 75, :keyword3 99, :abstract "We analyze robotized warehouses, where robots move shelves between a storage area and output stations. At every output station there is a person – the picker – who takes items from the shelves and packs them into boxes according to customers' orders. The content of each shelf is different. The customer's orders are random. As a result, some shelves are used more frequently than the others. When the picker does not need the shelf any more, a robot carries this shelf back to the storage area. In the storage area, there are several free places and we need to decide where to put this shelf. Every decision influences the next one. And the sequence of these decisions influences the overall efficiency of the warehouse. We look for an optimal sequence. We develop a simple mathematical model in order to better understand the complex real-world warehouse and to develop optimization algorithms. In this model we neglect refilling of the shelves, because it happen much less frequently than emptying of the shelves at the output stations. We consider multiple scenarios: when we know exactly the future orders (offline), and when we do not know them (online). We test our results with a simulation framework.", :title "Shelf Repositioning in a Robotized Warehouse", :keyword2 109, :authors (39352 27073 59818), :session 164}, 530 {:keyword1 92, :keyword3 101, :abstract "Achieving a resource efficient Europe is one of the flagship initiatives pursued within the EU Strategy 2020 program. Herein, the key concept is to establish circular economies. Among other measures, this requires the analysis of waste streams, the development of feasible technical recycling processes, and the installation of collection and recycling infrastructures. Herein, challenges exist with regard to amount and quality of future waste streams and applicable recycling techniques. Regarding the quality of the waste stream, composite materials often require the development of advanced (and costly) separation techniques in order to allow for recycling. With regard to the quantity of waste streams, high-volume or high-mass innovative products provide challenges as little information is available during the sales period of these products on total market size, speed of market penetration, technical lifetime and product replacement strategies. Rotor blades from wind power plants constructed with fiber reinforced plastics even combine these challenges, i.e. composite materials are used in an innovative product. Thus, technical challenges of the composite materials have to be tackled as well as challenges regarding the expected amounts of the future waste stream. \r\nAgainst this background, we aim at developing a strategic planning approach for the design of appropriate recycling infrastructures for fiber reinforced plastics from rotor blades of wind power plants regarding potential recycling techniques with their expected costs and achievable recycling targets. We develop a multi-period MILP accounting for technology, capacity and location decisions for the recycling of these rotor blades. The model is applied to a case study containing a detailed data set of expected fiber reinforced plastic waste masses from wind power plants, as well as information on established and potential recycling techniques. Scenario and sensitivity analyzes are conducted with regard to influencing parameters, i.e. targeted recycling quotas and expected annual amount and composition of the waste stream. From these analyses, recommendations are derived for legal decision makers and investors.\r\n", :title "Reverse logistic network for fiber reinforced plastic waste from wind power plants", :keyword2 65, :authors (56416 2650), :session 225}, 534 {:keyword1 45, :keyword3 97, :abstract "The number of general practitioners in rural areas has steadily declined in recent years. This has significantly increased the access distances to the nearest general practitioner in the affected regions. Especially for the growing elderly share of the population who are often no longer able to drive a vehicle on their own, this progressively endangers  primary health care. \r\n\r\nA popular approach to overcome these access difficulties are so-called patient transport services. The idea behind these services is to bundle patient transportation requests and to make use of ride sharing to efficiently take patients to their general practitioner at an affordable price. However, this requires a complex planning and scheduling process which is addressed by the dial-a-ride problem. Formally, the dial-a-ride problem is the following: Given a set of vehicles and a set of transportation requests, design feasible vehicle routes and schedules accommodating a maximum number transportation requests at minimal cost.\r\n\r\nFor patient transport services, service quality and convenience are crucial to ensure general acceptance. We therefore present algorithms for the dial-a-ride problem balancing out operational cost against service quality. In order to evaluate their applicability to patient transport services, we test these algorithms in an agent-based simulation environment which models the interactions of patients and general practitioners in primary care on an individual level. This enables us to compare algorithms with respect to their performance as well as quantify the influence and benefits of a patient transport services on the health care system itself. ", :title "The Dial-a-Ride Problem for Patient Transport Services", :keyword2 187, :authors (52270 17092 59946), :session 173}, 538 {:keyword1 169, :keyword3 5, :abstract "Our modern society relies more and more on increasingly interconnected technological infrastructures. Communication systems control terrestrial- and air traffic which requires electrical power supply to assure the logistic of industrial production and consumption of goods. These many mutually dependent networks are vulnerable towards a multitude of external and internal risks.\r\n \r\nTherefore, there is a great interest in the understanding of dynamic resilience concepts and the development of adaptive security structures for an holistic risk management. We summarize the main concepts like graph measures, and present actual examples in the field of safety and security via advanced analytics techniques.\r\n\r\nWe characterize the behavior and present some new optimization approaches which could be embedded in reachback processes. We will explore suitable strategies to make the networks more robust; for example motivated by Moreira in 2009 topological structure optimization, anticipatory strategies and AI instruments are combined in our presentation.\r\n\r\nAs innovative approach we introduce the concept and characterization of a control tower. In an „executive way“, we control the process and present first numerical results. We present the concept of „Executive Towers“ as basis for a suitable management cockpit.", :title "Resilience of Complex Networks - Analysis and Optimization of Critical Infrastructures Systems with Executive Towers", :keyword2 149, :authors (4796), :session 238}, 539 {:keyword1 18, :keyword3 97, :abstract "Unit Load Devices (ULDs) are standard equipment for loading baggage and cargo in airplanes. The maintenance of one's own ULD stock is a non-negligible cost factor for airlines. In recent years, therefore, many airlines have outsourced the management of their ULD's to independent ULD providers. The independent ULD providers should be able to pool the individual ULD stocks and therefore manage the ULD demand with less stock.\r\nAs part of an applied research project, we developed for an ULD provider decision support: \r\n- To determine the daily ULD safety stock levels at a station in order to guarantee a service level for a fixed planning horizon, and \r\n- To control safety stock levels at the stations by balancing empty ULD’s between the stations. \r\nFor the daily safety stock level we built a Monte Carlo simulation which is based on historical data. Extensive live tests showed that our safety stocks work reliable in daily operations.\r\nThe approach to determine the daily safety stock levels will be discussed shortly. The focus of this talk is on the modelling of the decision support for the ULD control. A linear optimization model was built to control the empty ULD movements. The objective was to balance the ULD stock between the stations in order to guarantee enough ULD’s for daily operations. Since we work with a linear model, we are able to compute solutions for huge airline networks in reasonable time. We will present test results of the implemented ULD control for an existing airline network.\r\n\r\n", :title "Development of a consistent approach for inventory control of Unit Load Devices (ULD) in international air transportation", :keyword2 2, :authors (21140 49276), :session 167}, 540 {:keyword1 72, :keyword3 153, :abstract "For the season 2016/2017, the Champions Hockey League (CHL) was performing a Group Stage Draw in which 48 teams had to be drawn out into 16 groups of three teams each. The allocation of the teams to the groups had to be done in a way such that teams coming from the same league were not drawn out into the same group. Furthermore, clubs from leagues where the national teams were participating in the final olympic qualification tournament could also not be drawn out into the same group.\r\nWhenever during the draw the assignment of a team to a group is not possible because it raises a league conflict or an olympic qualification conflict in this particular group, we will call this a “direct conflict”. These are easy to see and can thus be prevented easily. But there are also \"combinatorial conflicts\" which are hard to detect. These are conflicts which arise when a team is allocated to a group in which it does not provoke any direct conflict but the set of remaining teams in the pots cannot be assigned without direct conflicts anymore.\r\nSince the Draw was broadcasted live, the CHL needed to know immediately if an assignment would have led to a direct or a combinatorial conflict and to which group the teams had to be allocated directly after they have been drawn out of the pots.\r\nIn this talk we discuss the algorithm based on an integer programming model, which was used by the CHL for the 2016/17 Group Stage Draw.\r\n\r\n", :title "Avoiding combinatorial clashes for the Champions Hockey League Group Stage Draw", :keyword2 157, :authors (33211 47773), :session 208}, 541 {:keyword1 86, :keyword3 99, :abstract "The dynamic stochastic resource constrained project scheduling problem that is typical for R&D organizations is characterized by a stochastic arrival process. Arrived projects compete for scarce renewable resources, e. g,. employees and equipment, and are stochastic in terms of their content (number of activities, activity durations). Each project has an externally assigned due date and the objective is to minimize the weighted tardiness of the projects. We report on the result on an extensive study where we have investigated the relationship between problem parameters and the performance of priority policies. We consider not only well-established priority rules from job shop scheduling and multi-project scheduling but also new priority rules. As our problem is closely related to scheduling in fork-join queueing networks we finally extend our investigation to policy classes proposed for such networks.", :title "The Performance of Priority Rules for the Dynamic Stochastic Resource Constrained Multi-Project Scheduling Problem: An Experimental Investigation", :keyword2 97, :authors (59821 829 14155), :session 157}, 545 {:keyword1 48, :keyword3 0, :abstract "This paper presents the planning problem encountered by egg packing station managers. In an egg packing station, pallets containing unsorted eggs arrive daily from chicken farms and need to be packed into order-specific boxes on packing lanes. These eggs are placed on a conveyor belt and sent into a grader that automatically identifies damaged eggs and grades the remaining eggs in several weight classes, referred to hereafter as grades. This is a fully continuous process and such grader can process up to 255000 eggs per hour. If required, a higher capacity can be reached by placing multiple graders in parallel.  The number of packing lanes is station specific but can easily go up to 32 lanes. The orders are destined for retailers and they specify the number of eggs required and the minimum (and sometimes maximum) weight requirements, or put otherwise,  a set of allowed grades. \r\nThe challenge for a station manager is to assign these orders to the packing lanes in such a way that the incoming supply (distribution of grades) is completely covered by active orders on the packing lanes. If, for example, insufficient lanes are active that require Small eggs to meet the incoming supply of Small eggs, they will go to the end lane where they are collected. Typically, these are sent to a breaker machine where egg white and yolk are separated and sold to the food processing industry. Eggs sent to the food processing industry yield considerably less turnover. In fact, when grader costs are assigned to these eggs, they typically result in a net loss. Alternatively, these eggs can be sent back to the front of the line. Since these eggs already have been handled, some of them might be damaged and consequently, they once more need to pass through the grader. \r\nThe goal of the station manager is to complete as many orders as possible given the available supply while minimizing eggs sent to the end lane. A given order can be assigned to multiple packing lanes. Such packing lane orders belonging to the same order do not all have to start or end at the same time. Starting a new order on a lane requires several change-over operations which are dependent on the order sequence. \r\nEgg lane allocation by the grader is dependent on the supply grade distribution of eggs and the demand grade distribution over the lanes. This means that at every change (setup starts or finishes, a lane breaks down, a pallet with a different grade distribution is started), the egg lane allocation changes. Because of technical constraints, this egg lane allocation is out of the control of the station manager, but is done heuristically by the grader. \r\nThe goal of this paper is to present the challenging egg packing station planning problem, position it in the optimization literature, and propose a model that efficiently covers this planning problem. Furthermore, we point out several future research directions such as additional practical work floor constraints and algorithmic challenges.\r\n", :title "Modeling the egg packing station planning problem", :keyword2 96, :authors (46978 59823 59824 28099), :session 186}, 547 {:keyword1 157, :keyword3 0, :abstract "An analytic approach for the solution of integer programming problems with nonnegative input is presented. The method combines discrete optimization with generating function techniques and results from complex analysis in several variables. The input data of the optimization problem are used as parameters of an analytic function in the unit disc. Based on this representation, the optimization problem is linked to the evaluation of a complex path integral by a multi-path version of Cauchy's integral formula. This perspective allows the formulation of an algorithm that relies on numerical quadrature. \r\n\r\nThe theoretical description is supplemented with a discussion of challenges in practical implementations. Preprocessing with so-called path adaption algorithms can help to improve the condition number of the quadrature problem whose efficient solution is essential for the algorithm. An especially promising variant of the path adaption idea solves a shortest path problem on a predefined grid graph inside the unit disc. This leads to a refined version of the algorithm with better numerical stability and overall performance.", :title "Solving IP by Evaluating Path Integrals", :keyword2 8, :authors (50836), :session 206}, 550 {:keyword1 189, :keyword3 18, :abstract "The need for optimizing crowd flows is driven by trends in urbanization, economic growth, technological progress, and environmental sustainability. In the context of tourism, the continuously growing number of tourists visiting European cities, such as Venice, Barcelona and Dubrovnik, has led to increasing concerns for environmental sustainability and has even brought up anti-tourism movements. This raises the question on how existing space capacities can be better used and visitor flows can be managed in such a way that visitor satisfaction, environmental protection and economic returns are optimized. To effectively deal with these challenges, crowd management has to move beyond the traditional “point in time” optimization approach, to a more dynamic planning approach in which plans and execution are continuously adjusted as needed.\r\n\r\nThis work presents a data-driven approach for crowd modeling, analysis, and decision-making which enables the strategic and operational management of crowd flows in the context of tourism. The applicability of the proposed crowd management system for visitor flows is demonstrated at the highly frequented tourist attraction “Schönbrunn Palace” in Vienna, Austria. Based on automatic counts, paths derived from WiFi-enabled mobile devices and the number of ticket sales, we extrapolate visiting sequences and dwell times at key representative locations inside the palace. The analyzed crowd flow data is incorporated into a crowd simulation model that allows to examine visitors’ movement behavior in greater detail. This simulation-based prediction and analysis of visitor flows reveals valuable information for planning such as crowd density, local congestions and capacity estimations.\r\n\r\nThe resulting decision support tool combines the analysis of crowd flow data and simulation, and enables to compare a multitude of scenarios within a short time frame (i.e. simulating an entire day within several minutes). The scenario definition is simplified for the user since measured crowd flow data can be imported for selected days and converted into visitor demand. Hence, the right measures for optimizing visitor flows can be identified in retrospect and their impact can be continuously evaluated after implementation. As such congestions and waiting times can be reduced thus creating added value for visitors and ultimately higher customer satisfaction for tourist attractions. Furthermore, the historical structure of buildings can be better protected by reducing the number of touches in the crowds which in addition contributes to the safety of the visitors.", :title "A Data-driven Approach for Modeling and Managing Visitor Flows", :keyword2 97, :authors (59826 59827 59828 59830 53870), :session 44}, 552 {:keyword1 158, :keyword3 18, :abstract "Biomass feedstock is expected to bridge the gap between diminishing fossil resources and increasing global energy and material needs by providing load-flexible bioenergy and sustainable bioproducts. A successful implementation of bio-based value chains requires a detailed evaluation of valorization routes taking into account regional conditions and the multiplicity of biomass feedstocks, conversion technologies, and capacities, as well as output products. Mathematical optimization models in connection with GIS-based models can help identify ideal regional biomass valorization routes. We present a combination between a GIS model and an MILP formulation for optimizing regional decentralized bio-based value chains. This model combination has two central objectives, which are implemented iteratively with increasing level of geographical detail. First, the GIS model locates regional biomass volumes, identifies potential conversion sites, and determines actual transport distances on predefined geographical cluster layers from transparent open source data. Second, starting from the highest geographical cluster, the mathematical model plans locations of biomass conversion sites based on input data provided by the GIS model. Every cluster layer is optimized iteratively in terms of the most profitable biomass conversion site locations, integrating technological economies of scale, biomass feedstock and transport costs, as well as sales revenues. The optimal solution is returned to the GIS model, which updates the input data for the optimization on the next cluster layer. It is aim of this talk to present a model combination approach to evaluating decentralized bio-based value chains on the regional level through heuristic-based iterative optimization. The resulting insights support strategic decision making by determining conversion site locations and in tactical planning by allocating feedstock to conversion sites. ", :title "Heuristic-based Iterative Optimization for Evaluating Regional Decentralized Bio-based Value Chains through GIS and OR Model Combination", :keyword2 54, :authors (47422 59658 8713 2675), :session 193}, 554 {:keyword1 42, :keyword3 65, :abstract "When we solved location problems related to the design of a private charging infrastructure for a fleet of electric vehicles, we encountered a gap between the number of infeasible vehicles obtained from optimization and simulation results. The gap is caused by the fact that users of the charging infrastructure make decisions based on less information than available in the optimization algorithms. In our contribution, we show how to model these problems by using the flows in networks. We suggest an algorithm that will operate despite the lack of information utilised by the users of the charging infrastructure.", :title "Flow models for some decision situations with incomplete information", :keyword2 173, :authors (52444), :session 228}, 555 {:keyword1 97, :keyword3 175, :abstract "As connected and autonomous vehicle (CAV) technology continues to evolve and rapidly develop new capabilities it is becoming increasingly important for transportation planners to consider the effects that these vehicles will have on the transportation network. It is evident that this trend has already started; over 60% of long-range transportation plans in the largest urban areas in the United States now include some discussion of CAVs, up from just 6% in 2015.  There are also numerous CAV pilot programs currently underway that entail testing Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) interaction in both isolated and real-world environments.  In order to successfully plan for CAVs current investments must consider the performance now and the performance possible due to advances in technology in the future design year.   In order to understand how CAVs will impact the transportation system, their behavior has been predicted so that it can be incorporated into existing traffic models.  This performance is very uncertain, however, and each assumption and source of uncertainty propagates throughout the modeling process, which is why it is important to incorporate decision analysis techniques for handling uncertainty when evaluating CAV performance.  While an individual CAV is an engineered system, the collection of CAVs, the technology that supports them, and the other transportation systems on the road, function as a system of systems (SoS).  SoS has been a recent area of focus in systems engineering, and by analyzing the transportation system in this way it enables the use of set-based design, tradeoff analytics, and value-focused thinking to create better design options. Multiple objective decision analysis can then be applied to both CAV and traditional transportation alternatives, to determine the set of optimal transportation investments.  Many organizations are starting to consider how to plan for CAVs, but the possible changes that they can have to economic development, access, roadway capacity and travel demand make the issue exceedingly difficult.  This research assists in providing an understanding of these relationships to help develop policy and guide investment in transportation systems.  ", :title "Long Range Planning for Connected Autonomous Vehicles ", :keyword2 63, :authors (59629 6392 6367), :session 32}, 556 {:keyword1 124, :keyword3 167, :abstract "Recommender systems are an established approach for automatically suggesting potentially interesting products to customers in a personalized fashion. In the research field, the most popular because most accurate algorithm family is collaborative filtering, which only exploits customers' purchasing histories for generating new recommendations. On the other hand, many companies have rich profiles about their customers, consisting e.g. of demographic attributes, usage behavior, and customer value. They analyze those profiles using more generic data mining and machine learning methods such as regressions, decision trees, or clustering in order to recommend products. \r\nWhile collaborative filtering does not provide a natural way to incorporate more input data such as customer profiles or item properties in addition to the purchasing vectors, it is built to be able to deal with a high cardinality in the response variable, which is the product a given customer will purchase next. However, the more traditional methods, which are established in the field of data analysis and often applied to analytical customer relationship management, deteriorate in performance when a certain amount of classes is exceeded. Linear methods for classification, such as logistic regression, were originally designed for binary output, although there exist extensions for multiple classes. Decision trees are naturally able to handle more than two classes, but still decrease in accuracy for a high number of possible outcomes. \r\nMost companies offer a high number of different products, ranging from tens to thousands. This is the reason why specialized algorithms were developed for personalized recommendations instead of using the well-known classification techniques. Algorithms for recommender systems have been shown to be more accurate although they do not generally use all available input data. \r\nIn this work, we analyze the relationship between the number of available items and the prediction accuracy of different recommendation strategies, divided into data mining methods and specialized techniques for recommender systems. We aim to find a threshold, depending on the dataset characteristics, of the cardinality in the response variable above which collaborative filtering is distinctly more accurate and below which the additional input data usable in traditional classification methods makes them competitive and possibly more accurate. \r\nWe also investigate how product hierarchies can be exploited for recommender systems. Intuitively, the higher the hierarchy level we choose to predict, the more accurate, in relation to collaborative filtering, data mining algorithms should be. Therefore, we examine whether a hybrid recommender system which yields an aggregation of (1) predictions from data mining methods on higher hierarchy levels and (2) collaborative filtering on more granular levels can improve accuracy over either of those methods alone.", :title "The Influence of Product Cardinality on Recommender Systems", :keyword2 183, :authors (59761), :session 201}, 557 {:keyword1 175, :keyword3 99, :abstract "During the last few years, stationless (freefloating) bike sharing systems (BSS) are installed at a rapid pace in cities all over the world. In contrast to classical station-based systems, bikes can be dropped off anywhere within a predefined region. For pick-up, their location can be retrieved via smartphone. \r\n\r\nSuch freefloating BSS are much more attractive for users than station-based systems. At the same time, they are extremely attractive for operators and cities because they don’t need extra space nor the installation of stations and utilize already existing infrastructure. On the other hand, the redistribution of bikes from places where they are parked but not needed, to areas with a shortage of bikes is extremely expensive. These costs could be significantly reduced if users could be stimulated to take over at least a part of the redistribution effort. \r\n\r\nIn our paper we discuss the problem of user-based redistribution in freefloating BSS. Redistribution in BSS has been extensively studied in the last decades, but mainly for the case of station-based systems and for operator-based redistribution. There are only a few publications on freefloating systems, and less than a handful of them addresses user-based redistribution. Our paper aims to make a contribution to better understanding the mechanisms, potential and limitations of user-based redistribution in freefloating BSS. \r\n \r\nWe present a stochastic model of the bike dynamics in a freefloating BSS and study the spatio-temporal distribution of the bikes. As users are willing to walk a specific distance to pick up the next bike, a significant spatial correlation in the bike distribution is created. This is specific to freefloating systems and results in a substantially reduced service level compared to a classical closed queueing network. \r\n\r\nOffering incentives to users may stimulate them to changing their usage pattern. We model the different possible behavioral changes and perform sensitivity analyses to study the influence of various behavioral parameters on the service level. We show that, with a smart incentive system, the number of bikes for creating a service level of 95% can be reduced significantly, even if only a minority of users participates. Under realistic behavioral assumptions, 30-50% reduction of bikes is achievable, which converts into substantial costs savings for the operator. \r\n\r\nOur research was triggered by the development of the new e-bike sharing system “smide” in Zurich, launched in 2017 by the insurance company die mobiliar. In this context, we tested several incentive strategies both with classical market research methods and with an extensive real-life field test during a period of 5 months. In this field test, we could analyze the behavior of users if offered incentives to drop-off bikes in specific areas. The findings help to develop optimized incentive systems for free-floating BSS.\r\n", :title "User-based redistribution in freefloating bike sharing systems", :keyword2 189, :authors (59301 59302 59306 59303 59832), :session 36}, 558 {:keyword1 94, :keyword3 176, :abstract "We extend the notion of \"globalized robustness\", introduced by Ben-Tal and Nemirovski, to the case of polyhedral Gamma-uncertainty-sets.  The globalized robust counterpart to an uncertain linear pro- gram that is considered here allows for the immunization of the solution against Gamma-many changing parameters in a given row, as studied by Bertsimas and Sim. In addition, it allows to \"smoothen\" the behaviour of the solution for parameters outside of the prescribed Gamma-uncertainty-set. If more than the Gamma-many specified parameters change, or they change by more than was initially specified, the violation in the corresponding constraint or in the objective function will remain moderate, dampened by a suitable penalty term.\r\n\r\nIn this talk, we focus on the global robustification of the objective function, deriving compact linear formulations and complexity results. The tractability of our formulations and the quality of the obtained solutions will be tested for uncertain variants of several combinatorial optimization problems.\r\n", :title "Globalized Robustness for Gamma-Uncertainty-Sets", :keyword2 8, :authors (59498 17092 45066 49052 14713), :session 80}, 559 {:keyword1 16, :keyword3 0, :abstract "In this talk we consider an application from wood industry. Given some (potentially curved) tree trunk our goal is to cut boards of given sizes such that the total profit of the boards is maximized. In contrast to classic knapsack problems the value of a board does not only depend on its type and size but also on its position. For instance, if a board contains parts of the pith, it is less valuable. Because of these position-dependencies we propose to discretize the trunk into small cubes. So we derive a binary integer program for our problem with packing constraints.  Unfortunately it might not be possible to use our solution in practice because it may violate the guillotine property. Indeed using a saw, each cut through some wooden part is a straight line crossing that part from one side to the other, dividing it into two parts. We show how one can extend our model such that sawability is ensured by appropriate constraints, which are successively added during the solution process. Apart from the three-dimensional problem, we consider a two-dimensional special case for straight trunks as well, where the length of the boards and their position in one dimension are fixed. Finally, we present some first computational results. ", :title "A variation of 2- and 3-dimensional knapsack problems in wood industry", :keyword2 8, :authors (26471 59834 43552), :session 218}, 561 {:keyword1 120, :keyword3 93, :abstract "In credit risk analysis, one of the most important tasks is to decide upon loan provisioning. Binary scoring systems are widely deployed to support decision-making by extracting the systematic patterns from data to predict applicants’ willingness and ability to repay debt. From a computational perspective, the task to separate systematic customer behavior from random variation becomes increasingly complicated in high-dimensional data environments where hundreds of customer characteristics are available. Feature selection aims at solving this problem by removing irrelevant data, which can reduce computation time and improve the learning accuracy. \r\n\r\nSome recent studies criticized a widespread practice of using standard performance measures such as AUC for evaluating the scoring models and suggested that relying on profit-based indicators may improve the quality of the scorecards for businesses. Furthermore, a portion of the data for risk scoring is usually purchased from third-party data providers. An accurate evaluation of the value of purchased data is difficult because its value in the form of better decisions emerges only after a long period of doing business with the customer. These challenges stress the importance of using value-oriented feature selection strategies that identify the optimal subset of variables in a profit-maximizing manner.\r\n\r\nIn this study, we develop a wrapper-based feature selection framework that uses the Expected Maximum Profit measure (EMP) as a fitness function. EMP was previously applied in binary classification problems in credit scoring and customer churn. The advantage of the proposed feature selection approach is that it searches for variable subsets that are optimal in terms of the business-inspired indicator, which allows incorporating the profit-maximizing framework already on the data preprocessing stage. To validate the effectiveness of our approach, we conduct a set of empirical experiments on multiple real-world credit scoring data sets using different wrapper algorithms. Our findings support the hypothesis that EMP-maximizing feature selection identifies feature subsets that yield a higher expected profit compared to methods that optimize standard performance measures. Therefore, the results emphasize the importance of using profit-based metrics in feature selection for improving the business-driven model development.", :title "Profit-Oriented Feature Selection: An Application in Credit Scoring", :keyword2 124, :authors (59635 9422 59835), :session 201}, 563 {:keyword1 178, :keyword3 175, :abstract "Electric mobility charging behavior is the focal point between the sustainable energy and the sustainable mobility transitions in Germany. The energy transition is characterized by a reduction of fossil fuel usage as well as of related CO2 emissions in the energy sector, while the mobility transition aims at achieving these goals in the transport sector. Specifically, the mobility transition includes changes in the individual mobility behavior towards more sustainable solutions. The recharge of electric vehicles (EV) should adapt to both the energy transition and the mobility transition. From a user perspective, standard charging of the EV battery takes considerably longer than filling the gasoline tank. Thus, EV charging options will have to be adjusted to better fit user expectations, needs, and behavior.\r\n\r\nConsequently, it is crucial to understand the charging preferences of current and potential future EV drivers. There are studies that investigate single attributes of the charging process; Hackbarth and Madlener (2013, 2016), Hidrue et al. (2011), and Tanaka et al. (2014), for instance, investigate the willingness to pay (WTP) for the EV adoption whereas Ito et al. (2013) examine the willingness to pay for the EV-charging infrastructure. However, none of the mentioned studies has looked at the charging preferences as a whole including related services. \r\n\r\nTherefore, we assess EV drivers’ valuation of different attributes of the charging process such as charging speed, location, and price. Valuation means the WTP for specific attributes, measured in monetary terms, e.g. a 10% decrease in charging duration is worth x Euros to consumers. By extracting consumers’ marginal WTP, we elicit by how much attributes have to be improved so that the WTP increases over-proportionately. We then derive managerial implications both for specific attributes and for complete mobility solutions. For example, if EV drivers assign a high value to the charging duration, this could be an area to place additional focus on when offering new charging solutions and services.\r\n\r\nDue to the low number of current EV users in Germany, analyzing consumers’ preferences and their WTP for them based on real usage data is challenging. In addition, the results would not be transferable to the development of sound business cases since the sample size would be too low. Therefore, we gathered data through a Discrete Choice Experiment (DCE) conducted in Germany (N=4.000). We analyzed the data using econometric methods in order to gain actionable insights into current and future charging behavior of EV drivers.\r\n\r\nWe predict tendencies of consumer behavior and show which attributes are highly valued by potential EV drivers and which ones are not. These consumers can be divided ex-post into specific adopter categories (e.g. first movers, early adopters, laggards) and driver segments (e.g. homeowner, streetlamp parker, commuter, car-sharer), respectively. \r\n", :title "Elicitation of Preferences Regarding Electric Mobility Charging Behavior", :keyword2 189, :authors (44928 21108), :session 37}, 564 {:keyword1 95, :keyword3 157, :abstract "Multi-echelon distribution systems are very common in City Logistic context. In two-echelon systems, goods are not directly delivered to customers, but instead have to transit through intermediate facilities called satellites. Goods are first moved from the main depot to the satellites using large trucks, then shipped from the satellites to the customers using smaller vehicles. The problem of determining how to efficiently route goods at both levels simultaneously, is called the Two-Echelon Vehicle Routing Problem (2E-VRP).\r\nIn this paper, we propose a new hybrid heuristic method for solving the 2E-VRP that relies on two components: a neighborhood search heuristic to explore the search space and discover interesting routes, and a Set Cover model that combines the discovered routes into high-quality solutions.\r\nSuch an approach was applied to the VRP by Rochat et al. [1] as a post-optimization technique and was later adapted to other vehicle routing problems such as the 2E-VRP [2]. However, our current proposal is different in two key features. First, unlike precedent works that relied on a Set Partitioning formulation of the problem, we use a Set Cover (SC) formulation that allows more possible combinations while choosing the routes. Second, instead of using the SC as a refinement, we embed it into an iterative framework as a mean to find better solutions that were missed by the neighborhood search and to faster lead the algorithm towards promising regions of the solution space.\r\nComputational experiments on the standard benchmark of the 2E-VRP show the competitiveness of our approach. Our algorithm consistently achieves high quality solutions while requiring less running time compared to other methods from the literature. Furthermore, it was able to improve the current best known solutions for several large scale instances. \r\nReferences\r\n[1] Y. Rochat and É. D. Taillard, “Probabilistic diversification and intensification in local search for vehicle routing,” J. Heuristics, vol. 1, no. 1, pp. 147–167, Sep. 1995.\r\n[2] K. Wang, Y. Shao, and W. Zhou, “Matheuristic for a two-echelon capacitated vehicle routing problem with environmental considerations in city logistics service,” Transp. Res. Part D Transp. Environ., vol. 57, pp. 262–276, Dec. 2017.\r\n", :title "A Set Cover based heuristic for the Two-Echelon Vehicle Routing Problem", :keyword2 59, :authors (59754 59833 27556), :session 166}, 565 {:keyword1 39, :keyword3 162, :abstract "Fuzzy set theory proposed by Zadeh (1965) has been applied to several fields. Bellman and Zadeh (1970) first proposed concept of fuzzy decision making. After the pioneering work of Bellman and Zadeh (1970), application of fuzzy set theory to decision making has been done by many authors. Negoita and Sularia (1976) first applied fuzzy set theory to linear programming (LP). Zimmermann (1976) introduced fuzzy sets into an LP problem with fuzzy objective function and constraints. Zimmermann (1978) extended fuzzy LP method to a multi-objective linear programming (MOLP) problem with linear membership functions to represent fuzzy objective functions. Fuzzy nonlinear programming model with a fuzzy goal and fuzzy constraints is developed by Trappey et al., (1988). Fuzzy multi-objective nonlinear programming (FMONLP) is introduced by Sakawa (1984) as an extension of fuzzy linear programming (FLP). In the method, assuming that decision maker (DM) has fuzzy goals for each of the objective functions in rnultiobjective nonlinear programming (MONLP) problems considering five types of membership functions; linear, exponential, hyperbolic, hyperbolic inverse, and piecewise linear functions. The DM’s compromise or satisficing solution can be obtained from the Pareto optimal solution set by choosing one of the three possible fuzzy decisions. Sakawa et al. (1984) presented an interactive fuzzy decision making method for the solution of MONLP problems (Sakawa, 1993; Liang, 2006). Singh and Yadav (2016) formulated a multiobjective nonlinear programming problem in intuitionistic fuzzy environment, then the problem is converted into crisp problem. They also proposed a nonlinear membership function and developed various approaches for solving it by using different operators and fuzzy programming technique.\r\n\r\nIn the FMONLP model with objective functions fi(X), i=1,2,…k and inequality constraints gj(X), j=1,2,…,m,  all objective functions are asssumed as convex and differentiable and also constrained set X is convex and compact (Sakawa, 1993). Generally, linear membership functions have been used for all fuzzy sets for solving fuzzy mathematical programming problems. Zangibadi and Maleki (2013) analyzed concave or convex shaped nonlinear membership functions. \r\n\r\nIn this study, we aimed to give a comparative analysis of fuzzy multi-objective nonlinear programming models under different linear and nonlinear membership functions via a numerical example.\r\n", :title "Comparison of fuzzy multi-objective nonlinear programming models under different membership functions", :keyword2 161, :authors (59788 31863), :session 176}, 566 {:keyword1 35, :keyword3 29, :abstract "Modern portfolio theory, introduced by Harry M. Markowitz in 1952, is a well-developed paradigm based on probability theory and widely used for both financial as well as real assets. However, to capture the complex reality of decision-making processes fuzzy theory has been proposed as an alternative to the probabilistic approach. In contrast to probability theory, the possibility distribution function, which corresponds to the probability distribution function, is defined by a so-called membership function describing the degree of affiliation of fuzzy variables. In this paper, the investor's aspiration levels of a portfolio's return and risk are regarded and expressed by logistic membership functions. More specifically, we propose the semi-mean absolute deviation (SMAD) as a risk measure in situations where only negative deviations are to be considered. Moreover, we introduce a fuzzy semi-mean absolute deviation (FSMAD) portfolio selection model, aiming at investigating its usefulness for the selection of wind power generation assets. Using a semi-mean absolute deviation (SMAD) model as a benchmark, and a fuzzy semi-mean absolute deviation model for comparison, we consider five onshore wind parks in Germany in a portfolio analysis. Regarding the changing regulations in the German Renewable Energy Sources Act (Erneuerbare-Energien-Gesetz, EEG) the results show that the combinations of favorable assets representing efficient portfolios are very similar, although the portfolio shares are markedly different. In addition, the return and risk spans of the SMAD model are much broader than for the FSMAD model. The highest returns are generated by portfolios based on the latter model. Offering fewer portfolio choices, the FSMAD model thus facilitates decision-making. This is in compliance with the notion that portfolio optimization by fuzzy sets theory is able to better account for the decision-maker’s preferences under real-world conditions.", :title "Application of Fuzzy Theory for Optimizing Portfolios of Wind Power Generation Assets in a Changing Policy Environment", :keyword2 39, :authors (21108 59838), :session 9}, 567 {:keyword1 101, :keyword3 25, :abstract "We study product support outsourcing under two types of contracts -- the more traditional Transaction-based contracts (TBC) and the more recent Performance-based contracts (PBC), when the information of product failure rate is privately owned by the customer. PBC has become ubiquitous in industries ranging from aerospace and defence to computer support services. Despite advantages of PBC that have been highlighted in many previous studies, the more traditional TBC that ties supplier payments to each repair incident is not vanishing but is still widely adopted by companies in product support industry. In this paper, we explore the hidden superiorities of TBC in screening products with different failure rates only known by the customer, as is frequently the case in practice. We build a stylized adverse selection model in which the supplier acts as the uninformed principal who designs menus of contract terms (price and target uptime) contingent on the product failure rate, and the customer selects the contract based on her true information. We find that the two types of contracts lead to diverse screening effects: TBC can achieve separation of product failure rates without losing efficiency in setting service capacity, whereas distinguishing failure rates under PBC requires interactions of pricing and capacity decision, resulting in over-investment in repair capacity. Moreover, neither contract is dominant. The customer may prefer TBC (PBC) if she has a lower (higher) outside option, and the supplier may have an opposite preference. Given medium outside options, TBC can be both preferred by the supplier and the customer. Our paper brings to light a heretofore unknown advantage of TBC and it demonstrates when these contracts are likely to be observed, despite seeming superiority of PBC. We provide insights on how to choose the right contract type in the presence of asymmetric information in the third-party MRO market.", :title "Contracting for Product Support under Information Asymmetry", :keyword2 40, :authors (37640), :session 40}, 568 {:keyword1 2, :keyword3 126, :abstract "Continuous descent approach (CDA) aims at reducing fuel consumption and noise compared to other conventional descents. Instead of approaching an airport in a stairstep fashion, CDA allows for a smooth descent to landing. The descent profile depends on initial and final positions of aircraft, which depend on the followed route during the flight and the assigned landing runway, which in turn depends on airport congestion and/or avialability. This work develops an optimization model for the management of approach and landing operations in airports,  deciding on runway assignment and approach trajectory. The proposed scheme leads to a mixed integer non-linear model which is difficult to be solved. Therefore, a Benders decomposition is proposed. On one hand, the master model deals with runway assignment, making use of a set of binary variables. On the other hand, the sub-model deals with the trajectory calculation problem, minimizing fuel consumption and complying with noise constraints. \r\nRealistic computational experiments based on real airport operations are presented. ", :title "Integrated optimisation for descent trajectory operations and airport runway assignment ", :keyword2 150, :authors (23407 59087 59091), :session 45}, 569 {:keyword1 42, :keyword3 157, :abstract "Potential-based flows are an important extension of classical network flows that are relevant for the management of gas, power and water transportation networks. In networks of this type the flow on an arc is determined by the difference of the potentials of its incident nodes, which often leads to challenging MINLP problems. In this paper we study the combinatorial structure that results from the interplay between the flow balance at each vertex and the acyclic nature of potential-based flows, suggest a new approach to optimizing these flows and present some computational results.\r\n\r\n", :title "Acyclicity in Network Flow Problems - Towards a new approach to optimizing potential-based flows", :keyword2 162, :authors (11433 14736), :session 220}, 570 {:keyword1 101, :keyword3 158, :abstract "This contribution is based on a multi-period network design problem for strategic-tactical planning of material flows between plant locations of a manufacturing company. Transport capacities on edges can be allocated in integer multiples of a base capacity that corresponds to a single truck load. The number of truck loads that can be moved between two nodes in the network depends on the driving time. A single truck may serve multiple connections during a time period which usually corresponds to a working day. The total number of trips is limited by the truck's temporal availability (typically 8 hours per day), but it can be extended by renting additional trucks at (high) fixed costs. The network nodes allow for the limited storage of goods over time and impose handling capacity constraints on both inbound and outbound flows. \r\n\r\nThe pure design part of the problem under consideration exhibits strong similarities to the network loading problem which has already been studied extensively in the scientific literature. However, the dynamic multi-period nature of the overall problem in combination with admissible intermediate storage of commodities and various additional custom constraints has not been specifically addressed so far. In essence, the transfer of selected valid inequalities that have initially been designed for  mixed-integer programming (MIP) formulations in the context of network loading represents the core of this contribution. The focus, in particular, is on cutset and multicut (e.g., spanning tree) inequalities, involving design variables only. The key idea is to obtain a so-called capacity formulation of the problem by \"projecting out\" any flow-related decision variables. The final purpose is to embed these valid inequalities into a Benders decomposition approach in which the master problem solely contains design variables. Further conceivable application scenarios comprise Benders-and-cut or Branch-and-cut approaches in general. The motivation for employing this kind of approaches arises from the intractability of the original MIP formulation, primarily resulting from long planning horizons and a huge number of commodities. \r\n\r\nA time-expanded formulation of the original multi-period problem serves as the basis for installing those valid inequalities. Precisely speaking, cutsets are defined in a multi-layer fashion, potentially involving multiple \"copies\" of a link, each of which connects the same pair of nodes in different time periods. In other words, cutsets are \"spanned\" across predefined time intervals, depending on the respective commodities' first supply and latest demand dates. The effects of the added cuts are analyzed using both synthetic (randomly generated) and real-world benchmark problem instances. Preliminary experiments provide strong evidence for a successful and efficient strengthening of the respective LP formulation, in comparison to the relaxation of the original MIP.", :title "Capacity formulations for a multi-period network design problem", :keyword2 65, :authors (39457), :session 225}, 571 {:keyword1 18, :keyword3 0, :abstract "We study inventory decisions in a multi-period newsvendor model. In particular, we analyze the impact of the budget cycle in a behavioral setting. We derive optimal rational decisions and characterize the behavioral\r\ndecision making process using a short-sightedness factor. We test the aforementioned effect in a laboratory environment. To control for inventory that is carried over from on period to the next, we introduce a start-inventory factor and find that order-up-to levels increase in the starting inventory. Our results also indicate that the subjects are short-sighted with respect to future budget cycles. They reduce orders significantly at the end of the current budget cycle which results in a wave style order pattern during the budget cycle.", :title "Multi-Period Inventory Management with Budget Cycles: Rational and Behavioral Decision Making", :keyword2 101, :authors (19894 41788 56051), :session 20}, 572 {:keyword1 175, :keyword3 95, :abstract "Recently urban freight transport is more frequently performed and in bigger quantities, therefore it is considered as vital artery for cities economic growth. However, some stakeholders’ particularities and city logistics dynamics influence the freight flow and the distribution process efficiency in city centers. In addition, the transport activities have generated negative impacts which motivate the consideration of the transport efficiency from a sustainability perspective. This paper provides a mathematical model which defines distribution routes taking into account some real characteristics of urban transport. The objective is to minimize the distribution costs considering accident rate impacts, fuel consumption and carbon emissions; aiming at the sustainability based on the aforementioned dimensions.", :title "Sustainable Urban Freight Transportation: Routing Analysis Considering Accidents Impacts, Fuel Consumption and Polluting Emissions", :keyword2 31, :authors (3531 55798 7001), :session 166}, 575 {:keyword1 104, :keyword3 0, :abstract "Fibre to the Home (FttH) has been widely recognized as the most sustainable solution for offering very high-speed internet access to fixed-line customers. However, the deployment of FttH networks is very costly and requires a precise estimation of the investment cost. FttH networks are currently mainly deployed in large agglomerations, but as part of the « France Très Haut Débit » plan, several public initiative networks (Réseaux d'Initiative Publique, RIP) have been set up to extend these services throughout the country. With the aim of estimating the investment cost for these uneven population zones, we propose an approach based on HDSBSCAN clustering. This method supports variable density clusters in particular the detailed geospatial data to design the FttH network infrastructure and accurately estimate the deployment cost.", :title "Cost Estimation of FttH Deployment with HDBSCAN Clustering", :keyword2 0, :authors (59749 38253), :session 228}, 578 {:keyword1 181, :keyword3 167, :abstract "The application field of railway infrastructure maintenance is a field, which has not been in the main focus of operations research approaches. Nevertheless, several approaches have been evaluated to establish sensors, detectors or other hardware to detect infrastructure maintenance requirements, to supervise infrastructure elements (e.g. switches) and to produce warnings or early indicators before railway infrastructure fails, e.g. signal failure, switch problems, infrastructure state implied speed limits etc. Installing and establishing hardware based railway infrastructure supervision is a rather expensive, but often required arrangement to ensure safe and reliable railway operation.  Such hardware based measurement approaches will finally always act as the ultimate truth compared to more sophisticated, expectation based approaches.\r\nMoreover, classical railway infrastructure maintenance departments also use IT based systems to manage their infrastructure catalogues, track maintenance cycles, maintenance planning, expenses and proofing.\r\nOn the other hand, railway operations research activities deal with timetable data, with detailed running time computations, blocking times, microscopic and advanced infrastructure data models etc. One rather new challenge determined by the situation mentioned above is the support of infrastructure maintenance predictability by means of railway operations research for two reasons:\r\n•\tTo reduce investments for really hardware based maintenance facilities – OR approaches instead of hardware measurements if sufficient –  or\r\n•\tTo optimize hardware based measurement investments based on more reliable placement abilities\r\nIf suited and precision of operations research approaches for maintenance prediction are highly acceptable, such approaches might even substitute hardware based measurement activities.\r\nThis paper will concentrate on different aspects, key indicators and challenges from a practical point of view of setting up a suited system, defining sufficient rules and performance indicators and how the introduction into practice might be organized.\r\nThis paper will concentrate on different aspects facing this challenging task:\r\n-\tThe identification of key performance indicators for railway infrastructure maintenance.\r\n-\tA short look at available data sources, currently used data formats and available information to be processed and analysed.\r\n-\tIdentification of information and average information content of data and information usually processed when dealing with railway operations research activities.\r\n-\tDescription of developed and evaluated approaches to aggregate heterogeneous data sources and legacy systems.\r\n-\tThe calibration of algorithms used to derive predictive infrastructure maintenance information.\r\n-\tDescription of practical experiences made when evaluating the approaches within existing environments and systems.\r\n", :title "Operations research for predictive infrastructure maintenance", :keyword2 100, :authors (59602), :session 33}, 579 {:keyword1 175, :keyword3 187, :abstract "Range anxiety poses crucial limitations for logistics operations performed with electric vehicles (EVs) despite the advancements in the battery technology. Accurate route planning by considering external conditions is of critical importance for operational efficiency since different factors may increase the energy consumption significantly. In this study, we extend the Electric Vehicle Routing Problem with Time Windows (EVRPTW) by considering load factor. In EVRPTW, the energy on the battery is consumed proportional to the distance traveled by the EV. In our case, the energy discharged during the trip is affected by the load factor as well since it increases the consumption as the vehicle carries more load. We formulate this problem as a mixed integer linear program and perform an extensive experimental study to investigate how load factor influences the routing decisions. Our aim is to present managerial insights to both researchers and practitioners. We solve small instances using a commercial solver. The results reveal that neglecting load effect on the EV performance may yield route plans that cannot be implemented in the real business environment.", :title "The Impact of Load on the Route Planning of Electric Freight Vehicles", :keyword2 95, :authors (2423 58100 58102), :session 165}, 583 {:keyword1 175, :keyword3 25, :abstract "The automotive sector remains one of the key industries in many European countries and worldwide. Therefore, developments in this sector have wide reaching implications both for the industry itself, but also on a wider economic scale. Understanding the decision making process of car buyers is crucial for car manufacturers and policy makers alike. This paper analyzes the car purchasing behavior of new car buyers in five major European markets (Germany, France, the UK, Spain, and Italy). Exploiting a uniquely detailed set of survey data ranging from 2008 to 2017, we find the determinants of car buyers’ decision making behavior with regard to brand and model choice. The data covers an extensive set of variables related to the car buyers and their decision making process. Using discrete choice modeling, we derive the Willingness to Pay (WTP) for different attributes. In particular, we are interested in understanding the choices of consumers regarding brand loyalty. \r\nWe conduct our analysis based on a mixed logit framework. Mixed logit provides a flexible and computationally feasible solution for modeling car adopters’ choices. Mixed logit (MXL) can solve two major limitations of less sophisticated specifications, such as the multinomial logit (MNL) model. The first limitation is the Independence of Irrelevant Attributes (IIA), which forces the substitution patterns to be fixed between alternatives. Furthermore, unlike MNL, mixed logit models are able to capture differences in preferences that are not linked to observed attributes (random heterogeneity). A drawback of using mixed logit is the lack of a closed form solution of the log-likelihood function used for estimating the coefficients of the parameters. Instead, the results are obtained via numerical simulation.\r\nPreliminary analyses show significant fluctuations between car segments over time. Across all markets, buyers move from medium- and full-size cars towards both smaller cars and larger SUVs and Off Road vehicles, respectively. The causes of these developments and their implications and connection to brand loyalty in the five European markets considered are yet to be analyzed in more detail.\r\nThe full results will allow us to identify key drivers in brand loyalty across consumers. A particular focus is on the heterogeneity between different consumer groups. Furthermore, we put additional emphasis on the possible asymmetry between loyalty and disloyalty. While previous studies often treat loyal and disloyal behavior as two sides of the same coin, first results indicate that they might have very different drivers, meaning that brand disloyalty is a distinct behavior worth investigating, instead of the simple absence of loyalty.\r\n", :title "Choice Modeling of Passenger Car Purchase Behavior", :keyword2 178, :authors (59672 21108), :session 216}, 584 {:keyword1 41, :keyword3 162, :abstract "Convex and in particular semidefinite relaxations (SDP) for non-convex continuous quadratic optimization can provide tighter bounds than traditional linear relaxations. However, using SDP relaxations directly in Branch-&-Cut is impeded by lack of warm starting and inefficiency when combined with other cut classes, i.e. the reformulation-linearization technique. We present a general framework based on machine learning for a strong linear outer-approximation that can retain most tightness of such SDP relaxations, in the form of few strong low dimensional linear cuts selected offline. The cut selection complexity is taken offline by using a neural network estimator (trained before installing solver software) as a selection device for the strongest cuts. Lastly, we present results of our method on several non-convex application problems.\r\n", :title "Online generation via offline selection of strong linear cuts from QP SDP relaxation", :keyword2 158, :authors (51069 59840 49171 35785), :session 49}, 586 {:keyword1 177, :keyword3 37, :abstract "Most retailers offer multiple products of one product category. Managing inventories for these products is especially challenging due to substitution effects within the category which make the optimal inventory levels interdepend. Furthermore, the true demand distribution of the products is usually unknown to the decision maker and has to be estimated. We present an integrated estimation and optimization approach that leverages available data (e.g. historical sales, weather, special days) to manage inventory levels for a multi-product portfolio of perishable items. We empirically evaluate our approach based on a real-word data set of a large German bakery chain.", :title "Data-driven Inventory Management Under Customer Substitution", :keyword2 124, :authors (59842 59843 4229 59844), :session 202}, 587 {:keyword1 8, :keyword3 154, :abstract "The growing need to deal with uncertainties in optimization processes has lead to many new research directions. In robust optimization, an uncertainty set has to be defined containing all scenarios to be considered. Availability of historical data often suggests the use of a discrete or polyhedral uncertainty set. By this, new combinatorial optimization problems are evolved.\r\n\r\nIn this talk, we discuss a few examples of novel combinatorial optimization problems inspired by uncertainties in network design and production planning. Further, this talk should motivate research on the additional complexity introduced by uncertainties.", :title "Combinatorial Optimization inspired by Uncertainties", :keyword2 94, :authors (12177), :session 237}, 588 {:keyword1 88, :keyword3 0, :abstract "In queueing systems with vacations, the server may be unavailable for some time. This vacation feature can model a machine that is being maintained, a machine that is working on other product families, telecommunication resources that are given priority to other processes, et cetera.\r\nTherefore, queueing systems with vacations have been studied extensively.\r\n\r\nTwo well-studied vacation policies are the number-limited and the time-limited vacation policies. In the number(time)-limited policy, the server goes on vacation after it has served a predefined number of customers (amount of work) or when there are no customers present, whichever situation occurs first. However, the feature that the server goes on vacation also when the system becomes empty is not always adequate for modelling purposes. For instance, in case of usage-based maintenance, a machine (server) undergoes maintenance (vacation) after it has worked for a certain time, idle times not incorporated; if the machine is idle before the threshold for the operational hours has been reached, the machine is not yet maintained. Rather, it remains idle, and immediately starts working again when new work arrives.\r\n\r\nWe expand the literature with modified number-limited and modified time-limited vacation models, in which the server remains idle if the system is empty before having reached the threshold of the number of customers or amount of work respectively. We extend previous work to a discrete-time setting. A discrete-time analysis of the modified vacation models is not only interesting in its own right, since the analysis is different, but also because some extra results can be obtained.\r\n\r\nFiems and Bruneel have recently developed a framework to analyze discrete-time queues with Markovian vacations. We describe how the framework can be used to obtain the probability generating functions (PGFs) of the system content at departure epochs and at random slot boundaries, and of the waiting time, both for the modified number-limited and modified time-limited vacation models. The key is to define several matrix generating functions properly.\r\n\r\n\r\nThen, we adopt another analysis technique to obtain the same as well as additional performance quantities. The technique is a combination of establishing recurrence equations, using PGFs, applying discrete-time Fuhrmann decomposition, and applying the decomposition results of Kim et al. between the queue and the system content. In addition, an interesting relation between the model with number-limited policy and the model with time-limited policy is established.\r\n\r\n\r\n", :title "Discrete-time modified vacation queues", :keyword2 0, :authors (59853 59857), :session 242}, 593 {:keyword1 2, :keyword3 47, :abstract "\"Such algorithms aren't written by god in the heavens\"; Andreas Mundt (Chief of the Federal Cartel Office) interviewe by Sueddeutsche Zeitung. He attacked Deutsche Lufthansa AG\r\nfor suspected general price increases.\r\n\r\nDuring the past decades airlines have built complex Revenue Management (RM) tools. Large amounts of data have to be processed, hence clever algorithms were implemented. However, only a combination of the system and revenue managers can be successful. Therefore, trainings for the respective employees have to be considered as mandatory. The trainings in the best case are carried out with the support of a simulator to reach the full positive effect. So far the research on Revenue Management Simulation has focused so far mainly on development, verification and testing of new approaches. Here a new holistic approach has been developed, that integrates factors for research and practice, which explains the success of such a simulation based training methodology. The results are the following factors - \"Decision Support-compare and verify control strategies\", \"Optimization-compare methods\", \"Learning and Training - understand a new system, for new employees\", \"Fun-entertainment, gamification\", \"Innocent-realistic, risk-free environment\" and \"Network-team building, conflict management\", which are combined into the the \"DOLFIN-model\". The International Air Transport Association (IATA) has launched a new Training Program using the Revenue Management Training Simulator of Opremic based on that model in 2017 (see https://opremicsolutions.de/). The participants of the first course value practical and interactive exercises as beneficial for their daily work. In the future interviews with participants will be conducted to verify the model and its success in the long run.\r\n\r\nIn the movie (Matrix, 1999) a character says \"Never send a human to do a machine's job\". On the contrary, it is necessary to have well educated people as well as trusted machines.\r\n", :title "Agile Revenue Management training - A new holistic simulation based approach (DOLFIN)", :keyword2 97, :authors (59803 59790), :session 180}, 596 {:keyword1 95, :keyword3 187, :abstract "This presentation studies the active-passive vehicle-routing problem (APVRP). The APVRP covers a range of logistics applications where pickup-and-delivery requests necessitate a joint operation of active vehicles (e.g., trucks) and passive vehicles (e.g., loading devices such as containers). The problem supports a flexible coupling and decoupling of active and passive vehicles at customer locations in order to achieve a high utilization of both resources. \r\nThis flexibility raises the need to synchronize the operations and the movements of active and passive vehicles in time and space. The contribution of the presentation is twofold. First, we present a branch-and-cut algorithm for the exact solution of the APVRP that is based on Benders decomposition. Second, we show how this approach can be generalized to deal with other vehicle-routing problems with timing aspects and synchronization constraints, especially for the more complicated cases in which completion time or duration of routes is part of the objective. Preliminary computational experiments show that the proposed algorithm is well suited for the APVRP. It is able to compute optimal solutions for a number of previously unsolved APVRP benchmark instances.", :title "Branch-and-Cut for the Active-Passive Vehicle Routing Problem", :keyword2 150, :authors (39408 26277), :session 154}, 597 {:keyword1 40, :keyword3 0, :abstract "We construct approximate Nash equilibria in atomic splittable congestion games with convex cost functions, where the strategy space of each player is the base polytope of a polymatroid. The idea is to compute a pure Nash equilibrium for an associated integrally-splittable congestion game. In such games, players can only split their demand in integral multiples of a common packet size. It is known that one can compute pure Nash equilibria for integrally-splittable congestion games within a running time that is pseudo-polynomial in the aggregated demand of the players. We decide, for every epsilon, on a packet size and prove that the associated splittable Nash equilibrium is an epsilon-approximate Nash equilibrium for the original atomic splittable congestion game.\r\n\r\nWe then consider multimarket oligopolies with decreasing, concave price functions and quadratic production costs, and prove that there exists a polynomial time transformation to atomic splittable congestion games. Using our first result, this implies that we are also able to find epsilon-approximate Cournot-Nash equilibria for multimarket oligopolies within pseudo-polynomial time.", :title "Equilibrium Computation in Atomic Splittable Polymatroid Congestion Games", :keyword2 134, :authors (45115), :session 91}, 598 {:keyword1 174, :keyword3 158, :abstract "Empty freight car allocation problems, as well as fleet sizing problems depict a highly important topic in the field of railway cargo optimization. Fleet sizing is mainly used in order to find the minimal amount of freight cars (fixed costs) needed to operate the transportation network successfully (e.g.: satisfy customers’ demand). In contrast, after a consignment is transported to its destination, the unloaded freight cars have to be reallocated again. This reallocation process is linked to costs depending on the travelled distance.\r\n\r\nIn order to find the optimal trade-off between the amount of freight cars and costs linked to empty vehicle allocation, a mathematical model (MILP) is developed. The model is tested on a particular network. Following the results of this test, different deviations in the network (changes in cost structure, drive time or demand) are examined and compared to the basic scenario.\r\n", :title "Empty Freight Car Allocation and Fleet Sizing", :keyword2 159, :authors (59867), :session 155}, 602 {:keyword1 159, :keyword3 185, :abstract "Within the railway value chain (timetabling, line planning and vehicle scheduling, etc.) the coordination of the single planning steps is a key success factor. Hence, we consider the integration of the line planning and the timetabling process as crucial for timetabling in practical applications. To address this, we present a ‘track-choice’ extension of the commonly known method for the generation of periodic event schedules ‘PESP’. The extension makes use of the mesoscopic track infrastructure representation in the line planning and timetabling system Viriato, a system that is widely used by public transport planners and operators. Taking into consideration the technical and operational constraints given by rolling stock, station and track topology data on one hand, and the commercial requirements defined by a given line concept on the other, the method presented generates periodic timetables including train-track assignments. For this, we make use of the ‘service intention’, a standardized data structure for the line concept consisting of train paths and frequencies. Due to the utilization of infrastructure based track capacities, we are also able to assess the feasibility of the line concept given. Additionally, the method allows for handling temporary resource restrictions (e.g. caused by construction sites or operational disturbances) up to a certain degree. The methods presented here are part of a planning framework which is currently developed covering relevant parts of the railway value chain.", :title "Periodic timetabling with ‘Track Choice’-PESP based on given line concepts and mesoscopic infrastructure", :keyword2 105, :authors (59852 21140 45346 59876 59880), :session 211}, 603 {:keyword1 165, :keyword3 91, :abstract "Air and noise pollution, congestion, and shortage of living space are pressing problems in urban areas. What contributes to these problems is an ineffective use of vehicles. Vehicles like scooters, cars, and bicycles are underutilized when owned and run by users of merely one household. Offering several users access to a pool of vehicles against a per-minute usage fee, Shared Mobility Systems (SMS) have been emerging and help to counter the prementioned issues. However, experience has shown that SMS often suffer from imbalances: some locations run out of vehicles, while others get overcrowded. Both tendencies make SMS unattractive. Although optimizing the service area layout and the number of vehicles can help to mitigate such imbalances, these means are cost intensive and need a fair amount of time to be implemented. Another approach to resolve imbalances focuses on imposing specific parking regulations on the users or relocating vehicles from crowded to empty locations. Parking regulations have proven to be effective, but are hardly applicable to station-less SMS. Relocating vehicles reduces imbalances, but requires an infrastructure of its own and comes at high operative costs.\r\n\r\nIn this talk, we follow a different approach and present a dynamic pricing scheme similar to surge pricing to tackle imbalances in SMS by tuning a direct lookahead approximation to decide on how to set prices for different locations. We evaluate our approximation based on real-world data gathered from a SMS in the DACH region. Our findings suggest that dynamically adjusting prices leads to an overall better performance and increases profits.", :title "Surge Pricing in Shared Mobility Systems", :keyword2 175, :authors (59850 16305), :session 179}, 608 {:keyword1 29, :keyword3 133, :abstract "A smart grid is the combination of a traditional electrical power system with information and energy both flowing back and forth between suppliers and consumers. This new paradigm introduces major challenges such as the integration of decentralized energy generation, the increase of electric transportation, and the need for electricity consumers to play an active role in the operations of the grid. This presentation will summarize the opportunities for optimization to contribute to the success of smart grids and present some recent breakthroughs. ", :title "Optimizing the future of smart grids", :keyword2 57, :authors (3287), :session 233}, 609 {:keyword1 153, :keyword3 97, :abstract "Stochastic simulation optimization (hereafter sim-opt), refers to stochastic optimization using simulation. Specifically, the underlying problem is stochastic and the goal is to find the values of decision variables to optimize some performance measures of interest, which are evaluated via stochastic simulation. Since the evaluation of such computational modules is often expensive, different approximation approaches have been developed to provide inexpensive metamodels (also referred to as surrogate models) of the underlying simulation models. These have been used in some sim-opt algorithms to seek the optimum of the metamodeled function, considering the finite analysis runs that can be afforded with the limited computing power.\r\n\r\nIn this work we consider an arbitrary black-box setting, where multiple (expensive) performance measures are evaluated in a multidimensional decision space, but cannot be directly observed and must be estimated through a stochastic simulation model based on noisy observations. To build the observed Pareto front (the observed non-dominated objective values), we propose a scalarization algorithm (SK-MOCBA) using stochastic kriging [1] to sequentially search for candidate points in a discrete decision space. The stochastic kriging metamodels allow us not only to obtain fast approximations of the expensive functions, they also take into account the intrinsic (heterogeneous) noise in the simulation output. To assess the performance of the algorithm, we run it on a testbed of benchmark functions for multiobjective optimizers obtained from the literature, and compute well-known quality indicators, such as hypervolume and IGD.\r\n\r\nRelying only on the observed mean objective values to derive the Pareto front, however, may entail two potential errors due to sampling variability. A Type I error occurs when designs that actually belong to the non-dominated set, are considered dominated. A Type II error occurs when designs that are actually dominated, fall in the observed Pareto front. To ensure a high probability of correctly selecting a non-dominated design, we should smartly allocate the available computational budget to critically competitive designs, based on their observed performance and variance. Analogously, we should not spend budget on those designs that are clearly dominated. To do this we use MOCBA (Multiobjective Computing Budget Allocation [2]), one of the few approaches in Multiobjective Ranking and Selection, and evaluate its impact on the overall performance of the algorithm.\r\n\r\n[1] Ankenman, B., Nelson, B. L., & Staum, J. (2010). Stochastic kriging for simulation metamodeling. Operations Research, 58(2), 371-382.\r\n\r\n[2] Lee, L. H., Chew, E. P., Teng, S., & Goldsman, D. (2010). Finding the non-dominated Pareto set for multiobjective simulation models. IIE Transactions, 42(9), 656-674.\r\n", :title "Multiobjective optimization of noisy functions using stochastic kriging", :keyword2 63, :authors (59872 57929 16465), :session 71}, 610 {:keyword1 187, :keyword3 175, :abstract "Truck platoons are formed by several trucks that travel along a road section at the same time logically (or electronically) coupled so that the gap sizes between these vehicles are very small. As a consequence significant fuel savings for the platoon leader truck as well as for the other platoon members are possible. Within this talk, we discuss challenges arising from the integration of platoon formation into vehicle routing tasks. Furthermore, we present some modelling concepts for the consideration of platoon formation simultaneously to the vehicle route compilation. First computational results are presented and discussed.", :title "Platooning in Vehicle Routing", :keyword2 8, :authors (32377), :session 168}, 611 {:keyword1 8, :keyword3 153, :abstract "We research contiguous graph partitioning, specifically node partitioning in undirected, simple graphs. While node partitioning has already been extensively researched, a distinguishing feature of the problem we study in this paper is the objective function: to maximize the total number of edges adjacent to nodes assigned to the same partition. In other words, we aim to find a number of partitions that 'cluster' the maximum number of edges within partitions. The number of partitions is known in advance. The size of each partition, which need not be equal, is also known in advance. Another important characteristic of the graph partitions we study in this paper, is the so-called contiguity of partitions. In other words, the partitions of interest need to be connected, meaning that a path between every pair of nodes in the same partition, that uses only nodes contained in that partition, needs to exist. This partitioning problem has applications in e.g. seat assignments in parliaments. In a parliament, every political party needs to get assigned a number of seats, and the layout of the seats and their adjacencies can be easily be represented by a graph where seats correspond to nodes and adjacent seats are connected via edges. In this setting, the objective function is a measure of how well members of the same political party can communicate, e.g. by passing around documents. Hence we dub the problem the Seating Assignment Problem. We prove that the Seating Assignment Problem is strongly NP-hard, even in the case where contiguity is not required. In addition, we present MIP formulations for several variants of the problem and extensions thereof. We also provide different types of cuts. Finally, we present a computational study where we test the performance of different MIP formulations and cuts in three practical applications where documented political discussions have shown the necessity of an objective, neutral seating assignment approach: the Flemish Parliament, the Belgian Federal Parliament, and the House of Representatives of the Netherlands.", :title "Contiguous graph partitioning: who sits where?", :keyword2 158, :authors (44955 5838 9583 6251), :session 71}, 615 {:keyword1 178, :keyword3 0, :abstract "“An International Society for the Advancement of Economic Theory in its Relation to Statistics and Mathematics” is still the heading of ECONOMETRICA, the Journal of the Econometric Society, founded by the later and first Noble Prize winners in Economics: Frisch and Tinbergen. Nevertheless the context changed. Regression Analysis much used by Tinbergen, also as head of the Dutch Planning Office, is replaced more by Discrete Mathematics. The statistics are not only official statistics but also all kind of raw data such as “Big Data”, nevertheless remaining subjected to sampling or complete census.\r\nNowadays “Economic Theory” is much more related to the Universal Definition of Robbins; “Economics is neutral between ends”, automatically linked to Multi Objective Optimization with objectives or criteria on the one side and different solutions on the other. It leads to a Decision Matrix which can be read either horizontally or vertically. On this basis several methods were developed. Anyhow any method has to fulfill the following conditions of robustness:\r\n    1) choice of alternative solutions like Projects, at least two\r\n    2) choice of objectives (criteria), at least two, all expressed in different units like $ or €, kg, liter, meter, kilowatt-hour, calories etc.\r\n    3) normalization of the units of the objectives\r\n    4) importance of the objectives\r\n    5) a huge number of objectives has to be possible.\r\nThe whole operation can be made by one person but it is more advisable that all stakeholders, i.e. everybody interested in the issue, are involved. \r\n\tIn this modern definition of econometrics “Operations Research” takes its position. Consequently it would be wrong to consider OR as a service provided by a researcher following the subjective desiderata of his client. As Churchman, Ackoff and Arnoff state, it provides managers of an organization with a scientific basis for solving their problems, with as major phases:\r\n    1. formulating the problem\r\n    2. constructing a mathematical model \r\n    3. deriving a solution from the model\r\n    4. implementation.", :title "From econometrics to multi-objective optimization", :keyword2 63, :authors (59878 24686), :session 85}, 618 {:keyword1 175, :keyword3 37, :abstract "Major innovations have taken place in the transportation industry in recent years and new technologies are in the market or are expected to be soon. Driven by environmental awareness and new regulations for fuel efficiency, electric vehicles (EVs) have evolved in the last decade to the point of starting to present a viable alternative for some drivers. Nonetheless, electric vehicles do not have yet a significant market share, or the market share that is expected. Therefore, in this context of rapid change in vehicle characteristics and consumer decisions, it is paramount to reliably forecast the diffusion of this innovative mean of transportation. \r\nThe diffusion happens, in part, as an imitation of the so-called innovators by the followers, who are influenced by the number of adoptions that have already occurred. This concept of imitation corresponds to what in the psychological literature is defined as social conformity, which is the influence of the desire to fit socially into a consumer's behaviour. On the other hand, when a consumer considers buying a new vehicle, there is also a pure substitution effect regarding the kind of engine (EV vs. Gas). Thus, there is room for the typical discrete choice models to round off an estimation of technology spread.\r\nIn this paper we propose a substitution/diffusion model to measure the diffusion effect as the impact of social conformity on the individual choices. The influence of social conformity is represented by the number of EV sold, the number of people who tried an EV, and information that potential customers receive about specific characteristics of EV. In addition to that, this new dynamic model includes also the impact of policy incentives; in particular, the availability of parking spaces and parking cost strategies. we assume that the tradeoffs estimated with advanced disaggregate discrete choice models are stable over time and in the dynamic diffusion/substitution model we re-estimate only the scale and ASCs to adjust to the observed market shares. \r\nThe data used comes from different sources. On the one hand, the coefficients for the disaggregate substitution part of the model are available from previous work of the authors. They come from a Stated Preference survey performed in Denmark in the period between December 2014 and January 2015. The survey was built to specifically study the effect of parking policies on the choice of EV versus conventional cars and the role played by social conformity on this choice. The sample was gathered from a list of individuals who had signed up to participate in a real-life experiment with EV that was launched in Denmark in 2010. The sample includes then also people who have tried EV in real life, allowing some consideration about the impact of experience in the diffusion process. On the other hand, the information used in the diffusion part of the model, is based on the revealed demand for EV registered in Denmark up to February 2018.\r\n", :title "Predicting the diffusion of EV: A dynamic approach to model the impact of imitation and experience", :keyword2 178, :authors (59888 57456 27215), :session 37}, 620 {:keyword1 8, :keyword3 0, :abstract "The objective of this study consists in introducing a local search algorithm for solving the Maximum Dispersion Problem (MaxDP). For a given set of weighted objects, the MaxDP looks for partitioning the set into a given number of groups such that the mutual distance of each groups' elements is maximized. Further restrictions on each group address its total weight. The MaxDP might be formulated as a 0-1 fractional programming problem which can be linearized. The MaxDP is known to be NP-hard and, consequently, it is difficult to solve large-scale MaxDP instances using exact methods. In order to overcome this issue, we introduce an efficient local search algorithm. Through extensive computational experiments on randomly generated instances, we evaluate the performance of the proposed algorithm versus the standard solver Gurobi. The numerical results confirm the efficiency of the introduced method in solving the MaxDP.", :title "A Novel Approach for Solving the Maximum Dispersion Problem", :keyword2 59, :authors (13247), :session 205}, 621 {:keyword1 187, :keyword3 8, :abstract "Local search approaches have tended towards incorporating an ever-increasing number of made-to-measure heuristics for different problem classes, for example all manner of vehicle routing generalizations. These large heuristic sets consequently present a significant complication for problem solvers, namely: how can one determine the impact of individual heuristic components?\r\n\r\nIn contrast to targeting generalizing problem extensions, it may be worthwhile to focus on a problem's core when developing a basic optimization heuristic. This talk introduces a recently developed ruin & recreate heuristic, named SISRs. \r\nWhile ruin & recreate heuristics may have become widespread, SISRs is unique insofar as it seeks to induce `spatial slack' during its ruin phase which may subsequently be exploited in its greedy recreate phase.  Both the crucial `spatial slack' concept and the almost-greedy recreate emerged after a dedicated attempt towards solving the vehicle routing problem's most basic special case, that is the `capacitated VRP'.  \r\n\r\nSISRs' quality is validated by way of demonstrating its superior performance across a wide and diverse range of VRP generalizations. This confirms that the basic CVRP ruin & recreate heuristic is also effective when applied to more general problems, without the need to add problem-specific components. \r\n\r\nThe developed ruin & recreate outperforms current (and often dedicated) state of the art approaches in terms of both speed, robustness and its high-quality results.\r\n", :title "SISRs: An effective ruin & recreate heuristic based on slack induction", :keyword2 95, :authors (23268), :session 240}, 622 {:keyword1 96, :keyword3 7, :abstract "Organizations face increasing dynamic turbulences in their business environments through strong demand fluctuations driven by specific customer requirements, shorter lifecycles and technology changes. This results in more challenging production ramp-ups defined as the “period between completion of development and full capacity utilization” (Terwiesch & Bohn, 2001). To successfully manage ramp-up, workforce learning is of central importance to reduce the uncertainty and instability (Terwiesch & Bohn, 2001). Multiple research studies have shown that learning and training of shop-floor employees can significantly reduce production costs and improve the quality of products. However, training measures are often in conflict with employee capacity restrictions. \r\n\r\nWe present an MIP workforce scheduling model that allows to investigate the impact of demand volatility on the learning and training of employees in production systems. We specifically focus on the interactions of demand volatility and employee capacity and analyze the consequences on the learning and training behavior of employees and efficiency gains in different ramp-up scenarios. The model takes individual learning during task performance and through external training as well as forgetting into account. Furthermore, the model incorporates substitutable production activities, varying capacity restriction and shortage costs. To obtain insights about cost-optimal learning patterns, we examine an extensive dataset that is based on 300 scenarios with varying demand volatility and capacity restrictions. Each scenario is calculated for 18 periods and also includes the ramp-up phase of the production system. Overall, we show how to generate learning and qualification strategies under different demand volatility scenarios and analyze the specific properties of our solutions.\r\n", :title "Consequences of the interplay between volatility and capacity on workforce planning and employee learning", :keyword2 47, :authors (52562 1658), :session 158}, 624 {:keyword1 141, :keyword3 47, :abstract "Many companies have to adjust their product portfolio to fast changing markets and high demand volatility. As a result, they need to invest in workforce learning and training measures to gain flexibility. Especially during ramp-up phases employees have to adjust their skill sets to new production requirements. While traditional employee training models focus on a condensed period of training at the beginning of an employment or the ramp-up of a new production process, we aim to shed light on the effectiveness of more flexible concepts of training with a general availability of training measures during a product’s lifecycle. To compare different concepts of employee development, we budget training with regard to two dimensions, the training capacity per period and periods which do not allow for training.\r\nFor analyzing the impact of different training scenarios, a multi period workforce scheduling problem with workers, who learn on the job and due to external training is considered. All employees start with a defined initial skill level when a new production ramp-up phase starts. We also include forgetting into our model. Two simulated training environments are distinguished. In the first setting training possibilities are budgeted, training measures are only available in the first periods of production ramp-up. In the second setting training measures are not limited time-wise and employees can undergo training sessions in each of the calculated 18 periods per scenario. Data from a computational study with 600 scenarios and near-optimal solutions are analyzed statistically to derive insight on efficiency gains, production cost savings, shortage costs and competence outcomes depending on different training environments and demand volatility. Overall, we investigate different training strategies under different demand volatility and scenarios and analyze the specific outcomes to give managerial insights. ", :title "Consequences of budgeted training access in production systems and workforce planning", :keyword2 96, :authors (56432 1658 52562), :session 158}, 625 {:keyword1 99, :keyword3 89, :abstract "Maintenance plays a critical role in assuring maximum reliability of an asset in a manufacturing system. With the emergence of Industry 4.0, sensors will be ubiquitous and enable systems to monitor the condition of critical components while communicating this information to the planner. Condition based maintenance (CBM) predicts functional failures and takes appropriate preventive actions relying on the actual condition of the system. The information on the condition of the systems can be considered as some kind of Advance Demand Information (ADI). Research has shown that ADI may lead to significant savings in inventory costs if it is correctly implemented [1]. \r\nDue to the increasing complexity of the systems and the much bigger margins for after-sales services than for selling machines, the maintenance of systems is gradually taken over by the Original Equipment Manufacturers (OEMs) [2]. OEMs will adopt CBM in the following process. First, sensors are embedded in the systems of the customers of the OEM. Secondly, the up-to-date data is used by the OEM to update the information on the systems' conditions and review their maintenance planning accordingly. In a last step, the same information is used by the OEM to efficiently manage the spare parts. The key challenge for the OEMs is how to exploit the collected data on the condition of the systems to schedule efficiently the maintenance of the machines and at the same time manage cost-effectively the spare parts inventory. \r\nWe propose an inventory policy that combines spare parts management with condition based maintenance. Under this policy, the preventive and corrective replacement actions and spare parts inventory control are driven by the deterioration of the systems. Three control limits are introduced in the suggested policy: a fixed failure threshold for corrective maintenance and two thresholds, one for ordering the spare part and one for the preventive maintenance action. In contrast with the conventional base stock policy, the orders are placed based on the actual condition of the machines. This extension of ordering based on the condition results in a modified base stock policy. The purpose is to find the optimal values for the ordering and preventive maintenance thresholds that minimize the inventory and maintenance costs.  A comparison is established between the condition based spare parts inventory policy and the conventional base stock policy.\r\n\r\nKeywords: modified base stock policy, spare parts management, condition based maintenance\r\n\r\nReferences\r\n[1] R. Hariharan, P. Zipkin, Customer-order information, leadtimes, and inventories, Management Science 41 (10) (1995) 1599–1607.\r\n[2] R. J. I. Basten, G.-J. van Houtum, System-oriented inventory models for spare parts, Surveys in operations research and management science 19 (1) (2014) 34–55.\r\n", :title "A condition based spare parts inventory policy for OEMs", :keyword2 19, :authors (59892 59853 4565), :session 175}, 626 {:keyword1 151, :keyword3 63, :abstract "We revisit fundamental problems in undirected and directed graphs, such as the problems of computing spanning trees, shortest paths, steiner trees, and spanning arborescences of minimum cost. We assume that there are $d$ different cost functions associated with the edges of the input graph and seek for solutions to the resulting multidimensional graph problems so that the $p$-norm of the different costs of the solution is minimized. We present combinatorial algorithms that achieve very good approximations for this objective. The main advantage of our algorithms is their simplicity: they are as simple as classical combinatorial graph algorithms of Dijkstra and Kruskal, or the greedy algorithm for matroids.", :title "Simple Greedy Algorithms for Fundamental Multidimensional Graph Problems", :keyword2 42, :authors (44261), :session 91}, 628 {:keyword1 173, :keyword3 124, :abstract "The field of metaheuristics lists by now dozens of methods, and new algorithms are continuously being proposed. Moreover, while great importance is given to the effectiveness of such methods, comparatively little attention is devoted to understanding how and why these methods work.  As a consequence, the algorithm designer who wants to choose a metaheuristic algorithm to solve a problem is faced with the dilemma of choosing one algorithm.\r\n\r\nThe goal of this work is instead to understand more in depth the behaviour of metaheuristic algorithms from an experimental perspective, and we use Simulated Annealing (SA) as an example. \r\n\r\nSimulated Annealing (SA) is one of the oldest metaheuristics and has been adapted to solve many combinatorial optimization problems.  Over the years, many authors have proposed both general and problem-specific improvements and variants of SA. We propose to accumulate this knowledge into automatically configurable, algorithmic frameworks so that for new applications that wealth of alternative algorithmic components is directly available for the algorithm designer without further manual intervention. To do so, we describe SA as an ensemble of algorithmic components, and describe SA variants from the literature within these components. \r\n\r\nThis approach has several advantages. First, it is immediate to reinstantiate existing algorithms and imporove their performace with automatic algorithm configuration. Second, the combination of algorithmic frameworks with automatic configuration tools allows to automatically design new, state-of-the-art algorithms. Third, it facilitates a sound study on algorithms and algorithmic components based on experimental data. We experimentally demonstrate the potential of this approach on three common combinatorial optimization problems, the quadratic assignment problem and two variants of the permutation flow shop problem.\r\n\r\nIn particular, we study existing and automatically generated SA implementation for these problems, and we perform an importance analysis to determine which components of a SA are key to discover good solutions. We observe that the acceptance criterion (that determines whether a candidate solution has to be accepter or now) and the exploration criterion (that chooses a candidate solution in the neighbourhood to evaluate) are the two most important components; the component most studied in theory, the cooling scheme, is surprisingly not as important. We also observe that a strong convergence behaviour is necessary for a SA algorithm to perform well, opposed to the broad initial exploration entailed by the settings commonly chosen for a SA algorithm.\r\n", :title "A Component-Based Analysis of Simulated Annealing", :keyword2 59, :authors (59882 9511), :session 203}, 629 {:keyword1 91, :keyword3 0, :abstract "Knowing the customers response to the price changes is of utmost importance to many industries. In the parametric approach the response is described by the parameterized price-demand function, which can take different forms, like linear, exponential, log-linear, logistic, etc., depending on the modeled process and on the required properties. Whatever function we choose, we would like to find the best parameter values describing the customers behavior.\r\n\r\nUnfortunately, historical data for many industries, like hotels, airlines or car rentals, include examples of a positive correlation between price and demand -- there is a high demand in periods of high prices. This disturbs the classic procedures of price-demand function estimation. On the other hand, each customer makes his own decision based on his personal preferences and available data -- even in high season he accepts or not higher prices and compares prices of the same or similar products between competing producers/service providers effectively responding to price changes. We are interested in revealing this personal response, which is independent of the natural variability of the number of potential customers.\r\n\r\nTypically in hotels and airline industry the booking pattern over the booking horizon for a single stay date is similar for all stay dates, independent of the actual demand level. The correlation becomes even smaller when stay dates are grouped into sets with different total demand, for example high season, low season and very low season. \r\n\r\nIn the following we propose a methodology to estimate the parameters of the price-demand function in situations when reservations can be made long before the arrival/flight over some booking horizon. The changes in the distribution of demand over the booking horizon as a reaction to the price changes are used as the main source of the data for the estimation. The approach allows to estimate the parameters of different response models, including non-linear ones, with different reference prices. What is more important, distinct parameter set can be defined for each booking period, where the booking period is defined as a range of days before the arrival/flight common for all stay/flight dates, for example 0-1, 2-7, 7-15. This allows to reveal the changes in price-demand response depending on the time remaining  to the arrival, which can be extremely useful for the subsequent dynamic price optimization.\r\n\r\nWe show the results obtained using simulated as well as real booking and pricing data. We also roughly judge the  quality of the price-demand function parameter estimation.\r\n", :title "Estimating the price-demand function by the demand distribution analysis over the booking horizon", :keyword2 0, :authors (12318), :session 89}, 631 {:keyword1 59, :keyword3 0, :abstract "Metaheuristics and, in particular, Stochastic Local Search, SLS, methods such as Iterated Local Search (ILS), Iterated Greedy (IG), Tabu Search (TS), GRASP or Simulated Annealing (SA) have been used with good results for many NP-hard optimization problems. Typically, when tackling such problems, an algorithm designer has to decide which one of these methods to apply and how to adapt the chosen metaheuristic to the problem. So far, this process has been carried out manually using a trial and error approach that requires time and an expert designer in order to achieve good results.\r\n\r\nAn alternative to the manual algorithm engineering is the automated design of effective SLS algorithms through building flexible algorithm frameworks and using automatic algorithm configuration techniques to instantiate high-performing algorithms.\r\n\r\nThe concept of automatic algorithm design can be traced back to the introduction of automatic configuration tools and unified algorithm implementations.  The former simplifies the configuration of algorithms with a big parameter set, while, the latter expose the design choices, when building a SLS, as parameters. By using the two together, we can automatize the design of specific SLS in a process called programming by optimization. We propose a way to adapt these ideas towards generating high-performing algorithms for important scheduling problems. The method is based on decomposing the SLS algorithms to components and to define a set of rules to describe how to combine them. Finally, an automatic configurator is used to find the best combination of components that satisfies the given rules.  The presented system can choose either to instantiate an existing SLS method or to create a new one by hybridizing two, or more, SLS algorithms.  More specifically, the automatic configurator is used to select the best components, the rules are expressed as a grammar, and a new framework, called EMILI, has been created to implement the components and to instantiate the algorithms.\r\n  \r\nEMILI has been designed to be an unified framework for the automatic SLS design. EMILI is based on (i) a decomposition of SLS algorithms into algorithmic components, (ii) an algorithm template from which many different types of SLS methods can be instantiated, (iii) a recursive definition of possible algorithm compositions that in turn allow to generate hybrid algorithms, and (iv) a strict separation between algorithm-related components and problem related components. EMILI is a significant refinement over previous proposals in terms of ease of implementation and algorithm composition, the comprehensiveness of the implemented components, and the possibility of tackling problem classes rather than single optimization problems.\r\n", :title "Automatic Design of Hybrid Stochastic Local Search Algorithms", :keyword2 0, :authors (59893 9511), :session 203}, 632 {:keyword1 47, :keyword3 0, :abstract "In order to accomplish the missions of the organization, military manpower planning aims to provide the required workforce with the adequate competences and ranks. The military organization specificity is the hierarchical structure which restricts personnel movements and recruitments (only at lowest rank of the organization). Military personnel movements are mainly of two types: vertical advancement in rank (promotion) and horizontal transfers (job position transfers). Besides, each job position in the military organization requires some conditions related to rank, competence or other individual characteristics.\r\nMilitary manpower planning involves two logics: statutory logic and competence logic. Statutory logic deals with: recruitment, retirement and promotion to accomplish strategic goals. The competence logic aims to fulfill the job positions. However, these two logics affect each other. For example, if the statutory planning fluctuates, the competence policy should adapt. \r\nThe aim of our research is to combine both logics into one integrated model, which allows the simultaneous optimization of the two combined logics. This model gives detailed information about the workforce distribution in the coming years and it permits the human resources managers to better forecast the results of their policies.\r\nEach soldier in the military organization is characterized by a rank, a job position and acquired competences. The evolution of these characteristics through time is called the soldier's career path. We model the military manpower using a career path approach. First, we identify the possible career paths taking into account the organization’s policies. Then, the military manpower is assigned to the possible career paths. The competence and statutory goals are translated into finding the amount assigned to each career path. In order to find the optimal manpower assignment, we resort to goal programming. For the goal program, we consider three types of variables: new recruits assignment, initial manpower assignment and the goals deviations. New recruits assignment is the amount of recruited personnel in each career path. The initial manpower assignment defines the assignment to different career paths of the manpower initially in the organization when starting the simulation. The deviation variables are used in the soft constraints to define the deviation from the targeted goals.\r\nWe applied our modeling approach to a subpopulation of the Belgian military manpower (officers). The model helps the human resources managers study the impact of different policies on the statutory and the competence levels. Furthermore, the model contributes to planning the future policies, such as job transfers and annual recruitment.\r\n", :title "Military manpower planning using a career path approach applied to the Belgian defense", :keyword2 0, :authors (59866 38413 24396), :session 200}, 634 {:keyword1 42, :keyword3 8, :abstract "The 0-1-knapsack problem is a well-known NP-hard problem in combinatorial optimization. We consider the extensions to the knapsack problem with conflict graph (KCG) and the knapsack problem with forcing graph (KFG). KCG has first been introduced by Yamada et al. and represents incompatibilities between items of the knapsack instance. KFG has been introduced by Pferschy and Schauer and represents the necessity of items for other items. Within this paper we provide pseudo-polynomial solutions for KCG and KFG with co-graphs as conflict or forcing graphs and extend these solutions to conflict graphs and forcing graphs of bounded clique-width. Our solutions are based on dynamic programming using the tree-structure  representing the conflict graph and the forcing graph. Further we conclude fully polynomial time approximation schemes (FPTAS) for KCG on conflict graphs and KFG on forcing graphs of bounded clique-width. This generalizes the known results for conflict graphs and forcing graphs of bounded tree-width of Pferschy and Schauer.", :title "The Knapsack Problem with Conflict Graphs and Forcing Graphs of bounded Clique-width", :keyword2 156, :authors (39552 55900), :session 229}, 635 {:keyword1 158, :keyword3 163, :abstract "We will give an overview on new features and improvements in the current Gurobi release. In particular, we focus on the new Cloud and Compute Server enhancements and present our newest performance improvements. ", :title "Gurobi 8.0 - What's new", :keyword2 159, :authors (48817), :session 47}, 636 {:keyword1 34, :keyword3 0, :abstract "Central banks implement negative interest rate policies (NIRP) to incentivice economic subjects to spend and invest money for long term economic growth. Al-though nominal negative interest rates can not be eﬀectively explained by economic theory, when inﬂation is included there are currently real negative interest rates in almost all industrial nations. We investigate the impact of these varying rates on investment bank proﬁtability during and after the ﬁnancial crisis starting in 2007. With international clustering, it is possible to observe heterogeneous pass-throughs and diﬀerent performances of stock prices in the countries concerned.", :title "The impact of monetary policy on investment bank proﬁtability in unequal economies", :keyword2 0, :authors (59897 42818 59899 59898), :session 197}, 639 {:keyword1 65, :keyword3 175, :abstract "In the transportation industry, the express integrators are the only providers that offer a door-to-door overnight delivery of packages in regions as large as Europe or the US. To achieve such services, the express integrators need to design efficient transportation networks. Defining an efficient schedule of flights that enables the delivery of this service is known as the Express Shipment Service Network Design (ESSND) problem.\r\n\r\nIn the ESSND problem, the packages are typically hauled first from their origin cities to hubs. At the hubs, the packages are sorted (i.e. re-ordered by destination). Then they are hauled to their destination cities. In multi-hub regions, three  main types of decisions need to be made in the ESSND problem. The first type is to determine the hub assignments, i.e. the hub in which each package will be sorted. The second type is to determine the routes to fly with each aircraft. The third type is to decide how to load the aircrafts so to carry the packages from their origins to hubs and then to their destinations. Although the three decisions are highly interrelated, most works from the literature assume a fixed hub assignment, i.e. they consider the hub assignment as an input and thus as fixed. It can be said that using a fixed hub assignment has become the standard method for solving the ESSND problem. This is because, given a hub assignment,  the ESSND can  be solved to optimality for realistic instances in short times (less than one hour). However, generating a hub assignment is a problem in itself that, to the best of our knowledge, has not yet been explored in the literature, and that has a high impact in the network, as two hub assignments can lead to solutions with large cost differences.\r\n\r\nIn this research, we first propose an ESSND model with flexible hub assignment – i.e. a model that integrates the hub assignment, routing and flow decisions – and compare its performance with the state-of-the-art models with the same approach using 45 realistic instances (7 aircraft types, 77 cities and 2 hubs). The results show that our model produces solutions 20% less expensive and with much smaller optimality gaps. Second, to study the value of integrating the hub assignment decision in the ESSND model, we develop four heuristic methods to generate hub assignments. Then, we compare the results of our approach with those of the state-of-the-art model with fixed hub assignment when fed with assignments found by the heuristics we propose with 61 realistic instances (7 aircraft types, 77 cities, and between 2 and 4 hubs). The results show that our model finds better solutions for 51 instances, with costs improvements of around 3\\% on average. \r\n\r\nAcknowledgment:\r\nThis project was funded by the Brussels-Capital Region and Innoviris.\r\n", :title "A comparison between the fixed and flexible hub assignment approaches when solving the express shipment service network design problem", :keyword2 174, :authors (50556 25059 24964), :session 169}, 645 {:keyword1 55, :keyword3 18, :abstract "Statistical process control (SPC) is an industry-standard methodology for monitoring and controlling quality during the manufacturing process. In this method, one measures quality data of small samples in preset time intervals or after a specific amount of produced items. Based on this data and some mathematical statistics, one can extrapolate to the entirety and, if necessary, adjust process parameters to ensure perfect quality products. Still, this method is conditioned on the fact that the measured data is correct and neither the measuring device nor the inspector manipulated the incoming data. We study the problem of detecting manipulations in measurement data of manufacturing processes, which we refer to as validation of measurement data. To this end, we adapt different machine learning approaches and propose a novel variation of the Smith-Waterman algorithm to also operate on continuous data. We then compare these different techniques on real data from manufacturers in Germany and test the results for feasibility. The result is a solution, being a combination of decision stump forests and the Smith-Waterman variation to detect characteristics from a predefined list of typical manipulations. With regards to practical usage, we then provide an intuitively controllable environment to execute these algorithms and validate said quality data.", :title "Validating Measurement Data in Manufacturing Processes", :keyword2 180, :authors (59900 19477), :session 188}, 646 {:keyword1 151, :keyword3 65, :abstract "Given an undirected graph with edge weights given by c and requirements on the nodes given by an integral valued function b, the well known maximum weight b-matching problem asks for a minimum (multi-) set of edges M such that vertex v has at most b(v) edges in M incident to it and the total weight c(M) of the matching is maximized. This problem can be solved in polynomial time by classical algorithms from combinatorial optimization. We study the problem with additional minimum quantity constraints: every vertex must either be unmatched or have at least q edges from M incident with it. This is similar to lower bound constraints but they enforce a minimum number of edges only in the case that a vertex is matched. A practical application of this setting arises in intermediary trade. Assume a set of suppliers and buyers of a certain commodity and a broker in between who wants to maximize his brokerage, which depends linearly on the number of units sold. Each supplier has a limited supply and each buyer has a limited demand. In addition, some of the suppliers will only sell if a certain minimum number of units is sold. Analogously, some of the buyers will only buy if they receive at least a certain number of units. The above scenario can be modelled as an instance of the Maximum Weight b-Matching Problem with Minimum Quantity Constraints (MWBMMQ) on a bipartite graph. We show that MWBMMQ is strongly NP-hard even on bipartite graphs and that, unless P = NP, there is no PTAS for the problem. We also show NP-hardness of approximating MWBMMQ on perfect binary trees and on series-parallel graphs. On the other hand, we provide a dynamic program that solves the problem in polynomial time on paths and on cycles. Furthermore, we provide a pseudo-polynomial time algorithm for graphs of bounded treewidth. An interesting concept for tackling problems with minimum quantity constraints consists of approximating the solution value while relaxing the constraints within certain thresholds. We show that given a fixed precision parameter which can be arbitrarily close to one, there is a polynomial time bicriteria approximation algorithm that computes an approximate solution to MWBMMQ on series-parallel graphs. The precision parameter is an upper bound on both the approximation factor as well as on the factor by which minimum quantity and capacity constraints might be violated. ", :title "Matching problems with minimum quantity constraints", :keyword2 42, :authors (59901 19477), :session 229}, 648 {:keyword1 175, :keyword3 54, :abstract "We consider a goods distribution system that utilizes electric vehicles. We may need to use multiple vehicles as the capacity of a vehicle may not be sufficient for serving the demand of all clients. We assume that each vehicle is fully charged before their departure from the depot. However, we may need to recharge them during their trips if the total energy consumption to visit certain customers is larger than the battery level. Once a station is open, it might be visited multiple times by any vehicle and the vehicles can be recharged at any amount, in other words, partial recharging is possible. \t\r\nWe do not impose any restrictions on the types of stations or vehicles, therefore, we allow utilization of slow or fast charging stations and of heterogeneous vehicles. We do not consider time windows as the focus of our study is rather from a strategical point of view.\t\r\nThe problem is to decide on the number and location of stations, the number of vehicles needed, the amount of recharging needed for each vehicle, and the route(s) for visiting all the clients. The objective function will minimize the total cost including the variable cost of routing and recharging as well as the fixed costs of opening stations and operating vehicles. \r\nOur problem can be considered as an electric vehicle routing problem with location decisions or an electric location-routing problem (ELRP) with a heterogeneous fleet, multi-type stations, multi-visit, and partial recharging.\r\nWe propose a new mixed integer programming formulation for this strategic electric location-routing problem and develop a Benders decomposition algorithm based on our formulation to solve the problem optimally. We also introduce a greedy heuristic to start our Benders algorithm with a better upper bound and a stabilization component to improve the convergence speed of our algorithm.\r\n", :title "A Benders decomposition approach for the electric location-routing problem", :keyword2 150, :authors (36732 7956), :session 212}, 649 {:keyword1 91, :keyword3 169, :abstract "Revenue Management and Dynamic Pricing methodology was originally developed in the context of passenger aviation facing mounting economic pressure after deregulation of the market. In the context of car rental, other Operations Research techniques, related to production and logistics, were added in. Partly, this is due to the greater operational flexibility in capacity management and fleet relocation. On the other hand, customer requirements with regards to the inventory are more specific: for a premium mobility brand, dozens of relevant car groups have to be offered exactly where and when they are needed. Premium service includes almost unlimited flexibility for the customer, with the option to change plans on short notice, within a large network of rental locations or even whole city areas in a free float mode. Under these conditions, to maintain high levels of utilisation and a competitively priced offer requires advanced forecasting and optimisation techniques. Successful car rental Revenue Management is therefore key to creating customer excitement and loyalty.\r\nIn the talk we will give an overview of the evolution of relevant methods. At least as important as the choice of algorithms is the appropriate modelling of economic principles at play, such as opportunity costs, which form the central concept around which most RM systems are designed today. We will also discuss the impact of new forms of mobility on the development of Revenue Management, and the role of Machine Learning technology and of some other concepts from Artificial Intelligence.", :title "Optimization, Data Science, and Machine Learning in Car Rental Revenue Management", :keyword2 189, :authors (59580), :session 236}, 651 {:keyword1 29, :keyword3 0, :abstract "In Europe, the buildings sector accounts for 40% and cities for 69% of final energy consumption. The share of CO2 emissions in cities and urban districts are correspondingly high. To achieve the climate protection goals in Europe, new energy supply strategies must be sought for urban districts, which will not only make it possible to reduce CO2 emissions, but will also keep the costs of energy supply stable and guarantee security of supply.\r\nThe special nature of urban districts is the limited potential for the installation of generation units on the one hand and the high population density with an accompanying high demand for energy on the other. Photovoltaics (PV) for electricity production, solar thermal and geothermal energy for heat generation are the most suitable renewable energy (RE) technologies in urban areas. However, a largely self-sufficient power and heat supply based on RE is difficult to implement in urban districts with limited RE potential. Furthermore, it should be noted that sector coupling options such as power-to-heat or electric vehicles will lead to an increasing demand for electricity in urban district in the future. The implementation of microgrids is a possible strategy for more efficient use of resources and greater integration of decentralized power generation and electric mobility. \r\nThis paper analyses different scenarios with different penetration rates of electric vehicles and the resulting effects on energy demand, structure of power generation and transmission as well as energy system costs of a specific urban district in Germany. \r\nThe analysis based on a mixed-integer linear programming approach, which determines an optimal technology configuration for a specific urban district and additionally optimizes the operation of generation technologies, storage technologies and energy transmission between the buildings. The total annual discounted energy system costs are calculated in a time resolution of one hour and in a spatial resolution of 18 building nodes. The energy system costs consist of fixed and capacity dependent investment costs and fixed and variable operating costs of the installed technologies. The demand for heat and electricity in the buildings is determined by using a bottom-up model approach. Furthermore, traffic demand profiles for the urban district are synthesized and the additional local power consumption for charging the electric vehicles is determined with different penetration rates.\r\n", :title "Optimization of Urban Energy Supply Systems Considering an Increasing Integration of Battery Electric Vehicles", :keyword2 158, :authors (59841 59902 59903 59904 59905), :session 8}, 656 {:keyword1 103, :keyword3 0, :abstract "Behavioural operational research has accumulated evidence that many even highly educated people show a surprisingly poor mental ability to correctly infer the behaviour of even the simplest stock-flow systems consisting of only one stock, one inflow, and one outflow. This so called stock-flow-failure is shown to be a robust and persistent phenomenon comparable to the deep-rooted issues that people have in probabilistic judgments. It severely hampers human decision making in dynamic operational systems. \r\nTypically, stock-flow ability is measured using paper and pencil tasks that present a dynamic stock flow challenge, for instance determining the outflow from a stock whose inflows over time are provided. The purpose of this paper is to present an alternative, more naturalistic way of assessing this ability. A tangible stock-flow experiment is used in this study, which asks participants to pour a certain amount of water into a glass through a funnel in an as short time as possible. A range of measures of stock-flow thinking ability in this more naturalistic setting is derived and compared to the traditionally used more abstract indicators. Findings are that tangible and non-tangible measures are less related than expected. Measurement seems to make a difference. The methodological implication of this study is that more attention has to be paid to the way how stock-flow thinking ability is measured. Further research should extend this study by using a broader range of tangible stock-flow tasks and include individual differences of the participants. \r\n", :title "Tangible versus non-tangible measurements of human stock-flow thinking ability", :keyword2 19, :authors (19811), :session 42}, 659 {:keyword1 57, :keyword3 170, :abstract "A superpermutation on n symbols is a string that contains each permutation of n symbols as a substring. Due to its numerous applications, it is often desirable to find the smallest superpermutation for a given number of symbols. The smallest superpermutaion and optimal length have already been established for up to five symbols utilizing a clever exhaustive enumeration. However, for more than five symbols, establishing the length of minimal superpermutation and finding a superpermutation for a given value of n continues to be an open problem. So far, the asymmetric traveling salesman formulation of the problems has been able to produce high quality solutions for six symbols. But being a hard optimization problem, this exact technique fails to solve the  problem to optimality. Interestingly, multiple formulations are possible for this problem and the present work aims at studying these formulations and identifying formulations which are capable of producing optimal or near optimal superpermutations on six or more than six symbols. Formulations are compared based on the solution quality and are utilized to generate meaningful bounds on the optimal length of the superpermutation. To be able to cope with the increasing complexity of the problem as value of n increases, multiple-phase techniques are proposed which utilize different formulations in each phase. Another contribution of this work is a constructive matheuristic (CMH) strategy for the superpermutation problem. A CMH strategy is a decomposition based method which utilizes optimal solutions of the subproblems to construct a solution for the full problem. Being a heuristic, CMH does not guarantee optimal solutions, but is capable of generating quality solutions for problems with large number of symbols where exact techniques fail to be efficient. CMHs which use different formulations to solve the subproblems are compared and their performances are contrasted. Finally, a comprehensive evaluation of all the proposed formulations based on solution quality, algorithm runtime and generated bounds on the length of the superpermutation is presented. Best solutions found and newly generated bounds on the length of minimal superpermutation are also presented.", :title "A comparison of mathematical formulations for the superpermutation problem", :keyword2 150, :authors (58624 25830), :session 217}, 660 {:keyword1 174, :keyword3 0, :abstract "In single wagonload traffic, railcars are routed from their sources to their sinks in multiple trains, as no direct train service is available for all origin-destination-pairs. Therefore, railcars interchange from one train to another in so-called classification yards. Railcar interchanges require the disassembly of inbound trains, the assignment of railcars to outbound trains and the classification of outbound trains. \r\nIn order to ensure a smooth and safe operation, many safety and service operations must be planned and executed. The operations must be fulfilled in a given order and time window. They require both infrastructure elements, locomotives, and staff with process-specific skills. Hence, a complex scheduling and assignment problem arises. Even though some parts of the problem have been extensively studied, very few holistic models can be found in literature.\r\nIn this talk, we present a MIP formulation tackling simultaneously the scheduling of all operations, the resource assignment, and the railcar assignment. Due to the complexity of the problem, realistic instances cannot be solved with general-purpose solvers in a reasonable time. Therefore, we propose an Adaptive Large Neighborhood Search (ALNS) tailored for the described problem. We validate the quality of the solutions of the ALNS on small and medium-sized instances. Last, we report the performance of the ALNS for realistic instances. ", :title "An Adaptive Large Neighborhood Search for a scheduling and assignment problem in classification yards", :keyword2 96, :authors (57524 913), :session 155}, 661 {:keyword1 175, :keyword3 0, :abstract "Delayed passenger trains are still a major issue for railway companies. Some of the delays are caused by external events and often cannot be avoided. Others occur on a regular basis and can probably be avoided by improving the timetables. One important measure to improve the robustness, and thus the punctuality, of a timetable is to add supplement running times and dwell times. The supplement times can be used to reduce delays during a trip in real-time. However, too much supplement time reduces the capacity utilization of the railway infrastructure and should therefore be avoided.\r\nWe present a data-driven approach to determine the amount and allocation of supplement running times for a given timetable in order to reduce systematic train delays. First, we show how systematic delays can be detected and classified. Next, we analyze correlations between systematic delays and the supplement running times for the corresponding trains. In doing so, we identify tracks where more supplement running time is needed and tracks where the available supplement running time is not used up. Based on those results, we show how supplement running times should be shifted in order to use them more efficiently and reduce delays. In doing so, we do not change arrival or departure times or train sequences. Thus, the original timetable is preserved.\r\nTo demonstrate the approach, we use a dataset of the German railway company ‘Deutsche Bahn’, which contains delay information about every passenger and freight train that utilized the German railway infrastructure in 2016. We present examples where our approach leads to a better allocation of supplement running times and reduces delay times for trains.", :title "Improving Train Route Punctuality by Shifting Supplement Running Times", :keyword2 105, :authors (55692 1194), :session 211}, 663 {:keyword1 95, :keyword3 157, :abstract "Two critical yet frequently conflicting objectives for logistics and transportation service companies are improving customer satisfaction and reducing transportation cost. In particular, given a network of customer requests with preferred service times, it is very challenging to find vehicle routes and service schedules simultaneously that respect all operating constraints and minimize the total transportation and customers' inconvenience costs. In this paper, we introduce the Vehicle Routing Problem with Time Windows and Convex Node Costs (VRPTW-CNC), in which we model each customer's inconvenience cost as a convex function of the service start time at that customer. The VRPTW-CNC combines and extends both the standard vehicle routing problem with time windows and some previous results on the optimal service scheduling problem over a fixed route. We propose a branch-cut-and-price algorithm to solve the VRPTW-CNC with general convex inconvenience cost functions. To solve the pricing problem, our labeling algorithm only generates labels that possibly lead to optimal schedule times over a route, which significantly improves the effectiveness of pricing. Extensive computational results demonstrate the effectiveness of our approach.", :title "Branch-Cut-and-Price for the Vehicle Routing Problem with Time Windows and Convex Node Costs", :keyword2 8, :authors (4161 41330 44622), :session 217}, 664 {:keyword1 152, :keyword3 2, :abstract "The general trend in the aviation industry in last years has been generate ancillary revenue by offering additional services. Low-cost carriers are particularly known to only offer ancillary services a la carte (pure components). Many network carriers have adapted to unbundle their services and seek ancillary revenues, too. Preventing possible negative impact on customer perception and brand image, most of these traditional airlines also offer branded fares beside the single unbundled components as a preset bundle, where certain ancillaries are included (mixed bundling). In this study we introduce a novel perspective for ex-post evaluation of given bundle-pricing policies in the mixed bundling context and interpret the ancillary revenue sources as well as opportunities through comparing so-called transition-streams between three choices of a customer, namely no ancillaries, a la carte and bundle. We use standard regression methods (multinomial logit) to infer individual behaviour by analyzing aggregated data on market level from a major European airline. With the General Data Protection Regulation in the European Union come into effect, such high-level models which only require aggregated market data and no individual personal data are becoming more relevant. By using such models however, we assume the characteristics of customer-mix in each observed market are similar between the comparing periods. Under this assumption, the results reveal existence and variability of price elasticities among different segments based on likelihood ratio test. These results would help companies to segment their market based on price elasticity and optimize their ancillary offerings accordingly.\r\n", :title "A statistical approach to evaluate pricing policy on aggregated market level for mixed bundling", :keyword2 91, :authors (59908), :session 89}, 665 {:keyword1 94, :keyword3 57, :abstract "Multivariate Adaptive Regression Spline (MARS) is a modern methodology of data mining, statistical learning and estimation theory that is essential in both regression and classification. In recent years, MARS is applied in various areas of science, technology, finance, and engineering. It is a form of flexible non-parametric regression analysis capable of modeling complex data. There, it is supposed that the input data are known exactly and equal to some nominal values to construct a model. However, both output and input data include noise in real life. Solutions to optimization problems may present signiﬁcant sensitivity to perturbations in the parameters of the problem. So, optimization affected by parameter uncertainty is a focus of the mathematical programming and a need to handle uncertain data when optimization results are combined within real-life applications. As a result, in inverse problems of modeling, solutions to the optimization problems involved in MARS can represent a remarkable sensitivity with respect to perturbations in the parameters which base on the data, and a computed solution can be highly infeasible, suboptimal, or both. Under this motivation, we have included the existence of uncertainty into MARS and robustified it through robust optimization which is proposed to cope with data and, hence, parametric uncertainty. We have represented Robust MARS (RMARS) under polyhedral uncertainty. \r\n\r\nIn our previous studies, although we had small data sets for our applications, the uncertainty matrices for the input data had a huge size since vertices were too many to handle. Consequently, we had no enough computer capacity to solve our problems for those uncertainty matrices. To overcome this difficulty, we obtained different weak RMARS (WRMARS) models for all sample values (observations) applying a combinatorial approach and solved them by using MOSEK program. Indeed, we have a tradeoff between tractability and robustification.  In this presentation, we present a more robust model using cross-polytope and demonstrate its performance with the application of Natural Gas consumption prediction. Applying robustification in MARS, we aim to reduce the estimation variance.\r\n", :title "Robust Multivariate Adaptive Regression Splines (RMARS) under Polyhedral Uncertainty: The case of Prediction for Natural Gas Consumption", :keyword2 124, :authors (3524 20485 30325), :session 209}, 666 {:keyword1 35, :keyword3 99, :abstract "After the UK's decision to withdraw from the European Union had been finalized by the referendum, the first financial reaction was observed as a sudden depreciation of the pound, and trend of the pound has become a source of concern. In this study, via the Hidden Markov Model, pound exchange rate for the year 2018 has been predicted using pound rates and related economic factors observed in UK between the years 2016-2017. The accuracy of the predicted pound values has been found to be quite high.\r\n", :title "Prediction of Pound Exchange Rate via Hidden Markov Model in the Process of Brexit", :keyword2 37, :authors (19185), :session 198}, 667 {:keyword1 40, :keyword3 65, :abstract "We study strong equilibria in network creation games. These form a classical and well-studied class of games where a set of players form a network by buying edges to their neighbors at a cost of a fixed parameter α. The cost of a player is defined to be the cost of the bought edges plus the sum of distances to all the players in the resulting graph. \r\nWe identify and characterize various structural properties of strong equilibria, which lead to a characterization of the set of strong equilibria for all α in the range (0,2). For α>2, Andelman et al. (2009) prove that a star graph in which every leaf buys one edge to the center node is a strong equilibrium, and conjecture that in fact any star is a strong equilibrium. We resolve this conjecture in the affirmative. Additionally, we show that when αis large enough (≥2n) there exist non-star trees that are strong equilibria. For the strong price of anarchy, we provide precise expressions when α is in the range (0,2), and we prove a lower bound of 3/2 when α≥2. \r\nLastly, we aim to characterize under which conditions (coalitional) improvement dynamics may converge to a strong equilibrium. To this end, we study the (coalitional) finite improvement property and (coalitional) weak acyclicity property. We prove various conditions under which these properties do and do not hold. Some of these results also hold for the class of pure Nash equilibria.", :title "On Strong Equilibria and Improvement Dynamics in Network Creation Games", :keyword2 134, :authors (45236), :session 145}, 668 {:keyword1 40, :keyword3 65, :abstract "We introduce and analyze the possibilities of a new model for network creation by autonomous selfish agents: Unlike in typical network formation games such as the well-known model of Fabrikant et al. [PODC'03], the final network is not directly shaped by the players of a game. Instead, we design mechanisms that take edge preferences of agents as input for a social choice function and return a network that respects those preferences. In addition, it caters for compliance with global restrictions on the network topology and tries to establish several properties, such as global efficiency, maximizing the individual utility of agents, and building stable networks, especially in comparison to the result of an anarchic network formation. The mechanism also aims to produce Nash equilibria and encourages agents to honestly declare their preferences instead of playing strategically.\r\nThe mechanism approach is a true superset of both centralized network design and uncoordinated network creation games. To the best of our knowledge this is the first attempt to explore the realm inbetween those extremes.", :title "Mechanisms for Network Creation", :keyword2 134, :authors (59874 42734), :session 145}, 669 {:keyword1 40, :keyword3 99, :abstract "We consider clustering games in which the players are embedded in a network and want to coordinate (or anti-coordinate) their choices with their neighbors. Recent studies show that even very basic variants of these games exhibit a large price of anarchy. Our main goal is to understand how structural properties of the network topology impact the inefficiency of these games. We derive topological bounds on the price of anarchy for different classes of clustering games. These bounds provide a more informative assessment of the inefficiency of these games than the corresponding (worst-case) price of anarchy bounds. As one of our main results, we derive novel inefficiency bounds for clustering games on Erdős-Rényi random graphs which, depending on the density, stand in stark contrast to the known price of anarchy bounds.", :title "Topological inefficiency bounds of clustering games on (random) networks", :keyword2 134, :authors (59910), :session 145}, 671 {:keyword1 161, :keyword3 0, :abstract "The weighted sum method is a popular and widely used scalarization method in multiobjective optimization. Resulting solutions are guaranteed to be (weakly) efficient. Typically, the set of weights to be considered consists of vectors with non-negative components which sum up to one. For linear problems, this set is a polytope with some particular structural properties. Knowledge about the structure of the weight set implies some knowledge about the structure of the set of nondominated points. In this talk, we review existing methods for decomposing the weight set polytope into sub-polytopes. These sub-polytopes are characterized by the fact that each weight in a sub-polytope yields the same nondominated point. We propose a new method for obtaining an exact decomposition of the weight set. Moreover, the idea of obtaining an approximate decomposition with manageable quality will be newly introduced.\r\n", :title "Exact and Approximate Weight Set Decomposition", :keyword2 57, :authors (12666 57906 14848 59690), :session 2}, 672 {:keyword1 158, :keyword3 0, :abstract "Oligopolies are markets dominated by a small number of players competing for the same pool of customers. These players are utility maximizers, and their strategic decisions are influenced by both the preferences of the customers and the decisions of their competitors. In our work, the preferences of the customers are modelled at a disaggregate level according to the random utility theory, while competition among market players is modelled as a non-cooperative game.\r\n\r\nWe discuss some methodological approaches to model competition in a demand-based optimization framework which is particularly suitable for oligopolistic markets. Such approaches allow us to analyze oligopolies from three perspectives: at a customer level, by using discrete choice models to take into account preference heterogeneity and to model individual decisions; at an operator level, by solving a mixed integer linear program that maximizes any relevant objective function; and at a market level, by investigating the concept of Nash equilibrium in the resulting non-cooperative multi-leader-follower game. At the latter level, in order to find equilibrium solutions for this type of problem, we investigate the following solution approaches: an algorithm based on the fixed-point iteration method to model sequential games; a mixed integer linear program that enumerates the pure strategy Nash equilibria of a finite game; and an extension of this mixed integer linear program in which competitors are allowed to play mixed strategies.\r\n\r\nPreliminary results show that it is possible to find pure strategy Nash equilibria of games having both a finite and an infinite strategy set. However, Nash’s existence theorem only guarantees the existence of at least one mixed strategy equilibrium for finite games. Therefore, in the current phase of our research, particular emphasis is placed on the development of a model that finds mixed strategy Nash equilibrium solutions for finite games. ", :title "Modelling competition in demand-based optimization models", :keyword2 40, :authors (59879 36097 26236), :session 216}, 673 {:keyword1 40, :keyword3 42, :abstract "A Stackelberg network pricing game is a two-stage game, in which, in the first stage, a leader sets prices/tolls for a subset of edges so as to maximize profit (all other edges have a fixed cost), and, in the second stage, one or multiple followers choose a shortest path from their source to sink. Labbé et al. (1998) showed that finding optimal prices with lower bounds is NP-hard and gave an example in which profit is maximized by using negative prices. We explore this last phenomena and try to answer the following two questions. First, for which network topologies can the leader increase profit by using negative prices? Second, how much more profit can the leader realize by setting negative prices?", :title "Negative Prices in Stackelberg Network Pricing Games", :keyword2 134, :authors (59913), :session 147}, 677 {:keyword1 42, :keyword3 0, :abstract "Extremal Graph Theory aims to determine bounds for graph invariants as well as the graphs that attain those bounds. We are currently developping PHOEG, an ecosystem of tools designed to help researchers in Extremal Graph Theory. It uses a big database of undirected graphs and works with the convex hull of the graphs as points in the invariants space in order to exactly obtain the extremal graphs for some fixed parameters and infer optimal bounds on the invariants. This database also allows us to make queries on those graphs. \r\n\r\nFor a given problem (set of invariants under consideration), PHOEG allows to identify conjectures about extremal graphs. Usually, this step is not the most difficult. However, once a conjecture is highlighted, finding a general proof can be hard. To this aim, PHOEG goes one step further by helping in the process of designing a proof guided by successive applications of transformations from any graph to an extremal graph. In this talk we present the ideas and techniques used in PHOEG to assist the study of Extremal Graph Theory.", :title "PHOEG Helps Obtaining Extremal Graphs", :keyword2 5, :authors (51079 51088 48827), :session 230}, 678 {:keyword1 95, :keyword3 8, :abstract "The generalized traveling salesman problem with time windows (GTSPTW) can be defined as follows. Given a directed graph, the vertex set is partitioned into clusters with one cluster including only the depot. Arcs are only defined between vertices belonging to different clusters. Each vertex is associated with a time window (TW) and each arc has a traveling cost and a traveling time. The objective of the GTSPTW is to find a minimum cost tour starting and ending at the depot such that each cluster is visited exactly once and time constraints are respected. It reduces to the well-known Generalized Traveling Salesman Problem when TWs are not considered. \r\n\r\nSeveral valid inequalities are proposed for the GTSPTW, dividing into two types, i.e., polynomial families and exponential families. Polynomial families: (1) Arc orientation inequalities. An arc can only be oriented in one way, it either enters or leaves a vertex. This family of inequalities can be generalized considering clusters instead of vertices. (2) Arc-or-vertex inequalities. If a vertex cannot be visited either before or after an arc due to TWs, then only one of them can be chosen in any feasible solution. Exponential families: (1) Generalized subtour elimination constraints (GSEC). (2) Sequential ordering polytope constraints (SOP). SOP inequalities are based on the precedence relationships between pairs of vertices which are inferred by TWs. (3) Clique inequalities. If there is no feasible path passing through all the vertices in a certain set, then the number of vertices in this set that can be visited in all feasible solutions is strictly less than the size of the set. \r\n\r\nWe develop a branch-and-cut algorithm for the GTSPTW. Here we describe some important procedures included in this algorithm: (1) Preprocessing. The size of the problem can be reduced by eliminating arcs and vertices that cannot be a part of any feasible solution. (2) Initial heuristic to calculate upper bound. Given a fixed cluster sequence, a feasible solution can be obtained by solving a shortest path problem with TWs. (3) Separation algorithms to tighten lower bound. Heuristic separation for SOP inequalities and exact separation for GSEC inequalities are developed to iteratively improve the lower bound. Besides, other valid inequalities are stored in a cut pool and they are taken into account only when violation is found. (4) Branching priorities. To enhance the perfermance of the branch-and-cut algorithm, we branch on priority on variables that fix the visiting sequence of the clusters. \r\n\r\nThe algorithm is implemented in C++ using CPLEX 12.6 and Concert framework. For testing our algorithm, we propose new instances for the GTSPTW derived from GTSP instances. Results show that the proposed valid inequalities are effective to improve the lower bound. Instances with up to 24 clusters and 120 vertices can be solved to optimality within one hour. ", :title "A branch-and-cut algorithm for the generalized traveling salesman problem with time windows", :keyword2 158, :authors (59894 51294 54943 2247), :session 151}, 679 {:keyword1 175, :keyword3 0, :abstract "    In this work we study a commodity constrained split delivery vehicle routing problem (C-SDVRP) where customers require multiple commodities. In the C-SDVRP, the vehicles are flexible and can deliver any set of commodities, and a customer who requires multiple commodities can be delivered by different vehicles. However, when a commodity is delivered to a customer, the entire required amount is handed over. This problem arises when customers require several commodities and they accept that commodities are delivered separately, but for convenience they require that each commodity is delivered only once. For example, in delivery of fresh fruits and vegetables to catering, commodities can easily be mixed into the same vehicle, and splitting the delivery of an individual commodity is not acceptable.\r\n\r\n    The C-SDVRP is to find a solution that minimizes the total transportation cost and that involves two related decisions such as finding a set of vehicle routes that serve all customers and to select the commodities that are delivered by a vehicle route to each customer. Moreover, each solution must be such that: (1) each route starts and ends at the depot; (2) the total quantity of commodities delivered by each vehicle does not exceed the vehicle capacity; (3) each commodity requested by each customer must be delivered by a single vehicle; (4) the demands of all customers need to be satisfied.\r\n\r\n    This work aims at proposing an efficient heuristic to tackle medium and large sized C-SDVRP instances. To this end, we propose an adaptive large neighborhood search (ALNS) heuristic taking into account the specific features of the C-SDVRP. A C-SDVRP instance can be transformed into a CVRP instance by replicating each customer as many time as the required commodities, but this produce many equivalent solutions when exchanging commodities of the same customer. In order to avoid that, the proposed method explicitly takes into account the customer location associated to a commodity.\r\n\r\n    The proposed method relies on the ALNS algorithm and we apply some removals and insertions heuristics to the C-SDVRP.\r\nTo improve a solution, we adapt existing local search (LS) operators in order to deal with a customer as a whole (i.e., with the whole demand he/she requires) or only as a part (i.e., with a single commodity he/she requires). Moreover, in order to further improve the quality of a new global best solution, mathematical programming based operator that reassigns commodities to routes is developed.\r\n\r\n    Computational experiments have been performed on benchmark instances from the literature. The results confirm the efficiency of the algorithm. We provide a large number of new best known solutions for medium and large sized instance with up to 100 customers and 3 commodities, within a short computing time.", :title "Adaptive large neighborhood search for the commodity constrained split delivery VRP", :keyword2 95, :authors (59896 51294 54943 2247), :session 153}, 681 {:keyword1 7, :keyword3 45, :abstract "With the convergence of risk factors driving disease emergence, amplification and dissemination of pandemic prone pathogens, emerging diseases pose a greater threat to mankind now than ever before.  A key challenge for pandemic planning is assess the resilience of their health systems to cope with the demands brought on by the emergence of a new infectious agent, and to plan in an optimal manner to minimize adverse health and security outcomes. The acquisition and deployment of health system resources is a crucial activity for mitigating the impact of a pandemic. This research draws on the conceptual approach of Forrester’s Market Growth Model to identify the key feedbacks for this pandemic preparedness planning. The dynamic model is based on the SEIR structure, and includes health systems features such as the vaccine supply chain, and key resources such as  anti-virals, hospital beds, and surge capacity intensive care unit beds, and surge capacity.\r\n\r\nThe model shows important feedbacks, and how resource availability determines health outcomes. The model building process was informed by systematic literature reviews, expert workshops in public health surveillance and solutions, in-depth interviews with domain experts. Many ensembles of results are analysis using statistical screening, and the most influential parameters identified. The value of this model is that it can be used as part of an integrated planning approach, and provide public health professionals  with an assessment of their preparedness for a pandemic event. The system will also allow for the quantification of resources required, and provide guidance as to the optimal ways to allocate these resources in order to minimise morbidity and mortality rates.\r\n\r\n", :title "A System Dynamics Model to Explore the Impact of Resource Availability on Mitigating Pandemic Risk", :keyword2 103, :authors (23013), :session 42}, 682 {:keyword1 40, :keyword3 134, :abstract "The talk addresses the quality of Nash equilibria for congestion games with affine cost functions when the strategy spaces of the players are the set of bases of a k-uniform matroid. In this setting, for some parameter k, each player is to choose k out of a finite set of resources, and the cost of a player for choosing a resource depends affinely on the number of players choosing the same resource. Earlier work shows that the price of anarchy for this class of games is larger than 4/3 but less then 5/2. In this talk we give an almost final answer to close this gap. We determine an asymptotically tight bound on the price of anarchy equal to approximately 1.3518. This bound holds for all instances with sufficiently many players. Our analysis also yields an upper bound on the price of anarchy less than 1.4132, which holds for all instances. The new idea underlying our analysis is to interpret the difference between the equilibrium and optimum solutions as alternating paths in a bipartite graph. (Joint work with J. de Jong, W. Kern, and B. Steenhuisen)", :title "The price of anarchy for k-uniform matroid congestion games", :keyword2 8, :authors (1019), :session 91}, 683 {:keyword1 40, :keyword3 173, :abstract "Stable flows generalize the well-known concept of stable matchings to markets in which transactions may involve several agents, forwarding flow from one to another. An instance of the problem consists of a capacitated network, in which vertices express their preferences over their incident arcs. A flow is stable if there is no pair of nodes that could benefit from rerouting the flow along a walk with free capacity. Fleiner established existence of stable flows in any network via reduction to the stable allocation problem. We present an augmenting-path algorithm for computing a stable flow, the first algorithm that achieves polynomial running time for this problem without using stable allocation as a black-box subroutine. We also consider the problem of finding a stable flow such that the flow value on every edge is within a given interval. We present an elegant graph transformation that leads to a simple and fast algorithm for this problem and that can also be used to find a solution to the stable marriage problem with forced and forbidden edges.", :title "New and simple algorithms for stable flow problems", :keyword2 134, :authors (26508 59916), :session 145}, 686 {:keyword1 157, :keyword3 42, :abstract "Every student in North Rhine-Westphalia, Germany, studying to become a teacher, has to do a semester of practical courses at a school. In order to assign students to schools and satisfy the requests of the students, without exceeding capacity limitations of the schools, the problem is modeled as a discrete, assignment-like optimization problem and solved to optimality. \r\nEvery student can select a priority list of five schools, where he wants to do his internship. To avoid arbitrary assignments in the case that a student can not be assigned to one of its priority choices, every student additionally selects a location, where the school for the internship should be close by. Thus, we obtain a composite objective function, maximize the number of satisfied requests and if none of the requests of a student can be fulfilled minimize the distance of the assigned school to the selected location. \r\nSince students study two major subjects, a school has to provide capacity in both of them to be a candidate for a feasible assignment. An additional requirement comes from the fact that students have to attend seminar courses in the respective subjects in parallel to their internship. These courses are associated with costs which form, depending on the model formulation, another set of capacity constraints or a second objective function.\r\nOverall we yield a specific kind of assignment problem, which can be represented by a multi-commodity flow network. Alternative formulations, some theoretical results and computational results of this practically applied problem are presented.", :title "Assigning Students to Schools for an Internship", :keyword2 161, :authors (9695 1560 45302), :session 84}, 687 {:keyword1 40, :keyword3 65, :abstract "Wardrop equilibria in nonatomic congestion games are in general inefficient as they do not induce an optimal flow that minimizes the total travel time. Network tolls are a prominent and popular way to induce an optimum flow in equilibrium. The classical approach to find such tolls is marginal cost pricing which requires the exact knowledge of the demand on the network. In this paper, we investigate under which conditions demand-independent optimal tolls exist that induce the system optimum flow for any travel demand in the network. We give several characterizations for the existence of such tolls both in terms of the cost structure and the network structure of the game. Specifically we show that demand-independent optimal tolls exist if and only if the edge cost functions are shifted monomials as used by the Bureau of Public Roads. Moreover, non-negative demand-independent optimal tolls exist when the network is a directed acyclic multi-graph. Finally, we show that any network with a single OD pair admits demand-independent optimal tolls that, although not necessarily non-negative, satisfy a budget constraint.", :title "Demand-Independent Optimal Tolls", :keyword2 134, :authors (26950 59939 23325), :session 149}, 688 {:keyword1 95, :keyword3 40, :abstract "We consider a non-atomic network congestion game with incomplete information in which the incomplete information comes from randomness in the demand. We model this as a multi-commodity flow, where for each commodity it is uncertain if it will actually appear in the network. Wang, Doan, and Chen (2014), by considering an equilibrium notion in which users evaluate their expected cost using the full knowledge of the demand distribution, concluded that the price of anarchy of the game can be arbitrarily large. We consider the problem to be a Bayesian game, where users evaluate their cost conditioned on the fact that they themselves are present in the network. In contrast to the conclusion by Wang, Doan, and Chen (2014), we find that the known bounds on the price of anarchy for the deterministic demand game also apply to the Bayesian game, even if the probability of traveling for different commodities is arbitrarily correlated. Specifically, if all latency functions in the network are affine, the price of anarchy for the Bayesian game is 4/3. This result can also be generalized to the class of smooth games.", :title "Network Congestion Games are Robust to Variable Demand", :keyword2 134, :authors (29289 45062 59913), :session 149}, 691 {:keyword1 25, :keyword3 33, :abstract "\r\nLocation games are a classical object of study in economics, mathematics, op- erations research and game theory.  We consider a two-sided facility location game, where both facility and client agents face non-trivial strategic choices which influence each other. We introduce and analyze a generalization of Hotelling’s classical model, where the utility of a client agent not only depends on her distance from her selected facility but also on its load. ", :title "Two-Sided Facility Location Games", :keyword2 40, :authors (44469 42734 44822 59919), :session 91}, 692 {:keyword1 121, :keyword3 0, :abstract "An important problem in staff scheduling is roster generation. The task is to find an assignment of shifts to employees, such that qualification restrictions and demands are met as well as possible. This assignment problem is in particular challenging due to business rules concerning working time, day on/off patterns, rest times, or employee preferences. This talk outlines INFORM’s staff rostering optimizer that is used to solve large-scale real-world rostering instances, and evaluates the performance of the optimizer on nurse rostering data. Moreover, we describe how we integrate the optimizer into our system and adapt it to the needs of our customers using a declarative programming framework.\r\n", :title "Real-world staff rostering via branch-and-price in a declarative framework", :keyword2 57, :authors (59918 45742 60537 59927), :session 158}, 693 {:keyword1 91, :keyword3 0, :abstract "The standard parallel machine scheduling problem deals with the assignment of each job of a given set to exactly one machine of a given set in order to minimize an objective function value, e.g., the number of late orders, the makespan etc. In this talk, we extend the setting for a preceding selling period, i.e., the set of jobs is no longer given ex ante, but is the result of selling standardized products - which are characterized by a processing time and a revenue - throughout a selling horizon. Opposed to standard order acceptance settings, each arriving customer is offered a subset of all possible products, from which she/he chooses at most one, depending on the individual valuations for the different products. As soon as a product is sold to a customer, it becomes a job that needs to be scheduled in the subsequent service period. The question to be answered is: Which subset of products should individually be made available to each customer such that the overall profit, i.e., the overall revenue minus the scheduling cost is maximized? In order to solve the problem, a dynamic programming formulation is presented and its intractability is shown. In order to be able to solve real world instances, different heuristic algorithms are proposed. In a simulation study, the algorithms and their quality – compared to a greedy heuristic and the optimal solution (for small instances) – are compared.", :title "Integrating Revenue Management and Parallel Machine Scheduling", :keyword2 96, :authors (59920 16305), :session 180}, 694 {:keyword1 150, :keyword3 157, :abstract "Lift-and-project cuts are well-known general 0-1 programming cuts which are typically deployed in branch-and-bound-type methods to solve MILP problems. In this talk, we discuss ways to use these cuts in Benders' type decomposition algorithms for solving two-stage stochastic programming problems with binary first-stage variables. In particular, we show how L&P cuts derived for the mixed-binary first-stage master problem can be strengthened by utilizing second-stage information. We present an adapted L-shaped algorithm and some computational results.", :title "Utilizing strengthened lift-and-project cuts in decomposition methods to solve two-stage stochastic programming problems with binary first-stage variables", :keyword2 165, :authors (55472 9272 29687), :session 208}, 695 {:keyword1 157, :keyword3 150, :abstract "Applying Dantzig-Wolfe reformulation to specially structured mixed integer programs is well-known for yielding strong dual bounds from the linear programming relaxation. This special structure is typically a reordering of the coefficient matrix to singly bordered block diagonal form. For instances without any known structure, one needs to find such reordering in order to apply Dantzig-Wolfe reformulation. In our talk we present (a) the structure detection algorithm that we implemented in the generic branch-and-price solver GCG, (b) structure detection results for instances from the MIPLIB with unknown structure, and finally (c) a computational study of the resulting dual bounds for these instances.", :title "A Computational Study on the Strength of Dantzig-Wolfe Reformulations on Real-World Mixed Integer Programs with Unknown Structure", :keyword2 153, :authors (33581 14969), :session 66}, 697 {:keyword1 41, :keyword3 29, :abstract "The share of renewable electricity generation is raising in many countries all over the world leading to a more volatile energy generation as well as higher fluctuating electricity prices on power markets. This more flexible environment is posing major challenges to an efficient and economic operation of combined heat and power generation connected to district heating grids as the traditional heat driven control strategy does not consider volatility on the electricity side. \r\nEspecially the consideration of heat storage capabilities together with extremely volatile electricity prices is promising economic benefits to heating grid operators. If no dedicated heat storage tank is available, the heating grid itself can be used as a storage. However optimal operation considering this inherent grid storage capability is challenging, as the resulting model formulation is non-convex containing bilinear terms and variable time delays.\r\nIn the past there have been several approaches to find suitable optimization models for this problem. In all papers known to the authors, the problem is approached using linearization or simplifying assumptions resulting in a linear optimization model. Sometimes the linear optimization model is combined with a non-linear simulation to update the parameters and run the optimization in an iterative scheme. However, to the best knowledge of the authors, no global optimal solution for this problem has been proposed.\r\nIn this paper we would like to present an iterative solution scheme leading to a global optimum using multiparametric disaggregation for the bilinear terms and a new modeling method for the representation of variable time delays. Jointly with multiparametric disaggregation the new modeling approach can be used to derive a lower bound for the global optimization problem, whose precision can be increased in every iteration. As upper bound the solution of a non-linear optimization model with fixed integer decision variables is used.\r\nThe capabilities of this new approach will be presented in a small case study. \r\n", :title "Globally optimal short-term unit commitment and dispatch for combined heat and power generation units connected to district heating grids", :keyword2 96, :authors (37842 59922), :session 7}, 698 {:keyword1 63, :keyword3 0, :abstract "Rapid changes in the World diversify the products and services on both side, organizations and the customers. On one side, customers who demand a variety of products and services, on the other hand, organizations who aim to produce high quality and durable products have appeared. This makes the existing understanding needs to be changed in the way of development. In this sense, under the effect of globalization and innovation, research and development (R&D) and R&D activities become much more popular and important in developing new services and products and improving existing services and products. R&D can be defined as the development of new products and services, new production methods with new technologies, and creating a knowledge.  Nowadays, countries, institutions begin to support the enterprises, organizations, and academicians to R&D projects. R&D is very difficult to manage, having a risk in the financial area and activities are classified differ from one company to the other.  Therefore, it is too difficult to evaluate the R&D and R&D projects.\r\n\r\nIn this study, as being a part of R&D, a selection and ranking procedure has been applied to a project competition which is committed in ATA Techno city. This study designs an evaluation indicator system and analytical model according to the given criteria which are specified by experts who work in ATA Techno city. ANP method and DEMATEL method used as a hybrid to find the specified criteria weights within 4 main and 20 sub-criteria. With the use of ANP and DEMATEL together gave us the dependent criteria weights which will be used in our developed indicator system as an indicator. After getting the order of importance at the indicators, total weight and then compare and selection of the various projects obtained. \r\n", :title "R&D Project Selection with use of ANP and DEMATEL Methods", :keyword2 0, :authors (20840 59923), :session 175}, 699 {:keyword1 124, :keyword3 169, :abstract "Since 2004 almost all sea-going vessels are obligated to participate in the Automatic Identification System (AIS) for purpose of maritime safety, information, and surveillance. AIS is a system of cooperative VHF-radio exchange of navigational and ships' information. In previous work five standard methods has been applied to classification of maritime vessels based on a real-life AIS datasets from five maritime hotspots in early summer 2017, including English Channel, Strait of Gibraltar, and New York Harbor. Here, we addressed the question, up to what accuracy categorization of vessels can be accomplished based on ship's positional, motion, and dimensions' AIS-data. In this extending work, the research question is, if it is possible to further improve classifications' accuracies by use of classifiers' combinations. Using a voting mechanism, classifiers combining different basic methods appear promising, e.g., based on a combination of Decision Tree, Fuzzy Rule, and k Nearest Neighbor. Likewise we are interested in the performance of same type classifiers' combinations in this maritime application, e.g., Random Forests. For evaluation, we use the KNIME Analytics Platform (www.knime.org), an open-source Data Science environment, which provides a broad variety of methods and options.", :title "Combination of Classifiers for AIS-based Categorization of Maritime Vessels", :keyword2 183, :authors (26200), :session 242}, 700 {:keyword1 175, :keyword3 0, :abstract "In branch-price-and-cut algorithms for vehicle routing, variable fixing based on path reduced cost is a well-known speedup technique that allows to eliminate arcs after solving a linear relaxation. In this talk, we extend this technique to also eliminate sequences of two arcs. This requires modifying the labeling algorithm used to solve the pricing problem. Computational results on the vehicle routing problem with time windows and the electric vehicle routing problem with time windows will be reported.", :title "Two-arc sequence variable fixing in branch-price-and-cut algorithms for vehicle routing", :keyword2 0, :authors (29571 16468 18350 4161), :session 154}, 703 {:keyword1 54, :keyword3 0, :abstract "The Location Routing Problem (LRP) unites two important challenges in the design of distribution systems. On the one hand, the delivery of customers needs to be planned as effectively as possible, and on the other hand, the location of depots from where these deliveries are executed has to be determined carefully. In the last years many heuristic approaches have been proposed to tackle LRPs, and usually the computation of  excellent solutions comes at the cost of an intricate algorithmic design. Under the premise `if we can solve routing, we can solve LRPs', in this paper we introduce an efficient heuristic for LRPs that is entirely based on a heuristic to solve routing problems. We estimate an upper bound for the number of open depots, and iteratively apply the routing heuristic on each remaining location options. Despite its simple design, the heuristic competes with the best results in literature, and is the first one that can also be readily adapted to solve problems of very large scale.", :title "Solving Location Routing Problems is as simple (or difficult) as solving Routing Problems", :keyword2 95, :authors (51420 428), :session 165}, 705 {:keyword1 185, :keyword3 175, :abstract "The determination of frequencies and vehicle capacities is a crucial tactical decision when planning public transport services. All methods developed so far use static assignment approaches which assume average and perfectly reliable supply conditions. The objective of this study is to determine frequency and vehicle capacity at the network-level while accounting for the impact of service variations on users and operator costs. To this end, we propose a simulation-based optimization approach. Model formulation allows for minimizing user costs, operational costs or the combination of which by using simulated annealing as the search method in combination with a dynamic transit assignment simulation model. \r\n\r\nThe iterative model framework consists of three modules: \r\n\r\n(i) a dynamic public transport operations and assignment tool, BusMezzo, that considers the interaction between demand and supply and its potential impacts on service reliability. The assignment model involves an iterative network loading procedure which yield network-wide steady-state conditions which can be seen as an equivalent to the congested user equilibrium in conventional static assignment models. The model captured the following congestion effects: (1) Deteriorating comfort on-board a crowded vehicle, (2) denied boarding in case of insufficient vehicle capacity, (3) service headway fluctuations resulting from riding and dwell time variations; \r\n\r\n(ii) evaluating the performance of alternative solutions by transforming the outputs of the assignment model into a transport user and operator cost function. The former is based on value of time coefficients for each passenger travel time component and the latter consists of fixed and variable costs, and; \r\n\r\n(iii) a search algorithm that selects potential solutions using the meta-heuristic of simulated annealing, a probabilistic metaheuristic to find the global optimum in large search spaces. A neighbour of a specific solution is generated by altering either the headway or the vehicle capacity of a selected line while keeping all other variables unchanged and satisfying the feasibility constraints. \r\n\r\nThe overall model allows accounting for variations in service reliability and crowding that have not been accounted for in the tactical planning insofar. Practical benefits of the model are demonstrated by an application to a bus network in the Amsterdam metropolitan area for different demand periods, flexibility in decision variable settings and optimization objectives. Results indicate that the current situation in the regarded network can be improved by changing the supply provision in terms of frequencies and vehicle capacities. This study contributes to the development of a new generation of methods that integrate reliability into the tactical planning phase.\r\n", :title "Frequency and Vehicle Capacity Determination using a Dynamic Transit Assignment Model", :keyword2 7, :authors (57043), :session 30}, 706 {:keyword1 27, :keyword3 143, :abstract "Caseine is a learning platform (caseine.org). Its aim is to stimulate students' learning and autonomy while improving the quality of the time the teacher gives them. Based on Moodle, it allows to\r\n- automatically evaluate the student's computer code and mathematical models(e.g. linear programs),\r\n- monitor the students' progress,\r\n- share contents between the teachers through a community of users.\r\n\r\nWe present some use cases of Caseine, specially in Linear Programming and Graph Theory. For instance, we explain how the linear programming models are evaluated automatically on the plateform and how the activities are shared between the teachers of various universities.\r\n\r\nCaseine offers a connexion for all users in Edugain who can connect via their own university. With this connexion, you can test the Operations Research open course. We will present how to join the OR teacher community on Caseine and create your own courses while using and contributing to the shared activities.", :title "A community of teachers for an active pedagogy in OR", :keyword2 159, :authors (50029 37984 31689), :session 234}, 707 {:keyword1 158, :keyword3 97, :abstract "Discrete choice models are the state-of-the-art of demand modeling at the disaggregate level. Their integration with Mixed Integer Linear Programming (MILP) models provides a better understanding of customers' preferences to operators while planning for their systems. However, the formulations associated with discrete choice models are highly nonlinear and non convex, and therefore difficult to include in MILP models. In order to overcome this limitation, we propose a linear formulation of a general discrete choice model that can be embedded in any MILP model by relying on simulation. \r\n\r\nThis approach can be used to model numerous applications, such as the design of a train timetable in transportation or the shelf space allocation problem in retail. For the sake of illustration, we characterize a demand-based benefit maximization problem where an operator that sells services to a market, each of them at a certain price and with a certain capacity (both to be decided), aims at maximizing its benefit, understood as the difference between the generated revenues and the operating costs. Despite the clear advantages of this integration, the size of the resulting formulation is high, which makes it computationally expensive. \r\n\r\nGiven the underlying structure of the demand-based benefit maximization problem, we use Lagrangian relaxation to decompose it into two separable subproblems: one concerning the decisions of the operator, that can be written as a Capacitated Facility Location Problem (CFLP), and the other referring to the choices of customers, for which we need to develop additional strategies to further decompose the resulting formulation along the two dimensions that, by design, allow to decompose the problem (the customers and the draws). Indeed, each customer solves aims at maximizing their own utility, and each draw represents an independent behavioral scenario. However, we notice that it cannot be directly decomposed in independent subproblems for each customer n and scenario r, as all the customers are combined together in the objective function and in the constraints managing capacity allocation, and the draws are also coupled in the objective function. Finally, we consider an iterative method called subgradient method to optimize the Lagrangian dual.", :title "A Lagrangian relaxation technique for the demand-based benefit maximization problem", :keyword2 59, :authors (50839 5855 36097 36405 26236), :session 216}, 708 {:keyword1 92, :keyword3 158, :abstract "Abstract\r\nThe quantity of electrical and electronic equipments (EEEs) introduced in the market has been growing fast since EEEs have become an indispensable part of our daily life. The performances of the products are increasing steadily while their prices are decreasing. Moreover, the decreasing lifespan of EEEs and expanding range of the products directly affect the size of the EEE market. One consequence of this expansion is waste EEEs (WEEEs) occurring after the end of use or end of lifespan. WEEE contain various complicated hazardous substances which may cause over-consumption of resources, severe damage to the environment and various health related problems. Therefore, developing proper waste management strategies and operations is crucial. Many countries have implemented environmental legislations for WEEE management. In these regulations, the responsibilities of stakeholders ─such as EEE producers, logistics service providers and municipalities─ are specified clearly. Similarly, the Ministry of Environment and Urbanization in Turkey started implementing WEEE Directive in May 2012. Even though responsibilities of related authorities are stated in this directive, scrap dealers still collect and treat WEEEs illegally. These scrap dealers are not equipped with necessary tools and conditions for the suitable treatment of WEEEs, which creates risk for their own health and inefficiency in the system. For this reason, they should be included in WEEE management system by being supported by the government. This study proposes mixed integer linear programming model for handling of the WEEEs, based on the requirements set by Turkish WEEE Directive. In this study, the proposed model is designed for multi-echelon, multi-product, multi-period reverse logistics network and is solved by CPLEX optimization software. The emission costs occurred due to transportation and disposal activities are considered in objective function. The proposed model is validated by using the amount of WEEE to be collected in Istanbul, considering WEEE collection target per capita specified in the directive. The objective of this model is to maximize the profit and efficiency of WEEE management system when illegal scrap dealers are included. Results of the study suggest opening WEEE treatment facilities in specified locations and subsidizing the scrap dealer junkyards which will be incorporated into WEEE management system. This study suggests managerial insight for governmental authorities and emphasizes importance of efficient waste management.\r\n\r\n\r\n", :title "Reverse Logistics Network Design Model for WEEE: A Case Study on Istanbul", :keyword2 65, :authors (59773 48468 2423), :session 169}, 710 {:keyword1 134, :keyword3 95, :abstract "We develop an algorithm that computes for a given undirected or directed network with flow-dependent piece-wise linear edge cost functions all Wardrop equilibria as a function of the flow demand. Our algorithm is based on Katzenelson's homotopy method for electrical networks. The algorithm uses a bijection between vertex potentials and flow excess vectors that is piecewise linear in the potential space and where each linear segment can be interpreted as an augmenting flow in a residual network. The algorithm iteratively increases the excess of one or more vertex pairs until the bijection reaches a point of non-differentiability. Then, the next linear region is chosen in a Simplex-like pivot step and the algorithm proceeds. We first show that this algorithm correctly computes all Wardrop equilibria in undirected single-commodity networks along the chosen path of excess vectors. We then adapt our algorithm to also work for discontinuous cost functions which allows to model directed edges and/or edge capacities. Our algorithm is output-polynomial in non-degenerate instances where the solution curve never hits a point where the cost function of more than one edge becomes non-differentiable. For degenerate instances we still obtain an output-polynomial algorithm computing the linear segments of the bijection by a convex program. The latter technique also allows to handle multiple commodities.", :title "Computing all Wardrop Equilibria parametrized by the Flow Demand", :keyword2 42, :authors (59914 26950), :session 149}, 711 {:keyword1 17, :keyword3 149, :abstract "The rising air traffic volume in Europe, and beyond, is demanding. Accordingly, the need for safe but also efficient air traffic management asks for approaches to evaluate service productions by more than just univariate measures. Data Envelopment Analysis (DEA) is a non-parametric method to evaluate the efficiency of organizations and processes, considering multivariate data in this assessment. \r\nAs almost all DEA applications in the field of air transport refer to airports or airlines as complete units, we concentrate on air navigation services providers (ANSPs), aiming to find an adequate instrument for regulation purposes. In this contribution, first, we focus on the approach and departure phases where the set of DMUs comprises 32 major European airports. The Performance Review Unit of EUROCONTROL provided all data. After applying a DEA, we determine graphical projections of the initial results by Multidimensional Scaling. Consequently, possible interpretations of underlying latent variables will then be given. However, DEA is based on linear programming, and hence might be subject to alternative optima. Therefore, in the second step, we face the problem of multiple optimal solutions in DEA and study the effects on the stability of respective graphical projections.", :title "Exploring stability of solutions for Data Envelopment Analysis of air-navigation service efficiency", :keyword2 2, :authors (59929 29296 14890), :session 45}, 712 {:keyword1 95, :keyword3 189, :abstract "In this contribution, an Electric-Vehicle Routing Problem (E-VRP) with partial charging, flexible time windows and speed-dependent energy consumption is presented. This mixed-integer linear routing problem is based on a minimization of the costs of the travelled distances as well as the delay times. This enables for the consideration of flexible time windows, which allow an upward violation of the time windows. Amongst others, the constraints of the model include a realistic representation of the energy consumption and the charging as well as the consideration of different priorities of the customers. The constraints can be divided into three categories: The route constraints indicate the typical vehicle scheduling restrictions. The time constraints include the arrival and delay times of all nodes as well as the charging time at the charging stations. The charging constraints ensure a sufficient state of charge of the battery at all nodes. This model is used to derive recommendations for electric vehicle fleets of the criminal investigation service at the police.", :title "Electric-Vehicle Routing with partial charging, flexible time windows and speed-dependent energy consumption", :keyword2 187, :authors (15178 56018 2651), :session 212}, 713 {:keyword1 173, :keyword3 151, :abstract "We investigate online convex optimization with switching costs  (OCO; Lin et al., INFOCOM 2011), a natural online problem arising when rightsizing data centers: A server initially located at p_0 on the real line is presented with an online sequence of non-negative convex functions f_1,f_2,...,f_n: IR -> IR+. In response to each function f_i, the server moves to a new position p_i on the real line, resulting in cost |p_i-p_{i-1}|+f_i(p_i). The total cost is the sum of costs of all steps. One is interested in designing competitive algorithms.\r\nWe review 2-competitive deterministic online algorithms for OCO (Andrew et al., COLT 2013/arXiv 2015; Bansal et al., APPROX 2015). We then solve the problem in the classical sense: We give a lower bound of 2 on the competitive ratio of any possibly randomized online algorithm (Antoniadis and Schewior, WAOA 2017). It had been previously conjectured that (2-epsilon)-competitive algorithms exist for some epsilon>0 (Bansal et al., APPROX 2015).", :title "Tight Bounds for Online Convex Optimization with Switching Costs", :keyword2 13, :authors (52563), :session 223}, 715 {:keyword1 175, :keyword3 0, :abstract "In todays globalized world, many manufacturers are operating world-wide supply chains, linking production facilities with warehouses, commodity specific facilities (such as ripening chambers for perishable goods), distribution centres, wholesalers and retailers. Where possible, goods are consolidated into standardized containers to improve container handling efficiency and ease of switching transportation modes.\r\nIn research, a strong focus has been given to the customer side, whose objective is to plan efficient, robust and resilient supply chains. The underlying infrastructure used to plan the supply chain, such as complex liner shipping or intermodal transportation networks, is usually assumed to be a static network, where capacities, prices and transit times for transportation are often contractually defined. The manufacturer typically takes a holistic view on optimizing the entire chain. \r\nIn contrast, decision problems offered on the infrastructure supply side of container logistics (e.g. terminals, shipping lines, intermodal transportation, equipment handling, warehouses) are usually approached as separate decision problems with clear organizational boundaries, such as terminal planning or liner shipping network design. Some approaches exist on integrating decision problems of single actors, for example the berth planning and quay crane scheduling problem occurring at container terminals. However, this isolated view is only partially representing decision problems in today's transportation and logistics industry.\r\nMost of the large ocean carriers, such as CMA CGM, COSCO Shipping and Maersk provide solutions for container logistics beyond the commoditized sea transportation. Besides owning and operating ocean vessels, they are increasingly investing in container terminals, stowage facilities and intermodal transportation, transforming them rather into container logistics providers. These companies are increasingly challenged with integrating planning processes across previously independent actors to make containerized transportation more efficient, cheaper and more attractive to their customers.\r\nThe contribution of this work is threefold: First, it provides an overview of real-world planning problems occurring at an end-to-end container logistics provider. It provides practical insights about this industry and how decisions are linked across actors. Second, it classifies recent academic work into these planning problems to provide the state-of-the art in this research space. Third, it identifies research gaps to handle the increasing integration of planning problems. Thereby, new research opportunities of integrating planning problems and applying existing approaches to new field are presented.", :title "Digitalization of the Container Transportation and Logistics Industry - Research opportunities for OR", :keyword2 174, :authors (46747), :session 168}, 717 {:keyword1 8, :keyword3 0, :abstract "The presence of symmetries in integer programs is well known to hurt the performance of branch-and-cut methods and several symmetry handling methods have been proposed. In this talk, I will discuss polyhedral ways to handle such symmetries. This is accomplished by considering the convex hull of all lexicographic maximal points in each orbit. While a complete description of these polytopes is only known for special symmetry groups, one can use their structure to construct efficiently solvable integer programming formulations. Computational results with the framework SCIP will show that this approach is competitive with the state-of-the-art methods based on pruning the tree and sometimes superior.", :title "Polyhedral Handling of Symmetries in Integer Programs", :keyword2 153, :authors (17083 55298), :session 50}, 718 {:keyword1 41, :keyword3 14, :abstract "We consider linear bilevel programming problem in the optimistic sense. It is wellknown that by using the optimal value function of the second level problem the initial bilevel problem can be reduced to a standard optimization problem with an implicit nonconvex constraint. To treat this constraint we suggest to apply explicit piecewise linear support functions. In practice, such approach leads to a branch and bound procedure with auxiliary linear programming problems. We describe the solution technique and give comparative computational results. ", :title "Branch and bound scheme with piecewise linear support functions in linear bilevel problems ", :keyword2 153, :authors (48465), :session 182}, 719 {:keyword1 40, :keyword3 6, :abstract "We consider the problem of selling k identical items to n unit-demand bidders who arrive sequentially with values drawn independently from identical distributions, and ask how much more revenue can be obtained by posting discriminatory prices to individual bidders rather than the same anonymous price to all of them. We show that the ratio between the maximum revenue from discriminatory pricing and that from anonymous pricing is at most 2 - k/n, and this bound is tight for all values of n and k. For the special case of regular distributions we show that this ratio is substantially smaller. We give a closed form expression for the ratio between the maximum revenue from discriminatory pricing and that from anonymous pricing for regular distributions that is tight and of order (1-1 / k^(1/2) )^(-1). Interestingly, our analysis reveals an interesting dichotomy. As the number of items grows large the benefit of discriminatory prices vanishes for regularly distributed valuations but remains significant for non-regular value distributions.", :title "Revenue Gaps for Discriminatory and Anonymous Pricing", :keyword2 134, :authors (52405 48830 26950), :session 147}, 720 {:keyword1 45, :keyword3 151, :abstract "Emergency Medical Services (EMSs) have a significant impact in the health status of the population. These services are the first health care providers to arrive in an emergency situation, and they are perceived as an external sleeve of hospital’s urgency service. Instead of waiting the arrival of the patient, the urgency service reaches the patient in a shorter time using several vehicles (e.g. ambulances) from the EMS, thus being able to provide faster medical assistance and to avoid harmful results in the involved victims’ or patients’ health. Ambulances must be strategically positioned to provide a good system’s coverage allowing to provide fast assistance in an emergency and to fulfil short maximum response times. Moreover, the decision on which ambulance to dispatch to a given emergency situation must consider system’s sustainability or the ability to answer future emergency requests.\r\nThis work focuses on ambulances’ action to respond to urgent emergency requests. The decision-making process plays a very important role to help EMS managers in strategic, tactical and operational decisions. We focus on the operational level by handling the ambulance dispatching and relocation problems. Ambulance dispatching decisions assign ambulances to emergencies and the relocation problem decides to which base available ambulances are (re)assigned.\r\nAn effective and efficient EMS response is needed, so it is essential to have an optimized system. We propose a mathematical model and a pilot-method heuristic with an integrated optimization approach for the dispatching and relocation problems. To evaluate system's coverage, a time-preparedness metric is considered and calculated for a fleet of available ambulances at each time period. The main goal is to ensure the sustainability of the system, i.e. a good system's preparedness for emergencies on the current period and in the future. It is of maximum importance not to have current uncovered emergencies and to provide a good service level within the maximum response time.\r\nExperiments are performed to test different dispatching policies and relocation rules. EMS data from Lisbon, Portugal, is used to test these methods and to validate the effectiveness and efficiency of the proposed approaches.\r\n", :title "Ambulance dispatching and relocation using a time-preparedness metric", :keyword2 174, :authors (9369 58623 2197), :session 170}, 721 {:keyword1 40, :keyword3 154, :abstract "In a Stackelberg pricing game a distinguished player, the leader, chooses prices for a set of items, and the other player, the follower, seeks to buy a minimal cost feasible subset of the items.\r\n\r\nThe goal of the leader is to maximize her revenue, which is determined by the sold items and their prices. Typically, the follower is given by a combinatorial covering problem, e.g., his feasible subsets are the edge sets spanning a network or the edges of an s-t-path in a network.\r\n\r\nWe initiate the study of Stackelberg pricing games where the follower solves a maximization problem. In this model, the leader offers a payment to include her items in the follower’s solution. This can be used to model make-or-buy decisions for the follower.\r\n\r\nNot surprisingly, the follower's maximization problem dictates the computational complexity of the leader's problem of computing optimal prices. We show that the leader's problem ranges from polynomial time solvable cases to cases complete for higher levels of the polynomial hierarchy.", :title "Revenue maximization in leader-follower games", :keyword2 156, :authors (59931), :session 147}, 723 {:keyword1 59, :keyword3 124, :abstract "Modern optimization algorithms typically require the setting of a large number of parameters to optimize their performance. The immediate goal of automatic algorithm configuration is to find, automatically, the best parameter settings of an optimizer. Ultimately, automatic algorithm configuration has the potential to lead to new design paradigms for optimization software. The irace package is a software package that implements a number of automatic configuration procedures. In particular, it offers iterated racing procedures, which have been used successfully to automatically configure various state-of-the-art algorithms. The iterated racing procedures implemented in irace include the iterated F-race algorithm and several extensions and improvements over it. In this talk, we summarize the main features of the irace package and the configuration methods it implements. The main focus of the presentation will be on recent developments that include extensions of irace for improving its performance for specific configuration tasks, the usage of machine learning models inside irace, and some tools for the analysis of the the configuration process and the proposed algorithms. We also review some recent applications of irace.  ", :title "The irace package for automatic algorithm configuration: recent developments", :keyword2 5, :authors (59882 9511 59934 32167), :session 203}, 724 {:keyword1 61, :keyword3 57, :abstract "Over the past decade the IT has been moving steadfastly towards utilizing software on clouds using Web Services REST API's. The old traditional way of deploying software on standalone computers is slowly but surely going away. \r\n\r\nIn this presentation we will demonstrate the soon-to-be-released MPL REST Server, which allows optimization models to be easily deployed on the cloud.  By delivering optimization through a standard REST API, which accepts data in either JSON or XML formats, the optimization becomes purely data-driven.  Client applications can now be implemented relatively easily on different client platforms such as mobile/tablets or web sites, using just standard HTML/CSS with Javascript, or any other preferred programming language.\r\n\r\nGoogle and Amazon have been among of the leading software vendors in the area of Web Services and publish several REST API's which can be quite useful for deploying optimization applications.  On the server side, optimization models can easily access online data using for example the Google Sheets API and Amazon DynamoDB.  On the client side, libraries such as the Google Maps API and the Google Visualization API can be used to provide rich user experience.  We will be demonstrating mobile web applications which utilize the MPL REST Server and the Google/Amazon REST API's for deploying optimization models.\r\n", :title "Optimizing in the Cloud - Deploying Optimization Models on the Cloud with Web Services REST API's", :keyword2 98, :authors (3843), :session 48}, 725 {:keyword1 120, :keyword3 59, :abstract "This work describes a problem with origins in sea exploration, though similar problems arise in other contexts.  The identification of the contents of the seafloor is important in view of a possible exploitation of some of these resources.  The aim of this problem is to schedule the journey of a ship for collecting information about the composition of the seafloor.  We consider a bounded surface, through which some resource can be found with a given level.  This \"true value\" is initially unknown, except for a limited number of points for which there is previous empirical information.\r\n\r\nOptimal expedition planning involves three subproblems, each corresponding to a different phase in the process: assessment, planning and estimation.\r\n\r\nAssessment consists of estimating the amount of information that would be conveyed by probing the surface at each point.  This is done by means of an indicator function.  Previous work assumed that actual information obtained by probing is not usable at the time of planning; here, we assume that after committing to probing at a certain place, the information obtained can immediately be used to change the course of the following decisions (in particular, the set of points used for building the indicator function is dynamically expanded).\r\n\r\nPlanning, the next phase in the solution process, consists of deciding on the position of points to probe until the end of the expedition; the point to probe next is the only one to which we commit.  The objective is to maximize the overall informational reward obtained, taking into account that the total duration of the trip is limited to a known bound.  Hence, online planning involves using the previously available points together with the points newly probed in this trip, in order to decide the location of the next point to probe --- though an estimation of the whole remaining trip is necessary for correctly taking this decision.\r\n\r\nThe third subproblem is estimation, which is related to the final aim of the problem: an estimation of the  resource level available at any point on the surface, based on all the information available at the end of the trip.  This is done through regression using both the initially available points and those collected during the expedition.\r\n", :title "Online correlated orienteering on continuous surfaces", :keyword2 187, :authors (24368 59938), :session 209}, 727 {:keyword1 186, :keyword3 187, :abstract "The quality of service and efficiency of labour utilization in vehicle fleets that respond to emergencies in life-threatening situations (such as police, firefighters, and emergency medical services (EMS)) depends, among other things, on the efficiency of work break scheduling. The workload of vehicle crews within such fleets usually cannot be forecasted with certainty and its urgency requires an immediate response. To guarantee efficient and timely emergency assistance, a minimum number of stand-by vehicles with in-vehicle emergency crews must always be available to cover each area of interest, i.e., to assist a probable incident within a predefined maximum delay in the arrival. This can be done by dynamically transferring stand-by vehicles to (time- and area- dependent) locations that maximize the coverage of a region of interest in each time period. These locations can be a set of strategically positioned depots, parking lots, terminals, garages, and similar.\r\nHowever, prolonged focused work periods decrease efficiency as the brain uses up oxygen and glucose, leaving one feeling drained with related decline of attention and performance. Therefore, break schedule in this case should consider both area coverage and minimum legal requirements for breaks to avoid fatigue.\r\nSince this problem has not been considered in the literature, in this paper, we propose and formulate break assignment problem considering area coverage (BAPCAC) and give a mathematical programming model for this problem. Based on the historical intervention data and service requirements, the model coordinates the vehicles' break times in relation to the coverage of forecasted incidents in each time period and thus serves for decisions about the fleet's break assignment strategy based on the fleet's size (long and short break scheduling  and  when to call vehicles on break back to duty). Moreover, the model computes the best locations for idle vehicles in each time period and arranges vehicles' crews' work breaks considering legal requirements and coverage of incident densities within the region. The objective is an efficient emergency vehicle fleet coordination based on historical data in order to increase both the quality of service of emergency fleets as well as the well-being of the vehicles' crew members while reducing their absenteeism due to fatigue and related costs.\r\nWe analyze the complexity of the proposed model and show its performance on a simple use-case.\r\n", :title "Break assignment problem considering area coverage (BAPCAC)", :keyword2 18, :authors (59936 13772 13758 59940), :session 170}, 728 {:keyword1 75, :keyword3 101, :abstract "Collaborative operations planning is a key element of modern supply chains, where firms are forced to overcome inefficiencies in order to stay in business. The spectrum of collaborative operations planning goes from simple coordination of plans to centralized decision making. This might require that actors are willing to reveal parts of their business information to coalition partners. Digitalization and emerging concepts like cloud manufacturing make it possible that data can be exchanged extremely fast and in secure environments. However, firms are still not willing to reveal critical data like their existing customers, cost structure or capacities. Thus, collaborative planning demands for distributed decision making mechanisms, where no sensitive information has to be shared.  We discuss different collaborative planning problems arising in operations management. Auction-based mechanisms are renowned methods in the field of decentralized decision making. This is based on the advantage that agents are enabled to indirectly share preference values, without having to reveal critical data. Based on a computational study, we investigate problems, where such mechanisms are powerful, but we also show their limitations. Dealing with collaborative decision making, we have to take game theoretical aspects into account. We identify desirable properties of the proposed mechanisms and elaborate on incentive compatibility and side payments.   ", :title "Solution approaches and incentive schemes in collaborative operations planning", :keyword2 174, :authors (39372 10538), :session 190}, 731 {:keyword1 5, :keyword3 59, :abstract "The general concept of the proposed Self-Adaptive Per Instance Algorithm Selection concept labeled as “SAPIAS” concept is composed of four important cooperating layers. The first two layers are supposed to be implemented for an online execution mode and the last two layers for an offline mode. The first “Prediction” layer defines a Per-Instance Algorithm Selection. This is the classical task where, based on a pre-built prediction model, a schedule of algorithms is selected to optimize a new given instance. Once the optimization process is achieved, the predicted schedule along with the solution found are passed to the second layer called the Advisor layer. In this second “Advisor” layer, two operations are respectively triggered. The first one is using a low budget “Prediction Checker” algorithm to optimize the new instance starting from the actual solution received from the first layer. The goal here is not to check the prediction accuracy in the precedent layer, but rather detect if an improvement of this solution can be performed. Actually, The Prediction Checker implements all the improvement strategies used in all algorithms present in the algorithm space used by the prediction model in the first layer. Afterwards, if the solution is enhanced, the Prediction Checker identifies the algorithm(s) which the enhancing improvement strategy(s) belongs to. The set of active algorithms in the schedule is passed to the next layer. The third “AAC” layer aims to find an algorithm by automatically configuring different components used by the set of algorithms received. For this reason, a Two Phase Automatic Algorithm Configuration is established. In the first phase, an algorithm configuration is performed at the component level. Indeed, an algorithmic framework is constructed first, then an automatic configuration is performed to find a well performing configuration. Besides the technical implementation of such configuration, a very important point is that this configuration is evaluated using only the new instance. Afterwards, if a successful configuration is found, the next phase performs an extensive parameter tuning, however this time, all instances available are used. The parameter tuning should ensure in the first place a good parameter set for the new instance and build a performance space for the new algorithm mapping its performance to each instance. In the fourth “Update” layer, the existing performance space is merged with the new performance space of the new algorithm allowing to remove algorithms where the new algorithm performs better in their respective instances. In this layer, the prediction model is also updated by regenerating a new one using extracted features from the newly given instances. This update is ruled using an update threshold monitoring the number of new instances or algorithms waiting to be added.", :title "SAPIAS Concept: Towards an independent Self-Adaptive Per-Instance Algorithm Selection", :keyword2 124, :authors (56860), :session 203}, 734 {:keyword1 165, :keyword3 2, :abstract "When coordinating departure sequences from different airports, uncertainty on the ground and in the air has to be taken into account. A possible formalization leads to a sequening model with uncertain release dates. \r\nThis model has received little attention in the literature, although other transportation problems also often exhibit such properties.\r\n\r\nIn this paper, a sequence that minimizes the expected total weighted completion time under uncertain release dates is determined. The approach is a two-stage model, where an a priori sequence is established in the first stage and a scheduling operation is performed in the second stage.\r\n \r\nThe major difficulty is an exponential number of the joint realization of the release dates. This difficulty is resolved by a Markov model of the optimal solution of the second stage. It allows to solve instances to optimality with millions of scenarios. Moreover, the optimal policy turns out to shift a single task at the beginning of a sequence that is built according to the Weighted Shortest Expected Processing Times rule, depending on the variance of the release dates.", :title "A Priori Sequencing with Uncertain Release Dates", :keyword2 96, :authors (23312), :session 157}, 735 {:keyword1 95, :keyword3 175, :abstract "The youth academy of TSG 1899 Hoffenheim (TSG) is one the most successful soccer training academies in Germany, with players from all over the country’s southwest attending the training. Since no sufficient public transport to the training centers exists, TSG offers a van transfer service for its youth players. Weekly manual scheduling of the vans is a complex and time-consuming task, which currently leaves many players unserved. These players have to resort to private transport.\r\nWe extend the capacitated team orienteering problem (CTOP) to fit the problem of optimizing the player transport. Players are picked up according to their age group priority, given a capacitated heterogeneous fleet and a limit in travel time. Since potentially multiple players can be collected at a pick-up location, our model contains an additional decision level, which decides on the pick-up location included in the route, as well as on the players collected at each pick-up location. As TSG’s drivers rely on local area knowledge, our model introduces the concept of cluster stability in the multi-period CTOP context. Only limited route changes beyond cluster borders are accepted in this concept. Due to the problem’s high computational complexity, a MIP solver fails to solve even small instances, thus we use a customized Tabu Search to solve our problem. Our algorithms significantly increases the number of players transported and reduces the planning effort from several days to a few\r\nminutes.", :title "Optimizing the Training Transport of Junior Soccer Players", :keyword2 72, :authors (59942 44745 26634 829), :session 205}, 736 {:keyword1 35, :keyword3 0, :abstract "Companies investing in new products generally do not only have to decide whether or not to launch the product but also when to invest and how much production capacity should be installed. As the investment decision can only be based on sales forecasts the optimal investment policy has to be devised under uncertainty. We model such a simultaneous choice of optimal investment timing and capacity under uncertainty in continuous time. We employ the model to evaluate the effect of uncertainty on investment, i.e. the investment-uncertainty relationship, based on current insights from relevant literature. That is, the propensity to invest in the new product is analyzed from various angles and contrasted with the capacity installed. Furthermore, we examine whether the traditional result that higher uncertainty leads to more capacity later holds.", :title "A New Approach on Investment Timing and Capacity Choice under Uncertainty", :keyword2 100, :authors (41930 31822), :session 196}, 741 {:keyword1 158, :keyword3 0, :abstract "The selection of cutting planes is important for the performance of modern branch-and-cut-based MIP solvers. We introduce a novel measure to estimate the quality of a cutting plane by using information about feasible solutions found during the solving process. Its usefulness for guiding the selection of cutting planes is demonstrated by computational experiments with SCIP, one of the fastest MIP and MINLP solvers available in source code.", :title "Novel Strategies for Cut Selection in SCIP", :keyword2 157, :authors (55419), :session 50}, 744 {:keyword1 175, :keyword3 29, :abstract "The problem of vehicle ownership and use has been extensively studied in the fields of economics, marketing and transportation. Models that account for households’ decisions over the number of vehicles, their type, and mileage traveled are used to: (a) determine consumer demand for different types of vehicles (Bunch et al., 1993; Axsen and Kurani, 2013; Glerum et al., 2014; Cirillo et al., 2017), (b) predict individuals’ activity and travel behavior (Ben-Akiva and Bowman, 1998; Bhat and Singh, 2000; Paleti et al., 2013; Oakil et al., 2014), and (c) evaluate policies and market incentives to reduce vehicular emissions (Hayashi et al., 2001; Vyas et al., 2012; Feng et al., 2013; Liu and Cirillo, 2015; Liu and Cirillo, 2016). In practice, it is very important to accurately predict household vehicle holding and miles traveled by vehicle type to support critical transportation infrastructure planning and determine auto emission levels (Bhat and Sen, 2006). \r\nIn transportation, comprehensive car ownership models have been developed and utilized to jointly estimate household car holding, type and use decisions. Among them, we recall the multiple discrete-continuous extreme value (MDCEV) model proposed by Bhat and Sen (2006), the Bayesian multivariate ordered probit and tobit (BMOPT) model by Fang (2008), and the integrated discrete-continuous choice model based on multivariate probit model by Liu et al. (2014). Although these models are able to jointly estimate discrete and continuous decisions, they are static and they are not able to capture the time-dependent changes in households’ behavior and market dynamics over time.\r\nIn this contribution we will present methods that model discrete and continuous decisions over time and we will present applications in the context of the vehicle ownership problem. We propose a Recursive Binary Probit (RBP) model to capture a sequence of vehicle holding decisions made by households over time. Households are assumed to be forward-looking and at each time period the household will obtain an instantaneous utility and an expected downstream (future) utility associated with the discrete choice. To obtain the choice probabilities and to estimate the model, the key point is to calculate the expected downstream utility. Here we employ a finite horizon scenario tree to approximate the infinite horizon problem expressed by the Bellman equation. We suppose that each household has an expectation over a limited number of future time periods, which is characterized by attributes of alternatives changing over time. \r\nThe study contributes to existing literature on a number of points: (a) the model is able to measure the interdependency between discrete choice (i.e. car holdings) and continuous choice (i.e. VMT) over time; (b) allows unrestricted substitution pattern between alternatives; (c) has no restrictions on the number of cars held by households; and (d) is an efficient tool for policy evaluation.   \r\n", :title "Dynamic discrete continuous choice models: an application to the vehicle ownership and use problem", :keyword2 156, :authors (27215 59947), :session 37}, 745 {:keyword1 17, :keyword3 0, :abstract "In today’s technology-centric economies of the information age, the importance of R&D activities and investments continues to increase. The economic and political power of developed countries/firms come from their possessed technological superiority. The opposite can be observed in underdeveloped and developing countries. It is difficult to talk about economic and political superiority in regions where countries and firms are net technology importers and where value-added product investments are below expectations.\r\nTo be able to stand out in competitive conditions and to gain market advantage, limited resources must be used in the right place and in a right way. For this, companies have developed performance, and efficiency measurement methods that are appropriate to their business sectors and business forms, and supervisory/regulatory agencies have also become trackers of these methods through incentives and criminal sanctions. From this point of view, it can be said that companies aiming sustainable growth and market leadership should use the resources they possess in an optimum way and the highest possible yields.\r\nIn this study, a model was developed to measure the efficiency of R&D projects. In the model in which Data Envelopment Analysis (DEA) is used, project data from the R&D center of a company operating in the telecommunication sector in Turkey were evaluated. With the different variations installed, it was possible to measure the efficiency of projects compared to the most efficient project(s).\r\nIn the study, four different alternative models were tested with a constant/variable return to scale assumptions and different parameter set. It has been observed that how the assumptions and the change of the parameter set affect the performance score of the projects. At the end of the study, efficiency and performance scores were calculated and in which areas inefficient projects should improve and which projects need to refer to were determined.\r\nThese findings have shown that when the assumptions modeled correctly and parameter selection is completed per company goals, this model is a very effective performance measurement method. By using the data obtained in the study, alternatives to the performance model can be developed for any relevant sector, and resulting model can be positioned as a tool in companies' decision support systems.", :title "Assessing Efficiency of R&D Projects with Data Envelopment Analysis", :keyword2 0, :authors (12591 59948), :session 175}, 748 {:keyword1 185, :keyword3 97, :abstract "Relevance \r\nThe passenger impact of a disruption on the train network can propagate over the multi-level public transport (PT) network, via the transfer hub to the urban PT network. Hence, an optimal holding control decision for urban services at the transfer location should account for the impact of a disruption on another PT network level. \r\n\r\nModelling framework\r\nWe first quantify the passenger impacts of disruption propagation resulting from an exogenous train network disruption to the urban PT network level. Thereafter, we develop a rule-based controller for holding urban PT services while taking into account predicted passenger delays and rerouting from the train network level caused by the train network disruption. This means that in this study a control decision is triggered by services which are not subject to this same control decision.\r\n\r\nScenario design\r\nWe quantify the total passenger welfare for three different scenarios, expressed as the generalized travel time over all passengers:\r\n-Scenario 1: undisrupted train network; no urban control intervention;\r\n-Scenario 2: train network disruption; no urban control intervention;\r\n-Scenario 3: train network disruption; urban control intervention.\r\n\r\nControl problem description\r\nThe applied control strategy entails the decision whether to hold urban PT runs at multi-level transfer stops for a certain holding time in case a disruption occurs on the train network. The predicted welfare impacts on four different passenger segments are incorporated in this holding decision:\r\n(i)\tUpstream boarding and downstream alighting (through) passengers;\r\n(ii)\tDownstream boarding passengers;\r\n(iii)\tReverse downstream boarding passengers;\r\n(iv)\tTransferring passengers at holding location.\r\n\r\nA passenger-oriented decision rule is applied for the controller, where predicted costs of the control decision are deducted from the predicted control benefits for all passenger segments, aimed at minimizing passenger travel costs on the urban network.\r\n\r\nHolding results in a direct extension of in-vehicle time at the holding stop of passengers who board upstream the holding location and alight downstream the holding location, and a waiting time extension for downstream boarding passengers, corrected for turnaround buffer time for reverse downstream boarding passengers. Besides, holding reduces waiting time for passengers transferring at the holding location, compared to having to wait for the next service. The holding strategy also affects the different passenger segments in terms of perceived in-vehicle time due to changed crowding levels. Due to the non-linear nature of perceived in-vehicle time as function of crowding, we quantify crowding effects over all passenger segments simultaneously.\r\n\r\nApplication\r\nWe apply our methodology to the multi-level PT network of The Hague, the Netherlands. BusMezzo, an agent-based dynamic simulation model for PT operations and passenger assignment, is used as evaluation tool. \r\n", :title "Controlling the propagation of passenger disruption impacts in multi-level public transport networks", :keyword2 188, :authors (59949 57043), :session 30}, 749 {:keyword1 151, :keyword3 42, :abstract "We study online resource allocation problems with a diseconomy of scale. In these problems, there are certain requests, each demanding a set of resources, that arrive in an online manner. The cost of each resource is semi-convex and grows superlinearly in the total load on the resource. An irrevocable allocation decision has to be made directly after the arrival of each request with the goal to minimize the total cost on the resources. We focus on two simple greedy online policies that provide very fast and easy approximation algorithms.\r\nThe \ffirst policy is to minimize the individual cost of the current online request with respect to all previous requests that have been allocated before. The second policy is to minimize the marginal total cost overall requests that have arrived up to this point. In the literature, these type of algorithms is also considered as one-round walks in congestion\r\ngames starting from the empty state.\r\nWe consider the weighted and unweighted version of the problem. In the weighted variant, and for cost functions that are polynomials with maximal degree d and positive coefficients, we proof a tight competitive ratio of for the marginal total cost policy. Interestingly, this result exactly matches the approximation factor for the corresponding multiple-round walk algorithm that starts in an arbitrary state. Our work indicates that one-round walks that start in an empty starting state are exactly as efficient as multiple-round walks. We also show that this\r\ndoes not carry over to the unweighted version of the problem. For unweighted instances, we provide lower bounds for both policies that are significantly larger than the corresponding multiple-round walks. We complement our results with an upper and lower bound on the solution quality of the personal cost policy for weighted and unweighted instances.", :title "Online Best Reply Algorithms for Resource Allocation Problems", :keyword2 40, :authors (55265 26950 45274), :session 223}, 750 {:keyword1 42, :keyword3 0, :abstract "Stimulating innovation and growth within the European Union is crucial and can be achieved by fostering R&D partnerships with EU Foreign Policies. Research collaboration networks induced by these policies received strong attention from policymakers. In this paper, we show that some structures from graph theory (such as Minimum Dominating Set or Maximum Independent Set) can be used to determine which members are most involved in these collaborative networks. They provide a better understanding of the impact of EUFP on collaborations induced between companies or research organizations. Although these networks are large in size, it is possible to determine optimal MDS and MIS. This allows us, for example, to evaluate the impact of the withdrawal of an EU member on the collaborations’ network (Brexit for example).", :title "Minimum Dominating Set and Maximum Independent Set for evaluation of EU funding polices in collaboration networks", :keyword2 0, :authors (59957), :session 38}, 751 {:keyword1 185, :keyword3 175, :abstract "The development of autonomous driving technology potentially enables a better public transport service. While there are a bunch of studies about the implementation of fully autonomous (Level-5 automation) taxies and trials on driverless buses, the applicability of semi-autonomous buses has not been adequately explored yet. In our study, semi-autonomous buses belong to the Level-4 automation, and benefit from labor saving when they form bus platoon(s). \r\nThe generalized cost is modeled as the sum of waiting cost, riding cost, operating cost and capital cost. The discomfort factor is considered in the value of in-vehicle time. Due to reasons such as road geometry and technical concerns, the size (seats plus standees) of buses is restricted to a certain threshold. Thus, the problem is formulated as a constrained optimization problem, where the objective is to minimize the generalized cost and the decision variables are the bus size and the service headway. The difference between conventional buses and semi-autonomous buses lies in the capital cost and operating cost. It is assumed that semi-autonomous buses cost more than conventional buses for the requirement of extra modules (e.g., controllers and sensors), while semi-autonomous bus platoons experience a reduction of drivers’ cost in the platoon followers. For conventional bus service, only headways are adjusted during peak and off-peak hours, whereas semi-autonomous bus service can also change the capacity (by adding more buses to the platoon) without introducing extraordinary additional operating cost.\r\nThe calculation result shows that the performance of semi-autonomous buses relies on several parameters. The main aspect is the demand, which includes the peak/off-peak demand levels and the relative length of each period. Moreover, the variations of capacity threshold, additional capital cost coefficient and reduction in operating cost of semi-autonomous bus also alter the total costs. When the bus capacity is restricted to 100 passengers and the additional capital cost is 20%, the savings by semi-autonomous buses can be up to 1600 SEK/hour, given a 67% reduction in the operating cost of platoon followers and large peak/off-peak demands. The decrease of the capacity restriction favors the application of semi-autonomous buses. By conducting sensitivity analysis, the scenarios where conventional buses or semi-autonomous buses are preferred are identified. Although it needs further investigation on the comparison between semi-autonomous buses and other transport modes, semi-autonomous bus is likely to be more ready to use than trains when a large number of passengers need to be delivered.", :title "Bus operation modeling to compare conventional and semi-autonomous buses in serving flexible demand", :keyword2 25, :authors (59945 59958 59959), :session 30}, 753 {:keyword1 40, :keyword3 13, :abstract "\r\nModern society is based on complex systems populated by selfish decision makers, generally called agents, e.g. energy companies in power grids, car drivers in road traffic. The fundamental challenge in the model of multi-agent systems with stationary payoff function is to achieve an efficient equilibrium where the decision of each agent is optimal given the collective decisions or those of some other agents. However, in many applications (in particular the ones mentioned above), the real-world strategic interaction is certainly not stationary, at least over long time spans. Instead, this talk will focus on population dynamics determined by games with time-varying payoff functions. Temporal variability of the utility functions captures important real-life aspects of large population games such, such as changing latency functions in congestion games, or regime-switching in biological and technological networks.\r\nThis talk will describe recent results on population and learning dynamics in such time-varying environments, focusing on no-regret learning dynamics and ergodic convergence results. ", :title "Learning and evolutionary dynamics in time-varying environments", :keyword2 108, :authors (59966 51676), :session 223}, 756 {:keyword1 7, :keyword3 28, :abstract "The ongoing transformation of the European energy system has sofar been mainly dominated by the integration of variable renewable energy sources (vRES) into the electricity sector. Yet it is expected that future developments will include also significant transformations of the heat and transportation sector. Besides efficiency measures, these transformations will encompass the integration of, possibly flexible, electricity-based technologies – i.e. applications coupling the heat and transportation sector with the electricity sector, notably through E-Mobility and heat pumps. Thus, the combination of an increasing amount of vRES, sector coupling technologies and their flexibilization level induces considerable uncertainty within the electricity sector. In particular, power plant investments in the long run and power plant dispatch in the short run are affected through these developments. \r\nElectricity market developments regarding country specific load developments and power plant investments are assessed quantitatively in the presence of different flexibilisation levels of E-Mobility and heat pumps by extending and applying the existing electricity market model E2M2s. Since vRES are expected to satisfy an increasing amount of electricity demand and thus spatial and temporal fluctuations of electrical energy generation are expected to increase, a special focus is set on the flexibilisation potential for the considered sector coupling technologies. Thereby empirical data are used and sensitivity analyses are carried out. Notably, data sets of driving profiles are investigated in order to derive (load profile) groups for e-mobility and their temporal flexibility in charging. Vehicle-2-Grid applications are considered, too. \r\nTo illustrate the range of possible future developments for the European electricity system up to 2050, three scenarios differing in the spatial integration of sector coupling technologies are investigated: Introduction in whole Europe, introduction solely in Germany and none. Both generation investments and dispatch as well as utilization of transmission lines – depicted simplified by NTCs - are optimized for these scenarios and additional sensitivity analyses are carried out. Furthermore, effects on annual electricity demand, peak electricity demand, optimal supply mix and electricity prices are investigated. \r\n", :title "The impact of sector coupling technologies on the future European electricity system – A scenario analysis", :keyword2 29, :authors (59956 24773), :session 7}, 757 {:keyword1 40, :keyword3 169, :abstract "In this work, we extend the procedure of defining the Binomial Semivalues, due to A.Puente, to cover the entire class of Semivalues. We get this result by a transformation of weights and we apply the results connected to the Inverse Problem, shown in an earlier work,in order to find a new game with the same Semivalue, but a coalitional rational Semivalue, for a given game. Some examples are illustrating the procedure. This may be applied to a gas routing problem, like in another previous work.", :title "An alternative representation of the Semivalues of cooperative TU games.", :keyword2 95, :authors (11792 227), :session 223}, 758 {:keyword1 8, :keyword3 59, :abstract "The traveling sales person problem (TSP) has been studied in extensive detail over close to a century ([1]). Extremely efficient solvers for particular versions exist [2] and standard libraries of benchmark instances [3] show impressive results. When it comes to real world applications, only exceptionally a 'pure' TSP problem is encountered. Most often a problem is recognised to have a TSP embedded or to be a TSP problem with extra constraints. As it tuns out, small modification to the problem have a huge impact the solver efficiency. Moreover, such problems are often of the on-line kind in the sense that decisions have to be taken immediately without room for long computation times and without powerful hardware. In this talk we will discuss a TSP variant originating from a practical example and report on possibilities for learning suitable algorithms from solutions for the original problem.\r\n\r\nThe variant is the Intermittent Traveling Sales Person (ITSP) problem [4]. It occurs in a production application where an energy beam is to be used at a number of locations of a product. The energy beam could be a laser, a focussed ion beam or even a water jet although the problem is different in the latter case. In the case of lasers or focussed ion beams, the application of the energy beam causes the product to increase in temperature locally. Depending on the material and the application, the temperature cannot raise above a certain bound and as a consequence, the time the beam can be applied in one visit is limited. On the other hand, each location requires a certain total processing time. Given the production task, a sequence of visits is asked for that minimises the execution time. Time is the sum of the traveling time of the beam source and the processing time at the given locations. The minimisation of the traveling time is a similar to the TSP setting but the bounds on the visiting time require multiple visits to the locations. This apparently small addition turns out to make the problem much harder.\r\n\r\nWe discuss how algorithms for the underlying TSP problem deliver algorithm components that together with heuristics for the additional elements, allow to automatically construct algorithms fulfilling the set requirements. \r\n\r\nWe describe a number of similar problems and illustrate how algorithm components can be identified to be fed into an automatic algorithm construction tool.\r\n\r\n[1] Applegate, D. L.; Bixby, R. M.; Chvátal, V.; Cook, W. J. (2006), The Traveling Salesman Problem, ISBN 0-691-12993-2\r\n[2] http://www.math.uwaterloo.ca/tsp/concorde/index.html\r\n[3] https://wwwproxy.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/\r\n[4]\tPieter Leyman, San Tu Pham, Patrick De Causmaecker, The Intermittent Traveling Salesman Problem with Different Temperature Profiles: Greedy or not?, arXiv:1701.08517 [cs.DS]", :title "Learning in TSP-variants", :keyword2 124, :authors (7432 54627 35904), :session 163}, 760 {:keyword1 124, :keyword3 0, :abstract "The training of deep neural networks is typically conducted via nonconvex optimization. Indeed, for nonlinear models, the nonlinear nature of the activation functions yields empirical loss functions that are nonconvex in the weight parameters. Even for linear models, i.e., when all activation functions are linear with respect to inputs and the output of the entire deep neural network is a chained product of weight matrices with the input vector, the (squared error) loss functions remain nonconvex. On the other hand, to circumvent the limits resulting from finding sharp minima (corresponding to weight parameters specified with high precision) of the empirical loss function, Hochreiter suggested in 1995 to find a large region in the weight parameter space with the property that each weight from that region can be given with low precision and lead to similar small error. In this paper, we propose to minimize the empirical loss (training error) together with weights precision (regularization error) by means of a Trust Region (TR)-based algorithm. When extended to nonconvex regularized objectives, this method contrasts to current techniques which either arbitrarily -sometimes strongly- convexify the empirical loss minimization problem or involve slowly converging Stochastic Gradient algorithms without guaranteeing the production of good predictors. TR methods instead provide i) better complexity bounds for convergence to (approximate) first- and second-order critical points by means of rich set of iterative methods for TR subproblem solving, e.g., Steighaug-Toint and Generalized Lanczos Trust-Region (GLTR); and ii) fast escape from saddle points which include at least one direction of negative curvature, e.g., by exploiting the Hessian information. In addition, they can be combined with approximation techniques (e.g., sub-sampling) that are effective in reducing computational cost associated to Hessian evaluation. The latter provides an essential property in solving high-dimensional instances. Performance bounds of the TR-based algorithm are characterized against gradient descent together with numerical experiments for evaluation and comparison purposes.", :title "A Trust-Region Method for Minimizing Regularized Nonconvex Loss Function", :keyword2 162, :authors (32497), :session 163}, 761 {:keyword1 91, :keyword3 7, :abstract "A large number of network revenue management problems can be solved by path-based decomposition. In this approach, each path corresponds to a different product that uses some of the capacities on the network. After some simple transformation, the network problems resulting from the path-based decomposition approach are mostly solved by linear programming. Rather than the optimal allocation of the capacities to the products, the dual optimal solution of the linear programming model is used for accepting or rejecting the reservation requests. This is known as the bid-price control in the revenue management literature. In this work, we consider the case where multiple parties have access to some of the capacities on the network for their own reservation systems. Though agreed to collaborate, the major privacy concern for the parties is to conceal their sensitive data. That is, each party tries not to reveal its own revenues, products and capacities. We first present the steps to mask the private data for all the parties by a series of transformations. Then, we state our key result, which shows that the bid-price control can safely be used with the resulting private model because the dual optimal solution remains the same even after the transformations. We conclude with a simulation study demonstrating the importance of collaboration.", :title "Data Privacy in Bid-price Control for Network Revenue Management", :keyword2 150, :authors (406 56360), :session 163}, 763 {:keyword1 185, :keyword3 59, :abstract "In the last decades, the popularity of flexible transport services (FTS) has increased considerably, as witnessed in applications such as shared taxis and on-demand  carpooling. Even though public bus transport is still largely bound to fixed routes and fixed timetables, the ubiquity of mobile devices and the improved technology of automated vehicle location (AVL) systems would allow for a large-scale shift to on-demand public transport in the near future. In such an on-demand system, buses would drive along routes completely determined by the demand of passengers. To support the routing of on-demand buses we define a new optimization problem: the on-demand bus routing problem (ODBRP), which combines the dial-a-ride problem (DARP) with bus stop selection, introduced in the school bus routing problem. Given a set of requests for transportation, indicating a passenger's departure and arrival location, as well as his/her preferred arrival time, the aim of the problem is to (1) assign each passenger to a departure and arrival bus stop within walking distance, and (2) develop a set of bus routes, picking up passengers at their departure stop and delivering them to their departure stop before their preferred arrival time. In this talk, we present (a mathematical formulation of) the ODBRB, as well as a straightforward heuristic to solve it.", :title "The on-demand bus routing problem: towards a more performant public transport system", :keyword2 95, :authors (57467 428), :session 36}, 765 {:keyword1 124, :keyword3 158, :abstract "\r\nWe stand on the threshold of an AI revolution, where explicit programming as the fundamental paradigm for algorithmic problem solving is being replaced by increasingly automated approaches. Specifically, methods from generalised machine learning not only dramatically increase our ability to solve challenging computational problems, they also bring about a fundamental change in the way in which we design and deploy algorithms and software. In this talk, I will examine the nature of this change and its consequences, and I will give examples of the meta-algorithmic techniques that enable it. Specifically, I will discuss algorithm selection and configuration techniques, auto-tuning and the increasingly impactful area of automated machine learning (AutoML). Using examples from mixed integer programming, combinatorial optimisation and propositional reasoning, I will demonstrate the impact of these techniques, in terms of the results they achieve, as well as with respect to the way we approach these and other computational challenges.\r\n", :title "Learning how to solve it - faster, better and cheaper", :keyword2 173, :authors (10089), :session 232}, 766 {:keyword1 174, :keyword3 0, :abstract "Current challenges and future requirements for logistics networks like tremendous growth in small package shipping and extremely ambitious ecological targets at global and local level call for more flexibility, efficiency, and sustainability in logistics. Herein, logistics networks with intermediate stops constitute a promising concept to realize these goals, as they allow for freight replenishment in-between service stops to use smaller vehicles, for multimodal transportation in city logistics, and for recharging electric commercial vehicles (ECVs) en-route.\r\nAgainst this background, this dissertation focuses on the strategic design and operation of logistics networks with intermediate stops. Regarding its methodological contribution, it introduces a new class of location-routing problems (LRPs), the LRP with intra-route facilities (LRPIF), for the design and operation of such networks. It further presents a generic and competitive algorithmic framework for LRPIFs, but also for 14 different classes of vehicle routing problems with intermediate stops. This algorithmic framework represents a new state of the art in terms of solution quality, computational performance, and usability as it can be applied to a large variety of LRPIFs and VRPISs without additional tailoring. Moreover, these approaches are applied to a real-world case on the deployment of ECVs in mid-haul transportation. Accordingly, this dissertation derives deep managerial insights for fleet operators to foster the adoption of ECVs in logistics networks and thus helps to realize sustainable modes of transportation.", :title "Logistics networks with intermediate stops – Designing innovative and green solutions", :keyword2 0, :authors (52258), :session 222}, 767 {:keyword1 105, :keyword3 0, :abstract "The large body of research concerning optimization methods for the nurse rostering problem shows that it is a difficult problem to solve to optimality. This problem asks to assign shifts to nurses in a given scheduling period, subject to a variety of organizational and personal constraints. Computational experiences have shown that the presence of specific types of constraints have a significant impact on the performance of optimization algorithms. In particular, constraints on the number of consecutive assignments have been shown to have a strong effect on the performance of integer programming solvers. Coincidentally, it is also the presence of such constraints which often make nurse rostering problems NP-hard. The present research targets this class of constraints in an attempt to improve the performance of integer programming solvers by reformulating them in a graph structure. The resulting model is evaluated on a set of benchmark instances. The results show that the new formulation is competitive with other models and is much faster specifically for small- and medium-sized problem instances. To gain a better understanding of these results, we analyze a series of computational experiments to characterize problem instances for which the proposed reformulation significantly improves the performance of integer programming solvers. It is demonstrated that the new formulation performs best on instances in which the presence of constraints on consecutive assignments has a significant impact on algorithmic performance.  \r\n", :title "Reformulating constraints for the nurse rostering problem", :keyword2 96, :authors (32203), :session 156}, 768 {:keyword1 158, :keyword3 0, :abstract "There are many publications on routing of forest machinery on existing tracks, and the design of new forest road networks. However, to the best of our knowledge, less attention has been paid to the planning of skid trails. Skid trails are small tracks, used to harvest trees with special machinery.\r\n\r\nThe careful design of the skid trails is important for seeking a sustainable balance between their economic and environmental impact. A too sparse network complicates the harvesting process and significantly increases harvesting costs. A too dense network leads to unnecessary loss of effective area. Once a skid trail is generated, the affected soil is compacted for decades. This underlines the importance of the prior planning.\r\n\t\r\nThe design of the skid-trail network is far from trivial, due to a variety of contradictory planning criteria. The trails run preferably parallel to each other with an optimal pairwise distance of 21m and an orientation orthogonal to the local main wind direction. On plain land, these targets are easy to accomplish. However, in most of the practical cases a lot of obstacles such as creeks, rocks, steep slopes, and other natural features as well as man-made barriers force the planer to deviate from the optimal spacing and orientation.\r\n\r\nWe tried to build a mathematical optimization model to support the tedious planning process. We narrowed the set of planning criteria to the orientation of and the distance between trails, as well as the avoidance of obstacles. The resulting model is inspired by the set cover problem with additional constraints.\r\n\r\nThe coordinates of a polygonal area and polygonal obstacles define an instance of the problem. We discretize the area to be developed and the surrounding roads. The discretized roads lead to a finite number of pairs of discretization points. For each of these pairs, a pre-processing algorithm determines, whether the pair defines a possible skid trail (valid orientation, not interrupted by an obstacle etc.). \r\n\r\nFrom the resulting set of possible skidding trails, the model tries to find a subset, such that each point in the area can be harvested (distance between point and a selected trail less than 12.5 m) and no two selected trails are closer than 20 m. In the process of selecting trails, our model tries to minimize the selected overall length, and to minimize the deviation from the optimal orientation and the optimal pairwise distance.\r\n\r\nThe initial results of the developed multi-objective MILP had performance issues and difficulties arising from a myriad of possible area shapes. At least the former part can be addressed by relaxing some of the binary decision variables without affecting model correctness. The latter part seems harder to resolve. ", :title "Skid-Trail Location Problem in Forestry based on the Set Cover Problem", :keyword2 38, :authors (55376 60136), :session 84}, 769 {:keyword1 95, :keyword3 0, :abstract "This presentation deals with new exact branch-and-price-and-cut algorithms for the solution of two variants of the well-known vehicle routing problem. In both cases, the focus lies on the effective solution of the pricing problems with labeling algorithms.\r\nIn the truck-and-trailer routing problem (TTRP), the vehicle fleet consists of truck-and-trailer-combinations. Some customers are not accessible with a truck-and-trailer combination, but can however be serviced by one if the trailer is previously parked at a suitable location. In a first extension, the planning horizon comprises two days and customers may be visited either on both days or only once, in which case twice the daily supply must be collected. A second extension incorporates load transfer times depending on the quantity moved from a truck to its trailer.\r\nIn the periodic vehicle routing problem with time-windows (PVRPTW), customers require one or several visits during a planning horizon of several periods. The possible visiting patterns (schedules) per customer are limited. In the classical PVRPTW, it is commonly assumed that each customer requires a specific visit frequency and allows all corresponding schedules with regular intervals between the visits. In the new version with flexible schedule structures, we permit the choice of the service frequency and also irregular schedules.\r\nBoth problems are tackled with specialized branch-and-price-and-cut algorithms, which make use of the inherent symmetries. The effectiveness of the algorithms is demonstrated with extensive computational studies.", :title "Branch-and-Price-and-Cut Algorithms for Two Vehicle Routing Problems", :keyword2 0, :authors (49040), :session 222}, 771 {:keyword1 45, :keyword3 0, :abstract "In recent years, several presentations I have given have addressed the utility of the Accumulating Priority Queue (APQ) discipline, to respond to the stated limits of Key Performance Indicators for the waiting times, such as the Canadian Triage and Acuity Score (CTAS) and the Australasian Triage Score (ATS). Recently, we have been working with a two-year Emergency Department dataset from a hospital in Southern Ontario, which profiles the demand for emergency care by CTAS category. This profile reveals that this hospital, and others like it in Ontario, are highly dominated by the middle acuity class, CTAS 3 (Urgent cases). This reality changes significantly the appropriateness of an APQ approach, which now needs to entail an element of delay for some classes before priority starts to accumulate. This presentation will explain the rationale behind this conclusion, and present numerical results for the lower acuity class of interest: CTAS 4 (Less Urgent) cases. We may be able to present analytical waiting time results for the higher priority classes; it not, simulation results will be reported.\r\n", :title "An updated approach to Emergency Department prioritization in light of empirical data", :keyword2 0, :authors (8964), :session 174}, 772 {:keyword1 93, :keyword3 0, :abstract "Prestressed concrete bridges contain a risk of stressed corrosion because of the occurrence of cracks in the material. To which extent these cracks can become dangerous, was shown impressively in the latest news about the collapse of a high concrete bridge in Genoa, Italy. Thus a regular maintenance and inspection of construction conditions are very important to preserve bridges and to avoid any danger for the civilians. The fifth natural frequency of the bridge can be used to detect condition changes of the substance. In this regard the acceleration sensor uses a frequency around 10 Hz for the condition monitoring in the present use case of the Stadtring Süd bridge in the city of Würzburg, Germany. In the case of the spread of cracks the natural frequency would change. Therefore it should be possible, to monitor the condition of bridges by the use of acceleration sensors.\r\n", :title "Bridge monitoring techniques by means of acceleration sensors", :keyword2 175, :authors (60454), :session 200}, 773 {:keyword1 22, :keyword3 0, :abstract "The main task of evacuation planning is the guidance of the evacuees through the street network to reduce casualty risks and increase the performance of the evacuation process. Usually the capacities of the street network are assumed as in daily-traffic. However, such rare and unique situations induce disaster-related or traffic-related factors which affect the capacities of the street network negatively. The contribution of this work lies in designing a deterministic optimization model that is more robust against these capacity uncertainties. Therefore, we adopt an idea that has already been successfully applied to robust network design: The robustness of the street network is enhanced by a better utilization of the available network capacities and by reducing interdependencies in the network. Thus, evacuation performance (e.g., the total evacuation time) is not our only objective and we are willing to sacrifice some of it to enhance the robustness in the face of unpredictable capacity disruptions. A new innovative bi-objective evacuation model and individual solution methods are presented. These methods and the new robust concept are evaluated in an extensive computational study. ", :title "Robust Evacuation Planning for Urban Areas", :keyword2 0, :authors (49060), :session 222}, 774 {:keyword1 95, :keyword3 59, :abstract "One possibility of coordinating service requests that arise for vehicles of a carsharing fleet is to optimize routes of shuttles that drop-off and pick up service agents. This scenario is modeled as a variant of Vehicle Routing Problem (VRP), including aspects of the VRP with Time Windows, the Team Orienteering Problem and the Pick-Up and Delivery Problem. A metaheuristic, an Adaptive Large Neighborhood Search is adapted, tested by applying real-world data and evaluated regarding performance and run time. The results show that, despite high run times to improve the initial solution several times, a feasible solution is obtained quickly. Some very practicable routes are obtained when including the minimization of the latest arrival time in the hierarchical objective function. Then, all shuttles are occupied evenly and results reach a high number of served requests. The algorithm can support fleet managers to handle a complex problem within their daily business.\r\n", :title "An Adaptive Large Neighborhood Search for Routing and Scheduling Carsharing Service Requests", :keyword2 96, :authors (60383), :session 227}, 775 {:keyword1 95, :keyword3 59, :abstract "Recently, there has been a surge of interest, from both practitioners and academic researchers, that concerns the utilization of drones in civil applications. In this context, the Vehicle Routing Problem (VRP) has also been affected by this interest, as many variants have been proposed where the inclusion of drones in last-mile delivery might lead to increased savings in terms of cost, emissions, energy, or time.\r\nIn this work, we are interested in studying a variant that is called the Vehicle Routing Problem with Drones (VRPD). In the case of the VRPD, a fleet of vehicles, each of them equipped with a set of drones, is tasked with serving a set of customers. The drones may be launched from and recovered by the vehicle and might reach the customers faster than the vehicle. However, drones possess a limited flight endurance and carrying capacity. Hence, a high degree of synchronization is required in determining a feasible routing with minimal mission time. The VRPD can be formulated as a Mixed Integer Linear Program (MILP) and, consequently, be solved by any standard MILP solver. The formulation can be enhanced through the introduction of some valid inequalities (VIEQ). However, only small-sized instances can be solved through a MILP solver within a reasonable amount of time. Thus, for solving large-scale VRPD instances, we propose an algorithm based on Variable Neighborhood Search (VNS). In order to verify the efficiency of our proposed VIEQ and VNS algorithm, we carried out extensive computational experiments. Through our numerical results, we provide an insight that drones can be beneficial with regards to significantly reduced mission times.\r\n", :title "Integration of Drones in Last-Mile Delivery: The Vehicle Routing Problem with Drones", :keyword2 174, :authors (50469), :session 227}, 776 {:keyword1 42, :keyword3 0, :abstract "The 'clique problem under multiple-choice constraints' (CPMC) is a special case of the general clique problem which incorporates a commonly found structure of real-world applications like e.g. subway, railway or runway scheduling. Although CPMC is NP-complete, polynomial-time solvable subclasses have been identified.\r\n\r\nWe investigate a subclass where the multiple-choice sets have a forest-like dependency structure (FCPMC). A full convex hull description based on stable set inequalities will be presented and it will be shown that FCPMC is in P . Surprisingly, the convex hull description can have exponentially many facets. To apply the convex hull description to real-world problems, we developed criteria on how to more efficiently find the required stable sets as well as a polynomial-time separation algorithm.\r\n\r\nThe theoretical results were then successfully applied to energy efficient subway and railway timetabling. Using the convex hull description, the Nürnberg subway traf- fic during morning rush-hour has been optimized. The comparison of the optimized schedule to the currently used schedule showed that the total energy consumption can be reduced by up to 18%. The convex hull description of FCPMC has also been tested on a general CPMC instance where it had a remarkable positive impact on solving times.\r\n", :title "The Clique-Problem under Multiple-Choice Constraints with Cycle-Free Dependency Graphs", :keyword2 105, :authors (55909), :session 227}, 777 {:keyword1 162, :keyword3 0, :abstract "The amazing success of computational mathematical optimization over the last decades has been driven more by insights into mathematical structures than by the advance of computing technology. In this talk, we focus on work on non-convex quadratic programs and show how problem specific structure can be used to obtain tight relaxations and speed up Branch&Bound methods.  \r\n\r\nWe contribute in several ways: First, we establish a new way to handle missing linearization variables in the well-known Reformulation-Linearization-Technique (RLT). Second, we study the optimization of a quadratic objective over the standard simplex.  These basic structure appears as part of many complex models.  Exploiting connections to the maximum clique problem and RLT, we derive new valid and strong inequalities. Third, we strengthen the state-of-the-art relaxation for the Pooling Problem, a well-known non-convex quadratic problem, which is, for example, relevant in the petrochemical industry. We propose a novel relaxation that captures the essential non-convex structure of the problem but is small enough for an in-depth study. All our finding are backed by extensive computational studies.\r\n", :title "Exploiting structure in non-convex quadratic optimization", :keyword2 158, :authors (30768), :session 222}}, :users {1 {:firstname "Bernard", :lastname "Fortz", :department "Département d'Informatique", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (231 189 232)}, 125 {:firstname "Norbert", :lastname "Trautmann", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (160)}, 227 {:firstname "Irinel", :lastname "Dragan", :department "Mathematics", :institution "University of Texas", :country "United States", :sessions (223)}, 406 {:firstname "Ilker", :lastname "Birbil", :department "Econometric Institute", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (163)}, 428 {:firstname "Kenneth", :lastname "Sörensen", :department "Faculty of Applied Economics", :institution "University of Antwerp", :country "Belgium", :sessions (165 36)}, 829 {:firstname "Rainer", :lastname "Kolisch", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (157 389645 205)}, 909 {:firstname "Martin", :lastname "Grunow", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (186)}, 913 {:firstname "Jean-François", :lastname "Cordeau", :department "Department of Logistics and Operations Management", :institution "HEC Montréal", :country "Canada", :sessions (155)}, 930 {:firstname "Christoph", :lastname "Schwindt", :department "Institute of Management and Economics", :institution "Clausthal University of Technology", :country "Germany", :sessions (191)}, 1019 {:firstname "Marc", :lastname "Uetz", :department "Applied Mathematics ", :institution "University of Twente ", :country "Netherlands", :sessions (91)}, 1116 {:firstname "Elena", :lastname "Fernandez", :department "Statistics and Operations Research", :institution "Technical University of Catalonia", :country "Spain", :sessions (154)}, 1131 {:firstname "Heinrich", :lastname "Kuhn", :department "Operations Management", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (187 168)}, 1194 {:firstname "Natalia", :lastname "Kliewer", :department "Information Systems", :institution "Freie Universitaet Berlin", :country "Germany", :sessions (211)}, 1244 {:firstname "Thomas", :lastname "Vossen", :department "Leeds School of Business", :institution "University of Colorado", :country "United States", :sessions (158)}, 1256 {:firstname "Teresa", :lastname "Melo", :department "Business School", :institution "Saarland University of Applied Sciences", :country "Germany", :sessions (225 173)}, 1344 {:firstname "Yves", :lastname "Crama", :department "HEC - Management School", :institution "University of Liège", :country "Belgium", :sessions (217 36)}, 1560 {:firstname "Kathrin", :lastname "Klamroth", :department "Department of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (84)}, 1601 {:firstname "Anita", :lastname "Schöbel", :department "TU Kaiserslautern", :institution "Fachbereich Mathematik", :country "Germany", :sessions (210 207 389643)}, 1609 {:firstname "Axel", :lastname "Tuma", :department "Faculty of Business Administration ", :institution "University of Augsburg", :country "Germany", :sessions (193 162)}, 1658 {:firstname "Peter", :lastname "Letmathe", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (222 158)}, 2197 {:firstname "Maria Eugénia", :lastname "Captivo", :department "Departamento de Estatística e Investigação Operacional", :institution "Universidade de Lisboa, Faculdade de Ciências and Centro de Matemática, Aplicações Fundamentais e Investigação Operacional", :country "Portugal", :sessions (170)}, 2236 {:firstname "Arik", :lastname "Sadeh", :department "Technology Management Faculty", :institution "HIT Holon Institute of Technology", :country "Israel", :sessions (196)}, 2247 {:firstname "Frédéric", :lastname "Semet", :department "CRIStAL", :institution "Centrale Lille", :country "France", :sessions (153 151)}, 2391 {:firstname "Werner", :lastname "Jammernegg", :department "Department of Information Systems and Operations", :institution "WU Vienna University of Economics and Business", :country "Austria", :sessions (226)}, 2423 {:firstname "Bülent", :lastname "Çatay", :department "Faculty of Engineering and Natural Sciences", :institution "Sabanci University", :country "Turkey", :sessions (165 169)}, 2429 {:firstname "Endre", :lastname "Boros", :department "MSIS & RUTCOR", :institution "Rutgers University", :country "United States", :sessions (217)}, 2435 {:firstname "Tolga", :lastname "Bektas", :department "University of Liverpool Management School", :institution "University of Liverpool", :country "United Kingdom", :sessions (228)}, 2519 {:firstname "El-Ghazali", :lastname "Talbi", :department "", :institution "Laboratoire d'Informatique Fondamentale de Lille", :country "France", :sessions (157 174)}, 2650 {:firstname "Grit", :lastname "Walther", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (225 153 193)}, 2651 {:firstname "Thomas", :lastname "Spengler", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (212 190)}, 2675 {:firstname "Frank", :lastname "Schultmann", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (226 193)}, 2795 {:firstname "Oliver", :lastname "Stein", :department "Institute of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (389644)}, 2813 {:firstname "Michele", :lastname "Monaci", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (230)}, 2987 {:firstname "Jeroen", :lastname "Belien", :department "Center for Information Management, Modeling and Simulation", :institution "KU Leuven", :country "Bermuda", :sessions (234 71)}, 3287 {:firstname "Miguel F.", :lastname "Anjos", :department "School of Mathematics", :institution "University of Edinburgh", :country "United Kingdom", :sessions (233)}, 3297 {:firstname "Naoki", :lastname "Katoh", :department "Department of Informatics", :institution "Kwansei Gakuin University", :country "Japan", :sessions (229)}, 3397 {:firstname "Deniz", :lastname "Aksen", :department "College of Administrative Sciences and Economics", :institution "Koç University", :country "Turkey", :sessions (151)}, 3524 {:firstname "Gerhard-Wilhelm", :lastname "Weber", :department "Faculty of Engineering Management, Chair of Marketing and Economic Engineering", :institution "Poznan University of Technology", :country "Poland", :sessions (181 209 182)}, 3531 {:firstname "Javier", :lastname "Faulin", :department "Institute Smart Cities- Dept Statistics and Operations Research", :institution "Public University of Navarre", :country "Spain", :sessions (166)}, 3614 {:firstname "Aydin", :lastname "Sipahioglu", :department "Industrial Engineering", :institution "Osmangazi University", :country "Turkey", :sessions (84)}, 3693 {:firstname "Xavier", :lastname "Gandibleux", :department "LS2N - UMR CNRS 6004", :institution "University of Nantes", :country "France", :sessions (177)}, 3753 {:firstname "Robert", :lastname "Fourer", :department "", :institution "AMPL Optimization Inc.", :country "United States", :sessions (68)}, 3843 {:firstname "Bjarni", :lastname "Kristjansson", :department "", :institution "Maximal Software", :country "Iceland", :sessions (48)}, 4161 {:firstname "Stefan", :lastname "Irnich", :department "Chair of Logistics Management, Gutenberg School of Management and Economics", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (217 154)}, 4229 {:firstname "Moritz", :lastname "Fleischmann", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (202 226)}, 4357 {:firstname "Christian", :lastname "Stummer", :department "Department of Business Administration and Economics", :institution "Bielefeld University", :country "Germany", :sessions (241)}, 4565 {:firstname "El-Houssaine", :lastname "Aghezzaf", :department "Industrial Management", :institution "Ghent University ", :country "Belgium", :sessions (175)}, 4796 {:firstname "Stefan Wolfgang", :lastname "Pickl", :department "Department of Computer Science", :institution "UBw München COMTESSA", :country "Germany", :sessions (241 242 238)}, 5078 {:firstname "Stefan", :lastname "Nickel", :department "Institute for Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (239)}, 5319 {:firstname "Luís", :lastname "Gouveia", :department "DEIO - Departamento de Estatística e Investigação Operacional", :institution "Universidade de Lisboa - Faculdade de Ciências", :country "Portugal", :sessions (228)}, 5392 {:firstname "Houshang", :lastname "Taghizadeh", :department "Department of Mangement", :institution "Tabriz Branch, Islamic Azad University, Tabriz, Iran", :country "Iran, Islamic Republic of", :sessions (191)}, 5838 {:firstname "Dirk", :lastname "Briskorn", :department "", :institution "University of Wuppertal", :country "Germany", :sessions (152 71)}, 5855 {:firstname "Bernard", :lastname "Gendron", :department "DIRO/CIRRELT", :institution "Université de Montréal", :country "Canada", :sessions (216)}, 5934 {:firstname "Nils", :lastname "Boysen", :department "Lehrstuhl für ABWL/ Operations Management", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (164)}, 6251 {:firstname "Frits", :lastname "Spieksma", :department "Mathematics and Computer Science", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (71)}, 6367 {:firstname "Edward", :lastname "Pohl", :department "Industrial Engineering", :institution "University of Arkansas", :country "United States", :sessions (32)}, 6392 {:firstname "Gregory", :lastname "Parnell", :department "Department of Industrial Engineering", :institution "University of Arkansas", :country "United States", :sessions (32)}, 7001 {:firstname "Angel A.", :lastname "Juan", :department "IN3 - Computer Science Dept.", :institution "Open University of Catalonia", :country "Spain", :sessions (166)}, 7367 {:firstname "Francois", :lastname "Margot", :department "Tepper School of Business", :institution "Carnegie Mellon University", :country "United States", :sessions (54)}, 7432 {:firstname "Patrick", :lastname "De Causmaecker", :department "Computer Science, CODeS research group", :institution "KU Leuven", :country "Belgium", :sessions (163 240)}, 7687 {:firstname "Stephan", :lastname "Dempe", :department "Mathematics and Computer Sciences", :institution "Technische Universitaet Freiberg", :country "Germany", :sessions (208)}, 7698 {:firstname "Alain", :lastname "Bensoussan", :department "School of Management", :institution "University of Texas at Dallas", :country "United States", :sessions (195)}, 7956 {:firstname "Ammar", :lastname "Oulamara", :department "", :institution "University Lorraine - LCOMS", :country "France", :sessions (212)}, 7965 {:firstname "Manuel", :lastname "Iori", :department "DISMI", :institution "University of Modena and Reggio Emilia", :country "Italy", :sessions (71)}, 8713 {:firstname "Magnus", :lastname "Fröhling", :department "Faculty of Economics", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (193)}, 8798 {:firstname "Aris", :lastname "Syntetos", :department "Cardiff Business School", :institution "Cardiff University", :country "United Kingdom", :sessions (184)}, 8964 {:firstname "David", :lastname "Stanford", :department "Dept. of Statistical & Actuarial Sciences", :institution "The University of Western Ontario", :country "Canada", :sessions (174)}, 9112 {:firstname "Stefan", :lastname "Minner", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (226 20 67)}, 9272 {:firstname "Achim", :lastname "Koberstein", :department "Information and Operations Management", :institution "European University Viadrina Frankfurt (Oder)", :country "Germany", :sessions (208)}, 9293 {:firstname "Masashi", :lastname "Miyagawa", :department "Regional Social Management", :institution "University of Yamanashi", :country "Japan", :sessions (216)}, 9301 {:firstname "Christophe", :lastname "Picouleau", :department "CNAM", :institution "Laboratoire Cedric", :country "France", :sessions (38)}, 9369 {:firstname "Inês", :lastname "Marques", :department "", :institution "Instituto Superior Técnico, Universidade de Lisboa", :country "Portugal", :sessions (170)}, 9412 {:firstname "Bruce ", :lastname "Golden", :department "Decision & Information Technologies", :institution "University of Maryland", :country "United States", :sessions (152)}, 9422 {:firstname "Stefan", :lastname "Lessmann", :department "School of Business and Economics", :institution "Humboldt-University of Berlin", :country "Germany", :sessions (201)}, 9487 {:firstname "Griselda", :lastname "Deelstra", :department "", :institution "Université libre de Bruxelles", :country "Belgium", :sessions (195)}, 9511 {:firstname "Thomas", :lastname "Stützle", :department "IRIDIA", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (203)}, 9524 {:firstname "Julia", :lastname "Rieck", :department "Operations Research Group", :institution "University of Hildesheim", :country "Germany", :sessions (153 192)}, 9583 {:firstname "Dries", :lastname "Goossens", :department "Business Informatics and Operations Management", :institution "Ghent University", :country "Belgium", :sessions (71)}, 9684 {:firstname "Francisco", :lastname "Saldanha-da-Gama", :department "Department of Statistics and Operations Research / CMAF-CIO, Faculty of Science", :institution "University of Lisbon", :country "Portugal", :sessions (239)}, 9695 {:firstname "Michael", :lastname "Stiglmayr", :department "School of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (84)}, 9731 {:firstname "Philipp", :lastname "Christophel", :department "Operations Research R&D", :institution "SAS Institute GmbH", :country "Germany", :sessions (47)}, 9881 {:firstname "Philippe", :lastname "Chevalier", :department "Louvain School of Management - CORE", :institution "Université catholique de Louvain", :country "Belgium", :sessions (40)}, 9964 {:firstname "Nobusumi", :lastname "Sagara", :department "Department of Economics", :institution "Hosei University", :country "Japan", :sessions (182)}, 10057 {:firstname "Brigitte", :lastname "Werners", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (170 173 172 190)}, 10089 {:firstname "Holger", :lastname "Hoos", :department "Leiden Institute of Advanced Computer Science (LIACS)", :institution "Universiteit Leiden", :country "Netherlands", :sessions (232)}, 10362 {:firstname "Birol", :lastname "Yüceoglu", :department "Information Technologies", :institution "Migros T.A.Ş.", :country "Turkey", :sessions (201)}, 10538 {:firstname "Richard", :lastname "Hartl", :department "Business Admin", :institution "University of Vienna", :country "Austria", :sessions (235 190)}, 10542 {:firstname "Michael", :lastname "Bussieck", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (48 68)}, 10607 {:firstname "Roel", :lastname "Leus", :department "ORSTAT", :institution "KU Leuven", :country "Belgium", :sessions (156 160 71 162)}, 10954 {:firstname "Erwin", :lastname "Pesch", :department "Faculty III", :institution "University of Siegen", :country "Germany", :sessions (161)}, 11028 {:firstname "Sureyya", :lastname "Ozogur-Akyuz", :department "Department of Mathematics Engineering", :institution "Bahcesehir University", :country "Turkey", :sessions (202)}, 11178 {:firstname "Clifford", :lastname "Stein", :department "Dept. of IEOR", :institution "Columbia University", :country "United States", :sessions (220)}, 11277 {:firstname "Olivier", :lastname "Hudry", :department "Informatique et Reseaux", :institution "Télécom ParisTech", :country "France", :sessions (38)}, 11433 {:firstname "Kai Helge", :lastname "Becker", :department "Department of Mathematical Optimization", :institution "Zuse-Institut Berlin", :country "Germany", :sessions (220)}, 11482 {:firstname "Van-Dat", :lastname "Cung", :department "Grenoble INP - Génie Industriel", :institution "Laboratory G-SCOP", :country "France", :sessions (214)}, 11792 {:firstname "Pierre", :lastname "Dehez", :department "CORE", :institution "University of Louvain", :country "Belgium", :sessions (223)}, 12046 {:firstname "Markus", :lastname "Leitner", :department "Department of Supply Chain Analytics", :institution "Vrije Universiteit Amsterdam", :country "Netherlands", :sessions (154 230)}, 12059 {:firstname "Wlodzimierz", :lastname "Ogryczak", :department "Institute of Control & Computation Engineering", :institution "Warsaw University of Technology", :country "Poland", :sessions (85)}, 12177 {:firstname "Arie", :lastname "Koster", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (170 237)}, 12318 {:firstname "Tomasz", :lastname "Sliwinski", :department "Institute of Control and Computation Engineering", :institution "Warsaw University of Technology", :country "Poland", :sessions (89)}, 12336 {:firstname "Tobias", :lastname "Achterberg", :department "", :institution "Gurobi", :country "Germany", :sessions (50 49)}, 12428 {:firstname "Ulrich", :lastname "Dorndorf", :department "", :institution "INFORM GmbH", :country "Germany", :sessions (236)}, 12591 {:firstname "Ozay", :lastname "Ozaydin", :department "Industrial Engineering", :institution "Dogus University", :country "Turkey", :sessions (175)}, 12666 {:firstname "Stefan", :lastname "Ruzika", :department "Mathematik", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (2 177 227)}, 12952 {:firstname "Dirk Christian", :lastname "Mattfeld", :department "Business Information Systems", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (207)}, 13000 {:firstname "Mohsen", :lastname "Afsharian", :department "Department of Business Sciences", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (177)}, 13086 {:firstname "Frank", :lastname "Meisel", :department "", :institution "Christian-Albrechts-University", :country "Germany", :sessions (155 168)}, 13247 {:firstname "Mahdi", :lastname "Moeini", :department "Business Studies and Economics", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (205)}, 13758 {:firstname "Miguel", :lastname "Ortega-Mier", :department "Department of Industrial Engineering, Business Administration and Statistics", :institution "Technical University of Madrid (UPM)", :country "Spain", :sessions (170)}, 13772 {:firstname "Álvaro", :lastname "García-Sánchez", :department "Ingeniería de Organización, Administración de Empresas y Estadística", :institution "Universidad Politécnica de Madrid", :country "Spain", :sessions (170)}, 14155 {:firstname "John J.", :lastname "Kanet", :department "Operations Management - Niehaus Chair in Operations Management", :institution "University of Dayton", :country "United States", :sessions (157)}, 14573 {:firstname "Ulrich", :lastname "Thonemann", :department "Supply Chain Management", :institution "Universtiy of Cologne", :country "Germany", :sessions (20)}, 14588 {:firstname "Knut", :lastname "Haase", :department "Institut f. Verkehrswirtschaft, Lehrstuhl BWL, insb. Verkehr", :institution "Universität Hamburg", :country "Germany", :sessions (214)}, 14713 {:firstname "Frauke", :lastname "Liers", :department "Department Mathematik", :institution "FAU Erlangen-Nuremberg", :country "Germany", :sessions (80)}, 14715 {:firstname "Alf", :lastname "Kimms", :department "Mercator School of Management", :institution "University of Duisburg-Essen, Campus Duisburg", :country "Germany", :sessions (152 221 389646)}, 14736 {:firstname "Benjamin", :lastname "Hiller", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (220 221 206)}, 14848 {:firstname "Anthony", :lastname "Przybylski", :department "", :institution "LS2N - département Informatique, Université de Nantes", :country "France", :sessions (2 177)}, 14853 {:firstname "Franz", :lastname "Nelissen", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (48)}, 14876 {:firstname "Dominik", :lastname "Möst", :department "Chair of Energy Economics", :institution "Technische Universität Dresden", :country "Germany", :sessions (9)}, 14890 {:firstname "Andreas", :lastname "Kleine", :department "Operations Research", :institution "FernUniversität in Hagen (University of Hagen)", :country "Germany", :sessions (45)}, 14898 {:firstname "Lutz", :lastname "Westermann", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (48)}, 14938 {:firstname "Petra", :lastname "Mutzel", :department "Computer Science", :institution "University of Dortmund", :country "Germany", :sessions (54)}, 14969 {:firstname "Marco", :lastname "Lübbecke", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (84 66)}, 14975 {:firstname "Nicole", :lastname "Megow", :department "Mathematik/Informatik", :institution "Universität Bremen", :country "Germany", :sessions (220)}, 15060 {:firstname "Jens", :lastname "Brunner", :department "Chair of Health Care Operations/Health Information Management", :institution "Faculty of Business and Economics, University of Augsburg", :country "Germany", :sessions (171 172)}, 15178 {:firstname "Kerstin", :lastname "Schmidt", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (212)}, 15197 {:firstname "Michael", :lastname "Schroeder", :department "Optimization", :institution "Fraunhofer Institute for Industrial Mathematics", :country "Germany", :sessions (62)}, 15198 {:firstname "Wolfgang", :lastname "Brüggemann", :department "Inst. f. Operations Research", :institution "Universität Hamburg", :country "Germany", :sessions (189)}, 15433 {:firstname "Karl-Heinz", :lastname "Küfer", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (2)}, 15955 {:firstname "Anne", :lastname "Lange", :department "Luxembourg Centre for Logistics and Supply Chain Management", :institution "Université du Luxembourg", :country "Luxembourg", :sessions (167)}, 16034 {:firstname "Raffaele", :lastname "Pesenti", :department "DMA -  Dept. of Management", :institution "University of Venezia", :country "Italy", :sessions (221)}, 16035 {:firstname "Daniele", :lastname "Catanzaro", :department "Center for Operations Research and Econometrics", :institution "Université Catholique de Louvain", :country "Belgium", :sessions (221)}, 16305 {:firstname "Claudius", :lastname "Steinhardt", :department "Chair of Business Analytics & Management Science", :institution "Bundeswehr University Munich (UniBw)", :country "Germany", :sessions (179 180)}, 16315 {:firstname "Armin", :lastname "Fügenschuh", :department "MINT", :institution "Brandenburg Technical University", :country "Germany", :sessions (26 83)}, 16465 {:firstname "Inneke", :lastname "Van Nieuwenhuyse", :department "", :institution "Hasselt University", :country "Belgium", :sessions (71)}, 16468 {:firstname "Claudio", :lastname "Contardo", :department "Department of management and technology", :institution "ESG UQÀM", :country "Canada", :sessions (154)}, 16639 {:firstname "Sven", :lastname "Müller", :department "Transport Business Economics", :institution "Karlsruhe University of Applied Sciences", :country "Germany", :sessions (214)}, 16880 {:firstname "Timo", :lastname "Berthold", :department "", :institution "Fair Isaac Germany GmbH", :country "Germany", :sessions (47 50)}, 16919 {:firstname "Jan Fabian", :lastname "Ehmke", :department "Management Science", :institution "Otto-von-Guericke University", :country "Germany", :sessions (226)}, 16923 {:firstname "Guntram", :lastname "Scheithauer", :department "Mathematik", :institution "Technische Universität Dresden", :country "Germany", :sessions (220 71)}, 16988 {:firstname "Frank", :lastname "Fischer", :department "Mathematics and Natural Sciences", :institution "University of Kassel", :country "Germany", :sessions (218)}, 17006 {:firstname "Christoph", :lastname "Helmberg", :department "Fakultät für Mathematik", :institution "Technische Universität Chemnitz", :country "Germany", :sessions (192)}, 17083 {:firstname "Marc", :lastname "Pfetsch", :department "Discrete Optimization", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (50)}, 17092 {:firstname "Christina", :lastname "Büsing", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (170 80 173 194 62 237)}, 17147 {:firstname "Maria", :lastname "Cortinhal", :department "Dep. Métodos Quantitativos para Economia e Gestão, ISCTE - IUL / Centro IO, Portugal", :institution "ISCTE-IUL/CIO", :country "Portugal", :sessions (225)}, 17358 {:firstname "Sebastian", :lastname "Rachuba", :department "Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (173)}, 18188 {:firstname "Luigi", :lastname "De Giovanni", :department "Dipartimento di Matematica \"Tullio Levi-Civita\"", :institution "Università di Padova", :country "Italy", :sessions (45)}, 18193 {:firstname "Joanna", :lastname "Berlińska", :department "Faculty of Mathematics and Computer Science", :institution "Adam Mickiewicz University in Poznań", :country "Poland", :sessions (161)}, 18296 {:firstname "Markus", :lastname "Friedrich", :department "Institut für Straßen- und Verkehrswesen", :institution "Universität Stuttgart ", :country "Germany", :sessions (210)}, 18350 {:firstname "Guy", :lastname "Desaulniers", :department "", :institution "École Polytechnique de Montréal and GERAD", :country "Canada", :sessions (154)}, 18480 {:firstname "Raimund", :lastname "Kovacevic", :department "DB04 J03", :institution "Institut für Stochastik und Wirtschaftsmathematik, ORCOS", :country "Austria", :sessions (194)}, 18585 {:firstname "Julien", :lastname "Darlay", :department "", :institution "LocalSolver", :country "France", :sessions (46 49)}, 19100 {:firstname "Michael H.", :lastname "Breitner", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (196)}, 19101 {:firstname "Maria João", :lastname "Lopes", :department "Departamento de Métodos Quantitativos para a Gestão e Economia", :institution "Instituto Universitário de Lisboa (ISCTE - IUL) and CIO", :country "Portugal", :sessions (225)}, 19185 {:firstname "Efsun", :lastname "Kürüm", :department "Department of Banking and Finance", :institution "Near East University", :country "Cyprus", :sessions (198)}, 19297 {:firstname "Catherine", :lastname "Cleophas", :department "Service Analytics", :institution "CAU Kiel University", :country "Germany", :sessions (226)}, 19320 {:firstname "Michael", :lastname "Schneider", :department "Deutsche Post Chair of Optimization of Distribution Networks", :institution "RWTH Aachen", :country "Germany", :sessions (153)}, 19376 {:firstname "Rajendran", :lastname "C", :department "", :institution "IITMadras", :country "India", :sessions (161)}, 19453 {:firstname "Stefan", :lastname "Creemers", :department "", :institution "IESEG School of Management", :country "France", :sessions (156 162)}, 19477 {:firstname "Sven", :lastname "Krumke", :department "Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (159 188 229 62)}, 19811 {:firstname "Jürgen", :lastname "Strohhecker", :department "Management Department", :institution "Frankfurt School of Finance & Management", :country "Germany", :sessions (42)}, 19894 {:firstname "Michael", :lastname "Becker-Peth", :department "Technology and Operations Management", :institution "Rotterdam School of Management, Erasmus University", :country "Netherlands", :sessions (20)}, 20485 {:firstname "Ayse", :lastname "Özmen", :department "Mathematics and Statistics", :institution "University of Calgary", :country "Canada", :sessions (209)}, 20524 {:firstname "Thierry", :lastname "Pironet", :department "HEC - Management School", :institution "University of Liège", :country "Belgium", :sessions (36)}, 20832 {:firstname "Grigory", :lastname "Pishchulov", :department "", :institution "University of Manchester; St. Petersburg State University", :country "United Kingdom", :sessions (164)}, 20840 {:firstname "Erdem", :lastname "Aksakal", :department "Industrial Engineering", :institution "Ataturk University", :country "Turkey", :sessions (175)}, 20937 {:firstname "Kathrin", :lastname "Fischer", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology (TUHH)", :country "Germany", :sessions (180)}, 21108 {:firstname "Reinhard", :lastname "Madlener", :department "School of Business and Economics / E.ON Energy Research Center", :institution "RWTH Aachen University", :country "Germany", :sessions (9 37 216)}, 21140 {:firstname "Stephan", :lastname "Buetikofer", :department "Institute of Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (167 211)}, 21574 {:firstname "Susanne", :lastname "Heipcke", :department "Xpress Optimization", :institution "FICO", :country "France", :sessions (68)}, 22042 {:firstname "Ivana", :lastname "Ljubic", :department "IDS", :institution "ESSEC Business School of Paris", :country "France", :sessions (231 154)}, 22533 {:firstname "Lynda", :lastname "Sellami", :department "Sciences de Gestion", :institution "Université de Bejaia", :country "Algeria", :sessions (174)}, 22618 {:firstname "Birsen", :lastname "Eygi Erdogan", :department "Statistics", :institution "Marmara University", :country "Turkey", :sessions (202)}, 22874 {:firstname "Vladimir", :lastname "Beresnev", :department "Operation Research", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (217)}, 22994 {:firstname "Jochen", :lastname "Gönsch", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (212 209)}, 23013 {:firstname "Jim", :lastname "Duggan", :department "Information Technology", :institution "NUI, Galway", :country "Ireland", :sessions (42)}, 23161 {:firstname "Heiner", :lastname "Ackermann", :department "Department of Optimization", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (2 159)}, 23268 {:firstname "Greet", :lastname "Vanden Berghe", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (240)}, 23312 {:firstname "Claus", :lastname "Gwiggner", :department "Operations Research", :institution "University of Hamburg", :country "Germany", :sessions (45 157)}, 23325 {:firstname "Marco", :lastname "Scarsini", :department "", :institution "LUISS University", :country "Italy", :sessions (149)}, 23371 {:firstname "Andrea", :lastname "Seidl", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (181 182)}, 23407 {:firstname "Luis", :lastname "Cadarso", :department "European Institute for Aviation Training and Accreditation", :institution "Rey Juan Carlos University", :country "Spain", :sessions (45)}, 23883 {:firstname "Necati", :lastname "Aras", :department "Industrial Engineering", :institution "Bogazici University", :country "Turkey", :sessions (205)}, 23913 {:firstname "Bernd", :lastname "Zey", :department "", :institution "TU Dortmund", :country "Germany", :sessions (54)}, 23971 {:firstname "Kris", :lastname "Braekers", :department "Research Group Logistics", :institution "Hasselt University", :country "Belgium", :sessions (173 165 36 191)}, 23979 {:firstname "An", :lastname "Caris", :department "Research Group Logistics", :institution "Hasselt University", :country "Belgium", :sessions (165 235 191)}, 24047 {:firstname "Takayuki", :lastname "Okuno", :department "", :institution "RIKEN AIP", :country "Japan", :sessions (182)}, 24368 {:firstname "Joao Pedro", :lastname "Pedroso", :department "Campus da FEUP", :institution "INESC TEC and Faculdade de Ciencias, Universidade do Porto", :country "Portugal", :sessions (209)}, 24376 {:firstname "Christof", :lastname "Büskens", :department "Zentrum für Technomathematik", :institution "Universität Bremen", :country "Germany", :sessions (49)}, 24396 {:firstname "Marie-Anne ", :lastname "Guerry", :department "MOSI", :institution "Vrije Universiteit Brussel", :country "Belgium", :sessions (200)}, 24622 {:firstname "Jutta", :lastname "Geldermann", :department "Chair of Business Administration and Production Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (175 192)}, 24686 {:firstname "Edmundas Kazimieras", :lastname "Zavadskas", :department "Department of Construction Technology and Management", :institution "Vilnius Gediminas Technical University", :country "Lithuania", :sessions (85)}, 24773 {:firstname "Christoph", :lastname "Weber", :department "", :institution "University Duisburg-Essen", :country "Germany", :sessions (7)}, 24964 {:firstname "Jean-Sébastien", :lastname "Tancrez", :department "Louvain School of Management", :institution "Université catholique de Louvain", :country "Belgium", :sessions (225 169)}, 25059 {:firstname "Jean-Charles", :lastname "Lange", :department "Information & Production", :institution "UCL", :country "Belgium", :sessions (169)}, 25256 {:firstname "Alper", :lastname "Aladag", :department "Industrial Engineering Department", :institution "Osmangazi University", :country "Turkey", :sessions (84)}, 25372 {:firstname "Luce", :lastname "Brotcorne", :department "", :institution "INRIA", :country "France", :sessions (189 233)}, 25620 {:firstname "Walter", :lastname "Rei", :department "", :institution "CIRRELT and UQAM", :country "Canada", :sessions (166)}, 25830 {:firstname "Tony", :lastname "Wauters", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (217)}, 26135 {:firstname "Masao", :lastname "Fukushima", :department "", :institution "Kyoto University", :country "Japan", :sessions (182)}, 26181 {:firstname "Kei", :lastname "Takahashi", :department "Center for Mathematics and Data Science", :institution "Gunma University", :country "Japan", :sessions (176)}, 26200 {:firstname "Max", :lastname "Krueger", :department "Fakultät Wirtschaftsingenieurwesen", :institution "Hochschule Furtwangen", :country "Germany", :sessions (242)}, 26236 {:firstname "Michel", :lastname "Bierlaire", :department "ENAC INTER TRANSP-OR", :institution "École Polytechnique Fédérale de Lausanne (EPFL)", :country "Switzerland", :sessions (44 216)}, 26277 {:firstname "Michael", :lastname "Forbes", :department "", :institution "University of Queensland", :country "Australia", :sessions (154)}, 26368 {:firstname "Martin", :lastname "Grunewald", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (169)}, 26409 {:firstname "Mario", :lastname "Ruthmair", :department "Department of Statistics and Operations Research", :institution "University of Vienna", :country "Austria", :sessions (154 230)}, 26471 {:firstname "Anja", :lastname "Fischer", :department "", :institution "TU Dortmund", :country "Germany", :sessions (218)}, 26508 {:firstname "Jannik", :lastname "Matuschke", :department "TUM School of Management, Lehrstuhl für Operations Research", :institution "Technische Universität München", :country "Germany", :sessions (145)}, 26613 {:firstname "Ralf", :lastname "Gössinger", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (188 164)}, 26634 {:firstname "Sebastian", :lastname "Schiffels", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (19 205)}, 26841 {:firstname "Thomas", :lastname "Volling", :department "Chair of Production and Operations Management", :institution "TU Berlin", :country "Germany", :sessions (169)}, 26950 {:firstname "Max", :lastname "Klimm", :department "Wirtschaftswissenschaftliche Fakultät", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (147 149 223)}, 27073 {:firstname "Lin", :lastname "Xie", :department "Wirtschaftsinformatik", :institution "Leuphana Universität Lüneburg", :country "Germany", :sessions (164)}, 27111 {:firstname "Ann", :lastname "Campbell", :department "Management Sciences", :institution "The University of Iowa", :country "United States", :sessions (226)}, 27215 {:firstname "Cinzia", :lastname "Cirillo", :department "Civil and Environmental Engineering", :institution "University of Maryland", :country "United States", :sessions (37)}, 27556 {:firstname "Aziz", :lastname "Moukrim", :department "HeuDiaSyC (UMR CNRS 7253)", :institution "Université de Technologie de Compiègne", :country "France", :sessions (166)}, 27800 {:firstname "Christian", :lastname "Gahm", :department "Chair of Production & Supply Chain Management", :institution "Augsburg University", :country "Germany", :sessions (193 162)}, 28033 {:firstname "Daniel", :lastname "Schmidt", :department "Institut für Informatik", :institution "Universität zu Köln", :country "Germany", :sessions (54)}, 28099 {:firstname "Dirk", :lastname "Cattrysse", :department "Centre for Industrial Management/Traffic & Infrastructure", :institution "KU Leuven", :country "Belgium", :sessions (186)}, 28300 {:firstname "Narayan", :lastname "Rangaraj", :department "Industrial Engineering and Operations Research", :institution "Indian Institute of Technology Bombay", :country "India", :sessions (210)}, 28733 {:firstname "Lars-Peter", :lastname "Lauven", :department "", :institution "Chair of Energy Management and Power System Operation, University of Kassel", :country "Germany", :sessions (9 192)}, 29289 {:firstname "Ruben", :lastname "Hoeksma", :department "", :institution "Universität Bremen", :country "Germany", :sessions (149)}, 29296 {:firstname "Andreas", :lastname "Dellnitz", :department "", :institution "Chair of Operations Research, FernUniversität in Hagen", :country "Germany", :sessions (45)}, 29390 {:firstname "Jaroslav", :lastname "Janacek", :department "Mathematical Methods and Operations Research", :institution "University of Zilina", :country "Slovakia", :sessions (220)}, 29393 {:firstname "Marek", :lastname "Kvet", :department "", :institution "University of Zilina", :country "Slovakia", :sessions (220)}, 29473 {:firstname "Vakif", :lastname "Dzhafarov", :department "Mathematics", :institution "Anadolu University", :country "Turkey", :sessions (181)}, 29563 {:firstname "Dominik", :lastname "Kress", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (161)}, 29571 {:firstname "Timo", :lastname "Gschwind", :department "", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (154)}, 29594 {:firstname "Gregor", :lastname "Hendel", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (47 50)}, 29687 {:firstname "Csaba", :lastname "Fabian", :department "Dept. of Informatics", :institution "John von Neumann University", :country "Hungary", :sessions (208)}, 29689 {:firstname "Andrej", :lastname "Bregar", :department "", :institution "Informatika", :country "Slovenia", :sessions (85)}, 29732 {:firstname "Imre", :lastname "Dobos", :department "Economics", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (164)}, 29815 {:firstname "Simon", :lastname "Emde", :department "Management Science / Operations Research", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (162)}, 30108 {:firstname "Vittorio", :lastname "Maniezzo", :department "dept. Computer Science", :institution "University of Bologna", :country "Italy", :sessions (201)}, 30325 {:firstname "Yuriy", :lastname "Zinchenko", :department "Math and Stat", :institution "University of Calgary", :country "Canada", :sessions (209)}, 30768 {:firstname "Jonas", :lastname "Schweiger", :department "", :institution "Atesio GmbH", :country "Germany", :sessions (222)}, 30921 {:firstname "Matteo", :lastname "Fischetti", :department "DEI", :institution "University of Padua", :country "Italy", :sessions (230)}, 30955 {:firstname "Philipp", :lastname "Hungerländer", :department "Mathematics", :institution "University of Klagenfurt", :country "Austria", :sessions (218 52 87 205)}, 31192 {:firstname "Frank", :lastname "Herrmann", :department "Innovation and Competence Centre for Production Logistics and Factory Planning", :institution "OTH Regensburg", :country "Germany", :sessions (189)}, 31468 {:firstname "Olivier", :lastname "Gallay", :department "HEC, Department of Operations", :institution "University of Lausanne", :country "Switzerland", :sessions (214)}, 31567 {:firstname "Maksim", :lastname "Barketau", :department "United Institute of Informatics Problems", :institution "Academy of Sciences of Belarus", :country "Belarus", :sessions (161)}, 31689 {:firstname "Nicolas", :lastname "Catusse", :department "", :institution "Grenoble INP / G-SCOP", :country "France", :sessions (234)}, 31710 {:firstname "Michaël", :lastname "Gabay", :department "", :institution "Artelys", :country "France", :sessions (24)}, 31822 {:firstname "Elmar", :lastname "Lukas", :department "Faculty of Economics and Management, LS Financial Management and Innovation Finance", :institution "Otto-von-Guericke-University of Magdeburg", :country "Germany", :sessions (195 196)}, 31863 {:firstname "Nimet", :lastname "Yapıcı Pehlivan", :department "Statistics", :institution "Selcuk University", :country "Turkey", :sessions (204 176)}, 32167 {:firstname "Manuel", :lastname "López-Ibáñez", :department "", :institution "University of Manchester", :country "United Kingdom", :sessions (203)}, 32203 {:firstname "Pieter", :lastname "Smet", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (156)}, 32377 {:firstname "Jörn", :lastname "Schönberger", :department "Faculty of Transportation and Traffic Sciences", :institution "Technical University of Dresden", :country "Germany", :sessions (168)}, 32497 {:firstname "Dimitri", :lastname "Papadimitriou", :department "Mathematics and Computer Science", :institution "University of Antwerp", :country "Belgium", :sessions (163)}, 32597 {:firstname "Sebastian", :lastname "Velten", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (159)}, 32723 {:firstname "Andrey", :lastname "Melnikov", :department "", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (217)}, 32758 {:firstname "Matthias", :lastname "Miltenberger", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (50)}, 33211 {:firstname "Stephan", :lastname "Westphal", :department "Institute for Applied Stochastics and Operations Research", :institution "Clausthal University of Technology", :country "Germany", :sessions (208)}, 33475 {:firstname "Joachim", :lastname "Block", :department "Institut für Theoretische Informatik, Mathematik und Operations Research", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (241 238)}, 33554 {:firstname "André", :lastname "Koukal", :department "", :institution "Leibniz Universität Hannover, Institut für Wirtschaftsinformatik", :country "Germany", :sessions (196)}, 33581 {:firstname "Michael", :lastname "Bastubbe", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (66)}, 33684 {:firstname "Russell", :lastname "McKenna", :department "", :institution "Chair for Energy Economics, IIP, KIT", :country "Germany", :sessions (7 8 194)}, 34301 {:firstname "Geoffrey", :lastname "De Smet", :department "", :institution "Red Hat (company)", :country "Belgium", :sessions (46)}, 35097 {:firstname "Alena", :lastname "Otto", :department "", :institution "University of Siegen", :country "Germany", :sessions (152)}, 35181 {:firstname "Ruud", :lastname "Teunter", :department "Operations", :institution "University of Groningen", :country "Netherlands", :sessions (184)}, 35382 {:firstname "Stefan", :lastname "Waldherr", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (67)}, 35390 {:firstname "Aadhaar", :lastname "Chaturvedi", :department "Business Administration", :institution "Université de Namur", :country "Belgium", :sessions (40)}, 35621 {:firstname "Lotte", :lastname "Verdonck", :department "Research Group Logistics", :institution "Hasselt University", :country "Belgium", :sessions (225)}, 35785 {:firstname "Andrea", :lastname "Tramontani", :department "", :institution "IBM Italy Research & Development", :country "Italy", :sessions (49)}, 35904 {:firstname "Pieter", :lastname "Leyman", :department "CODeS, Department of Computer Science", :institution "KU Leuven Kulak", :country "Belgium", :sessions (163)}, 36097 {:firstname "Virginie", :lastname "Lurkin", :department "Industrial Engineering", :institution "TU Eindhoven", :country "Netherlands", :sessions (216)}, 36110 {:firstname "Maximilian", :lastname "Merkert", :department "Institute of Mathematical Optimization", :institution "OVGU Magdeburg", :country "Germany", :sessions (80)}, 36404 {:firstname "Yousef", :lastname "Maknoon", :department "ENAC INTER TRANSP-OR", :institution "École Polytechnique Fédérale de Lausanne (EPFL)", :country "Switzerland", :sessions (32)}, 36405 {:firstname "Shadi", :lastname "Sharif Azadeh", :department "Econometrics (OR & Logistics)", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (216)}, 36480 {:firstname "Marco", :lastname "Rinaldi", :department "", :institution "University of Luxembourg", :country "Luxembourg", :sessions (33)}, 36484 {:firstname "Francesco", :lastname "Viti", :department "", :institution "University of Luxembourg", :country "Luxembourg", :sessions (33)}, 36600 {:firstname "Célia", :lastname "Paquay", :department "", :institution "Maastricht University", :country "Netherlands", :sessions (36)}, 36610 {:firstname "Patrick", :lastname "Beullens", :department "School of Mathematics, School of Management", :institution "University of Southampton", :country "United Kingdom", :sessions (225)}, 36613 {:firstname "Katrien", :lastname "Ramaekers", :department "Research group Logistics", :institution "Hasselt University", :country "Belgium", :sessions (173 191)}, 36732 {:firstname "Hatice", :lastname "Calik", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (212)}, 36906 {:firstname "Roman", :lastname "Cada", :department "Department of Mathematics", :institution "University of West Bohemia", :country "Czech Republic", :sessions (194)}, 36955 {:firstname "Clemens", :lastname "Thielen", :department "Department of Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (2)}, 37248 {:firstname "Patricia", :lastname "Rogetzer", :department "TUM School of Management, Logistics and Supply Chain Management", :institution "Technische Universität München", :country "Germany", :sessions (226)}, 37535 {:firstname "Mohamed Zied", :lastname "Babai", :department "", :institution "BEM-Bordeaux Management School", :country "France", :sessions (184)}, 37640 {:firstname "Nishant", :lastname "Mishra", :department "Operations Management Group", :institution "Faculty of Economics and Business, KU Leuven", :country "Belgium", :sessions (40)}, 37842 {:firstname "Lennart", :lastname "Merkert", :department "Corporate Research Germany", :institution "ABB AG", :country "Germany", :sessions (7)}, 37984 {:firstname "Hadrien", :lastname "Cambazard", :department "Operations Research", :institution "G-SCOP", :country "France", :sessions (234)}, 38253 {:firstname "Michel", :lastname "Nakhla", :department "CSG", :institution "Mines Paristech", :country "France", :sessions (228)}, 38413 {:firstname "Filip", :lastname "Van Utterbeeck", :department "", :institution "Royal Military Academy", :country "Belgium", :sessions (200)}, 39141 {:firstname "Salim", :lastname "Rostami", :department "", :institution "KU Leuven", :country "Belgium", :sessions (162)}, 39349 {:firstname "Takayuki", :lastname "Shiina", :department "Department of Industrial and Management Systems Engineering", :institution "Waseda University", :country "Japan", :sessions (157)}, 39352 {:firstname "Ruslan", :lastname "Krenzler", :department "Institute of information systems", :institution "Leuphana University of Lüneburg", :country "Germany", :sessions (164)}, 39359 {:firstname "Pirmin", :lastname "Fontaine", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (166)}, 39372 {:firstname "Margaretha", :lastname "Gansterer", :department "", :institution "University of Vienna", :country "Austria", :sessions (190)}, 39380 {:firstname "Borzou", :lastname "Rostami", :department "", :institution "École de technologie supérieure and CIRRELT", :country "Canada", :sessions (169)}, 39408 {:firstname "Christian", :lastname "Tilk", :department "Chair of Logistics Management", :institution "Gutenberg School of Management and Economics, Johannes Gutenberg University Mainz", :country "Germany", :sessions (154)}, 39424 {:firstname "Adrian", :lastname "Zimmermann", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (160)}, 39455 {:firstname "Mario", :lastname "Strassberger", :department "Faculty of Business Studies", :institution "Zittau/Goerlitz University of Applied Sciences", :country "Germany", :sessions (197)}, 39457 {:firstname "Roland", :lastname "Braune", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (225)}, 39462 {:firstname "Matthias", :lastname "Schacht", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (172)}, 39470 {:firstname "Bernd", :lastname "Hillebrand", :department "Chair of Production Management and Logistics", :institution "TU Dortmund University", :country "Germany", :sessions (187)}, 39552 {:firstname "Frank", :lastname "Gurski", :department "Institute of Computer Science", :institution "Heinrich Heine University Düsseldorf", :country "Germany", :sessions (229)}, 39554 {:firstname "Ulf", :lastname "Lorenz", :department "Chair of Technology Management", :institution "Universitaet Siegen", :country "Germany", :sessions (24 25)}, 40229 {:firstname "Herbert", :lastname "Hamers", :department "", :institution "Tilburg University", :country "Netherlands", :sessions (156)}, 40497 {:firstname "Malte", :lastname "Fliedner", :department "", :institution "University of Hamburg", :country "Germany", :sessions (191)}, 40519 {:firstname "Frederik", :lastname "Fiand", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (48 68)}, 41082 {:firstname "Henrik", :lastname "Madsen", :department "Applied Mathematics and Computer Science", :institution "Technical University of Denmark", :country "Denmark", :sessions (7)}, 41246 {:firstname "Erik", :lastname "Demeulemeester", :department "KBI", :institution "KU Leuven", :country "Belgium", :sessions (160 172)}, 41330 {:firstname "Qie", :lastname "He", :department "Industrial and Systems Engineering", :institution "University of Minnesota", :country "United States", :sessions (217)}, 41520 {:firstname "Thomas", :lastname "Bruckner", :department "Institute for Infrastructure and Resources Management", :institution "Universität Leipzig", :country "Germany", :sessions (8)}, 41758 {:firstname "Lena Charlotte", :lastname "Altherr", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (25 26 83)}, 41788 {:firstname "Kai", :lastname "Hoberg", :department "Supply Chain and Operations Strategy", :institution "Kühne Logistics University", :country "Germany", :sessions (20)}, 41930 {:firstname "Stefan", :lastname "Kupfer", :department "", :institution "Faculty of Economics and Management, LS Financial Management and Innovation Finance, Otto-von-Guericke-University of Magdeburg", :country "Germany", :sessions (196)}, 42140 {:firstname "Torsten", :lastname "Buchwald", :department "", :institution "TU Dresden", :country "Germany", :sessions (220)}, 42187 {:firstname "Peter", :lastname "Pelz", :department " \tChair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (25 26)}, 42203 {:firstname "Anna-Lena", :lastname "Sachs", :department "Department of Supply Chain Management and Management Science", :institution "University of Cologne", :country "Germany", :sessions (20)}, 42315 {:firstname "Jonas", :lastname "Witt", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (66)}, 42334 {:firstname "Sadia", :lastname "Farooq", :department "Hailey College of Commerce", :institution "University of the Punjab", :country "Pakistan", :sessions (174)}, 42548 {:firstname "Dimitri", :lastname "Nowak", :department "", :institution "Fraunhofer ITWM", :country "Germany", :sessions (2)}, 42734 {:firstname "Pascal", :lastname "Lenzner", :department "Department of Computer Science", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (91 145)}, 42818 {:firstname "Bernard ", :lastname "Gilroy", :department "Economics", :institution "University of Paderborn", :country "Germany", :sessions (197)}, 43552 {:firstname "Lisa", :lastname "Thom", :department "Institute for Numerical and Applied Mathematics", :institution "Georg-August University Goettingen", :country "Germany", :sessions (218)}, 44261 {:firstname "Angelo", :lastname "Fanelli", :department "", :institution "CNRS", :country "France", :sessions (91)}, 44469 {:firstname "Alexander", :lastname "Skopalik", :department "", :institution "University of Twente", :country "Netherlands", :sessions (91)}, 44622 {:firstname "Yongjia", :lastname "Song", :department "Statistical Sciences and Operations Research", :institution "Virginia Commonwealth University", :country "United States", :sessions (217)}, 44745 {:firstname "Alexander", :lastname "Döge", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (205)}, 44822 {:firstname "Matthias", :lastname "Feldotto", :department "Heinz Nixdorf Institute", :institution "University of Paderborn", :country "Germany", :sessions (91)}, 44928 {:firstname "Stefanie", :lastname "Wolff", :department "Faculty of Business and Economics / E.ON Energy Research Center", :institution "RWTH Aachen University", :country "Germany", :sessions (37)}, 44955 {:firstname "Bart", :lastname "Vangerven", :department "Lehrstuhl für Produktion und Logistik", :institution "Bergische Universität Wuppertal", :country "Germany", :sessions (71)}, 44979 {:firstname "Matthias", :lastname "Claus", :department "Mathematik", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (208)}, 45055 {:firstname "Sebastian", :lastname "Goderbauer", :department "Lehrstuhl für Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (84)}, 45062 {:firstname "José", :lastname "Correa", :department "Departamento de Ingenieria Industrial", :institution "Universidad de Chile", :country "Chile", :sessions (149)}, 45065 {:firstname "Andre", :lastname "Bardow", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (24)}, 45066 {:firstname "Lena Maria", :lastname "Hupp", :department "Lehrstuhl für Wirtschaftsmathematik", :institution "Friedrich-Alexander Universität Erlangen-Nürnberg", :country "Germany", :sessions (80)}, 45115 {:firstname "Veerle", :lastname "Timmermans", :department "Management Science", :institution "RWTH Aachen", :country "Netherlands", :sessions (91)}, 45137 {:firstname "Daniela", :lastname "Guericke", :department "Applied Mathematics and Computer Science", :institution "Technical University of Denmark", :country "Denmark", :sessions (7)}, 45164 {:firstname "Michael", :lastname "Zipf", :department "Chair of Energy Economics", :institution "Technische Universität Dresden", :country "Germany", :sessions (9 193)}, 45180 {:firstname "Dirk", :lastname "Abel", :department "", :institution "Institute of Automatic Control (IRT), RWTH Aachen University", :country "Germany", :sessions (8 83)}, 45236 {:firstname "Bart", :lastname "de Keijzer", :department "", :institution "University of Essex", :country "United Kingdom", :sessions (145)}, 45242 {:firstname "Maike", :lastname "Hennen", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (24)}, 45244 {:firstname "Yuya", :lastname "Higashikawa", :department "", :institution "University of Hyogo", :country "Japan", :sessions (229)}, 45274 {:firstname "Daniel", :lastname "Schmand", :department "", :institution "Goethe University Frankfurt", :country "Germany", :sessions (223)}, 45285 {:firstname "Markus", :lastname "Bambach", :department "Institute of Metal Forming", :institution "RWTH Aachen University", :country "Germany", :sessions (83)}, 45302 {:firstname "Simon", :lastname "Görtz", :department "", :institution "University of Wuppertal", :country "Germany", :sessions (84)}, 45303 {:firstname "Pierre F", :lastname "Tiako", :department "", :institution "3Langston University  and CITDR,", :country "United States", :sessions (174)}, 45346 {:firstname "Albert", :lastname "Steiner", :department "School of Engineering", :institution "ZHAW", :country "Switzerland", :sessions (211)}, 45477 {:firstname "Hocine", :lastname "Mouslim", :department "", :institution "Faculty of Management, University of Tlemcen", :country "Algeria", :sessions (176)}, 45506 {:firstname "Teodor Gabriel", :lastname "Crainic", :department "School of Management", :institution "Univ. du Québec à Montréal", :country "Canada", :sessions (166)}, 45742 {:firstname "Sebastian", :lastname "Berckey", :department "Workforce Management", :institution "INFORM GmbH", :country "Germany", :sessions (158)}, 45941 {:firstname "Dennis", :lastname "Prak", :department "", :institution "University of Groningen", :country "Netherlands", :sessions (184)}, 46168 {:firstname "Corrinne", :lastname "Luteyn", :department "Centre for Industrial Management / Traffic & Infrastructure", :institution "KU Leuven", :country "Belgium", :sessions (165)}, 46184 {:firstname "Jan", :lastname "Brinkmann", :department "Decision Support Group", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (207)}, 46228 {:firstname "Pieter", :lastname "Vansteenwegen", :department "Leuven Mobility Research Center - CIB", :institution "KU Leuven", :country "Belgium", :sessions (30 33 165 211 26)}, 46349 {:firstname "Emel", :lastname "Savku", :department "Institute of Applied Mathematics, Financial Mathematics", :institution "Middle East Technical University", :country "Turkey", :sessions (181)}, 46464 {:firstname "Anja", :lastname "Hähle", :department "Fakultät für Mathematik", :institution "TU Chemnitz", :country "Germany", :sessions (192)}, 46526 {:firstname "Daniel", :lastname "Santos", :department "DEIO", :institution "Universidade de Lisboa - Faculdade de Ciências", :country "Portugal", :sessions (228)}, 46747 {:firstname "Stefan", :lastname "Guericke", :department "", :institution "A.P. Moller - Maersk", :country "Denmark", :sessions (168)}, 46978 {:firstname "Reginald", :lastname "Dewil", :department "Centre for Industrial Management / Traffic & Infrastructure", :institution "KU Leuven", :country "Belgium", :sessions (186)}, 46997 {:firstname "Lena", :lastname "Silbermayr", :department "Department of Information Systems and Operations", :institution "WU Vienna University of Economics and Business", :country "Austria", :sessions (226)}, 47283 {:firstname "Sofie", :lastname "Van Thielen", :department "Leuven Mobility Research Centre", :institution "KU Leuven", :country "Belgium", :sessions (211)}, 47336 {:firstname "Elisabeth", :lastname "Rodriguez-Heck", :department "Chair of Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (217)}, 47422 {:firstname "Andreas", :lastname "Rudi", :department "Institute for Industrial Production (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (193)}, 47722 {:firstname "Gudrun", :lastname "Kiesmuller", :department "Business Administration", :institution "Otto von Guericke University", :country "Germany", :sessions (184 188)}, 47773 {:firstname "Martin", :lastname "Dahmen", :department "Institute of Applied Stochastics and Operations Research", :institution "TU Clausthal", :country "Germany", :sessions (208)}, 47783 {:firstname "Nicolas", :lastname "Gillis", :department "Mathematics and Operational Research", :institution "Université de Mons", :country "Belgium", :sessions (182)}, 47846 {:firstname "Teun", :lastname "van Gils", :department "Research Group Logistics", :institution "Hasselt University", :country "Belgium", :sessions (191)}, 47964 {:firstname "Marco Antonio", :lastname "Boschetti", :department "", :institution "University of Bologna", :country "Italy", :sessions (201)}, 48187 {:firstname "Simone", :lastname "Neumann", :department "Chair of Health Care Operations / Health Information Management", :institution "University of Augsburg", :country "Germany", :sessions (45)}, 48339 {:firstname "Nora", :lastname "Dörmann", :department "", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (241)}, 48465 {:firstname "Oleg", :lastname "Khamisov", :department "", :institution "Energy System Institute", :country "Russian Federation", :sessions (182)}, 48468 {:firstname "Berk", :lastname "Ayvaz", :department "Industrial Engineering", :institution "Istanbul Commerce University", :country "Turkey", :sessions (169)}, 48604 {:firstname "John", :lastname "Boylan", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (184)}, 48742 {:firstname "Rainer", :lastname "Schlosser", :department "Hasso Plattner Institute", :institution "University of Potsdam", :country "Germany", :sessions (179)}, 48817 {:firstname "Michael", :lastname "Winkler", :department "", :institution "Gurobi GmbH", :country "Germany", :sessions (47)}, 48827 {:firstname "Pierre", :lastname "Hauweele", :department "Algorithms Lab", :institution "UMONS", :country "Belgium", :sessions (230)}, 48830 {:firstname "Paul", :lastname "Duetting", :department "Mathematics", :institution "London School of Economics", :country "United Kingdom", :sessions (147)}, 48911 {:firstname "Paul", :lastname "Karaenke", :department "Department of Informatics (I18)", :institution "Technical University of Munich", :country "Germany", :sessions (67)}, 48992 {:firstname "John", :lastname "Martinovic", :department "Mathematik", :institution "Technische Universität Dresden", :country "Germany", :sessions (71)}, 49040 {:firstname "Ann-Kathrin", :lastname "Rothenbächer", :department "", :institution "Johannes Gutenberg University", :country "Germany", :sessions (222)}, 49052 {:firstname "Manu", :lastname "Kapolke", :department "Department Mathematik", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (80)}, 49060 {:firstname "Marc", :lastname "Maiwald", :department "", :institution "Mercator School of Management, University of Duisburg-Essen", :country "Germany", :sessions (222)}, 49073 {:firstname "Fabian", :lastname "Strohm", :department "Chair of Service Operations Management", :institution "University of Mannheim", :country "Germany", :sessions (156)}, 49079 {:firstname "Steffen", :lastname "Goebbels", :department "iPattern Institute, Faculty of Electrical Engineering and Computer Science", :institution "Niederrhein University of Applied Sciences", :country "Germany", :sessions (218)}, 49085 {:firstname "Björn", :lastname "Bahl", :department "", :institution "RWTH Aachen", :country "Germany", :sessions (24)}, 49145 {:firstname "Patrick", :lastname "Gerhards", :department "Institute of Computer Science", :institution "Helmut-Schmidt-University", :country "Germany", :sessions (160)}, 49158 {:firstname "Viktor", :lastname "Bindewald", :department "Institute for Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (54)}, 49171 {:firstname "Pierre", :lastname "Bonami", :department "", :institution "IBM", :country "Spain", :sessions (49)}, 49180 {:firstname "Sven", :lastname "Mallach", :department "", :institution "Universität zu Köln", :country "Germany", :sessions (52 87)}, 49192 {:firstname "Maryam", :lastname "Nouri", :department "", :institution "University of Mannheim", :country "Germany", :sessions (226)}, 49216 {:firstname "Jan", :lastname "Schoenfelder", :department "Health Care Operations / Health Information Management", :institution "University of Augsburg", :country "Germany", :sessions (171)}, 49276 {:firstname "Christoph", :lastname "Hofer", :department "Institute for Data Analysis and Process Design", :institution "University of Applied Sciences Zurich", :country "Switzerland", :sessions (167)}, 50029 {:firstname "Nadia", :lastname "Brauner", :department "", :institution "Université Grenoble Alpes ", :country "France", :sessions (234)}, 50134 {:firstname "Jakob", :lastname "Witzig", :department "Mathematical Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (50)}, 50435 {:firstname "Hilde", :lastname "Heggen", :department "Research Group Logistics", :institution "UHasselt", :country "Belgium", :sessions (165)}, 50469 {:firstname "Daniel", :lastname "Schermer", :department "Departement of Business Studies and Economics", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (227)}, 50556 {:firstname "Jose Miguel", :lastname "Quesada", :department "CORE - Louvain School of Management", :institution "Universite catholique de Louvain", :country "Belgium", :sessions (169)}, 50791 {:firstname "Michael", :lastname "Hartisch", :department "Chair of Technology Management", :institution "University of Siegen", :country "Germany", :sessions (24)}, 50802 {:firstname "Tom", :lastname "Walther", :department "", :institution "Gnosis / Zuse Institute Berlin", :country "Germany", :sessions (195 206)}, 50836 {:firstname "Ulf", :lastname "Friedrich", :department "Operations Research", :institution "Technical University of Munich", :country "Germany", :sessions (206)}, 50839 {:firstname "Meritxell", :lastname "Pacheco Paneque", :department "TRANSP-OR", :institution "EPFL", :country "Switzerland", :sessions (216)}, 50868 {:firstname "Michael", :lastname "Emmerich", :department "Leiden University", :institution "LIACS", :country "Netherlands", :sessions (2)}, 50992 {:firstname "Kerstin", :lastname "Maier", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (52 87)}, 50997 {:firstname "Christian", :lastname "Truden", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (87)}, 51069 {:firstname "Ruth", :lastname "Misener", :department "Department of Computing", :institution "Imperial College London", :country "United Kingdom", :sessions (49)}, 51077 {:firstname "Per", :lastname "Sjögren", :department "", :institution "RaySearch Laboratories", :country "Sweden", :sessions (167)}, 51079 {:firstname "Hadrien", :lastname "Mélot", :department "Computer Science Dept", :institution "Université de Mons", :country "Belgium", :sessions (230)}, 51088 {:firstname "Gauvain", :lastname "Devillez", :department "Computer science", :institution "UMONS", :country "Belgium", :sessions (230)}, 51089 {:firstname "Moritz", :lastname "Behrend", :department "School of Business", :institution "Kiel University", :country "Germany", :sessions (168)}, 51294 {:firstname "Diego", :lastname "Cattaruzza", :department "", :institution "Centrale Lille", :country "France", :sessions (153 151)}, 51420 {:firstname "Florian", :lastname "Arnold", :department "", :institution "University of Antwerp", :country "Belgium", :sessions (165)}, 51469 {:firstname "Bo", :lastname "Jensen", :department "CPLEX", :institution "IBM", :country "Denmark", :sessions (47)}, 51498 {:firstname "Cristina", :lastname "Feniser", :department "Management and System Engineer", :institution "Technical University of Cluj Napoca", :country "Romania", :sessions (196)}, 51656 {:firstname "Daniel", :lastname "Kowalczyk", :department "ORSTAT", :institution "KU Leuven", :country "Belgium", :sessions (71)}, 51662 {:firstname "Anna", :lastname "Jellen", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (52 87)}, 51676 {:firstname "Mathias", :lastname "Staudigl", :department "Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (223)}, 51992 {:firstname "Joren", :lastname "Marynissen", :department "KBI", :institution "KU Leuven", :country "Belgium", :sessions (172)}, 52004 {:firstname "Bernd", :lastname "Nieberding", :department "Institut Verkehr und Raum", :institution "Fachhochschule Erfurt", :country "Germany", :sessions (166)}, 52258 {:firstname "Maximilian", :lastname "Schiffer", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (222 153 193)}, 52268 {:firstname "Anja", :lastname "Heßler", :department "Institute of Management and Economics", :institution "Clausthal University of Technology", :country "Germany", :sessions (191)}, 52270 {:firstname "Martin", :lastname "Comis", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (173 62)}, 52290 {:firstname "Cornelia", :lastname "Schoen", :department "Chair of Service Operations Management", :institution "University of Mannheim", :country "Germany", :sessions (156 179)}, 52308 {:firstname "Daniel", :lastname "Sturm", :department "", :institution "Institute for Operations Research and Information Systems, Hamburg University of Technology (TUHH)", :country "Germany", :sessions (180)}, 52352 {:firstname "Jan-Hendrik", :lastname "Piel", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (196)}, 52367 {:firstname "Alexander", :lastname "Schiewe", :department "", :institution "TU Kaiserslautern", :country "Germany", :sessions (210)}, 52375 {:firstname "Paul Alexandru", :lastname "Bucur", :department "", :institution "Universität Klagenfurt", :country "Austria", :sessions (205)}, 52394 {:firstname "Martin", :lastname "Tschöke", :department "Institute for Operations Management", :institution "University of Hamburg", :country "Germany", :sessions (191)}, 52405 {:firstname "Felix", :lastname "Fischer", :department "School of Mathematical Sciences", :institution "Queen Mary University of London", :country "United Kingdom", :sessions (147)}, 52424 {:firstname "Julius", :lastname "Pätzold", :department "Institute for Numerical and Applied Mathematics", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (207)}, 52430 {:firstname "Manuel", :lastname "Glaser", :department "UNIKA-T", :institution "Universität Augsburg", :country "Germany", :sessions (172)}, 52443 {:firstname "Alexander", :lastname "Martin", :department "", :institution "Department Mathematik, FAU Erlangen-Nürnberg", :country "Germany", :sessions (80)}, 52444 {:firstname "Peter", :lastname "Czimmermann", :department "Dep. of Mathematical Methods and Operations Research", :institution "University of Zilina", :country "Slovakia", :sessions (228)}, 52445 {:firstname "Nicolas", :lastname "Kämmerling", :department "", :institution "Institute of Transport Logistics, TU Dortmund University", :country "Germany", :sessions (169)}, 52479 {:firstname "Oskar", :lastname "Schneider", :department "", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (80)}, 52489 {:firstname "Philine", :lastname "Schiewe", :department "", :institution "TU Kaiserslautern", :country "Germany", :sessions (210)}, 52493 {:firstname "Lisa", :lastname "Koppka", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (173 172)}, 52508 {:firstname "Tristan", :lastname "Becker", :department "Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (170 190)}, 52514 {:firstname "Pia Mareike", :lastname "Steenweg", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (170)}, 52549 {:firstname "Khairun", :lastname "Bapumia", :department "", :institution "Ruhr University Bochum", :country "Germany", :sessions (173)}, 52562 {:firstname "Matthias", :lastname "Schinner", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (158)}, 52563 {:firstname "Kevin", :lastname "Schewior", :department "Département d'Informatique", :institution "ENS Paris and TU München", :country "France", :sessions (220 223)}, 52585 {:firstname "Lin", :lastname "Chen", :department "", :institution "MTA SZTAKI", :country "Hungary", :sessions (220)}, 52590 {:firstname "Aynur", :lastname "Şahin", :department "Statistics", :institution "Selçuk University", :country "Turkey", :sessions (204)}, 52600 {:firstname "Masoud", :lastname "Shahmanzari", :department "College of Administrative Sciences and Economics", :institution "Koç University", :country "Turkey", :sessions (151)}, 52601 {:firstname "Marcus", :lastname "Wiens", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (226)}, 52606 {:firstname "Mathias", :lastname "Kasper", :department "", :institution "TU Dresden", :country "Germany", :sessions (214 204)}, 52640 {:firstname "Sakina", :lastname "Melloul", :department "Faculty of Management and Business.", :institution "University Centre of Maghnia, Algeria.", :country "Algeria", :sessions (176)}, 52669 {:firstname "Charlotte", :lastname "Köhler", :department "Management Science", :institution "Otto von Guericke University", :country "Germany", :sessions (226)}, 52786 {:firstname "Mohammad", :lastname "Rahimi", :department "", :institution "INRIA Centre de recherche Lille-Nord Europe", :country "France", :sessions (157)}, 52787 {:firstname "Andreas", :lastname "Westerlund", :department "", :institution "Jeppesen", :country "Sweden", :sessions (167)}, 52827 {:firstname "Alexander", :lastname "Tesch", :department "Mathematical Optimization", :institution "ZIB", :country "Germany", :sessions (80)}, 53033 {:firstname "José Rui", :lastname "Figueira", :department "", :institution "CEG-IST, Instituto Superior Técnico, Universidade de Lisboa", :country "Portugal", :sessions (177)}, 53427 {:firstname "Andreas", :lastname "Fügener", :department "", :institution "Universität Köln", :country "Germany", :sessions (19)}, 53481 {:firstname "Fabio", :lastname "D'Andreagiovanni", :department "", :institution "University of Technology of Compiègne (UTC)", :country "France", :sessions (189)}, 53572 {:firstname "Evrim", :lastname "Gencalp", :department "", :institution "Borusan R&D", :country "Turkey", :sessions (162)}, 53611 {:firstname "Ignacio", :lastname "Blanco", :department "", :institution "Applied Mathematics and Computer Science, Technical University of Denmark", :country "Denmark", :sessions (7)}, 53870 {:firstname "Martin", :lastname "Stubenschrott", :department "", :institution "AIT Austrian Institute of Technology", :country "Austria", :sessions (44)}, 53961 {:firstname "Renke", :lastname "Kuhlmann", :department "Zentrum für Technomathematik", :institution "Universität Bremen", :country "Germany", :sessions (49)}, 54047 {:firstname "Felix", :lastname "Tamke", :department "", :institution "TU Dresden", :country "Germany", :sessions (153)}, 54141 {:firstname "Anae", :lastname "Sobhani", :department "Technology, policy and management", :institution "Delft University", :country "Netherlands", :sessions (32)}, 54266 {:firstname "Warren", :lastname "Volk-Makarewicz", :department "Operations Research and Management", :institution "RWTH Aachen University", :country "Germany", :sessions (198)}, 54540 {:firstname "Hamid", :lastname "Abedinnia", :department "Produktion und Supply Chain Management", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (167)}, 54544 {:firstname "Mehdi", :lastname "Karimi-Nasab", :department "", :institution "Institute for Operations Research, University of Hamburg", :country "Germany", :sessions (189)}, 54586 {:firstname "David", :lastname "Christen", :department "Finance & Banking", :institution "University of Marburg", :country "Germany", :sessions (197)}, 54627 {:firstname "San Tu", :lastname "Pham", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (163)}, 54943 {:firstname "Maxime", :lastname "Ogier", :department "CRIStAL laboratory", :institution "Centrale Lille", :country "France", :sessions (153 151)}, 55079 {:firstname "Martin", :lastname "Bue", :department "", :institution "INRIA", :country "France", :sessions (174)}, 55197 {:firstname "Cornelius", :lastname "Rüther", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "University of Hildesheim", :country "Germany", :sessions (153)}, 55240 {:firstname "Maxence", :lastname "Delorme", :department "", :institution "University of Bologna", :country "Italy", :sessions (71)}, 55265 {:firstname "Andreas", :lastname "Tönnis", :department "", :institution "Universität Bonn", :country "Germany", :sessions (223)}, 55298 {:firstname "Christopher", :lastname "Hojny", :department "", :institution "TU Darmstadt", :country "Germany", :sessions (50)}, 55333 {:firstname "Martin", :lastname "Bichler", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (67)}, 55334 {:firstname "Adalat", :lastname "Jabrayilov", :department "Department of Computer Science", :institution "TU Dortmund", :country "Germany", :sessions (54)}, 55372 {:firstname "Moritz", :lastname "Mühlenthaler", :department "Fakultät für Mathematik", :institution "TU Dortmund University", :country "Germany", :sessions (54)}, 55376 {:firstname "Martin", :lastname "Matke", :department "", :institution "Fraunhofer IFF", :country "Germany", :sessions (84)}, 55419 {:firstname "Robert Lion", :lastname "Gottwald", :department "Mathematical Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (50)}, 55434 {:firstname "Ola", :lastname "Jabali", :department "Dipartimento di Elettronica, Informazione e Bioingegneria", :institution "Politecnico di Milano", :country "Italy", :sessions (166)}, 55472 {:firstname "Pavlo", :lastname "Glushko", :department "Information and Operations Management", :institution "European-University Viadrina Frankfurt (Oder)", :country "Germany", :sessions (208)}, 55546 {:firstname "Jérôme", :lastname "De Boeck", :department "Graphes et Optimisation Mathématique", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (189)}, 55580 {:firstname "Bernhard", :lastname "Nietert", :department "Finance and Banking", :institution "Philipps Universitaet Marburg", :country "Germany", :sessions (197)}, 55638 {:firstname "Sascha", :lastname "Kuhnke", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (194)}, 55639 {:firstname "Markus", :lastname "Seizinger", :department "Faculty of Business and Economics", :institution "Universität Augsburg", :country "Germany", :sessions (171)}, 55648 {:firstname "Sebastian", :lastname "Kraul", :department "", :institution "University of Augsburg", :country "Germany", :sessions (171)}, 55674 {:firstname "Lea", :lastname "Rausch", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (26)}, 55675 {:firstname "Philipp", :lastname "Leise", :department "", :institution "TU Darmstadt", :country "Germany", :sessions (25)}, 55676 {:firstname "Zhengyu", :lastname "Wang", :department "Mathematics", :institution "Nanjing University", :country "China", :sessions (242)}, 55684 {:firstname "John", :lastname "Friesen", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (26)}, 55691 {:firstname "Mirko", :lastname "Dahlbeck", :department "Mathematik  und Informatik", :institution "Universität Göttingen", :country "Germany", :sessions (218)}, 55692 {:firstname "Florian", :lastname "Hauck", :department "Information Systems", :institution "Freie Universität Berlin", :country "Germany", :sessions (211)}, 55713 {:firstname "Regina", :lastname "Pohle-Fröhlich", :department "", :institution "iPattern Institute, Faculty of Electrical Engineering and Computer Science, Niederrhein University of Applied Sciences", :country "Germany", :sessions (218)}, 55737 {:firstname "David", :lastname "Stenger", :department "Institute of Automatic Control (IRT)", :institution "RWTH Aachen University", :country "Germany", :sessions (83)}, 55746 {:firstname "Jonas Benjamin", :lastname "Weber", :department "Chair of Technology Management", :institution "University of Siegen", :country "Germany", :sessions (25)}, 55749 {:firstname "Guopeng", :lastname "Song", :department "ORSTAT", :institution "KU Leuven", :country "Belgium", :sessions (160)}, 55751 {:firstname "Christian", :lastname "Reintjes", :department "Technology Management", :institution "University of Siegen", :country "Germany", :sessions (24)}, 55798 {:firstname "Lorena", :lastname "Reyes-Rubiano", :department "Institute of Smart Cities-- Dept Statistics and Operations Research", :institution "Public university of Navarra", :country "Spain", :sessions (166)}, 55807 {:firstname "Julia Sophie", :lastname "Block", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (172)}, 55835 {:firstname "Katherina", :lastname "Meißner", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "University of Hildesheim", :country "Germany", :sessions (200)}, 55847 {:firstname "Timo", :lastname "Gersing", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (170)}, 55849 {:firstname "Stefan", :lastname "Lier", :department "", :institution "FH Südwestfalen", :country "Germany", :sessions (190)}, 55858 {:firstname "Tobias", :lastname "Volkmer", :department "Chair of Management and Organization", :institution "Otto von Guericke University Magdeburg", :country "Germany", :sessions (190)}, 55867 {:firstname "Andreas", :lastname "Hottenrott", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (186)}, 55873 {:firstname "Stephan", :lastname "Hocke", :department "Faculty of Transportation and Traffic Sciences", :institution "Technical University of Dresden", :country "Germany", :sessions (204)}, 55877 {:firstname "Nicolas", :lastname "Zufferey", :department "GSEM", :institution "University of Geneva", :country "Switzerland", :sessions (186 214 204)}, 55878 {:firstname "Marc-Antoine", :lastname "Coindreau", :department "HEC, Department of Operations", :institution "University of Lausanne", :country "Switzerland", :sessions (214)}, 55881 {:firstname "Jan", :lastname "Busse", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "Universität Hildesheim", :country "Germany", :sessions (192)}, 55900 {:firstname "Carolin", :lastname "Rehs", :department "Institute of Computer Science", :institution "Heinrich Heine University Düsseldorf", :country "Germany", :sessions (229)}, 55909 {:firstname "Patrick", :lastname "Gemander", :department "", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (80 227)}, 55920 {:firstname "Stefan", :lastname "Schwerdfeger", :department "", :institution "Friedrich-Schiller-Universität Jena, Lehrstuhl für Management Science", :country "Germany", :sessions (164)}, 55921 {:firstname "David", :lastname "Boywitz", :department "", :institution "Lehrstuhl für ABWL/Management Science, Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (164)}, 55946 {:firstname "Manuel", :lastname "Streicher", :department "", :institution "TU Kaiserslautern", :country "Germany", :sessions (62)}, 55986 {:firstname "Eva", :lastname "Schmidt", :department "", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (62)}, 55993 {:firstname "Jenny", :lastname "Nossack", :department "", :institution "HHL Leipzig", :country "Germany", :sessions (161)}, 56010 {:firstname "Frederik", :lastname "Proske", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (48)}, 56018 {:firstname "Felix", :lastname "Saucke", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (212)}, 56051 {:firstname "Margarita", :lastname "Protopappa-Sieke", :department "", :institution "University of Cologne", :country "Germany", :sessions (20)}, 56054 {:firstname "Benoit", :lastname "Chevalier-Roignant", :department "accounting & financial management", :institution "king's college london", :country "United Kingdom", :sessions (195)}, 56059 {:firstname "Keisuke", :lastname "Yoshihara", :department "Graduate School of Economics", :institution "The University of Tokyo", :country "Japan", :sessions (89)}, 56080 {:firstname "Hiroshi", :lastname "Ohashi", :department "", :institution "The University of Tokyo", :country "Japan", :sessions (89)}, 56097 {:firstname "Marcel", :lastname "Lehmann", :department "Supply Chain Management & Operations", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (187)}, 56360 {:firstname "Nursen", :lastname "Aydin", :department "Warwick Business School", :institution "University of Warwick", :country "United Kingdom", :sessions (163)}, 56416 {:firstname "Valentin", :lastname "Sommer", :department "Chair of Operations Management", :institution "RWTH Aachen University, School of Business and Economics", :country "Germany", :sessions (225)}, 56420 {:firstname "Christian", :lastname "Müller", :department "", :institution "University Duisburg-Essen", :country "Germany", :sessions (212)}, 56427 {:firstname "Markus", :lastname "Kreuz", :department "School of Business and Economics", :institution "Chair of Operations Management, RWTH Aachen University", :country "Germany", :sessions (193)}, 56432 {:firstname "Patricia", :lastname "Heuser", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (158)}, 56452 {:firstname "Patrick", :lastname "Engelsberg", :department "Production and Logistics Management", :institution "FernUniversität in Hagen", :country "Germany", :sessions (169)}, 56578 {:firstname "Pinar", :lastname "Karadayi Atas", :department "Computer Engineering", :institution "Bahcesehir University", :country "Turkey", :sessions (202)}, 56608 {:firstname "Paul", :lastname "Kaufmann", :department "Law, Management, and Economics", :institution "Mainz University", :country "Germany", :sessions (203)}, 56860 {:firstname "Mohamed Amine", :lastname "El Majdouli", :department "", :institution "Mohammed V University", :country "Morocco", :sessions (203)}, 56875 {:firstname "Julia", :lastname "Heil", :department "Faculty of Business and Economics, Chair of Business Management, esp. Industrial Management", :institution "TU Dresden", :country "Germany", :sessions (210)}, 56896 {:firstname "Oliver", :lastname "Frendo", :department "", :institution "SAP SE", :country "Germany", :sessions (212)}, 56971 {:firstname "Adam", :lastname "Narkiewicz", :department "", :institution "Simiade", :country "Poland", :sessions (207)}, 57015 {:firstname "Andrea", :lastname "D'Ariano", :department "Department of Engineering", :institution "Università degli Studi Roma Tre", :country "Italy", :sessions (33)}, 57043 {:firstname "Oded", :lastname "Cats", :department "", :institution "Delft University of Technology", :country "Netherlands", :sessions (30)}, 57080 {:firstname "Lien", :lastname "Vanbrabant", :department "Research Group Logistics", :institution "Hasselt University", :country "Belgium", :sessions (173)}, 57094 {:firstname "Chaimongkol", :lastname "Limpianchob", :department "Division of Information Science,Graduate school of Science and Technology", :institution "Nara Institute of Science and Technology", :country "Japan", :sessions (184)}, 57098 {:firstname "Jeannette A. L.", :lastname "Hermanns", :department "", :institution "Decision Support Group", :country "Germany", :sessions (207)}, 57109 {:firstname "Dorothea", :lastname "Calmels", :department "Business, Economics and Information Systems", :institution "University of Passau", :country "Germany", :sessions (161)}, 57195 {:firstname "Dilara", :lastname "Aykanat", :department "", :institution "Borusan R&D", :country "Turkey", :sessions (162)}, 57228 {:firstname "FIlipe", :lastname "Brandão", :department "", :institution "AMPL", :country "Portugal", :sessions (68)}, 57230 {:firstname "Michael", :lastname "Kahr", :department "Department of Statistics and Operations Research", :institution "University of Vienna", :country "Austria", :sessions (230)}, 57456 {:firstname "Elisabetta", :lastname "Cherchi", :department "School of Engineering", :institution "Newcastle University", :country "United Kingdom", :sessions (37)}, 57467 {:firstname "Lissa", :lastname "Melis", :department "Engineering Management", :institution "University of Antwerp", :country "Belgium", :sessions (36)}, 57474 {:firstname "Pascal", :lastname "Wortel", :department "", :institution "Fraunhofer ITWM", :country "Germany", :sessions (159)}, 57524 {:firstname "Moritz", :lastname "Ruf", :department "", :institution "Technische Universität Dresden", :country "Germany", :sessions (155)}, 57622 {:firstname "Anurag", :lastname "Agrawal", :department "Electrical Engineering", :institution "Indian Institute of Technology Bombay", :country "India", :sessions (210)}, 57667 {:firstname "Baiba", :lastname "Pudāne", :department "Transport and Logistics", :institution "TU Delft", :country "Netherlands", :sessions (32)}, 57758 {:firstname "Evert", :lastname "Vermeir", :department "", :institution "KU Leuven", :country "Belgium", :sessions (33)}, 57872 {:firstname "Konstantinos", :lastname "Papalamprou", :department "", :institution "Aristotle University of Thessaloniki", :country "Greece", :sessions (197)}, 57906 {:firstname "Pascal", :lastname "Halffmann", :department "Mathematics", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (2)}, 57923 {:firstname "Lukas", :lastname "Polten", :department "", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (162)}, 57929 {:firstname "Hamed", :lastname "Jalali", :department "Department of information systems, supply chain management, and decision making", :institution "NEOMA Business school", :country "France", :sessions (71)}, 58072 {:firstname "Carlo", :lastname "Lancia", :department "Mathematical Institute", :institution "Leiden University", :country "Netherlands", :sessions (45)}, 58100 {:firstname "Sina", :lastname "Rastani", :department "Faculty of Engineering and Natural Sciences", :institution "Sabanci University", :country "Turkey", :sessions (165)}, 58102 {:firstname "Tugce", :lastname "Yuksel", :department "Faculty of Engineering and Natural Sciences", :institution "Sabanci University", :country "Turkey", :sessions (165)}, 58371 {:firstname "Ben", :lastname "Hermans", :department "", :institution "KU Leuven", :country "Belgium", :sessions (156)}, 58406 {:firstname "Francesco", :lastname "Corman", :department "", :institution "ETH Zurich", :country "Switzerland", :sessions (211)}, 58456 {:firstname "Madhu", :lastname "Belur", :department "Electrical Engineering", :institution "Indian Institute of Technology Bombay", :country "India", :sessions (210)}, 58460 {:firstname "Soumya", :lastname "Dutta", :department "Electrical Engineering", :institution "Indian Institute of Technology Bombay", :country "India", :sessions (210)}, 58499 {:firstname "B.", :lastname "Sebastian", :department "Central Railway", :institution "Indian Railways", :country "India", :sessions (210)}, 58623 {:firstname "Ana Sofia", :lastname "Carvalho", :department "", :institution "CMAFcIO", :country "Portugal", :sessions (170)}, 58624 {:firstname "Reshma", :lastname "Chirayil Chandrasekharan", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (217)}, 58916 {:firstname "Andreas", :lastname "Größler", :department "Department of Operations Management", :institution "Universität Stuttgart", :country "Germany", :sessions (42)}, 58979 {:firstname "Cristiana", :lastname "Ionescu-Aichimoaie", :department "Mathematics & Informatics", :institution "University POLITEHNICA of Bucharest", :country "Romania", :sessions (202)}, 59087 {:firstname "Raúl", :lastname "de Celis", :department "European Institute For Aviation Training And Accreditation", :institution "Universidad Rey Juan Carlos", :country "Spain", :sessions (45)}, 59091 {:firstname "Adrián", :lastname "Barea", :department "Teoría de la Señal y Comunicaciones y Sistemas Telemáticos y Computación", :institution "Universidad Rey Juan Carlos", :country "Spain", :sessions (45)}, 59253 {:firstname "Marco", :lastname "Trost", :department "", :institution "Technische Universität Dresden", :country "Germany", :sessions (189)}, 59301 {:firstname "Christoph", :lastname "Heitz", :department "Institute for Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (36)}, 59302 {:firstname "Roman", :lastname "Etschmann", :department "", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (36)}, 59303 {:firstname "Thomas", :lastname "Bachmann", :department "", :institution "die Mobiliar", :country "Switzerland", :sessions (36)}, 59306 {:firstname "Raoul", :lastname "Stoeckle", :department "", :institution "smide KmG", :country "Switzerland", :sessions (36)}, 59376 {:firstname "Fabian", :lastname "Scheller", :department "", :institution "Institute for Infrastructure and Resources Management (IIRM), University Leipzig", :country "Germany", :sessions (8)}, 59377 {:firstname "Michelle D.", :lastname "Haurand", :department "Department of Business Administration and Economics", :institution "Bielefeld University", :country "Germany", :sessions (241)}, 59456 {:firstname "Sören", :lastname "Merting", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (67)}, 59459 {:firstname "Masahiro", :lastname "Sasabe", :department "", :institution "Nara Institute of Science and Technology", :country "Japan", :sessions (184)}, 59460 {:firstname "Shoji", :lastname "Kasahara", :department "", :institution "Nara Institute of Science and Technology", :country "Japan", :sessions (184)}, 59471 {:firstname "Marko", :lastname "Loparic", :department "", :institution "Engie Lab", :country "Belgium", :sessions (48)}, 59498 {:firstname "Andreas", :lastname "Bärmann", :department "", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (80)}, 59516 {:firstname "Sarah", :lastname "Vanheusden", :department "", :institution "Uhasselt", :country "Belgium", :sessions (191)}, 59568 {:firstname "Jyotsna", :lastname "Budideti", :department "Applied Mathematics", :institution "Ecole Polytechnique", :country "France", :sessions (230)}, 59571 {:firstname "Armin", :lastname "Klausnitzer", :department "Faculty of Business and Economics", :institution "TU Dresden", :country "Germany", :sessions (187)}, 59576 {:firstname "Aykut", :lastname "Uzunoglu", :department "", :institution "Chair of Production & Supply Chain Management, Augsburg University", :country "Germany", :sessions (67)}, 59578 {:firstname "Man Shun Andersen", :lastname "Ang", :department "Mathematics and Operational Research", :institution "UMONS", :country "Belgium", :sessions (182)}, 59580 {:firstname "Henrik", :lastname "Imhof", :department "Yield Management and Pricing", :institution "Sixt", :country "Germany", :sessions (236)}, 59584 {:firstname "Robin", :lastname "Schuchmann", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (48)}, 59586 {:firstname "Nils", :lastname "Baumgaertner", :department "Institute for Technical Thermodynamics", :institution "RWTH-Aachen University", :country "Germany", :sessions (24)}, 59590 {:firstname "David", :lastname "Müller", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (161)}, 59597 {:firstname "Marie-Sklaerder", :lastname "Vié", :department "", :institution "Geneva University", :country "Switzerland", :sessions (186)}, 59598 {:firstname "Quentin", :lastname "Delmée", :department "Informatique", :institution "Université de Nantes", :country "France", :sessions (177)}, 59599 {:firstname "Christoph", :lastname "Hertrich", :department "Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (159 87)}, 59602 {:firstname "Alexander", :lastname "Kuckelberg", :department "", :institution "VIA Consulting & Development GmbH", :country "Germany", :sessions (33)}, 59605 {:firstname "Jakob", :lastname "Heins", :department "", :institution "Chair of Health Care Operations / Health Information Management, University of Augsburg", :country "Germany", :sessions (171)}, 59606 {:firstname "Tobias", :lastname "Lieberum", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (19)}, 59607 {:firstname "Lizhi", :lastname "Wang", :department "Grenoble INP - Génie Industriel", :institution "Laboratory G-SCOP", :country "France", :sessions (214)}, 59617 {:firstname "Jean-Hubert", :lastname "Hours", :department "", :institution "Artelys", :country "France", :sessions (24)}, 59618 {:firstname "Sylvain", :lastname "Mouret", :department "", :institution "Artelys", :country "France", :sessions (24)}, 59619 {:firstname "Figen", :lastname "Oztoprak Topkaya", :department "", :institution "Artelys", :country "France", :sessions (24)}, 59620 {:firstname "Richard", :lastname "Waltz", :department "", :institution "Artelys", :country "France", :sessions (24)}, 59625 {:firstname "Denis", :lastname "Olschok", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (152)}, 59629 {:firstname "Bobby", :lastname "Cottam", :department "Industrial Engineering", :institution "University of Arkansas", :country "United States", :sessions (32)}, 59635 {:firstname "Nikita", :lastname "Kozodoi", :department "School of Business and Economics", :institution "Humboldt University of Berlin", :country "Germany", :sessions (201)}, 59636 {:firstname "Nadine", :lastname "Gaertner", :department "", :institution "SAP SE", :country "Germany", :sessions (212)}, 59646 {:firstname "Johanna", :lastname "Burtscheidt", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (208)}, 59647 {:firstname "Takumi", :lastname "Kitamura", :department "Graduate School of Creative and Engineering", :institution "Waseda University", :country "Japan", :sessions (157)}, 59650 {:firstname "Tim", :lastname "Müller", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (25)}, 59651 {:firstname "Marja", :lastname "Ahola", :department "Chair of Paper Technology and Mechanical Process Engineering", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (25)}, 59652 {:firstname "Tobias", :lastname "Kretz", :department "", :institution "PTV Planung Transport Verkehr AG", :country "Germany", :sessions (44)}, 59653 {:firstname "Arne", :lastname "Heinold", :department "School of Economics and Business", :institution "Kiel University", :country "Germany", :sessions (155)}, 59655 {:firstname "Yingshuai", :lastname "Zhao", :department "WiSo Faculty", :institution "University of Cologne", :country "Germany", :sessions (20)}, 59657 {:firstname "Simon", :lastname "Hohberger", :department "Chair of Service Operations Management", :institution "University of Mannheim", :country "Germany", :sessions (179)}, 59658 {:firstname "Charlie", :lastname "Liebscher", :department "Resource Management", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (193)}, 59660 {:firstname "Samuel", :lastname "Schabel", :department "Chair of Paper Technology and Mechanical Process Engineering", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (25)}, 59661 {:firstname "Benedikt", :lastname "Finnah", :department "", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (209)}, 59662 {:firstname "Erik", :lastname "Mühmer", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (66)}, 59663 {:firstname "Paul", :lastname "Sutterer", :department "", :institution "Technical University Munich (TUM)", :country "Germany", :sessions (67)}, 59664 {:firstname "Chris", :lastname "Stetter", :department "Information Systems Institute", :institution "Leibniz University Hannover", :country "Germany", :sessions (196)}, 59666 {:firstname "Stefan", :lastname "Voigt", :department "Department of Supply Chain Management & Operations", :institution "Catholic University of Eichstätt-Ingolstadt", :country "Germany", :sessions (168)}, 59669 {:firstname "Thorsten", :lastname "Claus", :department "IHI Zittau", :institution "TU Dresden", :country "Germany", :sessions (189)}, 59671 {:firstname "Matthes", :lastname "Koch", :department "Institut für Verkehrswirtschaft", :institution "Universität Hamburg", :country "Germany", :sessions (214)}, 59672 {:firstname "Hendrik", :lastname "Schmitz", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (216)}, 59674 {:firstname "Thomas", :lastname "Hildebrandt", :department "Institut für Betriebswirtschaftslehre", :institution "Martin-Luther-Universität Halle-Wittenberg", :country "Germany", :sessions (152)}, 59677 {:firstname "Luca", :lastname "Schäfer", :department "Mathematik", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (177)}, 59678 {:firstname "Fabian", :lastname "Gnegel", :department "Mathematics", :institution "BTU Cottbus-Senftenberg", :country "Germany", :sessions (26)}, 59681 {:firstname "Wolf", :lastname "Wenger", :department "", :institution "DHBW Stuttgart", :country "Germany", :sessions (46)}, 59682 {:firstname "Nicolas", :lastname "Fröhlich", :department "Mathematik", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (177)}, 59684 {:firstname "Tiphaine", :lastname "Rougerie", :department "", :institution "LocalSolver", :country "France", :sessions (46)}, 59685 {:firstname "Sohrab", :lastname "Faramarzi Oghani", :department "", :institution "Inria Lille-Nord Europe", :country "France", :sessions (174)}, 59686 {:firstname "Jana", :lastname "Plitt", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (188)}, 59687 {:firstname "Eric", :lastname "Varlet", :department "", :institution "Beckman Coulter, Normand-Info", :country "France", :sessions (174)}, 59689 {:firstname "Marvin", :lastname "Meck", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (26)}, 59690 {:firstname "Tobias", :lastname "Dietz", :department "", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (2 177)}, 59691 {:firstname "Gordon", :lastname "Briest", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (195)}, 59692 {:firstname "Michael", :lastname "Wurm", :department "Deutsches Fernerkundungsdatenzentrum - Georisiken und zivile Sicherheit", :institution "Deutsches Zentrum für Luft- und Raumfahrt e.V.", :country "Germany", :sessions (26)}, 59693 {:firstname "Hannes", :lastname "Taubenböck", :department "Deutsches Fernerkundungsdatenzentrum - Georisiken und zivile Sicherheit", :institution "Deutsches Zentrum für Luft- und Raumfahrt e.V.", :country "Germany", :sessions (26)}, 59696 {:firstname "Peter", :lastname "Hieber", :department "", :institution "University of Ulm", :country "Germany", :sessions (181)}, 59698 {:firstname "Donatien", :lastname "Hainaut", :department "", :institution "Université Catholique de Louvain", :country "Belgium", :sessions (195)}, 59699 {:firstname "An", :lastname "Chen", :department "", :institution "University of Ulm", :country "Germany", :sessions (181)}, 59700 {:firstname "Thai", :lastname "Nguyen", :department "", :institution "University of Ulm", :country "Germany", :sessions (181)}, 59701 {:firstname "Danja R.", :lastname "Sonntag", :department "Business School", :institution "University of Mannheim", :country "Germany", :sessions (184)}, 59702 {:firstname "Di", :lastname "Liu", :department "School of Transportation and Logistics; Leuven Mobility Research Center", :institution "Southwest Jiaotong University; KU Leuven", :country "China", :sessions (33)}, 59707 {:firstname "Bastian", :lastname "Bruns", :department "", :institution "Ruhr-Universität Bochum", :country "Germany", :sessions (190)}, 59708 {:firstname "Erika", :lastname "Picarelli", :department "visiting student at the University of Luxembourg", :institution "University of Roma Tre", :country "Italy", :sessions (33)}, 59709 {:firstname "Gilles", :lastname "Merckx", :department "", :institution "University of Namur", :country "Belgium", :sessions (40)}, 59710 {:firstname "Guansheng", :lastname "Peng", :department "", :institution "CIB", :country "Belgium", :sessions (26)}, 59711 {:firstname "Hans", :lastname "Ziegler", :department "School of Business, Economics and Information Systems", :institution "University of Passau", :country "Germany", :sessions (161)}, 59712 {:firstname "Vassilissa", :lastname "Lehoux", :department "Machine Learning And Optimization", :institution "NAVER LABS Europe", :country "France", :sessions (214)}, 59713 {:firstname "Marie-Laure", :lastname "Espinouse", :department "", :institution "Université Grenoble Alpes, G-SCOP Laboratory", :country "France", :sessions (214)}, 59714 {:firstname "Johanna", :lastname "Schneider", :department "Optimization", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (2 62)}, 59717 {:firstname "Verena", :lastname "Neisen", :department "Institut of Automatic Control", :institution "RWTH Aachen University", :country "Germany", :sessions (8)}, 59718 {:firstname "Michael", :lastname "Breuß", :department "", :institution "Brandenburg Technical University", :country "Germany", :sessions (83)}, 59719 {:firstname "Franziska", :lastname "Eberle", :department "FB 3: Mathematics / Computer Science", :institution "University of Bremen", :country "Germany", :sessions (220)}, 59720 {:firstname "Georg", :lastname "Radow", :department "Chair for Applied Mathematics", :institution "Brandenburg University of Technology", :country "Germany", :sessions (83)}, 59721 {:firstname "Michael", :lastname "Helmling", :department "Optimization", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (2 159)}, 59722 {:firstname "Sebastian", :lastname "Pokutta", :department "", :institution "Georgia Institute of Technology", :country "United States", :sessions (80)}, 59723 {:firstname "Neil", :lastname "Jami", :department "", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (2)}, 59724 {:firstname "Martin", :lastname "Bähr", :department "Chair for Applied Mathematics", :institution "Brandenburg University of Technology", :country "Germany", :sessions (83)}, 59725 {:firstname "Dimitri", :lastname "Watel", :department "", :institution "ENSIIE / SAMOVAR TSP", :country "France", :sessions (38)}, 59726 {:firstname "Balthasar", :lastname "Burgenmeister", :department "", :institution "IWB Industrielle Werke Basel", :country "Switzerland", :sessions (8)}, 59727 {:firstname "Sarah", :lastname "Frisch", :department "Mathematik", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (52)}, 59729 {:firstname "Johannes", :lastname "Buhl", :department "Maschinenbau, Elektro- und Energiesysteme", :institution "Lehrstuhl Konstruktion und Fertigung", :country "Germany", :sessions (83)}, 59730 {:firstname "Stefan", :lastname "Schaudt", :department "Institute of Transport Logistics", :institution "TU Dortmund University", :country "Germany", :sessions (152)}, 59732 {:firstname "Klaus", :lastname "Frick", :department "Institut für Computational Engineering", :institution "Interstaatliche Hochschule für Technik Buchs", :country "Switzerland", :sessions (205)}, 59733 {:firstname "Martin", :lastname "Frohn", :department "", :institution "CORE, Université Catholique de Louvain", :country "Belgium", :sessions (221)}, 59736 {:firstname "Florian Joseph", :lastname "Baader", :department "IRT", :institution "RWTH Aachen University", :country "Germany", :sessions (8)}, 59737 {:firstname "Hélène", :lastname "Frankowska", :department "UPMC", :institution "Univ Paris 06", :country "France", :sessions (182)}, 59738 {:firstname "Philipp", :lastname "Armbrust", :department "Mathematics", :institution "Alpen-Adria-Universität", :country "Austria", :sessions (87)}, 59739 {:firstname "Mohamed", :lastname "Benbouziane", :department "Faculty of Management and Business.", :institution "University of Tlemcen", :country "Algeria", :sessions (176)}, 59740 {:firstname "Adnan", :lastname "Sljoka", :department "Informatics", :institution "Kwansei Gakuin University", :country "Japan", :sessions (229)}, 59741 {:firstname "Richard", :lastname "Littmann", :department "Informatics", :institution "Technical University of Munich", :country "Germany", :sessions (67)}, 59744 {:firstname "Florian", :lastname "Diehlmann", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (226)}, 59745 {:firstname "Fabian", :lastname "Wilschewski", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (221)}, 59749 {:firstname "Mohamed Saâd", :lastname "El Harrab", :department "", :institution "Mines ParisTech", :country "France", :sessions (228)}, 59751 {:firstname "Tobias", :lastname "Lechner", :department "Technische Wissenschaften", :institution "Alpen-Adria Universität Klagenfurt", :country "Austria", :sessions (52)}, 59752 {:firstname "Peter", :lastname "Rescher", :department "Technische Wissenschaft", :institution "Alpen-Adria Universität", :country "Austria", :sessions (52)}, 59753 {:firstname "Jessica", :lastname "Hautz", :department "Technische Wissenschaften", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (52)}, 59754 {:firstname "Youcef", :lastname "Amarouche", :department "Heudiasyc UMR CNRS 7253", :institution "Université de Technologie de Compiègne (UTC)", :country "France", :sessions (166)}, 59755 {:firstname "Lovis", :lastname "Anderson", :department "", :institution "Zuse Institute Berlin", :country "Germany", :sessions (221 206)}, 59756 {:firstname "Stefan", :lastname "Poikonen", :department "", :institution "CU Denver", :country "United States", :sessions (152)}, 59757 {:firstname "Erik", :lastname "Diessel", :department "Department of Optimization", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (159)}, 59758 {:firstname "Manuel", :lastname "Lackenbucher", :department "", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (87)}, 59760 {:firstname "Man Kwun", :lastname "Chiu", :department "", :institution "National Institute of Informatics", :country "Japan", :sessions (229)}, 59761 {:firstname "Nicolas", :lastname "Haubner", :department "", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (201)}, 59762 {:firstname "Volker", :lastname "Seiler", :department "International Business School Suzhou (IBSS(", :institution "Xi'an Jiaotong-Liverpool University", :country "China", :sessions (198)}, 59763 {:firstname "Juliane", :lastname "Proelss", :department "John Molson School of Business", :institution "Concordia University", :country "Canada", :sessions (198)}, 59764 {:firstname "Denis", :lastname "Schweizer", :department "John Molson School of Business", :institution "Concordia University", :country "Canada", :sessions (198)}, 59765 {:firstname "Lisa", :lastname "Knoblinger", :department "", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (87)}, 59766 {:firstname "Stefan", :lastname "Jessenitschnig", :department "", :institution "AAU-Klagenfurt", :country "Austria", :sessions (87)}, 59768 {:firstname "Roy", :lastname "Lindelauf", :department "Intelligence & Security", :institution "Netherlands Defense Academy", :country "Netherlands", :sessions (156)}, 59770 {:firstname "Stefan", :lastname "Wahl", :department "Chair of Production & Supply Chain Management", :institution "Augsburg University", :country "Germany", :sessions (162)}, 59771 {:firstname "Christian", :lastname "Weiß", :department "Department of Optimization", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (159)}, 59772 {:firstname "Tabea", :lastname "Krabs", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen", :country "Germany", :sessions (173)}, 59773 {:firstname "Özlem", :lastname "Karadeniz Alver", :department "Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (169)}, 59774 {:firstname "Ni", :lastname "Fang", :department "Supply Chain Management - Strategy and Innovation", :institution "University of Cologne", :country "Germany", :sessions (20)}, 59775 {:firstname "Sabrina", :lastname "Schmitz", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (62)}, 59777 {:firstname "Nicholas", :lastname "Molyneaux", :department "", :institution "EPFL", :country "Switzerland", :sessions (44)}, 59778 {:firstname "Tobias", :lastname "Witt", :department "Chair of Production and Logistics", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (175)}, 59779 {:firstname "Erik", :lastname "Pohl", :department "", :institution "Chair of Production and Logistics", :country "Germany", :sessions (192)}, 59780 {:firstname "Hendrik", :lastname "Schaap", :department "Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (153)}, 59781 {:firstname "Junichi", :lastname "Teruyama", :department "", :institution "University of Hyogo", :country "Japan", :sessions (229)}, 59782 {:firstname "Riccardo", :lastname "Scarinci", :department "Route Cantonale", :institution "EPFL", :country "Switzerland", :sessions (44)}, 59783 {:firstname "Robert", :lastname "Luce", :department "", :institution "Gurobi", :country "Germany", :sessions (48)}, 59787 {:firstname "Maximilian", :lastname "Hartl", :department "", :institution "Universität Stuttgart", :country "Germany", :sessions (210)}, 59788 {:firstname "Ozlem", :lastname "Akarcay", :department "", :institution "Selcuk university", :country "Turkey", :sessions (176)}, 59790 {:firstname "Martin", :lastname "Friedemann", :department "", :institution "omb420.solutions GmbH", :country "Germany", :sessions (180)}, 59792 {:firstname "Elina", :lastname "Avila", :department "", :institution "KU Leuven", :country "Belgium", :sessions (30)}, 59793 {:firstname "Chris M.J.", :lastname "Tampère ", :department "", :institution "KU Leuven", :country "Belgium", :sessions (30)}, 59794 {:firstname "Pablo", :lastname "Vanegas", :department "", :institution "Universidad de Cuenca", :country "Ecuador", :sessions (30)}, 59795 {:firstname "Chantal", :lastname "Ganschinietz", :department "Chair of Production & Supply Chain Management", :institution "University of Augsburg", :country "Germany", :sessions (193)}, 59797 {:firstname "Erkan", :lastname "Yönder", :department "", :institution "Özyeğin University", :country "Turkey", :sessions (201)}, 59799 {:firstname "Karuna", :lastname "Singh", :department "", :institution "Central Railways", :country "India", :sessions (210)}, 59800 {:firstname "Felix", :lastname "Hommelsheim", :department "Fakultät für Mathematik", :institution "TU Dortmund University", :country "Germany", :sessions (54)}, 59801 {:firstname "Efthymios", :lastname "Pournaras", :department "Economics", :institution "University of Athens", :country "Greece", :sessions (197)}, 59802 {:firstname "Styliani", :lastname "Tychalaki", :department "Electrical and Computer Engineering", :institution "Aristotle University of Thessaloniki", :country "Greece", :sessions (197)}, 59803 {:firstname "Jens", :lastname "Hujer", :department "Business and Transport Management", :institution "Heilbronn University of Applied Sciences", :country "Germany", :sessions (180)}, 59804 {:firstname "Alamdar", :lastname "Khan", :department "Hailey college of Commerce", :institution "University of the Punjab, Lahore, Pakistan", :country "Pakistan", :sessions (174)}, 59805 {:firstname "Johanna", :lastname "Rollwage", :department "Institut für Logistik und SCM", :institution "Universität Hamburg", :country "Germany", :sessions (191)}, 59806 {:firstname "Thomas", :lastname "Pschybilla", :department "Central Department Digital Transformation", :institution "TRUMPF GmbH & Co. KG", :country "Germany", :sessions (46)}, 59807 {:firstname "Sander", :lastname "van Cranenburgh", :department "Transport and Logistics", :institution "TU Delft", :country "Netherlands", :sessions (32)}, 59808 {:firstname "Sandy", :lastname "Heydrich", :department "Department of Optimization", :institution "Fraunhofer Institute for Industrial Mathematics ITWM", :country "Germany", :sessions (159)}, 59809 {:firstname "Caspar G.", :lastname "Chorus", :department "Transport and Logistics", :institution "TU Delft", :country "Netherlands", :sessions (32)}, 59811 {:firstname "Daniel", :lastname "Baumann", :department "", :institution "TRUMPF GmbH & Co. KG", :country "Germany", :sessions (46)}, 59812 {:firstname "Dirk", :lastname "Wagner", :department "", :institution "TRUMPF GmbH & Co. KG", :country "Germany", :sessions (46)}, 59813 {:firstname "Stephan", :lastname "Manz", :department "Product Management", :institution "TRUMPF Laser- und Systemtechnik GmbH", :country "Germany", :sessions (46)}, 59814 {:firstname "Thomas", :lastname "Bauernhansl", :department "", :institution "Institut für Industrielle Fertigung und Fabrikbetrieb (IFF)", :country "Germany", :sessions (46)}, 59815 {:firstname "Anders N.", :lastname "Andersen", :department "", :institution "EMD International A/S", :country "Denmark", :sessions (7)}, 59816 {:firstname "Martin", :lastname "Starnberger", :department "", :institution "N-SIDE", :country "Belgium", :sessions (46)}, 59817 {:firstname "Pascal", :lastname "Richter", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (194)}, 59818 {:firstname "Hanyi", :lastname "Li", :department "", :institution "Hanning ZN Tech Co., Ltd (Beijing)", :country "China", :sessions (164)}, 59821 {:firstname "Philipp", :lastname "Melchiors", :department "", :institution "private", :country "Germany", :sessions (157)}, 59823 {:firstname "Johan", :lastname "Philips", :department "", :institution "KU Leuven", :country "Belgium", :sessions (186)}, 59824 {:firstname "Jan Jaap", :lastname "Kempenaar", :department "", :institution "Moba B.V., ", :country "Netherlands", :sessions (186)}, 59826 {:firstname "Stefan", :lastname "Seer", :department "Center for Mobility Systems", :institution "AIT Austrian Institute of Technology", :country "Austria", :sessions (44)}, 59827 {:firstname "Christian", :lastname "Kogler", :department "Center for Mobility Systems", :institution "AIT Austrian Institute of Technology", :country "Austria", :sessions (44)}, 59828 {:firstname "Thomas", :lastname "Matyus", :department "Center for Mobility Systems", :institution "AIT Austrian Institute of Technology", :country "Austria", :sessions (44)}, 59830 {:firstname "Helmut", :lastname "Schrom-Feiertag", :department "Center for Mobility Systems", :institution "AIT Austrian Institute of Technology", :country "Austria", :sessions (44)}, 59832 {:firstname "Matthias", :lastname "Templ", :department "Institute for Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (36)}, 59833 {:firstname "Rym", :lastname "Guibadj", :department "", :institution "Université du Littoral Côte d'Opale", :country "France", :sessions (166)}, 59834 {:firstname "Willy", :lastname "Hesselbach", :department "Wood Biology and Wood Products", :institution "University of Goettingen", :country "Germany", :sessions (218)}, 59835 {:firstname "Konstantinos", :lastname "Papakonstantinou", :department "", :institution "Kreditech Holding SSL", :country "Germany", :sessions (201)}, 59836 {:firstname "Steffen", :lastname "Netzband", :department "", :institution "University of Augsburg", :country "Germany", :sessions (171)}, 59838 {:firstname "Barbara", :lastname "Glensk", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (9)}, 59840 {:firstname "Radu", :lastname "Baltean-Lugojan", :department "", :institution "Imperial College London", :country "United Kingdom", :sessions (49)}, 59841 {:firstname "Timo", :lastname "Kannengiesser", :department "Institute of Electrochemical Process Engineering (IEK-3)", :institution "Forschungszentrum Juelich GmbH", :country "Germany", :sessions (8)}, 59842 {:firstname "Sebastian", :lastname "Müller", :department "Business School", :institution "University of Mannheim", :country "Germany", :sessions (202)}, 59843 {:firstname "Jakob", :lastname "Huber", :department "", :institution "University of Mannheim", :country "Germany", :sessions (202)}, 59844 {:firstname "Heiner", :lastname "Stuckenschmidt", :department "", :institution "University of Mannheim", :country "Germany", :sessions (202)}, 59850 {:firstname "Dennis", :lastname "Proksch", :department "Fakultät für Wirtschafts- und Organisationswissenschaften", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (179)}, 59852 {:firstname "Raimond", :lastname "Wüst", :department "School of Engineering", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (211)}, 59853 {:firstname "Dieter", :lastname "Claeys", :department "Industrial Systems Engineering and Product Design", :institution "Ghent University", :country "Belgium", :sessions (175 242)}, 59857 {:firstname "Stijn", :lastname "De Vuyst", :department "Industrial Systems Engineering and Product Design", :institution "Ghent University", :country "Belgium", :sessions (242)}, 59866 {:firstname "Oussama", :lastname "Mazari Abdessameud", :department "MWMW", :institution "Royal Military Academy", :country "Belgium", :sessions (200)}, 59867 {:firstname "Sebastian", :lastname "Steininger", :department "", :institution "Alpen-Adria-Universtität Klagenfurt", :country "Austria", :sessions (155)}, 59872 {:firstname "Sebastian", :lastname "Rojas Gonzalez", :department "Decision Sciences and Information Management", :institution "KU Leuven", :country "Belgium", :sessions (71)}, 59874 {:firstname "Stefan", :lastname "Neubert", :department "Algorithm Engineering", :institution "Hasso Plattner Institute, University of Potsdam", :country "Germany", :sessions (145)}, 59876 {:firstname "Severin", :lastname "Ess", :department "School of Engineering", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (211)}, 59878 {:firstname "Willem", :lastname "Brauers", :department "Economics", :institution "University of Antwerp", :country "Belgium", :sessions (85)}, 59879 {:firstname "Stefano", :lastname "Bortolomiol", :department "Transport and Mobility Laboratory", :institution "EPFL", :country "Switzerland", :sessions (216)}, 59880 {:firstname "Claudio", :lastname "Gomez", :department "School of Engineering", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (211)}, 59882 {:firstname "Alberto", :lastname "Franzin", :department "", :institution "IRIDIA, Université Libre de Bruxelles (ULB)", :country "Belgium", :sessions (203)}, 59888 {:firstname "Javier", :lastname "Bas Vicente", :department "", :institution "University of Maryland", :country "United States", :sessions (37)}, 59890 {:firstname "Grzegorz", :lastname "Zalewski", :department "Institute of Control & Computation Engineering", :institution "Warsaw University of Technology", :country "Poland", :sessions (85)}, 59892 {:firstname "Pieterjan", :lastname "Dendauw", :department "Industrial Systems Engineering and Product Design", :institution "Ghent University", :country "Belgium", :sessions (175)}, 59893 {:firstname "Federico", :lastname "Pagnozzi", :department "IRIDIA", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (203)}, 59894 {:firstname "Yuan", :lastname "Yuan", :department "", :institution "INOCS, INRIA", :country "France", :sessions (151)}, 59896 {:firstname "Wenjuan", :lastname "Gu", :department "", :institution "Centrale Lille, Inria, UMR 9189 - CRIStAL", :country "France", :sessions (153)}, 59897 {:firstname "Christian", :lastname "Peitz", :department "Economics", :institution "Paderborn University", :country "Germany", :sessions (197)}, 59898 {:firstname "Nico", :lastname "Stöckmann", :department "Economics", :institution "Paderborn University", :country "Germany", :sessions (197)}, 59899 {:firstname "Alexander", :lastname "Golderbein", :department "Economics", :institution "Universität Paderborn", :country "Germany", :sessions (197)}, 59900 {:firstname "David", :lastname "Brueck", :department "Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (188)}, 59901 {:firstname "Alexander", :lastname "Sieber", :department "Department of Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (229)}, 59902 {:firstname "Peter", :lastname "Stenzel", :department "IEK-3", :institution "Forschungszentrum Juelich GmbH", :country "Germany", :sessions (8)}, 59903 {:firstname "Peter", :lastname "Markewitz", :department "IEK-3", :institution "Forschungszentrum Juelich GmbH", :country "Germany", :sessions (8)}, 59904 {:firstname "Martin", :lastname "Robinius", :department "Institute of Electrochemical Process Engineering (IEK-3)", :institution "Forschungszentrum Juelich GmbH", :country "Germany", :sessions (8)}, 59905 {:firstname "Detlef", :lastname "Stolten", :department "Institute of Electrochemical Process Engineering (IEK-3)", :institution "Forschungszentrum Juelich GmbH", :country "Germany", :sessions (8)}, 59908 {:firstname "Shuai", :lastname "Shao", :department "Department of Statistics", :institution "LMU Munich", :country "Germany", :sessions (89)}, 59910 {:firstname "Pieter", :lastname "Kleer", :department "", :institution "CWI Amsterdam", :country "Netherlands", :sessions (145)}, 59913 {:firstname "Marc", :lastname "Schröder", :department "Chair of Management Science", :institution "RWTH Aachen University", :country "Germany", :sessions (147 149)}, 59914 {:firstname "Philipp", :lastname "Warode", :department "Wirtschaftswissenschaftliche Fakultät", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (149)}, 59916 {:firstname "Ágnes", :lastname "Cseh", :department "", :institution "Hungarian Academy of Sciences", :country "Hungary", :sessions (145)}, 59918 {:firstname "Marco", :lastname "Bender", :department "", :institution "INFORM GmbH", :country "Germany", :sessions (158)}, 59919 {:firstname "Louise", :lastname "Molitor ", :department "", :institution "Hasso Plattner Institute", :country "Germany", :sessions (91)}, 59920 {:firstname "Sebastian", :lastname "Spindler", :department "", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (180)}, 59922 {:firstname "Soeren", :lastname "Hohmann", :department "Institute of Control Systems (IRS)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (7)}, 59923 {:firstname "Ela", :lastname "Binici", :department "", :institution "Ataturk University Ata Technocity", :country "Turkey", :sessions (175)}, 59927 {:firstname "Jörg", :lastname "Herbers", :department "", :institution "INFORM GmbH", :country "Germany", :sessions (158)}, 59929 {:firstname "Steffen", :lastname "Hoffmann", :department "Chair of Operations Research", :institution "FernUniversität in Hagen (University of Hagen)", :country "Germany", :sessions (45)}, 59931 {:firstname "Oliver", :lastname "Schaudt", :department "Mathematics", :institution "RWTH Aachen University", :country "Germany", :sessions (147 54)}, 59934 {:firstname "Leslie", :lastname "Perez Cáceres", :department "scuela de Ingeniería Informática", :institution "Pontificia Universidad Católica de Valparaíso", :country "Chile", :sessions (203)}, 59936 {:firstname "Marin", :lastname "Lujak", :department "Department of Informatics and Control Systems", :institution "IMT Lille Douai", :country "France", :sessions (170)}, 59938 {:firstname "Davi", :lastname "Pereira dos Santos", :department "", :institution "INESC TEC", :country "Portugal", :sessions (209)}, 59939 {:firstname "Riccardo", :lastname "Colini-Baldeschi", :department "", :institution "Facebook", :country "United Kingdom", :sessions (149)}, 59940 {:firstname "Holger", :lastname "Billhardt", :department "", :institution "University Rey Juan Carlos", :country "Spain", :sessions (170)}, 59942 {:firstname "Christian", :lastname "Jost", :department "Operations Management", :institution "Technical University of Munich", :country "Germany", :sessions (205)}, 59945 {:firstname "Wei", :lastname "Zhang", :department "", :institution "KTH Royal Institute of Technology", :country "Sweden", :sessions (30)}, 59946 {:firstname "Waldemar", :lastname "Laube", :department "", :institution "aixigo AG", :country "Germany", :sessions (173)}, 59947 {:firstname "Yan", :lastname "Liu", :department "Civil and Environmental Engineering", :institution "University of Maryland, College Park", :country "United States", :sessions (37)}, 59948 {:firstname "Fatih", :lastname "Sonmez", :department "", :institution "Turkcell", :country "Turkey", :sessions (175)}, 59949 {:firstname "Menno", :lastname "Yap", :department "Transport & Planning", :institution "TU Delft", :country "Netherlands", :sessions (30)}, 59956 {:firstname "Gerald", :lastname "Blumberg", :department "Chair for Management Science and Energy Economics", :institution "House of Energy Markets and Finance", :country "Germany", :sessions (7)}, 59957 {:firstname "François", :lastname "Delbot", :department "", :institution "Université Paris Nanterre / LIP6", :country "France", :sessions (38)}, 59958 {:firstname "Erik", :lastname "Jenelius", :department "", :institution "KTH Royal Institute of Technology", :country "Sweden", :sessions (30)}, 59959 {:firstname "Hugo", :lastname "Badia", :department "", :institution "KTH Royal Institute of Technology", :country "Sweden", :sessions (30)}, 59966 {:firstname "Benoit", :lastname "Duvocelle", :department "Maastricht University", :institution "Quantitative Economics", :country "Netherlands", :sessions (223)}, 60136 {:firstname "Bastian", :lastname "Sander", :department "", :institution "Fraunhofer Institute for Factory Operation and Automation IFF", :country "Germany", :sessions (84)}, 60168 {:firstname "Berk", :lastname "Görgülü", :department "", :institution "Bogazici University", :country "Turkey", :sessions (205)}, 60247 {:firstname "Gabriel", :lastname "Gouvine", :department "", :institution "LocalSolver", :country "France", :sessions (49)}, 60321 {:firstname "Tounes", :lastname "Sellami", :department "Centre des Systèmes et Réseaux d'Information et de Communication, de Télé-enseignement et de l'Enseignement à Distance (CSRICTED)", :institution "UNIVERSITE de Bejaia", :country "Algeria", :sessions (174)}, 60383 {:firstname "Magdalena", :lastname "Lippenberger", :department "", :institution "Technische Universität München", :country "Germany", :sessions (227)}, 60454 {:firstname "Melanie", :lastname "Schaller", :department "Digital Business Synergy", :institution "University of Würzburg", :country "Germany", :sessions (200)}, 60537 {:firstname "Michael", :lastname "Elberfeld", :department "", :institution "INFORM GmbH", :country "Germany", :sessions (158)}, 60636 {:firstname "Dominic Manuel", :lastname "Weinberger", :department "", :institution "AAU Klagenfurt", :country "Austria", :sessions (52)}, 62522 {:firstname "Guglielmo", :lastname "Lulli", :department "Department of Management Science", :institution "University of Lancaster", :country "United Kingdom", :sessions (45)}}}