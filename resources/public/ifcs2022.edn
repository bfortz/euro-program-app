{:timeslots {7 {:schedule "Wednesday 14:30-16:00", :day "W", :time "E", :sessions [25 26]}, 20 {:schedule "Saturday 9.00-10.30", :day "S", :time "A", :sessions [74 75]}, 1 {:schedule "Tuesday, 9.30-11:00 and 11.30-13:00", :day "T", :time "A", :sessions [1]}, 4 {:schedule "Wednesday 9.30-10.30", :day "W", :time "B", :sessions [4]}, 15 {:schedule "Friday 12.00-13.00", :day "F", :time "C", :sessions [52 53 54 55 56 57 58 59 60 61]}, 21 {:schedule "Saturday 11.00-12.00", :day "S", :time "B", :sessions [76 77 78 79 80 81 82 83 84]}, 13 {:schedule "Friday 9.00-10.30", :day "F", :time "A", :sessions [49 50]}, 22 {:schedule "Saturday 12.00-13.00", :day "S", :time "C", :sessions [86]}, 6 {:schedule "Wednesday 12:00-13:00", :day "W", :time "D", :sessions [15 16 17 18 19 20 21 22 23 24]}, 17 {:schedule "Friday 15.30-16.00", :day "F", :time "E", :sessions [63]}, 3 {:schedule "Wednesday 9.00-9.30", :day "W", :time "A", :sessions [3]}, 12 {:schedule "Thursday 14.30-15.30", :day "H", :time "D", :sessions [48]}, 2 {:schedule "Tuesday, 14.30-16:00 and 16.30-18:00", :day "T", :time "B", :sessions [2]}, 23 {:schedule "Saturday 13.00-13.30", :day "S", :time "D", :sessions [87]}, 19 {:schedule "Friday 18.00-19.30", :day "F", :time "G", :sessions [73]}, 11 {:schedule "Thursday 11.00-13.00", :day "H", :time "C", :sessions [47]}, 9 {:schedule "Thursday 9.00-10.00", :day "H", :time "A", :sessions [36 37 38 39 40 41 42 43 44 45]}, 5 {:schedule "Wednesday 11.00-12:00", :day "W", :time "C", :sessions [5 6 7 8 9 10 11 12 13 14]}, 14 {:schedule "Friday 11.00-12.00", :day "F", :time "B", :sessions [51]}, 16 {:schedule "Friday 14.30-15.30", :day "F", :time "D", :sessions [62]}, 10 {:schedule "Thursday 10.00-10.30", :day "H", :time "B", :sessions [46]}, 18 {:schedule "Friday 16.30-18.00", :day "F", :time "F", :sessions [64 65 66 67 68 69 70 71 72]}, 8 {:schedule "Wednesday 16:30-18:00", :day "W", :time "F", :sessions [27 28 29 30 31 32 33 34 35]}}, :streams {"SEM" {:name "Statistics and Econometric Methods", :sessions [18]}, "SC" {:name "Supervised Classification", :sessions [17 78]}, "BIP" {:name "50 Years of Biplots", :sessions [8 39 55]}, 1 {:name "Tutorials", :sessions [1 2]}, "S-ML" {:name "Supervised Machine Learning", :sessions [13]}, "SNA" {:name "Social Network Analysis", :sessions [7 66]}, "ML" {:name "Machine Learning", :sessions [14 24 45 84]}, 4 {:name "Posters", :sessions [46 63]}, "DS-SS" {:name "Data Science in Social Sciences", :sessions [23 44]}, "DS-B" {:name "Data Science in Biology", :sessions [82]}, "DS-BM" {:name "Data Science for Business and Marketing", :sessions [64]}, "TS" {:name "Time Series", :sessions [29]}, "TM" {:name "Text Mining", :sessions [35]}, "OCC" {:name "Optimization in Classification and Clustering", :sessions [38 56 80]}, "DS-HS" {:name "Data Science in Health Sciences", :sessions [31]}, "CoDA" {:name "Compositional Data Analysis", :sessions [33 42]}, "MBC" {:name "Model-based Clustering", :sessions [12 22 34 43 59 71]}, "SDA" {:name "Symbolic Data Analysis", :sessions [5 15 36 52]}, "MBC-TS" {:name "Model-based Clustering for Time Series", :sessions [79]}, "SPE" {:name "SPE", :sessions [61]}, 3 {:name "Semi-Plenaries", :sessions [25 26 49 50 74 75]}, "STDA" {:name "Spatial-Temporal Data Analysis", :sessions [60 83]}, 2 {:name "Plenaries", :sessions [3 4 47 48 51 62 86 87]}, "FDA" {:name "Functional Data Analysis", :sessions [6 16 28 37 53 65 77]}, "DR+Cl" {:name "Dimension Reduction & Clustering", :sessions [76]}, "DS-E" {:name "Data Science in Education", :sessions [67]}, 5 {:name "Meetings", :sessions [73]}, "CL" {:name "Clustering", :sessions [10 20 32 41 57 69]}, "SLDM" {:name "Statistical Learning and Data Mining", :sessions [9 19 68]}, "TSC" {:name "Time Series Classification", :sessions [72]}, "DR" {:name "Dimension Reduction", :sessions [27]}, "DS-EF" {:name "Data Science in Economics and Finance", :sessions [40 81]}, "IML" {:name "Interpretable Machine Learning", :sessions [54]}, "SCT" {:name "Supervised Classification - Trees", :sessions [30]}, "RM" {:name "Robust Methods", :sessions [11 21 58 70]}}, :sessions {1 {:name "Analysis of Data Streams", :stream 1, :chairs [], :timeslot 1, :papers [282], :track 1}, 2 {:name "Categorical Data Analysis and Visualization", :stream 1, :chairs [], :timeslot 2, :papers [283], :track 1}, 3 {:name "Opening Session", :stream 2, :chairs [], :timeslot 3, :papers [], :track 1}, 4 {:name "Keynote Dianne Cook", :stream 2, :chairs [], :timeslot 4, :papers [256], :track 1}, 5 {:name "Symbolic Data Analysis 1", :stream "SDA", :chairs [], :timeslot 5, :papers [157 187 275], :track 1}, 6 {:name "Functional Data Analysis 1", :stream "FDA", :chairs [], :timeslot 5, :papers [47 85 235], :track 2}, 7 {:name "Social Network Analysis 1", :stream "SNA", :chairs [], :timeslot 5, :papers [13 38 195], :track 3}, 8 {:name "50 Years of Biplots 1", :stream "BIP", :chairs [], :timeslot 5, :papers [75 158 240], :track 4}, 9 {:name "Statistical Learning and Data Mining 1", :stream "SLDM", :chairs [], :timeslot 5, :papers [99 105 144], :track 5}, 10 {:name "Clustering 1", :stream "CL", :chairs [], :timeslot 5, :papers [50 160 237], :track 6}, 11 {:name "Robust Methods 1", :stream "RM", :chairs [], :timeslot 5, :papers [138 148 232], :track 7}, 12 {:name "Model-based Clustering 1", :stream "MBC", :chairs [], :timeslot 5, :papers [6 18 76], :track 8}, 13 {:name "Supervised Machine Learning 1", :stream "S-ML", :chairs [], :timeslot 5, :papers [4 98 216], :track 9}, 14 {:name "Machine Learning 1", :stream "ML", :chairs [], :timeslot 5, :papers [129 154 173], :track 10}, 15 {:name "Symbolic Data Analysis 2", :stream "SDA", :chairs [], :timeslot 6, :papers [56 59 86], :track 1}, 16 {:name "Functional Data Analysis 2", :stream "FDA", :chairs [], :timeslot 6, :papers [84 135 226], :track 2}, 17 {:name "Supervised Classification 1", :stream "SC", :chairs [], :timeslot 6, :papers [126 205 230], :track 3}, 18 {:name "Statistics and Econometric Methods", :stream "SEM", :chairs [], :timeslot 6, :papers [61 97 141], :track 4}, 19 {:name "Statistical Learning and Data Mining 2", :stream "SLDM", :chairs [], :timeslot 6, :papers [27 131 133], :track 5}, 20 {:name "Clustering 2", :stream "CL", :chairs [], :timeslot 6, :papers [10 25 184], :track 6}, 21 {:name "Robust Methods 2", :stream "RM", :chairs [], :timeslot 6, :papers [90 114 132], :track 7}, 22 {:name "Model-based Clustering 2", :stream "MBC", :chairs [], :timeslot 6, :papers [24 55 79], :track 8}, 23 {:name "Data Science in Social Sciences 1", :stream "DS-SS", :chairs [], :timeslot 6, :papers [33 91 153], :track 9}, 24 {:name "Machine Learning 2", :stream "ML", :chairs [], :timeslot 6, :papers [11 172 189], :track 10}, 25 {:name "Classification of Time Series", :stream 3, :chairs [], :timeslot 7, :papers [81 149 167], :track 1}, 26 {:name "Benchmarking Challenge", :stream 3, :chairs [], :timeslot 7, :papers [264 265 268 273], :track 2}, 27 {:name "Dimension Reduction", :stream "DR", :chairs [], :timeslot 8, :papers [71 102 214 219], :track 1}, 28 {:name "Functional Data Analysis 3", :stream "FDA", :chairs [], :timeslot 8, :papers [21 47 152 177], :track 2}, 29 {:name "Time Series", :stream "TS", :chairs [], :timeslot 8, :papers [7 109 164 258], :track 3}, 30 {:name "Supervised Classification - Trees", :stream "SCT", :chairs [], :timeslot 8, :papers [82 210 239 242], :track 4}, 31 {:name "Data Science in Health Sciences", :stream "DS-HS", :chairs [], :timeslot 8, :papers [31 125 254 255], :track 5}, 32 {:name "Clustering 3", :stream "CL", :chairs [], :timeslot 8, :papers [34 37 41], :track 6}, 33 {:name "Compositional Data Analysis 1", :stream "CoDA", :chairs [], :timeslot 8, :papers [14 44 201], :track 7}, 34 {:name "Model-based Clustering 3", :stream "MBC", :chairs [], :timeslot 8, :papers [28 32 257], :track 8}, 35 {:name "Text Mining", :stream "TM", :chairs [], :timeslot 8, :papers [30 48 168 171], :track 9}, 36 {:name "Symbolic Data Analysis 3", :stream "SDA", :chairs [], :timeslot 9, :papers [107 119 209], :track 1}, 37 {:name "Functional Data Analysis 4", :stream "FDA", :chairs [], :timeslot 9, :papers [78 155 212], :track 2}, 38 {:name "Optimization in Classification and Clustering 1", :stream "OCC", :chairs [], :timeslot 9, :papers [77 127 231], :track 3}, 39 {:name "50 Years of Biplots 2", :stream "BIP", :chairs [], :timeslot 9, :papers [96 145 222], :track 4}, 40 {:name "Data Science in Economics and Finance 1", :stream "DS-EF", :chairs [], :timeslot 9, :papers [121 139 185], :track 5}, 41 {:name "Clustering 4", :stream "CL", :chairs [], :timeslot 9, :papers [29 192 221], :track 6}, 42 {:name "Compositional Data Analysis 2", :stream "CoDA", :chairs [], :timeslot 9, :papers [170 174], :track 7}, 43 {:name "Model-based Clustering 4", :stream "MBC", :chairs [], :timeslot 9, :papers [19 123 204], :track 8}, 44 {:name "Data Science in Social Sciences 2", :stream "DS-SS", :chairs [], :timeslot 9, :papers [49 113 180], :track 9}, 45 {:name "Machine Learning 3", :stream "ML", :chairs [], :timeslot 9, :papers [2 112 270], :track 10}, 46 {:name "Poster Session 1", :stream 4, :chairs [], :timeslot 10, :papers [], :track 1}, 47 {:name "Awards", :stream 2, :chairs [], :timeslot 11, :papers [], :track 1}, 48 {:name "Keynote Charles Bouveyron", :stream 2, :chairs [], :timeslot 12, :papers [272], :track 1}, 49 {:name "COVID Data Analysis", :stream 3, :chairs [], :timeslot 13, :papers [206 260 262], :track 1}, 50 {:name "Categorical Data Analysis and Visualization", :stream 3, :chairs [], :timeslot 13, :papers [100 117 151], :track 2}, 51 {:name "Presidential Address Angela Montanari", :stream 2, :chairs [], :timeslot 14, :papers [284], :track 1}, 52 {:name "Symbolic Data Analysis 4", :stream "SDA", :chairs [], :timeslot 15, :papers [108 147 186], :track 1}, 53 {:name "Functional Data Analysis 5", :stream "FDA", :chairs [], :timeslot 15, :papers [43 74 134], :track 2}, 54 {:name "Interpretable Machine Learning", :stream "IML", :chairs [], :timeslot 15, :papers [190 193 250], :track 3}, 55 {:name "50 Years of Biplots 3", :stream "BIP", :chairs [], :timeslot 15, :papers [83 103 251], :track 4}, 56 {:name "Optimization in Classification and Clustering 2", :stream "OCC", :chairs [], :timeslot 15, :papers [15 143 188], :track 5}, 57 {:name "Clustering 5", :stream "CL", :chairs [], :timeslot 15, :papers [64 95 225], :track 6}, 58 {:name "Robust Methods 3", :stream "RM", :chairs [], :timeslot 15, :papers [5 208 217], :track 7}, 59 {:name "Model-based Clustering 5", :stream "MBC", :chairs [], :timeslot 15, :papers [26 93 198], :track 8}, 60 {:name "Spatial-Temporal Data Analysis 1", :stream "STDA", :chairs [], :timeslot 15, :papers [122 181 267], :track 9}, 61 {:name "SPE", :stream "SPE", :chairs [], :timeslot 15, :papers [128 130 211], :track 10}, 62 {:name "Keynote Genevera Allen", :stream 2, :chairs [], :timeslot 16, :papers [271], :track 1}, 63 {:name "Poster Session 2", :stream 4, :chairs [], :timeslot 17, :papers [], :track 1}, 64 {:name "Data Science for Business and Marketing", :stream "DS-BM", :chairs [], :timeslot 18, :papers [39 51 159 163], :track 1}, 65 {:name "Functional Data Analysis 6", :stream "FDA", :chairs [], :timeslot 18, :papers [65 169 202 253 280], :track 2}, 66 {:name "Social Network Analysis 2", :stream "SNA", :chairs [], :timeslot 18, :papers [36 224 243 245], :track 3}, 67 {:name "Data Science in Education", :stream "DS-E", :chairs [], :timeslot 18, :papers [156 241 247 248], :track 4}, 68 {:name "Statistical Learning and Data Mining 3", :stream "SLDM", :chairs [], :timeslot 18, :papers [72 87 89 146], :track 5}, 69 {:name "Clustering 6", :stream "CL", :chairs [], :timeslot 18, :papers [16 17 23], :track 6}, 70 {:name "Robust Methods 4", :stream "RM", :chairs [], :timeslot 18, :papers [42 94 116 223], :track 7}, 71 {:name "Model-based Clustering 6", :stream "MBC", :chairs [], :timeslot 18, :papers [8 12 110], :track 8}, 72 {:name "Time Series Classification", :stream "TSC", :chairs [], :timeslot 18, :papers [1 22 118 227], :track 9}, 73 {:name "IFCS Council meeting", :stream 5, :chairs [], :timeslot 19, :papers [], :track 1}, 74 {:name "Dimension Reduction", :stream 3, :chairs [], :timeslot 20, :papers [200 203 220], :track 1}, 75 {:name "Explainable Machine Learning", :stream 3, :chairs [], :timeslot 20, :papers [259 274 279], :track 2}, 76 {:name "Dimension Reduction & Clustering", :stream "DR+Cl", :chairs [], :timeslot 21, :papers [63 66 166], :track 1}, 77 {:name "Functional Data Analysis 7", :stream "FDA", :chairs [], :timeslot 21, :papers [92 124 263], :track 2}, 78 {:name "Supervised Classification 2", :stream "SC", :chairs [], :timeslot 21, :papers [104 115 175], :track 3}, 79 {:name "Model-based Clustering for Time Series", :stream "MBC-TS", :chairs [], :timeslot 21, :papers [70 136 179], :track 4}, 80 {:name "Optimization in Classification and Clustering 3", :stream "OCC", :chairs [], :timeslot 21, :papers [182 199 276], :track 5}, 81 {:name "Data Science in Economics and Finance 2", :stream "DS-EF", :chairs [], :timeslot 21, :papers [35 162 197], :track 6}, 82 {:name "Data Science in Biology", :stream "DS-B", :chairs [], :timeslot 21, :papers [111 161 238], :track 7}, 83 {:name "Spatial-Temporal Data Analysis 2", :stream "STDA", :chairs [], :timeslot 21, :papers [69 120 142], :track 9}, 84 {:name "Machine Learning 4", :stream "ML", :chairs [], :timeslot 21, :papers [40 191 196], :track 10}, 86 {:name "Keynote João Gama", :stream 2, :chairs [], :timeslot 22, :papers [62], :track 1}, 87 {:name "Closing Session", :stream 2, :chairs [], :timeslot 23, :papers [], :track 1}}, :papers {275 {:id 275, :title "The Use of Regression to Partition a Dataset of Interval Observations", :authors (342 178), :abstract "The use of regression modelling has an extensive history; likewise, clustering\r\nmethodologies have existed for some time. In this work, we extend the dynamical \r\npartitioning concepts developed initially by Diday and Simon [1] combined with\r\nthe k-means clustering approach of MacQueen [3], to a k-regression algorithm to\r\nenable clustering of interval-valued observations based on regression models. The\r\nusefulness of the algorithm is verified through some simulated data (as in the plots\r\nbelow) and applied to real data sets. More details can be found in [2].\r\n\r\nReferences\r\n1. Diday, E., Simon, J. C.: Clustering analysis. In: Fu, K.S. (ed.) Digital Pattern Recognition, \r\n   pp. 47-94. Springer, Berlin (1976)\r\n2. Liu, F., Billard, L.: Partition of interval-valued observations using regression. Pattern \r\n   Recognition (2022)\r\n3. MacQueen, J.: Some methods for classification and analysis of multivariate observations. \r\n   In: LeCam, L. M., Neyman, J. (eds.) Proceedings of the 5th Berkeley Symposium on Mathematical\r\n   Statistics and Probability, University of California Press, Berkeley 1, pp. 281-299 (1967)", :session 5, :keywords (300 302 164)}, 121 {:id 121, :title "Urban Development Paths in Poland: Multidimensional Perspective", :authors (77 255), :abstract "The development of countries and regions is strongly dependent on the socioeconomic \r\nsituation characterising the largest urban centres [3]. This is caused not only by a \r\nhigher intensity of processes taking place in urban space, but also by the predominance \r\nof the population living in cities in comparison to rural areas. The increasing role of \r\nurban systems in the creation of domestic product and the accumulation of services and \r\ninnovations on their area results in a growing interest in studying the phenomenon of \r\nurbanisation and concentration of social and economic activities realised in urban \r\nspace [1]. The main objective of the study will be the construction of development paths \r\nof the largest Polish cities, which are the capitals of a given region, in 2004-2020. \r\nTo achieve it, the authors will use their own methodological proposal from the area of \r\nmultidimensional analysis. An additional aspect of the study will be a comparison of the \r\nsimilarity of the changes and levels of development of particular cities with the use of \r\nselected measures of time series similarity and cluster analysis [2]. The analyses are to \r\nanswer the following research questions: (i) what was the socio-economic development of \r\nPolish voivodship cities characterised by in the last years, (ii) has this development \r\nproceeded in a similar way for all analysed cities, and (iii) what has been the impact of \r\nthe last two crises on the dynamics and heterogeneity of development of the analysed cities?\r\n\r\nReferences\r\n1. Bogdanski M.: Socio-economic potential of Polish cities – a regional dimension, Bull. Geogr.\r\n   Socio. Econ. Ser. 17, 13-20 (2012)\r\n2. Fanni Z., Khakpour B.A., and Heydari A.: Evaluating the regional development of border\r\n   cities by TOPSIS model (case study: Sistan and Baluchistan Province, Iran). Sustain. Cities\r\n   Soc. 10, 80-86 (2014)\r\n3. Zoeteman K., Mommaas H., and Dagevos J.: Are larger cities more sustainable? Lessons from\r\n   integrated sustainability monitoring in 403 Dutch municipalities. Environ. Dev. 17, 57-72\r\n   (2016)", :session 40, :keywords (59 144 169 403 631)}, 65 {:id 65, :title "Depth-Based Two-Sample Testing", :authors (179 117 28), :abstract "Depth functions provide measures of the deepness of a point with respect to a given\r\nset of observations. This non-parametric concept can be applied in spaces of any \r\ndimension and entails a center-outward ordering for the given data. A two-sample test\r\nhas been previously proposed that is based on depth-ranks and offers opportunities\r\nfor further investigations: Observing that the corresponding test statistic LS(X, Y)\r\nis not symmetric with respect to the two samples X and Y, the power can be greatly\r\nincreased if LS(X, Y) and LS(Y, X) are jointly considered. Within the last years,\r\ndepths with respect to functional data have been established that we combine with\r\nthis procedure to obtain new non-parametric two-sample tests for functional data.\r\nWe investigate the asymptotic behaviour of this modified test procedure for several\r\nclasses of depths including depths for functional data.\r\n\r\nReferences\r\n1. Liu, R.Y., Singh, K.: A Quality Index Based on Data Depth and Multivariate Rank Tests.\r\n   Journal of the American Statistical Association. 88:421, 252–260 (1993)", :session 65, :keywords (660 142 432)}, 70 {:id 70, :title "Clustering Intensive Longitudinal Data Through Mixture Multilevel Vector-Autoregressive\r\nModeling", :authors (57 366 180 86 99), :abstract "Experience sampling methodology is increasingly used in the social sciences to\r\nanalyze individuals’ emotions, thoughts and behaviors in everyday-life. The resulting \r\nintensive longitudinal data is often analyzed with the objective to describe the \r\ninter-individual differences that are present within it. To accommodate inter-individual \r\ndifferences to a greater extent than previously possible, a mixture multilevel \r\nvector-autoregressive model is proposed. This model combines a mixture model at level 2 \r\n(individual level) with a multilevel vector-autoregressive model [1] that describes the \r\ndynamic fluctuations present at level 1 (time-point level). This exploratory model identifies \r\nmixture components of individuals who exhibit similar overall means, autoregressions, and \r\ncross-regressions. Within each mixture component, multilevel coefficients allow additionally \r\nfor within-component variation on these vector-autoregressive coefficients. The advantage of \r\nexploratory identifying mixture components and accounting for within-component variation is \r\ndemonstrated on data from the COGITO study. This data contains samples of individuals from\r\ndisparate age groups of over 100 individuals each.\r\n\r\nReferences\r\n1. Rovine, M.J., Walls, T.A.: Multilevel Autoregressive Modeling of Interindividual \r\n   Differences in the Stability of a Process. In: Walls, T.A., Schafer, J.L. (eds.) \r\n   Models for intensive longitudinal data, pp. 124–147. Oxford University Press (2006)", :session 79, :keywords (386 642 15)}, 62 {:id 62, :title "Trends in Data Stream Mining", :authors (299), :abstract "Learning from data streams is a hot topic in machine learning and data mining.\r\nWe describe our recent work on emerging issues related to learning from data\r\nstreams. We discuss two quite different problems. The first use case is an application\r\nof data stream techniques to fraud detection. We propose an algorithm for the\r\ninterconnected by-pass fraud problem. This real-world problem requires processing\r\nhigh-speed telecommunications data and providing fraud alarms in real-time. The\r\nproposed solution clearly illustrates the need for online data stream processing.\r\nHyper-parameter tunning is a popular topic in offline learning. Nevertheless, few\r\nalgorithms have been presented for the online setting. We present one of the first\r\nalgorithms for online hyper-parameter tuning for streaming data. We discuss the Self\r\nhyper-Parameter Tunning (SPT) algorithm, an optimization algorithm for online\r\nhyper-parameter tuning from non-stationary data streams. SPT works as a wrapper\r\nover any streaming algorithm and can be used for classification, regression, and\r\nrecommendation.\r\n\r\n", :session 86, :keywords (211 273 321)}, 74 {:id 74, :title "Impact Point Selection in Semiparametric Bifunctional Models", :authors (512 206 457), :abstract "Nowadays, most applied sciences have to deal with datasets containing one, or more,\r\nfunctional object. Thus, developing techniques for functional data analysis with high\r\nlevel of flexibility and interpretability has become a target in statistical research.\r\n  Accordingly, a new sparse semiparametric model is proposed, which incorporates\r\nthe influence of two functional random variables in a scalar response in a flexible and\r\ninterpretable manner. One of the functional covariates is included through a singleindex \r\nstructure, while the other is included linearly through the high-dimensional\r\nvector formed by its discretised observations. Due to the sparse nature of the linear\r\ncomponent, variable selection is needed (see [1] for a review). The problem is that\r\nstandard variable selection methods (such that the proposed in [2]) can provide inadequate \r\nresults. Then, two new algorithms are presented for selecting impact points in\r\nthe linear component and estimating the model (see [3] for details). Both procedures\r\nutilise the functional origin of linear covariates. Finite sample experiments demonstrated \r\nthe scope of application of both algorithms. Some asymptotic results support\r\nboth procedures. A real data application showed the applicability of the presented\r\nmethodology from a predictive perspective and low computational cost.\r\n\r\nReferences\r\n1. Aneiros, G., Novo, S., Vieu, P.: Variable selection in functional regression models: \r\n   A review, J. Multivariate Anal., 188, 104871, (2021)\r\n2. Novo, S., Aneiros, G., Vieu, P.: Sparse semiparametric regression when predictors are \r\n   mixture of functional and high-dimensional variables. Test, 30, 481–504 (2021)\r\n3. Novo, S., Vieu, P., Aneiros, G.: Fast and efficient algorithms for sparse semiparametric \r\n   bifunctional regression, Aust. N. Z. J. Stat., 63, 606–638 (2021)", :session 53, :keywords (216 673 561)}, 164 {:id 164, :title "Multivariate Time Series Feature Extraction via Multilayer Networks", :authors (562 362 452 182), :abstract "The extraction of features from time-indexed data has proved to be an important\r\npreliminary task in many applications of time series analysis, such as classification, \r\nclustering and forecasting. Finding a set of features that summarizes the main\r\ncharacteristics of such data is therefore a crucial task, which usually involves conventional \r\nstatistical and non-linear measures of time series analysis [1]. Complementary, features based \r\non complex network methods have been shown to be useful to characterize time series data [2, 3]. \r\nFor multivariate time series (MTS) settings, feature extraction is even less trivial due to \r\ntemporal and cross-dimension dependencies. The existing methods and models are often developed \r\nunder certain constraints and for specific problems, and therefore new methodological and \r\ncomputational tools are required. Multilayer networks are complete structures able of mapping the \r\ninternal and external temporal dependencies of MTS through intra and inter-network connections [2]. \r\nIn this work, we introduce novel MTS features based on a new multilayer visibility network mapping \r\nmethod. To demonstrate its applicability, we performed a MTS clustering task based on the proposed \r\nfeatures set.\r\n\r\nAcknowledgements The authors gratefully acknowledge support from FCT (SFRH/BD/139630/2018)\r\n                 and PREFERENTIAL (PTDC/MAT-STA/28243/2017).", :session 29, :keywords (402 641 677 203)}, 282 {:id 282, :title "Analysis of Data Streams", :authors (299), :abstract "The challenge of deriving insights from the Internet of Things (IoT) has been recognized \r\nas one of the most exciting and key opportunities for both academia and industry. Advanced \r\nanalysis of big data streams from sensors and devices is bound to become a key area of data \r\nmining research as the number of applications requiring such processing increases. Dealing \r\nwith the evolution over time of such data streams, i.e., with concepts that drift or change \r\ncompletely, is one of the core issues in IoT stream mining. This tutorial is a gentle \r\nintroduction to mining IoT big data streams.\r\n\r\nContent: IoT Fundamentals and Stream Mining Algorithms; IoT Stream mining setting; Clustering; \r\n         Classification and Regression; Concept drift and Frequent Pattern mining\r\n\r\n", :session 1, :keywords ()}, 273 {:id 273, :title "Pitfalls of Automatic Optimization Procedures and Benchmarking in Cluster Analysis", :authors (461 389), :abstract "The pitfalls and challenges of automatic approaches are outlined in the case that\r\nrelevant and possibly prior unknown relationships in high-dimensional biological\r\ndatasets are to be discovered [1]. Priorly, [2] proposed one or more unsupervised\r\nquality measures for the automatic selection of clustering algorithms and their \r\nparameter optimization. However, employing optimization procedures within automated\r\npipelines is biased and not recommended if we assume there may be only one optimal \r\npartitioning of data, e.g., diagnoses or therapies [1]. Thus, the limitations of\r\na clustering algorithm induced by a global clustering criterion cannot be overcome\r\nby optimizing the algorithm parameters which only reduces the variance but not the\r\nintrinsic bias of the criterion [1]. Furthermore, such optimization can yield \r\nsignificant improvements even if the dataset does not possess any cluster structure. \r\nFinally, our work shows that benchmarking clustering algorithms using first-order \r\nstatistics or box plots on a small number of trials leads to misleading comparisons \r\nbetween algorithms. Assuming patterns in the data which can be recognizd by experts, \r\nwe use artifical generated datasets [3]. On these datasets, 41 open-source and state\r\nof-the-art algorithms standardized within R and Python in the “FCPS” library [4]\r\nare evaluated to disprove the claim of [2] that automatic algorithm and parameter\r\nselection by unsupervised quality measures is a viable approach in cluster analysis.\r\n\r\nReferences\r\n1. Thrun, M.C. Distance-based clustering challenges for unbiased benchmarking studies. \r\n   Nature Scientific Reports 11, 18988, doi:10.1038/s41598-021-98126-1 (2021)\r\n2. Wiwie, C., Baumbach, J., Röttger, R. Comparing the performance of biomedical \r\n   clustering methods. Nature Methods 12, 1033 (2015)\r\n3. Thrun, M.C., Ultsch, A. Clustering benchmark datasets exploiting the fundamental \r\n   clustering problems. Data in Brief 30, 105501, doi:10.1016/j.dib.2020.105501 (2020)\r\n4. hrun, M.C., Stier, Q. Fundamental clustering algorithms Suite SoftwareX 13, 100642,\r\n   doi:10.1016/j.softx.2020.100642 (2021)", :session 26, :keywords (68 34 509)}, 186 {:id 186, :title "Nonparametric Regressions for Distributional Data", :authors (14 265 66), :abstract "In distributional data individuals are described by means of distributions. While \r\ndistributions are complex data representations, several methods have been successfully\r\nproposed to analyze data represented by distributional variables, giving rise to the\r\nfield distributional data analysis [1]. In particular, several authors have proposed\r\nregression methods to model some specific kinds of linear relationships that can\r\ntake place among distributional variables. However, such methods may suffer in\r\ncases where the linear relationship in the data is not the one the method can deal\r\nwith, or when the relationship in the data is not linear. In such cases, nonparametric\r\nregression methods would be able to effectively model the underlying relationship.\r\n  We propose three nonparametric regression methods for distributional data: the\r\nkernel regression and the locally weighted regression using the Dias-Brito [2] and\r\nthe Irpino-Verde [3] linear regressions for distributional data. The performance of the\r\nproposed methods and the linear approaches will be compared by means of a Monte\r\nCarlo experiment that will consider different underlying relationships in the data. In\r\naddition, we propose the use of several statistical measures and plots to analyze the\r\nregression fit and its errors to better understand how the regressions work.\r\n\r\nReferences\r\n1. Brito, P., Dias, S. (eds.): Analysis of distributional data. Chapman and Hall/CRC, \r\n   Boca Raton (2022)\r\n2. Dias, S., Brito, P.: Linear regression model with histogram-valued variables. \r\n   Stat. Anal. Data Min. 8: 75-113 (2015)\r\n3. Irpino, A., Verde, R.: Linear regression for numeric symbolic variables: a least squares\r\n   approach based on Wasserstein Distance. Adv. Data Anal. Classif. 9, 81–106 (2015).", :session 52, :keywords (158 434 325)}, 188 {:id 188, :title "Nonlinear Approaches for Multiple Instance Learning", :authors (61 377 65), :abstract "Multiple Instance Learning (MIL) is a variant of traditional supervised learning\r\nconsisting in classifying bags of instances. Differently from the traditional supervised\r\nlearning scenario, each example is not represented by a fixed-length vector of features\r\nbut by a bag of feature vectors called instances. In the training phase the classification\r\nlabels are only provided for each entire bag whereas the labels of the instances inside\r\nthem are unknown. The final task is to learn a model that predicts the labels of the\r\nnew incoming bags together with the labels of the instances inside them.\r\n  We address the MIL problem in the case of two types of instances and two\r\ntypes of bags (positive and negative) through polyhedral approaches. The idea is\r\nto generate a polyhedral separation surface such that, for each positive bag, at least\r\none of its instances is inside the polyhedron and all the instances of each negative\r\nbag are outside. We come out with two models. For solving the first one, starting\r\nfrom the MIL-SVM type model proposed in [1], we develope a technique based on\r\niteratively separating the bags by means of successive maximum-margin polyhedral\r\nsurfaces, obtained by solving successive linear programs. In the second, substituting\r\nthe separating hyperplane with a maximum-margin polyhedral surface in the SVMtype model \r\npresented in [2], we obtain a nonsmooth unconstrained optimization\r\nproblem of DC (Difference of Convex) type that we solve by adapting the DCA\r\nalgorithm. Numerical results are presented on a set of benchmark datasets.\r\n\r\nReferences\r\n1. Andrews, S.,Tsochantaridis,I., Hofmann, T.: Support vector machines for multiple-instance\r\n   learning. In: Becker, S., Thrun, S., Obermayer, K., (eds.) Advances in Neural Information\r\n   Processing Systems, pp. 561-568. MIT Press, Cambridge (2003).\r\n2. Bergeron, C., Moore, G., Zaretzki, J., Breneman, C.M., Bennett, K.P.: Fast bundle algorithm\r\n   for multiple-instance learning. IEEE Trans. Pattern Anal. Mach. Intell. 34, 1068–1079 (2012).", :session 56, :keywords (400 623 492)}, 240 {:id 240, :title "Biplots for Categorical and Ordinal Data Based on Logistic Responses", :authors (287), :abstract "A joint representation of individuals and variables in a data matrix is called a Biplot.\r\nBiplots were proposed 50 years ago in [1].\r\n  When variables are binary, nominal or ordinal, a classical linear biplot representation \r\nis not adequate. More recently, biplots for categorical data, based logistic response models, \r\nhave been proposed for binary [2], or nominal data [3]. The coordinates of individuals and \r\nvariables are computed to have logistic responses along the biplot dimensions. The methods are \r\nrelated to logistic regression in the same way as Classical Biplots are related to linear \r\nregression, thus are referred as Logistic Biplots. In the same way as Linear Biplots are related \r\nto Principal Components Analysis, Logistic Biplots are related to Latent Trait Analysis or Item \r\nResponse Theory. The geometry of those kinds of biplots for binary, nominal or ordinal data is \r\nstudied.\r\n  For binary data we obtain straight lines as representations of the variables.\r\n  For nominal data the representation of the variables on the biplot is not a straight\r\nline but a “prediction region” and for ordinal data a straight line is obtained if the\r\n“proportional odds” model is used.\r\n  Algorithms for the construction on the biplots based on gradient descent methods\r\nare also provided.\r\n  The applicability and interpretation of the logistic biplots is illustrated with several\r\nreal data applications.\r\n\r\nReferences\r\n1. Gabriel, K. R. : The biplot graphic display of matrices with application to principal component\r\n   analysis. Biometrika, 58 (3), 453-467. (1971).\r\n2. Vicente-Villardon, J.L., Galindo, M.P., Blazquez-Zaballos, A.: Logistic biplots. In: Greenacre,\r\n   M., Blasius, J. (eds.) Multiple Correspondence Analysis and related methods, pp. 503-521.\r\n   Chapman and Hall, New York (2006)\r\n3. Hernandez-Sanchez, J. C., Vicente-Villardon, J. L. (2017). Logistic biplot for nominal data.\r\n   Advances in Data Analysis and Classification, 11 (2) 307-326.", :session 8, :keywords (40 49 326)}, 110 {:id 110, :title "Modeling Three-Way RNA Sequencing Data Using Data Transformations and Matrix-Variate\r\nGaussian Mixture Models", :authors (540 87), :abstract "RNA sequencing of time-course experiments leads to three-way count data where\r\nthe dimensions are the genes, the time points and the biological units. Clustering\r\nof RNA-seq data allows to detect groups of co-expressed genes over time. After\r\nstandardization, the counts of individual genes across time points and biological\r\nunits constitute compositional data. Rau and Maugis [1] propose an approach for\r\nanalyzing two-way RNA-seq data where they only have genes and time points as\r\ndimensions or the biological units are flattened out. For two-way data, they investigate\r\nthe use of data transformations in conjunction with Gaussian mixture models. In this\r\nwork we want to extend their approach to three-way data and investigate suitable\r\ndata transformations for three-way data before clustering the data using matrixvariate \r\nGaussian mixture models. Finite mixtures of matrix-variate distributions are\r\nimplemented in the R package MatTransMix [2]. Using a matrix-variate Gaussian\r\nmixture model already represents a more parsimonious model formulation than\r\nusing a Gaussian mixture model after flattening out the biological units. Additional\r\nparsimonity may be gained by assuming that different sets of parameters are identical\r\nacross clusters, thus allowing also for an easier interpretation of the fitted model.\r\nThe proposed three-way clustering approach will be applied to RNA-seq data from\r\nE. coli bioproduction processes and also compared to the two-way approach after\r\nflattening out the biological units.\r\n\r\nReferences\r\n1. Rau, A., Maugis-Rabusseau, C.: Transformation and model choice for RNA-seq co-expression\r\n  analysis. Brief. Bioinformatics 19, 425–436 (2018)\r\n2. Zhu, X., Sarkar, S., Melnykov, V.: MatTransMix: an R Package for Matrix Model-Based\r\n   Clustering and Parsimonious Mixture Modeling. J Classif 39, 147–170 (2022)", :session 71, :keywords (386 638 538)}, 130 {:id 130, :title "Outlier Detection: a Procedure to Capture Atypical Groups of Observations", :authors (36 563), :abstract "In thiswork, we introduce the concept of atypical group of observations and propose a\r\nprocedure for its identification. By atypical group, we mean a cluster of observations\r\nwhose ‘mean’ pattern stands out from the majority of the ‘mean’ patterns of the\r\nremaining clusters. Challenges that arise in atypical group detection are firstly to\r\nidentify a meaningful segmentation of the data, and secondly to flag the atypical\r\nsegments. Our work focus on data whose elements are discrete distributions.\r\nIf heterogeneous datasets, where distinct patterns coexist, can validly be clustered,\r\nthen the class prototypes provide a simplified description of data. Thus, the key idea\r\nof our proposal is to combine a clustering method with a functional outlyingness\r\ncriterion to capture atypical class prototypes.\r\nTo identify a segmentation of the distributional data we iteratively combine two\r\nsteps. The first creates a hierarchy of clusters, while the second flags atypical curves\r\nwithin each cluster, based on a measure of functional outlyingness which accounts for\r\nthe shape of the distributions [1]. Segments with atypical curves, are forwarded for\r\n(sub)clustering, and the procedure is repeated until no outlying curves are identified\r\nin clusters. Once the final partition is obtained, each cluster is represented by a\r\nclass prototype, whose outlyingness is evaluated according to the same functional\r\napproach. Clusters with an atypical class prototype are pointed as atypical.\r\nWe apply our procedure to investigate clusters of genomic words in human DNA\r\nby studying their inter-word lag distributions. These experiments demonstrate the\r\npotential of the new method for identifying clusters of words with outlying patterns.\r\n\r\nReferences\r\n1. Rousseeuw, P. J., Raymaekers, J., Hubert, M.: A measure of directional outlyingness \r\n   with applications to image data and video. J Comput Graph Stat. 27:2, 345-359 (2018)", :session 61, :keywords (456 75 158 215)}, 128 {:id 128, :title "Identification of Driver Genes in Glioblastoma via Regularized Classification", :authors (371 533), :abstract "Tumor heterogeneity is a major driver of tumor progression and treatment failure.\r\nIn the particular case of glioblastoma (GBM), the most common and aggressive\r\nprimary brain malignancy, intratumoral molecular heterogeneity translates into different\r\ntumor cell clones in a single patient, with different selective advantages, which\r\nmakes available therapy options ineffective. The identification of tumor molecular\r\nchanges at the cell level is a key to understanding tumor heterogeneity and providing\r\ninsights into the development of novel targeted therapies. With the rise of\r\nomics technologies, it is now possible to extract from a single cell a huge amount\r\nof information related to the cell functioning (e.g., genomics, transcriptomics, proteomics).\r\nHowever, these data came at the cost of high dimensionality (the number\r\nof features greatly outnumbering the number of observations), which requires appropriate\r\nstatistical and machine learning tools to extract relevant information from\r\nthese complex molecular networks. In this work, a strategy based on regularized\r\nlogistic regression with network information is applied to single-cell RNA sequencing\r\n(RNA-seq) data from GBM patients for classifying cells into distinct neoplastic\r\ncell groups and normal cells, while selecting the features discriminating between the\r\nclasses as putative GBM therapy targets. The relevance of the extracted features is\r\nsupported by literature reports on their established role in GBM, their significance\r\nin the survival outcomes in bulk GBM RNA-Seq data, and their association with\r\nseveral Gene Ontology biological process terms.\r\n\r\n", :session 61, :keywords (242 652 530 259 422)}, 259 {:id 259, :title "Classification Over Text, Relational Databases and Graphs - Software and Case Studies", :authors (546), :abstract "Best performing methods often produce models that are hard to interpret, leading\r\nto the so-called accuracy-interpretability trade-off. Also, each data type typically\r\nrequires a different type of model, such as BERT transformers for text or node\r\nembeddings for graphs. In projects involving multiple modalities, this leads to a mix\r\nof opaque models, an interpretability and interoperability Babylon.\r\n  This talk will cover rule-based methods as a possible “white-box” Swiss knife applicable \r\nto multiple data types, including tabular data, text and even large knowledge\r\ngraphs with millions of edges and nodes.\r\n  Given the advances in model-agnostic explanation algorithms, do rule models\r\nstill have an edge in interpretability over the more opaque classification workhorses\r\nsuch as random forests? The talk will hint at answers through use cases worked on\r\nat DIKE, such as comparing rule-based explanations with LIME and Shapley plots\r\nin the context text-mining of research articles on COVID-19 [1]. We will also cover\r\ntools such as the arc R package for rule-based classification of tabular data [2], the\r\nAction rule mining system [3], the cloud-based EasyMiner rule classifier and editor\r\n[4], and the RDFRules rule learner for knowledge graphs [5].\r\n\r\nAcknowledgements Presented research was partly supported by support of the CIMPLE project\r\n                 (CHIST-ERA-19-XAI-003) and VSE IGA 40/2021.", :session 75, :keywords (308 551 195)}, 210 {:id 210, :title "ExactTree: an R-Package for Globally Optimal Decision Trees", :authors (145 250 254 493 76), :abstract "Decision trees, such as Classification and Regression Trees (CART) are grown\r\nusing binary recursive partioning. The goal is to predict a categorical outcome\r\n(classification) or a continuous outcome (regression) as good as possible using\r\nbinary splits on predictor variables. Because our goal is to preserve interpretability,\r\nwe focus in this paper on single trees. The tree algorithm starts with all objects in the\r\nroot node and subsequently searches for the predictor variable and split point that\r\nleads to the maximum decrease in impurity (e.g., residual sum of squares); then the\r\nroot node is split into two child nodes. This process is repeated at each node until a\r\nfull tree is grown. A downside of this recursive procedure is the risk of arriving at a\r\nlocal minimum. Therefore, several attempts have been made to grow globally optimal\r\ntrees, among which evolutionary trees [1], based on a meta-heuristic algorithm, and\r\nthe method ExactTree [2, 3], that optimizes the entire tree structure globally using\r\ndynamic programming. We performed a benchmark study comparing both methods\r\non predictive accuracy and stability. Results on part of the data sets showed similar\r\npredictive accuracies, but higher stability for ExactTree. In our presentation, we show\r\nthe final results and demonstrate the R-package ExactTree for you.\r\n\r\nReferences\r\n1. Grubinger, T., Zeileis, A., Pfeiffer, K-P: evtree: Evolutionary learning of globally optimal\r\n   classification and regression trees in R. J. Stat. Softw. 61, 1–29 (2014)\r\n2. Os, B.J.: Dynamic Programming in Multivariate Data Analysis. Leiden University (2000)\r\n3. Meulman, J.J., Dusseldorp, E., Os, B.J.: An exact dynamic programming algorithm for regression \r\n   trees. In: Van der Heĳden, M., Koren, B., Van der Mei, R.D., Van Vonderen, J.A.J. (eds.) \r\n   Jan Karel Lenstra, the Traveling Science Man: Liber Amicorum, pp. 198–208. CWI, Amsterdam (2011).", :session 30, :keywords (134 290 63 528 244)}, 153 {:id 153, :title "Visualization of IATA Regions in Air Transport Before and After the COVID-19 Pandemic", :authors (552 414 74 428), :abstract "COVID-19 Pandemic has affected all transport modules including air passenger\r\ntransportation (ATP) as an unprecedented global crisis. This study aims to visualize\r\nthe position of International Air Transport Association (IATA) Regions considering\r\nsome important key indicators such as gross domestic product, human development index, \r\ntourism arrival, national and international ATP numbers [1]. Also, this study deals with \r\nrevealing out the negative impact of this global crisis on ATP during COVID-19 Pandemic \r\nbetween 2019-2021. In this study, to analyze ATP, three common airline metrics were gathered \r\nto figure out significant factors that lead to similarities between regions in terms of global \r\ncrisis’s negative impact for each year. Factor analysis (FA) and multidimensional scaling (MDS) \r\nwere applied to IATA dataset [2]. MDS has brought out some substantial inferences. For instance, \r\nEurope, North and Latin America have similarities in positively, whereas Africa, Asia Pacific\r\nand Middle East show these similarities negatively since they are located close to each other. \r\nThe location of regions has changed due to COVID-19 Pandemic compared to 2019 in MDS. \r\nThus, ATP recovery is better in the Middle East compared to Africa and the Asia Pacific; however, \r\nthis recovery circulation seems far from being adequate when compared to others. To sum up, these \r\nfindings may help aviators to manage the strategic perspective of ATP more professionally.\r\n\r\nReferences\r\n1. Scholl, W., Schermuly, C.C.: The impact of culture on corruption, gross domestic product,\r\n   and human development. Journal of Business Ethics 163(1), 171–189 (2020)\r\n2. Nyoja, E.T., Ragab, M.R.: Economic Impacts of Public Air Transport Investment: A Case\r\n   Study of Egypt. Sustainability 14(5), 2651 (2022)", :session 23, :keywords (118 9 613)}, 7 {:id 7, :title "Oracle-LSTM: a Neural Network Approach to Mixed Frequency Time Series Prediction", :authors (17 434), :abstract "In the context of macro-economic indicators there are two main concerns regarding\r\nthe frequency of the variables. The first is related to MIxed DAta Sampling (MIDAS),\r\ni.e. some indicators are reported annually, some quarterly, other monthly. The second\r\ndeals with the need of forecasting predictions between reporting dates, e.g. before\r\nthe end of the year, and it is known as ”nowcasting”. Existing methods rely on\r\nthe alignment of high-frequency input data to low-frequency target variable by the\r\nmeans of lagged variables and their temporal-decaying weighting. We develop a twosteps \r\nalgorithm that makes use of two Recurrent Neural Networks. The first, called Oracle, \r\nis a Deep Autoregressive network and predicts the target variable at highfrequency \r\ngiven past information. The second, called Predictor, is Long-Short Term Memory (LSTM) \r\nnetwork and learns the relationship between Oracle’s predictions and high-frequency \r\ninput  data. The prediction error is a weighted average of two terms: one compares the \r\nobserved low-frequency target with predictions of both Oracle and Predictor, the other \r\ncompares the Predictor’s high-frequency predictions with the Oracle’s ones. Our model \r\nis tested on both simulated data, where we know the generated high-frequency data, and \r\nreal macro-economic data. Our results show better performances compared to classical \r\napproach. Moreover, we apply gradientbased interpretability methods to estimate the \r\ninput features’ importance in the predictions.\r\n\r\n", :session 29, :keywords (367 19 331 436)}, 59 {:id 59, :title "Symbolic t-SNE and UMAP Methods for Interval Type Variables.", :authors (423), :abstract "UMAP (Uniform Manifold Approximation and Projection) is a very new method\r\nfor dimension reduction. UMAP method improve t-SNE (t-Distributed Stochastic\r\nNeighbor Embedding) method for data visualization and dimensionality reduction.\r\nThe great advantage of UMAP is that it preserves better than t-SNE the global\r\nstructure with superior run time performance. The foregoing makes UMAP an ideal\r\nmethod to be applied to the hyper-rectangles that are in the rows of the symbolic data\r\ntable with interval-type variables, since UMAP compresses the structure inside each\r\nhyper-rectangle very well and at the same time better preserves the global structure\r\nof the clusters generated by each hyper-rectangle. This paper presents an adapted\r\nversion of the t-SNE and UMAP methods for interval type variables. In addition, R\r\nand Python codes for both generalizations are presented.\r\n\r\nReferences\r\n1. Arce, J. and Rodríguez, O. (2019). Optimized dimensionality reduction methods for\r\n   interval-valued variables and their application to facial recognition. Entropy 2019\r\n   https://doi.org/10.3390/e21101016\r\n2. Billard, L. and Diday, E. (2006). Symbolic Data Analysis: Conceptual Statistics and Data\r\n   Mining (United Kingdom: John Wiley & Sons Ltd)\r\n3. Cazes, P., Chouakria, A., Diday, E., and Schektman, Y. (1997). Extension de l’analyse en\r\n   composantes principales à des données de type intervalle. Statistique Appliquée XLV 3, 5–24\r\n4. Douzal-Chouakria, A., Billard, L., Diday, E., and Schektman, Y. (2011). Principal component\r\n   analysis for interval-valued observations. Statistical Analysis and Data Mining XLV 4, \r\n   229–246. 10.1002/sam\r\n5. Laurens Van der Maaten, L. and Hinton, G. (2008) Visualizing Data using t-SNE. Journal of \r\n   Machine Learning Research, 9,86,2579-2605, http://jmlr.org/papers/v9/vandermaaten08a.html\r\n6. McInnes, L., Healy, J., and Melville, J. (2018). UMAP: Uniform Manifold Approximation and \r\n   Projection for Dimension Reduction. cite arxiv:1802.03426Comment: Reference implementation \r\n   available at http://github.com/lmcinnes/umap 6, 352–357. http://arxiv.org/abs/1802.03426\r\n7. Rodríguez, O. (2007). Correspondence analysis for symbolic multi-valued variables. Carme\r\n   2007, Rotterdam, The Netherlands. http://www.carme-n.org/carme2007/.\r\n8. Rodriguez, O. (2021). RSDA: R to Symbolic Data Analysis. R package version 3.0.9", :session 15, :keywords (626 630 663 294)}, 86 {:id 86, :title "Two-Stage Principal Component Analysis on Interval-Valued Data Using Patterned\r\nCovariance Structure", :authors (70), :abstract "A new approach is developed for facial recognition using principal component\r\nanalysis of interval-valued data. We exploit patterned covariance structures in doing\r\nso and we accomplish this in two stages: first, we get eigenblocks and eigenmatrices\r\nof the patterned variance-covariance matrix, and then we analyze these eigenblocks\r\nand the corresponding principal vectors together in some appropriate way to get the\r\nprincipal components of the interval-valued data. We apply our method to the face\r\nrecognition data in [1]. We take care of the three sequences of each face by using\r\nstructured covariance matrices and answer the question whether three sequences\r\nbelong to the same face or not. Face sequence recognition or classification is an\r\nimportant problem as face might slightly change due to several reasons. Results\r\nillustrating the accuracy and appropriateness of the new method over the existing\r\nmethods are presented.\r\n\r\nReferences\r\n1. Douzal-Chouakria, A., Billard, L. and Diday E.: Principal component analysis for \r\n   intervalvalued observations. Stat. Anal. Data Min.: The ASA Data Science Journal, \r\n   4(2), 229-246 (2011)", :session 15, :keywords (295 472 172 499)}, 154 {:id 154, :title "Comparison of Pixel Based Segmentation Methods in Papillary Thyroid US Images", :authors (414 592 144 428), :abstract "Thyroid nodules are one of the endocrine diseases caused by abnormal growth of\r\ncells. Ultrasonography (US) is an efficient tool that is routinely used to identify these\r\nnodules. Thyroid nodule segmentation on US images is a valuable and, it has a great\r\nimportance for the diagnosis of thyroid cancer. Despite US imaging is considered as\r\nthe best option, the high incidence rate increases the burden of radiologists in terms\r\nof diagnosing the thyroid cancer cases at early stages and their levels [1]. In such a\r\ncase, the contour and region-based segmentation methods have a potential to extract\r\nsome important features called as biomarkers which allow radiologists to make more\r\naccurate diagnosis. In this context, this study aims to compare the contour and regionbased \r\nsegmentation methods with respect to the feature extraction performance. In\r\nthis study, US images of 187 papillary carcinoma patients were analyzed. The image\r\nsegmentation quality was evaluated with respect to dice coefficient measurement and\r\nROC analysis results such as TN, FP, AUC, g-score, f-measure [2]. Also, the validity\r\nof the pixel-based methods were achieved with the extracted features obtained from\r\nthe manual segmentation methods performed by expert radiologists. The analysis\r\nresults showed that the automatic segmentation methods are superior performance\r\nto the manual ones according to the various statistical performance criteria.\r\n\r\nReferences\r\n1. Chen, J., You, H., Li, K. : A review of thyroid gland segmentation and thyroid nodule\r\n   segmentation methods for medical ultrasound images. Computer methods and programs in\r\n   biomedicine. 185, 105329 (2020)\r\n2. Koundal, D., Gupta, S., Singh, S. : Computer aided thyroid nodule detection system using\r\n   medical ultrasound images. CBiomedical Signal Processing and Control. 40, 117-130 (2018)", :session 14, :keywords (639 483 463)}, 224 {:id 224, :title "Exploratory Graph Analysis for Configural Invariance Assessment of a Test", :authors (21 321 501 415), :abstract "Self-report survey instruments are frequently used to investigate differences between\r\ngroups of respondents, such as citizens of different nations in cross-country comparative \r\nanalyses. In this context, a main methodological problem pertain to the configural invariance \r\nof the measurement instrument, which holds if the latent structure has the same pattern across \r\ndifferent groups across the groups. In this work, to address this issue, we adopt an exploratory \r\napproach rooted in the framework of graph theory. Specifically, considering a multi-group comparative \r\nanalysis and measurement instruments consisting of ordered categorical indicators, we discuss the\r\nuse of exploratory graph analysis to assess the instrument configural invariance. In\r\nthis framework, networks are used to represent latent constructs, and the covariance\r\nbetween observable indicators is explained in terms of a pattern of causal interactions\r\nbetween the items. Hence, we assume that if the measurement instrument functions\r\ninvariantly across the groups, the group specific correlation-based networks will be\r\ncharacterised by a similar structure. The network structures are estimated through a\r\nBayesian approach with sparse inducing priors and network embedding will be used\r\nto investigate the structure similarity. Through a simulation study we demonstrate\r\nthat the proposed method is able to identify the differences. Finally, the proposed\r\napproach is applied to test the configural invariance of the Democracy Scale adopted\r\nin the European Social Survey.\r\n\r\n", :session 66, :keywords (507 33 150)}, 72 {:id 72, :title "Kernel-based hierarchical structural component models for pathway analysis", :authors (529 530 507 228 243 536), :abstract "Pathway analyses have led to more insight into the underlying biological functions\r\nrelated to the phenotype of interest in various types of omics data. Pathway-based\r\nstatistical approaches have been actively developed, but most of them do not consider \r\ncorrelations among pathways. Because it is well known that there are quite\r\na few biomarkers that overlap between pathways, these approaches may provide\r\nmisleading results. In addition, most pathway-based approaches tend to assume that\r\nbiomarkers within a pathway have linear associations with the phenotype of interest,\r\neven though the relationships are more complex.\r\n  To model complex effects including nonlinear effects, we propose a new approach,\r\nHierarchical structural CoMponent analysis using Kernel (HisCoM-Kernel). The\r\nproposed method models nonlinear associations between biomarkers and phenotype\r\nby extending the kernel machine regression and analyzes entire pathways simultaneously \r\nby using the biomarker-pathway hierarchical structure. HisCoM-Kernel is a\r\nflexible model that can be applied to various omics data. It was successfully applied\r\nto three omics datasets generated by different technologies. Our simulation studies\r\nshowed that HisCoM-Kernel provided higher statistical power than other existing\r\npathway-based methods in all datasets. The application of HisCoM-Kernel to three\r\ntypes of omics dataset showed its superior performance compared to existing methods \r\nin identifying more biologically meaningful pathways, including those reported\r\nin previous studies.\r\n\r\n", :session 68, :keywords (257 303 442 471)}, 205 {:id 205, :title "Analysis of Gini Splitting Criterion and Comparison with Maximum Likelihood Rule", :authors (31 104), :abstract "A commonly used criterion in decision trees is the Gini index. Considering random\r\nvariables from two populations, with priors p_1 and p_2, the expected value of the\r\nGini function is given by the asymptotic result: (F_1(x) − F_2(x))^2 /{F(x) (1−F(x))},\r\nwhere class i has distribution function F_i(x) and F(x) = p_1 F_1(x) + p_2 F_2 (x) [1]. \r\nIn this population setting, x would be chosen to maximize this. This result is obtained\r\nby taking the conditional expectation of the weighted Gini expression: \\sum_i N^2_Li / N_L \r\n+ N^2_Ri / N_R, in which the random variables N_L1 denote the number in class 1 to the left \r\nof a split, etc. In contrast, the maximum likelihood (ML) classifier allocates according\r\nto arg max (p_1 f_1(x), p_2 f_2(x)), where f_i(x) is the density of the i-th population.\r\n  We consider the case of two normal populations, where (without loss of generality)\r\nf_1(x) is the standard normal distribution, and f_2(x) is normal with mean \\mu > 0 and\r\nvariance \\sigma^2, to find cases in which the two splitting rules are the same, or differ.\r\nWhen p_1 = p_2 = 1/2 and \\sigma = 1 both rules will split at x = \\mu/2.\r\n  When \\sigma = 1, then ML gives a split at \\mu/2 + \\mu^{−1} log(p_1/p_2), whereas an \r\napproximate solution for the Gini split, obtained by taking the derivative of the log\r\nof the above expected value, then taking a Taylor series expansion around x = \\mu/2\r\nand equating to zero, is: \\mu/2 + 2P^2 \\sqrt{2 \\pi} (p_2 - p_1) / { 4P exp(-\\mu^2/8 -\r\n\\mu \\sqrt{2 \\pi} }, where P = 2 \\Phi(\\mu/2) − 1 and \\Phi(·) is the CDF of the standard \r\nnormal distribution. When p_1 ≠ p_2, differences may be large, particularly as \\mu gets \r\ncloser to 0. In this case when \\sigma = 1, the Gini split is always in the interval (0, \\mu). \r\nWhen p_1 ≠ p_2 we have not been able to obtain an approximation to the Gini solution for \r\ngeneral \\sigma. However, in some examples, it can be seen that the MLE split and Gini split \r\nare generally closer together and there are cases in which neither split is in the \r\ninterval (0, \\mu).\r\n\r\nReferences\r\n1. Alharthi, A.S.: Weighted Classification Tree-based Ensemble Methods. PhD thesis, University\r\n   of Leeds, U.K. (2020)", :session 17, :keywords (63 241 346)}, 175 {:id 175, :title "Exploiting Pareto Density Estimation for Nonparametric Naïve Bayes Classifiers", :authors (461 389), :abstract "In parametric Naïve Bayes classifiers, a variety of class conditional distributions\r\nare defined if prior knowledge about the structures in data is given. Otherwise,\r\nlikelihood estimation is performed via kernel density estimation in non-parametric\r\nNaïve Bayes classifiers. However, our previous work showed that Pareto density\r\nestimation (PDE) [1] outperforms other density estimation methods available in R\r\nand Python, because conventional methods pose several problems when estimating\r\ndistributions that have clipped data or are uniform, multimodal or skewed [1]. In\r\ncontrast, PDE is particularly suitable for discovering structures in continuous data\r\nand allows for the discovery of mixtures of Gaussians [3]. This work proposes a\r\nnon-parametric Naïve Bayes classifier called PDEbayes that estimates the likelihood\r\nper class via PDE. It is compared with a non-parametric Naïve Bayes classifier\r\navailable on CRAN called naivebayes on a range of artificial datasets of the FCPS\r\n(N = 1000 samples) [2]. Moreover, a real-world dataset is used which consists of\r\npatients with either a positive B-Non-Hodgkin lymphoma (B-NHL) or a negative\r\nB-NHL diagnosis for which no prior knowledge about the distributions is available.\r\nPDEbayes outperforms the Naïve Bayes classifier on FCPS datasets slightly and on\r\nthe real-world dataset significantly with a precision of 86% and recall of 85% for\r\nPDEbayes, 82% and 76% for naivebayes for N = 19135 testdata patients.\r\n\r\nReferences\r\n1. Thrun, M. C., Gehlert, T., Ultsch, A.: Analyzing the Fine Structure of Distributions, \r\n   PloS one, Vol. 15 (10), (2020)\r\n2. Thrun, M. C., Ultsch, A.: Clustering Benchmark Datasets Exploiting the Fundamental \r\n   Clustering Problems, Data in Brief, Vol. 30 (C), (2020)\r\n3. Ultsch, A., Thrun, M.C., Hansen-Goos, O., Lötsch, J.: Identification of Molecular \r\n   Fingerprints in Human Heat Pain Thresholds by Use of an Interactive Mixture Model \r\n   R Toolbox (AdaptGauss), International Journal of Molecular Sciences, Vol. 16(10), (2015)", :session 78, :keywords (304 27 63)}, 27 {:id 27, :title "Detection of the Biliary Atresia using Deep Convolutional Neural Networks\r\nbased on Statistical Learning Weights via Optimal Similarity and Resampling Methods", :authors (318 157 405 161 317 376), :abstract "Recently, artificial intelligence methods have been applied in several fields, and their\r\nusefulness is attracting attention. Neural networks are representative online models\r\nfor prediction and discrimination. Many online methods require large training data\r\nto attain sufficient convergence. Thus, online models may not converge effectively\r\nfor low and noisy training datasets. For such cases, to realize effective learning \r\nconvergence in online models, we introduce statistical insights into an existing method\r\nto set the initial weights of deep convolutional neural networks. Using an optimal\r\nsimilarity and resampling method, we proposed an initial weight configuration approach \r\nfor neural networks. For a practice example, identification of biliary atresia\r\n(a rare disease), we verified the usefulness of the proposed method by comparing\r\nexisting methods that also set initial weights of neural networks.\r\n\r\n\r\n", :session 19, :keywords (22 45 563 503)}, 1 {:id 1, :title "Unsupervised Classification of Categorical Time Series Through Innovative Distances", :authors (52 291 459), :abstract "In this paper, two novel distances for nominal time series are introduced. Both\r\nof them are based on features describing the serial dependence patterns between\r\neach pair of categories. The first dissimilarity employs the so-called association\r\nmeasures, whereas the second computes correlation quantities between indicator\r\nprocesses whose uniqueness is guaranteed from standard stationary conditions. The\r\nmetrics are used to construct crisp algorithms for clustering categorical series. The\r\napproaches are able to group series generated from similar underlying stochastic\r\nprocesses, achieve accurate results with series coming from a broad range of models \r\nand are computationally efficient. An extensive simulation study shows that the\r\ndevised clustering algorithms outperform several alternative procedures proposed in\r\nthe literature. Specifically, they achieve better results than approaches based on \r\nmaximum likelihhod estimation, which take advantage of knowing the real underlying\r\nprocedures. Both innovative dissimilarities could be useful for practitioners in the\r\nfield of time series clustering.\r\n\r\n", :session 72, :keywords (51 75 20 280)}, 69 {:id 69, :title "Multivariate Mapping of Soil Organic Carbon and Nitrogen", :authors (526 131 205), :abstract "Soil maps, which can be effectively produced with statistical models in digital\r\nsoil mapping (DSM), contain vital information on the spatial distribution of soil\r\nproperties which are used in fields such as water- and land management and climate\r\nstudies [1]. Soil maps are usually produced in a univariate manner, that is, each map\r\nis produced independently and therefore, when multiple soil properties are mapped\r\nthe underlying covariance structure between these soil properties is ignored. This\r\nmay lead to inconsistent soil maps, for example, organic carbon and nitrogen maps\r\nproduced independently may show unrealistic carbon-nitrogen ratios. The latter is\r\nimportant as these ratios are used by map users to obtain information on residue\r\ndecomposition and the nitrogen cycle in the soil. In the last decade the production of\r\nsoil maps with machine learning models has become increasingly popular as these\r\nmodels are able to quantify complex non-linear relationships between a soil property\r\nand the environmental covariates. However, producing soil maps with multivariate\r\nmachine learning models is still lacking and requires much investigation in DSM. In\r\nthis talk we present the simultaneous mapping of soil organic carbon and nitrogen for\r\nthe region consisting of Belgium, The Netherlands, Luxembourg, and Germany. The\r\nsimultaneous mapping is performed with a multivariate random forest model [2],\r\nand we compare this model to that of two separate univariate random forest models.\r\n\r\nReferences\r\n1. McBratney, A. B., Mendonça Santos, M.L., Minasny, B.: On digital soil mapping. \r\n   Geoderma. 117, 3–52 (2003)\r\n2. Segal, M., Xiao, Y.: Multivariate random forests. WIREs Data Min. Knowl. Discovery. \r\n   1, 80–87 (2011)", :session 83, :keywords (515 147 403 332)}, 24 {:id 24, :title "Model Based Clustering of Functional Data with Mild Outliers", :authors (123 239), :abstract "We propose a procedure, called CFunHDDC, for clustering functional data with\r\nmild outliers which combines two existing clustering methods: the functional high\r\ndimensional data clustering (FunHDDC) [1] and the contaminated normal mixture\r\n(CNmixt) [2] method for multivariate data. We adapt the FunHDDC approach to data\r\nwith mild outliers by considering a mixture of multivariate contaminated normal\r\ndistributions. To fit the functional data in group-specific functional subspaces we\r\nextend the parsimonious models considered in FunHDDC, and we estimate the\r\nmodel parameters using an expectation-conditional maximization algorithm (ECM).\r\nThe performance of the proposed method is illustrated for simulated and real-world\r\nfunctional data, and CFunHDDC outperforms FunHDDC when applied to functional\r\ndata with outliers.\r\n\r\nReferences\r\n1. Bouveyron, C., Jacques, J: Model-based clustering of time series in group-specific \r\n   functional subspaces. Adv. Data. Anal. Classif. 5(4), 281–300 (2011)\r\n2. Punzo, A., McNicholas, P.D.: Parsimonious mixtures of multivariate contaminated normal\r\n   distributions. Biom. J., 58, 1506–1537 (2016)", :session 22, :keywords (215 386 108 176)}, 102 {:id 102, :title "Joint Sparse Principal Component Analysis A Simulation Study", :authors (551 142), :abstract "Measurement invariance is of great importance in the social and behavioral sciences, \r\nas it allows for generalization of latent constructs across different groups,\r\ntypically by investigating the equality of factor structures. Traditionally, in settings\r\nwhere the loadings for the different groups are not known beforehand, exploratory\r\nfactor analysis is commonly used. However, it has several drawbacks, including that\r\nmost methods cannot handle data with fewer observations than variables and other\r\nproblems (subjective thresholds for loading differences, unrealistic assumptions, \r\ninstability with small sample size, large amount of computational sources needed,\r\netc.). To overcome these drawbacks, joint sparse principal component analysis (joint\r\nSPCA) has been proposed, which adopts a regularized and cardinality constrained\r\nleast-square approach. The aim of this paper is to compare it with the best available\r\nEFA method, namely multigroup factor rotation (MGFR) [1] A simulation study\r\nwas carried out to evaluate the performance of joint SPCA in comparison with the\r\nMGFR technique, on three types of performance measures: recovery rate of the\r\nzero/non-zero pattern in the loadings, Tucker’s congruence, and computation time.\r\nFollowing the setup by [1], we varied the number of groups, group sizes, number\r\nof components, type and size of loading differences, and the number of loading\r\ndifferences. Based on the first two measures, joint SPCA performed slightly less\r\nwell than MGFR which reported a goodness-of-loading-recovery statistic for optimally \r\nrotated loadings of .99. Averaged across 6000 simulated datasets, joint SPCA\r\nhad a recovery rate and Tucker congurence of .96 (SD = .06) and .98 (SD = .02),\r\nrespectively. The CPU time increased as the conditions got more complex. Averaged\r\nacross 50 replications for each condition, the shortest time was 5.3s (2 groups) and\r\nthe longest time was 21.3s (4 groups) on an i5 processor with 8GB RAM.\r\n\r\nReferences\r\n1. De Roover, K., Vermunt, J.: On the exploratory road to unraveling factor \r\n   loading  noninvariance: A new multigroup rotation approach. Struct. Equ. Model. \r\n   26, 905–923 (2019)", :session 27, :keywords (394 474 355)}, 135 {:id 135, :title "Elastic Regression for Irregularly Sampled Curves in R^d", :authors (330 29 518), :abstract "We propose regression models for curve-valued responses in two or more dimensions,\r\nwhere only the image but not the parametrisation of the curves is of interest.\r\nExamples of such data are handwritten letters, movement paths or outlines of objects.\r\nIn the square-root-velocity framework [1], a parametrisation invariant distance\r\nfor curves is obtained as the quotient space metric with respect to the action of \r\nreparametrisation, which is by isometries. With this special case in mind, we discuss\r\nthe generalisation of ’linear’ regression to quotient spaces more generally, before\r\nillustrating the usefulness of our approach for curves modulo re-parametrisation.\r\nWe test this model in simulations and apply it to human hippocampi data, obtained\r\nfrom MRI scans [2]. Here we model how the shape of the hippocampus is related to\r\nage and Alzheimer’s disease. We address the issue of irregularly sampled curves by\r\nusing splines for modelling smooth predicted curves.\r\n\r\nReferences\r\n1. Srivastava, A. and Klassen, E.P.: Functional and Shape Data Analysis. In: Springer \r\n   Series in Statistics. Springer New York (2016)\r\n2. Petersen, R.C. et al.: Alzheimer’s disease neuroimaging initiative (ADNI): clinical \r\n   characterization. In: Neurology, 74(3):201–209, 2010.", :session 16, :keywords (175 588 605 681)}, 55 {:id 55, :title "Old and New Constraints in Model Based Clustering", :authors (338 12 210 358), :abstract "Model-based approaches to cluster analysis and mixture modeling often involve\r\nmaximizing classification and mixture likelihoods. Without appropriate constrains\r\non the scatter matrices of the components, these maximizations result in ill-posed\r\nproblems. Moreover, without constrains, non-interesting or “spurious” clusters are\r\noften detected by the EM and CEM algorithms traditionally used for the maximization \r\nof the likelihood criteria. A useful approach to avoid spurious solutions is\r\nto restrict relative components scatter by a prespecified tuning constant. Recently\r\nnew methodologies for constrained parsimonious model-based clustering have been\r\nintroduced which include the 14 parsimonious models that are often applied in\r\nmodel-based clustering when assuming normal components as limit cases. In this\r\npaper we initially review the traditional approaches and illustrate through an example\r\nthe benefits of the adoption of the new constraints.\r\n\r\n", :session 22, :keywords (382 376 105)}, 206 {:id 206, :title "Effect of Type 2 Diabetes and its Genetic Susceptibility on Severity and Mortality \r\nof COVID-19 in UK Biobank", :authors (9 584 306 536 576 328), :abstract "Although Type 2 diabetes (T2D) have been known as one of the important risk\r\nfactors for the severity and mortality of COVID-19, the effect of T2D and its genetic\r\nsusceptibility on COVID-19 are largely unknown. We analyzed the population-based\r\ncohort data of 459, 188 individuals from UK Biobank with COVID-19 test results,\r\nindividuals’ hospitalization data and death-related records during the period from\r\nMarch 11, 2020 to December 20, 2021. First, we investigated the association of\r\nT2D, and its genetic susceptibility with COVID-19 infection using multivariable\r\nlogistic regression model. To capture overall genetic susceptibility for T2D, we \r\ncomputed polygenic risk scores (PRS) based on summary statistics from UK Biobank.\r\nIn the multivariable logistic models, we found that the odds ratio (OR) of T2D was\r\n1.555 (P = 3.49×10^(−86)) and OR of PRS for T2D with one-unit (= standard deviation)\r\nincrease in PRS was 1.064 (P = 3.11 × 10^(−12)), indicating the roles of T2D-related\r\ngenetics in the pathogenesis of COVID-19 infection. Next, we performed multivariable \r\nCox proportional hazard models to investigate the effect of T2D patients infected\r\nwith COVID-19 on the survival times. The estimated survival curves and pairwise\r\nlog-rank tests showed that the estimated hazard for COVID-19 infected T2D patients\r\nwere 4.67 times (P = 9.88×10^(−324)) and 2.58 times (P = 6.20×10^(−231)) higher than\r\nindividuals without COVID-19 infection and T2D, respectively and the hazard ratio\r\n(HR) of PRS for T2D with one-unit increase in PRS was 1.088 (P = 4.76 × 10^(−14)).\r\nFurthermore, we found the mortality of COVID-19 infected T2D patients was dramatically \r\nincreased compared to T2D patients not infected with COVID-19 and the mortality of \r\nindividuals with high genetic susceptibility for T2D was increased as well.\r\n\r\n\r\n", :session 49, :keywords ()}, 85 {:id 85, :title "Outlier and Novelty Detection for Functional Data: a Semiparametric Bayesian Approach", :authors (191 44 188), :abstract "A novelty detection model can be seen as a supervised classifier, trained on a fully\r\nlabeled training set, that allows for the presence of new classes in the test set not\r\npreviously observed among the training units. When dealing with functional data,\r\nthis requires learning the main patterns for the curves in the known classes, whilst\r\nbeing able to isolate signals that possess distinctive characteristics in the unlabeled\r\nset. In order to tackle this challenging problem, we propose a two-stage Bayesian\r\nsemi-parametric novelty detector [2]. In the first stage, robust estimates are extracted \r\nfrom the training set via the Minimum Regularized Covariance Determinant (MRCD) estimator [1]. \r\nIn the second stage, such information is employed to elicit informative priors within a Bayesian \r\nmixture of known groups plus a novelty term. To reflect the lack of knowledge on the latter \r\ncomponent, we resort to a Dirichlet Process mixture model, thus overcoming the problematic a-priori \r\nspecification of the expected number of novelties that may be present in the test set. The described\r\nmethodology is applied to a spectroscopic dataset within a food authenticity study.\r\n\r\nReferences\r\n1. Denti, F., Cappozzo, A., Greselin, F.,: A two-stage Bayesian semiparametric model for novelty\r\n   detection with robust prior information. Stat. Comput. 31, 42 (2021)\r\n2. Boudt, K., Rousseeuw, P.J., Vanduffel, S., Verdonck, T.: The minimum regularized covariance\r\n   determinant estimator. Stat. Comput. 30, 113–128 (2020)", :session 6, :keywords (31 152 215 362)}, 225 {:id 225, :title "Hierarchies and Weak-Hierarchies as Interval Convexities", :authors (430 251), :abstract "There are several ways to characterize a hierarchy, one being a collection of nonempty\r\nsubsets that are convex according to a type of interval function. This characterization\r\nin terms of interval convexity, extends to general classes of multilevel clusterings,\r\nthus providing a unifying theoretical framework [1, 2]. We expand this line of research, \r\nwith a special attention to specifications allowing the capture of clusterings\r\nusually constructed in data mining practice, such as the Apresjan and the single-link\r\nhierarchies. We propose: (a) New characterizations of hierarchies and weak hierarchies \r\nas interval convexities, (b) Interval functions which induce known clustering schemes \r\nsuch as the Single Link hierarchy or the Apresjan hierarchy, (c) A sequence of nested \r\nfamilies of interval convexities that is gradually increasing from the Apresjan hierarchy \r\nto the Single-Link hierarchy, which enables the detection of redundant clusters.\r\n\r\nReferences\r\n1. Bertrand, P., Diatta, J.: Multilevel clustering models and interval convexities. Discrete Appl.\r\n   Math. 222, 54–66 (2017)\r\n2. Changat, M., Narasimha-Shenoi, P.-G., Stadler, P.-F.: Axiomatic characterization of transit\r\n   functions of weak hierarchies. Art Discrete Appl. Math. 2 #P1.01 (2019)\r\n3. Yu, Z., Liu, W., Liu, W., Yang, Y., Li, M., Kumar, B. V. K. V.: On order-constrained transitive\r\n   distance clustering. In: Proceedings of the AAAI Conference on Artificial Intelligence 30 (1)\r\n   (2016)", :session 57, :keywords (683 292 577)}, 39 {:id 39, :title "Using Clustering and Machine Learning Methods to Provide Intelligent Grocery\r\nShopping Recommendations", :authors (412 406 473 90 411 572), :abstract "Nowadays, grocery lists make part of shopping habits of many customers. With the\r\npopularity of e-commerce and plethora of products and promotions available on\r\nonline stores, it can become increasingly difficult for customers to identify products\r\nthat both satisfy their needs and represent the best deals overall. In this paper, we\r\npresent a grocery recommender system based on the use of traditional machine\r\nlearning methods aiming at assisting customers with creation of their grocery lists\r\non the MyGroceryTour platform which displays weekly grocery deals in Canada.\r\nOur recommender system relies on the individual user purchase histories, as well as\r\nthe available products’ and stores’ features, to constitute intelligent weekly grocery\r\nlists. The use of clustering prior to supervised machine learning methods allowed us\r\nto identify customers profiles and reduce the choice of potential products of interest\r\nfor each customer, thus improving the prediction results. The highest average F-score\r\nof 0.499 for the considered dataset of 826 Canadian customers was obtained using\r\nthe Random Forest prediction model which was compared to the Decision Tree,\r\nGradient Boosting Tree, XGBoost, Logistic Regression, Catboost, Support Vector\r\nMachine and Naive Bayes models in our study.\r\n\r\n", :session 64, :keywords (75 150 250 286 332 524)}, 274 {:id 274, :title "Towards Deep and Interpretable Rule Learning", :authors (282), :abstract "Inductive rule learning is concerned with the learning of classification rules from\r\ndata. Learned rules are inherently interpretable and easy to implement, so they are\r\nvery suitable for formulating learned models in many domains. Nevertheless, current\r\nrule learning algorithms have several shortcomings. First, with respect to the current\r\npraxis of equating high interpretability with low complexity, we argue that while\r\nshorter rules are important for discrimination, longer rules are often more interpretable \r\nthan shorter rules, and that the tendency of current rule learning algorithms\r\nto strive for short and concise rules should be replaced with alternative methods that\r\nallow for longer concept descriptions. In general, the mere syntactic comprehensibility \r\nof the learned concepts does often not yield convincing or plausible rules,\r\nand factors such as semantic coherence or the a priori relevance of used conditions\r\nshould be explicitly encoded as objectives in an interpretable rule learning algorithm. \r\nHuman cognitive biases can be one possible road towards the design of an interpretability \r\nbias for rule learning [3]. Second, we think that the main impediment of current rule \r\nlearning algorithms is that they are not able to learn deeply structured rule sets, unlike \r\nthe successful deep learning techniques. Both points are currently under investigation in \r\nour group, and we will show some preliminary results [1, 2].\r\n\r\nReferences\r\n1. Beck, F., Fürnkranz, J.: An empirical investigation into deep and shallow rule learning.\r\n   Frontiers Artif. Intell. 4:689398 (2021)\r\n2. Beck, F., Fürnkranz, J., Quoc, P.H.V.: Structuring rule sets using binary decision diagrams. \r\n   In: Proceedings of the 5th International Joint Conference on Rules and Reasoning (RuleML+RR),\r\n   Leuven, Belgium, pp. 48–61. Springer (2021)\r\n3. Fürnkranz, J., Kliegr, T., Paulheim, P.: On cognitive preferences and the plausibility of \r\n   rulebased models. Mach. Learn. 109(4):853–898 (2020)", :session 75, :keywords (281 289 193 135)}, 217 {:id 217, :title "Reconstruction of Atomic Measure Based on Its Simplicial Depth", :authors (456 522), :abstract "Statistical depth functions have been introduced in order to generalize the notions of\r\nranks, orderings and quantiles in the multivariate case. Depth is a function that to\r\nany point x assigns the quantity which aims to describe how centrally positioned is x\r\nrespect to a given measure. It is of importance to explore whether the depth function\r\ncontains all the information of the underlying measure, i.e. does it characterise it. By\r\ncharacterising we mean that there is no other measure with the same depth function\r\neverywhere. We focus on the special case of simplicial depth, introduced in [1, 2]\r\nand the class of atomic measures. In this particular setup, under mild assumption\r\nof atoms being in general position, we prove that the characterisation property is\r\nsatisfied and describe an algorithm for recovering atomic measure from its simplicial\r\ndepth.\r\n\r\nReferences\r\n1. Liu , R. Y.: On a notion of simplicial depth. Proc. Natl. Acad. Sci. U.S.A., 85(6), \r\n1732–1734 (1988)\r\n2. Liu, R. Y.: On a notion of data depth based on random simplices. Ann. Statist., 18(1), \r\n405-–414 (1990)", :session 58, :keywords (573 21 525)}, 149 {:id 149, :title "Clusters Based on Prediction Accuracy of Global Forecasting Models", :authors (432 591 291), :abstract "In the context of model-based time series clustering, the quality of a given clustering\r\nrelies on the predictive accuracy of the models that generated the cluster. Traditionally,\r\na model is fitted to each time series and then a dissimilarity matrix is generated\r\nfrom distances between models. This approach has a few limitations. Time series\r\nare notoriously difficult to fit, exhibiting problems such temporal dependency, low\r\nsample size and nonstationarity. Moreover, when clustering a large number time\r\nseries, we often have to rely on automatic fitting procedures without human supervision.\r\nThese problems lead to models with poor predictive accuracy. However, a\r\nnew paradigm has emerged in time series prediction, the so-called cross-learning or\r\nglobal model approach. A group of time series is pooled together and fitted with a\r\nsingle model, called a ‘global’ model, and a single predictive function is then used\r\nfor all of the time series in the group. Global models are showing superior accuracy\r\ncompared with traditional single-series (or ‘local’) models in a vast number of\r\napplications. Global models can be used for clustering, by finding a grouping that\r\nmaximizes the predictive accuracy of the global models fitted to each group. This\r\napproach has an important side-effect, it introduces the conceptof predictive accuracy\r\nas a measure of a cluster quality: given a model class and a dataset,the quality\r\nof a given clustering is the average predictive error of the global. This measure also\r\nserves to select the often unknown parameter of the number of clusters.\r\nIn this talk, we will introduce the idea of using global models for clustering time\r\nseries, showcasing several algorithms and results on simulation and real datasets.\r\nThe time series models include the classical linear autoregressive family, but also\r\nneural networks and decision trees. Finally, we will draw connections between global\r\nmodels and classic algorithms such as k-means and discuss implicit limitations of\r\nthe approach.\r\n\r\n", :session 25, :keywords (75 641 243 127 24)}, 239 {:id 239, :title "Optimal Random Projection Trees Ensemble", :authors (420 7 388 586 84), :abstract "This paper develops the idea of creating an ensemble of accurate and diverse trees\r\nfor improved classification accuracy: Optimal Random Projection Trees Ensemble\r\n(ORPTE), which is an extension of Optimal Trees Ensemble (OTE) [1]. Diversity\r\nin the base classification trees is introduced by the method of Random Projection\r\nas a dimensionality reduction tool that preserves pairwise distances between \r\nobservations [2]. A sufficiently large number of trees is grown on bootstrap samples by\r\nusing the Random Forest algorithm, each generated on a random projection of the\r\ntraining data. For maintaining accuracy in the base models, trees are ranked based on\r\ntheir out-of-bag error estimates and a certain proportion of the top ranked trees are\r\nselected. The selected trees are integrated as an ensemble for predicting new/unseen\r\ndata. The proposed method was assessed on 25 benchmark datasets against seven\r\ncompetitor methods in addition to a simulation study. The results demonstrate that\r\nthe proposed method outperformed its competitors in most of the data sets and the\r\nsimulation setup.\r\n\r\nReferences\r\n1. Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., Lausen, B.:\r\n   Ensemble of optimal trees, random forest and random projection ensemble classification.\r\n   Advances in Data Analysis and Classification 14, 97–116 (2020)\r\n2. Cannings, T.J., Samworth, R.J.: Random projection ensemble classification. Journal of the\r\n   Royal Statistical Society B 79(4), 1–38 (2017)", :session 30, :keywords (518 449 180)}, 157 {:id 157, :title "Symbolic Concordance and Discordance Illustrated on Data from an International\r\nTeaching and Learning Survey", :authors (514 79 149), :abstract "A \"similarity\" as a \"concordance\" in data analysis represents mathematical modeling\r\nof the common words \"similarity\" and \"concordance\" used in our natural language.\r\nThe similarity between a class c and a collection P of classes c’ for a category x is\r\nhigh if the mean of the similarities between the frequency of x in c and the frequency\r\nof x in c’ that varies in P is high. A class has high concordance with a given collection\r\nof classes for a category x if that category is frequent in that class and if, in addition,\r\nthere are numerous classes in the given collection of classes for which the category\r\nx is also frequent. Similarity and concordance thus express two different kinds of\r\nknowledge. In this presentation, we introduce some measures of concordance and\r\ndiscordance between a class and a given collection of classes that fall within the\r\nframework of symbolic data analysis (SDA) [1].\r\nWe will illustrate the use of new measures on the real dataset from the international\r\nlarge-scale assessment PIRLS 2016 [2] that measured the achievement of students\r\nin classical reading and reading from digital devices in more than 50 countries.\r\nOnline reading is becoming an extremely important skill for younger generations and\r\nresearch is needed to understand how it develops along with classical reading from\r\npaper. We will study distributions of high and low-achieving students in informational\r\nreading from paper and online reading, and compare these across countries and\r\nwithin teachers of classes of students inside a specific country. For example, if we\r\nconsider the teacher as a class and his or her students as individuals, by examining\r\ntheir reading ability, we can measure the concordance or discordance between the\r\nteacher’s student responses of a country and the other countries.\r\n\r\nReferences\r\n1. Diday, E.: Explanatory tools for machine learning in the symbolic data analysis framework.\r\n   In: Diday, E., Guan, R., Saporta, G., Wang, H. (eds.) Advances in Data Science, pp. 3-30.\r\n   ISTE-Wiley (2020)\r\n2. PIRLS: Progress in Internationals Readings Literacys Study\r\n   https://timssandpirls.bc.edu/pirls2016\r\n", :session 5, :keywords (626 625 627)}, 4 {:id 4, :title "Anomaly Detection-Based Under-Sampling for Imbalanced Classification Problems", :authors (583 112 480 141), :abstract "In this research, we propose a new anomaly detection-based under-sampling method\r\ncalled ADU to improve the classification performance of imbalanced datasets by \r\neffectively removing anomalies, such as outliers and noises. To detect the anomalies \r\nin different clusters effectively, three useful approaches are considered. Specifically, \r\nto detect the outliers belonging to the majority class, neighborhood-based and density\r\nbased outlier detection methods, namely OBN (outlierness based on neighborhood) and \r\nDBSCAN (density-based spatial clustering based on noise applications) are\r\nused [1, 2]. Finally, to eliminate the borderline noise samples in the majority class\r\n(i.e., the majority class samples with low membership probabilities), a membership\r\nprobability-based under-sampling is proposed with changing the under-sampling rate\r\nso that a proportion of majority class samples can be removed.\r\n\r\nReferences\r\n1. Gupta, U., Bhattacharjee, V., Bishnu, P.S.: A New Neighborhood-Based Outlier Detection\r\n   Technique. In: Nath, V., Mandal, J.K. (eds.) MCCS 2018, pp. 527-534. Springer, Singapore\r\n   (2018)\r\n2. Ester, M., Kriegel, H.P., Sander, J., Xu, X.: A density-based algorithm for discovering clusters\r\n   in large spatial databases with noise. In: Simoudis, E., Han, J., Fayyad U. (eds.) KDD 1996,\r\n   pp. 226-231. AAAI Press, Oregon, USA. (1996)\r\n", :session 13, :keywords (63 60 61 664 356)}, 204 {:id 204, :title "A Family of Skewed Power Exponential Mixture Models for Clustering and Classification", :authors (556 391 492 439), :abstract "In model-based clustering, mixture models that can deal with varying cluster tailweight, \r\nskewness, concentration, and kurtosis are increasingly becoming common.\r\nMixtures of multivariate power exponential (MPE) distributions were previously\r\nshown to be competitive for clustering in comparison to other elliptical mixture\r\ndistributions [1]. Here, we introduce a novel formulation of a multivariate skewed\r\npower exponential distribution and mixtures thereof to combine the flexibility of the\r\nMPE distribution with the ability to model cluster-specific skewness. These mixtures\r\nare more robust to departures from normality and can model skewness, varying tail\r\nweight, and peakedness within clusters. A family of parsimonious models is proposed\r\nusing an eigen-decomposition of the scale matrix. For parameter estimation, a generalized \r\nexpectation-maximization approach combining minorization-maximization and optimization based \r\non accelerated line search algorithms on the Stiefel manifold is utilized. These mixtures are \r\nimplemented both in the model-based clustering and classification frameworks. We illustrate \r\nperformance on toy and benchmark data in a wide range of scenarios.\r\n\r\nReferences\r\n1. Dang, U.J., Browne, R.P., McNicholas, P.D.: Mixtures of multivariate power exponential\r\n   distributions. Biometrics. 71, 1081–1089 (2015)", :session 43, :keywords (386 410 377 63)}, 77 {:id 77, :title "Generating Collective Counterfactual Explanations in Score-Based Classification \r\nvia Mathematical Optimization", :authors (264 155 138), :abstract "Due to the increasing use of Machine Learning models in high stakes decisionmaking \r\nsettings, it has become increasingly important to be able to understand how\r\nmodels arrive at decisions. Assuming an already trained Supervised Classification\r\nmodel, an effective class of post-hoc explanations are counterfactual explanations \r\n[2], i.e., a set of actions that can be taken by an instance such that the given \r\nMachine Learning model would have classified it in a different class. In this talk, \r\nfor scorebased multiclass classification models, we propose novel Mathematical \r\nOptimization formulations to construct the so-called collective counterfactual \r\nexplanations, i.e., explanations for a group of instances in which we minimize the \r\nperturbation in the data (at the individual and group level) to have them labelled by \r\nthe classifier in a given group [1]. Although the approach is valid for any \r\nclassification model based on scores, we focus on additive tree models, like random \r\nforests or XGBoost. Our approach is capable of generating diverse, sparse, plausible \r\nand actionable collective counterfactuals. Real-world data are used to illustrate our \r\nmethod.\r\n\r\nReferences\r\n1. Carrizosa, E., Ramírez-Ayerbe, J., Romero Morales , D.: Generating Counterfactual \r\n   Explanations in Score-Based Classification via Mathematical Optimization. Technical \r\n   Report IMUS, Sevilla, Spain (2022) doi: 10.13140/RG.2.2.22996.12168/1\r\n2. Wachter, S., Mittelstadt, B., Russell, C.: Counterfactual explanations without \r\n   opening the black box: Automated decisions and the GDPR. Harvard Journal of Law and \r\n   Technology, 31 841 (2017)", :session 38, :keywords (81 556 341)}, 197 {:id 197, :title "The Usefulness of Selected Machine Learning Methods for Estimating Missing Data to\r\nSupplement Databases Used for Corporate Bankruptcy Prediction", :authors (80 297), :abstract "Socio-economic consequences of corporate bankruptcies and forecasting the risk\r\nfirms’ bankruptcy enjoys unflagging interest among researchers and practitioners.\r\nFinancial indicators that are the basis for building forecasting models very often\r\ncontain data shortages. In our previous research, we supplemented the missing\r\ndata primarily by median of a given variable, determined separately for bankrupt\r\nand non-bankrupt firms [2]. The aim of the paper is presentation the results of\r\ninvestigations on the usefulness of selected machine learning methods for estimation\r\nvalues of missing data (e.g. multivariate imputation method based on random forests),\r\nto supplement databases used for building and estimations corporate bankruptcy\r\nprediction models. The study included three databases designed to forecast the\r\nbankruptcy of enterprises in Poland one year, two years and three years in advance.\r\nVarious mechanisms for generating data gaps were considered [1]. Selected methods\r\nwere used to estimate missing data, such as: mean, median, k-nearest neighbors,\r\nclassification tree, multivariate imputation based on random Forests or predictive\r\nmean matching [3], and others.\r\n\r\nReferences\r\n1. Kauermann, G., Küchenhoff, H., Heumann, C.: Statistical Foundations, Reasoning and \r\n   Inference. For Science and Data Science. Springer, Cham (2021)\r\n2. Pociecha, J., Pawelek, B., Baryla, M., Augustyn, S.: Classification Models as Tools of\r\n   Bankruptcy Prediction – Polish Experience. In: Mola, F., Conversano, C., Vichi, M. (eds.)\r\n   Classification, (Big) Data Analysis and Statistical Learning. Springer, Cham (2018)\r\n3. van Buuren, S., Groothuis-Oudshoorn, K.: mice: Multivariate Imputation by Chained Equations \r\n   in R. J. Stat. Softw. 45(3), 1-67 (2011)", :session 81, :keywords (364 26 332)}, 232 {:id 232, :title "Robust Classification for Toroidal Data", :authors (214 334 121), :abstract "Circular data commonly occur in many different fields, such as biology, meteorology\r\nand geology, where observations can be measured by angles. Here, we consider the\r\nproblem of classifying circular observations into one of possible distinct populations\r\nand we focus on the situations where observations can be thought as points that lie on\r\nthe surface of a Torus. Some proposals can be found in literature for the classification\r\nof circular data, however this problem is poorly explored in case of toroidal data.\r\nIn general, the traditional procedures for the classification problem can be greatly\r\naffected by inaccurancies in features and labels of training data. Hence, we propose\r\na procedure based on the weighted likelihood technique which is able to classify\r\nnew data points scattered on a p-dimensional torus following multivariate Wrapped\r\nNormal distributions. In particular, the Weighted CEM algorithm proposed by [1]\r\nis applied on the training data set considering the classes separately. Ineed, this\r\nestimator is able to handle the model inadequacies in the fitting process by an\r\neffective downweighting of observations not following the assumed model. In this\r\nway, a pair of robust location and scale estmates are available for each group. In a\r\nsecond step, a set of data-dependent weights is computed for the testing data points\r\nfor each group-based estimates. Finally, the resulting weights are used to classify\r\neach observations into one of the groups or none of them. The finite sample behavior\r\nof the proposed procedure is investigated by a Monte Carlo numerical study and real\r\ndata examples.\r\n\r\nReferences\r\n1. G. Saraceno and C. Agostinelli and L. Greco (2021). Robust estimation for multivariate\r\n   wrapped models. METRON, 79:225–240.", :session 11, :keywords (63 413 545 650 686)}, 260 {:id 260, :title "Prognosis of COVID-19 Patients by the Underlying Diseases and Drug Treatment in Korea", :authors (231 535), :abstract "Certain underlying diseases such as diabetic mellitus and hypertension\r\nare a risk factor for the severity and mortality of coronavirus disease (COVID-19)\r\npatients. Furthermore, both angiotensin converting enzyme inhibitors (ACEi) and\r\nangiotensin II receptor blockers (ARBs) are controversial at role in the process of\r\nCOVID-19 cases. The aim of the study was to investigate whether underlying diseases \r\nand taking ACEi/ARBs, affect the duration of hospitalization and mortality in patients \r\nwith confirmed COVID-19. Among the comorbidities, a history of hypertension (hazard \r\nratio [HR], 1.51; 95% confidence interval [CI], 1.056–2.158) and diabetes (HR, 1.867; \r\n95% CI, 1.408–2.475) were associated significantly with mortality. Furthermore, heart \r\nfailure (HR, 1.391; 95% CI, 1.027–1.884), chronic obstructive pulmonary disease (HR, \r\n1.615; 95% CI, 1.185–2.202), chronic kidney disease (HR, 1.451; 95% CI, 1.018–2.069), \r\nmental disorder (HR, 1.61; 95% CI, 1.106–2.343), end stage renal disease (HR, 5.353; \r\n95% CI, 2.185–13.12) were also associated significantly with mortality. The underlying \r\ndisease has increased the risk of mortality in patients with COVID-19. Diabetes, \r\nhypertension, cancer, chronic kidney disease, heart failure, and mental disorders \r\nincreased mortality. Controversial whether taking ACEi/ARBs would benefit COVID-19 \r\npatients, in our study, patients taking ACEi/ARBs had a higher risk of mortality.\r\n\r\nReferences\r\n1. CDC COVID-19 Response Team; Chow, N.; Fleming-Dutra, K.; Gierke, R.; Hall, A.; Hughes, M.; \r\n   Pilishvili, T.; Ritchey, M.; Ritchey, K.; Skoff, T.; et al. Preliminary estimates of the\r\n   prevalence of selected underlying health conditions among patients with coronavirus disease\r\n   2019—United States, February 12–March 28, 2020. Morb. Mortal. Wkly. Rep. 2020, 69, 382.", :session 49, :keywords (120)}, 267 {:id 267, :title "Visualization of the Number of New Positives for COVID-19 in Japan", :authors (582 497 387 534), :abstract "COVID-19 has been spreading in Japan and other parts of the world since 2020.\r\nIn Japan, the number of newly confirmed positive cases is reported daily in the\r\nnews. As the number of infected people increases, restraints on behavior and other\r\nmeasures have been taken to control the spread of infection. Our group has developed\r\na system to visualize the number of positive cases of COVID-19 in five prefectures\r\nwhere university campuses are located, so that the status of the spread of COVID19 \r\ninfection can be monitored. ([1],[2], http://covid-map.bmi-tokai.jp/) The system\r\nprovides a visualization of the number of newly confirmed positive cases in each\r\nmunicipality, and is designed to provide an interactive function to provide the user\r\nwith the information he or she wants to know. We present the details of the data\r\ncollection method as well as the visualization information realized by this system.\r\n\r\nAcknowledgments This research was supported by a research grant (2021) from\r\n                the Tokai University Union Supporting Association. We would \r\n                like to express our deepest gratitude.\r\n\r\nReferences\r\n1. Tanahashi, M., Yamada, S., Imanishi, T., Yamamoto, Y.: Choropleth map of newly infected \r\n   people with COVID-19. 2021 19th International Conference on ICT and Knowledge Engineering.\r\n   IEEE Xplore (2021)\r\n2. Tanahashi, M., Yamamoto, Y.: Visualization of the distribution of newly infected persons \r\n   with COVID 19 in the prefecture. 2020 18th International Conference on ICT and Knowledge\r\n   Engineering. IEEE Xplore (2020)", :session 60, :keywords (117 679 288)}, 119 {:id 119, :title "Symbolic Clustering Methods Applied to Interval Estimates of Production Cost Quantiles", :authors (139), :abstract "The decision to adopt one or another of the sustainable land management alternatives\r\nshould not be based solely on their respective benefits in terms of climate change\r\nmitigation, but also on the performance of the productive systems used by the farms,\r\nassessing their environmental impacts through the cost of the specific resources\r\nused. This communication presents applications of the symbolic clustering methods,\r\nproposed in [1, 2] for interval data, to conditional quantile estimates of production\r\ncosts in agriculture. The interval data clustering tools are used to obtain typologies of\r\nEuropean countries and regions, on the basis of the conditional quantile distributions\r\nof agricultural production cost empirical estimates. A procedure to find optimal\r\npartitions along with various criteria is used. Some standard statistical tests are\r\nproceed. This work extends preliminary results published in [3]. The comparative\r\nanalysis of the econometric results for the main products between European countries\r\nand regions illustrates the relevance of the typologies obtained for national and\r\ninternational comparisons based on their specific input productivity.\r\n\r\nReferences\r\n1. Carvalho, F., Souza, R., Chavent, M., Lechevallier, Y.: Adaptive Hausdorff distances and\r\n   dynamic clustering of symbolic interval data. Pattern Recognition Letters, 27(3), 167–179 (2006)\r\n2. Chavent, M., Lechevalier, Y., Briant, O.: DIVCLUS-T: A monothetic divisive hierarchical\r\n   clustering method. Computational Statistics & Data Analysis, 52(2), 687–701 (2007)\r\n3. Desbois, D.: Applying interval PCA and clustering to quantile estimates: empirical distributions \r\n   of fertilizer cost estimates for yearly crops in European Countries. Communications in Statistics: \r\n   Case Studies, Data Analysis and Applications, 7(4), 695–716 (2021)", :session 36, :keywords (624 293 511 8 358)}, 222 {:id 222, :title "Biplots in Dimension Reduction and Clustering", :authors (25 55 394), :abstract "In unsupervised learning, dimension reduction (e.g., PCA) and distance-based \r\nclustering are often applied sequentially: the distances used to cluster the \r\nobservations are computed on the reduced dimensions. Since the dimension reduction \r\nstep does not take into account the possible cluster structure, it is possibly detrimental \r\nto the clustering step. Methods for joint dimension reduction and clustering combine the\r\ntwo in a single optimization problem which is solved using iterative procedures alternating \r\nthe two steps. Just like for principal component methods, different approaches\r\nhave been proposed that deal with continuous, categorical or mixed-type data. In\r\nparticular, for continuous data, reduced K-means [1] combines principal component\r\nanalysis with K-means clustering; for categorical data, cluster correspondence analysis [2] \r\ncombines correspondence analysis with K-means; for mixed-type data, mixed Reduced K-means [3] \r\ncombines factor analysis for mixed data with K-means. The biplot visualization of the solution \r\nis of particular interest for interpretation purposes: in fact, the low-dimensional map can be \r\nvery helpful for cluster characterization. In this work, we illustrate the use of biplots in the \r\ncontext of dimension reduction and clustering.\r\n\r\nReferences\r\n1. De Soete, G., Carroll, J. D.: K-means clustering in a low-dimensional Euclidean space. In: E.\r\n   Diday, et al. (eds.), New approaches in classification and data analysis, pp. 212–219, Springer,\r\n   Heidelberg (1994)\r\n2. van de Velden, M., Iodice D’Enza, A., Palumbo, F.: Cluster correspondence analysis. \r\n   Psychometrika 82(1), 158–185 (2017)\r\n3. van de Velden, M., Iodice D’Enza, A., Markos, A.: Distance-based clustering of mixed data.\r\n   Wiley Interdisciplinary Reviews: Computational Statistics 11(3), e1456 (2019)", :session 39, :keywords (40 149 75)}, 95 {:id 95, :title "Clustering with Missing Data: Which Imputation Model for Which Cluster Analysis Method?", :authors (568 413 382), :abstract "Multiple imputation (MI) is a popular method for dealing with missing values. One\r\nmain advantage of MI is to dissociate the imputation phase and the analysis one.\r\nHowever, both are related since they are based on distribution assumptions that have\r\nto be consistent. This point is well known as congeniality.\r\n  In this talk, we discuss congeniality of imputation models and clustering on\r\ncontinuous data. First, we theoretically highlight how two joint modelling (JM)\r\nMI methods, using either general location model (JM-GL) or Dirichlet process\r\nmixture (JM-DP), could be congenial with various clustering methods. Then, we\r\npropose a new fully conditional specification (FCS) MI method with the same\r\ntheoretical properties as JM-GL. Finally, we extend this FCS MI method from\r\nnormal distribution to account for more complex distributions. Based on an extensive\r\nsimulation study, all MI methods are compared for various cluster analysis methods\r\n(k-means, k-medoids, mixture model, hierarchical clustering).\r\n  This study highlights the partition accuracy is always improved when the imputation \r\nmodel accounts for clustered individuals. From this point of view, standard\r\nMI methods ignoring such a structure should be avoided. JM-GL and JM-DP should\r\nbe recommended when data are distributed according to a Gaussian mixture model,\r\nwhile FCS methods outperform JM ones on data involving more complex distributions.\r\n\r\n", :session 57, :keywords (75 364 399 95)}, 144 {:id 144, :title "Resampling, Relabeling, and Raking for Extremely Imbalanced Classification", :authors (223 506 283), :abstract "In this presentation, we consider the binary classification of extremely imbalanced\r\ndata. Imbalanced data classification is often challengeable, especially for\r\nhigh-dimensional data, because unequal classes deteriorate classifier performance.\r\nUndersampling the majority class or oversampling the minority class are popular\r\nmethods to construct balanced samples, facilitating classification performance improvement.\r\nHowever, many existing sampling methods cannot be easily extended\r\nto high-dimensional data and mixed data, including categorical variables, because\r\nthey often require approximating the attribute distributions, which becomes another\r\ncritical issue. To handle these issues, we propose a new sampling strategy employing\r\nresampling, relabeling, and raking procedures, such that the attribute values of the\r\nmajority class are imputed for the values of the minority class in the construction of\r\nbalanced samples. Our proposed algorithm is attractive in practice, considering that\r\nit does not require density estimation for synthetic data generation in oversampling\r\nand is not bothered by mixed-type variables. In addition, the proposed sampling\r\nstrategy is robust to classifiers in the sense that classification performance is not sensitive\r\nto choosing the classifiers. Also the proposed method can be directly applied\r\nto one-class classification problem.\r\n\r\n", :session 9, :keywords (47 372 443)}, 192 {:id 192, :title "Multinomial Multilevel Models with Discrete Random Effects: a Multivariate Clustering Tool", :authors (105 189 59), :abstract "We propose a Semi-Parametric Mixed-Effects Multinomial regression model to deal\r\nwith estimation and inference issues in the case of categorical data with a \r\nhierarchical structure [1]. Considering a K−categories response, the proposed modelling\r\nassumes the probability of each response category to be identified by a set of fixed\r\nand random effects parameters, one for each logit, estimated by means of an EM\r\nalgorithm [2]. Random effects are assumed to follow a discrete distribution with an\r\na priori unknown number of support points, that identifies a latent structure at the\r\nhighest level of grouping, where observations are clustered into (K−1)−dimensional\r\nsubpopulations. This method is an extension of the MSPEM algorithm proposed in\r\n[4], in which we relax the independence assumption across random-effects relative\r\nto different response categories. Since the category-specific random effects arise\r\nfrom the same subjects, their independence assumption is seldom verified in real\r\ndata and, by relaxing it, the proposed method properly fits the natural data structure,\r\nas emerges by the results of simulation and case studies. In the case study, we apply\r\nthe algorithm to Politecnico di Milano data, to model different categories of student\r\ncareers, where students are enrolled in 20 engineering degree courses. Results are\r\ncompared to the ones of the parametric MCMCglmm appraoch [3].\r\n\r\nReferences\r\n1. Agresti, A.: An introduction to categorical data analysis. Wiley (2018)\r\n2. Dempster, A.P., Laird, N.M., & Rubin, D.B.: Maximum likelihood from incomplete data\r\n   via the EM algorithm. Journal of the Royal Statistical Society: Series B, 39(1), 1-22 (1977).\r\n3. Hadfield, J.D.: MCMC methods for multi-response generalized linear mixed models: the\r\n   MCMCglmm R package. Journal of statistical Software, 33, 1-22 (2010).\r\n4. Masci, C., Ieva, F., & A.M. Paganoni: Semiparametric Multinomial Mixed-Effects Models: A\r\n   University Students Profiling Tool. Annals of Applied Statistics, in press (2022)", :session 41, :keywords (370 50 154 269)}, 92 {:id 92, :title "Registration of 24-Hour Accelerometric Rest-Activity Profiles and Its Application \r\nto Human Chronotypes", :authors (162 559 272 269 304), :abstract "By collecting data continuously over 24 hours, accelerometers and other wearable\r\ndevices can provide novel insights into circadian rhythms and their relationship\r\nto human health. Existing approaches for analyzing diurnal patterns using these\r\ndata, including the cosinor model and functional principal component analysis,\r\nhave revealed and quantified population-level diurnal patterns, but considerable\r\nsubject-level variability remained uncaptured in features such as wake/sleep times\r\nand activity intensity. This remaining informative variability could provide a better \r\nunderstanding of chronotypes, or behavioral manifestations of one’s underlying\r\n24-hour rhythm. Curve registration, or alignment, is a technique in functional data\r\nanalysis that separates “vertical” variability in activity intensity from “horizontal”\r\nvariability in time-dependent markers like wake and sleep times; this data-driven approach \r\nis well-suited to studying chronotypes using accelerometer data. We develop\r\na parametric registration framework for 24-hour accelerometric rest-activity profiles\r\nrepresented as dichotomized into epoch-level states of activity or rest. Specifically,\r\nwe estimate subject-specific piecewise linear time-warping functions parametrized\r\nwith a small set of parameters. We apply this method to data from the Baltimore\r\nLongitudinal Study of Aging and illustrate how estimated parameters give a more\r\nflexible quantification of chronotypes compared to traditional approaches.\r\n\r\n", :session 77, :keywords (217 10 75)}, 221 {:id 221, :title "PD-Clustering for Mixed Data Type", :authors (192 126), :abstract "Data clustering aims to find homogeneous groups in the data using systematic\r\nnumerical methods; non-hierarchical algorithms can offer considerable advantages\r\nover other approaches. Above all, they are easily parallelizable. In a few words,\r\nthey solve an optimization problem to find two quantities: the cluster memberships\r\nand the cluster parameters, which depend on each other. Therefore, algorithms\r\nalternatively compute the two quantities, optimizing the same criterion at each step,\r\nand stop when the criterion reaches a minimum (maximum). The membership can\r\nbe crisp or probabilistic: a point is assigned to all the clusters with a degree of\r\nmembership. Probabilistic Distance Clustering (PDC) maximizes the classifiability\r\nof all the observations assuming that the belonging probability to each cluster is\r\ninversely proportional to the distance from the cluster center [1].\r\nTo jointly consider mixed data variables, one possible solution is to re-code all\r\nvariables in a single data type through pre-processing, which can seriously weaken\r\nthe true association structure. Some satisfactory clustering methods for mixed data\r\nexist, but they tend to be slow. The primary issue in clustering mixed data is the\r\nidentification of a unified similarity metric. The most popular approaches based on\r\nthis idea are k-prototypes [3] and KAy-means for MIxed LArge data (Kamila) [2].\r\nThis proposal extends the PDC to mixed-type data using a dissimilarity for mixedtype \r\ndata and redefining the cluster centers. The cluster parameters that optimize the\r\ncriterion are based on the updated dissimilarity and integrated into the algorithm.\r\nThe performance of the new algorithm are compared to K-prototype and Kamila.\r\n\r\nReferences\r\n1. A. Ben-Israel, C. Iyigun, Probabilistic d-clustering, J Class 25 (1) (2008) 5–26.\r\n2. A. H. Foss, M. Markatou, kamila: Clustering mixed-type data in R and Hadoop, J Stat Softw\r\n  83 (13) (2018) 1–45.\r\n3. G. Szepannek, clustmixtype: User-friendly clustering of mixed-type data in r, The R Journal\r\n   10 (2) (2018) 200–208.", :session 41, :keywords (500 366)}, 141 {:id 141, :title "Testing Equality of Multivariate Coefficients of Variation", :authors (351 593), :abstract "The univariate coefficient of variation is well known unit-free variability measure,\r\nwhich is often applicable. There are a few its multivariate extensions, and no one is\r\nassumed to be a default [2]. Moreover, only for one of the multivariate coefficients\r\nof variation, statistical tests are known for verifying their equality in several groups\r\n[1, 3]. In this paper, we would like to fill this gap. We prove that the asymptotic\r\ndistribution of the estimators of multivariate coefficients of variation is normal with\r\nappropriate variances. Using this result, we construct a Wald-type test statistics,\r\nwhose distributions are approximated by the permutation method. The properties of\r\nthe obtained tests are investigated in simulation studies. We consider the control of\r\ntype I error level and power.\r\n\r\nReferences\r\n1. Aerts, S., Haesbroeck, G.: Robust asymptotic tests for the equality of multivariate \r\n   coefficients of variation. Test 26, 163–187 (2017)\r\n2. Albert, A., Zhang, L.: A novel definition of the multivariate coefficient of variation. \r\n   Biom. J. 52, 667–675 (2010)\r\n3. Ditzhaus, M., Smaga, Ł.: Permutation test for the multivariate coefficient of variation \r\n   in factorial designs. J. Multivariate Anal. 187, 104848 (2022)", :session 18, :keywords (404 478 610)}, 264 {:id 264, :title "Vine Copula Mixture Models and Clustering for Non-Gaussian Data", :authors (429 116), :abstract "The majority of finite mixture models suffer from not allowing asymmetric tail\r\ndependencies within components and not capturing non-elliptical clusters in \r\nclustering applications. Since vine copulas are very flexible in capturing these \r\ndependencies, a novel vine copula mixture model for continuous data is proposed. \r\nThe model selection and parameter estimation problems are discussed, and further, \r\na new model-based clustering algorithm is formulated. The use of vine copulas in\r\nclustering allows for a range of shapes and dependency structures for the clusters.\r\nThe simulation experiments illustrate a significant gain in clustering accuracy when\r\nnotably asymmetric tail dependencies or/and non-Gaussian margins within the coponents \r\nexist. The analysis of real data sets accompanies the proposed method. The model-based \r\nclustering algorithm with vine copula mixture models outperforms others, especially for \r\nthe non-Gaussian multivariate data.\r\n\r\n", :session 26, :keywords (141 168 386 407 460)}, 104 {:id 104, :title "Logistic Regression with Sparse Common and Distinctive Covariates", :authors (519 168 312), :abstract "Having large sets of predictor variables from multiple sources concerning the same\r\nindividuals is becoming increasingly common in research. On top of the variable\r\nselection problem, predicting the category in which the observations belong to\r\nusing such data gives rise to an additional challenge of identifying the processes\r\nat play underneath the predictors. These processes are of particular interest in the\r\nsetting of multi-source data because they can either be associated individually with\r\na single data source or jointly with multiple sources. Although many methods have\r\naddressed the classification problem in high dimensionality, the additional challenge\r\nof distinguishing such underlying predictor processes from multi-source data has not\r\nreceived sufficient attention. To this end, we propose the method of Sparse Common\r\nand Distinctive Covariates Logistic Regression (SCD-Cov-logR). The method is a\r\nmulti-source extension of principal covariates regression (PCovR) [1] that combines\r\nwith generalized linear modeling framework to allow classification of a categorical\r\noutcome. PCovR is a dimension reduction method that extracts components that\r\nexplain the xvariance in both predictor and outcome variables. In a simulation study,\r\nSCD-Cov-logR resulted in outperformance compared to related methods commonly\r\nused in behavioural sciences. We also demonstrate the practical usage of the method\r\nunder an empirical dataset.\r\n\r\nReferences\r\n1. De Jong, S., Kiers, H.A.: Principal covariates regression: part i. theory. Chemom. \r\n   Intell. Lab. Syst. 14(1-3): 155–164 (1992)", :session 78, :keywords (149 327 392 498)}, 15 {:id 15, :title "PcTVI: Parallel MDP Solver Using a Decomposition Into Independent Chains", :authors (257 158 572), :abstract "Markov Decision Processes (MDPs) are useful to solve real-world probabilistic \r\nplanning problems [1]. However, finding an optimal solution in an MDP\r\ncan take an unreasonable amount of time when the number of states in the\r\nMDP is large. In this paper, we present a way to decompose an MDP into\r\nStrongly Connected Components (SCCs) and to find dependency chains for\r\nthese SCCs. We then propose a variant of the Topological Value Iteration\r\n(TVI) algorithm [2], called parallel chained TVI (pcTVI), which is able to\r\nsolve independent chains of SCCs in parallel leveraging modern multicore\r\ncomputer architectures. The performance of our algorithm was measured by\r\ncomparing it to the baseline TVI algorithm on a new probabilistic planning\r\ndomain introduced in this study. Our pcTVI algorithm led to a speedup\r\nfactor of 20, compared to traditional TVI (on a computer having 32 cores).\r\n\r\nReferences\r\n1. Mausam, Kolobov: Planning with Markov Decision Processes: An AI Perspective.\r\n   Morgan & Claypool (2012)\r\n2. Dai, Mausam, Weld, Goldsmith: Topological value iteration algorithms. J. Artif.\r\n   Intell. Res., vol. 42, pp. 181–209 (2011)\r\n", :session 56, :keywords (340 484 615 140 464)}, 48 {:id 48, :title "Improving Classification of Documents by Semi-Supervised Clustering \r\nin a Semantic Space", :authors (263 226), :abstract "In the paper we propose method for representation of documents in a semantic \r\nlowerdimensional space based on the modified Reduced k-means method which penalize\r\nclusterings that are distant from classification of train documents given by experts.\r\nIterative method of the Reduced k-means (RKM) [1] enables simultaneously clustering \r\nof documents and extraction of factors. By projection of documents represented in the \r\nvector space model on extracted factors, documents are clustered in the semantic space \r\nin a semi-supervised way because clustering is guided by classification given by experts, \r\nwhich enables improvement of classification performance of test documents.\r\n  Classification performance is tested for classification by logistic regression and support \r\nvector machines (SVMs) for classes of Reuters-21578 data set. It is shown that representation \r\nof documents by the RKM method with penalization improves average precision of classification \r\nfor 25 largest classes of Reuters collection for about 5,5% with the same level of average \r\nrecall  in comparison to the basic representation in the vector space model. In the case on \r\nclassification by logistic regression, representation by the RKM with penalization improves \r\naverage recall for about 1% in comparison to the basic representation.\r\n\r\nReferences\r\n1. De Soete, G., Carroll, J.D.: K-means clustering in a low-dimensional Euclidean space.\r\n   In: Diday, E., Lechevallier, Y., Schader, M., Bertrand, P., Burtschy, B. (eds.) New \r\n   Approaches in Classification and Data Analysis. Studies in Classification, Data Analysis, \r\n   and Knowledge Organization, pp. 212-219. Springer, Heidelberg (1994)", :session 35, :keywords (64 330 526)}, 242 {:id 242, :title "Predictors of Quantitative Skills in Degree Schemes at University", :authors (22 7 24 107 84), :abstract "In the United Kingdom, students are required to study mathematics up until the age\r\nof 16. After this age it ceases to become compulsory, despite students remaining in\r\neducation until the age of 18. This means that only 20% of students on UK degree\r\nschemes have studied mathematics between the ages of 16-18 [1]. Comparing this\r\nfigure with over 50% uptake in comparable countries, the UK falls short in terms of\r\nmaths skills in Higher Education and industry [2].\r\n  In this paper, we will discuss the findings of a two-wave study that we conducted at\r\na UK Higher Education institution with first-year undergraduate students. We conducted \r\nthe first wave of the study at the start of the university term to understand the\r\neffect mathematical literacy has on their maths and statistics performance. Further,\r\nwe investigated the extent maths anxiety, personality traits and metacognition impact \r\non their performance accuracy. Results showed that post-16 mathematics, low\r\nmathematics anxiety, low conscientiousness and low extraversion were associated\r\nwith better maths and statistics performance at the start of the university term. Only\r\nhigher agreeableness (working with others) was associated with higher improvement\r\nof maths and statistics performance after one term.\r\n\r\nReferences\r\n1. Smith, A.: Report of Professor Sir Adrian Smith’s review of post-16 mathematics. London:\r\n   DfE (2017)\r\n2. Hodgen, J., Pepper, D., Sturman, L., Ruddock, D.: Is the UK an outlier? An international\r\n   comparison of upper secondary mathematics education. The Nuffield Foundation (2010)", :session 30, :keywords (480 342 91)}, 50 {:id 50, :title "Clustering Validation in Hierarchical Cluster Analysis: an Empirical Study", :authors (426 73 225), :abstract "The evaluation of clustering structures is a crucial step in cluster analysis. This study\r\npresents the main results of the hierarchical cluster analysis of variables concerning\r\na real dataset in the context of Higher Education. The goal of this research is to find\r\na typology of some relevant items taking into account both the homogeneity and\r\nthe isolation of the clusters. Two similarity measures, namely the standard affinity\r\ncoefficient and Spearman’s correlation coefficient, were used, and combined with\r\nthree probabilistic (AVL, AVB and AV1) aggregation criteria, from a parametric family\r\nin the scope of the VL (Validity Link) methodology [1]. The best partitions were\r\nselected based on some validation indices, namely the global STAT levels statistics\r\nand the measures P(I2, \\Sigma) and \\gamma [2], adapted to the case of similarity \r\ncoefficients [3]. In order to evaluate the clusters and identify their most representative \r\nelements, the Mann and Whitney U statistics and the silhouette plot were also used.\r\n\r\nReferences\r\n1. Bacelar-Nicolau, H.: Contributions to the Study of Comparison Coefficients in Cluster Analysis \r\n  (in Portuguese). Univ. Lisbon (1980)\r\n2. Gordon, A.D.: Classification, 2nd Ed. Chapman & Hall, London (1999)\r\n3. Silva, O., Bacelar-Nicolau, H., Nicolau, F.C., Sousa, A.: Probabilistic approach for \r\n   comparing partitions. In: Manca, R., McClean, S., Skiadas, C.H. (eds.) New Trends in \r\n   Stochastic Modeling and Data Analysis, pp. 113-122. ISAST (International Society for \r\n   the Advancement of Science and Technology), Athens (2015)", :session 10, :keywords (77 7 595 680)}, 251 {:id 251, :title "Biplot Representation of Partial Least Squares Regression for Binary Responses", :authors (325 287), :abstract "In this work we describes biplot representation for visualization of Partial Least\r\nSquares Regression for Binary Responses (PLS-BLR). The PLS-BLR is a generalization \r\nof Partial Least Squares Regression [3] to handle a matrix of continuous predictors \r\nand a set of binary responses. The resulting biplot will be a combination of a traditional \r\nrepresentation for numeric data and a Logistic Biplot as described by [2] or [1].\r\n  First we describe the base methods, PLSR, PLSR-BLR and their associated biplots, then \r\nthe connection among them. Finally we present an application to real data.\r\n  Software packages for the calculation of the main results are also provided.\r\n\r\nReferences\r\n1. Demey, J., Vicente-Villardon, J.L., Galindo, M.P., Zambrano, A.: Identifying Molecular \r\n   Markers Associated With Classification Of Genotypes Using External Logistic Biplots. \r\n   Bioinform., 24(24),2832-2838, 2008\r\n2. Vicente-Villardon, J.L., Galindo, M.P., Blazquez-Zaballos, A.: Logistic biplots. In: \r\n   Greenacre, M., Blasius, J. (eds.) Multiple Correspondence Analysis and related methods., \r\n   pp. 503-521. Chapman and Hall, New York (2006)\r\n3. Wold., H.: Soft modeling by latent variables: the nonlinear iterative partial least squares\r\n   (NIPALS) approach. J. Appl. Probab. , 12(S1), 117-142, (1975)", :session 55, :keywords (40 37 486 488)}, 116 {:id 116, :title "Robustness and Initialization Issues in Subspace Clustering", :authors (338 12), :abstract "Observations are often assumed to cluster around lower-dimensional affine linear\r\nsubspaces. In fact, this is one of the most frequently applied approaches when\r\ndealing with high or moderately high dimensional clustering problems. There are\r\nseveral subspace clustering approaches in the literature that attempt to find such\r\nclusters and their associated optimal underlying subspaces.\r\n  The detrimental effect that even a few outliers can have on cluster analysis,\r\nsometimes affecting even the correct determination of clusters, is well known. Robust\r\nsubspace clustering methods try to discover those linear subspaces while avoiding\r\nthe effect of outlying values. Detecting anomalies in the data can be an interesting\r\nproblem in itself, as well as taking advantage of the subspace clustering structure to\r\n”reconstruct” the data prior to the data contamination process.\r\n  Some robustified subspace clustering methods, that follow from the application of\r\ntrimming principles, will be reviewed. A proportion \\alpha of entire cases were proposed\r\nto be trimmed in [1] and a proportion \\alpha of individual cells were trimmed in [2]. These\r\napproaches provide good robustness but require the specification of a trimming rate\r\n\\alpha. A proposal will be presented to determine \\alpha based on the data.\r\n  The initialization of the iterative algorithms used to implement these trimming\r\nprocedures is one of the most critical aspects for the good performance of these\r\nalgorithms. Useful initialization strategies will also be provided.\r\n\r\nReferences\r\n1. García-Escudero, L.A., Gordaliza, A., San Martin, R., Van Aelst, S., Zamar, R.: Robust linear\r\n   clustering. J. R. Stat. Soc. Ser. B 71, 301–318 (2009)\r\n2. García-Escudero, L.A., Rivera-García, D., Mayo-Iscar, A., Ortega, J.: Cluster analysis with\r\n   cellwise trimming and applications for the robust clustering of curves. Inf. Sci. 573, 100–124\r\n   (2021)", :session 70, :keywords (617 547 265)}, 75 {:id 75, :title "The Biplot Inner Product for Interpretation and Derivation of Eigenvector Methods", :authors (95), :abstract "To celebrate K. Ruben Gabriel’s biplot paper [1], I describe its influence, via my\r\nsupervisor Leo C. A. Corsten, on my first to last papers (1981-2021) and on my\r\nteaching. Being not just a plot of two sets of items, Gabriel’s biplot shifted attention\r\nfrom the meaning of individual PCA axes to inference from the first 2-3 axes together\r\nvia the inner product interpreted geometrically, namely as the product of the arrow\r\nlengths and the cosine of their angle or as the product of the lengths of the one\r\narrow and the other projected on to it. These simple equations cannot only be\r\nused for interpreting biplots, I will show that they can also be used to derive the\r\neigen equations. Whereas later, even non-linear, extensions turned the arrows in to\r\ncalibrated, possibly curved, lines, I always promoted inference using the rank order\r\nof the projection points.\r\n  Gabriel showed that the biplot could be used beyond PCA, for example, in canonical\r\ncorrelation analysis and variants thereof [2]. Double-constrained correspondence\r\nanalysis even allows for plots with four sets of items, pairs of which approximated\r\ndifferent summary statistics of the method [3].\r\n  I will also briefly describe how the distinction between predictive and interpolative\r\nbiplot was discovered and how multivariate analysis was taught in the 70-80s in\r\nFrance and Japan, compared to the English literature that was focussing more on\r\nweighted least-squares approximation and Gabriel’s biplot interpretation of factorial\r\ndiagrams.\r\n\r\nReferences\r\n1. Gabriel, K.R.: The biplot graphic display of matrices with application to principal \r\n   component analysis. Biometrika 58, 453–467 (1971)\r\n2. ter Braak, C.J.F.: Interpreting canonical correlation analysis through biplots of \r\n   structural correlations and weights. Psychometrika. 55, 519–531 (1990)\r\n3. ter Braak, C.J.F., Smilauer, P., Dray, S.: Algorithms and biplots for double constrained \r\n   correspondence analysis. Environ. Ecol. Stat. 25, 171–197 (2018)", :session 8, :keywords (40 285 474 48 159)}, 159 {:id 159, :title "Industry Sector Detection in Legal Articles Using Transformer-Based Deep Learning", :authors (232 525 585 491 85), :abstract "Industry analysis, which identifies multiple industry sectors hidden in massive legal\r\ntexts, could benefit greatly to business activities of legal professions such as \r\nimproving customer services by detecting overall industry trends across legal topics.\r\nHowever, manual industry labeling on enormous legal information will be expensive and \r\ntime-consuming. This research investigated an AI-powered approach to\r\nautomatically recognise industry sectors using transformer-based deep learning [1]\r\nwhich had shown advantages on a set of Natural Language Processing (NLP) tasks\r\nrecent years. In this study, a dataset consisting of over 1,700 annotated legal articles\r\nwas curated for the identification of six industry sectors. Two main research questions \r\nwill be answered by the outcome of our work: (1) Like other NLP tasks that\r\nmostly focus on the analysis at word token or sentence level, do transformer models\r\nalso perform well on the full-text articles? (2) Compared with large-scale general\r\ndomain data, could transformer models work effectively on a small legal-specific\r\ndomain dataset? Our experimental results showed that the transformer-based predictive \r\nmodels achieved the F1 scores ranged between 0.73 and 0.83 on the detection of\r\nthe six industry sectors. When the word sequence length was increased to 1,024 or\r\n2,048 words, the performance got slight worse compared with that of the relatively\r\nshort word sequences (e.g., 512). The research results suggested that transformer\r\nmodels are sensitive to the data size, text structure, and domain area to some extent.\r\n\r\nReferences\r\n1. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep \r\n   bidirectional transformers for language understanding. In: Proceedings of the \r\n   NAACL-HLT 2019 Conference, pp. 4171-86. Minnesota (2019)", :session 64, :keywords (282 635 653)}, 99 {:id 99, :title "Heterogeneous Random Forests", :authors (578 235), :abstract "Random forest (RF) is one of the most popular machine learning methods for classification \r\nproblems. Two factors that affect the performance of RF are known to be the accuracy of \r\nindividual trees and the diversity among trees. That is, the better the performance of each \r\nclassifier and the more heterogeneous the individual classifiers, the better the RF performance. \r\nIn this study, we propose a heterogeneous RF to increase the diversity of trees. The diversity \r\nwas induced by intentionally creating a tree that is heterogeneous from the previous trees. \r\nFeatures used for splitting near the root node of the previous tree have lower weights when \r\nconstructing the feature subspace of the next tree. Therefore, Features that were dominant in \r\nthe previous tree are less likely to be used in the next tree and splitting features of root nodes \r\nbecomes more diverse. As a result of comparing accuracy in several real data, Heterogeneous RF \r\nperformed better than RF in data with dominant variables.\r\n\r\nReferences\r\n1. Breiman, L. Random Forests. Machine Learning. 45, 5–32 (2001)\r\n2. Han, S., Kim, H. & Lee, Y.S. Double Random Forest. Machine Learning. 109, \r\n   1569–1586 (2020)\r\n3. Simon Bernar, Sebastien Adam & Laruent Heutte. Dynamic Random Forests. Pattern \r\n   Recognition Letters, Elsevier. 33(12), 1580–1586 (2012)", :session 9, :keywords (179 516 133)}, 21 {:id 21, :title "Penalized Model-Based Functional Clustering: a Regularization Approach via \r\nShrinkage Methods", :authors (415 484 337 501), :abstract "With the advance of modern technology, and with data being recorded continuously,\r\nfunctional data analysis has gained a lot of popularity in recent years. Working\r\nin a mixture model-based framework, we develop a flexible functional clustering\r\ntechnique achieving dimensionality reduction schemes through a L_1 penalization.\r\nThe proposed procedure results in an integrated modelling approach where shrinkage\r\ntechniques are applied to enable sparse solutions in both the means and the covariance\r\nmatrices of the mixture components, while preserving the underlying clustering\r\nstructure. This leads to an entirely data-driven methodology suitable for simultaneous\r\ndimensionality reduction and clustering. Preliminary experimental results, both from\r\nsimulation and real data, show that the proposed methodology is worth considering\r\nwithin the framework of functional clustering.\r\n\r\n", :session 28, :keywords (217 310 569 248 374)}, 31 {:id 31, :title "Emotion Classification Based on Single Electrode Brain Data: \r\nApplications for Assistive Technology", :authors (143 341 93), :abstract "This research case focused on the development of an emotion classification system\r\naimed to be integrated in projects committed to improve assistive technologies.\r\nAn experimental protocol was designed to acquire an electroencephalogram (EEG)\r\nsignal that translated a certain emotional state. To trigger this stimulus, a set of\r\nclips were retrieved from an extensive database of pre-labeled videos[1]. Then,\r\nthe signals were properly processed, in order to extract valuable features [2] and\r\npatterns to train the machine and deep learning models.There were suggested 3\r\nhypotheses for classification: recognition of 6 core emotions; distinguishing between\r\n2 different emotions and recognising if the individual was being directly stimulated\r\nor merely processing the emotion. Results showed that the first classification task\r\nwas a challenging one, because of sample size limitation. Nevertheless, good results\r\nwere achieved in the second and third case scenarios (70% and 97% accuracy scores,\r\nrespectively) through the application of a recurrent neural network.\r\n\r\nReferences\r\n1. Cowen, A., Keltner, D.: Self-report captures 27 distinct categories of emotion bridged by\r\n   continuous gradients In: Proceedings of the National Academy of Sciences of the United\r\n   States of America (2017) doi: 10.1073/pnas.1702247114.\r\n2. Jenke, R., Peer, A., Buss, M.: Feature Extraction and Selection for Emotion Recognition from\r\n   EEG. In: IEEE Transactions on Affective Computing, vol. 5, no. 3, pp. 327-339, (2014) \r\n   doi: 10.1109/TAFFC.2014.2339834", :session 31, :keywords (178 46 171 334)}, 113 {:id 113, :title "Detecting Fabricated Interviews Using the Hamming Distance", :authors (280), :abstract "In the research literature on survey methodology, there is considerable discussion\r\nof interviewer effects and how to prevent data fabrication; however, there is little\r\ndiscussion on the detection of data fabrication by interviewers in published data,\r\nand there are even fewer papers examining the phenomenon of employees of survey\r\nresearch organizations fabricating data. Among them, Blasius and Thiessen ([1])\r\nshow for the PISA 2009 principal data that employees of survey research organizations \r\nin some countries duplicate cases to generate data. While the authors focus on\r\nexact copies, more sophisticated data fabrication techniques might include duplicating \r\nwhole cases and changing a few entries afterwards. By calculating Hamming distances and \r\napplying them to the same data, we show that - in some countries in particular - large \r\nparts of the data have been duplicated, and most of them have been retrospectively modified \r\nto a small degree.\r\n\r\nReferences\r\n1. Blasius, J., Thiessen, V.: Should we trust survey data? Assessing response simplification \r\n   and data fabrication. Soc.Sci.Res. 52, 479–493 (2015)", :session 44, :keywords (199 614 482)}, 32 {:id 32, :title "Latent Block Regression Model", :authors (467 326 408), :abstract "When dealing with high dimensional sparse data, such as in recommender systems,\r\nco-clustering turns out to be more beneficial than one-sided clustering, even if one\r\nis interested in clustering along one dimension only. Thereby, co-clusterwise is a\r\nnatural extension of clusterwise. Unfortunately, all of the existing approaches do not\r\nconsider covariates on both dimensions of a data matrix. In this paper, we propose\r\na Latent Block Regression Model (LBRM) overcoming this limit. For inference,\r\nwe propose an algorithm performing simultaneously co-clustering and regression\r\nwhere a linear regression model characterizes each block. Placing the estimate of the\r\nmodel parameters under the maximum likelihood approach, we derive a Variational\r\nExpectation-Maximization (VEM) algorithm for estimating the model’s parameters.\r\nThe finality of the proposed VEM-LBRM is illustrated through simulated datasets.\r\n\r\n", :session 34, :keywords (80 79 632 126)}, 136 {:id 136, :title "Mispecification Tests for Hidden Markov Models Based on a New Class of Finite Mixture Models", :authors (190 513 196), :abstract "In the context of longitudinal data, we show that a general class of hidden Markov\r\n(HM, [1]) models may be equivalent to a class of finite mixture (FM, [3]) models\r\nbased on an augmented set of components and suitable constraints on the conditional\r\nresponse probabilities, given these components. We formulate a misspecification test\r\nfor the latent structure of an HM model comparing maximum likelihood values of\r\nthe two models for the same data, and when the number of possible latent state\r\nsequences is excessive, we propose a multiple version of this test including the\r\nBonferroni correction. The procedure is simple since it is based on the output\r\nof the Expectation-Maximization estimation algorithm [2]. The properties of this\r\ntesting procedure are evaluated through a simulation study. An empirical application\r\nillustrates it through data from the National Longitudinal Survey of Youth, in which\r\nwe jointly consider wages and years of experience after labour force entry. We show\r\nthat the proposed testing procedure may also be used as an alternative model selection\r\ncriterion for the number of latent states of an HM model to those usually employed.\r\n\r\nReferences\r\n1. Bartolucci, F., Farcomeni, A., Pennoni, F.: Latent Markov Models for Longitudinal Data. \r\n   Boca Raton FL: Chapman & Hall/CRC. Taylor & Francis (2013)\r\n2. Dempster, A.P., Laird, N.M., Rubin, D.B.: Maximum likelihood from incomplete data via the\r\n   EM algorithm (with discussion). J. R. Stat. Soc. 39, 1–38, (1977)\r\n3. McLachlan, G., Lee, S.X., Rathnayake, S.I.: Finite mixture models. Annu. Rev. Stat. Appl.\r\n   10, 355–378 (2019)", :session 79, :keywords (191)}, 139 {:id 139, :title "Analyzing the Evolution of EU Countries and Indicators of Europe 2020 Agenda", :authors (5 181), :abstract "In this study we analyze the evolution of the European Union countries and of some\r\nindicators of Europa 2020 agenda in the following areas: Employment, Education,\r\nResearch and Development, Poverty and Social Exclusion, and Climate Change and\r\nEnergy. More precisely, we collected data from Pordata during the period 2010-\r\n2019 on the following indicators: employment rate; early leavers from education and\r\ntraining rate; population, aged 30 to 34, with higher education; expenditure on R&D\r\nas % of GDP; population at risk of poverty; greenhouse gas emissions; renewable\r\nenergy consumption; primary energy consumption; final energy consumption.\r\nWe start with a preliminary data analysis, and some countries appear as outliers in\r\nsome of the variables and for some years of the period, which would be expected.\r\nHowever, we highlight that Luxembourg is a severe outlier and had to be discarded\r\nfrom the analysis to allow a better comparison and differentiation of the other\r\ncountries. Additionally, as we do not have all the target values for the United Kingdom\r\nand for the variable population at risk of poverty, we did not consider this country\r\nand variable in the further multivariate analysis. We applied the Statis methodology,\r\ndeveloped in [1] and [2], to analyze the evolution of the European countries and of\r\nthe indicators referred above, during the period 2010-2019. The trajectories of the\r\ncountries and of the variables under study along the period 2010-2019 help us to\r\nunderstand how the Europe 2020 strategy is being achieved.\r\n\r\nAcknowledgements This work is financed by National Funds through the Portuguese funding\r\n                 agency, FCT - Fundação para a Ciência e a Tecnologia, within the projects \r\n                 LA/P/0063/2020 (INESC TEC) and UIDB/00006/2020 (CEAUL).", :session 40, :keywords (186 187 606)}, 174 {:id 174, :title "Clustering Count Data Using Compositional Methods", :authors (350 289 218 590), :abstract "Multivariate count data are multivariate vectors of non-negative integers. When\r\nthe total number of counts depends on varying external factors (e.g. duration of the\r\ncounting process or ability to measure a count), the relative magnitude of the observed\r\nvalues is of special importance. These data are called point-counting data in some\r\napplied fields, and they are affected by compositional variability and multinomial\r\ncounting uncertainties [4]. For clustering analysis purposes, it is crucial to consider\r\nboth sources of variability. Compositional variability is commonly modeled using\r\nthe Dirichlet or the logratio-normal distribution, leading respectively to the classical\r\nDirichlet-multinomial distribution and the logratio-normal-multinomial (LRNM)\r\ndistribution [2]. In model-based clustering, these models are usually included as\r\ncomponents in a finite mixture model [1,3].\r\n  In this contribution, we propose a fast approach for clustering analysis of pointcounting \r\ndata based on the LRNM model. A part of the procedure takes care of the\r\ncompositional aspect through logratio coordinates, including the treatment of zero\r\ncounts as necessary. Moreover, through the computation of the posterior distribution\r\nconditioned to the measured variability and the observed data, the multinomial\r\nvariability is accounted for by using simulated samples of the latent compositional\r\nprocess. These samples are combined into a final partition of the original sample by\r\nusing clustering ensembling methods. We will illustrate our proposal using different\r\ndatasets.\r\n\r\nReferences\r\n1. Comas-Cufí, M., Martín-Fernández, J.A., Mateu-Figueras, G. and Palarea-Albaladejo, J.:\r\n   Model-based clustering of count data based on the logistic-normal-multinomial distribution.\r\n   2017 International Federation of Classification Societies Conference, Tokyo, Japan (2017)\r\n2. Comas-Cufí, M., Martín-Fernández, J.A., Mateu-Figueras, G. and Palarea-Albaladejo, J.:\r\n   Modelling count data using the logratio-normal-multinomial distribution. SORT 44(1), \r\n   99–126 (2020)\r\n3. Fang, Y. and Subedi, S.: Clustering microbiome data using mixtures of logistic normal \r\n   multinomial models. arXiv preprint: 2011.06682 (2020)\r\n4. Vermeesch, P.: Statistical models for point-counting data. Earth and Planetary Science Letters\r\n   501, 112–118 (2018)", :session 42, :keywords (405 75 88)}, 284 {:id 284, :title "Perturb and conquer. How classification can benefit from data perturbation", :authors (53), :abstract "Data perturbation has a longstanding tradition in statistics. The bootstrap method\r\nand random forests are evergreen examples in this stream. The focus, in this talk,\r\nwill be on the use of data perturbation for classification purposes. In particular, we\r\nwill focus on perturbations obtained by random projections [1] and we will address\r\nissues ranging from variable selection [2] to imbalanced classes [3], from data shift\r\nto semi-supervised learning.\r\n\r\nThe content of the talk is a joint work with Laura Anderlucci, Department of\r\nStatistical Sciences University of Bologna.\r\n\r\nReferences\r\n1. Cannings, T.I., Samworth, R.J.: Random-projection ensemble classification. J. R. Stat. Soc.\r\n   B 79, 959–1035 (2017)\r\n2. Fortunato, F., Anderlucci, L., Montanari, A.: One-class classification with application to\r\n   forensic analysis. J. R. Stat. Soc. C 69, 1227–1249 (2020)\r\n3. Falcone, R., Anderlucci, L., Montanari, A.: Matrix sketching for supervised classification \r\n   with imbalanced classes. Data Mining and Knowledge Discovery 36, 174–208 (2022)", :session 51, :keywords (519 128 276)}, 208 {:id 208, :title "Exact Computation of the Angular Halfspace Depth", :authors (522 468), :abstract "Directional data arise naturally as observations lying in the unit sphere of a d-dimensional \r\nEuclidean space. The angular halfspace depth [2] is a nonparametric tool for the analysis of \r\ndirectional data, with wide applications in e.g. classification and pattern recognition tasks. \r\nThe angular halfspace depth was proposed already in 1987 in [3], but its widespread use has been \r\nhampered in practice by significant computational issues. We address these problems by considering \r\na simple projection scheme that allows reducing the computation of the angular halfspace depth to the\r\ntask of evaluating a variant of the usual halfspace depth in a linear space [1]. Efficient algorithms \r\nfor exact computation and approximation of the angular halfspace depth are thus developed.\r\n\r\nReferences\r\n1. Dyckerhoff, R., Mozharovskyi, P.: Exact computation of the halfspace depth. Comput. Statist.\r\n   Data Anal. 98, 19–30 (2016)\r\n2. Liu, R.Y., Singh, K.: Ordering directional data: concepts of data depth on circles and spheres.\r\n   Ann. Statist. 20(3), 1468–1484 (1992)\r\n3. Small, C.G.: Measures of centrality for multivariate and directional distributions. Canad. J.\r\n   Statist. 15(1), 31–39 (1987)", :session 58, :keywords (13 89 151)}, 182 {:id 182, :title "True Sparsity Approaches in Classification via Conic Optimization", :authors (242 89), :abstract "Pursuing sparsity is an important issue in all classification tasks, in particular \r\nin view of the nowadays increasing popular move towards explainable machine learning.\r\nHere we address this quest by linking the exact sparsity term/zero norm\r\n\r\n    ||x||_0 = number of nonzero xi ’s\r\n\r\nto copositive optimization. We present a novel, purely continuous model, which\r\navoids any branching or use of large constants in implementation. The resulting model\r\nis a (nonconvex) quadratic optimization problem with complementarity constraints.\r\nWe show that the copositive formulation is exact under mild conditions involving\r\nonly the constraints, not the (classifying criterion) objective, and discuss strong\r\nduality to ensure tight bounds. The covered problem class includes sparse leastsquares \r\nregression under linear constraints as well. Numerical comparisons between\r\nour method and other approximations are reported from the perspective of criterion\r\nvalue.\r\n\r\n", :session 80, :keywords (587 103 96)}, 256 {:id 256, :title "A Showcase of New Methods for High Dimensional Data Viewing with Linear\r\nProjections and Sections", :authors (135), :abstract "In the last few years there have been several huge strides in new methods available\r\nfor exploring high-dimensional data using tours. Tours is the collective term for\r\nvisualisations built on linear projections. Tours have two key elements: the path that\r\ngenerates a sequence, and the display to make of the low-dimensional projection.\r\nThere are numerous path algorithms available (and implemented in the tourr [1]\r\nR package), including the old (grand, guided, little, local, manual), and the new\r\n(slice [2], sage [3]). This talk will show off these new tools and how they can be used\r\nfor several contemporary problems, including understanding nonlinear dimension\r\nreductions (e.g. t-SNE) using the liminal [4] R package, and explainable artificial\r\nintelligence (XAI) using the cheem [5] R package. Step into the fascinating world of\r\nhigh-dimensions with me.\r\n\r\nThis most recent methodology is joint with primarily Ursula Laa, German Valencia,\r\nStuart Lee and Nicholas Spyrison.\r\n\r\nReferences\r\n1. H. Wickham, D. Cook, H. Hofmann, and A. Buja. tourr: An R package for exploring\r\n   multivariate data with projections. Journal of Statistical Software, 40(2):1–18, 2011. \r\n   URL http://www.jstatsoft.org/v40/i02/.\r\n2. U. Laa, D. Cook, and G. Valencia. A slice tour for finding hollowness in high-dimensional\r\n   data. Journal of Computational and Graphical Statistics, 29(3):681–687, 2020. \r\n   URL https://doi.org/10.1080/10618600.2020.1777140.\r\n3. U. Laa, D. Cook, and S. Lee. Burning sage: Reversing the curse of dimensionality in the\r\n   visualization of high-dimensional data. Journal of Computational and Graphical Statistics,\r\n   31(1):40–49, 2022. URL https://doi.org/10.1080/10618600.2021.1963264.\r\n4. S. Lee. liminal: Multivariate data visualization with tours and embeddings, 2021. \r\n   URL https://CRAN.R-project.org/package=liminal. R package version 0.1.2.\r\n5. N. Spyrison cheem: Interactively Explore the Support of Local Explanations with the Radial\r\n   Tour, 2022. URL https://CRAN.R-project.org/package=cheem. R package version 0.2.0.", :session 4, :keywords (607 197 651 691 630 514)}, 214 {:id 214, :title "Joint Sparse Principal Component Analysis", :authors (313), :abstract "Comparing multivariate relations between different groups forms the core of many\r\nstudies in the empirical sciences. Latent variable approaches such as principal \r\ncomponent and factor analysis are most useful (and used) to explore such multivariate\r\nrelations. The loadings are key to the interpretation of these latent variable models\r\nas they express the strength of association of the observed variables with the latent\r\nvariables. Preferably variables load on one or a few components/factors only and\r\nhave zero loadings elsewhere as this eases interpretation. In addition, when comparing \r\nmultiple groups, also a clear distinction between those variables that function\r\nin the same way over groups and those that do not is needed: Loadings should be\r\nexactly equal between those groups where the variables function in the same way\r\nand unequal elsewhere. In this paper we propose a multigroup latent variable model,\r\ncalled joint sparse principal component analysis, that has these properties. Sparsity\r\nis imposed using cardinality constraints while equal loadings are obtained as the\r\nresult of a fusion penalty. We efficiently solve the estimation problem by use of an\r\nalternating optimization procedure that includes the alternating direction method\r\nof multipliers (ADMM) as one of the steps. Tuning of the cardinality and fusion\r\npenalty is based on the index of sparseness. We illustrate with an example on the\r\nco-occurrence of experienced symptoms by cancer survivors belonging to different\r\ntumor types.\r\n\r\n", :session 27, :keywords (395 531 6)}, 193 {:id 193, :title "On Explaining Model Change Based on Feature Importance", :authors (385 172 78 170), :abstract "Understanding the decisions of complex machine learning (ML) models is vital for\r\nleveraging ML ethically and responsibly in everyday applications [1]. The research\r\nfield of Explainable Artificial Intelligence (XAI) aims at increasing the interpretability \r\nof otherwise opaque ML systems. While XAI mainly focuses on static learning\r\ntasks, we are interested in explaining models in dynamic learning environments,\r\nsuch as online learning from real-time data streams, where models are trained in an\r\nincremental rather than a batch mode. Models in such dynamic settings need to react\r\nand adapt to changes in their environment. We motivate the problem of explaining\r\nthese dynamic models by directly explaining the model change, i.e., the difference\r\nbetween models before and after adaptation, instead of the models per se. We discuss \r\nhow this problem may be approached by agnostic explanation methods such\r\nas Feature Importance (FI) and, more specifically, an adaption of the well-known\r\nPermutation Feature Importance (PFI) [2]. We present an incremental version of PFI\r\nand showcase how existing algorithms for detecting changes in data streams can be\r\nadapted to explain model change directly.\r\n\r\nAcknowledgements We gratefully acknowledge funding by the Deutsche Forschungsgemeinschaft\r\n                 (DFG, German Research Foundation): TRR 318/1 2021–438445824.", :session 54, :keywords (194 196 279 477)}, 241 {:id 241, :title "Predictors of Quantitative Skills in Degree Schemes at University", :authors (22 7 24 107 84), :abstract "In the United Kingdom, students are required to study mathematics up until the age\r\nof 16. After this age it ceases to become compulsory, despite students remaining in\r\neducation until the age of 18. This means that only 20% of students on UK degree\r\nschemes have studied mathematics between the ages of 16-18 [1]. Comparing this\r\nfigure with over 50% uptake in comparable countries, the UK falls short in terms of\r\nmaths skills in Higher Education and industry [2].\r\n  In this paper, we will discuss the findings of a two-wave study that we conducted at\r\na UK Higher Education institution with first-year undergraduate students. We conducted \r\nthe first wave of the study at the start of the university term to understand the\r\neffect mathematical literacy has on their maths and statistics performance. Further,\r\nwe investigated the extent maths anxiety, personality traits and metacognition impact \r\non their performance accuracy. Results showed that post-16 mathematics, low\r\nmathematics anxiety, low conscientiousness and low extraversion were associated\r\nwith better maths and statistics performance at the start of the university term. Only\r\nhigher agreeableness (working with others) was associated with higher improvement\r\nof maths and statistics performance after one term.\r\n\r\nReferences\r\n1. Smith, A.: Report of Professor Sir Adrian Smith’s review of post-16 mathematics. London:\r\n   DfE (2017)\r\n2. Hodgen, J., Pepper, D., Sturman, L., Ruddock, D.: Is the UK an outlier? An international\r\n   comparison of upper secondary mathematics education. The Nuffield Foundation (2010)", :session 67, :keywords (480 342 91)}, 226 {:id 226, :title "Misalignment of Spectral Data: Constrained Optimization in a Functional Data Analysis\r\nFramework", :authors (187 134 202), :abstract "Across several branches of sciences, a large number of applications involves data\r\nrepresented as functions and curves, for which functional data analysis can play a\r\ncentral role in solving a variety of problem formulations. With some thecnologies,\r\nthe obtained data are spectra containing a vast amount of information concerning the\r\ncomposition of a sample: in order to infer the chemical composition of the materials\r\nfrom spectra, functional data analysis offers a valuable mean for characterizing\r\nthe spectral response through identification of peaks position and intensity. The\r\ncollection of data from different measurement may exhibit similar peak pattern but\r\ndisplay misalignment in their peaks. In general, the multiple alignment is crucial in\r\nthe subsequent analysis; the method proposed faces with the challenge of random\r\nshifts in the peaks and implements constraints in a proper objective function to\r\noptimize the alignment. The constraints are based on a priori information that is\r\nformalized in the choice of a set of peaks across functions. Spectrum data from\r\nX-ray Fluorescence (XRF) and Total Reflectance-Fourier Transform Infra-Red (TRFTIR) \r\nspectroscopies are considered to illustrate the approach and to provide useful\r\ncomparison with other approaches.\r\n\r\nReferences\r\n1. Houhou, R., Rösch, P., Popp, J., Bocklitz, T.: Comparison of functional and discrete data\r\n   analysis regimes for Raman spectra. Anal. and Bioanal. Chem.413, 5633–5644, (2021)\r\n2. Marron, J.S., Ramsay, J.O., Sangalli L. M., Srivastava, A.: Functional Data Analysis of\r\n   Amplitude and Phase Variation. Stat. Sci. 30, No. 4, 468–484, (2015)\r\n3. Srivastava, A., Klassen, E.P.: Functional and Shape Data Analysis. Springer Series in \r\n   Statistics, Springer-Verlag, New York (2016)", :session 16, :keywords (414 217 104)}, 235 {:id 235, :title "A Geometric Perspective on Functional Outlier Detection", :authors (409 173), :abstract "Outlier detection in functional data faces specific challenges due to the information\r\nrich and complex nature of functional observations. We [1] consider the problem\r\nfrom a geometric perspective and present a general conceptualization based on the\r\nassumption that functional datasets are drawn from a manifold defined by the data’s\r\nmodes of variation in shape, translation, and phase. Theoretical and experimental\r\nanalyses demonstrate this conceptualization has important advantages. It considerably \r\nimproves theoretical understanding and allows to describe and analyze complex\r\nfunctional outlier scenarios consistently and in full generality, by differentiating \r\nbetween structurally anomalous outlier data that are off-manifold and distributionally\r\noutlying data that are on-manifold, but at its margins. From a practical perspective, \r\nwe show that well-established manifold learning methods can be used to learn low-dimensional \r\nvector-valued representations of functional observations to reliably infer and visualize the \r\ngeometric structure of functional datasets. Our experiments on synthetic and real data \r\ndemonstrate that using these representations in combination with the simple outlier scoring \r\nmethod  Local Outlier Factors (LOF) yields performances at least on par with existing \r\nfunctional-data-specific methods in a large variety of settings, without the highly specialized, \r\ncomplex methodology and narrow domain of application these methods often entail.\r\n\r\nReferences\r\n1. Herrmann, M., Scheipl F.: A geometric perspective on functional outlier detection. Stats 4,\r\n   971-1011 (2021)", :session 6, :keywords (217 454 336 149)}, 262 {:id 262, :title "Algorithms for Clustering COVID-19 Data: A Holistic Overview of Current Trends \r\nand New Visual Approaches", :authors (167), :abstract "COVID 19 was first discovered in China, and it spread worldwide and became a\r\npandemic. Since then, many researchers have tried to analyze the temporal tracking\r\nof cases and death of COVID-19. In this talk, we focused on the predictive models and\r\nclustering methods of the time series of growth rates regarding confirmed cases and\r\ndeaths of COVID-19. We reviewed the clustering method of time series data included\r\nin the papers since 2020. We compared various methods extensively, including\r\nthe classic statistical methods (k-means, PCA, factor analysis, etc.), fuzzy time\r\nseries models, functional data analysis models, and deep learning models. We also\r\noverviewed the visual approaches to the time course data and proposed new visual\r\napproaches. We applied these clustering and visualization methods to the cases and\r\ndeath of COVID-19 in each country for comparison.\r\n\r\n", :session 49, :keywords (116 641 68 679)}, 263 {:id 263, :title "A Wavelet-Mixed Effect Landmark Model for the Effect of Potassium and Biomarkers \r\nProfiles on Survival in Heart Failure Patients", :authors (100 215 189), :abstract "Statistical methods to study the association between a longitudinal biomarker and the\r\nrisk of death are a very relevant problem for the long-term monitoring of biomarkers.\r\nIn this context, sudden crises can cause the biomarker to undergo very abrupt changes.\r\nAlthough these oscillations are typically short-term, they often contain relevant\r\nprognostic information. We propose a method that couples a linear mixed-model\r\nwith a wavelet smoothing to extract both the long-term component and the shortterm \r\noscillations of the individual longitudinal biomarker profiles, and describe them\r\nas functional data.\r\n  We then use them as predictors in a landmark model to study their association\r\nwith the risk of death. To illustrate the method, we use clinical application which\r\nmotivated our work, i.e. the monitoring of potassium and related biomarkers in Heart\r\nFailure patients. The dataset consists of real-world data coming from the integration\r\nof Administrative Health Records and Outpatient and Inpatient Clinic E-chart from\r\nTrieste (Italy).\r\n  Our method not only allows us to identify the short-term oscillations, but also\r\nreveals their prognostic role, according to their duration, demonstrating the \r\nimportance of including them in the modeling. Compared to other state of the art methods\r\n(e.g., landmark analyses and joint models), our proposal archives higher predictive\r\nperformances. Our analysis has also an important clinical implications, since it allows \r\nus to derive a dynamic score that can be used in clinical practice to assess the\r\nrisk related to an observed patient’s potassium trajectory and then tune the actual\r\ndrug therapy she/he has to undergo.\r\n\r\n", :session 77, :keywords (369 311 646 215 252)}, 40 {:id 40, :title "Supervised Classification via Neural Networks for replicated Point Patterns", :authors (311 247 275), :abstract "A spatial point pattern is a collection of points observed in a bounded region of R^d,\r\nd ≥ 2. Individual points represent, e.g., observed locations of cell nuclei in a tissue\r\n(d = 2) or centers of undesirable air bubbles in industrial materials (d = 3). The main\r\ngoal of this paper is to show the possibility of solving the supervised classification\r\ntask for point patterns via neural networks with general input space [3]. To predict\r\nthe class membership for a newly observed pattern, we compute an empirical estimate of \r\na selected functional characteristic (e. g., the pair correlation function). Then,\r\nwe consider this estimated function to be a functional variable that enters the input \r\nlayer of the network. A short simulation example illustrates the performance of the proposed \r\nclassifier in the situation where the observed patterns are generated from two models with \r\ndifferent spatial interactions. In addition, the proposed classifier is compared with \r\nconvolutional neural networks [1] (with point patterns represented by binary images) and kernel \r\nregression. Kernel regression classifiers for point patterns have been studied in our previous \r\nwork [2], and we consider them a benchmark in this setting.\r\n\r\nReferences\r\n1. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press, Cambridge (2016)\r\n2. Konasova, K., Dvorak, J.: Techniques from functional data analysis adaptable for spatial point ´\r\n   patterns (2021) Available as a part of the Proceedings of the 22nd European Young Statisticians\r\n   Meeting. https://www.eysm2021.panteion.gr/publications.html. Cited 10 Jan 2022\r\n3. Thind, B., Multani, K., Cao, J.: Deep Learning with Functional Inputs (2020) Available via\r\n   arxiv. https://arxiv.org/pdf/2006.09590.pdf. Cited 10 Jan 2022", :session 84, :keywords (594 459 618 428 215)}, 129 {:id 129, :title "Kurtosis-Based Projection Pursuit for Matrix-Valued Data", :authors (553 315 284), :abstract "A classical problem in image processing is that of discriminatory feature extraction,\r\nwhere gray-scale images are naturally represented as matrices. We develop\r\nprojection pursuit for data that admit a natural representation in matrix form, where\r\nanother common data type admitting this representation is e.g. a univariate spatial\r\ndata collected on a regular grid. For projection indices we propose extensions of\r\nthe classical kurtosis and Mardia’s multivariate kurtosis. The first index estimates\r\nprojections for both sides of the matrices simultaneously, while the second index\r\nfinds the two projections separately. Both indices are shown to recover the optimally\r\nseparating projection for two-group Gaussian mixtures in the full absence of any\r\nlabel information. We further establish the strong consistency of the corresponding\r\nsample estimators. Simulations and a real data example on hand-written postal code\r\ndata are used to demonstrate the method.\r\n\r\nReferences\r\n1. Radojicic, U., Nordhausen, K., and Virta, J.: Kurtosis-based projection pursuit \r\n   for matrix-valued data. arXiv preprint arXiv:2109.04167 (2021).", :session 14, :keywords (155 345 522)}, 91 {:id 91, :title "Are Attitudes Toward Immigration Changing in Europe? An Analysis Based on\r\nlatent Class IRT Models", :authors (169 190), :abstract "We analyze the changing attitudes toward immigration in EU host countries in the last\r\nfew years (2010-2018) on the basis of the European Social Survey data. These data are\r\ncollected by the administration of a questionnaire made of items concerning different\r\naspects related to the immigration phenomenon. For this analysis, we rely on a latent\r\nclass approach considering a variety of models that allow for:(i) multidimensionality;\r\n(ii) discreteness of the latent trait distribution; (iii) time-constant and time-varying\r\ncovariates; and (iv) sample weights. Through these models we find latent classes of\r\nEuropeans with similar levels of immigration acceptance and we study the effect of\r\ndifferent socio-economic covariates on the probability of belonging to these classes\r\nfor which we provide a specific interpretation. In this way we show which countries\r\ntend to be more or less positive toward immigration and we analyze the temporal\r\ndynamics of the phenomenon under study.\r\n\r\n", :session 23, :keywords (153)}, 117 {:id 117, :title "A General Framework for Implementing Distance Measures for Categorical Variables", :authors (96 394 25 55), :abstract "In many statistical methods, distance plays an important role. For instance, data \r\nvisualization, classification and clustering methods require quantification of \r\ndistances among objects. How to define such distance depends on the nature of the \r\ndata and/or problem at hand. For distance between numerical variables, in particular \r\nin multivariate contexts, there exist many definitions that depend on the actual observed\r\ndifferences between values. It is worth underlining that often it is necessary to rescale\r\nthe variables before computing the distances. Many distance functions exist for numerical \r\nvariables, see [2] for a detailed list. For categorical data, defining a distance\r\nis even more complex as the nature of such data prohibits straightforward arithmetic\r\noperations. Specific measures therefore need to be introduced that can be used to\r\ndescribe or study structure and/or relationships in the categorical data. In this paper,\r\nwe introduce a general framework that allows an efficient and transparent implementation \r\nfor distance between categorical variables. We show that several existing distances (for \r\nexample a distance measure proposed by Ahmad and Dey [1] that incorporates association among \r\nvariables) can be incorporated into the framework. Moreover, our framework quite naturally \r\nleads to the introduction of new distance formulations as well.\r\n\r\nReferences\r\n1. Ahmad, A. and Dey, L.: A k-mean clustering algorithm for mixed numeric and categorical\r\n   data. Data & Knowledge Engineering, 63, 2, 503–3527 (2007)\r\n2. Mardia, K.V.: Some properties of classical multidimesional scaling. Communications in \r\n   Statistics - Theory and Methods, 7, 13, 1233–1241 (1978)", :session 50, :keywords (49 156 68)}, 172 {:id 172, :title "Uncovering Regions of Maximum Dissimilarity on Random Process Data", :authors (400 198), :abstract "Everyday millions of data patterns flow around the world at unprecedented speed,\r\nthus leading to an explosion on the demand for modeling stochastic process data—\r\nsuch as time series, point processes, and functional data; each of these types of data\r\nplays a key role in machine learning, as can be seen, for instance, from the recent\r\npapers of [1], [2], and [3]. Hand in hand with this shock on demand arrived a pressing\r\nneed for the development of data-intensive methods, techniques, and algorithms for\r\nlearning and comparing random processes.\r\nIn this talk, I will propose a statistical method that learns about regions with a\r\ncertain volume, where the marginal attributes of two processes are less similar. The\r\nproposed methods are devised in full generality for the setting where the data of\r\ninterest are themselves stochastic processes, and thus the proposed method can be\r\nused for pointing out the regions of maximum dissimilarity with a certain volume,\r\nin the contexts of functional data, time series, and point processes. The parameter\r\nfunctions underlying both stochastic processes of interest are modeled via a basis\r\nrepresentation, and Bayesian inference is conducted via an integrated nested Laplace\r\napproximation. The numerical studies validate the proposed methods, and we showcase \r\ntheir application with case studies on criminology, finance, and medicine.\r\n\r\nReferences\r\n1. José R Berrendero, Beatriz Bueno-Larraz, and Antonio Cuevas. On Mahalanobis distance in\r\n   functional settings. J. Machine Learning Res., 21(9)cl, 1–33 (2020).\r\n2. Johann Faouzi and Hicham Janati. pyts: A python package for time series classification. J.\r\n   Machine Learning Res., 21(46), 1–6 (2020).\r\n3. Ganggang Xu, Ming Wang, Jiangze Bian, Hui Huang, Timothy R. Burch, Sandro C. Andrade,\r\n   Jingfei Zhang, and Yongtao Guan. Semi-parametric learning of structured temporal point\r\n   processes. J. Machine Learning Res., 21(192), 1–39 (2020).", :session 24, :keywords (221 390 461 309 568 692)}, 108 {:id 108, :title "Analysis of the Changes in the Polish Traditional Drugstores Market During COVID-19", :authors (356 66 393), :abstract "The COVID-19 pandemic has a significant impact on different aspects of economy.\r\nUsually the impact on traditonal economy. The paper presents the results of the\r\nanalysis of the changes in the Polish traditional drugstores market during COVID-19\r\nsituation (from 2019 till 2021). Three different approaches with dynamic multidimensional \r\nscaling have been evaluated: classical data, symbolic interval-valued variables and symbolic \r\nhistogram variables. The results show that symbolic historgram variables are able to capture \r\nall the variability in the data and refect all the changes.\r\n\r\nReferences\r\n1. Bock H.-H., Diday E. (eds), Analysis of symbolic data. Exploratory statistics for complex.\r\n   Springer, Heidelberg (2002)\r\n2. de Carvalho, F.A.T.: Histograms in symbolic data analysis. Annals of Operations Research,\r\n   55(2), 299-322 (1995).\r\n3. Irpino, A., & Verde, R.: A new Wasserstein based distance for the hierarchical clustering of\r\n   histogram symbolic data. In Data science and classification (pp. 185-192). Springer, Berlin,\r\n   Heidelberg (2006)", :session 52, :keywords (270 416 162 117)}, 156 {:id 156, :title "Attitudes Toward Statistics in the 3rd Cycle of Basic Education in Portugal", :authors (6 37 453 43), :abstract "Statistics learning during the first school years is essential to provide all the citizens\r\nwith Statistical Literacy that allows them to correctly read statistical information.\r\nWhile attitudes towards Statistics is a topic widely investigated at university level,\r\nit is scarce for students in the 3rd cycle of basic education (12-15 years-old). The\r\nwell known questionnaire SATS-36© (Survey of Attitudes Toward Statistics, version\r\nPos) [1] was culturally adapted to Portuguese (European) language and for students\r\nof that school cycle. Based on a sample of 215 students from schools in the central\r\nregion of Portugal, a model with four factors (Affect, Interest, Value, and Effort) is\r\nproposed for the adapted scale. Randomly partitioning the data into a training sample\r\nand a test sample, the following analyses were performed to define the model: (i)\r\nExploratory Factorial Analysis on training samples, showing invariance property of\r\nthe 4-dimensional model; and (ii) Confirmatory Factorial Analysis on test samples,\r\nshowing adequacy of the 4-factorial structure. The structure of the proposed model\r\nis compared with (a few) other models proposed in other countries.\r\n\r\nAcknowledgements: Work partially supported by the Center for Research and Development \r\nin Mathematics and Applications (CIDMA, University of Aveiro) through\r\nFCT (Fundação para a Ciência e a Tecnologia), reference UIDB/04106/2020.", :session 67, :keywords (554 198 92)}, 223 {:id 223, :title "A Likelihood Ratio Test for Choosing Input  Parameters  in Robust Model Based \r\nClustering", :authors (338 12 210 358), :abstract "In the last twenty five years robust several proposals for maximum likelihood \r\nestimation based on trimming and constraints have been developed. For these \r\nprocedures, consistency results have been obtained and their robustness has been \r\njustified.\r\n  There remains an open issue, when applying estimators based on the joint application \r\nof trimming and constraints, related to choosing the number of clusters, the level\r\nof trimming and the strength of the constraints imposed on the components’ scatter\r\nmatrices. Some exploratory tools are available to help users make these decisions\r\nusing so-called “ctlcurves”.\r\n  A new parametric bootstrap-based likelihood ratio test procedure has been developed \r\nto identify combinations of input parameters associated to the most interesting\r\nclustering solutions. The statistical properties of this proposal and empirical evidence\r\non its performance when applied to artificial and real data, including contaminating\r\nobservations, will be presented.\r\n\r\n", :session 70, :keywords (382 658 101)}, 181 {:id 181, :title "Group Lasso Penalty for Spatially Clustered Coefficient Regression", :authors (550 307), :abstract "Spatial data has variables with location information. One of the main purposes of\r\nspatial data analysis is to explain the relationships between objective variables and\r\ncovariates according to this location information. Geographically weighted \r\nregression (GWR) [1] is a method that allows regression coefficients to vary by location.\r\nHowever, Li and Sang [3] showed that GWR can lead to numerical instability in estimations \r\nat locations with few surrounding observation points. They then proposed\r\nspatially clustered coefficients (SCC) regression using the fused lasso penalty. SCC\r\nenables the regression coefficients to be estimated with greater numerical stability\r\nthan in GWR.\r\n  However, these methods do not assume groups among the covariates. The results\r\nhence tend to be difficult to interpret.\r\n  Herein, we propose a method that combines SCC and the group lasso penalty [2].\r\nThe proposed method makes it easier for regression coefficients to be the same at\r\nnearby locations while facilitating interpretation by selecting covariates on a \r\ngroupby-group basis.\r\n\r\nReferences\r\n1. Brunsdon et al.: Geographically weighted regression : a method for exploring spatial \r\n   nonstationarity. Geographical Analysis 28, 281–298 (1996)\r\n2. Yuan, M. and Lin, Y.: Model selection and estimation in regression with grouped variables.\r\n   Journal of the Royal Statistical Society: Series B (Statistical Methodology) 68, 49–67 (2006)\r\n3. Li, F. and Sang, H.: Spatial homogeneity pursuit of regression coefficients for large datasets.\r\n   Journal of the American Statistical Association. 114, 1050–1062 (2019)", :session 60, :keywords (238 224 591)}, 56 {:id 56, :title "Optimized Symbolic Correspondence Analysis for Multi-Valued Variables", :authors (285 423), :abstract "In this paper, we propose an Optimized Correspondence Factorial Analysis (OCFA)\r\nmethod to analyze a data table with set-valued symbolic variables. This is an \r\nextension of Symbolic Correspondence Factorial Analysis (SCFA). OCFA is a combination \r\nbetween Symbolic Correspondence Factorial Analysis, based on an interval contingency \r\ndata table and integer optimization. The idea is to choose the best matrix of integer \r\nvalues inside the interval contingency data table. We are interested in studying two \r\ndifferent objective functions: the first one search to minimize the distance between \r\nprojections and the original points, while the second one search to maximize the \r\nexplained variance. To solve these problems, we generalize the concepts of row and column \r\nprofiles to interval row and interval column profiles, respectively. Further, we propose \r\ntwo theorems to find the coordinates of the interval contingency table in the factorial axes. \r\nAll of the methods proposed in this paper can be executed in the RSDA package, developed in R \r\nthat can be downloaded from CRAN.\r\n\r\nReferences\r\n1. Billard, L. and Diday, E. (2006). Symbolic Data Analysis: Conceptual Statistics and Data\r\n   Mining (United Kingdom: John Wiley & Sons Ltd)\r\n2. Rodriguez, O. (2021). RSDA: R to Symbolic Data Analysis. R package version 3.0.9\r\n3. Takagia, I. and Yadohisab, H. (2011). Correspondence analysis for symbolic contingency tables \r\n   based on interval algebra. Procedia Computer Science 6, 352–357. 10.1016/j.procs.2011.08.065", :session 15, :keywords (626 114 391 291)}, 33 {:id 33, :title "Political and Religion Attitudes in Greece: Behavioral Discourses", :authors (433 102), :abstract "The research presented in this paper attempts to explore the relationship between\r\nreligious and political attitudes. More specifically we investigate how religious \r\nbehavior, in terms of belief intensity and practice frequency, is related to specific\r\npatterns of political behavior such as ideology, understanding democracy and his set\r\nof moral values. The analysis is based on the use of multivariable methods and more\r\nspecifically Hierarchical Cluster Analysis and Multiple Correspondence Analysis\r\nin two steps. The findings are based on a survey implemented in 2019 on a sample of\r\n506 respondents in the wider area of Thessaloniki, Greece. The aim of the research is\r\nto highlight the role of people’s religious practice intensity in shaping their political\r\nviews by displaying the profiles resulting from the analysis and linking individual\r\nreligious and political characteristics as measured with various variables. The final\r\noutput of the analysis is a map where all variable categories are visualized, bringing\r\nforward models of political behavior as associated together with other factors such\r\nas religion, moral values and democratic attitudes.\r\n\r\nReferences\r\n1. Greenacre, M.: Correspondence Analysis in Practice. Chapman and Hall/CRC Press, Boca\r\n   Raton (2007)\r\n2. Marangudakis, M. Chadjipadelis, T.: The Greek Crisis and its Cultural Origins. Palgrave\r\n   Macmillan, New York (2019)\r\n3. Mayer, N.: Les modeles explicatifs du vote. L’Harmatan, Paris (1997)\r\n4. Michelat, G., Simon, M.: Classe, Religion et Comportement Politique. PFNSP-Editions \r\n   Sociales, Paris (1977)\r\n5. Panagiotidou, G., Chadjipadelis, T.: First-time Voters in Greece: Views and Attitudes of \r\n   Youth on Europe and Democracy. In Theodore Chadjipadelis, Berthold Lausen, Angelos Markos,\r\n   Tae Rim Lee, Angela Montanari and Rebecca Nugent (Eds), Studies in Classification, Data\r\n   Analysis and Knowledge Organization, 415-429, Springer (2020)\r\n6. Papadimitriou, G., Florou, G.: Contribution of the Euclidean and chi-square metrics to \r\n   determining the most ideal clustering in ascending hierarchy (in Greek). In Annals in Honor \r\n   of Professor I. Liakis, 546-581. University of Macedonia, Thessaloniki (1996)\r\n7. Rose, R.: Electoral Behavior: a comparative Handbook. Free Press, New York (1974)", :session 23, :keywords (491 533 137 408 125)}, 13 {:id 13, :title "Clustering and Blockmodeling Temporal Networks -- Two Indirect Approaches", :authors (571), :abstract "Two approaches to clustering and blockmodeling of temporal networks are presented:\r\nthe first is based on an adaptation of the clustering of symbolic data described by\r\nmodal values and the second is based on clustering with relational constraints.\r\nDifferent options for describing a temporal block model are discussed.\r\n\r\n", :session 7, :keywords (585 423 42 626 78)}, 22 {:id 22, :title "Detecting Differences in Italian Regional Health Services During Two Covid-19 Waves", :authors (336 476), :abstract "During the first two waves of Covid-19 pandemic, territorial healthcare systems\r\nhave been severely stressed in many countries. The availability (and complexity)\r\nof data requires proper comparisons for understanding differences in performance\r\nof health services. We apply a three-steps approach to compare the performance of\r\nItalian healthcare system at territorial level (NUTS 2 regions), considering daily time\r\nseries regarding both intensive care units and ordinary hospitalizations of Covid-19\r\npatients. Changes between the two waves at a regional level emerge from the main\r\nresults, allowing to map the pressure on territorial health services.\r\n\r\n", :session 72, :keywords (527 641 393 68 657)}, 257 {:id 257, :title "Monitoring Hyper-Parameter Choice for Robust Cluster Weighted Model", :authors (44 340 188 12), :abstract "The estimation of the Cluster Weighted Model is particularly attractive for providing\r\nexplicit modeling of the explanatory variables, in a mixture of regression. The Robust\r\nversion of the model requires the specification of a set of crucial parameters, like\r\nthe proportion of trimmed units \\alpha, the thresholds to be adopted for the constrained\r\nestimation of groups scatter and for regression errors, beyond the number of components \r\nof the Mixture. To assist the choice of such hyper-parameters, a monitoring\r\nmethodology could be of great help. The purpose is to provide a set of graphical tools\r\nto guide the final user in making an informed judgment, considering a landscape of\r\nplausible choices. The final output offers a set of optimal solutions, featured by the\r\ninterval of hyper-parameters values in which their optimality holds, their stability\r\nand validity. An assessment of the role and extent of the outlying observations has\r\nbeen provided, introducing three new silhouette plots. The purpose is to understand\r\nthe possible effects of the contaminated observations, with respect to the clustering\r\nof the covariate X, and the local regression lines Y, following the nature of the Cluster\r\nWeighted model.\r\n\r\nReferences\r\n1. Cappozzo, A., García Escudero, L.A., Greselin, F., and Mayo-Iscar, A.: Parameter Choice,\r\n   Stability and Validity for Robust Cluster Weighted Modeling. Stats 4 (3), 602–615 (2021).\r\n2. Riani, M., Atkinson, A.C., Cerioli, A., and Corbellini, A.: Efficient robust methods via\r\n   monitoring for clustering and multivariate data analysis. Pattern Recognit. 88, 246-260, (2019)\r\n3. Rousseeuw, P.J.: Silhouettes: a graphical aid to the interpretation and validation of cluster\r\n   analysis. J. Comput. Appl. Math. 20, 53–65 (1987)", :session 34, :keywords (74 455 656 173 388 386 544)}, 168 {:id 168, :title "Is It Hate or Criticism? An Exploratory Approach to Negative Comments on YouTube", :authors (349), :abstract "As many communities on YouTube develop around controversial topics, marginalized \r\nidentities, and extreme ideological positions, negative, anti-social or hateful\r\ncommenting behavior on YouTube has garnered increasing interest. Whereas previous \r\nstudies analyze these comments by sentiment analysis or use of profanity only,\r\nin this exploratory approach, the analysis of negative comments on YouTube is \r\nexpanded on by combining sentiment analysis [1], a dictionary approach for defining\r\nand matching video topics using automatically generated transcripts, a dictionary\r\nmatching for swear words [2], and video and comment metadata. A small group of\r\ncontent creators was selected for the analysis.\r\n  The combination of comment sentiment, the relation to a video and use of profanity \r\nallowed for the classification into four groups of different sizes: Impoliteness,\r\nIncivility, Flaming and Criticism [3].\r\n  Comparing approaches, sentiment analysis alone shows a similar prevalence of\r\nnegative comments between creators. When the classification is applied, a different\r\ndistribution of negative groups between the creators is observable along expectations.\r\nThe frequency, commonality, and difference of the language used show that while\r\nthe groups share multiple expressions, especially those carrying a negative sentiment\r\nvalue, they make distinct use of crucial terms. While this classification is valuable\r\nfor gaining insight and nuance into negative comments, some applicability issues for\r\nlarger studies will also be discussed.\r\n\r\nReferences\r\n1. Thelwall, M., Buckley, K., Paltoglou, G.: Sentiment strength detection for the social web.\r\n   Journal of the American Society for Information Science and Technology, 63(1), 163—173\r\n   (2012)\r\n2. Dumm, S., Niekler, A. Methoden, Qualitätssicherung und Forschungsdesign. In M. Lemke,\r\n   G. Wiedemann (eds.), Text Mining in den Sozialwissenschaften, pp. 89–116. Springer VS,\r\n   Wiesbaden (2015)\r\n3. Barnes, R. Uncovering Online Commenting Culture: Trolls, Fanboys and Lurkers. Palgrave\r\n   Macmillan, Cham (2018)", :session 35, :keywords (636 586 583 564)}, 90 {:id 90, :title "How to Mitigate the Effect of Outliers on Balancing Technique", :authors (471 361 118), :abstract "Imbalanced data brings additional difficulties to the analysis of the data since the\r\ndistribution of the number of observations across the known classes is skewed. The\r\nskewness implies that the number of observations in the Minority class is drastically\r\nsmaller than the number of observations in the Majority class. This is a problem\r\nsince, typically, the Minority class is the interesting and relevant class. Many real\r\nworld applications face this issue due to their natural characteristics, such as fraud\r\ndetection, rare disease detection, etc.\r\n  Balancing techniques are a common strategy to overcome imbalanced data problems,\r\nbut the presence of outliers may lead to bias and poor results, especially when the\r\noutliers are located in the Minority class and we use classical methods.\r\n  In this work, first, we illustrate the negative effect of outliers on the performance\r\nof classical balancing techniques. Next, we propose a robust balancing technique\r\nto mitigate the effect of outliers - named RM-SMOTE – which combines the idea\r\nof SMOTE with robust Mahalanobis distance. We propose to automatically down\r\nweight atypical Minority class observations so that they have a low chance of being\r\nselected in the resampling step.\r\n  The performance of the RM-SMOTE is evaluated using simulated data with different\r\nlevels of contamination, and benchmark imbalanced datasets. The results indicate\r\nthe superiority of RM-SMOTE when handling different proportions of outliers. In\r\ncases where the observations are not linearly separable, RM-SMOTE superiority is\r\neven more evident.\r\n\r\n", :session 21, :keywords (278 25 546 457 582)}, 237 {:id 237, :title "Significance Mode Analysis (SigMA) for hierarchical structures", :authors (505 549 288 298 242 523), :abstract "We present an innovative clustering method, Significance Mode Analysis (SigMA),\r\nto extract co-spatial and co-moving stellar populations from large-scale surveys such\r\nas ESA Gaia. The method studies the topological properties of the density field in the\r\nmultidimensional phase space. The set of critical points in the density field gives rise\r\nto the cluster tree, a hierarchical structure in which leaves correspond to modes of\r\nthe density function. Typically, however, non-parametric density estimation methods\r\nlead to an over-clustering of the input data. We propose an interpretable cluster tree\r\npruning strategy by determining minimum energy paths between pairs of neighboring modes \r\ndirectly in the input space. We test for deviations from unimodality along these paths, \r\nwhich provides a measure of significance for each pair of clusters.\r\n  We apply SigMA to Gaia data of the closest young stellar association to Earth,\r\nScorpio-Centaurus (Sco-Cen), and find 48 co-moving clusters in Sco-Cen. These\r\nclusters are independently validated using astrophysical knowledge, to a certain extent, \r\nby their association with massive stars too bright for Gaia, both unknown to SigMA. Our \r\nfindings suggest that Sco-Cen is more actively star-forming and dynamically richer than \r\npreviously thought. This application demonstrates that SigMA allows for an accurate census \r\nof young populations, quantify their dynamics, and reconstruct the recent star formation \r\nhistory of the local Milky Way.\r\n\r\n", :session 10, :keywords (380 71 611)}, 109 {:id 109, :title "Time Series of Counts Under Censoring", :authors (246 362 245 92), :abstract "Censored time series arise when explicit limits are placed on the observed data\r\nand occur in several fields including environmental monitoring, economics, medical\r\nand social sciences. The censoring may due to measuring device limitations, such\r\nas detection limits in air pollution or mineral concentration in water. Censoring\r\nmay also occur when constraints or regulations are imposed, such as in international \r\ntrade studies where exports and imports are subject to trade barriers or hours\r\nworked, often treated as censored variables. This work considers time series of counts\r\nunder censoring, focusing on the Poisson first-order integer-valued autoregressive\r\n(PoINAR) models ([3] for details on PoINAR(1) models). This class, while being\r\nsimple and flexible, is useful for modelling positive-valued and integer-valued time\r\nseries possessing an autoregressive structure with non-negative serial correlation. We\r\ninvestigate two natural approaches to analyse censored PoINAR(1) time series under\r\nthe Bayesian framework: the Approximate Bayesian Computation (ABC) methodology [2] and \r\nthe Gibbs sampler with Data Augmentation (GDA) approach [1]. Both approches may also be \r\nvaluable to analyse time series of counts with missing data.\r\n\r\nReferences\r\n1. Chib, S.: Bayes Inference in the Tobit Censored Regression Model. J. Econom. 51, \r\n   79–99 (1992)\r\n2. Plagnol V., Tavare S.: Approximate Bayesian computation and MCMC. In: Niederreiter H\r\n   (ed) Monte Carlo and quasi-Monte Carlo methods, pp. 99–113. Springer, Heidelberg \r\n   (2004)\r\n3. Scotto, M.G., Weiß, C.H., Gouveia, S.: Thinning-based models in the analysis of integer\r\n   valued time series: a review. Stat. Model. 15, 590–618 (2015)", :session 29, :keywords (28 55 489)}, 216 {:id 216, :title "Machine Learning Approach to Identify Factors That Influence Accident Severity", :authors (128 570 295 442 441 219 42 327 451 354 482 438 443), :abstract "Since the twentieth century, road traffic accidents became a severe public health \r\nconcern, with deaths and injuries posing a serious threat to world health and a negative\r\ninfluence on social and economic progress. One of the primary goals of accident\r\ndata analysis is to determine the main factors that contribute to a traffic accident.\r\nThis study aims to create a Machine Learning approach capable of identifying the\r\nfactors that influence accident severity (seriously injured/dead or lightly injured/no\r\ninjured), supporting the analysis of accident data. A four-year traffic accident data set\r\nfrom 2016 to 2019 in the Portuguese district of Setúbal is used. Clustering, Random\r\nForests and C5.0 rule models are some of the techniques used to select the most\r\ninfluential factors and represent them in rule sets. Results show that a rule-based\r\nmodel using the C5.0 algorithm can accurately identify the most relevant factors\r\ndescribing road accident severity. Factors such as accidents involving motorcycles\r\nand pedestrian running over are the most prominent factors in our data.\r\n\r\n", :session 13, :keywords (332 539 550)}, 191 {:id 191, :title "Reliability Assessment of Ancient Stone Arch Bridge Applying ANN Models, Case Study: \r\nLeça Railway Bridge", :authors (148 38 292 488), :abstract "In many areas of engineering, surrogate models are used to replace traditional methods \r\nof obtaining data and evaluating the performance of engineering outcomes.\r\nHowever, the investment in computation time using analytical models is, in some\r\ncases, impractical (a simulation could take minutes, hours, or even days). This is\r\nthe case for the structural assessment field, where the construction of approximation\r\nmodels to predict the performance by generating a relationship between the analyzed\r\nparameters (inputs and outputs) is recommended. The main objective of this investigation \r\nis to evaluate a surrogate model into a developed data set of a bridge case\r\nstudy. In this sense, the data set will be generated by using a finite element model\r\nto consider structural uncertainties to compute the ultimate load-carrying capacity.\r\nThus, based on the data set, a mathematical function will be derived to compute\r\nfailure probabilities through statistical analysis [1].\r\n\r\nReferences\r\n1. Baron, E.A., Galvão, N., Docevska, M., Matos, J., Markovski, G.: Application of \r\n   quality control plan to existing bridges. Struct. Infrastruct. Eng., \r\n   DOI: 10.1080/15732479.2021.1994618 (2021)", :session 84, :keywords (12 427 502 532)}, 143 {:id 143, :title "Classification of Viral Pneumonia Images via Multiple Instance Learning", :authors (65 377 166 164), :abstract "We present an application of the Multiple Instance Learning (MIl) paradigm to the\r\nclassification of pneumonia X-ray images, considering three different categories:\r\nradiographies of healthy people, of people with bacterial pneumonia and of people\r\nwith viral pneumonia. The proposed algorithms, which are very fast in practice,\r\nappear promising especially if we take into account that no preprocessing technique\r\non the images has been used.\r\n  In particular we will focus on the application of three different MIL instancespace\r\napproaches: MIL-RL [1], based on a Lagrangian relaxation technique, mi-SPSVM [2], \r\nwhich combines the classical Support Vector Machine approach with\r\nthe Proximal Support Vector Machine technique and MIL-kink [3], which provides\r\na separation hyperplane fixing in advance the normal and computing the bias by\r\nnonsmooth techniques.\r\n  Numerical results on some real-world data sets are presented.\r\n\r\nReferences\r\n1. Astorino, A., Fuduli, A., Gaudioso, M.: A Lagrangian relaxation approach for binary \r\n   multiple instance classification. IEEE Trans. Neural Netw. Learn. Syst. 30, 2662–2671 \r\n   (2019)\r\n2. Avolio, M., Fuduli, A.: A semiproximal support vector machine approach for binary \r\n   multiple instance learning. IEEE Trans. Neural Netw. Learn. Syst. 32, 3566–3577 (2021)\r\n3. Fuduli, A., Gaudioso, M., Khalaf,W., Vocaturo, E.,: A heuristic approach for multiple \r\n   instance learning by linear separation. Soft Comput. 26, 3361–3368 (2022)", :session 56, :keywords (400 65 275)}, 247 {:id 247, :title "Using Excel and R for Teaching Statistics and Data Analysis", :authors (574), :abstract "The presentation is about the use of computer software in teaching Statistics and Data\r\nAnalysis with the purpose of enhancing students learning experience and preparing\r\nthem better for a career. The software that comes to mind in this regard are Excel\r\n(part of MS Office) and R (available free of charge).\r\n  The effects of Covid-19 resulted in the teaching and assessment at many universities \r\nbeing moved from classroom to online. With teaching and assessment online the emphasis \r\nis more on understanding concepts, computing results and interpreting computer output. \r\nIn such a teaching environment the use of computer software like Excel and R is essential.\r\n  Problem: How and when to use Excel (spreadsheet based) and R (computing code based) in \r\nteaching?\r\n  Methodology: This depends very much on who are being taught and the goals to be achieved \r\nby using the software.\r\n  Results: Depending on the type of teaching, Excel and R can be used separately or to \r\ncomplement each other.\r\n  Implications: Excel and R can be used at every level of teaching from demonstrating simple \r\nconcepts to complicated Data Mining and bootstrapping calculations.\r\n  All these issues and more will be discussed in the presentation.\r\n\r\nReferences\r\n1. Dell’Omodarme, M. and Valle, G.: Teaching Statistics with Excel and R. Available at https:\r\n   //doi.org/10.48550/arXiv.physics/0601083 (2006)\r\n2. Duller, C., Kepler, J.: Teaching Statistics with Excel A Big Challenge for Students and \r\n   Lecturers. Australian Journal of Statistics, 37(2), 195-206 (2008)\r\n3. Hyndman, R.: Why R is better than Excel for teaching Statistics. Part of a conversation on\r\n   the Australian and New Zealand R mailing list (2010). Available at https://robjhyndman.\r\n   com/hyndsight/rvsexcel/", :session 67, :keywords (319 604 90)}, 167 {:id 167, :title "Clustering and Classifying Time Series in the Sktime Toolkit: a Practical Review of Latest\r\nAdvances in the Field", :authors (62), :abstract "sktime (https://github.com/alan-turing-institute/sktim) is an open source, scikit learn\r\ncompatible, toolkit for machine learning with time series. It was conceived in 2019\r\nvia a collaboration with the Alan Turing Institute and has matured through the growth\r\nof a vibrant open source community. It contains modules for a range of learning tasks\r\nsuch as forecasting, annotation and transformation. Researchers at UEA have played\r\na key role in researching and implementing algorithms for time series classification\r\n(TSC) and clustering (TSCL) within the sktime framework. I will present a practical\r\noverview of the TSC and TSCL functionality available within sktime, with specific\r\nemphasis on our new classification algorithm, HIVE-COTEv2.0 [2] (HC2). HC2\r\nis a meta ensemble of four classifiers, built on four different data representations.\r\nIt is state of the art for both univariate [1] and multivariate TSC [3]. I will also\r\ndemonstrate how to develop a simple pipeline classifier and compare performance\r\nto our published results. The clustering module is a more recent addition to sktime.\r\nI will present some recent experimental clustering benchmark results and show how\r\nsktime can be used with other toolkits such as tslearn to perform TSCL.\r\n\r\nReferences\r\n1. Bagnall A, Lines J., Bostrom A., Large J. and Keogh E. Middlehurst M., Large J., Flynn M.: \r\n   Data Mining and Knowledge Discovery 31, 606––660 (2017)\r\n2. Middlehurst M., Large J., Flynn M., Lines J., Bostrom A. and Bagnall A: HIVE-COTE 2.0: a\r\n   new meta ensemble for time series classification. Machine Learning 110, 3211—3243 (2021)\r\n3. Ruiz A.P Flynn M, Large J., Middlehurst M., Bagnall A.: The great multivariate time series\r\n   classification bake off: a review and experimental evaluation of recent algorithmic advances.\r\n   Data Mining and Knowledge Discovery 35(2), 401––449 (2021)", :session 25, :keywords (643 644 580)}, 36 {:id 36, :title "Data Clustering and Representation Learning Based on Networked Data", :authors (326 408), :abstract "To deal simultaneously with both, the attributed network embedding and clustering,\r\nwe propose a new model exploiting both content and structure information. The\r\nproposed model relies on the approximation of the relaxed continuous embedding\r\nsolution by the true discrete clustering. Thereby, we show that incorporating an\r\nembedding representation provides simpler and easier interpretable solutions. \r\nExperiment results demonstrate that the proposed algorithm performs better, in terms \r\nof clustering, than the state-of-art algorithms, including deep learning methods \r\ndevoted to similar tasks.\r\n\r\n", :session 66, :keywords (425 75 535 601)}, 41 {:id 41, :title "New Metrics for Classifying Phylogenetic Trees Using k-Means and the Symmetric \r\nDifference Metric", :authors (411 15), :abstract "The k-means method can be adapted to any type of metric space and is sometimes\r\nlinked to the median procedures. This is the case for symmetric difference metric \r\n(or Robinson and Foulds [1]) distance in phylogeny, where it can lead to median trees\r\nas well as to Euclidean Embedding. We show how a specific version of the popular\r\nk-means clustering algorithm, based on interesting properties of the Robinson and\r\nFoulds topological distance, can be used to partition a given set of trees into one\r\n(when the data is homogeneous) or several (when the data is heterogeneous) cluster(s)\r\nof trees. We have adapted the popular cluster validity indices of Silhouette, and Gap\r\nto tree clustering with k-means based on a previous work by Tahiri et al. [2]. In this\r\narticle, we will show results of this new approach on a real dataset (aminoacyl-tRNA\r\nsynthetases) of Woese et al. [3]. The new version of phylogenetic tree clustering\r\nmakes the new method well suited for the analysis of large genomic datasets.\r\n\r\nReferences\r\n1. Robinson, D. & Foulds, L. Comparison of phylogenetic trees. Mathematical Biosciences. 53,\r\n   131-147 (1981)\r\n2. Tahiri, N., Willems, M. & Makarenkov, V. A new fast method for inferring multiple consensus\r\n   trees using k-medoids. BMC Evolutionary Biology. 18, 1-12 (2018)\r\n3. Woese, C., Olsen, G., Ibba, M. & Soll, D. Aminoacyl-tRNA synthetases, the genetic code, and\r\n   the evolutionary process. Microbiology And Molecular Biology Reviews. 64, 202-236 (2000)", :session 32, :keywords (75 629 300 481 73)}, 187 {:id 187, :title "A clusterwise regression method for distributional data", :authors (462 1 2), :abstract "This work deals with a cluster-wise regression method for distributional data. The set\r\nof objects to be clustered are described by distributional variables {Y, X_1, . . . , X_p},\r\nwith Y the response variable and X_j´s the predictors. Each object is represented by\r\np + 1 probability functions, or empirical ones. Our proposal is based on a K-means\r\nclustering type-algorithm, where the centroid of the clusters are represented by linear\r\nregression models and the objects are assigned to the clusters according to minimum\r\nsum of squared errors. [1] and [2] proposed two regression models for distributional\r\ndata based on a Non Linear Least Squared method and on the Wasserstein metric in a\r\nlinear space. The constrain of non-negativity were imposed to guarantee the outcome\r\nis still a distributional variable. In consideration of the most recent developments\r\nin distributional data analysis (DDA), we introduce a transformation of the qf’s in\r\nquantile density functions [3], which allows to map density functions in an Hilbert\r\nspace and overcome some challenge in DDA. Applications on synthetic and real data\r\nhave corroborated the new method.\r\n\r\nReferences\r\n1. Irpino, A., Verde, R.: Linear regression for numeric symbolic variables: a least squares\r\n   approach based on Wasserstein Distance, Advances in Data Analysis and Classification 9 (1)\r\n   81-106 (2015)\r\n2. Dias, S., Brito, P.: Linear regression model with histogram-valued variables, Statistical \r\n   Analysis and Data Mining: The ASA Data Science Journal 8 (2) 75-113 (2015)\r\n3. Petersen, A., Muller, H.: Functional data analysis for density functions by transformation \r\n   to a Hilbert space, Annals of Statistics 44 (1) 183-218 (2016)", :session 5, :keywords (626 158 510)}, 195 {:id 195, :title "Multi-Perspective Risky User Classification in Social Networks", :authors (67 212 395), :abstract "The widespread adoption of social media platforms opened up new ways to connect\r\nand engage in a globalized manner. However, it also led to the introduction of\r\nharmful addiction phenomena, and to the spread of cyberbullying and cyberterrorism\r\nactivities. As a result, monitoring operations on the content published by users, as\r\nwell as on their behavior, has become critical to ensure a correct and safe use of social\r\nmedias. This monitoring process becomes very difficult in presence of borderline\r\nusers, i.e., users who appear to act in safe way based on their posted content, but not\r\naccording to other viewpoints (e.g., their relationships), and viceversa.\r\n  In this context, this abstract contributes towards an effective identification of\r\nrisky users in social networks. Specifically, we propose a novel method that solves\r\nnode classification tasks in social networks by exploiting the information conveyed\r\nby three different perspectives: the semantics of the textual content generated by\r\nusers, the network of user relationships, and the users spatial closeness, derived\r\nfrom geo-tagging metadata associated with posted contents.\r\n  Existing approaches that consider multiple perspectives are mainly based on the\r\ninjection of features identified from one perspective into the other [2], or are tailored\r\nfor the analysis of the network structure and node attributes, without being able to\r\ncapture the semantics of the generated content [1]. On the contrary, our method\r\nbuilds three models that exploit the peculiarities of each viewpoint, and learns a final\r\nmodel to fuse their contributions through a stacked generalization approach.\r\n  Our experiments on two variants of a real Twitter dataset showed that the proposed\r\nmethod outperforms 13 competitors based on one or more perspectives. This advantage \r\nis also clear on borderline users, confirming the applicability of our method in\r\nreal-world social networks, which are potentially affected by noisy data.\r\n\r\nReferences\r\n1. Pio, G.: Multi-type clustering and classification from heterogeneous networks. Inf. Sci. 425,\r\n   107–126 (2018)\r\n2. Campbell, W.: Content+ context networks for user classification in twitter. NIPS 2014 \r\n   Workshop (2014)", :session 7, :keywords (584 669 590)}, 118 {:id 118, :title "The Clustering Performance of a Weighted Combined Distance Between Time Series", :authors (359 34 300), :abstract "Recently, [1], we proposed a new dissimilarity measure between time series - COMB,\r\na uniform convex combination of four (normalized) distance measures: Euclidean;\r\nPearson correlation based; Periodogram based; and a distance between estimated \r\nautocorrelation structures. In this work, we propose a method to determine the \r\nweights of the convex combination of distances in COMB: it relies on the concordance\r\nof clusterings obtained by each individual distance measure and COMB derived\r\nclustering. A weighted COMB measure is thus obtained, WCOMB. We then test\r\nthe clustering performance of WCOMB vs. COMB by conducting an experimental\r\nanalysis on all the time series datasets of the UCR archive. We evaluate the \r\nconcordance between the clusters obtained using K-Medoids and the original classes \r\n(using adjusted Rand index) as well as the cohesion-separation of the clusters (using \r\nthe Silhouette index). In addition, we consider a clustering application - with data \r\nfrom the Portuguese Transmission System Operator, on time series of electricity \r\nconsumption  (2014 to 2019) - to compare the performance of both methods. Significant\r\ndifferences between the average Silhouette values of clusters obtained were found.\r\nThe concordance with the original classes’ structure exhibits similar performance in\r\nboth approaches. We conclude that, for unsupervised leaning, it can be worthwhile\r\nto invest on deriving specific weights for the distances integrating COMB.\r\n\r\nReferences\r\n1. Cardoso, M.G.M.S., Martins, A.A.: The performance of a combined distance between time\r\n   series. In: Bispo, R., Henriques-Rodrigues, L., Alpizar-Jara, R. and de Carvalho, M. \r\n   (eds.) Recent Developments in Statistics and Data Science - Proceedings of the XXV \r\n   Congress of the Portuguese Statistical Society. Springer. (to be published)", :session 72, :keywords (75 157 641)}, 238 {:id 238, :title "Comparison of K-Mer and Alignment-Based Pre-Processing Approaches for Machine\r\nLearning Based Functional Annotation with 16S RRNA Data", :authors (464 7 165 84), :abstract "Over the last few decades, the continuing advancements in Next-GenerationSequencing \r\ntechnologies provided new opportunities to obtain large volumes of biological sequence \r\ndata from uncultured environments. Moreover, continuing efforts to store labelled RNA, \r\nDNA and protein sequences have opened opportunities to implement Machine Learning (ML) \r\ntechniques and build predictive tools that can estimate key characteristics of sequenced \r\nenvironments. Traditionally, processing of biological sequences for comparative analysis \r\ninvolved implementing sequence alignment techniques. However, alignment algorithms have \r\nhigh computational costs that scale non-linearly with the number of sequences. Moreover, \r\ncurrent Multiple Sequence Alignment methods produce a representation of data, where a \r\nformat of each sequence is heavily dependent on other most similar sequences in the current\r\nset, making any subsequently trained predictive model unstable.\r\n  Our investigation focused on identifying scalable and effective data pre-processing\r\ntechniques for the series of functional annotation tasks using 16S rRNA data [1]. To\r\nthis end, we tested the use of a pairwise-alignment pre-processing technique, which\r\nwe then compared to an alignment-free, k-mer based method. Additionally, we examined whether \r\ncombining both techniques improves the accuracy of ML classifiers. The results of our \r\nexperiments  showed that the k-mer frequencies provide the most favourable set of features \r\nfor these problems.\r\n\r\nReferences\r\n1. Kulakowski, R., Lausen, A, Low-Decarie, E., Lausen, B.: Classification Methods for 16S\r\n   rRNA Based Functional Annotation. Archives of Data Science, Series A 4 (1), 23 (2020).", :session 82, :keywords (566 301 202 214 63)}, 196 {:id 196, :title "Application of Artificial Intelligence (AI) in Flood Risk Forecasting", :authors (404 38 153 237 292), :abstract "Floods are the most serious natural disasters currently, directly affecting people’s\r\ndaily lives and causing many serious effects. The number of annual floods is increasing \r\nwith different intensity in several locations [1]. The sustainable development of\r\npeople, critical infrastructure, the economy and society will be severely affected if\r\nno preventive or countermeasures are taken [2]. With the goal of minimizing damage\r\nby providing effective flood prevention and response solutions, forecasting requires\r\nhigh accuracy and long forecasting time. However, recently, along with the powerful\r\ndevelopment of computer science, big data and the development history of society, \r\nartificial intelligence (AI) tools have the potential to perform this challenging\r\ntask more accurately and faster than traditional methods, as highlighted in Pham et\r\nal. [3]. This investigation presents the application of AI in a comprehensive flood\r\nrisk forecasting methodology, with the potential to provide a useful tool for flood\r\nmanagement and definition of mitigation measures in urban areas, as well as for\r\nassisting in catastrophic events prevention.\r\n\r\nReferences\r\n1. The EU Floods Directive. https://ec.europa.eu/environment/water/flood_risk/.\r\n2. Kundzewicz, Z.W., Hegger, D.L.T., Matczak, P., Driessen, P.P.J. (2018): Flood-risk reduction:\r\n   Structural measures and diverse strategies. Proceedings of the National Academy of Sciences.\r\n3. Pham, B.T., Luu, C., Tran, P., Nguyen, H.D., Le, H.V., Quoc, T., Ta, H.T., Prakash, I. (2021):\r\n   Flood risk assessment using hybrid artificial intelligence models integrated with multi-criteria\r\n   decision analysis in Quang Nam Province, Vietnam. Journal of Hydrology 592(11)", :session 84, :keywords (18 209 495)}, 162 {:id 162, :title "Adaptive Fuzzy Systems in Economics and Finance: Evaluating Interval Forecasts of\r\nHigh-Frequency Data", :authors (483), :abstract "The forecast of the future movement of economic and financial variables assumes\r\na central role for the composition of portfolios, risk management, asset pricing and\r\ninvestment analysis; therefore, the development of prediction methodologies is of\r\nfundamental importance. With the recent and rapid growth in the availability of\r\nfinancial information, especially at intraday frequencies, approaches to forecasting\r\ninterval time series have gained prominence in the literature, since they comprise\r\nthe construction of more informative forecasts, capable of capturing the fluctuations \r\nof an asset, index or rate over the course of a transaction day, as opposed to\r\ntechniques based on one-off anticipations. In general, forecast models have some\r\npractical limitations, such as linear structure, nonconsideration of market uncertainties, \r\nrestrictive hypotheses about the data, need for a large number of observations\r\nto estimate parameters, and inadequacy for the natural treatment of interval data. To\r\naddress such limitations, fuzzy modeling has been proposed for forecasting interval\r\ntime series. Adaptive fuzzy models are nonlinear, are able to update their structure\r\nand functionality according to data streams, and handle uncertainty from fuzzy sets.\r\nThus, this approach allows the dynamic treatment of complex phenomena, as well as\r\nconsidering information affected by uncertainties, as is the case of financial markets.\r\nThese approaches have been applied to different economies by forecasting stock\r\nprices, exchange rates, stock exchange indices and price volatility, as opposed to\r\ntraditional univariate and multivariate econometric methods.\r\n\r\n", :session 81, :keywords (3 645 266)}, 184 {:id 184, :title "Combining KDE and DBSCAN Clustering to Understand Road Traffic Accidents: \r\nthe Case of Setúbal, Portugal", :authors (451 354 441 443 327 42 219), :abstract "Road traffic accidents (RTA) constitute a scourge that modern societies face, with\r\nan increasing death toll each passing year. Deep knowledge of the conditioning\r\nfactors might help to mitigate this problem. Understanding the RTA location and\r\nwhat variables play a role are keys to foster road safety and outline prevention\r\npolicies. The analysis of hotspots location based on RTA is the most common\r\napproach to understand the relations between neighboring accidents, looking for\r\nspatial significance. Herein, it is proposed that the comparison and analysis of\r\nhotspots with the clusters defined by DBSCAN algorithm is a valid tool to further\r\nclarify the spatial distribution of RTA. Data from the Portuguese district of Setúbal\r\nbetween the years 2016 and 2019 was used and the following datasets/subsets were\r\ndefined: i) all accidents, ii) accidents with victims, and iii) accidents with fatalities\r\nand/or major injuries. The Kernel Density Estimation (KDE) was used with a quartic\r\nfunction to define the hotspots in QGIS.\r\nThe comparison of the hotspots with DBSCAN results allow us to conclude that:\r\nA) datasets i) and ii) have similar hotspot locations and there is no relation between\r\nhotspots and DBSCAN clusters, a single cluster comprises all the hotspots, being\r\nthe other for small patches randomly distributed in the studied area; B) For dataset\r\niii) the hotspots are not well defined, with one exception, whereas DBSCAN creates\r\ntwo clusters, separating urban areas with dense traffic, from more rural areas with\r\ntraffic concentrated in high-speed roads; C) Moreover, for dataset iii) the remaining\r\nDBSCAN clusters define RTA in specific low traffic roads. These low traffic roads\r\nare, therefore, the targets that are prone to deepen the studies for understanding the\r\nlocation of RTA with fatalities or major injuries.\r\n\r\n", :session 20, :keywords (540 305 130 508)}, 219 {:id 219, :title "Copula-Based Non-Metric Unfolding on Augmented Data Matrix", :authors (373 63), :abstract "A multidimensional unfolding technique [1] that is not prone to degenerate solutions\r\nand is based on multidimensional scaling of a complete data matrix is proposed. We\r\nadopt the strategy of augmenting the data matrix, trying to build a complete \r\ndissimilarity matrix, by using Copulas-based association measures [2] among rankings \r\n(the individuals), and between rankings and objects (namely, a rank-order representation\r\nof the objects through tied rankings). The proposed technique leads to acceptable\r\nrecovery of given preference structures. Application on real datasets show that our\r\nprocedure returns non-degenerate unfolding solutions.\r\n\r\nReferences\r\n1. Cox, T.F. and Cox, M.A.A.: Multidimensional scaling. Chapman & Hall/CRC (2000)\r\n2. Nelsen, R.B.: An introduction to copulas. Springer, New York (2013)", :session 27, :keywords (113 665 393)}, 89 {:id 89, :title "Fitting an Accelerated Failure Time Model with Time-Dependent Covariates\r\nvia Nonparametric Gaussian Scale Mixtures", :authors (302 94 498), :abstract "An accelerated failure time (AFT) model is a popular regression model in survival\r\nanalysis. It models the relationship between the failure time and a set of covariates via\r\na log link with an addition of a random error. The model can be either parametric or\r\nsemiparametric depending on the degree of specification of the error distribution. The\r\ncovariates are usually assumed to be fixed - ‘time independent’. In many biomedical\r\nstudies, however, ‘time-dependent’ covariates are frequently observed and Cox and\r\nOakes [1] proposed an AFT model with time-dependent covariates.\r\nIn this work, we consider a semiparametric time-dependent AFT model. We assume\r\nthat the distribution of the baseline failure time as an infinite scale mixture of\r\nGaussian densities. Thus, this model is highly flexible compared to that assumes a\r\none-component parametric density. We consider a maximum likelihood estimation\r\nand propose an algorithm based on the constrain newton method [2] for estimating\r\nmodel parameters and mixing distributions. The proposed methods are investigated\r\nvia simulation studies to assess the finite sample properties. The proposed methods\r\nare illustrated with a real data set.\r\n\r\nReferences\r\n1. Cox, D.R, and D. Oakes.: Analysis of Survival Data. Chapman & Hall, London (1984)\r\n2. Wang, Y.: On fast computation of the non-parametric maximum likelihood estimate of a\r\n   mixing distribution. Journal of the Royal Statistical Society: Series B. 69.2, 185–198 (2007)", :session 68, :keywords (640 433 100 622)}, 100 {:id 100, :title "Embedded Word MCA Biplots for Sentiment Visualisation: \r\nApplication to COVID-19 Related Tweets", :authors (589 281 416 528), :abstract "Social media platforms are continually gaining popularity which results in vast\r\namounts of shared data in the form of images, videos and text. Twitter is a micro-\r\nblogging platform which allows the sharing of short messages that are labelled\r\naccording to a specific key word (i.e. tag), representing a relevant topic or theme.\r\nThese messages reflect personal opinions with subjective content which could provide \r\ninsight to grasp the underlying attitude towards specific topics. During the global \r\nCOVID-19 pandemic users could easily share messages by using social media platforms \r\ncontaining information on for example regulations on lockdown or vaccination. Twitter’s \r\napplication programming interface (API) allows the procurement of posts made on the \r\nplatform for a specific Twitter tag, timeframe and location within a specified radius. \r\nIn this study the unstructured pieces of text, Tweets, are processed and the sentiment \r\nof the remaining words are classified using two lexicons. Multi-dimensional visualisation \r\nenables the exploration of the associations between the Twitter users based on the resultant \r\nsentiment scores of their posts. A multiple correspondence analysis (MCA) biplot is embedded \r\nwith the extracted words to enable the simultaneous interpretation of the underlying sentiment \r\nof the processed Tweets. This paper presents two case studies of COVID-19 related Tweets.\r\nThe first case study considers posts made by South African users in three cities (Cape\r\nTown, Johannesburg and Durban), with the second case study evaluating the sentiment towards \r\nCOVID-19 on a global scale by considering three predominantly English-speaking countries \r\n(South Africa, Australia and United Kingdom).\r\n\r\n", :session 50, :keywords (41 119 398 565 684)}, 243 {:id 243, :title "An Extension of Edge Reduction for Large Networks", :authors (447), :abstract "In Network Science, edge reduction in graphs has been studied by several authors\r\nfor many years [2] [1]. The applications are varied, from telecommunications, to\r\nInternet of Things (IoT), and fraud detection. In fraud detection, the objective is\r\nto simplify the structure of networks to better identify money laundering patterns.\r\nIn most literature, edge reduction techniques are based on network structure and\r\nlink weights. In this work we use node attributes and edge attributes to reduce the\r\nstructure of large graphs, where the edges and nodes are characterized by a large\r\namount of features. For the reduction task we use an adaptation of Supervised PCA,\r\nan algorithm that uses a subset of features based on their association with the outcome\r\n([4]), but we extend the edge reduction by using a double reduction both at the levels\r\nof nodes and edges using a double Supervised PCA (2X-SPCA). An illustrative\r\napplication of the method is made with a variant of PaySim, a Synthetic Financial\r\nDataset For Fraud Detection ([3]), containing more than 6 million of transactions\r\n(the edges) between more than 2 million users (the nodes). An outcome variable -\r\nisFraud – is used, assigning the edge to a transaction made by the fraudulent agents\r\ninside the simulation.\r\n\r\nReferences\r\n1. Papageorgiou, A., Cheng, B., and Kovacs, E., \"Real-time data reduction at the network edge\r\n   of Internet-of-Things systems,\" 2015 11th International Conference on Network and Service\r\n   Management (CNSM), 2015, pp. 284-291, doi: 10.1109/CNSM.2015.7367373.\r\n2. Hambrusch, S.E., Lim, H. (1999). Minimizing the Diameter in Tree Networks Under Edge\r\n   Reductions. Parallel Process. Lett., 9, 361-371.\r\n3. Lopez-Rojas, E.A., Elmir, A., and Axelsson, S., \"PaySim: A financial mobile money simulator\r\n   for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS,\r\n   Larnaca, Cyprus. 2016\r\n4. Bair, E., Hastie, T., Paul, D., Tibshirani, R. (2006). Prediction by Supervised Principal \r\n   Components. Journal of the American Statistical Association, 101(473), 119–137.\r\n   http://www.jstor.org/stable/30047444\r\n5. Hamburger, C.: Quasimonotonicity, regularity and duality for nonlinear systems of partial\r\n   differential equations. Ann. Mat. Pura. Appl. 169, 321–354 (1995)", :session 66, :keywords (170 161 211)}, 131 {:id 131, :title "Variational Autoencoder with Gamma Mixture for Clustering Right-Skewed Data", :authors (274 262), :abstract "Generative models such as generative adversarial network (GAN), autoencoder (AE),\r\nand variational autoencoder (VAE) enable model-based clustering to be undertaken\r\nbecause they can learn and extract significant features from data. Among them, variational\r\nautoencoder with deep embedding (VaDE) is an unsupervised clustering\r\nmethod proposed within the VAE framework by assuming Gaussian distribution\r\nfor both the marginal distribution of the latent feature vector and the conditional\r\ndistribution of data given the latent vector. Several analyses of many real microarray\r\ndatasets have suggested that the empirical distribution of gene expression levels\r\nis approximately right-skewed like log-normal with some extreme values depending\r\non the biological samples under investigation. Therefore, the above approach\r\nis sensitive to both non-normality of the data and extreme expression levels. We\r\npropose a new VAE approach based on gamma mixture that efficiently fits data\r\nwith right-skewed distribution. We derive the evidence lower bound (ELBO) and\r\noptimize the ELBO using the reparameterization trick for gamma distribution and\r\nStochastic Gradient Variational Bayes estimator. The proposed method is applied to\r\nsome high-dimensional real gene expression datasets and single-cell RNA-seq data\r\nwith small sample sizes and shows its better performance over the existing generative\r\nmodels including statistical model-based method such as mixtures of common\r\nt-factor analyzers.\r\n\r\n", :session 19, :keywords (75 675 228)}, 122 {:id 122, :title "Hotspot Cluster Detection Based on Spatial Hierarchical Structure and Its Software", :authors (197 509 316), :abstract "With the remarkable development of GIS in recent years, it has become easier to\r\nanalyze and visualize a wide variety of geospatial data. Echelon analysis [3] was\r\nproposed as a method for objectively visualizing geospatial data by a topological\r\nhierarchical structure. An example application of using echelon analysis is hotspot\r\ndetection, that is, detecting a subset of regions with significantly higher or lower\r\nrelative risk in geospatial data. An echelon scan method we have proposed uses\r\nechelon’s hierarchical structures to perform hotspot detection [2], and thereby has\r\nbecome possible to detect an arbitrary shaped cluster even when large amounts of\r\ndata are targeted, which is difficult to detect by the conventional method. In this\r\nstudy, we introduce the R package for the echelon analysis and echelon scan method\r\nwe have developed [1], and the web application that can execute these methods while\r\nperforming them interactively. In addition, an example of analysis using actual data\r\nwill be demonstrated.\r\n\r\nReferences\r\n1. Ishioka, F.: echelon: The Echelon Analysis and the Detection of Spatial Clusters using \r\n   Echelon Scan Method. R package version 0.1.0. (2020) \r\n   https://cran.r-project.org/package=echelon\r\n2. Kurihara, K., Ishioka, F., Kajinishi, S.: Spatial and temporal clustering based on the \r\n   echelon scan technique and software analysis. Jpn. J. Stat. Data Sci. 3, 313–332 (2020)\r\n3. Myers, W.L., Patil, G.P., Joly, K.: Echelon approach to areas of concern in synoptic \r\n   regional monitoring. Environmental and Ecological Statistics. 4, 131–152 (1997)", :session 60, :keywords (166 167 271)}, 43 {:id 43, :title "Generalized Spatio-Temporal Regression with PDE Penalization", :authors (150 151 323), :abstract "We develop a novel generalised linear model for the analysis of data distributed over\r\nspace and time. The model involves a nonparametric term f, a smooth function over\r\nspace and time. The estimation is carried out by the minimization of an appropriate\r\npenalized negative log-likelihood functional, with a roughness penalty on f that\r\ninvolves space and time differential operators, in a separable fashion, or an evolution\r\npartial differential equation. The model can include covariate information in a \r\nsemi-parametric setting. The functional is discretized by means of finite elements in \r\nspace, and B-splines or finite differences in time. Thanks to the use of finite elements, \r\nthe proposed method is able to efficiently model data sampled over irregularly shaped\r\nspatial domains, with complicated boundaries. To illustrate the proposed model we\r\npresent an application to study the criminality in the city of Portland, from 2015 to\r\n2020.\r\n\r\n", :session 53, :keywords (217 592 562)}, 231 {:id 231, :title "Model Extraction Based on Counterfactual Explanations", :authors (101 564), :abstract "Automated decision-making classification systems based on Machine Learning algorithms \r\nare often used in many real-life scenarios such as healthcare, credit, or criminal\r\njustice. There is thus increasing interest in making Machine Learning systems trustworthy: \r\ninterpretability, robustness, and fairness are often essential requirements for\r\nthe deployment of these systems [1]. In particular, according to the European Union’s\r\nGeneral Data Protection Regulation (GDPR), automated decision-making systems\r\nshould guarantee the ”right to explanations” [2], meaning that those affected by the\r\ndecision may require an explanation. Counterfactual Explanations are becoming a\r\nde-facto standard for a post-hoc explanation [3]. Given an instance of a classification\r\nproblem, belonging to a class, its counterfactual explanation corresponds to small\r\nperturbations of that instance that allow changing the classification outcome. The\r\nobjective of this work is to try and exploit the information revealed by a small set\r\nof examples with their counterfactual explanations to build a surrogate model of the\r\nclassification system. The idea is to define an optimization problem that provides in\r\noutput a Forest of Optimal Trees as close as possible to the original classification\r\nmodel, given the information derived from the counterfactual points. This tool can\r\nbe used, on one hand, to attack a target model; on the other hand, it is also possible\r\nto improve the target system by building a more interpretable and sparse model.\r\nPreliminary results show the viability of this approach.\r\n\r\nReferences\r\n1. Rudin, C.: Stop explaining black box machine learning models for high stakes decisions and\r\n   use interpretable models instead. Nat. Mach. Intell. 1, 206–215 (2019)\r\n2. Goodman, B., Flaxman, S.: European Union regulations on algorithmic decision-making and\r\n   a “right to explanation”. AI Mag. 38, 50–57 (2017)\r\n3. Verma, S., Dickerson, J., Hines, K.: Counterfactual explanations for machine learning: A\r\n   review. arXiv preprint arXiv:2010.10596 (2020)", :session 38, :keywords (446 360 290)}, 61 {:id 61, :title "A Moment-Free Measure of Multivariate Skewness", :authors (51 348), :abstract "Multivariate skewness measures proposed in the literature are usually generalizations\r\nof univariate ones, and are based on the third central moment or Pearson’s relation\r\nbetween mode, mean and standard deviation. Popular measure was proposed by\r\nMardia [2], and good review of other propositions can be found in [1]. The aim of\r\nthe paper is to propose a new measure of sample multivariate skewness which uses\r\nthe idea of a ”mirror observation”. The measure is calculated on standardized data.\r\nThe ”mirror observation” is an artificial point lying on the line from the given data\r\npoint through the coordinate origin, within the same distance to the origin as the\r\nactual point, and located on the other side of the origin. Then the distance from the\r\nreal data point closest to the mirror one is used in the construction of the measure,\r\nwhich is finally the average over all data points. The problem of assymetry sign\r\nis discussed as well as the distribution of the measure under multivariate normal\r\ndistribution. The empirical example compares the multivariate skewness of different\r\nsocio-economic spheres in European Union countries distribution.\r\n\r\nReferences\r\n1. Balakrishnan N. and Scarpa B.: Multivariate measures of skewness for the skew-normal\r\n   distribution. J. Multivariate Anal. 104, 73-87 (2012).\r\n2. Mardia K.V.: Measures of multivariate skewness and kurtosis with applications. \r\n   Biometrika 36, 519-530 (1970)", :session 18, :keywords (411 419 188)}, 29 {:id 29, :title "Stability of Mixed-Type Cluster Partitions for Determination of the Number of Clusters", :authors (463 207 3), :abstract "For partitioning clustering methods, the number of clusters has to be determined\r\nin advance and is therefore an important issue. Besides the application of so-called\r\ninternal validation indices, the determination of an optimal number of clusters can\r\nbe achieved with stability indices. In this paper several stability based validation\r\nmethods are investigated with regard to the k-prototypes algorithm for mixed-type\r\ndata, which is an extension to the popular k-means algorithm.\r\n  Under consideration are the Jaccard coefficient, the Simple Matching coefficient\r\nand the indices published by Fowlkes and Mallows as well as by von Luxburg.\r\nFurthermore, the weighted average of cluster-wise stability values based on the\r\nJaccard index and a numerical approximation of the stability value interpretation\r\nproposed by Ben-Hur et al. were investigated. The stability based approaches are\r\ncompared to common internal validation indices in a comprehensive simulation\r\nstudy in order to analyze preferability as a function of the underlying data generating\r\nprocess.\r\n\r\n", :session 41, :keywords (70 72 373)}, 151 {:id 151, :title "Some Descriptive Statistics of Aggregated Symbolic Data", :authors (308 419 581), :abstract "When we have a huge amount of data, we sometimes are interested in comparing meaningful \r\ngroups of data, not individual observations. Aggregated symbolic data (ASD) expresses \r\na group of observations that have continuous and categorical variables by using up to \r\nsecond moments of variables. ASD for a group of data is equivalent to the set of means, \r\nvariances, and correlations for continuous variables, Burt matrix for categorical variables, \r\nand means of a continuous variable against one value of a categorical variable. \r\nAs ASD for many categorical variables is still complicated, it is preferable to have simple \r\nmeasures of location and dispersion for a categorical variable, and a measure of the correlation \r\nbetween two categorical and/or continuous variables. We propose such measures by specifying \r\nappropriate scores to categorical values. They are compared with measures that are defined as\r\nextensions of the polychoric correlation coefficient [1].\r\n\r\nReferences\r\n1. Olsson, U.: Maximum Likelihood Estimation of the Polychoric Correlation Coefficient, \r\n   Psychometrika, 12, 443–460 (1979)\r\n", :session 50, :keywords (52 111 351 352 353)}, 44 {:id 44, :title "The Death Process in Italy Before and During the Covid-19 Pandemic: \r\na Functional Compositional Approach", :authors (477 16 323 458), :abstract "In this talk, based on [1], we propose a spatio-temporal analysis of daily death\r\ncounts in Italy, collected by ISTAT (Italian Statistical Institute), in Italian provinces\r\nand municipalities. While in [1] the focus was on the elderly class (70+ years old),\r\nwe here focus on the middle class (50-69 years old), carrying out analogous analyses\r\nand comparative observations. We analyse historical provincial data starting from\r\n2011 up to 2020, year in which the impacts of the Covid-19 pandemic on the overall\r\ndeath process are assessed and analysed. The cornerstone of our analysis pipeline\r\nis a novel functional compositional representation for the death counts during each\r\ncalendar year: specifically, we work with mortality densities over the calendar year,\r\nembedding them in the Bayes space B^2 of probability density functions. This Hilbert\r\nspace embedding allows for the formulation of functional linear models, which are\r\nused to split each yearly realization of the mortality density process in a predictable\r\nand an unpredictable component, based on the mortality in previous years. The\r\nunpredictable components of the mortality density are then spatially analysed in\r\nthe framework of Object Oriented Spatial Statistics. Via spatial downscaling of the\r\nresults obtained at the provincial level, we obtain smooth predictions at the fine\r\nscale of Italian municipalities; this also enable us to perform anomaly detection,\r\nidentifying municipalities which behave unusually with respect to the surroundings\r\n\r\nReferences\r\n1. Scimone, R., Menafoglio, A., Sangalli, L.M., Secchi,P. (2021): A look at the \r\n   spatio-temporal mortality patterns in Italy during the COVID-19 pandemic through \r\n   the lens of mortality densities. Spatial Statistics, \r\n   doi: https://doi.org/10.1016/j.spasta.2021.100541, preprint available \r\n   at https://mox.polimi.it/reports-and-theses/publication-results/?id=952", :session 33, :keywords (117 440 217 593)}, 258 {:id 258, :title "On the Use of the Choquet Fuzzy Integral to Aggregate Predictions of Time Series: \r\nan Application to Economic (and Other Types of) Data", :authors (136 293 496), :abstract "The Choquet Integral with respect to a given fuzzy measure is a powerful aggregation\r\noperator that fuses several sources of information into a single value [1]. An as of\r\nyet unexplored application is the use of the method to aggregate predictions of time\r\nseries (as well as supervised learning representations) methods. Time series have an\r\ninternal structure based on temporal ordering of the data, and the fact that changes in\r\nthe relative ordering of observations would change the meaning of the data is a fact\r\nthat presents its own set of challenges in the context of Machine Learning (see [2, 3]\r\nfor examples of applications). The objective is twofold: first, to compare the methods\r\nused in terms of performance. Second, to obtain a model acting as an ensemble, able\r\nto muster the relative strengths of each method into a more accurate (in the sense of\r\nsmaller in and out-of-sample errors with respect to its components) super predictor,\r\nin a \"wisdom of crowds\" effect. An application example with 8 time series (of both\r\nsynthetic and \"real-life\" origin) is explored.\r\n\r\nReferences\r\n1. Grabisch, M., Labreuche, C.: Fuzzy Measures and Integrals in MCDA. In: Greco, S., Ehrgott,\r\n   M., Figueira, J. (eds) Multiple Criteria Decision Analysis. International Series in Operations\r\n   Research & Management Science, vol 233, pp 553-603. Springer, New York, NY (2016)\r\n2. Ribeiro, M.H.D.M., Coelho, L.S.: Ensemble approach based on bagging, boosting and stacking\r\n   for short-term prediction in agribusiness time series. App. Soft Comp. 86, 105837 (2020)\r\n3. Cicceri, G., Inserra, G. and Limosani, M. A machine learning approach to forecast economic\r\n   recessions—an italian case study. Mathematics 8(2), 241 (2020)", :session 29, :keywords (225 58 645 16 619)}, 250 {:id 250, :title "Interpretable Multi-Class Trees for Travel Choice Mode Analysis", :authors (109 47 397 478), :abstract "Analysis of travel mode choice is fundamental to forecast travel demand when \r\nplanning intervention on the supply system. Commonly, this is conducted via Random\r\nUtilities Models (RUMs) which relies on the random utility theory [1]. Recently, the\r\nlarge availability of travel demand data, mainly from smartphones, has increasingly\r\nled to the use of machine learning models that find their ideal context of use in big\r\ndata. Although such models are generally capable of good performance, their intrinsic \r\nblack-box nature is a critical aspect. Hence, to fruitfully apply Machine Learning\r\napproaches to travel mode choice, some enhancements must be considered. Recently,\r\ninterpretable machine learning approach [2] has been proposed. The main idea is\r\nto improve the output results of random forests with some additional aids. This\r\npaper provides a new framework to approach interpretable machine learning using\r\ntree-based methods in combination with classical models. The basic rationale with\r\nthe main theoretical aspects can be found in old papers [3, 4, 5]. A fresh approach\r\nintegrating logistic regression and latent budget models will be demonstrated for a\r\nmulti-class response problem typical in transportation studies.\r\n\r\nReferences\r\n1. Cascetta, E., Papola, A.: Random utility models with implicit availability/perception of choice\r\n   alternatives for the simulation of travel demand. Transport. Res. C-Emer. 9(4), 249–263 (2001)\r\n2. Kim, E-J.: Analysis of Travel Mode Choice in Seoul Using an Interpretable Machine Learning\r\n   Approach. J. Adv. Transp. 2021, 6685004 (2021)\r\n3. Siciliano, R., Mola, F.: Multivariate data analysis and modeling through classification and\r\n   regression trees. Comput. Stat. & Data An. 2021, 6685004 (2021)\r\n4. Siciliano, R.: Latent budget trees for multiple classification. I In: Vichi, M., Opitz, O. (eds)\r\n   Classification and Data Analysis. Studies in Classification, Data Analysis, and Knowledge\r\n   Organization. Springer, Berlin, Heidelberg (1999)\r\n5. Mola, F., Klaschka, J., Siciliano, R.: Logistic classification trees. In: Prat, A. (ed.) COMPSTAT\r\n   1996, pp. 373-378. Physica-Verlag, Heidelberg (1996)", :session 54, :keywords (655 327 654)}, 93 {:id 93, :title "Frugal Gaussian Clustering of Huge Imbalanced Datasets Through a Bin-Marginal Approach", :authors (184 111 110), :abstract "Clustering conceptually reveals all its interest when the dataset size considerably\r\nincreases since there is the opportunity to discover tiny but possibly high value\r\nclusters which were out of reach with more modest sample sizes. However, clustering \r\nis practically faced to computer limits with such high data volume, since\r\npossibly requiring extremely high memory and computation resources. In addition,\r\nthe classical subsampling strategy, often adopted to overcome these limitations, is\r\nexpected to heavily failed for discovering clusters in the highly imbalanced cluster \r\ncase. Our proposal first consists in drastically compressing the data volume by\r\njust preserving its bin-marginal values, thus discarding the bin-cross ones. Despite\r\nthis extreme information loss, we then prove identifiability property for the diagonal \r\nmixture model and also introduce a specific EM-like algorithm associated to a\r\ncomposite likelihood approach. This latter is extremely more frugal than a regular\r\nbut unfeasible EM algorithm expected to be used on our bin-marginal data, while\r\npreserving all consistency properties. Finally, numerical experiments highlight that\r\nthis proposed method outperforms subsampling both in controlled simulations and\r\nin various real applications where imbalanced clusters may typically appear, such as\r\nimage segmentation, hazardous asteroids recognition and fraud detection.\r\n\r\n", :session 59, :keywords (277 313 231 38 520 212)}, 6 {:id 6, :title "A New Decomposition of Orthogonal Matrices with Application to Common Principal Components", :authors (333 68), :abstract "In many statistical problems, the estimation of a (d × d) orthogonal matrix Q is \r\ninvolved [2]. The orthonormality constraints on Q often makes this estimation difficult.\r\nTo cope with this problem, we use the well-known PLU decomposition [3], which\r\nfactorizes any invertible (d × d) matrix as the product of a (d × d) permutation\r\nmatrix P, a (d × d) unit lower triangular matrix L, and a (d × d) upper triangular\r\nmatrix U. Thanks to the QR decomposition [3], we find the formulation of U when\r\nthe PLU decomposition is applied to Q. We call the result as PLR decomposition;\r\nit produces a one-to-one correspondence between Q and the d (d − 1) /2 entries\r\nbelow the diagonal of L, which are advantageously unconstrained real values. Thus,\r\nonce the decomposition is applied, regardless of the objective function under consideration, \r\nwe can use any classical unconstrained optimization method to find the minimum (or maximum) \r\nof the objective function with respect to L. For illustrative purposes, we apply the PLR \r\ndecomposition in common principle components  analysis (CPCA) for the maximum likelihood \r\nestimation of the common orthogonal matrix when a multivariate leptokurtic-normal distribution \r\nis assumed in each group. Compared to the commonly used normal distribution, the leptokurtic-normal\r\nhas an additional parameter governing the excess kurtosis [1]; this makes the estimation of Q in \r\nCPCA more robust against mild outliers. The usefulness of the PLR decomposition in leptokurtic-normal \r\nCPCA is illustrated by two biometric data analyses.\r\n\r\nReferences\r\n1. Bagnato, L., and Punzo, A., and Zoia, M.G.: The Multivariate Leptokurtic-Normal \r\n   Distribution and its Application in Model-Based Clustering. Can. J. Stat. 45, \r\n   95–119 (2017)\r\n2. Graybill, F.A.: An Introduction to Linear Statistical Models. McGraw-Hill (1976)\r\n3. Lutkepohl, H.: Handbook of Matrices. John Wiley & Sons, Chicester (1996)\r\n", :session 12, :keywords (452 343 82 205 322)}, 111 {:id 111, :title "Time Resolved Feature Importance of a Biopharmaceutical Purification Process Using\r\nPermutation Based Methods", :authors (381 540 72 195), :abstract "Real-time monitoring of critical process parameters of biotechnological processes\r\nis a major step towards quality-by-design in the production of biopharmaceuticals.\r\nThe emergence of novel monitoring devices has resulted in the accumulation of\r\ncomplex high-dimensional data. Recently, statistical models capable of predicting\r\ncritical process parameters online -e.g. the product or impurity concentration- have\r\nbeen developed. However, to generate these models the variable space has been\r\nreduced manually based on expert knowledge. This presents a problem as (a) expert\r\nknowledge is not always available, especially for novel technologies, (b) experts\r\nmight overlook important variables and (c) the importance of some variables might\r\nbe unknown in general. Therefore, we propose a deep learning framework capable\r\nof predicting critical process parameters of a biopharmaceutical purification process\r\nbased on the whole high-dimensional variable space (1400 variables). To achieve\r\nthis, a neural network architecture consisting of two parallel strands that are \r\nconcatenated at the end has been developed. One strand consists of fully connected layers\r\nand takes standalone variables -e.g. pH, conductivity- as input, while the other strand\r\nconsists of convolutional layers and utilizes whole Fourier transform infrared spectra\r\nas input. Using this method, the model itself learns, which variables contain useful\r\ninformation or not. By determining the variable importances with the model, \r\n(a) previously unknown correlations and patterns can be identified to gain further \r\nunderstanding about the underlying mechanics of the purification process and \r\n(b) more accurate models can be generated that utilize all informative variables available.\r\n\r\n", :session 82, :keywords (135 671 476 39)}, 28 {:id 28, :title "Parsimonious Mixtures of Seemingly Unrelated Contaminated Normal Regression Models", :authors (200 201), :abstract "In recent years, the research into multivariate linear regression based on finite mixture\r\nmodels has been intense. With such an approach, it is possible to perform regression\r\nanalysis for a multivariate response by taking account of the possible presence of\r\nseveral unknown homogeneous groups, each of which is characterised by a different\r\nlinear regression model. For a continuous multivariate response, mixtures of normal\r\nregression models are generally employed. However, in real data, mildly atypical\r\nobservations can negatively affect the estimation of the regression parameters under\r\na normal distribution in each mixture component. Robust methods insensitive to the\r\npresence of such observations have been recently introduced [1]. Furthermore, in\r\nsome fields of research, a multivariate regression model with a different vector of\r\ncovariates for each response should be specified, based on some prior information\r\nto be conveyed in the analysis. This approach has been recently embedded into the\r\nframework of Gaussian mixture models [2]. To take account of all these aspects,\r\nmixtures of seemingly unrelated contaminated normal regression models has been\r\ndefined [3]. A further extension is presented here so as to ensure parsimony, which\r\nis obtained by imposing constraints on the component-covariance matrices. The\r\nresulting parsimonious mixtures of seemingly unrelated contaminated regression\r\nmodels are described together with an illustration of their practical usefulness.\r\n\r\nReferences\r\n1. Mazza, A., Punzo, A.: Mixtures of multivariate contaminated normal regression models. Stat.\r\n   Pap. 169, 787–822 (2020)\r\n2. Galimberti, G., Soffritti, G.: Seemingly unrelated clusterwise linear regression. Adv. Data\r\n   Anal. Classif. 14, 235–260 (2020)\r\n3. Perrone, G., Soffritti, G.: Seemingly unrelated clusterwise linear regression for contaminated\r\n   data. Under review (2021)", :session 34, :keywords (107 168 378 385 559)}, 134 {:id 134, :title "Latent Function-On-Scalar Regression Models for Observed Sequences of Correlated Binary\r\nData: a Restricted Likelihood Approach", :authors (175 561), :abstract "In function-on-scalar regression problems, the response curve is sometimes observed\r\nas a sequence of correlated binary or multilevel data. This kind of situations can be\r\nhandled via the family of generalized functional regression models, with several\r\nproposals in this direction already present in the literature [2, 3]. In this talk, we\r\nintroduce a functional regression setting where the random response curve is unobserved,\r\nand only its dichotomized version as a sequence of correlated binary data is\r\nobserved. We propose a practical computational framework for maximum likelihood\r\nanalysis relying on the use of a complete data likelihood, which has the advantages of\r\nscaling to large datasets, and of handling non-equally spaced and missing observations\r\neffectively and flexibly. The proposed method is used in the Function-on-Scalar\r\nregression setting, with the latent response variable being a Gaussian random element\r\ntaking values in a separable Hilbert space. We provide smooth estimations for\r\nthe functional regression coefficients and principal components by introducing an\r\nadaptive Monte Carlo Expectation Maximization (MCEM) algorithm that circumvents\r\nselecting the smoothing parameters. The novel method is described in details\r\nin [1], where its performance is also demonstrated by simulated and real case studies, \r\nand is implemented in the R package dfrr.\r\n\r\nReferences\r\n1. Asgari, F., Alamatsaz, M.H., Vitelli, V., Hayati, S.: Latent function-on-scalar \r\n   regression models for observed sequences of binary data: a restricted likelihood approach. \r\n   arXiv preprint arXiv:2012.02635.(2020)\r\n2. Goldsmith, J., Zipunnikov, V., Schrack, J.: Generalized multilevel function-on-scalar \r\n   regression and principal component analysis. Biometrics, 71, 344–353 (2015)\r\n3. Scheipl, F., Gertheiss, J., Greven, S.: Generalized functional additive mixed models. \r\n   Electron. J. Stat. 10, 1455–1492 (2016)", :session 53, :keywords (213 329 349)}, 64 {:id 64, :title "Two Simple But Efficient Algorithms to Recognize Robinson Dissimilarities", :authors (401 221 567 435), :abstract "A dissimilarity d on a set S of size n is said to be Robinson [3] if its matrix can\r\nbe symmetrically permuted so that its elements do not decrease when moving away\r\nfrom the main diagonal along any row or column. Equivalently, s admits a total\r\norder < such that i < j < k implies that d(i, j) <= d(i, k) and d(j, k) <=  d(i, k).\r\nIntuitively, d is Robinson if d can be represented by points on a line. Recognizing\r\nRobinson dissimilarities has numerous applications in seriation and classification.\r\nIn this paper, we present two simple algorithms (inspired by Quicksort) to recognize\r\nRobinson dissimilarities. One of these algorithms uses partition refinement [2] and\r\nruns in O(n^2 lon n), the other one uses PQ-trees [1] and runs in O(n^3) in worst case\r\nand in O(n^2) on average.\r\n\r\nAcknowledgements This work was supported in part by ANR project DISTANCIA (ANR-17-CE40-0015).", :session 57, :keywords (541 63 567 493 470)}, 189 {:id 189, :title "Franz Liszt’s Transcendental Études: an Evolutionary Analysis by Machine Learning", :authors (379), :abstract "Musical data mining is a young discipline, that is gaining momentum in recent\r\nyears (see [1]). In this paper, we apply the most relevant tools of Music Information\r\nRetrieval (MIR, see [2]) to Franz Liszt’s Transcendental Études, with the aim to\r\nmark the evolution of his composition style and musical grammar. We consider the\r\nthree versions of Transcendental Études published by the composer in 1826, 1837\r\nand 1851. We perform a systematic evolutionary analysis of each Étude, and we\r\ncompare different recordings of some Études.\r\n  For each trace, we estimate the amplitude spectrum, the envelope spectrum, and\r\nthe spectrogram, in order to retrieve the musical content in terms of frequencies\r\nand intensity over time. Based on the estimated spectral features, we derive the\r\nchromagram, that is the redistribution of the spectrum over the twelve notes of the\r\nchromatic scale across all the registers. We also perform a segmentation based on the\r\ndegree of novelty, intended as spectral dissimilarity, calculated frame-by-frame via\r\nthe cosine distance. This process allows to discover and compare the macro-formal\r\nstructure of the Études across the three published versions in terms of harmonic and\r\nmelodic content.\r\n  Generally speaking, we learn that the first version represents a sketch of each\r\nÉtude, the second version is a highly technical evolution of the first version, while\r\nthe definitive version is characterized by the high degree of technical difficulty of\r\nthe second version and the same formal clarity of the first version.\r\n\r\nReferences\r\n1. Cancino-Chacón, C., Carlos E., Grachten, M., Goebl, W., Widmer, G.: Computational models\r\n   of expressive music performance: a comprehensive and critical review. Frontiers in Digital\r\n   Humanities. 5, 321–354 (2018)\r\n2. Müller, M. Fundamentals of music processing: audio, analysis, algorithms, applications.\r\n   Springer, 2015.\r\n3. Lartillot, O., Toiviainen, P., Eerola, T.: A MATLAB toolbox for music information retrieval.\r\n   In: Data analysis, machine learning and applications, pp. 261-268. Springer, (2008)", :session 24, :keywords (415 598 210)}, 280 {:id 280, :title "Depth-Based Classifiers for Partially Observed Functional Data", :authors (64 472 58 323), :abstract "Partially observed functional data are frequently encountered in applications and are\r\nthe object of an increasing interest by the literature. We here address the problem\r\nof classification in the context of partially observed functional data based on Depth\r\nto-Depth classifiers [1]. To do that, we propose an integrated functional depth for\r\npartially observed functional data [2], dealing with the very challenging case where\r\npartial observability can occur systematically on any observation of the functional\r\ndataset. In particular, differently from many techniques for partially observed \r\nfunctional data, we do not request that some functional datum is fully observed, nor \r\nwe require that a common domain exist, where all of the functional data are recorded.\r\nBecause of this, our proposal can also be used in those frequent situations where\r\nreconstructions methods and other techniques for partially observed functional data\r\nare inapplicable. By means of simulation studies, we demonstrate the very good\r\nperformances of the proposed depth on finite samples. We illustrate our proposal\r\nwith a classification problem with data obtained from medical imaging.\r\n\r\nReferences\r\n1. Cuesta-Albertos, J. A., Febrero-Bande, M., and Oviedo de la Fuente, M.: \r\n   The DD^G-classifier in the functional setting. TEST, 26, 119–142 (2017)\r\n2. Elías, A., Jiménez, R., Paganoni, A. M. and Sangalli, L.: Integrated depths \r\n   for partially observed functional data. J. Comput. Graph. Stat.. (2022)\r\n", :session 65, :keywords (63 469 143)}, 198 {:id 198, :title "Reinforced EM Algorithm Through Clever Initialization for Clustering with Gaussian\r\nMixture Models", :authors (290 106 402), :abstract "Gaussian mixture models (GMMs) are a prominent clustering method that assume\r\nthe data generating process to be a mixture distribution of a finite number of \r\nGaussian components. The clusters are taken to be the constituent components. GMMs\r\nare ubiquitous in clustering applications as they are both simple and flexible, \r\nallowing the clusters to vary in terms of their shape, size and orientation. In practice,\r\nthe Expectation Maximization (EM) algorithm is used to find maximum likelihood\r\nestimates of the GMM parameters. As the likelihood function is non-convex, care\r\nmust be taken to ensure that EM is initialized with values close to the true parameters. \r\nPresent initialization methods fail to provide such estimates. The random\r\ninitialization approach fails to ensure consistency between runs, and can cause EM\r\nto converge to arbitrarily bad values of the likelihood. A widely used deterministic\r\napproach initializes EM using partitions from likelihood-based hierarchical clustering. \r\nThis method is computationally infeasible for large datasets, and is ill-suited for\r\ndetecting clusters of different sizes. We here propose initialization scheme which is\r\napplicable to large datasets and reliably produces consistent clustering outputs. We\r\napply an efficient mode-finding criterion to generate a set of initial mean vectors.\r\nThis set is then pruned through optimization of a convex objective with an adaptive\r\ncardinality penalty. We demonstrate how to prune the mean vectors one at a time,\r\ngenerating a sequence of nested clustering results. We provide guidance on how\r\nto select the optimal clustering from this sequence. We present theoretical guarantees \r\nfor the quality of our initialization and experimental results to verify that our\r\nalgorithm works well in practice.\r\n\r\n", :session 59, :keywords (190 232 139 112)}, 155 {:id 155, :title "Model Free Predictive Inference for Functional Kriging Techniques Based \r\non Conformal Prediction", :authors (46 154 286), :abstract "In the last years several geostatistical predictive techniques like universal kriging,\r\nkriging with external drift and kriging with residuals has been extended to the\r\nfunctional framework to predict curve at unmonitored location. Here we present\r\na new approach for model-free spatial prediction for kriging methods based on\r\nthe conformal prediction. We propose non conformity measures for this class of\r\npredictive methods and introduce a local spatial conformal prediction algorithm that\r\nyields valid functional prediction intervals without any distributional assumption.\r\nPractical solutions are provided to construct conformal intervals and are compared\r\nwith existing validation methods. The approach is illustrated on some well known\r\ndata sets, on simulated and on a real data.\r\n\r\nReferences\r\n1. Degras, D.A.: Simultaneous confidence bands for nonparametric regression with functional\r\n   data. Statist. Sinica 21, (2011)\r\n2. Diquigiovanni, J., Fontana, M., Vantini, S.: Conformal Prediction Bands for Multivariate\r\n   Functional Data. Journal of Multivariate Data Analysis (2022).\r\n3. Franco-Villoria, M., Ignaccolo, R.: Bootstrap based uncertainty bands for prediction in \r\n   functional kriging,  Spatial Statistics, Volume 21, Part A,pp. 130-148, (2017).\r\n4. Franco-Villoria, M. Ignaccolo, R.: Universal, Residual, and External Drift Functional Kriging.\r\n   In: Geostatistical Functional Data Analysis. Giraldo, R., Mateu, J. (eds.) Wiley & Sons Ltd,\r\n   pp. 55-72, (2022).\r\n5. Giraldo, R., Delicado, P. and Mateu, J. (2011). Ordinary kriging for function-valued spatial\r\n   data. Environmental and Ecological Statistics, 18, 411-426.\r\n6. Ignaccolo, R., Mateu, J. and Giraldo, R. :Kriging with external drift for functional data for air\r\n   quality monitoring. Stochastic Environmental Research and Risk Assessment, 28, 1171-1186, (2014)", :session 37, :keywords (220 494 384 94)}, 248 {:id 248, :title "Students’ Assessment Through a IRT and Archetypal Analysis Joint Strategy", :authors (336 192), :abstract "Item response theory [1, IRT] measures latent traits from one or more sets of manifest\r\nvariables, namely items, by defining the relations between the observed variables\r\n(e.g., item responses to a test) and the latent variables. Three of the five higher \r\neducation items that refer to student’s abilities, as defined by the Dublin descriptors, \r\nare considered in this proposal: knowledge, application, judgment. IRT models assume\r\nthat students belong to homogeneous groups concerning these abilities. Mixture\r\nIRT models [2, mixIRT] assume that the observed population is composed of latent\r\nsubpopulations with class-specific quantitative parameters, representing a practical\r\napproach to finding groups by aggregating the units with respect to group’s average\r\nabilities. However, assessors generally want to discover \"extreme\" groups of students:\r\nthe most skilled, but especially those profiles that have peculiar deficits for one or\r\nmore learning abilities, to define a recommendation system helping the student to fill\r\nthe gaps. Archetypical analysis (AA) represents an effective data partitioning alternative \r\nto the clustering approaches around the means. The archetypes are observed or unobserved \r\nextreme points lying on the convex-hull, minimizing the sum of the squared distances from \r\nall points. The algorithm computes a membership vector for each unit with respect to each \r\narchetype. This proposal integrates the mixIRT model with the probabilistic archetypal \r\nanalysis [3, PAA], presenting a hybrid estimation algorithm which iteratively computes \r\nthe latent variables and the units’ memberships to a set of k archetypes, where k is \r\nassumed to be known.\r\n\r\nReferences\r\n1. Hambleton, R. K., Swaminathan, H.: Item response theory, principles and applications.\r\n   Springer Science & Business Media (1985)\r\n2. Mislevy, Robert J., Verhelst, N.: Modeling item responses when different subjects employ\r\n   different solution strategies. Psychometrika 55.2, 195-215 (1990)\r\n3. Seth, S., Eugster, M.J.A.: Probabilistic archetypal analysis. Mach Learn 102.1, 85-113 (2016)", :session 67, :keywords (298 75 320)}, 227 {:id 227, :title "Dimensionality Reduction and Multivariate Time Series Classification", :authors (566 54 156), :abstract "In this work we tackle the problem of dimensionality reduction when classifying\r\nmultivariate time series (MTS). Multivariate time series classification is a \r\nchallenging task, especially as sparsity in raw data, computational runtime and \r\ndependency among dimensions increase the difficulty to deal with such complex data.\r\n  In a recent work, a novel subspace model named EMMV (Ensemble de Mhistogrammes \r\nMulti-Vues) [1] that combines M-histograms and multi-view learning together with \r\nan ensemble learning technique to handle the MTS classification task was reported. \r\nThe aforementioned model has shown good results when compared to state of the art \r\nMTS classification methods. Before performing the classification itself, EMMV reduces \r\nthe dimension of the multivariate time series using correlation analysis, and uses \r\nafter that a random selection of the views. In this work, we explore two more \r\nalternatives to the dimensionality reduction method used in EMMV, the goal being to \r\ncheck the efficiency of randomness on EMMV. The first technique named Temporal Laplacian \r\nEigenmaps [2] comes from manifold learning and the second one named Fractal Redundancy \r\nElimination [3] comes from the fractal theory. Both are nonlinear dimensionality reduction \r\nalgorithms in contrast to correlation analysis which is linear, meaning that the first cited \r\nare able to eliminate more correlations than the latter.\r\n  We then conduct several experiments on available MTS benchmarks in order to compare the \r\ndifferent techniques, and discuss the obtained results.\r\n\r\nAcknowledgements: This work was partially supported by LabEx IMobS3 and \r\n                  IMI2-H2020 Project NeuroDeRisk.", :session 72, :keywords (412 150 63)}, 220 {:id 220, :title "Conditional Gaussian Mixture Modeling", :authors (573 577), :abstract "Due to a potentially high number of parameters, finite mixture models are often at\r\nthe risk of overparameterization even for a relatively low number of components.\r\nThis can lead to overfitting and result in mixture order underestimation. One of\r\nthe most popular approaches to alleviate this issue is to reduce the number of\r\nparameters by considering parsimonious models. The vast majority of techniques\r\nin this area focus on the reparameterization of covariance matrices associated with\r\nmixture components. We propose an alternative approach that shows great modeling\r\nflexibility. The utility of the proposed methodology is demonstrated on simulated as\r\nwell as well-known classification data sets.\r\n\r\n", :session 74, :keywords (206 386 466)}, 103 {:id 103, :title "Categorical Data Visualization and the Cressie-Read Divergence Statistic", :authors (159 485), :abstract "The literature on correspondence analysis is largely centred on Pearson’s chi-squared\r\nstatistic (Greenacre, 1984; Beh and Lombardo, 2014). For such an analysis, differences \r\nbetween categories is assessed using the chi-squared distance while distances\r\nin a low-dimensional space are Euclidean. Recently, Beh and Lombardo (2022)\r\nshowed that the Cressie-Read divergence statistic (Cressie and Read, 1984) plays\r\na pivotal role in correspondence analysis. This is because Pearson’s statistic, the\r\nFreeman-Tukey statistic, the log-likelihood ratio statistic and others are special cases\r\nof this statistic. Therefore, differences amongst categories can be assessed using this\r\ndivergence statistic and still yield Euclidean distances in a low-dimensional space.\r\nThis is very appealing since it provides a greater range of difference measures, including \r\nthe chi-squared, Hellinger and logarithmic distances.This paper compares the quality and \r\nconfiguration of points in a low-dimensional correspondence plot using the Cressie-Read \r\ndivergence statistic. This will be done by deriving a global measure that allows for such \r\na comparison and is an extension of a similar measure presented in the past; see, for example, \r\nCuadras, Cuadras and Greenacre (2006).\r\n\r\nReferences\r\n1. Beh, E.J., Lombardo, R.: Correspondence analysis: Theory, practice and new strategies.\r\n   Wiley, Chichester (2014)\r\n2. Beh, E.J., Lombardo, R.: Correspondence analysis and the Cressie-Read Divergence Statistic.\r\n   Submitted (2022)\r\n3. Cressie, N.A.C., Read, T.R.C.: Multinomial goodness-of-fit tests. Journal of the Royal\r\n   Statistical Society, Series B, 46, 440–464 (1984)\r\n4. Cuadras, C.M., Cuadras, D., Greenacre, M.J.: A Comparison of Different Methods for\r\n   Representing Categorical Data. Communications in Statistics - Simulation and Computation,\r\n   35, 447–459 (2006)\r\n5. Greenacre, M.: Theory and application of correspondence analysis. Academic Press, London\r\n   (1984)", :session 55, :keywords (475 122 85)}, 170 {:id 170, :title "PLS-Based Principal Balances for Regression and Classification with \r\nHigh-Dimensional Compositional Data", :authors (558 238 309 249 431 253), :abstract "Compositional data naturally occur in many different research fields, such as \r\ngeochemistry or metabolomics. Due to their relative nature, compositions cannot be\r\ndirectly analysed using standard statistical methods. Instead, it is common to express\r\ncompositional data as log-ratio coordinates with respect to an orthonormal basis of\r\ntheir sample space, see [1, 3], named as orthonormal logratio (olr) coordinates.\r\nPrincipal balances (PBs) are a specific class of olr coordinates, which are a suitable \r\nchoice in a high-dimensional context, see [2]. They are constructed such that\r\nthe first few coordinates capture most of the original data variability. In this work,\r\nwe adapt the PB procedure introduced in [2] to be used for variable selection in\r\nregression and classification problems with a high-dimensional composition acting\r\nin an explanatory role. Moreover, hereby we extend popular logcontrast models to\r\nconsider other potentially interesting (orthonormal) logcontrasts. For this, partial\r\nleast squares (PLS) estimation is embedded into the construction of the PBs. The\r\nperformance of the proposal is demonstrated using simulated and real-world data.\r\n\r\nReferences\r\n1. Filzmoser, P., Hron, K., Templ, M.: Applied compositional data analysis. Springer, Cham\r\n   (2018)\r\n2. Martín-Fernández, J.A., Pawlowsky-Glahn, V., Egozcue, J.J., Tolosona-Delgado, R.: Advances\r\n   in principal balances for compositional data. Math. Geosci. 50, 273–298 (2018)\r\n3. Pawlowsky-Glahn, V., Egozcue, J.J, Tolosana-Delgado, R.: Modeling and analysis of \r\n   compositional data. John Wiley & Sons (2015)", :session 42, :keywords (261 496 487)}, 51 {:id 51, :title "Typology of Motivation Factors for Employees in the Banking Sector: \r\nMultivariate Data Analysis", :authors (73 426 343 500 222), :abstract "The main purpose of this work is to know the perceptions of bank employees on the\r\nmain motivational factors in the organizational context. Data analysis was performed\r\nbased on Categorical Principal Component Analysis (CatPCA) and some agglomerative \r\nhierarchical clustering algorithms from VL parametrical family, applied to the\r\nitems that aim to assess the aspects most valued by bankers. The CatPCA allowed\r\nto extract four principal components which explain almost 70% of the total data\r\nvariance. The dendrograms provided by the hierarchical clustering algorithms over\r\nthe same data, exhibit four main branches, which are associated with different main\r\nmotivational factors. Moreover, CatPCA and clustering results show an important\r\ncorrespondence concerning the main motivations in this sector.\r\n\r\nReferences\r\n1. Bacelar-Nicolau: The affinity coefficient. In: Bock, H.-H. and Diday, E. (eds.) Analysis \r\n   of Symbolic Data: Exploratory Methods for Extracting Statistical Information from Complex\r\n   Data, Series: Studies in Classification, Data Analysis, and Knowledge Organization, \r\n   pp. 160-165. Springer-Verlag, Berlin (2000) doi: 10.1007/978-3-642-57155-8\r\n2. Lerman, I.C.: Foundations and Methods in Combinatorial and Statistical Data Analysis and\r\n   Clustering. Series: Advanced Information and Knowledge Processing. Springer-Verlag, Boston\r\n   (2016)", :session 64, :keywords (318 689 389 53 69)}, 25 {:id 25, :title "Fuzzy Clustering by Hyperbolic Smoothing", :authors (130 163 266 8), :abstract "We propose a novel method for building fuzzy clusters of large data sets, using a\r\nsmoothing numerical approach. The usual sum-of-squares criterion is relaxed so\r\nthe search for good fuzzy partitions is made on a continuous space, rather than a\r\ndiscrete space as in classical methods [2]. The smoothing allows a conversion from a\r\nstrongly non-differentiable problem into low dimensional differentiable subproblems\r\nof optimization without constraints, by using an infinitely differentiable function.\r\nFor the implementation of the algorithm we used the statistical software R and the\r\nresults obtained were compared to the traditional fuzzy C–means method, proposed\r\nby Bezdek [1].\r\n\r\nReferences\r\n1. Bezdek, J.C.: Pattern Recognition with Fuzzy Objective Function Algorithms. \r\n   Plenum Press, New York (1981)\r\n2. Hartigan, J.A.: Clustering Algorithms. Wiley, New York, NY (1975)", :session 20, :keywords (75 226 439)}, 201 {:id 201, :title "Sampling Design for Uncovering Natural Laws in Compositional Data", :authors (320 218 259), :abstract "Natural law refers to a stable mathematical relationship being constructed by some\r\nparts of the composition obtained from nature. One of the common forms of natural\r\nlaws in the composition is the constant logcontrast relationship between parts, usually\r\nindicating a compositional system at an equilibrium state. A statistical approach to\r\ndetecting this form of law includes two steps: 1) collecting appropriate data for\r\nthe analysis, and 2) choosing proper statistical methods to analyze the data. In\r\nthe aspect of statistical methodology, ample studies have shown that the logratio\r\nprincipal component analysis (LR-PCA) is an effective tool for detecting the constant\r\nlogcontrast patterns [1, 2]. However, though the sampling design is also an important\r\naspect of statistical design, limited literature discusses its effect on drawing accurate\r\nconclusions about the laws in composition. Therefore, this study aims to investigate\r\nthe limitations of different sampling methods on LR-PCA procedure and develop\r\nmore suitable sampling strategies for law detection.\r\n  Through a simulation study of genotype frequencies in Hardy Weinberg Equilibrium (HWE), \r\nwe found that when generating a 3D compositional data set containing HWE law, if one variable \r\nis assigned an exact value and thus has a small variance, the ratios between pair-wise variables \r\nare close to constants. In this context, the LR-PCA may report the proportionality between two \r\nparts instead of the law of interest. To avoid this problem, high heterogeneity in compositional \r\nsamples is required.\r\n\r\nReferences\r\n1. Aitchison, J.: Logratios and natural laws in compositional data analysis. Mathematical \r\n  Geology. 31 (5), 563–580 (1999)\r\n2. Pawlowsky-Glahn, V., Egozcue, J.J., Tolosana-Delgado, R.: Modeling and Analysis of Compositional \r\n   Data. John Wiley & Sons, Chichester (2015)", :session 33, :keywords (87 418 99 328 552)}, 166 {:id 166, :title "Simultaneous Factorial Reduction and Clustering for Three-Mode Data Sets: \r\na Comparison", :authors (460 6 384 213), :abstract "Two iterative techniques, called T3Clus and 3Fkmeans, aimed at a simultaneous\r\nclustering of objects and a factorial dimensionality reduction of variables and \r\noccasions on three-mode data sets, as well as a combination of these two procedures\r\nwere proposed in [1]. In each iteration, T3Clus (3Fkmeans) is based on a sequential\r\napplication of the Tucker2 algorithm and the k-means algorithm (vice versa). We\r\nhave implemented the three simultaneous methods in Python. In this work, applications \r\non real data sets are presented to show the features of these three simultaneous\r\nmethods when compared with tandem analyses which can be executed in two different ways. \r\nIn a tandem analysis only one sequential application of clustering and factorial \r\nmethodologies is performed.\r\n\r\nAcknowledgements This work was partially supported by the Center for Research and Development \r\n                 in Mathematics and Applications (CIDMA, University of Aveiro) through the \r\n                 Portuguese Foundation for Science and Technology (FCT - Fundação para a Ciência \r\n                  e a Tecnologia), reference UIDB/04106/2020.", :session 76, :keywords (637 75 200)}, 34 {:id 34, :title "Clustering Brain Connectomes Through a Density-Peak Approach", :authors (475), :abstract "The density-peak (DP) algorithm is a mode-based clustering method that identifies\r\ncluster centers as data points being surrounded by neighbors with lower density\r\nand far away from points with higher density. Since its introduction in 2014, DP\r\nhas reaped considerable success for its favorable properties. A striking advantage is\r\nthat it does not require data to be embedded in vector spaces, potentially enabling\r\napplications to arbitrary data types. In this work, we propose improvements to\r\novercome two main limitations of the original DP approach, i.e., the unstable density\r\nestimation and the absence of an automatic procedure for selecting cluster centers.\r\nThen, we apply the resulting method to the increasingly important task of graph\r\nclustering, here intended as gathering together similar graphs. Potential implications\r\ninclude grouping similar brain networks for ability assessment or disease prevention,\r\nas well as clustering different snapshots of the same network evolving over time to\r\nidentify similar patterns or abrupt changes. We test our method in an empirical\r\nanalysis whose goal is clustering brain connectomes to distinguish between patients\r\naffected by schizophrenia and healthy controls. Results show that, in the specific\r\nanalysis, our method outperforms many existing competitors for graph clustering.\r\n\r\n", :session 32, :keywords (435 381 426 247 306)}, 146 {:id 146, :title "Comparison of survival prediction models for pancreatic cancer: Cox model vs. machine\r\nlearning models", :authors (236 536 508), :abstract "A survival prediction model has been recently developed to evaluate the prognosis\r\nof nonmetastatic resected pancreatic ductal adenocarcinoma (PDAC) based on a Cox\r\nmodel using two nationwide database: Surveillance, Epidemiology and End Results\r\n(SEER) and Korea Tumor Registry System-Biliary Pancreas (KOTUS-BP). In this\r\nstudy, we applied the two machine learning methods such as random survival forests\r\n(RSF) and support vector machines (SVMs) for survival analysis, and compared\r\nthe prediction performance with the Cox model, RSF and SVMs using SEER and\r\nKOTUS-BP datasets. For the model development and evaluation, three different\r\nschemes were conducted. First, we utilized data from SEER for model development\r\nand used data from KOTUS-BP for external evaluation. Secondly, these two datasets\r\nwere swapped by taking data from KOTUS-BP for model development and data from\r\nSEER for external evaluation. Finally, we mixed these two datasets half and half and\r\nutilized the mixed datasets as either a model development or a validation. We used\r\n9,624 patients from SEER and 3,281 patients from KOTUS-BP for constructing a\r\nprediction model and only seven covariates including age, sex, histologic differentiation, \r\nadjuvant treatment, resection margin status, AJCC 8th T-stage and N-stage were\r\nutilized due to the difference between sets of covariates in two datasets. Comparing\r\nthe three schemes for constructing survival prediction models, the performance of\r\nCox model, RSF and SVM is better when using mixed dataset rather than when\r\nusing unmixed dataset. When using mixed dataset, the C-index, 1-year, 2-year, and\r\n3-year time-dependent AUCs for the Cox model were 0.644, 0.698, 0.680, and 0.687,\r\nrespectively. Similarly, the C-index, 1-year, 2-year, and 3-year time-dependent AUCs\r\nfor RSF were 0.634, 0.682, 0.668, and 0.678, respectively while those for SVM were\r\n0.623, 0.685, 0.635, and 0.626, respectively. In conclusion, the Cox model performs\r\nslightly better than the two machine learning methods such as RSF and SVM. This\r\nis probably because only seven clinical variables were available for constructing the\r\nprediction model.\r\n\r\n", :session 68, :keywords (121 521 621)}, 125 {:id 125, :title "On the Role of Data, Statistics and Decisions in a Pandemic", :authors (554 81 503 277 278 469 368 4 422 369 557 542), :abstract "A pandemic poses particular challenges to public health decision-making because of\r\nthe need to continuously adapt public measures to rapidly changing evidence and data\r\navailability. This presentation provides an overview of the process of decision making\r\nusing data in a pandemic and gives recommendations for the different steps from a\r\nstatistical perspective. A range of modelling techniques with different goals including\r\nmathematical, statistical and decision-analytic models applied in the COVID-19\r\ncontext are briefly introduced. We discuss the importance of statistical literacy, and\r\nof effective dissemination and communication of findings.\r\n  One recommendation relates to the need and value of interdisciplinary cooperation. \r\nCooperation is central in a pandemic to the society at large, but also specifically\r\nwithin the field of data science: we should act as a specialist group rather than as\r\nindividuals, broadly positioned and media-sensitive. The presentation is based on a\r\nmanuscript summarizing the discussion of an interdisciplinary group [1].\r\n  Presenting this topic at the IFCS, we aim to foster the understanding of the goals\r\nof these modelling approaches and the specific data requirements that are essential\r\nfor data collection and transformation, the interpretation of results and for successful\r\ninterdisciplinary collaborations among statisticians, epidemiologists, public health\r\nexperts, social sciences, and ethicists, as well as health decision and communication\r\nscientists.\r\n\r\nReferences\r\n1. Jahn, B., Friedrich, S., Behnke, J., Engel, J., Garczarek, U., Munnich, R., Pauly, M., \r\n   Wilhelm, A., Wolkenhauer, O., Zwick, M., Siebert, U., Friede, T: On the role of data, \r\n   statistics and decisions in a pandemic AStA Adv Stat Anal (forthcoming).\r\n   https://doi.org/10.48550/arXiv.2108.04068", :session 31, :keywords (462 387 608 131)}, 276 {:id 276, :title "MARGOT: a Maximum MARGin Optimal Classification Tree", :authors (177 372), :abstract "In recent years there has been a growing attention to machine learning models which\r\nare able to give explanatory insights on the decisions made by the algorithm. Thanks\r\nto their interpretability, decision trees have been intensively studied for classification\r\ntasks, and, due to the remarkable advances in mixed-integer programming (MIP),\r\nvarious approaches have been proposed to formulate the Optimal Classification Tree\r\n(OCT) problem as a MIP model starting from the seminal paper [2]. We present\r\na novel MIQP formulation for binary classification using OCT and exploiting the\r\ngeneralization capabilities of Support Vector Machines. The maximum MARGin\r\nOptimal Classification Tree (MARGOT) selects at each node of the decision tree a\r\nmaximum margin separating hyperplane using an l_2-norm linear SVM (see e.g. [1]\r\nand references therein). The resulting model combines such multivariate hyperplanes\r\nminimizing the global misclassification error. The model can also include feature\r\nselection constraints, following e.g. [3], which allows to define a hierarchy on the\r\nsubsets of features which mostly affect the outcome. MARGOT has been tested on\r\nnon-linearly separable synthetic datasets in a 2-features space in order to provide\r\na graphical representation of the optimal hyperplanes. Finally, MARGOT has been\r\ntested on benchmark datasets from the UCI repository.\r\n\r\nReferences\r\n1. Piccialli, V. and Sciandrone, M.: Nonlinear optimization and support vector machines. Ann\r\n   Oper Res (2022).\r\n2. Bertsimas, D. and Dunn, J.: Optimal classification trees. Machine Learning, 7, 1039–1082\r\n   (2017).\r\n3. Labbé, M., and Martínez-Merino, L. I. and Rodríguez-Chía, A. M.: Mixed integer linear\r\n   programming for feature selection in support vector machine. Discrete Applied Mathematics\r\n   261, 276–304 (2019).", :session 80, :keywords (621 447 368)}, 148 {:id 148, :title "Robust Classification in High Dimensions Using Regularized Covariance Estimates", :authors (560 455), :abstract "High-dimensional highly correlated data exist in many application domains which\r\nrequires the development of appropriate statistical methods. The classical classification\r\nmethods like LDA and QDA become practically useless in such a setting because\r\nthey will suffer from the singularity problem if the number of observed variables p\r\nexceeds the number of observations n. Numerous regularization techniques with the\r\npurpose to stabilize the classifier and achieve an improved classification performance\r\nhave been developed and there exist several studies comparing various regularization\r\ntechniques trying to facilitate the choice of a method. However, these methods are\r\nvulnerable to the presence of outlying observations (outliers) in the training data set\r\nwhich can influence the obtained classification rules and make the results unreliable.\r\nOn the other hand, the high breakdown versions of discriminant analysis proposed in\r\nthe literature, like [3] do not work or are not reliable in high dimensions. We propose\r\nto utilize the recently introduced regularized versions of the minimum covariance\r\ndeterminant (MCD) estimator - the regularized MCD (RMCD) estimator [2] and\r\nthe minimum regularized covariance determinant (MRCD) estimator [1] to define\r\nthe robust discriminant rules which will combine high robustness to outliers with\r\napplicability in high dimensions. The computations can be done with the R package\r\nrrcov available at CRAN. Simulated and real data examples show that the proposed\r\nmethods perform better than the existing ones in a wide range of settings.\r\n\r\nReferences\r\n1. Boudt, K., Rousseeuw, P.J., Vanduffel, S., Verdonck, T.: The minimum regularized \r\n   covariance determinant estimator. Statistics and Computing 30(1), 113–128 (2020).\r\n2. Croux, C., Gelper, S., Haesbroeck, G.: Regularized minimum covariance determinant \r\n   estimator. Technical report, Mimeo New York (2012).\r\n3. Hubert, M., Van Driessen, K.: Fast and Robust Discriminant Analysis. Computational \r\n   Statistics & Data Analysis 45, 301–320 (2004).", :session 11, :keywords (529 260 542)}, 17 {:id 17, :title "Modeling a Most Specific Generalization in Domain Taxonomies", :authors (588 75), :abstract "We define a most specific generalization of a fuzzy set of topics assigned to leaves\r\nof the rooted tree of a domain taxonomy. This generalization lifts the set to its\r\n“head subject” node in the higher ranks of the taxonomy tree. The head subject is\r\nsupposed to “tightly” cover the query set, possibly involving some errors referred\r\nto as “gaps” and “offshoots”. We develop a method to globally maximize either the\r\nparsimony or the likelihood of a scenario involving gains and losses of the general\r\nconcept manifested in a fuzzy cluster of leaf nodes of the taxonomy. Supplemented\r\nwith fuzzy c-means clustering, this allows us to obtain meaningful generalizations\r\nfor fuzzy thematic clusters of Data Science topics using several dozen thousand\r\nabstracts from issues of relevant research journals published from 2000 on.\r\n\r\nReferences\r\n1. The 2012 ACM Computing Classification System — Association for Computing Machinery.—2012.\r\n   — URL: https://www.acm.org/publications/class-2012.\r\n2. E. Chernyak, B. Mirkin. Refining a taxonomy by using annotated suffix trees and Wikipedia\r\n   resources // Annals of Data Science. Vol. 2, no. 1, 61-82, 2015.\r\n3. D. Frolov, S. Nascimento, T.I. Fenner, B. Mirkin. Parsimonious generalization of fuzzy \r\n   thematic sets in taxonomies applied to the analysis of tendencies of research in \r\n   Data Science. Information Sciences, 512, pp. 595-615, 2020. ", :session 69, :keywords (233 347 346 227 536)}, 279 {:id 279, :title "Current Challenges in Interpretable Machine Learning and Partitioning Approaches", :authors (83), :abstract "Model-agnostic interpretation methods in machine learning produce explanations\r\nbased on non-linear, non-parametric prediction models. Explanations are often \r\nrepresented in the form of summary statistics or visualizations, e.g., feature \r\nimportance values or effects. Many interpretation methods either describe the \r\nbehavior of a black-box model locally for a specific observation or globally for \r\nthe entire model and input space. Methods that produce regional explanations and \r\nlie between local and global explanations are rare and not well studied, but offer \r\na flexible way to combine advantages of both types of explanations. Here, we will \r\nfocus on subgroup approaches for IML methods, where interpretable areas in the input \r\nspace are often induced by a combination of recursive partitioning and IML. These \r\nsubgroup approaches will be studied in the contexts of interpretable permutation \r\nfeature importance and PDPs [1], interaction detection [2], and interpretable \r\nhyperparameter tuning [3].\r\n\r\nReferences\r\n1. Molnar, C., König, G., Bischl, B., & Casalicchio, G. (2020). Model-agnostic Feature \r\n   Importance and Effects with Dependent Features – A Conditional Subgroup Approach. \r\n   arXiv preprint arXiv:2006.04628.\r\n2. Herbinger, J., Bischl, B., & Casalicchio, G. (2022, May). REPID: Regional Effect Plots\r\n   with implicit Interaction Detection. In International Conference on Artificial Intelligence \r\n   and Statistics (pp. 10209-10233). PMLR.\r\n3. Moosbauer, J., Herbinger, J., Casalicchio, G., Lindauer, M., & Bischl, B. (2021). Explaining\r\n   Hyperparameter Optimization via Partial Dependence Plots. Advances in Neural Information\r\n   Processing Systems, 34.\r\n", :session 75, :keywords (332 290 691)}, 12 {:id 12, :title "Clustering Adolescent Female Physical Activity Levels with an Infinite Mixture Model on Random Effects", :authors (33 538 133 547), :abstract "Physical activity trajectories from the Trial of Activity in Adolescent Girls (TAAG)\r\ncapture the various exercise habits over female adolescence. Previous analyses of\r\nthis longitudinal data from the University of Maryland field site, examined the effect\r\nof various individual-, social-, and environmental-level factors impacting the change\r\nin physical activity levels over 14 to 23 years of age. We aimed to understand the\r\ndifferences in physical activity levels after controlling for these factors. Using a\r\nBayesian linear mixed model incorporating a model-based clustering procedure for\r\nrandom deviations that does not specify the number of groups a priori, we find that\r\nphysical activity levels are starkly different for about 5% of the study sample. These\r\nyoung girls are exercising on average 23 more minutes per day.\r\n\r\n", :session 71, :keywords (30 339 374 537 603)}, 152 {:id 152, :title "Localization Processes for Functional Data Classification", :authors (64 472 252), :abstract "We propose an alternative to k-nearest neighbors for functional data whereby the\r\napproximating neighboring curves are piecewise functions built from a functional\r\nsample. Using a locally defined distance function that satisfies stabilization criteria,\r\nwe establish pointwise and global approximation results in function spaces when\r\nthe number of data curves is large enough. We exploit this feature to develop the\r\nasymptotic theory when a finite number of curves is observed at time-points given\r\nby an i.i.d. sample whose cardinality increases up to infinity. We use these results\r\nto study the problem of functional classification and outlier detection. For such\r\nproblems our methods are competitive with and sometimes superior to benchmark\r\npredictions in the field.\r\n\r\n", :session 28, :keywords (218 420 454)}, 2 {:id 2, :title "Anomaly Detection-Based Under-Sampling for Imbalanced Classification Problems", :authors (583 112 480 141), :abstract "In this research, we propose a new anomaly detection-based under-sampling method\r\ncalled ADU to improve the classification performance of imbalanced datasets by \r\neffectively removing anomalies, such as outliers and noises. To detect the anomalies \r\nin different clusters effectively, three useful approaches are considered. Specifically, \r\nto detect the outliers belonging to the majority class, neighborhood-based and density\r\nbased outlier detection methods, namely OBN (outlierness based on neighborhood) and \r\nDBSCAN (density-based spatial clustering based on noise applications) are\r\nused [1, 2]. Finally, to eliminate the borderline noise samples in the majority class\r\n(i.e., the majority class samples with low membership probabilities), a membership\r\nprobability-based under-sampling is proposed with changing the under-sampling rate\r\nso that a proportion of majority class samples can be removed.\r\n\r\nReferences\r\n1. Gupta, U., Bhattacharjee, V., Bishnu, P.S.: A New Neighborhood-Based Outlier Detection\r\n   Technique. In: Nath, V., Mandal, J.K. (eds.) MCCS 2018, pp. 527-534. Springer, Singapore\r\n   (2018)\r\n2. Ester, M., Kriegel, H.P., Sander, J., Xu, X.: A density-based algorithm for discovering clusters\r\n   in large spatial databases with noise. In: Simoudis, E., Han, J., Fayyad U. (eds.) KDD 1996,\r\n   pp. 226-231. AAAI Press, Oregon, USA. (1996)\r\n", :session 45, :keywords (63 60 61 664 356)}, 66 {:id 66, :title "Combining Latent Class Analysis and Multiple Correspondence Analysis", :authors (27), :abstract "Both Latent Class Analysis (LCA) and Multiple Correspondence Analysis (MCA)\r\nare analysis methods to find patterns in complex categorical data tables. LCA \r\naims at representing heterogeneity in the observed data by estimating internally \r\nhomogeneous groups (the latent classes). It can thus be understood as a \r\nprobability-based clustering approach. MCA is a scaling method that reduces the \r\ndimensionality of a multi-way frequency table. As such, it is an extension of \r\nsimple correspondence analysis (CA) for two-way frequency tables. Both CA and MCA \r\nare often used to visualize relations in a lower-dimensional space. Several \r\npossibilities of combining LCA and correspondence analysis have been discussed. \r\nSome authors use MCA as a diagnostic tool to select variables which are subsequently \r\nused in an LCA. Others propose to visualize results from an LCA using CA [1].\r\n  In this presentation, a different approach is discussed: the projection of LCA \r\nresults as passive variables into a two-dimensional space created by MCA, using the \r\nexample of relations between attitudes towards migration and socio-demographic \r\ncharacteristics in Germany (World Values Survey Round 7, 2017). First, latent structures \r\nin attitudes towards migration are estimated based on eight items such as ”immigration\r\nin your country increases unemployment” with answer options ”agree”, ”disagree” and ”hard \r\nto say”. Information criteria indicate a four-class-solution. Second, a ”social space” is \r\nconstructed via MCA. Here, socio-demographic characteristics such as gender, highest \r\neducational qualification, occupational group and size of town of residence are used. \r\nThe association of latent class membership with certain sociodemographic characteristics \r\nis assessed by projecting the categories of the latent class variable (modal posterior \r\nprobabilities) into the two-dimensional MCA solution. Further, possibilities of preserving \r\ninformation on individuals’ probabilities of class membership in this approach are discussed.\r\n\r\nReferences\r\n1. McCutcheon, A.: Correspondence Analysis Used Complimentary to Latent Class Analysis in\r\n   Comparative Social Research. In: Blasius, J., Greeenacre, M. (eds.) Visualization of \r\n   CategoricalData, pp. 477-488. Academic Press (1998)", :session 76, :keywords (49 314 114)}, 142 {:id 142, :title "Spatio-Temporal Variability of Distribution and Abundance of Sardine in Portuguese\r\nContinental Coast: Environmental Effects", :authors (129 470 40 41 532), :abstract "Scientific tools capable of identifying the distribution patterns of species are important\r\nas they contribute to improve knowledge about biodiversity and species\r\nabundance, to make sustainable management decisions and conserve biodiversity.\r\nThis study aims to estimate the spatio-temporal distribution of sardine (Sardina\r\npilchardus, Walbaum 1792) in the Western Iberian waters and Gulf of Cadiz, relating\r\nthe spatio-temporal variability of biomass indicator with the environmental conditions.\r\nAcoustic data was collected during Portuguese spring acoustic (PELAGO)\r\nsurveys conducted by the Portuguese Institute for Sea and Atmosphere (IPMA) over\r\na total of 19920 hauls from 2000 to 2020 (gap in 2012). Daily environmental data was\r\nobtained for the region and time of study, particularly satellite derived sea surface\r\ntemperature, chlorophyll-a concentration, bathymetry, and intensity and direction of\r\nocean currents. Species Distribution Models are investigated to relate sardine presence/\r\nabsence and biomass with the environmental conditions, aiming at predicting\r\nsardine distribution in unobserved locations and for the unobserved year of 2012.\r\nThe hurdle Bayesian models become suitable since they allow to incorporate the\r\nspecificities of the data: complex spatio-temporal dynamics, excess of zeros, and\r\nthe difference between the occurrence and biomass under occurrence processes. The\r\nhurdle model is a two-part model such that species biomass is given by the product\r\nof these two processes. In addition to considering the spatio-temporal structure, the\r\nimpact of the covariates with a time lag on biomass indicator is evaluated using a\r\nkernel gaussian function. Data from the west and south Iberian coasts are studied\r\nseparately due to the shape of the coast and the different oceanographic conditions.\r\n\r\n", :session 83, :keywords (184 239 272 553 597)}, 107 {:id 107, :title "Isolation Forests for Symbolic Data as a Tool for Outlier Mining", :authors (50 355), :abstract "The intuitive definition of an outliers would be ’an observation which deviate so\r\nmuch from other observations as to arouse suspicions that is generated by a different\r\nmechanism’. Detection of outliers is a fundamental issue in data analysis, its main\r\ngoal is to detect and remove anomalous objects from the data. Because the technology\r\nchanges rapidly, number of databases and their size grows over time, which makes\r\noutlier detection and removal even harder.\r\n  The main aim of the paper is to propose an adaptation of well-known isolation\r\nforest methods, that has been proofed to be useful in outlier detection in the classical\r\ndata, for symbolic data case. Isolation forest uses well-known decision tree idea\r\nto detect anomalies using isolation on the basis how far a data point is to the\r\nrest of the data, rather than modelling normal points. The same ideas (applying\r\nideas of the decision tree) can be used for symbolic data. In the empirical part of\r\nthe presentation artificial and real data with outliers is used to evaluate proposed\r\napproach and compare it with DBSCAN, decision tree and kernel discriminant\r\nanalysis for symbolic data.\r\n\r\nReferences\r\n1. Diday, E., Noirhomme-Fraiture, M.: Symbolic data analysis and the SODAS software. Wiley,\r\n   Chichester (2008).\r\n2. Liu, F.T., Ting, K.M., & Zhou, Z.H.: Isolation forest. In 2008 eighth ieee international\r\n   conference on data mining (pp. 413-422). IEEE (2008).\r\n3. Aggrawal, Ch.C.: Outlier analysis. Second edition. Springer (2018).", :session 36, :keywords (455 626 296)}, 23 {:id 23, :title "A Proposal for Formalization and Definition of Anomalies in Dynamical Systems", :authors (261 273 276), :abstract "Although many scientists strongly focus on anomaly detection in different applications \r\nand domains, there currently exists no universally accepted definition of anomalies and \r\noutliers bib2. Using an approach based on control theory and dynamical systems, as well \r\nas a definition for anomalies as described by philosophy of science bib5, the authors \r\npropose a generalized framework viewing anomalies as key drivers of progress for a better \r\nunderstanding of the dynamical systems around us. By mathematically defining anomalies and \r\ndelimiting deviations within expectations from completely unforeseen instances, this paper \r\naims to be a contribution to set up a universally accepted definition of anomalies and outliers.\r\n\r\nReferences\r\n1. Hodge, V.J.; Austin, J.A.: Survey of Outlier Detection Methodologies. Artif Intell Rev 22, \r\n   pp. 85-126 (2004)\r\n2. Spoor, J.M.; Weber, J.; Ovtcharova, J.: A Definition of Anomalies, Measurements and Predictions \r\n   in Dynamical Engineering Systems for Streamlined Novelty Detection. Accepted for the 8th International \r\n   Conference on Control, Decision and Information Technologies (CoDIT), Istanbul (2022)", :session 69, :keywords (14 453 165)}, 230 {:id 230, :title "Envelope-Based Support Vector Machine Classifier", :authors (30 48), :abstract "The envelope method is a relatively new and efficient dimension reduction technique\r\nthat was introduced in the regression framework by Cook 2010 [1]. In this work,\r\nwe extended this method to classification and developed a new projection-based \r\napproach based on a Support Vector Machine (SVM) classifier. Our proposed classifier\r\nis obtained by combining the envelope method and SVM to achieve a better and more\r\nefficient classification. Using the idea of the envelope to extract a lower-dimensional\r\nsubspace projected the data on has advanced the classification performance.\r\n\r\nReferences\r\n1. Cook, R. Dennis, Bing Li, and Francesca Chiaromonte. Envelope models for parsimonious\r\n   and efficient multivariate linear regression. Statistica Sinica. 927-960 (2010)", :session 17, :keywords (63 149 620 182)}, 47 {:id 47, :title "Clustering in FDA Mixing the Epigraph and the Hypograph Indexes \r\nwith Machine Learning Algorithms", :authors (82 13 481), :abstract "Clustering is considered as one of the most used techniques in Data Science. \r\nClustering functional data is a challenging problem since it involves working in \r\nan infinite dimensional space. In this work this problem is addressed by applying \r\nthe epigraph and the hypograph indexes to a functional dataset and thereby, converting \r\nit from a functional data problem into a multivariate problem. See [1]. Once the \r\nmultivariate dataset is obtained, the techniques that have been fully studied in the \r\nliterature for clustering multivariate data can be applied, including both procedures \r\ntypical of the area of Statistics and those from the machine learning field. This \r\nmethodology is applied to both simulated and real datasets, and it is also compared to \r\ntwo clustering techniques originally designed for functional data ([2] and [3]).\r\n\r\nReferences\r\n1. Pulido, B., Franco-Pereira, A.M., Lillo, R.E.: Functional clustering via multivariate \r\n   clustering. arXiv:2108.00217 [stat.ME] (2021)\r\n2. Martino, A., Ghiglietti, A., Ieva, F., Paganoni, A.M.: A k-means procedure based on a\r\n   Mahalanobis type distance for clustering multivariate functional data. Statistical Methods \r\n   and Applications, 28(2), 301-322 (2019)\r\n3. Zambom, A.Z., Collazos, J.A., Dias, R.: Functional data clustering via hypothesis testing\r\n   k-means. Computational Statistics, 34(2), 527-549 (2019)", :session 28, :keywords (185 274 75 215 333)}, 180 {:id 180, :title "Digital Development and Internet Use in the European Union Countries", :authors (181 5), :abstract "In this study we analyze how people from the European Union countries are prepared\r\nto work and use in their lives the digital technologies. It is also interesting to know\r\nwhether the least developed countries are close or quite distant from the others in\r\nthis way to the digital.\r\n  We considered some variables associated with digital skills, digital economy\r\nand digital society, and collected the data from Eurostat database during the period\r\n2010-2020. To analyze the data, we applied a Double Principal Component Analysis\r\n(DPCA), a method of multivariate data analysis introduced in Bouroche [1] to analyze\r\nthree-way data with quantitative variables. We considered six different data tables,\r\ncorresponding to the years 2010, 2012, 2014, 2016, 2018 and 2020, with the same\r\ncountries and variables. As the UK does not belong to the EU countries in 2020,\r\nand all the tables must have the same countries to apply a DPCA, we considered the\r\nvalues obtained in 2019 for the UK to include it in the analysis.\r\n  The results allow to identify the differences and similarities between countries\r\nand variables along the period of time 2010-2020, more precisely, to study the \r\nevolution trends of the countries and the evolution of the relations between the \r\ndifferent variables.\r\n\r\nAcknowledgements This work is financed by National Funds through the Portuguese funding\r\n                 agency, FCT - Fundação para a Ciência e a Tecnologia, within the projects \r\n                 UIDB/00006/2020 (CEAUL) and LA/P/0063/2020 (INESC TEC).", :session 44, :keywords (146 160 497)}, 158 {:id 158, :title "Fifty Years of Biplots: Some Remaining Enigmas and Challenges", :authors (259), :abstract "Biplots have found applications in many fields of science, where they are often used\r\nto detect groups, outliers or other regularities in multivariate data. A recent search\r\nat the web of science (using the core collection) reveals there are well over 2,200\r\nscientific articles that refer to biplots since the term was first coined by Gabriel [1].\r\nSeveral textbooks on biplots are available with a varying level of mathematical depth,\r\nthough classical textbooks on multivariate analysis have been slow at incorporating\r\nthe concept, or at recognising its universal value for all classical methods that are\r\nbased on the singular value decomposition.\r\n  In applied scientific studies, several aspects of biplot construction and interpretation \r\nare still not well understood, to the point that it is easy to find a poor biplot\r\nin a high-impact scientific journal. Some of the more problematic aspects will be\r\naddressed in the talk and concern: the choice of the multivariate method, aspect ratio, \r\nbiplot scaling, interpretation rules and (sub)optimality of approximations among\r\nothers. There is a lot of software available for making biplots, but in spite of this, the\r\ntruth is that many users would not be able to make an optimal biplot for representing\r\none of the most elementary matrices: the correlation matrix.\r\n  The growing size of datasets being analysed poses an important challenge to\r\nbiplot methodology. For example, by 2015 the 1,000 genomes project contained\r\ninformation on 88 million genetic polymorphisms for over 2,500 human individuals,\r\nobviously impossible to sensibly represent in a single biplot. In this situation, cases\r\nand variables are finally often presented in separate plots, thereby sacrificing the\r\nbiplot’s most appealing feature: its ability to jointly represent and interpret observations \r\nand variables. We address some examples in the high-dimensional context,\r\nwhere biplots are too dense, often have low goodness-of-fit, and where aggregation,\r\nclustering or filtering are needed to make their application feasible.\r\n\r\nReferences\r\n1. Gabriel, K.R.: The biplot graphic display of matrices with application to principal \r\n   component analysis. Biometrika. 58(3), 453–467 (1971)", :session 8, :keywords (40 578 262)}, 35 {:id 35, :title "A Review on Official Survey Item Classification for Mixed-Mode Effects Adjustment", :authors (10 447), :abstract "The COVID-19 pandemic has had a direct impact on the development, production,\r\nand dissemination of official statistics. This situation led National Statistics Institutes\r\n(NSIs) to make methodological and practical choices for survey collection without\r\nthe need for the direct contact of interviewing staff (i.e. remote survey data collection). \r\nMixing telephone interviews (CATI) and computer-assisted web interviewing\r\n(CAWI) with direct contact of interviewing constitute a new way for data collection\r\nat the time COVID-19 crisis. This paper presents a literature review to summarize\r\nthe role of statistical classification and design weights to control coverage errors and\r\nnon-response bias in mixed-mode questionnaire design. We identified 289 research\r\narticles with a computerized search over two databases, Scopus and Web of Science.\r\nIt was found that, although employing mixed-mode surveys could be considered as a\r\nsubstitution of traditional face-to-face interviews (CAPI), proper statistical classification \r\nof survey items and responders is important to control the nonresponse rates and coverage error \r\nrisk.\r\n\r\nReferences\r\n1. Ashofteh, A., and Bravo, J.M.: A study on the quality of novel coronavirus (COVID-19)\r\n   official datasets. Stat. J. IAOS, vol. 36, no. 2, pp. 291–301, (2020). doi: 10.3233/SJI-200674\r\n2. Ashofteh, A., and Bravo, J.M.: Data science training for official statistics: A new scientific\r\n   paradigm of information and knowledge development in national statistical systems. Stat. J.\r\n   IAOS, vol. 37, no. 3, pp. 771–789, (2021). doi: 10.3233/SJI-200674\r\n3. Kim, S. and Couper, M.P.: Feasibility and Quality of a National RDD Smartphone Web\r\n   Survey: Comparison With a Cell Phone CATI Survey. Soc. Sci. Comput. Rev., vol. 39, no. 6,\r\n   pp. 1218–1236, (2021).", :session 81, :keywords (371 297 688 75 354)}, 127 {:id 127, :title "Spherical Separation in Machine Learning", :authors (377 61 65), :abstract "We extend the spherical separation approach to clustering problems and to the\r\nMultiple Instance Learning (MIL) paradigm, the latter constituting a kind of weak\r\nsupervised classification, using a multisphere criterion. In both the cases, while the\r\ncenters of the spheres are heuristically fixed, the corresponding radii are computed\r\nby solving a specific optimization problem.\r\n  In particular, for the clustering problem, all the centers are fixed in advance as\r\nthe barycenters of the current clusters (as in the standard K-Means algorithm), while\r\nthe corresponding radii are computed by solving a finite numbers of transportation\r\nproblems.\r\n  Instead, in the case of Multiple Instance Learning (MIL) problem whose objective\r\nis to categorize bags of instances, our proposed technique is based on iteratively \r\nseparating the bags by means of successive maximum-margin spheres (whose number\r\nis automatically determined), obtained by solving successive linear programs.\r\n  Numerical results on some test problems drawn from the literature show the\r\neffectiveness of our proposals.\r\n\r\n", :session 38, :keywords (332 602 75 400)}, 82 {:id 82, :title "Estimating Optimal Decision Trees for Treatment Assignment with k > 2 Treatment\r\nAlternatives: A Classification Problem with A unit- and Class- Dependent \r\nMisclassification Cost", :authors (248 56), :abstract "For many medical and psychological problems, multiple treatment alternatives are\r\navailable. Given data from a randomized controlled trial, an important challenge is\r\nto estimate an optimal decision rule that specifies for each patient the most effective\r\ntreatment alternative given his or her pattern of pretreatment characteristics. At this\r\npoint, optimality refers to the most favorable expected (potential) outcome if the\r\nrule would be applied to the entire population of patients of interest. The estimation\r\nproblem at hand can be shown to come down to a classification problem with a unitand \r\nclass-dependent misclassification cost, that is, a misclassification cost that may\r\ndepend on both the object that is misclassified and the class to which it is erroneously\r\nassigned.\r\n  Classification trees constitute an insightful class of solutions for problems of \r\ndecision rule estimation. Unfortunately, however, there is dearth of software tools for\r\ntree estimation that minimizes an object- and class-dependent misclassification cost,\r\nin particular for problems with k > 2 classes. In this talk, we explain how such an\r\nestimation can be achieved by means of a shrewd and novel type of application of a\r\nmainstream R-package for tree building, rpart, via a user-defined splitting function\r\nand a rectangular misclassification cost matrix. We illustrate with an application on\r\nthe search for an optimal tree-based treatment regime in a randomized controlled\r\ntrial on k = 3 different types of after-care for younger women with early-stage breast\r\ncancer. We finally argue that the proposed software solution may have relevance for various \r\nother classification problems with a unit- and class-dependent misclassification cost, such \r\nas credit card fraud detection and customer retention management.\r\n\r\n", :session 30, :keywords (66 666 448)}, 76 {:id 76, :title "Comparison of Segmentation Approaches for Partial Least Squares Path Modeling \r\nwith Stability Assessment", :authors (520 407 174 268 565), :abstract "In the social sciences, structural equation modeling has become an established\r\nmethod for analyzing complex interrelationships between manifest and latent \r\nvariables. In this context, the composite-based Partial Least Squares Path Modeling\r\n(PLS-PM) approach [2] has gained popularity over the past decades because of its\r\nversatility. Several segmentation methods dedicated to PLS-PM have been proposed\r\nto account for the potential heterogeneity of the data [3]. These techniques differ\r\nfrom each other in various aspects such as proceeding in two steps (PLS-PM then \r\nsegmentation) or not (simultaneous determination of local PLS-PM models per group),\r\nbeing based on finite mixture models, on a distance or more recently on alternate\r\nleast squares algorithm [1], etc. In this presentation, we propose to compare these\r\nsegmentation approaches both theoretically according to the criterion they optimize\r\nand practically by evaluating the stability of the different segmentations obtained \r\non the basis of a case study pertaining to marketing.\r\n\r\nReferences\r\n1. Fordellone, M., Vichi, M.: Finding groups in structural equation modeling through \r\n   the partial least squares algorithm. Comput. Stat. and Data Anal. 147, 106957 (2020)\r\n2. Lohmoller, JB.: Predictive vs. Structural Modeling: PLS vs. ML. In: Latent Variable \r\n   Path Modeling With Partial Least Squares, pp. 199-226. Springer, Heidelberg (1989)\r\n3. Sarstedt, M.: A review of recent approaches for capturing heterogeneity in partial \r\n   least squares path modelling. J. of Model. in Manag. 3, 140-161 (2008)", :session 12, :keywords (468 75 616 338)}, 97 {:id 97, :title "The Weighted RV Coefficient: Exact Moments by Invariant Orthogonal Integration", :authors (194), :abstract "Weighted configurations (f, D), describing the squared Euclidean dissimilarities D\r\nbetween n objects endowed with a normalized vector of weights f, are pervasive\r\nin Data Analysis. Weighted classical MDS, returning the configuration coordinates\r\nmaximizing the low-dimensional proportion of inertia, obtains as a straightforward\r\ngeneralization of the well-known Torgerson-Gower procedure. It is based upon the\r\nspectral decomposition of the matrix of weighted scalar products or kernel K.\r\n  Comparing two weighted configurations (f, D_X) and (f, D_Y ) with identical\r\nweights f can be performed by computing the coefficient CV_XY = trace(K_X K_Y),\r\nor its normalized version RV_XY = CV_XY / \\sqrt(CV_XX CV_YY) \\in [0, 1], which \r\nconstitutes the weighted extension of the RV similarity coefficient [1].\r\n  In the literature, there seems to be no complete agreement for the expressions of\r\nthe null expectation of the RV first moments, permitting to asses the significance of\r\nthe association between two configurations. We propose a new procedure consisting\r\nto integrate out products of orthogonal matrices occurring in the spectral decompositions \r\nof K_X and K_Y , yielding exact expressions for the three first moments of\r\nthe weighted RV coefficient; they depend on n and on the spectral moments of the\r\neigenvalues of K_X and K_Y (their scree graphs), but not on f.\r\n  Besides its relevance for applications (the scope of data analytic problems able to\r\nbe expressed by various kernels, including conditional kernels, seems inexhaustible),\r\nthe present approach sheds new light on some formal issues of interest, such as:\r\n• Under the null distribution, the skewness of the RV coefficient is here proportional\r\n  to the product of both spectral skewness, thus implying a positive RV skewness\r\n  for most ”natural” configurations, as often noticed in the literature [2].\r\n• The traditional Moran test of spatial auto-correlation fits info the present framework, \r\n  and its application can be generalized to multivariate features (and weighted\r\n  regions) by the introduction of an exact variance-deflating correction.\r\n\r\nReferences\r\n1. Robert, P. and Escoufier, Y.: A unifying tool for linear multivariate statistical methods: \r\n   the RV-coefficient. Journal of the Royal Statistical Society: Series C 25(3), 257–265 (1976)\r\n2. Josse, J., Pagès, J., and Husson, F.: Testing the significance of the RV coefficient. \r\n   Computational Statistics & Data Analysis 53(1), 82–91 (2008)", :session 18, :keywords (687 479 451)}, 19 {:id 19, :title "On Parsimonious Modelling via Matrix-Variate t Mixtures", :authors (494), :abstract "Mixture models for matrix-variate data have becoming more and more popular in\r\nthe most recent years. One issue of these models is the potentially high number of\r\nparameters. To address this concern, parsimonious mixtures of matrix-variate normal \r\ndistributions have been recently introduced in the literature. However, when data\r\ncontains groups of observations with longer-than-normal tails or atypical observations, \r\nthe use of the matrix-variate normal distribution for the mixture components may affect \r\nthe fitting of the resulting model. Therefore, we consider a more robust approach based \r\non the matrix-variate t distribution for modeling the mixture components. To introduce \r\nparsimony, we use the eigen-decomposition of the components scale matrices and we allow \r\nthe degrees of freedom to be equal across groups. This produces a family of 196 parsimonious \r\nmatrix-variate t mixture models. Parameter estimation is obtained by using an AECM algorithm. \r\nThe use of our parsimonious models is illustrated via a real data application, where \r\nparsimonious matrix-variate normal mixtures are also fitted for comparison purposes.\r\n\r\n", :session 43, :keywords (344 377 75 466)}, 202 {:id 202, :title "Functional Random Forest for Biomedical Signals Classification \r\nand Interpretative Tools", :authors (171 462), :abstract "This study deals with tree-based techniques and functional data analysis (FDA)\r\n[1] for supervised classification of curves representing high-dimensional \r\nbiomedical data recorded over time. Recently [3] proposed Functional Classification Trees\r\n(FCTs) and Functional Random Forest (FRF) [2] using b-spline representation and\r\nthe Functional Principal Components Decomposition (FPCD) as possible basis transformation \r\nto obtain features from curves for training the classifiers. In our proposal,\r\nan original contribution is also given by new interpretative tools of the functional\r\nclassification rules in the functional framework. Applications on ECG data have\r\nshown the effectiveness of the proposed functional classifiers in terms of accuracy\r\nand their usefulness in terms of interpretability.\r\n\r\nReferences\r\n1. Ramsay J, Silverman B. Functional Data Analysis, 2nd edn. New York: Springer (2005)\r\n2. Breiman L. Random Forests. Machine Learning 45(1) 5–32 (2001)\r\n3. Maturo, F., Verde, R.: Pooling random forest and functional data analysis for biomedical\r\n   signals supervised classification: theory and application to electrocardiogram data. \r\n   Statistics in Medicine, 1–29 (2022)", :session 65, :keywords (217 618 222)}, 200 {:id 200, :title "Variable Screening in High Dimensional Regression via Random Projection Ensembles", :authors (322 378 216 53), :abstract "Random projections (RP) are a fairly new tool for dimension reduction employed in\r\nseveral multivariate data analysis contexts (see, e.g. [2],[3]). In this paper, we present\r\na novel approach based on RP ensemble for variable screening in the multiple linear regression \r\nframework. By employing axis-aligned random projections, column sub-sampling is performed, thus \r\nconstituting an even cheaper way of randomized dimension reduction outside the class of \r\nJohnson-Lindenstrauss transforms. Differently from the approach proposed in [1], the method allows \r\nto account for the correlation among the predictors, and returns a variable ranking based on their\r\nimportance.\r\n  We provide numerical results based on synthetic and real data as well as basic theoretical results \r\nthat characterize the proposed solution.\r\n\r\nReferences\r\n1. Fan, J., Lv, J.: Sure independence screening for ultrahigh dimensional feature space. J. R. Stat.\r\n   Soc. B 70, 849–911 (2008)\r\n2. Gataric, M., Wang, T. and Samworth, R. J.: Sparse principal component analysis via axisaligned \r\n   random projections. J. R. Stat. Soc. B 82, 329–359 (2020)\r\n3. Thanei, G.A., Heinze, C., Meinshausen, N.: Random Projections for Large-Scale Regression.\r\n   In: Ahmed, S. (eds) Big and Complex Data Analysis, pp. 51-68. Contributions to Statistics.\r\n   Springer, Cham (2017)", :session 74, :keywords (672 519 264)}, 11 {:id 11, :title "Similarity Forest for Time Series Classification", :authors (545 346 444), :abstract "The idea of similarity forest comes from Sathe and Aggarwal [1] and is derived\r\nfrom random forest. Random forests proved to be one of the most excellent methods,\r\nshowing top performance across a vast array of domains, preserving simplicity, time\r\nefficiency, still being interpretable at the same time. However, its usage is limited \r\nto multidimensional data. Similarity forest does not require such representation — it \r\nis only needed to compute similarities between observations. Thus, it may be applied\r\nto data, for which multidimensional representation is not available. In this paper,\r\nwe propose the implementation of similarity forest for time series classification. We\r\ncompare the performance of similarity forest with 1NN classifier and random forest\r\non the UCR benchmark database. We show that similarity forest with DTW, taking\r\ninto account mean ranks, outperforms other classifiers. The comparison is enriched\r\nwith statistical analysis.\r\n\r\nReferences\r\n1. Sathe, S., Aggarwal, C.C.: Similarity Forests. Proc. of the 23rd ACM SIGKDD, \r\n   395–403 (2017)\r\n", :session 24, :keywords (641 643 515 570)}, 115 {:id 115, :title "Accuracy Measures for Binary Classification based on Quantitative Group Tests", :authors (489 279 399), :abstract "Classification of a large number of individuals using individual tests can be expensive\r\nand time-consuming. Hence, taking a sample from different individuals and mixing\r\nit into a homogeneous fluid (the pooled sample) may be a methodology to be taken\r\ninto account. Based on quantitative group testing, different classification procedures\r\ncan be performed to save resources, although the probability of misclassification\r\nmay increase due to the dilution of the discriminant substance in the pooled sample.\r\nIn this work, the specificity (\\Phi_\\epsilon) and sensitivity (\\Phi_s) of a classification \r\nmethodology based on quantitative group tests are used to create a ROC curve which depends \r\non the sensitivity and specificity from individual and group tests (i.e., from the cut-off \r\npoints applied in the individual and in the group tests), as well as on the group size. These\r\nROC curves are applied to assess the reliability of classification of some methodologies based \r\non quantitative group tests. The results were computed by simulation using populations with 106\r\nindividuals, different distributions for the discriminant substance (Gaussian, Weibull, Pareto, \r\nLevy, among others) setting different measures for the quality of the individual tests \\Phi_s = \r\n\\Phi_\\epsilon \\in {0.99, 0.95, 0.9, 0.8, 0.7}, prevalence rates p \\in {0.001, 0.005, 0.01, 0.05, \r\n0.1} and group sizes n \\in {2, 5, 10, 20, 50, 100}. In some cases, it is possible to almost maintain \r\nthe accuracy of the individual test and achieve a significant gain in efficiency.\r\n\r\nReferences\r\n1. Hughes-Oliver, J.: Pooling experiment for blood screening and drug discovery, screening \r\n   methods for experimentation in industry, Drug Discovery and Genetics, Springer, 48–68 (2006)\r\n2. Kim, H., Hudgens, M., Dreyfuss, J., Westreich, D., Pilcher, D.: Comparison of group testing \r\n   algorithms for case identification in the presence of testing error, Biometrics 63, 1152–63 (2007)\r\n3. Santos, R., Martins, J.P., Felgueiras, M.: An Overview of Quantitative Continuous Compound\r\n   Tests. In Bourguignon, J.P., Jeltsch, R., Pinto, A., Viana, M. (eds.) Dynamics, Games and\r\n   Science, CIM Series in Mathematical Sciences 1, 627–641 (2015)\r\n4. Santos, R., Martins, J., Felgueiras, M., Ferreira, L.: Accuracy Measures for Binary Classification \r\n   Based on a Quantitative Variable, REVSTAT-STAT J 17(2), 223–244 (2019)", :session 78, :keywords (63 148 251 548 574)}, 255 {:id 255, :title "Identification of Shared Genetic Loci Between Psychiatric Disorders and \r\nTelomere Length and Evaluation of Their Role as Potential Drug Targets", :authors (119 60 20), :abstract "Patients with psychiatric disorders such as bipolar disorder (BD), schizophrenia\r\n(SCZ) and major depression (MD) show features suggestive of accelerated cellular \r\naging such as shorter telomere length (TL). However, contrasting results have\r\nalso been reported. We leveraged large genome-wide association studies to investigate \r\nwhether shared genetic factors might predispose patients to cellular aging or rather \r\nplay a counteractive role. For BD (41,917 cases, 371,549 controls), SCZ\r\n(69,369 cases, 236,642 controls) and MD (170,756 cases, 329,443 controls) we\r\nused datasets from the Psychiatric Genomics Consortium, while for TL a metaanalysis \r\nincluding 78,592 individuals. We identified shared genetic loci with conjunctional false \r\ndiscovery rate (conjFDR) [1]. Heritability and bivariate local genetic correlation was \r\ninvestigated with LAVA, while target druggability with different tools, including DGIdb. \r\nWe identified two loci shared between BD and TL: 1) lead single nucleotide polymorphism (SNP) \r\nrs113833990, conjFDR=0.03; 2) lead SNP rs12919664, conjFDR=0.002. The latter showed significant \r\nheritability for BD (h2=0.0007, p=5.8E-06) and TL (h2=0.0004, p=0.006) and significant local \r\ngenetic correlation (rg=0.78, p=0.005). One locus shared between SCZ and TL (lead SNP rs143773357, \r\nconjFDR=0.03) showed significant heritability (SCZ: h2=0.002, p=1.1E-09; TL: h2=0.0004, p=0.044) \r\nand local genetic correlation (rg=0.78, p=0.007). For all loci, the lead SNP was associated with \r\nincreased TL and predisposition to psychiatric disorders. Our results suggest that shorter TL in\r\npatients with SCZ or BD could be at least partly counteracted by genetic factors.\r\n\r\nReferences\r\n1. Smeland, O.B., Frei, O., Shadrin, A. et al.: Discovery of shared genomic loci using the\r\n   conditional false discovery rate approach. Hum. Genet. 139, 85–94 (2020)", :session 31, :keywords (236 485 237 506)}, 145 {:id 145, :title "Biplots: A Sophisticated Multivariate Approach or a User-Friendly Technique?", :authors (345), :abstract "Predictive biplots are based on the visualization of the results of multivariate analyses\r\nthrough the relations between the objects and the original variables equipped with\r\nmeasuring scales, avoiding the interpretation of latent variables, making them a\r\nuseful tool for non-statisticians. However, to achieve this desideratum, biplots need\r\nto be automatically simplified as is commonly done with any multivariate analysis.\r\nThrough the definition of an axis mean standard predictive error (mspe), which\r\nevaluates the error that is made by the analyst when reading a biplot axis, it is\r\npossible to automatically select the axes to be included in the biplots, to define the\r\nnumber of dimensions necessary to conveniently describe any given problem, to\r\nenable the evaluation of outliers and avoid common overestimations. A series of\r\n\"AutoBiplot\" functions have been written in R to produce PCA [1] and CCA [2]\r\nbiplots and can be easily adjusted to many other multivariate analyses [3]. Apparently\r\nforgotten, interpolative biplots can be used in laboratory practical work, and can be\r\nautomatically produced following a similar strategy, based on the definition of an\r\noverall standard interpolative error (osie).\r\nAlthough the techniques for the automatic production of biplots are available, a\r\nwide use of biplots is still restricted mainly to statisticians. Therefore, a good way\r\nto commemorate fifty years of biplots may be to envisage ways of rendering these\r\nmethods available to any person needing to apply multivariate analysis.\r\n\r\nReferences\r\n1. Alves, M. R.: Evaluation of the predictive power of biplot axes to automate the construction \r\n   and layout of biplots based on the accuracy of direct readings from common outputs of \r\n   multivariate analyses: 1. application to principal component analysis. J. Chem., 26(5), 180–190 \r\n   (2012)\r\n2. Alves, M.R.: Getting full control of canonical correlation analysis with the AutoBiplot.CCA\r\n   function. AIP Conference Proceedings 1738, 370015 (2016);\r\n3. Barbosa, C., Oliveira, M. B., Alves, M. R.: Chemometrics in food authentication. In: Oliveira, B., \r\n   Mafra, I., Amaral, J. (eds) Current topics on food authentication, pp. 237-268. Transworld\r\n   Research Network, Kerala, India (2011).", :session 39, :keywords (41 402 23)}, 5 {:id 5, :title "Robustness Aspects of Optimized Centroids", :authors (260 437), :abstract "Centroids are often used for object localization tasks, supervised segmentation in\r\nmedical image analysis, or classification in other specific tasks. This paper starts\r\nby contributing to the theory of centroids by evaluating the effect of modified\r\nillumination on the weighted correlation coefficient. Further, robustness of various \r\ncentroid-based tools is investigated in experiments related to mouth localization \r\nin non-standardized facial images or classification of high-dimensional data in\r\na matched pairs design. The most robust results are obtained if the sparse centroid\r\nbased method for supervised learning is accompanied with an intrinsic variable\r\nselection. Robustness, sparsity, and energy-efficient computation turn out not to\r\ncontradict the requirement on the optimal performance of the centroids.\r\n\r\n", :session 58, :keywords (57 685 547 109 56)}, 112 {:id 112, :title "Continuous Adaptation to Distribution Drifts Through Continual Learning in Manufacturing", :authors (227 425), :abstract "Distribution drifts usually occur in the context of time series processing in manufacturing. \r\nThe causes for this problem include continual optimization of cutting processes in machining \r\nand incremental precision loss from long-term stress exerted on the machine’s components. \r\nTherefore, it is critical to understand the performance of machine learning (ML) models for \r\nanomaly detection in manufacturing under distribution drifts for reliable and robust virtual \r\nquality control.\r\n  In fact, the generalization capability of ML models is strongly compromised when\r\nperforming inference under a distribution different from the training data [1]. As a\r\nresult, these models can have a significant drop in performance with a negative impact\r\non overall equipment effectiveness (OEE). OEE is the gold standard in manufacturing\r\nthat defines productivity based on availability, performance and quality. In this\r\nregard, OEE decreases when workpieces produced under the new distribution are\r\nwrongly categorized as faulty workpieces, slowing down the manufacturing process\r\nby unnecessary and excessive manual quality measurements.\r\n  To avoid this kind of problem in production, anomaly detection systems must\r\nbe constantly evaluated, if necessary, retrained to the new data distribution and redeployed. \r\nInstead of adopting a manual and time-demanding workflow, continual learning approaches could \r\nacquire novel information from a continuous data stream. This property can possibly endow those \r\nsystems with continuous adaptation to contextual distribution drifts [2]. In the present study, \r\nwe aim to investigate how continual learning concepts can be exploited for the development of \r\nanomaly detection systems with continuous adaptation to distribution drifts on real-world \r\nmanufacturing data.\r\n\r\nReferences\r\n1. Liang, W. and Zou, J.: MetaShift: A Dataset of Datasets for Evaluating Contextual \r\n   Distribution Shifts and Training Conflicts. In ICLR (2022).\r\n2. Mundt, M., Lang, S., Delfosse, Q. and Kersting, K.: CLEVA-Compass: A Continual \r\n   Learning EValuation Assessment Compass to Promote Research Transparency and Comparability. \r\n   In ICLR (2022).", :session 45, :keywords (110 14 337)}, 179 {:id 179, :title "Natural Cubic Smoothing Splines for Latent Class Identification in Longitudinal Growth\r\nTrajectories", :authors (310 324), :abstract "Latent growth curve modeling is regularly used to examine intra-individual changes\r\nover time, inter-individual differences in intra-individual changes over time, as well\r\nas a variety of other intra- and inter-individual disparities over time. In such models,\r\nthe growth trajectories are usually modeled as linear functions. However, nonlinear\r\npatterns of change over time are quite common in social and behavioral science\r\nresearch. Recently Marcoulides and Khojasteh [2] proposed to use natural cubic\r\nsmoothing splines to analyze non-linear longitudinal data. This approach has the\r\nmain advantage of avoiding knot selection when using splines and avoids imposing\r\noverly restrictive assumptions that other non-linear modeling approaches often require. \r\nOne limitation is that all the sampled individuals in a given longitudinal study\r\nare assumed to rise from a single population. Traditional growth mixture modeling\r\nmethods are useful when analyzing such samples with unobserved heterogeneity,\r\nthough they still assume the growth trajectories to be the same for all individuals\r\nwithin a latent class [1]. During our presentation we will discuss a novel approach\r\nthat uses derivatives of individual natural cubic smoothing spline functions and then,\r\nfollowing some recent work by Marcoulides and Trinchera [3], applies a hierarchical \r\nclustering algorithm to group or cluster individuals who follow similar growth\r\ntrajectory patterns without requiring to define the number of classes a priori.\r\n\r\nReferences\r\n1. Diallo, T. M. O., Morin, A.J.S., Lu, H.: Impact of misspecifications of the latent \r\n  variancecovariance and residual matrices on the class enumeration accuracy of growth \r\n  mixture models. Struct. Equ. Model. 23, 507–531 (2016)\r\n2. Marcoulides, K.M., Khojasteh, J.: Analyzing longitudinal data using natural cubic smoothing\r\n   splines. Struct. Equ. Model. 25, 965–971 (2018)\r\n3. Marcoulides, K.M., Trinchera, L.: Detecting unobserved heterogeneity in latent growth curve\r\n   models. Struct. Equ. Model. 26, 390–401 (2018)", :session 79, :keywords (667 560 315)}, 245 {:id 245, :title "Patterns of Cooperation for Polish Authors of research Publications in Economics, \r\nBusiness and Medicine Area", :authors (555 445 347 352), :abstract "The analysis of the publication activity has not only great cognitive importance, but\r\nit should be treated as an important tool supporting scientific activity management.\r\nThe authors’ attention has been directed to this aspect of scientific productivity\r\nresearch, which concerns the analysis of main features of the network of cooperation\r\namong authors and the identification of the most frequent patterns of cooperation\r\n[1, 2].\r\n  The authors are planning to:\r\n1. identify the type of networks in the context of random networks (Erdős - Rényi -\r\nGilbert model) and small-world networks (Watts–Strogatz model),\r\n2. carry out an analysis of the structure of author teams and determine their size,\r\ndiversification of institutions and countries represented by authors and lastingness\r\nof teams,\r\n3. study the relationship between essential features of authors’ teams and main\r\nmeasures reflecting publication significance expressed by journal prestige and\r\nthe number of citations of a given paper,\r\n4. compare networks of authors and patterns of cooperation for economics, business\r\nand medicine area.\r\n  The analysis will be performed using data from Scopus database describing\r\nresearch publications of Polish authors working in the field of economics, business\r\nand medicine.\r\n\r\nReferences\r\n1. Cook, D.J., Holder, L.B. (eds.): Mining Graph Data. Wiley-Interscience (2010)\r\n2. Pieńkosz, K., Wojciechowski, J.: Grafy i sieci. Wydawnictwo Naukowe PWN, Warszawa\r\n   (2013)", :session 66, :keywords (555 473 424)}, 254 {:id 254, :title "A Deep Learning Analytics to Detect Dental Caries", :authors (535), :abstract "Deep Learning Analytics uses predictive models that provide actionable information\r\nfor a better prognosis of dental caries. It is a multidisciplinary approach based on \r\ndental caries data processing, AI technology-learning enhancement, dental caries data\r\nmining, and visualization. Three key components need further clarification to help\r\nthem effectively apply deep learning in dental caries prognosis to explain the methods\r\nfor conducting deep learning, the benefits of using deep learning, and the challenges\r\nof using learning analytics in dental caries. Discover significant socio-demographic\r\nfactors and microbiologic factors to detect the prognosis of dental caries. Compare\r\nthe efficiency with other prognosis models using support vector machine, linear\r\ndiscriminant, random forest, logistic regression by ROC curves using ICD-9 codes\r\nfor dental caries, 365 boys and 340 girl cohort with dental caries and normal group\r\ntogether. All available data variables required to develop and test models were \r\nidentified from a sociodemographic and microbiological records database. Data on 500\r\nrecords among 705 was utilized for the development of the model and on 205 patients\r\nutilized to perform cross-validation analysis of the models. Socio-demographic data\r\nsuch as presenting signs & symptoms, presence of caries, microbiologic data, and\r\ncorresponding diagnosis and outcomes were collected. Dental data was collected\r\nfor each target group was utilized to retrospectively ascertain optimal preventive\r\nmanagement for dental caries. Clinical presentations and corresponding treatment\r\nwere utilized as training examples.\r\n\r\nReferences\r\n1. Krizhevsky, A., Sutskever, I. & Hinton, G. ImageNet classification with deep convolutional\r\n   neural networks. In Proc. Advances in Neural Information Processing Systems 25 1090–1098\r\n   (2012)\r\n2. Sutskever, I. Vinyals, O. & Le. Q. V. Sequence to sequence learning with neural networks. \r\n   In Proc. Advances in Neural Information Processing Systems 27 3104–3112 (2014)", :session 31, :keywords (136)}, 283 {:id 283, :title "Categorical Data Analysis and Visualization", :authors (485 160), :abstract "The impact of the internet, social media and smart devices means that people are\r\nbecoming increasingly literate with use of these technologies and it has changed\r\nhow we engage with others on a professional and personal level. For the analyst, the\r\ncapacity to adapt to such changes has impacted upon the tools designed for analyzing \r\n“big data”, i.e. huge amount of numerical and categorical data. One of the most \r\nimportant tools is that of “visualization”. \r\n  With focus on categorical data, this tutorial, after briefly introducing association \r\nindices, models and methods, will outline some cutting-edge visualization tools and \r\ntechniques.\r\n\r\nContent: A Quick Historical Overview of the Visualization of Categorical Data;\r\n         The Contingency Table and the Chi-Squared Statistic; Measures of Symmetric \r\n         Association for I x J Contingency Tables; Correspondence Analysis (symmetrical,\r\n         non-symmetrical, ordinal) and Multiple and Multi-way Correspondence Analysis.\r\n\r\n", :session 2, :keywords ()}, 83 {:id 83, :title "Biplots Based on Latent Variable Models in the Analysis of Ecological Communities", :authors (271 502), :abstract "Throughout the last decade, joint species distribution modelling concept (JSDM,\r\n[1]) has gained popularity in the analysis of species communities, where the object\r\nof interests is usually in describing and understanding the structure and dynamics of\r\na group of interacting species. JSDMs offer a flexible approach for determining and\r\nassessing the mechanisms that drive the communities to exhibit patterns in observed\r\nspecies communities. One particular JSDM approach, which we focus on, is based on\r\ngeneralized linear latent variable models (GLLVMs,[2]). The GLLVMs are closely\r\nrelated to latent factor models which are applicable in several fields of science, but\r\nhere we consider them in the analysis of species communities.\r\n  While being capable to model, for example, environmental factors on species\r\nabundances and species-to-species associations, the GLLVMs also provide a modelbased \r\ntool for producing ordinations and biplots, thus providing a powerful tool for \r\nvisualizing those species-to-species associations and connecting them to the\r\nenvironmental or underlying latent factors driving the species communities. We\r\nintroduce the GLLVMs and show how they can be used for producing biplots. In\r\naddition, some useful properties of methods are illustrated by applying them to an\r\necological dataset.\r\n\r\nReferences\r\n1. Warton, D.I., Guillaume Blanchet, F., O’Hara, R.B., Ovaskainen, O., Taskinen, S., \r\n   Walker, S.C., Hui, F.K.C.: So Many Variables: Joint Modeling in Community Ecology. \r\n   Trends in Ecology & Evolution. 30(12), 766–779 (2015)\r\n2. Niku, J., Warton, D.I., Hui, F.K.C., Taskinen, S.: Generalized linear latent variable \r\n   models for multivariate count and biomass data in ecology. Journal of Agricultural, \r\n   Biological and Environmental Statistics, 22(4), 498–522 (2017)", :session 55, :keywords (40 317 299 596)}, 138 {:id 138, :title "Consistency of Trimmed Estimators of Scatter under the t-Distribution", :authors (45 335 339 11), :abstract "It is well known that trimmed estimators of multivariate scatter, such as the Minimum\r\nCovariance Determinant (MCD) estimator, are inconsistent unless an appropriate\r\nfactor is applied to them in order to take the effect of trimming into account. This\r\nfactor is widely recommended and applied when uncontaminated data are assumed\r\nto come from a multivariate Normal model (see, e.g., [4]). We address the problem\r\nof computing a consistency factor for the MCD estimator in a heavy-tail scenario,\r\nwhen uncontaminated data come from a multivariate Student’s C-distribution. The\r\nmultivariate C-distribution has a representation as an infinite mixture o fNormals with\r\nscales depending on Gamma distribution. This representation allows estimation of\r\nthe C-distribution parameters by using algorithms in the EM family. Additionally,\r\nthe required consistency factor for trimmed estimators of multivariate scatter, such\r\nas the MCD, can be obtained through the corresponding consistency factors defined\r\nunder the Normal model. We compare results from this mixture-based approach to\r\nanalytical derivation of consistency factors that follows from the functional \r\nrepresentation of the MCD [2]. We also consider implications for outlier detection [1] \r\nand robust clustering [3].\r\n\r\nReferences\r\n1. Cerioli, A.: Multivariate Outlier Detection With High-Breakdown Estimators. J. Am. Stat.\r\n   Assoc. 105, 147–156 (2010)\r\n2. Croux, C., Haesbroeck, G.: Influence Function and Efficiency of the Minimum Covariance\r\n   Determinant Scatter Matrix Estimator. J. Multivar. Anal. 71, 161–190 (1999)\r\n3. Dotto, F., Farcomeni, A., Garcìa-Escudero, L.A., Mayo-Iscar, A.: A reweighting approach \r\n   to robust clustering. Stat. Comp. 28, 477–493 (2018)\r\n4. Hubert, M., Debruyne, M., Rousseeuw, P.J.: Minimum covariance determinant and extensions.\r\n   WIREs Comput Stat. 10, e1421 (2018)", :session 11, :keywords (98 176 348 543)}, 14 {:id 14, :title "A New Regression Model for the Analysis of Microbiome Data", :authors (479 517), :abstract "Human microbiome data are becoming extremely common in biomedical research\r\ndue to the relevant connections with different types of diseases. A widespread discrete\r\ndistribution to analyze this kind of data is the Dirichlet-multinomial. Despite its\r\npopularity, this distribution often fails in modeling microbiome data due to the strict\r\nparameterization imposed on its covariance matrix.\r\n  The aim of this work is to propose a new distribution for analyzing microbiome data\r\nand to define a regression model based on it. The new distribution can be expressed\r\nas a structured finite mixture model with Dirichlet-multinomial components. We\r\nillustrate how this mixture structure can improve a microbiome data analysis to cluster\r\npatients into ”enterotypes”, which are a classification based on the bacteriological\r\ncomposition of gut microbiota. The comparison between the two models is performed\r\nthrough an application to a real gut microbiome dataset.\r\n\r\n", :session 33, :keywords (115 29 374 409)}, 265 {:id 265, :title "Comparison of Similarity Measures for Categorical Data in Hierarchical Clustering", :authors (587 224), :abstract "This contribution examines 13 similarity measures for data characterized by nominal\r\nvariables in hierarchical clustering. Most of the measures come from [1], where\r\nthey were initially studied in outlier detection tasks, and two of them are newly\r\nproposed in [2]. The inspected measures consider additional characteristics of the\r\nclustered dataset, such as a frequency distribution of categories or the number of\r\ncategories of a given variable, which should lead to a better cluster quality than\r\nthe commonly used simple matching approach. The experiment is conducted on 60\r\ngenerated datasets. It compares and evaluates the similarity measures regarding the\r\nquality of the produced clusters in hierarchical clustering using the mean ranked\r\nscores of two internal evaluation criteria. The calculations are performed using the\r\nnomclust R package [3]. The obtained results determine which similarity measures\r\nare the most suitable for use with a given number of variables or a linkage algorithm.\r\n\r\nReferences\r\n1. Boriah, S., Chandola, V., Kumar, V.: Similarity measures for categorical data: a \r\n   comparative evaluation. In: Proceedings of the eighth SIAM International Conference \r\n   on Data Mining, pp. 243–254. (2008)\r\n2. Sulc, Z., Rezankova, H. Comparison of Similarity Measures for Categorical Data in \r\n   Hierarchical Clustering. J Classif 36, 58–72. (2019)\r\n3. Sulc, Z., Cibulkova, J., Rezankova, H. Nomclust 2.0: an R package for hierarchical \r\n   clustering of objects characterized by nominal variables. Comput Stat (2022)", :session 26, :keywords (571 430 256)}, 78 {:id 78, :title "Probabilistic Clustering with Local Alignement of Italian COVID-19 Death Curves", :authors (375 543 186), :abstract "Italy is one of the most hardly hit countries in the world by the COVID-19 pandemic.\r\nA striking aspect of the pandemic in Italy has been its heterogeneity. Indeed, Italian\r\nregions were hit at different times and with different strengths, especially during the\r\nfirst wave. We consider official COVID-19 death curves, as well as excess mortality\r\ncurves for the 20 Italian regions. The goal is to cluster these misaligned functional\r\ndata, in order to assess whether there are regions sharing similar pandemic patterns\r\n[1]. Importantly, we are looking for clusters based on a local similarity among curves,\r\nsince patterns might differ only on a (misaligned) portion of the domain.\r\n  We develop probabilistic K-mean with local alignment (probKMA), a new functional data \r\nanalysis method to locally cluster a set of curves and discover functional motifs, i.e. \r\ntypical “shapes” that may recur several times along and across the curves capturing \r\nimportant local characteristics of these curves [2]. Using probKMA as a probabilistic \r\nclustering method to group COVID-19 curves we find two starkly different first waves of \r\nCOVID-19 pandemics; an “exponential” one unfolding in Lombardia and the worst-hit areas \r\nof the north, and a milder, “flat(tened)” one in the rest of the country. Local alignments \r\nof curves provide an indication of the lags between different regions, which can be employed \r\nin subsequent analyses to associate patterns of mortality with functional covariates such as \r\nmobility and positivity [1].\r\n\r\nReferences\r\n1. Boschi, T., Di Iorio, J., Testa, L., Cremona, M.A., Chiaromonte F.: Functional data \r\n   analysis characterizes the shapes of the first COVID-19 epidemic wave in Italy. \r\n   Scientific Reports 11:17054 (2021)\r\n2. Cremona, M.A., Chiaromonte F.: Probabilistic K-mean with local alignment for clustering\r\n   and motif discovery in functional data. arXiv 1808.04773 (2020)", :session 37, :keywords (217 323 117)}, 132 {:id 132, :title "Robustified Elastic Net Estimator for Multinomial Regression", :authors (176 455), :abstract "The elastic net estimator has been proposed in particular for high-dimensional low\r\nsample size data sets [5], and it has been extended to generalized linear regression\r\nmodels [1]. A fully robust version of the elastic net estimator has been introduced\r\nfor linear and logistic regression by [3]. This work is extended to the setting of \r\nrobust multinomial regression. Robustness is achieved by trimming the negative \r\nlog-likelihood function, and by introducing group-wise weights according to the \r\noutlyingness of the observations. The procedure is implemented in the R package \r\nenetLTS [4], using internally the R package glmnet [2]. Simulation studies and real \r\ndata examples are conducted to show the performance in comparison to the classical, \r\nnon-robust counterpart for multinomial regression.\r\n\r\nThe work was supported by grant TUBITAK 2219 from the Scientific and Technological\r\nResearch Council of Turkey.\r\n\r\nReferences\r\n1. Friedman, J., Hastie, T. and Tibshirani, R.: Regularization paths for generalized \r\n   linear models via coordinate descent. Journal of Statistical Software, 33, 1–22, 2010.\r\n2. Friedman, J., Hastie, T. and Tibshirani, R., Narasimhan, B., Tay, K., Simon, N., Qian, J. \r\n   and Yang, J. 2021: glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models, \r\n   R Foundation for Statistical Computing, Vienna, Austria. R package version 4.1–3, \r\n   https://CRAN.Rproject. org/package=glmnet\r\n3. Kurnaz, F.S, Hoffmann, I. and Filzmoser, P.: Robust and sparse estimation methods for \r\n   high-dimensional linear and logistic regression. Chemometrics and Intelligent Laboratory \r\n   Systems, 172, 211–222 (2018).\r\n4. Kurnaz, F.S, Hoffmann, I. and Filzmoser, P.: enetLTS: Robust and sparse estimation \r\n   methods for high-dimensional linear and logistic regression, R Foundation for Statistical \r\n   Computing, Vienna, Austria. R package, https://CRAN.R-project.org/package=enetLTS\r\n5. Zou, H. and Hastie, T.: Regularization and variable selection via the elastic net, Journal \r\n   of Royal Statistics Society Series B, 67, 301–320 (2005).", :session 21, :keywords (174 396 547 589)}, 26 {:id 26, :title "An Online Minorization-Maximization Algorithm", :authors (229 185 208 424), :abstract "Modern statistical and machine learning settings often involve high data volume\r\nand data streaming, which require the development of online estimation algorithms.\r\nThe online Expectation–Maximization (EM) algorithm extends the popular EM\r\nalgorithm to this setting, via a stochastic approximation approach. We show that an\r\nonline version of the Minorization–Maximization (MM) algorithm, which includes\r\nthe online EM algorithm as a special case, can also be constructed in a similar\r\nmanner. We demonstrate our approach via an application to the logistic regression\r\nproblem and compare it to existing methods.\r\n\r\n\r\n", :session 59, :keywords (192 363 465 445 612)}, 123 {:id 123, :title "Four Skewed Tensor Variate Distributions", :authors (391 454 439), :abstract "In recent years, data has become more and more complex, coming in many different\r\nforms. One such example is data that come in the form of higher order tensors.\r\nSome examples of these type of data are coloured images, video clips, and medical\r\ndata. Just like in the multivariate and matrix variate cases, the tensor or multilinear\r\nnormal distribution is most commonly used in the literature; however, in the area\r\nof clustering and classification, if the data is skewed or contain outliers, then the\r\nuse of a tensor normal distribution may result in over fitting the number of groups.\r\nWe will introduce four skewed tensor variate distributions which will be utilized for\r\nmodel-based clustering and classification. Parameter estimation and properties will\r\nbe discussed, and simulated and real data will be used for illustration.\r\n\r\n", :session 43, :keywords (268 633 579)}, 203 {:id 203, :title "Model-Based Clustering and Dimension Reduction for Multidimensional Social Networks", :authors (390 511 357), :abstract "Social network data are relational data recorded among a group of actors, interacting\r\nin different contexts. Often, the same set of actors can be characterized by multiple\r\nsocial relations, captured by a multidimensional network. A common situation is\r\nthat of colleagues working in the same institution, whose social interactions can be\r\ndefined on professional and personal levels. In addition, individuals in a network\r\ntend to interact more frequently with similar others, naturally creating communities.\r\nLatent space models for network data are useful to recover clustering of the actors,\r\nas they allow to represent similarities between them by their positions and relative\r\ndistances in an interpretable low dimensional social space. We propose the infinite\r\nlatent position cluster model for multidimensional network data, which enables \r\ndimension reduction and model-based clustering of actors interacting across multiple\r\nsocial dimensions. The model is formulated within a Bayesian nonparametric framework, \r\nwhich allows to perform automatic inference on the clustering allocations, the\r\nnumber of clusters, and the latent social space.\r\n\r\n", :session 74, :keywords (32 316 386 609)}, 268 {:id 268, :title "Comparing Model Selection Techniques to Determine the Number of Overlapping Clusters\r\nfor the Additive Profile Clustering Model", :authors (544 305 270), :abstract "In several areas of science, researchers aim at disclosing the mechanisms that \r\ngenerated object by variable data, like, for example, patient by symptom or consumer\r\nby brand data. Regularly, based on previous knowledge, it makes sense to assume\r\nthat these mechanisms can be nicely captured through an object clustering. In such\r\na case, researchers very often opt for a partitioning method, like, for example, k-means, \r\nwhich results in non-overlapping clusters. Sometimes, however, expectations\r\nare that objects can be grouped into clusters that overlap, implying that an object may\r\nbelong to multiple clusters. Applied to the patient by symptom data, for example, in\r\nwhich clusters correspond with syndromes, it is quite natural to assume that patients\r\nmay suffer from multiple syndromes at the same time as co-morbidity of syndromes\r\nis often observed in clinical practice. To extract the overlapping object clusters,\r\nMirkin’s additive profile (overlapping) clustering model may be used. A non-trivial\r\ntask consists of determining the optimal number of overlapping clusters that are\r\npresent in a given empirical data set. Up to now, however, although some methods\r\nfor model selection for ADPROCLUS were proposed before, no systematic attempt\r\nof investigating this issue of model selection has been undertaken. Therefore, in this\r\npresentation, we evaluate in an extensive simulation study several model selection\r\ntechniques. In partiular, several new model selection methods for ADPROCLUS,\r\nwith some of them being methods for the partitioning case tailored to the context of\r\noverlapping clustering (e.g., AIC, CH-index) are compared to existing methods (e.g.,\r\nCHull, cross-validation). As such, in order to build a cumulative body of knowledge,\r\nour study is a benchmarking study in which the performance of new methods is\r\ncarefully compared to the performance of existing methods.\r\n\r\n", :session 26, :keywords (458 4 383 575 34)}, 16 {:id 16, :title "A Topological Clustering of Individuals", :authors (466), :abstract "The clustering of objects-individuals is one of the most widely used approaches to\r\nexploring multidimensional data. The two common unsupervised clustering strategies \r\nare Hierarchical Ascending Clustering (HAC) and k-means partitioning used to\r\nidentify groups of similar objects in a dataset to divide it into homogeneous groups.\r\nThe proposed Topological Clustering of Individuals, or TCI, studies a homogeneous\r\nset of individuals-rows of a data table, based on the notion of neighborhood graphs;\r\nthe columns-variables are more-or-less correlated or linked according to whether\r\nthe variable is of a quantitative or qualitative type. It enables topological analysis\r\nof the clustering of individual variables which can be quantitative, qualitative or a\r\nmixture of the two. It first analyzes the correlations or associations observed between\r\nthe variables in the topological context of principal component analysis (PCA) or\r\nmultiple correspondence analysis (MCA), depending on the type of variable, then\r\nclassifies individuals into homogeneous groups relative to the structure of the variables \r\nconsidered. The proposed TCI method is presented and illustrated here using a simple real \r\ndataset with quantitative variables; however, it can also be applied with qualitative or \r\nmixed variables.\r\n\r\nReferences\r\n1. Abdesselam, R.: A Topological Principal Component Analysis. International Journal of Data\r\n   Science and Analysis. Vol.7, Issue 2, 20–31 (2021)\r\n2. Batagelj, V., Bren, M.: Comparing resemblance measures. Journal of classification, 12, \r\n   73–90 (1995)\r\n3. Lesot, M.J., Rifqi, M. and Benhadda, H.: Similarity measures for binary and numerical data:\r\n   a survey. In: IJKESDP, 1, 1, 63-84 (2009)\r\n4. Panagopoulos, D.: Topological data analysis and clustering. Chapter for a book, Algebraic\r\n   Topology (math.AT) arXiv:2201.09054, Machine Learning, (2022)\r\n5. Zighed, D., Abdesselam, R., and Hadgu, A.: Topological comparisons of proximity measures.\r\n   In: Tan et al. (Eds). 16th PAKDD 2012 Conference, pp. 379–391. Springer, (2012)", :session 69, :keywords (256 505 421 5 406)}, 133 {:id 133, :title "An efficient way to identify inliers via inlier-memorization effect of deep \r\ngenerative models", :authors (140 258 579), :abstract "Identifying whether a given sample is an outlier or not is a significant issue in \r\nvarious real-world domains. Many trials have developed outlier detection methods, \r\nbut they mainly presumed no outliers in the training data set. This study considers \r\na more general situation where training data contains some outliers, and any \r\ninformation about inliers and outliers is not given. We propose a powerful and \r\nefficient learning framework to identify inliers in a training data set using deep \r\nneural networks. We start with a new observation, called the inlier-memorization \r\neffect, that when we train a deep generative model with data contaminated with \r\noutliers, the model first memorizes inliers before outliers. Exploiting this finding, \r\nwe develop a new method called ODIM (Outlier Detection via the  Inlier-Memorization \r\neffect). The ODIM only requires a few updates; thus, it is fast and efficient. We \r\nempirically demonstrate that our method can refine inliers successfully in both tabular \r\nand image data sets. \r\n\r\n", :session 19, :keywords (668 284 674)}, 163 {:id 163, :title "User Segmentation Based on Online Behavioural Data via Ensemble Predictions and Clustering", :authors (525 232 585 490 84), :abstract "We use unsupervised clustering and supervised ensemble machine learning to identify \r\nsegments of users defined by behavioural data. Hierarchical clustering is used as\r\nan explorative method and to identify users with similar behavioural patterns based\r\non their online activity data (aka click data from mondaq.com). We assess estimated\r\nclusters by parametric bootstrap evaluation [1]. Stable clusters are used as additional\r\nfeatures in ensemble prediction of win-loss probabilities for potential clients. We\r\nimprove the interpretability of the machine learning model by ensembles of optimal\r\ntrees [2, 3]. Our approach is compared with several machine learning models as\r\nrandom forest, neural networks and logistic regression.\r\n\r\nReferences\r\n1. Lausen, B., Degens, P.O.: Evaluation of the reconstruction of phylogenies with DNA-DNA\r\n   hybridization data. In: Bock, H.-H. (ed.) Classification and Related Methods of Data Analysis:\r\n   Proceedings of the First Conference of the International Federation of Classification Societies\r\n   (IFCS), North-Holland, Amsterdam (1988)\r\n2. Khan, Z., Gul, A., Perperoglou, A., Miftahuddin, M., Mahmoud, O., Adler, W., Lausen, B.:\r\n   Ensemble of optimal trees, random forest and random projection ensemble classification.\r\n   Advances in Data Analysis and Classification 14, 97–116 (2020)\r\n3. Khan, Z., Gul, N., Faiz, N., Gul,A., Adler, W., Lausen, B.:Optimal trees selection for \r\n   classification via out-of-bag assessment and sub-bagging. IEEE Access 9, 28591–28607 (2021)", :session 64, :keywords (44 181 690)}, 81 {:id 81, :title "A Criterion for Selecting the Number of Time Series Clusters", :authors (127 487), :abstract "A new method is proposed to select the number of clusters in hierarchical clustering\r\nof a set of independent time series, including a test statistic for detecting existence\r\nof multiple cluster. The method focuses on the steps (height increments) of a dendrogram \r\nand uses simulation to generate a reference distribution of the step. The proposed test \r\nstatistic employs an upper sample quantile of the dendrogram steps of the data and the \r\nreference distribution. The largest step of the dendrogram is then used to select the \r\nnumber of clusters. We provide theoretical justification for the proposed method and show \r\nthat it works well in simulation and applications. The performance of the criterion is \r\nillustrated with different measures of similarity between the univariate time series features.\r\n\r\n", :session 25, :keywords (138)}, 120 {:id 120, :title "Spatial Configuration of Fire Stations in Portugal", :authors (474 115 193 421 449 294 23 370 183 301 69), :abstract "Fire stations (FS) provide a global emergency response to non-fire incidents, \r\ne.g., vehicle crashes. Urban fires are nonetheless one of the most frequent \r\ntypes of occurrences and sources of property damage that may lead to severe losses. \r\nThis severity is linked to the characteristic higher population densities and larger \r\nbuilding agglomerations in urban centers. In Portugal, FS are very non-uniformly \r\nspatially distributed between municipalities both in terms of number and geographical \r\nlocation. Since the spatial configuration of fire stations may considerably influence \r\nthe effectiveness of the provided services, national and regional governments need \r\nresearch-based advice on how many and where to establish firefighting facilities. Hence, \r\nbased on information regarding urban and rural fires and vehicle crashes occurrences, \r\nthis study aimed at estimating the number of FS per municipality by fitting a Poisson \r\nregression while accounting for spatial dependence. In addition, an unsupervised machine \r\nlearning clustering approach was used to assess the adequacy and efficiency of FS \r\nlocations, aiming to minimize the distance or the arrival time to the incidents.\r\n\r\n", :session 83, :keywords (207 208 490 300)}, 79 {:id 79, :title "Model Based Clustering and Outlier Detection with Missing Data", :authors (126 234 332), :abstract "Cluster analysis is a data analysis technique that aims to produce smaller groups\r\nof similar observations in a data set. In model-based clustering, the population is\r\nassumed to be a convex combination of sub-populations, each of which is modeled by \r\na probability distribution. When the data are characterized by outliers the\r\nmultivariate Student-t (T) and the contaminated normal distribution (CN) provide\r\nrobust parameter estimates and therefore are more suitable choices compared to\r\nGaussian Mixture models. Recently, the T and CN distributions have been extended\r\nto accommodate different tail behaviors across principal components, the models\r\nare referred to as multiple scaled distributions, i.e., MST and MSCN respectively.\r\nThe mixture of CN has the advantage of automatically detecting outliers while the\r\nMSCN distribution, has the advantage of directional robust parameter estimates and\r\noutlier detection. The term “directional” implies that the parameter estimation and\r\noutlier detection procedures work separately for each principal component. Some\r\npractical limitations of the mentioned models are that they require the number of\r\nclusters to be known and the data set to be complete. This work has overcome the two\r\nmentioned limitations providing a study of indices to select the number of clusters\r\nand presenting recent extensions of the CN and MSCN mixtures to cluster data that\r\ncontain values missing at random. All the discussed techniques are available in two\r\nconvenient R packages MSclust and MixtureMissing.\r\n\r\nReferences\r\n1. Tong H., Tortora. C. Model-based clustering and outlier detection with missing data.\r\n   Advances in data analysis and classification, 1-26 2022\r\n2. Tran L. and Tortora C. How Many Clusters Are Best? Investigating Model Selection in \r\n   Robust Clustering. In JSM Proceedings, Statistical Computing Section. Alexandria, VA: \r\n   American Statistical Association. 1159-1180 2021\r\n3. Tong H., Tortora. C. Mixture Missing: Robust Model-Based Clustering for Data Sets with\r\n   Missing Values at Random. R package v. 1.0.2. 2022\r\n4. Tortora. C., Punzo A., Tran L. MSclust: Multiple-Scaled Clustering. R package v. 1.0. \r\n   2022", :session 22, :keywords (382 454 365)}, 211 {:id 211, :title "Bayesian Classification and Non-Bayesian Label Estimation via EM Algorithm to Identify\r\nDifferential Expression in Omics Data: a Comparative Study", :authors (367 331), :abstract "Analyses of omics data (biomolecules including large macromolecules such as proteins \r\nand nucleic acids, as well as small molecules such as metabolites and natural\r\nproducts) allow comprehensive genome-wide analysis of complex diseases, offering\r\na major advantage over previous candidate gene analysis or pathway analysis. One of\r\nthe main goals in high-throughput data analysis is the identification of biomolecules\r\namong several thousands that differ between different sample groups.\r\n  Omics data classification problem is studied considering the ratio of the expression\r\nlevels and a non-observed categorical variable indicating how differentially expressed\r\neach biomolecule is: non differentially expressed, down-regulated or up-regulated.\r\nAssuming that the ratios follow a mixture of gamma distributions, two methods are\r\nproposed [1]. The first method is based on a hierarchical Bayesian model. The conditional \r\nprobability of a biomolecule to belong to each group is calculated and the\r\nbiomolecule is assigned to the group for which this conditional probability is higher.\r\nThe second method uses the EM algorithm to estimate the most likely group label\r\nfor each biomolecule, that is, to assign the biomolecule to the group which contains\r\nit with the higher estimated probability. Both approaches are applied to omics data\r\nand results are compared.\r\n\r\nReferences\r\n1. Antunes, M., Sousa, L.: Bayesian classification and non-Bayesian label estimation via EM\r\n   algorithm to identify differentially expressed genes: a comparative study. Biometrical J. \r\n   50(5), 824–836 (2008)", :session 61, :keywords (145 177 254 377)}, 38 {:id 38, :title "Clustering Student Mobility Data in 3-Way Networks", :authors (569 217 209 364), :abstract "The present contribution aims at introducing a network data reduction method for\r\nthe analysis of 3-way networks [1] in which classes of nodes of different types are\r\nlinked. The proposed approach enables simplifying a 3-way network into a weighted\r\ntwo-mode network by considering the statistical concept of joint dependence in a\r\nmultiway contingency table. Starting from a real application on student mobility data\r\nin Italian universities [2], a 3-way network is defined, where provinces of residence,\r\nuniversities and educational programmes are considered as the three sets of nodes,\r\nand occurrences of student exchanges represent the set of links between them. The\r\nInfomap community detection algorithm [3] is then chosen for partitioning two-mode\r\nnetworks of students’ cohorts to discover different network patterns.\r\n\r\nReferences\r\n1. Batagelj, V., Ferligoj, A., Doreian, P.: Indirect Blockmodeling of 3-Way Networks. \r\n   In: Brito P., Cucumel G., Bertrand P., de Carvalho F. (eds) Selected Contributions \r\n   in Data Analysis and Classification. Studies in Classification, Data Analysis, and \r\n   Knowledge Organization, pp. 151–159. Springer, Berlin, Heidelberg (2007)\r\n2. Columbu, S., Porcu, M., Primerano, I., Sulis, I., Vitale, M.P.: Geography of Italian \r\n   student mobility: A network analysis approach. Socio Econ Plan Sci 73, 100918 (2021)\r\n3. Edler, D., Bohlin, L., Rosvall, M.: Mapping higher-order network flows in memory and\r\n   multilayer networks with infomap. Algorithms, 10, 112 (2017)", :session 7, :keywords (1 86 84 379 634)}, 173 {:id 173, :title "Bootstrapping Binary GEV Regressions for Massive Unbalanced Datasets", :authors (396 353 365), :abstract "Research on rare events is constantly increasing over the years in many research areas.\r\nExamples include fraud detection, credit default prediction, bankruptcy prediction,\r\ncustomer/students churn predictions and accident occurrence. In all these cases, rare\r\nevents data are usually defined as binary variables with fewer events (ones) than\r\nnon-events (zeros). In other words, the degree of unbalance is more extreme in rare\r\nevents than it is in the class of unbalanced data. However, both unbalanced and\r\nrare events data have been studied as statistical problems with possible applications\r\nin different fields such as biology, political science, engineering, economics and\r\nmedicine. The unbalanced variables related to rare events are difficult to predict and\r\nexplain, specially in high dimensional settings and in presence of massive datasets,\r\nwhere unbalancing might be even more critical.\r\n  The logistic model may not be appropriate for such data since it strongly underestimates \r\nthe probability of rare events because the estimators tend to be biased\r\ntowards the majority class, which is usually less critical. Moreover, as underlined in\r\nthe literature, the bias of the maximum likelihood estimators of logistic regression\r\nparameters in small sample sizes could be amplified in a rare events context. Thus,\r\nin this framework, there is an increasing interest in using the quantile function of the\r\nGEV distribution as a link function to investigate the relationship between the binary\r\nresponse variable and a set of predictors. The main advantage of this approach is\r\nthat thanks to its skewness, the GEV link function has an asymmetric behaviour. It\r\napproaches one slower than it approaches zero, handling nicely rare events.\r\n  This work aims to estimate the probability of success given a set of features\r\nby using a generalized extreme value regression model for binary data, also taking\r\ninto account the effects on the response variable of class imbalance in categorical\r\npredictors. Confidence intervals and hypothesis testing are constructed by using\r\nbootstrap methods, specifically designed for massive datasets, in multiple testing\r\nperspectives. The performance of our proposed procedure is evaluated by Monte\r\nCarlo simulation studies and applications to real datasets.\r\n\r\n", :session 14, :keywords (523 240 43 401)}, 126 {:id 126, :title "Quantile-Distribution Functions and Their Use for Classification", :authors (146 114 19), :abstract "We develop a flexible parametric framework for the estimation of quantile functions.\r\nThe method involves the specification of an analytical quantile distribution function\r\nfor the data at hand [1]. We focus on quantile functions that are linear with respect\r\nto their parameters, such as the flattened generalized logistic distribution [2]: these\r\ncan adapt to a wide range of distributional shapes and allow for the estimation to be\r\ncarried out through a computationally efficient least-squares method based on the\r\norder statistics.\r\n  Inferential properties of this estimator, such as its asymptotic distribution, are \r\nderived, and these allow for the definition of a test of hypothesis for the equality of \r\ntwo distributions. The properties of the test are evaluated via a simulation study.\r\n  Our method of quantile function estimation is implemented as a density estimation\r\nmethod in the naive Bayes classifier. This innovation is compared to standard approaches \r\nfor the classifier in a simulation study, and is illustrated on a real data set coming \r\nfrom microRNA profiling in human Medulloblastoma. Moreover, the test of hypothesis is \r\nshown to be useful as a variable selection method.\r\n\r\nReferences\r\n1. Gilchrist, W.: Statistical Modelling with Quantile Functions. Taylor & Francis, \r\n   Andover (2000)\r\n2. Chakrabarty, T.K., Sharma, D.: A generalization of the quantile-based flattened \r\n   logistic distribution. Ann. Data. Sci. 8, 603–627 (2021)", :session 17, :keywords (512 417 673)}, 98 {:id 98, :title "Covariate Selection Method in Propensity Score Model for the Quantile Treatment Effect Estimation", :authors (537 307 230), :abstract "Estimation of a treatment effect, which is the impact of a treatment on an outcome, \r\nis important in some research areas, such as econometrics, social programs, and \r\npolicies. Quantile treatment effects (QTE) are primarily used in econometrics because\r\nthey can characterize the heterogeneous treatment effects on different points of an\r\noutcome distribution. For estimating QTE, Firpo [2] proposed an estimation method\r\nusing propensity scores.\r\n  In estimating of treatment effects using propensity scores, selection of covariates to\r\ninclude propensity score model is an important issue, and it is known that it is better\r\nto include covariates that are relevant to the outcome [1]. For achieving this issues,\r\nOutcome Adaptive Lasso (OAL) was employed as a covariate selection method for\r\npropensity score models[3]. However, OAL assumes an average treatment effect estimation \r\nand not a quantile treatment effect estimation.\r\n  In this study, we propose a covariate selection method that includes propensity score\r\nmodels for quantile treatment effect estimation. Here, the central principle is changing \r\nthe weight term from an outcome regression model to a quantile regression model. This allows \r\nfor the selection of covariates related to an outcome at an interesting quantile corresponding \r\nto QTE. Through numerical experiments, we compare the proposed method’s performance with that \r\nof the existing methods, such as OAL.\r\n\r\nReferences\r\n1. Brookhart, M.A., Schneeweiss, S., Rothman, K.J., Glynn, R.J., Avorn, J., & Sturmer, T.:\r\n   Variable selection for propensity score models. American journal of epidemiology. 163(12),\r\n   1149–1156 (2006)\r\n2. Firpo, S.: Efficient semiparametric estimation of quantile treatment effects. Econometrica.\r\n   75(1), 259–276 (2007)\r\n3. Shortreed, S.M., & Ertefaie, A.: Outcome-adaptive lasso: variable selection for causal \r\n   inference. Biometrics, 73(4), 1111–1122 (2017)", :session 13, :keywords (504 54 513)}, 124 {:id 124, :title "Functional Data from Wearable Devices. A Review", :authors (418 448), :abstract "With the recent development of sensor and information technologies, it is more and\r\nmore common to collect data obtained from people by sensors or wearable devices\r\nin a continuous an automatic way, to which we refer as wearable device data. Mobile\r\nphones have sensors and accelerometers measuring from the number of steps that\r\nwe have walk daily to our instantaneous stress level. In healthcare there are wearable\r\ndevices that measure the amount of oxygen in the blood, the electrical activity of the\r\nheart over time and the concentration of glucose in blood. See [2].\r\n  Since wearable device data are usually continuous, time-dependent, and has high\r\nvolume, Functional Data Analysis (FDA) are suitable for them. Through an exhaustive \r\nliterature revision, here we explore the possibilities that FDA offers as a generic\r\nmethodology for analyzing wearable device data. In particular, we identify relevant\r\nproblems in wearable data that can be approached using FDA, and we document open\r\naccess datasets that can be used as benchmarks in posterior research on functional\r\ndata coming from wearable devices.\r\n  As an example, in [1] data come from a clinical trial evaluating the beneficial\r\neffects of quinoa consumption on prediabetic subjects, which were monitored during\r\n8 weeks with FreeStyle Libre (a sensor applied to the back of the upper arm of subjects\r\nthat records the data on glucose concentration every 15 minutes). The glucose values\r\ncorresponding to the breakfast (from minute -30’ to +120’) were considered the\r\nfunctional response in a functional regression model fitted to measure the effect on\r\nglucose curves of diet type (rich in quinoa or not) and nutrient intakes.\r\n\r\nReferences\r\n1. Diaz-Rizzolo, D.A., Acar-Denizli, N., Kostov, B., Roura, E., Siso-Almirall, A., Delicado, P.,\r\n   Gomis, R.: Beneficial effects of quinoa consumption on glycaemia fluctuations: a pilot study\r\n   in old-age prediabetic subjects. Submitted. (2022)\r\n2. Goldsmith, J., Liu, X., Jacobson, J.S., Rundle, A.: New insights into activity patterns in\r\n   children, found using functional data analyses. Med. Sci. Sports Exerc., 48, 1723–1729 (2016).", :session 77, :keywords (2 245 534)}, 171 {:id 171, :title "A Time-Varying Text Based Ideal Point Model to Infer Partisanship in the U.S. Senate", :authors (521 88 440), :abstract "Ideal point models analyze lawmakers’ votes, speeches, press statements and social\r\nmedia posts to quantify their political positions along a latent continuum. In this\r\nwork, we extend the text based ideal point model [3] to obtain a time-varying version\r\nto study the evolution of the ideological positions of lawmakers over time and assess\r\nthe change in partisanship among representatives from two political parties. We\r\naim to confirm recent findings regarding the increase in partisanship manifested in\r\nspeeches by Republicans and Democrats in the U.S. Senate during the last years\r\n[2]. These findings were drawn using a penalized estimator for measuring group\r\ndifferences in choices with high-dimensional data and text analysis was based on\r\nmanually pre-defined topics. By contrast, the time-varying text based ideal point\r\nmodel estimated using variational inference [1] infers topics in a data-driven way\r\nand does not use party membership to determine the ideological positions and thus\r\nis not susceptible to overrating spurious differences in vocabulary use of different\r\nparty members. Drawing the same substantive conclusions based on the results of\r\ntwo different statistical text analysis methods provides evidence for their robustness.\r\n\r\nReferences\r\n1. Blei, D., Kucukelbir, D., McAuliffe, J. D.: Variational inference: A review for \r\n   statisticians. J. Am. Stat. Assoc. 112, 859–877 (2017)\r\n2. Gentzkow, M., Shapiro, J.M., Taddy, M.: Measuring group differences in high-dimensional\r\n   choices: Method and application to congressional speech. Econometrica. 87 1307–1340 (2019)\r\n3. Vafa, K., Naidu, S., Blei, D.: Text based ideal points. In: Proceedings of the 58th Annual\r\n   Meeting of the Association for Computational Linguistics, 5345–5357 (2020)", :session 35, :keywords (262 636 647 676)}, 87 {:id 87, :title "Bayesian Inference for the Generation Interval of COVID-19 in Busan, Korea", :authors (267 241 319 580), :abstract "In epidemiological dynamics, there are important parameters to provide knowledge\r\nof disease transmission, such as reproduction number, generation interval, serial\r\ninterval and incubation time. Among them, generation interval, which is the transmission \r\ntime difference between infector and infectee, is key parameter to estimate\r\nhow quickly the disease spread out. However, it is hard to calculate generation time\r\nbecause the time when a person is infected is considerably uncertain. In this study,\r\nwe estimate generation interval of COVID-19 in Busan, South Korea according to\r\nthe emergence of new variants. Markov chain Monte Carlo (MCMC) method is used\r\nto estimate generation interval. In a simulation, distributions of generation interval\r\nand incubation period are assumed to follow gamma distribution. As a results, we\r\nprovide quantiles of generation interval and pre-symptomatic transmission rates for\r\nperiods with a newly predominant mutation.\r\n\r\nReferences\r\n1. Ganyani, T., Kremer, C., Chen, D., Torneri, A., Faes, C., Wallinga, J., Hens, N.: \r\n   Estimating the generation interval for coronavirus disease (COVID-19) based on \r\n   symptom onset data, March 2020. Eurosurveillance 25, 2000257 (2020)\r\n2. Hart, W.S., Maini, P.K., Thompson, R.N.: High infectiousness immediately before \r\n   COVID19 symptom onset highlights the importance of continued contact tracing. \r\n   Elife 10, e65534 (2021)", :session 68, :keywords (234 350)}, 169 {:id 169, :title "The Control of False Discovery Rate for Functional Data", :authors (417 18 515), :abstract "In functional data analysis (FDA), the object of statistical methods are functions,\r\nwhich are typically modeled as random elements of a Hilbert space. In this framework \r\ninference is particularly challenging, since it deals with elements of infinite\r\ndimensional spaces. A popular topic in FDA is local inference, i.e., the continuous\r\nstatistical testing of a null hypothesis along the domain. The principal issue in this\r\ntopic is the infinite amount of tested hypotheses, which can be seen as an extreme\r\ncase of multiple comparisons problem. Local inferential techniques are either based\r\non simultaneous confidence bands, or on the definition of a p-value function, which\r\nprovides a p-value at each point of the domain, guaranteeing a control of a quantity\r\nrelated with the error rate on the whole domain. In this work we focus on this second\r\nline, and in particular on the control of the false discovery rate (FDR), which is the\r\nexpected proportion of false discoveries (rejected null hypotheses) among all discoveries, \r\nand was first introduced in the seminal paper by Benjamini and Hochberg [1]. We define FDR \r\nin the setting of functional data defined on a manifold domain.\r\n  We then introduce the functional Benjamini-Hochberg (fBH) procedure: a procedure\r\nable to control the previously defined functional FDR. Finally, the fBH procedure\r\nis applied to the analysis of daily temperatures on Earth. All details about the fBH\r\nprocedure are reported in [2].\r\n\r\nReferences\r\n1. Benjamini, Y., Hochberg, Y.: Controlling the False Discovery Rate: A Practical and Powerful\r\n   Approach to Multiple Testing. Journal of the Royal Statistical Society: Series B, 57 (1) 289–300\r\n   (1995) doi: 10.1111/j.2517-6161.1995.tb02031.x\r\n2. Lundtorp Olsen, N., Pini, A., Vantini, S.: False discovery rate for functional data. Test (2021)", :session 65, :keywords (35 397 437 324)}, 160 {:id 160, :title "Divide and Conquer: a Clustering Method for Hierarchical and Nested Data Structures", :authors (49 400 199 465), :abstract "Joint clustering on data with nested or hierarchical structures can be challenging.\r\nResults obtained by similarity-based methods (i.e. via K-means and K-medoids)\r\noften do not reflect the structure of the data, while model-based clustering (i.e. via\r\nmixture models), as we show, likely to leads to the same number of components\r\non each margin, i.e. same number of groups on each level of the hierarchy. We\r\naddress these drawbacks of joint models by proposing a novel approach for cluster \r\nanalysis—to which we refer to as divide and conquer clustering—that lies on\r\nthe interface between model-based clustering and similarity-based clustering. The\r\napproach consists of three steps and provides interpretable cluster solutions while\r\nallowing differing number of components on the margins. We achieve this by first\r\nestimating the margins of each hierarchy level by recently introduced non-local prior\r\nmixtures, which have the advantage of treating the number of components as a model\r\nparameter. Secondly, we learn about a set of joint clusters (proto clusters) that are\r\nobtained via a Voronoi tessellation on the product space of the marginal component means. \r\nFinally, the final joint clusters are the Voronoi faces centred at local\r\ndensity maxima of the joint distribution. These are obtained by dividing up proto\r\nclusters with a density below a threshold between the remaining Voronoi faces. In\r\nthis sense the high density areas divide and conquer low density regions. We analyse\r\nand compare the performance of our method with selected state of the art clustering\r\nmethods. The results on both simulated data and real datasets suggest an on par or\r\nbetter performance than competing methods.\r\n\r\n\r\n", :session 10, :keywords (68 386 572 431 253)}, 30 {:id 30, :title "Evolution of Media Coverage on Climate Change and Environmental Awareness: \r\nan Analysis of Tweets from UK and US Newspapers", :authors (211 383 122), :abstract "Climate change represents one of the biggest challenges of our time. Newspapers\r\nmight play an important role in raising awareness on this problem and its consequences. \r\nWe collected all tweets posted by six UK and US newspapers in the last decade to assess \r\nwhether 1) the space given to this topic has grown, 2) any breakpoint can be identified \r\nin the time series of tweets on climate change, and 3) any main topic can be identified \r\nin these tweets. Overall, the number of tweets posted on climate change increased for all \r\nnewspapers during the last decade. Although a sharp decrease in 2020 was observed due to \r\nthe pandemic, for most newspapers climate change coverage started to rise again in 2021. \r\nWhile different breakpoints were observed, for most newspapers 2019 was identified as a \r\nkey year, which is plausible based on the coverage received by activities organized by \r\nthe Fridays for Future movement. Finally, using different topic modeling approaches, we \r\nobserved that, while unsupervised models partly capture relevant topics for climate change, \r\nsuch as the ones related to politics, consequences for health or pollution, semi-supervised\r\nmodels might be of help to reach higher informativeness of words assigned to the topics.\r\n\r\n", :session 35, :keywords (67 659 183 641 648)}, 96 {:id 96, :title "Some Biplot Alternatives", :authors (436), :abstract "Biplots provide a valuable tool for exploring and visualizing the relations between two\r\nentities, often individuals and attributes. They originate from principle components\r\nanalysis, but have been applied to many other techniques that provide a decomposition\r\nbetween. The most well known biplot provides a projection interpretation: attributes\r\nare shown as vectors in a low-dimensional space, individuals as points, and the\r\nprojection of an individual onto the direction of the variable is proportional to the\r\nreconstructed data value of this individual for that attribute. Here we discuss two\r\nalternatives to the standard biplot. The first one is the so-called area biplot [1] that\r\ncan be used as an alternative to every standard projection biplot. Its main difference\r\nis that the estimate of the data is given by the area formed by the origin and two\r\npoints. The second variety is the nonlinear biplot with a distance interpretation: the\r\nreconstructed value on a variable of each sample point is obtained by finding the\r\nnearest marker point on a nonlinear curve representing the variable [2]. Each type\r\nof biplot will be explained briefly and compared with the standard biplot.\r\n\r\nReferences\r\n1. Gower, J.C., Groenen, P.J.F., van de Velden, M.: Area biplots. J Comput Graph Stat, \r\n   19 (1), 46-61 (2010)\r\n2. Groenen, P.J.F., Le Roux, N.J., Gardner-Lubbe, S.: Spline-based nonlinear biplots. \r\n   Adv Data Anal Classif, 9 (2), 219–238 (2015)", :session 39, :keywords (40 678)}, 10 {:id 10, :title "Three-Way Spectral Clustering", :authors (113 495), :abstract "In this paper, we present a spectral clustering approach for clustering three-way data.\r\nThree-way data concerns data characterized by three modes: n units, n variables, and\r\nt different occasions. In other words, three-way data contain a t × p observed matrix\r\nfor each statistical observation. The units generated by simultaneous observation of\r\nvariables in different contexts are usually structured as three-way data, so each unit\r\nis basically represented as a matrix. The spectral clustering application to three-way\r\ndata can be a powerful tool for unsupervised classification. Here, one example on\r\nreal three-way data have been presented showing that spectral clustering method is\r\na competitive method to cluster this type of data.\r\n\r\n", :session 20, :keywords (599 307 638)}, 272 {:id 272, :title "Statistical Learning with Dynamic Interaction Data for Public Health", :authors (103), :abstract "This work focuses on the problem of statistical learning with dynamic relational data\r\nfor two specific public health problems: the analysis of the COVID-19 publication\r\nnetwork and the study of a large-scale pharmacovigilance data set. On the one hand,\r\nthe Covid-19 epidemic presented a unique use case for researchers and institutions in\r\nthe health field where the ability to monitor and synthesize scientific publications on\r\na given theme has proven to be strategic. Indeed, with more than 5000 publications\r\nand pre-publications per month on the Covid-19 virus, it has proved essential for\r\nresearchers and doctors to have tools capable of synthesizing publications on this\r\nsubject by grouping them on the basis of the research themes they mobilize. On the\r\nother hand, pharmacovigilance is a central medical discipline aiming at monitoring\r\nand detecting public health events (adverse drug reactions) caused by medicines and\r\nvaccines. As the current expert detection of safety signals is unfortunately incomplete\r\ndue to the workload it represents, we investigate here an automatized method of\r\nsafety signal detection from ADR data. To address those problems, we proposed\r\ntwo generative models for clustering the nodes of a dynamic graph, accounting\r\nfor the content of textual edges as well as their frequency, in the first case, and\r\nthe co-clustering of dynamic count data, for pharmacovigilance. In both cases, the\r\ncontinuous time is handled by partitioning the considered time period, allowing the\r\ndetection of temporal breaks in the signals.\r\n\r\nAcknowledgements This work has been supported by the French government, through the 3IA\r\n                 Côte dAzur Investment in the Future project managed by the National \r\n                 Research Agency (ANR) with the reference number ANR-19-P3IA-0002.", :session 48, :keywords (75 287 163 235 176)}, 270 {:id 270, :title "Detecting Anomalies with TADGAN: a Case Study", :authors (244 98 71 446), :abstract "Generative Adversarial Networks (GAN) is neural network architecture to generate\r\nrealistic artificial [2]. The generated data is typically used to learn more accurate\r\nmodels. The approach underlying GAN has been adapted for other tasks. One example are \r\nTADGAN, which is an adaptation of GAN to detect anomalies in time series data [1]. A \r\ntime series anomaly is defined as a timepoint or period where a phenomenon displays \r\nan unusual behavior. The TADGAN algorithm can be summarized has: 1. generate a time \r\nseries that is similar to the original one; 2. periods where the distance between the \r\noriginal and the generated time series is very large are classified as anomalies. \r\nThe classification is affected by a sensitivity hyperparameter, which is a threshold \r\nthat defines the minimal distance between the time series for the period to be considered \r\nanomalous. In this paper, we empirically evaluate TADGAN on the problem of detecting anomalies \r\nin data from sensors of a fire detection system. Preliminary results indicate that the performance \r\nof the method depends on the values of the sensitivity hyperparameter.\r\n\r\nReferences\r\n1. Alexander Geiger, Dongyu Liu, Sarah Alnegheimish, Alfredo Cuesta-Infante, and Kalyan \r\n   Veeramachaneni. Tadgan: Time series anomaly detection using generative adversarial \r\n   networks. 2020 IEEE International Conference on Big Data (Big Data), pages 33–43, 2020.\r\n2. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil\r\n   Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Commun. ACM,\r\n   63(11):139–144, oct 2020.", :session 45, :keywords (14 17 229)}, 271 {:id 271, :title "Fast Minipatch Ensemble Strategies for Learning and Inference", :authors (204), :abstract "Enormous quantities of data are collected in many industries and disciplines; this\r\ndata holds the key to solving critical societal and scientific problems. Yet, fitting\r\nmodels to make discoveries from this huge data often poses both computational\r\nand statistical challenges. In this talk, we propose a new ensemble learning strategy\r\nprimed for fast, distributed, and memory-efficient computation that also has many\r\nstatistical advantages. Inspired by random forests, stability selection, and stochastic \r\noptimization, we propose to build ensembles based on tiny subsamples of both\r\nobservations and features that we term minipatches. While minipatch learning can\r\neasily be applied to prediction tasks similarly to random forests, this talk focuses\r\non using minipatch ensemble approaches in unconventional ways: We will highlight\r\nnew minipatch learning methods for unsupervised learning, specifically clustering\r\nand structural graph learning, and distribution-free and model-agnostic inference for\r\nboth predictions and important features. Through huge real data examples from \r\nneuroscience, genomics and biomedicine, we illustrate the computational and statistical\r\nadvantages of our minipatch ensemble learning strategies.\r\n\r\n", :session 62, :keywords (180 97 249 93 204)}, 18 {:id 18, :title "An MML Embedded Approach for Estimating the Number of Clusters", :authors (120 360 410), :abstract "Assuming that the data originate from a finite mixture of multinomial distributions,\r\nwe study the performance of an integrated Expectation Maximization (EM) algorithm\r\nconsidering Minimum Message Length (MML) criterion to select the number of\r\nmixture components. The referred EM-MML approach, rather than selecting one\r\namong a set of pre-estimated candidate models (which requires running EM several\r\ntimes), seamlessly integrates estimation and model selection in a single algorithm.\r\nComparisons are provided with EM combined with well-known information criteria\r\n– e.g. the Bayesian information Criterion. We resort to synthetic data examples and\r\na real application. The EM-MML computation time is a clear advantage of this\r\nmethod; also, the real data solution it provides is more parsimonious, which reduces\r\nthe risk of model order overestimation and improves interpretability.\r\n\r\nReferences\r\n1. Figueiredo, M.A.T., Jain, A.K. : Unsupervised Learning of Finite Mixture Models. IEEE T.\r\n   Pattern Anal. 24, 381–396 (2002)\r\n2. Novais, L., Faria, S.,: Selection of the number of components for finite mixtures of linear\r\n   mixed models. J. Int. Math. 24(8), 2237–2268 (2021)\r\n3. Silvestre, C., Cardoso, M. G. M. S. and Figueiredo, M.: Feature selection for clustering\r\n   categorical data with an embedded modeling approach. Expert Syst. 32(3), 444–453 (2014).", :session 12, :keywords (206 176 383 361 49)}, 105 {:id 105, :title "Analysis of the Damage Rate Using Typhoon Information", :authors (527 403), :abstract "According to the Intergovernmental Panel on Climate Change, the scale and intensity\r\nof damage are increasing as well as the frequency of meteorological disasters due to\r\nglobal warming. Typhoon usually occur between July and October, so they are similar\r\nto the harvest of crops, causing a lot of damage to farmers. In order to minimize\r\ndamage to farmers caused by meteorological disasters, South Korea has implemented\r\ncrop insurance since 2001. This study aims to analyze typhoon and damage rate by\r\nusing crop insurance data. Since crop insurance is measured objectively and fairly\r\nfor accurate actual damage judgment, analysis using crop insurance data is expected\r\nto be highly reliable. It will identify and analyze the relationship between typhoon\r\ninformation and the damage rate, and further present the expected typhoon damage\r\nrate for future typhoon. Considering the characteristics of the analysis data, the\r\nzero-inflated beta regression will be used to analyze the damage rate. In addition,\r\nby using Random Forest and XGBoost, which are representative machine learning\r\nmodels, we intend to compare the prediction results between models. As a result of\r\nthe prediction, the performance of machine learning models was better than zeroinflated \r\nbeta regression. The results of this analysis are expected to be used not only to predict \r\nthe expected damage rate for future typhoon but also to prepare measures to reduce damage \r\nto farmers.\r\n\r\nReferences\r\n1. Tang, B., Frye, H.A., Gelfand, A.E., Silander Jr, J.A.: Zero-inflated Beta distribution \r\n   regression modeling. arXiv preprint arXiv:2112.07249 (2021)\r\n2. Breiman, L.: Random forests. Machine learning, 45(1), 5-32 (2001)\r\n3. Chen, T., Guestrin, C.: Xgboost: A scalable tree boosting system. In Proceedings of the \r\n   22nd acm sigkdd international conference on knowledge discovery and data mining, 785-794 \r\n   (2016)", :session 9, :keywords (661 124 693 332)}, 185 {:id 185, :title "Google Trends as a Macroeconomic Predictor: Behind the Scenes", :authors (147 362), :abstract "Data sourced from online activities and particularly from Google Trends (GT) has\r\nbeen gaining importance in the literature as predictors for economic indicators. \r\nRecent research evidence relationships between GT and a range of outcomes, thus\r\nestablishing GT as a complementary data source. GT yields a measure of the interest \r\nof Google search-engine users in a subject or a specific keyword over time,\r\nresulting in a normalised index [1]. The benefits of GT as a data supplier include\r\nits promptness, inexpensive collection costs, mixed sampling frequency and approaches \r\nto diversified research areas. There are, however, two issues associated with GT that \r\nrequire attention. The first regards the frequency of the returned index, which depends \r\non the time length and span required, leading to limited historical data in high-frequency \r\nsampling. If daily data are necessary, then GT is limited to 9-months of data, whereas \r\nmonthly sampling grants more than 5-years of data. Since GT normalises indexes, stacking \r\nmultiple time frames to obtain extended periods of high-frequency data would conceal \r\neventual trends in the underlying data; thus, temporal disaggregation procedures must be \r\napplied [2]. The second issue involves the data source sampling noise since different \r\nindexes are produced on distinct days, even when all the other constraints (time length, \r\ntime span, subject and keywords) are kept constant. As GT considers aggregated searches \r\nbased on samples, performing collections over multiple days and summarising them into a \r\nsingle measure controls for the data uncertainty [1]. This work addresses the construction \r\nof  a time series predictor from GT’s indexes in a nowcasting exercise with mixed frequency \r\ndata.\r\n\r\nAcknowledgements Eduardo Andre Costa gratefully acknowledges support from CEF.UP/FCT\r\n                 (UIDB/04105/2020) and FCT (2021.07583.BD).", :session 40, :keywords (246 129 267)}, 114 {:id 114, :title "Outliers Detection in Functional Data", :authors (32 203 256), :abstract "The modern technologies ease the collection of massive data at high frequency. \r\nFrom a statistical point of view, these data can be considered as functional data: \r\ndiscrete observations of random functions. One of the key problems in functional data\r\nanalysis, is the detection of outliers. For this purpose, we propose a robust method \r\nbased on contaminated Gaussian mixture models [1]. This model allows both to group \r\nand to detect outliers in multivariate functional data. A mixture of multivariate \r\ncontaminated Gaussian distributions [2] is a Gaussian mixture where each cluster has \r\ntwo components: one, with a large prior probability, represents normal observations, \r\nand the other, with a small prior probability, represents outliers. Dimension reduction \r\nmethods based on [3], are used to introduce parsimony into the model. An ECM (Expectation-\r\nConditional Maximization) algorithm is proposed for model inference and the choice of hyper-\r\nparameters is addressed through model selection. The model performs efficiently on simulated \r\ndata. It also helps to correctly detect outliers in the industrial data sets which motivated \r\nthis work.\r\n\r\nReferences\r\n1. Amovin-Assagba, M., Gannaz, I., & Jacques, J.: Outlier detection in multivariate functional\r\n   data through a contaminated mixture model. arXiv preprint arXiv:2106.07222 (2021)\r\n2. Punzo, A., & McNicholas, P.D. : Parsimonious mixtures of multivariate contaminated normal\r\n   distributions. Biom. J., 58, 1506-1537 (2016)\r\n3. Schmutz, A., Jacques, J., Bouveyron, C., Cheze, L., & Martin, P. : Clustering multivariate\r\n   functional data in group-specific functional subspaces. Comput. Stat., 35, 1101-1131 (2020)", :session 21, :keywords (454 106 215 386 176)}, 253 {:id 253, :title "Correlation-Based Iterative Clustering Methods for Time Course Data", :authors (398 510 220 233), :abstract "Many pragmatic clustering methods have been developed to group data vectors or\r\nobjects into clusters so that the objects in one cluster are very similar and objects\r\nin different clusters are distinct based on some similarity measure. The availability\r\nof time course data has motivated researchers to develop methods, such as mixture\r\nand mixed-effects modelling approaches, that incorporate the temporal information\r\ncontained in the shape of the trajectory of the data. However, there is still a need for\r\nthe development of time-course clustering methods that can adequately deal with\r\ninhomogeneous clusters (some clusters are quite large and others are quite small).\r\n  We propose two such methods, hierarchical clustering (IHC) and iterative\r\npairwise-correlation clustering (IPC). We evaluate and compare the proposed methods to \r\nthe Markov Cluster Algorithm (MCL) and the generalised mixed-effects model (GMM) using \r\nsimulation studies and an application to a time course gene expression data set from a \r\nstudy containing human subjects who were challenged by a live influenza virus. We identify \r\nfour types of temporal gene response modules to influenza infection in humans, i.e., single-gene \r\nmodules (SGM), small-size modules (SSM), medium-size modules (MSM) and large-size modules (LSM).\r\n\r\n", :session 65, :keywords (217 283 263)}, 209 {:id 209, :title "Fisher Discriminant Analysis for Interval Data", :authors (137 344 240 329), :abstract "In Data Science, entities are typically characterized by vectors of single-valued\r\nmeasurements, called conventional data. Symbolic Data Analysis can model more\r\ncomplex data structures like lists, intervals, histograms, or even distributions. These\r\ncomplex structures may result from the aggregation of conventional data according\r\nto the research interests or may exist in their own right. The complexity of these data\r\nstructures brings new statistical challenges and the need of new methodologies to\r\nextract information from it, of which classification is a good example.\r\n  In this work, we propose an extension of the conventional Fisher Discriminant\r\nAnalysis based on Mallows’ distance and Moore’s interval algebraic structure. The\r\nsquared Mallows’ distance between two interval-valued vectors is written as an explicit \r\nform of the sum of two squared Euclidean distances between the vectors of the\r\ninterval’s centers and the vectors of the interval’s ranges. The ranges’ contribution is\r\nweighted according to the assumption of the micro-data distribution within intervals,\r\nextending previous work on this topic. This allows us to define associated symbolic\r\ncovariances matrices that can be decomposed into within and between covariance\r\nmatrices. Using Moore’s algebraic structure, we generalize Fisher’s objective function \r\nto interval data, aiming to discriminate between two classes. Examples based\r\non real problems are used to illustrate the advantages of this approach over the\r\nconventional one, which ignores the interval structure of the data.\r\n\r\nAcknowledgements This work was supported by Fundação para a Ciência e Tecnologia, Portugal,\r\n                 through the projects UIDB/04621/2020, PTDC/EGE-ECO/30535/2017 and \r\n                 UID/MAT/04459/2020.\r\n\r\n", :session 36, :keywords (626 63 628 295 335)}, 147 {:id 147, :title "Logistic Regression Models for Aggregated Data", :authors (541 91 504), :abstract "Logistic regression models are a popular and effective method to predict the probability\r\nof categorical response data. However, inference for these models can become\r\ncomputationally prohibitive for large datasets. Here we adapt ideas from symbolic\r\ndata analysis to summarize the collection of predictor variables into histogram form,\r\nand perform inference on this summary dataset. We develop ideas based on composite\r\nlikelihoods to derive an efficient one-versus-rest approximate composite likelihood\r\nmodel for histogram-based random variables, constructed from low-dimensional\r\nmarginal histograms obtained from the full histogram. We demonstrate that this\r\nprocedure can achieve comparable classification rates to the standard full data multinomial\r\nanalysis and against state-of-the-art subsampling algorithms for logistic regression,\r\nbut at a substantially lower computational cost. Performance is explored\r\nthrough simulated examples, and analyses of large supersymmetry and satellite crop\r\nclassification datasets.\r\n\r\n", :session 52, :keywords (62 312 444 517 626)}, 161 {:id 161, :title "Off-Target Predictions in CRISPR-Cas9 Gene Editing Using Machine Learning", :authors (26 427), :abstract "Recently, CRISPR (Clustered Regularly Interspaced Short Palindromic Repeated)\r\napplications widely appear in gene editing for treatment of cancer. Therefore,\r\nCRISPR Cas-9 system is a robust method for effectively editing the genome of\r\ncell. CRISPR locus is composed of DNA in genes located on cell. DNA/Target \r\nsequence occurs 23 endonucleases. Off/on-target sequence are diagnosed with \r\nmatching between endonucleases and Guide RNA. The prediction of off-target mutations\r\nin CRISPR-Cas9 is a hot topic because of its relevance to gene editing research.\r\nIn literature, Off/on target levels are often evaluated by CFD/MIT scores in terms\r\nof binary classification. Instead of those scores, determining more than 2 classes\r\nby the latent class analysis (LCA) in the pre-processing step helps to interpret, and\r\nclassify more accurately. In this study, a benchmark dataset that consists of Human\r\n(Homo-sapiens) - (GRCh37/hg19) + SNPs: 10000 Genomes, ExaC was used. In the\r\nanalysis, LCA produced three significant classes related to the off-target scores over\r\nbenchmark dataset. These classes are identified as high (7.1%), middle (86.5%),\r\nlow (6.4%). Afterwards, the estimated off-target scores were modeled by machine\r\nlearning methods such as Xgboost, SVM, ANN and decision trees etc. where the\r\nbenchmark dataset was partitioned by 10-fold cross-validation procedure. \r\nThe analysis results figure out the effect of locus structures and mismatching positions \r\non the off-target. The best model is Xgboost with accuracy (AUC=100%).\r\n\r\nReferences\r\n1. Kang, S.H., Lee, W. jae, An, J.H., Lee, J.H., Kim, Y.H., Kim, H., . . . Lee, S. H. : \r\n   Predictionbased highly sensitive CRISPR off-target validation using target-specific \r\n   DNA enrichment. Nat Commun. 11(1), 1–11 (2020)\r\n2. Leibowitz, M.L., Papathanasiou, S., Doerfler, P.A., Blaine, L.J., Sun, L., Yao, Y., . . . \r\n   Pellman, D.: Chromothripsis as an on-target consequence of CRISPR–Cas9 genome editing. \r\n   Nat Genet. 53(6), 895–905 (2021)", :session 82, :keywords (314 332 123 441)}, 71 {:id 71, :title "Alternating Optimization Framework for Sparse Simultaneous Component Analysis \r\nBased on Data Integration", :authors (486 303 312 314), :abstract "Given multiple data blocks from different sources sharing the same observations\r\n(such as psychological questionnaires or genetic risk scores), Simultaneous \r\nComponent Analysis (SCA) aims to find a few linear combinations of the variables\r\nthat explain as much as possible the variability in the joined data set. However,\r\nrooting the analysis on all variables makes interpretability difficult, especially in\r\nhigh-dimensional settings. Therefore, looking for a sparse structure is natural; it\r\nidentifies the common and distinctive source of variation across all data blocks.\r\nSolving the sparse SCA problem is intractable, given its combinatorial nature. Here,\r\nthe nonconvex SCA problem is formulated as different convex maximization problems over \r\nthe sphere, inducing sparsity via cardinality constraint and lasso penalties.\r\nTo solve these models, optimization algorithms based on the alternating directions\r\nmethods are proposed; these algorithms find high-quality feasible solutions for large\r\ndimensions. Extensive experiments, including a real-world data set, are used to assess\r\nthe solution quality, computational time, and scalability of the methods.\r\n\r\n", :session 27, :keywords (11 149 576)}, 42 {:id 42, :title "Some Issues in Robust Clustering", :authors (108), :abstract "Some key issues in robust clustering are discussed with focus on Gaussian mixture\r\nmodel based clustering, namely the formal definition of outliers, ambiguity between\r\ngroups of outliers and clusters, the interaction between robust clustering and the\r\nestimation of the number of clusters, the essential dependence of (not only) robust\r\nclustering on tuning decisions, and shortcomings of existing measurements of cluster\r\nstability when it comes to outliers.\r\n\r\nReferences\r\n1. Garcia-Escudero, L.A., Gordaliza, A., Matran, C., Mayo-Iscar, A., Hennig, C.: Robustness ´\r\n   and Outliers. In: Hennig, C., Meila, M., Murtagh, F., Rocci, R. (eds.) Handbook of Cluster\r\n   Analysis, pp. 653-678. Chapman & Hall/CRC, Boca Raton FL (2016)\r\n2. Hennig, C.: Dissolution point and isolation robustness: robustness criteria for general cluster\r\n   analysis methods. J. Multivariate Anal. 99, 1154–1176 (2008)\r\n3. Hennig, C., Coretto, P.: An adequacy approach for deciding the number of clusters for\r\n   OTRIMLE robust Gaussian mixture-based clustering. Aust. N. Z. J. Stat. (2021) \r\n   doi: 10.1111/anzs.12338", :session 70, :keywords (230 658 429 438 670 70)}, 199 {:id 199, :title "Creating Homogeneous Sectors: Criteria and Applications of Sectorization", :authors (124 363 152 39 35 125 296 450), :abstract "Sectorization is the process of grouping a set of previously defined basic units\r\n(points or small areas) into a fixed number of sectors. Sectorization is also known\r\nin the literature as districting or territory design [1], and is usually performed to\r\noptimize one or more criteria regarding the geographic characteristics of the territory\r\nand the planning purposes of sectors. The most common criteria are equilibrium,\r\ncompactness and contiguity, which can be measured in many ways [2].\r\n  Sectorization is similar to clustering but with a different motivation. Both aggregate \r\nsmaller units into groups. But, while clustering strives for inner similarity of\r\ndata, sectorization aims at outer homogeneity [1]. In clustering, groups should be\r\nvery different from each other, and similar points are classified in the same cluster.\r\nIn sectorization, groups should be very similar to each other, and therefore very\r\ndifferent points can be grouped in the same sector.\r\n  We classify sectorization problems into four types: basic sectorization, sectorization \r\nwith service centers, resectorization, and dynamic sectorization. A Decision\r\nSupport System for Sectorization, D3S, is being developed to deal with these four\r\ntypes of problems. Multi-objective genetic algorithms were implemented in D3S\r\nusing Python, and a user-friendly web interface was developed using Django. Several \r\napplications can be solved with D3S, such as political districting, sales territory\r\ndesign, delivery service zones, and assignment of fire stations and health services to\r\nthe population.\r\n\r\nReferences\r\n1. Kalcsics, J., Nickel, S., Schroeder,M.: Towards a unified territorial design approach - \r\n   Applications, algorithms and GIS integration. TOP 13(1), 1–56 (2005)\r\n2. Rodrigues, A.M., Ferreira, J.S.: Measures in Sectorization Problems. In: Póvoa, A., \r\n   de Miranda, J. (eds.) Operations Research and Big Data 15. Springer, Cham. (2015)", :session 80, :keywords (558 75 132 450)}, 37 {:id 37, :title "Towards a Bi-Stochastic Matrix Approximation of K-Means and Some Variants", :authors (326 408), :abstract "The k-means algorithm and some k-means variants have been shown to be useful and\r\neffective to tackle the clustering problem. In this paper we embed k-means variants\r\nin a bi-stochastic matrix approximation (BMA) framework. Then we derive from\r\nthe k-means objective function a new formulation of the criterion. In particular, we\r\nshow that some k-means variants are equivalent to algebraic problem of bi-stochastic\r\nmatrix approximation under some suitable constraints. For optimizing the derived\r\nobjective function, we develop two algorithms; the first one consists in learning a\r\nbi-stochastic similarity matrix while the second seeks for the optimal partition which\r\nis the equilibrium state of a Markov chain process. Numerical experiments on real\r\ndata-sets demonstrate the interest of our approach.\r\n\r\n", :session 32, :keywords (300 526 201 36)}, 63 {:id 63, :title "An Ultrametric Model for Clustering and Dimensionality Reduction", :authors (213), :abstract "The study of multidimensional phenomena is currently growing with the complexity\r\nof the reality, raising the need for methodologies to explore the relationships between\r\ntheir many facets. Multidimensional phenomena are often explained by nested latent\r\nconcepts ordered in a hierarchical, tree structure, whose characterization can differ\r\nin heterogeneous populations. In this work, a new parsimonious parameterization\r\nof the covariance matrix able to pinpoint a hierarchical structure on variables is\r\nproposed, and implemented into a Gaussian Mixture Model (GMM). The proposal\r\nis based upon the definition of an ultrametric matrix [2], which is one-to-one\r\nassociated with a hierarchy of latent concepts. Its implementation into a GMM aims,\r\non one hand, at introducing a new parsimonious GMM with a reduced number of\r\nparameters and, on the other hand, at identifying a different characterization of the\r\nphenomenon under study for each component (subpopulation) of the mixture. With\r\nrespect to the existing parsimonious parameterizations of the component covariance\r\nstructure, e.g., the eigen-decomposition [1] and the decomposition based on Factor\r\nAnalysis [3], the ultrametric GMM works particularly well in situations where a\r\nhierarchy over variables can be identified. Nonetheless, the proposal shows good\r\nperformance also when a general (non-hierarchical) covariance structure is assumed\r\nfor the data. The application of the proposal to real data concerning well-being and a\r\nbenchmark data set illustrates its potentials to explore multidimensional phenomena\r\nin a heterogeneous population.\r\n\r\nReferences\r\n1. Banfield, J., Raftery, A.: Model-based Gaussian and non-Gaussian clustering. Biometrics.\r\n   49(3), 803-–821 (1993)\r\n2. Dellacherie, C., Martinez, S., San Martin, J.: Inverse M-matrices and ultrametric matrices.\r\n   Lecture Notes in Mathematics, Springer, Switzerland (2014)\r\n3. McLachlan, G, Peel, D.: Mixtures of factor analyzers. In: Langley, P. (ed.) Proceedings of the\r\n   seventeenth international conference on machine learning, pp 599–606. Morgan Kaufmann,\r\n   San Francisco (2000)", :session 76, :keywords (662 467 386 258)}, 212 {:id 212, :title "Density Modelling via Functional Data Analysis", :authors (524 548), :abstract "Recent technological advances have eased the collection of big amounts of data\r\nin many research field. In this scenario an useful statistical technique is density\r\nestimation which represents an important source of information. One dimensional\r\ndensity functions represent a special case of functional data subject to the constraints\r\nto be non-negative and with a constant integral equal to one [1]. Because of these\r\nconstraints, densities functions do not form a vector space and a naive application of\r\nfunctional data analysis (FDA) methods may lead to non valid estimates. To address\r\nthis issue two main strategies can be found in the literature. In the first, the probability\r\ndensity functions (pdfs) are mapped into a linear functional space through a suitably\r\nchosen transformation [2]. Established methods for Hilbert space valued data can\r\nbe applied to the transformed functions and the results are moved back into the\r\ndensity space by means of the inverse transformation. In the second strategy, pdfs\r\nare treated as an infinite dimensional compositional data since they are part of some\r\nwhole which only carry relative information. An approach based on the Aitchison\r\ngeometry for compositional data has been sketched in [3, 4]. In this work, by means\r\nof a suitable transformation, densities are embedded in the Hilbert space of square\r\nintegrable functions where standard FDA methodologies can be applied.\r\n\r\nReferences\r\n1. Ramsay, J.O. and Silverman, B.W.: Functional Data Analysis, 2nd edn. Springer, New York\r\n   (2005)\r\n2. Petersen, A. and Muller, H.: Functional data analysis for density functions by transformation\r\n   to a Hilbert space. Ann. Stat. 32(1), 183–218 (2016)\r\n3. Delicado, P.: Dimensionality reduction when data are density functions. Comput. Stat. Data.\r\n   Anal. 55, 401–420 (2011)\r\n4. Hron, K., Menafoglio, M., Templ, M., Hruzova, K. and Filzmoser, P.: Simplicial principal\r\n   component analysis for density functions in Bayes spaces. Comput. Stat. Data. Anal. 94,\r\n   330–350 (2016)", :session 37, :keywords (102 217 501)}, 94 {:id 94, :title "Assessing Common Principal Directions", :authors (132 97), :abstract "In this paper we address the problem of comparing the principal axes of a covariance\r\nmatrix with other given axes. The point of view adopted is based on the problem\r\nof optimal transport in families of location and shape, which gives rise to a very\r\nsimple relation between the variances of the corresponding components in both\r\nbases. Our analysis includes the asymptotic behavior of the statistic involved, and\r\nthe comparison of the method with other existing proposals in the literature.\r\n\r\nReferences\r\n1. Flury, B.: Common principal components and related multivariate models. Wiley, \r\n   New York (1988)\r\n2. Alvarez-Esteban, P.C., del Barrio, E., Cuesta-Albertos, J.A., Matrán, C.: A fixed-point \r\n   approach to barycenters in Wasserstein space. J. Math. Anal. Appl. 441, 744–762 (2016)\r\n3. Lewis, A.S., Sendov, H.S.: Twice differentiable spectral functions. SIAM J. Matrix Anal.\r\n   Appl. Vol 23, No. 2, 368–386 (2001)", :session 70, :keywords (682 83 403 600)}, 8 {:id 8, :title "Clustering High-Dimensional Microbiome Data", :authors (499 575), :abstract "The human microbiome plays an important role in human health and disease status. \r\nNext-generation sequencing technologies allow for quantifying the composition\r\nof the human microbiome. Clustering these microbiome data can provide valuable\r\ninformation by identifying underlying patterns across samples. Here, we develop a\r\nfamily of logistic normal multinomial factor analyzers (LNM-FA) by incorporating\r\na factor analyzer structure. The family of models is suitable for high-dimensional\r\nmicrobiome data as the number of parameters in LNM-FA can be greatly reduced\r\nby assuming that the underlying latent factors is small. Parameter estimation is done\r\nusing a computationally efficient variant of the alternating expectation conditional\r\nmaximization algorithm that utilizes variational Gaussian approximations. The proposed \r\nmethod is illustrated using simulated and real datasets.\r\n\r\n", :session 71, :keywords (68 359 386 262 375)}, 190 {:id 190, :title "A Rule-Based Approach to Scoring Systems", :authors (392 282 170), :abstract "Scoring systems have a long history of active use in safety-critical domains such\r\nas healthcare and justice, where they provide guidance for making objective and\r\naccurate decisions. While scoring systems have often been handcrafted by domain\r\nexperts in the past, the use of machine learning algorithms to deduce decision models\r\nfrom historic data is becoming more prevalent, also due to an increased availability\r\nof data and computational resources. In this work, we present an overview of existing\r\nmethods for the data-driven construction of scoring systems and propose a taxonomy\r\nfor characterizing the different types of models they produce. We further provide a\r\nnew perspective on the topic by establishing a connection between scoring systems\r\nand additive rule models, and propose a rule-based methodology that allows for\r\nconstructing scoring systems with different characteristics. In an experimental study,\r\nwe investigate the effects of various constraints that are typically imposed on the\r\ncomplexity of scoring systems to facilitate their use by human practitioners. We also\r\ninvestigate how existing rule learning techniques help reduce negative impacts in\r\nterms of predictive accuracy they may entail.\r\n\r\n", :session 54, :keywords (290 557 549)}, 177 {:id 177, :title "A New Functional Data Clustering Technique Based on Spectral Clustering and Downsampling", :authors (374 531 386), :abstract "We present a new framework for clustering functional data along with a new paradigm\r\nfor performing model selection based on downsampling. Our clustering framework is\r\na generalisatiion of the spectral clustering approach and is flexible enough to exploit\r\nhigher order features of curves, including derivatives. Extensive comparative studies\r\nwith existing methods show a clear advantage of our approach over existing functional\r\ndata analysis clustering approaches. Additionally, we present a new paradigm for\r\nmodel selection, by introducing the technique of downsampling, which allows us\r\nto create lower resolution replicates of the observed curves. These replicates can\r\nthen be used to provide insight into the tuning parameters for the specific clustering\r\ntechniques. The usefulness of the proposed methods is illustrated through simulations\r\nand applications to real-life datasets.\r\n\r\nReferences\r\n1. Ramsay, JO and Silverman, BW.: Functional Data Analysis. Springer, c1997. New York (2005)\r\n2. Ng, Andrew Y and Jordan, Michael I and Weiss, Yair.: On spectral clustering: Analysis and an\r\n   algorithm. Advances in Neural Information Processing Systems. 849–856 (2002)\r\n3. Von Luxburg, Ulrike.: A tutorial on spectral clustering. Statistics and Computing 17(4), 395–416\r\n   (2007)\r\n4. Al Alawi, M., Ray, S. and Gupta, M. A New Framework for Distance-based Functional Clustering.\r\n   In: 34th International Workshop on Statistical Modelling, Guimarães, Portugal, 07-12 Jul 2019, \r\n   (2019)\r\n", :session 28, :keywords (75 76 217 383 219)}, 49 {:id 49, :title "COVID-19 Pandemic: A Methodological Model for the Analysis of Government’s Preventing\r\nMeasures and Health Data Records", :authors (539 516), :abstract "The study aims to investigate the associations between the government’s response\r\nmeasures during the COVID-19 pandemic and weekly incidence data (positivity\r\nrate, mortality rate and testing rate) in Greece. The study focuses on the period from\r\nthe detection of the first case in the country (26th February 2020) to the first week of\r\n2022 (08th January 2022). Data analysis was based on Correspondence Analysis on\r\na fuzzy-coded contingency table, followed by Hierarchical Cluster Analysis (HCA)\r\non the factor scores. Results revealed distinct time periods during which interesting\r\ninteractions took place between control measures and incidence data.\r\n\r\nReferences\r\n1. As¸an, Z., Greenacre, M.: Biplots of fuzzy coded data. Fuzzy Sets and Systems, 183(1), \r\n   57-71 (2011)\r\n2. Chadjipadelis, T.: Facebook profile, https://www.facebook.com/theodore.chadjipadelis (2022)\r\n3. Benzecri, J.P.: L’Analyse des Données. 2. L’Analyse des Correspondances. Dunod, Paris (1973) ´\r\n4. Hale, T., Petherick, A., Phillips, T., and Webster, S.: Variation in government responses to\r\n   COVID-19. Blavatnik school of government working paper, 31, 2020-11 (2020)\r\n5. Karapistolis, D.: Software Method of Data Analysis MAD. (2010) http://www.pylimad.gr/\r\n6. Markos A., Moschidis O., Chadjipadelis T.: Hierarchical clustering of mixed-type data based\r\n   on barycentric coding (2022) https://arxiv.org/submit/4142768\r\n7. Moschidis O., Chadjipadelis T.: A method for transforming ordinal variables. In: Palumbo F., \r\n   Montanari A., Vichi M. (eds) Data Science. Studies in Classification, Data Analysis, and \r\n   Knowledge Organization. Springer, Cham. https://doi.org/10.1007/978-3-319-55723-6 22 (2017)\r\n8. Papadimitriou, G., Florou, G.: Contribution of the Euclidean and chi-square metrics to \r\n   determining the most ideal clustering in ascending hierarchy (in Greek). In Annals in Honor \r\n   of Professor I. Liakis, 546-581. University of Macedonia, Thessaloniki (1996)", :session 44, :keywords (255 114 117 189)}, 84 {:id 84, :title "Functional Data Representation with Merge Trees", :authors (380 458), :abstract "Topological Data Analysis is a branch of data analysis aiming at representing data\r\nby means of topological information. Such representations are very different from\r\nclassical statistical ones and posses interesting properties that can be used to tackle\r\ndata analysis problems with a different perspective. We will represent functions by\r\nmeans of objects called merge trees, and with their properties we will look at the\r\nproblem of alignment and smoothing of functional data within a benchmark case study.\r\n\r\n", :session 16, :keywords (217 649 357 223 581)}}, :keywords {558 {:name "Sectorization", :sessions (80)}, 453 {:name "Outlier analysis", :sessions (69)}, 584 {:name "Social network analysis", :sessions (7)}, 487 {:name "Pls regression and classification", :sessions (42)}, 637 {:name "Three-mode data", :sessions (76)}, 519 {:name "Random projections", :sessions (51 74)}, 357 {:name "Merge trees", :sessions (16)}, 275 {:name "Image recognition", :sessions (56)}, 530 {:name "Regularized classification", :sessions (61)}, 389 {:name "Motivational factors", :sessions (64)}, 586 {:name "Social science", :sessions (35)}, 410 {:name "Multivariate skewed power exponential", :sessions (43)}, 433 {:name "Nonparametric gaussian-scale mixture", :sessions (68)}, 521 {:name "Random survival forest", :sessions (68)}, 451 {:name "Orthogonal haar integration", :sessions (18)}, 291 {:name "Interval contingency table", :sessions (15)}, 443 {:name "One-class classification", :sessions (9)}, 249 {:name "Graphical model selection", :sessions (62)}, 638 {:name "Three-way data", :sessions (20 71)}, 299 {:name "Joint species distribution model", :sessions (55)}, 121 {:name "Cox midel", :sessions (68)}, 287 {:name "Interaction data", :sessions (48)}, 65 {:name "Classification problems", :sessions (56)}, 70 {:name "Cluster stability", :sessions (41 70)}, 218 {:name "Functional data classification", :sessions (28)}, 648 {:name "Topic modeling", :sessions (35)}, 62 {:name "Class prediction", :sessions (52)}, 74 {:name "Cluster-weighted modeling", :sessions (34)}, 475 {:name "Pearson’s chi-squared", :sessions (55)}, 497 {:name "Principal component analysis", :sessions (44)}, 580 {:name "Sktime", :sessions (25)}, 164 {:name "Dynamical partitioning", :sessions (5)}, 282 {:name "Industry sector detection", :sessions (64)}, 273 {:name "Hyper-parameter tuning", :sessions (86)}, 186 {:name "Europe 2020", :sessions (40)}, 430 {:name "Nominal variables", :sessions (26)}, 641 {:name "Time series", :sessions (24 25 29 35 49 72 72)}, 529 {:name "Regularization", :sessions (11)}, 370 {:name "Mixed-effects models", :sessions (41)}, 233 {:name "Generalization", :sessions (69)}, 298 {:name "Item response theory", :sessions (67)}, 188 {:name "European union countries", :sessions (18)}, 240 {:name "Gev regression", :sessions (14)}, 110 {:name "Continual learning", :sessions (45)}, 130 {:name "Dbscan", :sessions (20)}, 620 {:name "Support vector machine", :sessions (17)}, 311 {:name "Landmark survival analysis", :sessions (77)}, 128 {:name "Data shift", :sessions (51)}, 399 {:name "Multiple imputation", :sessions (57)}, 377 {:name "Mixture models", :sessions (43 43 61)}, 468 {:name "Partial least squares", :sessions (12)}, 259 {:name "High dimentionality", :sessions (61)}, 210 {:name "Franz liszt", :sessions (24)}, 229 {:name "Gan", :sessions (45)}, 153 {:name "Discrete latent variables; european social survey; expectation-maximization\r\n          algorithm; item response theory.", :sessions (23)}, 621 {:name "Support vector machines", :sessions (68 80)}, 213 {:name "Function-on-scalar regression", :sessions (53)}, 670 {:name "User tuning", :sessions (70)}, 343 {:name "Matrix decomposition", :sessions (12)}, 472 {:name "Patterned covariance structures", :sessions (15)}, 7 {:name "Affinity coefficient", :sessions (10)}, 59 {:name "Cities", :sessions (40)}, 473 {:name "Patterns of cooperation", :sessions (66)}, 86 {:name "Complex network", :sessions (7)}, 613 {:name "Strategic perspective", :sessions (23)}, 491 {:name "Political behavior", :sessions (23)}, 154 {:name "Discrete random effects", :sessions (41)}, 20 {:name "Association measures", :sessions (72)}, 224 {:name "Fused lasso", :sessions (60)}, 355 {:name "Measurement invariance", :sessions (27)}, 592 {:name "Spatial data analysis", :sessions (53)}, 610 {:name "Statistical test", :sessions (18)}, 571 {:name "Similarity measures", :sessions (26)}, 466 {:name "Parsimonious models", :sessions (43 74)}, 72 {:name "Cluster validation", :sessions (41)}, 454 {:name "Outlier detection", :sessions (6 21 22 28)}, 463 {:name "Papillary carcinoma", :sessions (14)}, 58 {:name "Choquet integral", :sessions (29)}, 205 {:name "Fg algorithm", :sessions (12)}, 555 {:name "Scientific productivity", :sessions (66)}, 552 {:name "Sampling", :sessions (33)}, 60 {:name "Class imbalance", :sessions (13 45)}, 459 {:name "Pair correlation function", :sessions (84)}, 175 {:name "Elastic regression", :sessions (16)}, 322 {:name "Leptokurtic-normal distribution", :sessions (12)}, 510 {:name "Quantile density functions", :sessions (5)}, 662 {:name "Ultrametric models", :sessions (76)}, 27 {:name "Bayes", :sessions (78)}, 352 {:name "Measure of dispersion", :sessions (50)}, 493 {:name "Pq-trees", :sessions (57)}, 416 {:name "Mutidimensional scaling", :sessions (52)}, 1 {:name "3-way network", :sessions (7)}, 631 {:name "Temporal analysis", :sessions (40)}, 69 {:name "Cluster analysis .", :sessions (64)}, 101 {:name "Constrained estimation", :sessions (70)}, 24 {:name "Autoregression", :sessions (25)}, 547 {:name "Robustness", :sessions (21 58 70)}, 102 {:name "Constrained estimator", :sessions (37)}, 385 {:name "Model-based cluster analysis", :sessions (34)}, 135 {:name "Deep learning", :sessions (75 82)}, 397 {:name "Multiple comparisons", :sessions (65)}, 490 {:name "Poisson regression", :sessions (83)}, 354 {:name "Measurement error", :sessions (81)}, 360 {:name "Milp", :sessions (38)}, 55 {:name "Censored time series", :sessions (29)}, 568 {:name "Set function optimization", :sessions (24)}, 688 {:name "Weighting methods", :sessions (81)}, 269 {:name "Higher education.", :sessions (41)}, 676 {:name "Variational techniques", :sessions (35)}, 448 {:name "Optimal treatment regimes", :sessions (30)}, 527 {:name "Regional healthcare", :sessions (72)}, 206 {:name "Finite mixture model", :sessions (12 74)}, 165 {:name "Dynamical systems", :sessions (69)}, 387 {:name "Modelling", :sessions (31)}, 652 {:name "Transcriptomics", :sessions (61)}, 683 {:name "Weak hierarchy", :sessions (57)}, 85 {:name "Comparison", :sessions (55)}, 615 {:name "Strongly connected components", :sessions (56)}, 681 {:name "Warping", :sessions (16)}, 225 {:name "Fuzzy measures", :sessions (29)}, 297 {:name "Item classification", :sessions (81)}, 39 {:name "Bioprocess", :sessions (82)}, 274 {:name "Hypograph", :sessions (28)}, 88 {:name "Compositional data analysis", :sessions (42)}, 217 {:name "Functional data analysis", :sessions (6 16 16 28 28 33 37 37 53 65 65 77)}, 46 {:name "Brain-computer interface", :sessions (31)}, 682 {:name "Wasserstein distance", :sessions (70)}, 508 {:name "Qgis", :sessions (20)}, 149 {:name "Dimension reduction", :sessions (6 17 27 39 78)}, 415 {:name "Musical data mining", :sessions (24)}, 239 {:name "Geostatistics", :sessions (83)}, 478 {:name "Permutation method", :sessions (18)}, 157 {:name "Distance measures", :sessions (72)}, 345 {:name "Matrix-variate gaussian mixture", :sessions (14)}, 300 {:name "K-means", :sessions (5 32 32 83)}, 4 {:name "Additive profile clustering", :sessions (26)}, 550 {:name "Rule-based model", :sessions (13)}, 204 {:name "Feature importance inference", :sessions (62)}, 470 {:name "Partition refinement", :sessions (57)}, 646 {:name "Time-dependent covariates", :sessions (77)}, 77 {:name "Clustering validation", :sessions (10)}, 106 {:name "Contaminated gaussian mixture model", :sessions (21)}, 197 {:name "Exploratory data analysis", :sessions (4)}, 405 {:name "Multivariate count data", :sessions (42)}, 518 {:name "Random projection", :sessions (30)}, 232 {:name "Gaussian mixtures", :sessions (59)}, 260 {:name "High-dimensional classification", :sessions (11)}, 267 {:name "High-frequency sampling", :sessions (40)}, 119 {:name "Covid-19 tweets", :sessions (50)}, 319 {:name "Learning", :sessions (67)}, 534 {:name "Remote patient monitoring", :sessions (77)}, 222 {:name "Functional random forest", :sessions (65)}, 603 {:name "Split-merge procedures", :sessions (71)}, 293 {:name "Interval data", :sessions (36)}, 95 {:name "Congeniality", :sessions (57)}, 450 {:name "Optimization", :sessions (80)}, 329 {:name "Longitudinal binary data", :sessions (53)}, 144 {:name "Development", :sessions (40)}, 504 {:name "Propensity score", :sessions (13)}, 505 {:name "Proximity measure", :sessions (69)}, 176 {:name "Em algorithm", :sessions (11 12 21 22 48)}, 471 {:name "Pathway", :sessions (68)}, 349 {:name "Mcem algorithm", :sessions (53)}, 512 {:name "Quantile function estimation", :sessions (17)}, 192 {:name "Expectation–maximization", :sessions (59)}, 54 {:name "Causal effect", :sessions (13)}, 92 {:name "Confirmatory factorial analysis", :sessions (67)}, 221 {:name "Functional parameters", :sessions (24)}, 141 {:name "Dependence", :sessions (26)}, 502 {:name "Probability of failure", :sessions (84)}, 464 {:name "Parallel computing", :sessions (56)}, 307 {:name "Kernel function", :sessions (20)}, 290 {:name "Interpretable machine learning", :sessions (30 38 54 75)}, 627 {:name "Symbolic discordance", :sessions (5)}, 517 {:name "Random histograms", :sessions (52)}, 361 {:name "Minimum message length", :sessions (12)}, 264 {:name "High-dimensional linear regression", :sessions (74)}, 137 {:name "Democracy", :sessions (23)}, 356 {:name "Membership probability", :sessions (13 45)}, 678 {:name "Visualisation", :sessions (39)}, 327 {:name "Logistic regression", :sessions (54 78)}, 234 {:name "Generation interval", :sessions (68)}, 104 {:name "Constrained registration", :sessions (16)}, 353 {:name "Measure of location", :sessions (50)}, 15 {:name "Applications in social sciences", :sessions (79)}, 48 {:name "Canonical correlation analysis", :sessions (8)}, 242 {:name "Glioblastoma", :sessions (61)}, 50 {:name "Categorical responses", :sessions (41)}, 557 {:name "Scoring systems", :sessions (54)}, 251 {:name "Group test", :sessions (78)}, 394 {:name "Multigroup", :sessions (27)}, 116 {:name "Covid 19", :sessions (49)}, 585 {:name "Social networks", :sessions (7)}, 583 {:name "Social media", :sessions (35)}, 75 {:name "Clustering", :sessions (12 19 20 25 28 28 32 38 39 42 43 48 57 61 64 66 67 72 72 76 77 80 81)}, 437 {:name "Null hypothesis testing", :sessions (65)}, 516 {:name "Random forests", :sessions (9)}, 687 {:name "Weighted rv coefficient", :sessions (18)}, 159 {:name "Double constrained correspondence analysis", :sessions (8)}, 99 {:name "Constant logcontrast", :sessions (33)}, 540 {:name "Road traffic accidents", :sessions (20)}, 645 {:name "Time series forecasting", :sessions (29 81)}, 479 {:name "Permutation test", :sessions (18)}, 630 {:name "T-sne", :sessions (4 15)}, 281 {:name "Inductive rule learning", :sessions (75)}, 402 {:name "Multivariate", :sessions (29 39)}, 669 {:name "User risk identification", :sessions (7)}, 429 {:name "Noise component", :sessions (70)}, 309 {:name "Kolmogorov metric", :sessions (24)}, 458 {:name "Overlapping clustering", :sessions (26)}, 21 {:name "Atomic measures", :sessions (58)}, 388 {:name "Monitoring", :sessions (34)}, 495 {:name "Predictive model", :sessions (84)}, 626 {:name "Symbolic data analysis", :sessions (5 5 7 15 15 36 36 52)}, 31 {:name "Bayesian mixture model", :sessions (6)}, 113 {:name "Copulas", :sessions (27)}, 32 {:name "Bayesian nonparametric", :sessions (74)}, 407 {:name "Multivariate finite mixtures", :sessions (26)}, 398 {:name "Multiple correspondence analysis", :sessions (50)}, 136 {:name "Deep learning analytics; support vector machine; random forest", :sessions (31)}, 691 {:name "Xai", :sessions (4 75)}, 139 {:name "Density peaks", :sessions (59)}, 506 {:name "Psychiatry", :sessions (31)}, 396 {:name "Multinomial regression", :sessions (21)}, 460 {:name "Pair-copula", :sessions (26)}, 483 {:name "Pixel-based segmentation", :sessions (14)}, 589 {:name "Sparsity", :sessions (21)}, 581 {:name "Smoothing", :sessions (16)}, 174 {:name "Elastic net penalty", :sessions (21)}, 578 {:name "Singular value decomposition", :sessions (8)}, 331 {:name "Lstm", :sessions (29)}, 363 {:name "Minorization–maximization", :sessions (59)}, 284 {:name "Inlier memorization effect", :sessions (19)}, 208 {:name "Fire stations", :sessions (83)}, 305 {:name "Kernel density estimation map", :sessions (20)}, 182 {:name "Envelope methods.", :sessions (17)}, 256 {:name "Hierarchical clustering", :sessions (26 69)}, 657 {:name "Trimmed k-means", :sessions (72)}, 514 {:name "R", :sessions (4)}, 619 {:name "Supervised learning", :sessions (29)}, 485 {:name "Pleiotropy", :sessions (31)}, 214 {:name "Functional annotation", :sessions (82)}, 193 {:name "Explainable ai", :sessions (75)}, 685 {:name "Weighted correlation", :sessions (58)}, 635 {:name "Text classification", :sessions (64)}, 442 {:name "Omics data", :sessions (68)}, 561 {:name "Semiparametric regression", :sessions (53)}, 656 {:name "Trimmed bic", :sessions (34)}, 607 {:name "Statistical graphics", :sessions (4)}, 241 {:name "Gini index", :sessions (17)}, 314 {:name "Latent class analysis", :sessions (76 82)}, 226 {:name "Fuzzy sets", :sessions (20)}, 235 {:name "Generative model", :sessions (48)}, 672 {:name "Variable screening", :sessions (74)}, 420 {:name "Nearest neighbors", :sessions (28)}, 418 {:name "Natural law", :sessions (33)}, 262 {:name "High-dimensional data", :sessions (8 35 71)}, 263 {:name "High-dimensional data analysis", :sessions (65)}, 304 {:name "Kernel density estimation", :sessions (78)}, 401 {:name "Multiple testing", :sessions (14)}, 673 {:name "Variable selection", :sessions (17 53)}, 40 {:name "Biplot", :sessions (8 8 8 39 39 55 55)}, 129 {:name "Data source", :sessions (40)}, 600 {:name "Spectral functions.", :sessions (70)}, 467 {:name "Parsimonious parameterization", :sessions (76)}, 445 {:name "Online algorithms", :sessions (59)}, 317 {:name "Latent variable model", :sessions (55)}, 294 {:name "Interval variables.", :sessions (15)}, 91 {:name "Confidence judgements", :sessions (30 67)}, 364 {:name "Missing data", :sessions (57 81)}, 515 {:name "Random forest", :sessions (24 83)}, 412 {:name "Multivariate time series", :sessions (72)}, 553 {:name "Sardina pilchardus", :sessions (83)}, 341 {:name "Mathematical optimization", :sessions (38)}, 117 {:name "Covid-19", :sessions (33 37 44 52 60)}, 665 {:name "Unfolding", :sessions (27)}, 523 {:name "Rare events data", :sessions (14)}, 172 {:name "Eigenblocks and eigenmatrices", :sessions (15)}, 601 {:name "Spectral rotation", :sessions (66)}, 108 {:name "Contaminated normal distributions", :sessions (22)}, 156 {:name "Distance", :sessions (50)}, 358 {:name "Micro-economics", :sessions (36)}, 308 {:name "Knowledge graphs", :sessions (75)}, 649 {:name "Topological data analysis", :sessions (16)}, 531 {:name "Regularized pca", :sessions (27)}, 223 {:name "Functional registration", :sessions (16)}, 419 {:name "Nearest neighbor", :sessions (18)}, 365 {:name "Missing values", :sessions (22)}, 181 {:name "Ensemble of optimal trees", :sessions (64)}, 417 {:name "Naive bayes", :sessions (17)}, 278 {:name "Imbalanced data", :sessions (21)}, 56 {:name "Centroid optimization", :sessions (58)}, 33 {:name "Bayesian sparse modelling", :sessions (66)}, 13 {:name "Angular halfspace depth", :sessions (58)}, 22 {:name "Auc", :sessions (19)}, 618 {:name "Supervised classification", :sessions (65 84)}, 380 {:name "Mode seeking", :sessions (10)}, 257 {:name "Hierarchical structure", :sessions (68)}, 338 {:name "Marketing", :sessions (12)}, 500 {:name "Probabilistic distance clustering", :sessions (41)}, 168 {:name "Ecm algorithm", :sessions (26 34)}, 496 {:name "Principal balances", :sessions (42)}, 347 {:name "Maximum parsimony", :sessions (69)}, 501 {:name "Probability density functions.", :sessions (37)}, 596 {:name "Species community", :sessions (55)}, 90 {:name "Computing", :sessions (67)}, 237 {:name "Genomics", :sessions (31)}, 292 {:name "Interval convexity", :sessions (57)}, 109 {:name "Contamination", :sessions (58)}, 216 {:name "Functional data analyisis", :sessions (53)}, 191 {:name "Expectation-maximization algorithm; likelihood ratio test; model selection;\r\n          multiple testing", :sessions (79)}, 498 {:name "Principal covariates regression", :sessions (78)}, 375 {:name "Mixture model.", :sessions (71)}, 525 {:name "Reconstruction", :sessions (58)}, 367 {:name "Mixed frequency data", :sessions (29)}, 143 {:name "Depth-to-depth", :sessions (65)}, 178 {:name "Emotions", :sessions (31)}, 640 {:name "Time dependent covariates", :sessions (68)}, 247 {:name "Graph clustering", :sessions (32)}, 328 {:name "Logratio principal component analysis (lr-pca)", :sessions (33)}, 391 {:name "Multi-valued variables", :sessions (15)}, 167 {:name "Echelon scan method", :sessions (60)}, 36 {:name "Bi-stochastic matrix", :sessions (32)}, 41 {:name "Biplots", :sessions (39 50)}, 474 {:name "Pca", :sessions (8 27)}, 187 {:name "European countries", :sessions (40)}, 551 {:name "Rules", :sessions (75)}, 528 {:name "Regression", :sessions (30)}, 599 {:name "Spectral clustering", :sessions (20)}, 376 {:name "Mixture modelling", :sessions (22)}, 195 {:name "Explainable machine learning", :sessions (75)}, 316 {:name "Latent space model", :sessions (74)}, 668 {:name "Unsupervised anomaly detection", :sessions (19)}, 428 {:name "Neural networks", :sessions (84)}, 303 {:name "Kernel", :sessions (68)}, 671 {:name "Variable importance", :sessions (82)}, 368 {:name "Mixed integer quadratic programming", :sessions (80)}, 560 {:name "Sem", :sessions (79)}, 565 {:name "Sentiment classification", :sessions (50)}, 310 {:name "L_1 penalty", :sessions (28)}, 366 {:name "Mixed data", :sessions (41)}, 118 {:name "Covid-19 pandemic", :sessions (23)}, 522 {:name "Rank-1 projection", :sessions (14)}, 150 {:name "Dimensionality reduction", :sessions (64 66 72)}, 313 {:name "Large size data", :sessions (59)}, 384 {:name "Model validation", :sessions (37)}, 567 {:name "Seriation", :sessions (57)}, 238 {:name "Geographically weighed regression", :sessions (60)}, 196 {:name "Explaining model change", :sessions (54)}, 162 {:name "Drugstores", :sessions (52)}, 393 {:name "Multidimensional scaling", :sessions (27 72)}, 184 {:name "Environmental effects", :sessions (83)}, 219 {:name "Functional data clustering", :sessions (28)}, 461 {:name "Pairs of random processes", :sessions (24)}, 89 {:name "Computation", :sessions (58)}, 100 {:name "Constrain newton method", :sessions (68)}, 426 {:name "Networks", :sessions (32)}, 604 {:name "Spreadsheet", :sessions (67)}, 477 {:name "Permutation feature importance", :sessions (54)}, 541 {:name "Robinson dissimilarities", :sessions (57)}, 351 {:name "Measure of correlation", :sessions (50)}, 243 {:name "Global models", :sessions (25)}, 131 {:name "Decision making", :sessions (31)}, 629 {:name "Symmetric difference metrics", :sessions (32)}, 122 {:name "Cressie-read divergence statistic", :sessions (55)}, 43 {:name "Bootstrap", :sessions (14)}, 231 {:name "Gaussian mixture models", :sessions (59)}, 61 {:name "Class overlap", :sessions (13 45)}, 654 {:name "Travel mode choice", :sessions (54)}, 598 {:name "Spectral analysis", :sessions (24)}, 413 {:name "Multivariate wrapped distributions", :sessions (11)}, 29 {:name "Bayesian inference", :sessions (33)}, 151 {:name "Directional data analysis", :sessions (58)}, 369 {:name "Mixed-effect models", :sessions (77)}, 348 {:name "Mcd", :sessions (11)}, 575 {:name "Simulation study", :sessions (26)}, 693 {:name "Zero-inflated beta regression", :sessions (9)}, 44 {:name "Bootstrap assessment of cluster stability", :sessions (64)}, 258 {:name "Hierarchy of latent concepts", :sessions (76)}, 250 {:name "Grocery shopping recommendation", :sessions (64)}, 674 {:name "Variational auto-encoders", :sessions (19)}, 539 {:name "Road accident data", :sessions (13)}, 301 {:name "K-mer", :sessions (82)}, 424 {:name "Network models", :sessions (66)}, 93 {:name "Conformal inference", :sessions (62)}, 6 {:name "Admm", :sessions (27)}, 684 {:name "Web scraping", :sessions (50)}, 573 {:name "Simplicial depth", :sessions (58)}, 408 {:name "Multivariate methods", :sessions (23)}, 563 {:name "Sensitivity and specificity", :sessions (19)}, 616 {:name "Structural equation modeling", :sessions (12)}, 111 {:name "Continuous variable", :sessions (50)}, 689 {:name "Welfare", :sessions (64)}, 28 {:name "Bayesian estimation", :sessions (29)}, 456 {:name "Outlyingness", :sessions (61)}, 374 {:name "Mixture model", :sessions (28 33 71)}, 608 {:name "Statistical literacy", :sessions (31)}, 548 {:name "Roc curve", :sessions (78)}, 538 {:name "Rna sequencing", :sessions (71)}, 411 {:name "Multivariate skewness", :sessions (18)}, 134 {:name "Decision trees", :sessions (30)}, 64 {:name "Classification of textual documents", :sessions (35)}, 623 {:name "Svm", :sessions (56)}, 465 {:name "Parameter estimation", :sessions (59)}, 334 {:name "Machine/deep learning", :sessions (31)}, 323 {:name "Local clustering", :sessions (37)}, 189 {:name "Evidence-based policy making", :sessions (44)}, 280 {:name "Indicator processes", :sessions (72)}, 198 {:name "Exploratory factorial analysis", :sessions (67)}, 155 {:name "Discriminant analysis", :sessions (14)}, 295 {:name "Interval-valued data", :sessions (15 36)}, 248 {:name "Graphical lasso", :sessions (28)}, 587 {:name "Sparse classifier", :sessions (80)}, 285 {:name "Inner product", :sessions (8)}, 507 {:name "Psychometric networks", :sessions (66)}, 227 {:name "Fuzzy thematic cluster", :sessions (69)}, 476 {:name "Permutation", :sessions (82)}, 494 {:name "Prediction", :sessions (37)}, 220 {:name "Functional data modelling", :sessions (37)}, 103 {:name "Constrained least squares", :sessions (80)}, 611 {:name "Stellar groups", :sessions (10)}, 170 {:name "Edge reduction", :sessions (66)}, 51 {:name "Categorical time series", :sessions (72)}, 25 {:name "Balancing techniques", :sessions (21)}, 261 {:name "High-dimensional compositional data", :sessions (42)}, 201 {:name "Factorial k-means", :sessions (32)}, 590 {:name "Spatial analysis", :sessions (7)}, 489 {:name "Poisson inar(1) model", :sessions (29)}, 166 {:name "Echelon analysis", :sessions (60)}, 447 {:name "Optimal decision trees", :sessions (80)}, 34 {:name "Benchmarking", :sessions (26 26)}, 252 {:name "Heart failure", :sessions (77)}, 325 {:name "Locally-weighted learning", :sessions (52)}, 594 {:name "Spatial point patterns", :sessions (84)}, 436 {:name "Nowcast", :sessions (29)}, 535 {:name "Representation learning", :sessions (66)}, 146 {:name "Digital", :sessions (44)}, 228 {:name "Gamma distribution", :sessions (19)}, 306 {:name "Kernel density estimation.", :sessions (32)}, 125 {:name "Data analysis", :sessions (23)}, 276 {:name "Imbalanced classes", :sessions (51)}, 340 {:name "Markov decision process (mdp)", :sessions (56)}, 148 {:name "Dilution effect", :sessions (78)}, 482 {:name "Pisa data", :sessions (44)}, 622 {:name "Survival analysis", :sessions (68)}, 588 {:name "Sparse functional data", :sessions (16)}, 17 {:name "Artificial data", :sessions (45)}, 312 {:name "Large datasets", :sessions (52)}, 606 {:name "Statis methodology", :sessions (40)}, 3 {:name "Adaptive fuzzy systems", :sessions (81)}, 520 {:name "Random subsampling", :sessions (59)}, 286 {:name "Intelligent shopping list", :sessions (64)}, 279 {:name "Incremental learning", :sessions (54)}, 536 {:name "Research tendencies", :sessions (69)}, 663 {:name "Umap", :sessions (15)}, 12 {:name "Ancient bridge", :sessions (84)}, 440 {:name "O2s2", :sessions (33)}, 332 {:name "Machine learning", :sessions (9 13 38 64 75 81 82 83)}, 330 {:name "Lsa", :sessions (35)}, 382 {:name "Model based clustering", :sessions (22 22 70)}, 152 {:name "Dirichlet process mixture model", :sessions (6)}, 544 {:name "Robust estimation", :sessions (34)}, 642 {:name "Time series analysis", :sessions (79)}, 435 {:name "Nonparametric statistics", :sessions (32)}, 342 {:name "Mathematics anxiety", :sessions (30 67)}, 2 {:name "Accelerometer", :sessions (77)}, 66 {:name "Classification trees", :sessions (30)}, 484 {:name "Planning", :sessions (56)}, 439 {:name "Numerical smoothing.", :sessions (20)}, 236 {:name "Genetic correlation", :sessions (31)}, 556 {:name "Score-based classification", :sessions (38)}, 373 {:name "Mixed-type data", :sessions (41)}, 142 {:name "Depth", :sessions (65)}, 359 {:name "Microbiome data", :sessions (71)}, 371 {:name "Mixed-mode official surveys", :sessions (81)}, 444 {:name "One-versus-rest regression", :sessions (52)}, 570 {:name "Similarity forest", :sessions (24)}, 107 {:name "Contaminated normal distribution", :sessions (34)}, 532 {:name "Reliability index", :sessions (84)}, 23 {:name "Autobiplots", :sessions (39)}, 230 {:name "Gaussian mixture model", :sessions (70)}, 625 {:name "Symbolic concordance", :sessions (5)}, 47 {:name "Calibration", :sessions (9)}, 526 {:name "Reduced k-means", :sessions (32 35)}, 180 {:name "Ensemble learning", :sessions (30 62)}, 537 {:name "Reversible jump", :sessions (71)}, 659 {:name "Twitter", :sessions (35)}, 158 {:name "Distributional data", :sessions (5 52 61)}, 350 {:name "Mcmc", :sessions (68)}, 35 {:name "Benjamini-hochberg procedure", :sessions (65)}, 644 {:name "Time series clustering", :sessions (25)}, 127 {:name "Data pooling", :sessions (25)}, 675 {:name "Variational autoencoder", :sessions (19)}, 383 {:name "Model selection", :sessions (12 26 28)}, 533 {:name "Religion", :sessions (23)}, 302 {:name "K-regression algorithm", :sessions (5)}, 564 {:name "Sentiment analysis", :sessions (35)}, 566 {:name "Sequence alignment", :sessions (82)}, 82 {:name "Common principal components", :sessions (12)}, 76 {:name "Clustering stability", :sessions (28)}, 492 {:name "Polyhedral separation", :sessions (56)}, 215 {:name "Functional data", :sessions (6 21 22 28 61 77 84)}, 97 {:name "Consensus clustering", :sessions (62)}, 277 {:name "Imbalanced clustering", :sessions (59)}, 19 {:name "Artificial neural networks", :sessions (29)}, 335 {:name "Mallows’ distance", :sessions (36)}, 597 {:name "Species distribution model", :sessions (83)}, 57 {:name "Centroids", :sessions (58)}, 609 {:name "Statistical network analysis", :sessions (74)}, 202 {:name "Feature engineering", :sessions (82)}, 68 {:name "Cluster analysis", :sessions (10 26 49 50 71 72)}, 452 {:name "Orthogonal matrix", :sessions (12)}, 200 {:name "Factorial dimensionality reduction", :sessions (76)}, 11 {:name "Alternating optimization", :sessions (27)}, 115 {:name "Count data", :sessions (33)}, 339 {:name "Markov chain monte carlo", :sessions (71)}, 431 {:name "Non-local priors", :sessions (10)}, 462 {:name "Pandemic", :sessions (31)}, 337 {:name "Manufacturing", :sessions (45)}, 255 {:name "Hierarchical cluster analysis", :sessions (44)}, 503 {:name "Projection matrix", :sessions (19)}, 546 {:name "Robust mahalanobis distance", :sessions (21)}, 9 {:name "Air passenger transportation", :sessions (23)}, 632 {:name "Tensor", :sessions (34)}, 457 {:name "Over-sampling", :sessions (21)}, 427 {:name "Neural network", :sessions (84)}, 145 {:name "Differential expression", :sessions (61)}, 5 {:name "Adjacency matrix", :sessions (69)}, 624 {:name "Symbolic clustering", :sessions (36)}, 244 {:name "Global optimization", :sessions (30)}, 289 {:name "Interpretability", :sessions (75)}, 112 {:name "Convex optimization.", :sessions (59)}, 414 {:name "Multple alignment", :sessions (16)}, 179 {:name "Ensemble", :sessions (9)}, 344 {:name "Matrix-variate", :sessions (43)}, 481 {:name "Phylogenetic trees", :sessions (32)}, 661 {:name "Typhoon", :sessions (9)}, 245 {:name "Glucose level curve", :sessions (77)}, 378 {:name "Mixture of regression models", :sessions (34)}, 658 {:name "Trimming", :sessions (70 70)}, 266 {:name "High-frequency data", :sessions (81)}, 324 {:name "Local inference", :sessions (65)}, 680 {:name "Vl methodology", :sessions (10)}, 446 {:name "Optimal classification trees", :sessions (38)}, 524 {:name "Recommender systems", :sessions (64)}, 254 {:name "Hierarchical bayesian model", :sessions (61)}, 404 {:name "Multivariate coefficient of variation", :sessions (18)}, 617 {:name "Subspace clustering", :sessions (70)}, 283 {:name "Inhomogeneous clusters", :sessions (65)}, 513 {:name "Quantile regression", :sessions (13)}, 572 {:name "Similarity-based clustering", :sessions (10)}, 83 {:name "Common principal directions", :sessions (70)}, 634 {:name "Tertiary education", :sessions (7)}, 138 {:name "Dendrogram heights; hierarchical clustering; linear time series models", :sessions (25)}, 346 {:name "Maximum likelihood", :sessions (17 69)}, 14 {:name "Anomaly detection", :sessions (45 45 69)}, 455 {:name "Outliers", :sessions (34 36)}, 265 {:name "High-dimensions", :sessions (70)}, 449 {:name "Optimal trees", :sessions (30)}, 333 {:name "Machine learning algorithms", :sessions (28)}, 650 {:name "Torus", :sessions (11)}, 639 {:name "Thyroid us image", :sessions (14)}, 569 {:name "Silhouette width", :sessions (28)}, 326 {:name "Logistic biplot", :sessions (8)}, 647 {:name "Topic model", :sessions (35)}, 45 {:name "Bootstrap method", :sessions (19)}, 53 {:name "Catpca", :sessions (64)}, 559 {:name "Seemingly unrelated regression.", :sessions (34)}, 78 {:name "Clustering with relational constraints", :sessions (7)}, 562 {:name "Semiparametric regression\r\n          with roughness penalty", :sessions (53)}, 542 {:name "Robust covariance estimation", :sessions (11)}, 664 {:name "Under-sampling", :sessions (13 45)}, 315 {:name "Latent class detection", :sessions (79)}, 480 {:name "Personality traits", :sessions (30 67)}, 132 {:name "Decision support system", :sessions (80)}, 26 {:name "Bankruptcy prediction", :sessions (81)}, 123 {:name "Crispr", :sessions (82)}, 203 {:name "Feature extraction", :sessions (29)}, 667 {:name "Unobserved heterogeneity", :sessions (79)}, 392 {:name "Multiblock data", :sessions (78)}, 577 {:name "Single link hierarchy", :sessions (57)}, 140 {:name "Dependancy chains", :sessions (56)}, 321 {:name "Learning from data streams", :sessions (86)}, 441 {:name "Off target scoring", :sessions (82)}, 268 {:name "High-order data", :sessions (43)}, 16 {:name "Arima", :sessions (29)}, 320 {:name "Learning analytics", :sessions (67)}, 133 {:name "Decision tree", :sessions (9)}, 288 {:name "Interactive plot", :sessions (60)}, 381 {:name "Mode-based clustering", :sessions (32)}, 605 {:name "Square-root-velocity framework", :sessions (16)}, 163 {:name "Dynamic data", :sessions (48)}, 81 {:name "Collective counterfactual explanations", :sessions (38)}, 120 {:name "Covid-19; underlying disease; medical treatment", :sessions (49)}, 643 {:name "Time series classification", :sessions (24 25)}, 79 {:name "Clusterwise", :sessions (34)}, 211 {:name "Fraud detection", :sessions (66 86)}, 38 {:name "Binned data", :sessions (59)}, 173 {:name "Eigenvalue constraint", :sessions (34)}, 126 {:name "Data mining", :sessions (34)}, 421 {:name "Neighborhood graph", :sessions (69)}, 593 {:name "Spatial downscaling", :sessions (33)}, 636 {:name "Text mining", :sessions (35 35)}, 98 {:name "Consistency factor", :sessions (11)}, 422 {:name "Network", :sessions (61)}, 423 {:name "Network analysis", :sessions (7)}, 614 {:name "String distances", :sessions (44)}, 582 {:name "Smote", :sessions (21)}, 666 {:name "Unit- and class-dependent misclassification cost", :sessions (30)}, 554 {:name "Sats-36©", :sessions (67)}, 409 {:name "Multivariate regression", :sessions (33)}, 574 {:name "Simulation", :sessions (78)}, 595 {:name "Spearman correlation coefficient", :sessions (10)}, 124 {:name "Crop insurance", :sessions (9)}, 171 {:name "Eeg", :sessions (31)}, 87 {:name "Compositional data", :sessions (33)}, 169 {:name "Economic crisis", :sessions (40)}, 653 {:name "Transformer models", :sessions (64)}, 679 {:name "Visualization", :sessions (49 60)}, 160 {:name "Double principal component analysis", :sessions (44)}, 30 {:name "Bayesian methodology", :sessions (71)}, 400 {:name "Multiple instance learning", :sessions (38 56 56)}, 509 {:name "Quality measure", :sessions (26)}, 207 {:name "Fire", :sessions (83)}, 434 {:name "Nonparametric regression", :sessions (52)}, 690 {:name "Win-loss probabilities of potential clients", :sessions (64)}, 194 {:name "Explainable artificial intelligence", :sessions (54)}, 511 {:name "Quantile estimates", :sessions (36)}, 73 {:name "Cluster validity indices", :sessions (32)}, 486 {:name "Pls", :sessions (55)}, 336 {:name "Manifold learning", :sessions (6)}, 96 {:name "Conic optimization", :sessions (80)}, 10 {:name "Alignment", :sessions (77)}, 660 {:name "Two-sample test", :sessions (65)}, 272 {:name "Hurdle model", :sessions (83)}, 499 {:name "Principal vectors", :sessions (15)}, 488 {:name "Pls-blr", :sessions (55)}, 386 {:name "Model-based clustering", :sessions (10 21 22 26 34 43 71 71 74 74 76 79)}, 270 {:name "Histogram variables", :sessions (52)}, 576 {:name "Simultaneous component analysis", :sessions (27)}, 543 {:name "Robust distance", :sessions (11)}, 271 {:name "Hotspot cluster", :sessions (60)}, 18 {:name "Artificial intelligence (ai)", :sessions (84)}, 395 {:name "Multigroup data", :sessions (27)}, 403 {:name "Multivariate analysis", :sessions (40 70 83)}, 469 {:name "Partially observed functional data", :sessions (65)}, 105 {:name "Constraints", :sessions (22)}, 185 {:name "Epigraph", :sessions (28)}, 52 {:name "Categorical variable", :sessions (50)}, 545 {:name "Robust estimators", :sessions (11)}, 633 {:name "Tensors", :sessions (43)}, 114 {:name "Correspondence analysis", :sessions (15 44 76)}, 253 {:name "Hierarchical and nested data structures", :sessions (10)}, 612 {:name "Stochastic approximation", :sessions (59)}, 628 {:name "Symbolic fisher discriminant analysis", :sessions (36)}, 209 {:name "Flood events", :sessions (84)}, 147 {:name "Digital soil mapping", :sessions (83)}, 655 {:name "Tree-based methods", :sessions (54)}, 425 {:name "Networked data", :sessions (66)}, 67 {:name "Climate change", :sessions (35)}, 296 {:name "Isolation forest", :sessions (36)}, 602 {:name "Spherical separation", :sessions (38)}, 318 {:name "Leadership", :sessions (64)}, 161 {:name "Double supervised pca", :sessions (66)}, 651 {:name "Tours", :sessions (4)}, 372 {:name "Mixed-type", :sessions (9)}, 406 {:name "Multivariate data analysis", :sessions (69)}, 438 {:name "Number of clusters", :sessions (70)}, 71 {:name "Cluster tree", :sessions (10)}, 579 {:name "Skewed distributions", :sessions (43)}, 42 {:name "Blockmodeling", :sessions (7)}, 80 {:name "Co-clustering", :sessions (34)}, 677 {:name "Visibility graphs", :sessions (29)}, 199 {:name "Fabricated data", :sessions (44)}, 591 {:name "Spatial data", :sessions (60)}, 37 {:name "Binary data", :sessions (55)}, 183 {:name "Environment", :sessions (35)}, 432 {:name "Non-parametric", :sessions (65)}, 379 {:name "Mobility data", :sessions (7)}, 63 {:name "Classification", :sessions (11 13 17 17 30 36 43 45 57 65 72 78 78 82)}, 212 {:name "Frugal learning", :sessions (59)}, 94 {:name "Conformal prediction", :sessions (37)}, 362 {:name "Minimum regularized covariance determinant", :sessions (6)}, 8 {:name "Agricultural production costs", :sessions (36)}, 686 {:name "Weighted likelihood", :sessions (11)}, 692 {:name "Youden j statistic", :sessions (24)}, 246 {:name "Google trends", :sessions (40)}, 190 {:name "Exemplar", :sessions (59)}, 549 {:name "Rule learning", :sessions (54)}, 177 {:name "Emalgorithm", :sessions (61)}, 49 {:name "Categorical data", :sessions (8 12 50 76)}, 390 {:name "Multi-objective optimization", :sessions (24)}, 84 {:name "Community detection", :sessions (7)}}, :users {558 {:firstname "V.", :lastname "Nesrstová", :sessions (42)}, 453 {:firstname "Pedro", :lastname "Sá Couto", :sessions (67)}, 584 {:firstname "Youngkwang", :lastname "Cho", :sessions (49)}, 487 {:firstname "Ruey", :lastname "S. Tsay", :sessions (25)}, 519 {:firstname "Soogeun", :lastname "Park", :sessions (78)}, 357 {:firstname "Marco", :lastname "Alfò", :sessions (74)}, 275 {:firstname "Jiri", :lastname "Dvorak", :sessions (84)}, 530 {:firstname "Sungyoung", :lastname "Lee", :sessions (68)}, 389 {:firstname "Michael", :lastname "C. Thrun", :sessions (78 26)}, 586 {:firstname "Zardad", :lastname "Khan", :sessions (30)}, 410 {:firstname "Mário", :lastname "Figueiredo", :sessions (12)}, 433 {:firstname "Panagiotidou", :lastname "Georgia", :sessions (23)}, 521 {:firstname "Sourav", :lastname "Adhikari", :sessions (35)}, 451 {:firstname "Pedro", :lastname "Nogueira", :sessions (20 13)}, 291 {:firstname "José", :lastname "A. Vilar", :sessions (25 72)}, 443 {:firstname "Paulo", :lastname "Rebelo Manuel", :sessions (20 13)}, 249 {:firstname "J.", :lastname "A. Martín-Fernández", :sessions (42)}, 299 {:firstname "João", :lastname "Gama", :sessions (1 86)}, 121 {:firstname "Claudio", :lastname "Agostinelli", :sessions (11)}, 287 {:firstname "Jose", :lastname "Luis Vicente-Villardon", :sessions (55 8)}, 65 {:firstname "Antonio", :lastname "Fuduli", :sessions (38 56 56)}, 70 {:firstname "Anuradha", :lastname "Roy", :sessions (15)}, 218 {:firstname "Glòria", :lastname "Mateu-Figueras", :sessions (33 42)}, 62 {:firstname "Anthony", :lastname "Bagnall", :sessions (25)}, 74 {:firstname "Aylin", :lastname "Yaman Kocadağlı", :sessions (23)}, 475 {:firstname "Riccardo", :lastname "Giubilei", :sessions (32)}, 497 {:firstname "Sanetoshi", :lastname "Yamada", :sessions (60)}, 580 {:firstname "Yongkuk", :lastname "Kim", :sessions (68)}, 164 {:firstname "Ester", :lastname "Zumpano", :sessions (56)}, 282 {:firstname "Johannes", :lastname "Fürnkranz", :sessions (54 75)}, 273 {:firstname "Jens", :lastname "Weber", :sessions (69)}, 186 {:firstname "Francesca", :lastname "Chiaromonte", :sessions (37)}, 430 {:firstname "P.", :lastname "Bertrand", :sessions (57)}, 529 {:firstname "Suhyun", :lastname "Hwangbo", :sessions (68)}, 370 {:firstname "Marta", :lastname "B. Lopes", :sessions (83)}, 233 {:firstname "Hulin", :lastname "Wu", :sessions (65)}, 298 {:firstname "João", :lastname "Alves", :sessions (10)}, 188 {:firstname "Francesca", :lastname "Greselin", :sessions (34 6)}, 240 {:firstname "Igor", :lastname "Kravchenko", :sessions (36)}, 110 {:firstname "Christine", :lastname "Keribin", :sessions (59)}, 130 {:firstname "David", :lastname "Mas´ıs", :sessions (20)}, 311 {:firstname "Katerina", :lastname "Pawlasova", :sessions (84)}, 128 {:firstname "Daniel", :lastname "Santos", :sessions (13)}, 399 {:firstname "Miguel", :lastname "Felgueiras", :sessions (78)}, 377 {:firstname "Matteo", :lastname "Avolio", :sessions (38 56 56)}, 468 {:firstname "Rainer", :lastname "Dyckerhoff", :sessions (58)}, 259 {:firstname "Jan", :lastname "Graffelman", :sessions (8 33)}, 210 {:firstname "Gianluca", :lastname "Morelli", :sessions (70 22)}, 229 {:firstname "Hien", :lastname "Duy Nguyen", :sessions (59)}, 153 {:firstname "Elisabete", :lastname "Teixeira", :sessions (84)}, 213 {:firstname "Giorgia", :lastname "Zaccaria", :sessions (76 76)}, 343 {:firstname "M.", :lastname "Grac¸a Batista", :sessions (64)}, 472 {:firstname "Raúl", :lastname "Jiménez", :sessions (28 65)}, 7 {:firstname "Adi", :lastname "Lausen", :sessions (82 67 30 30)}, 59 {:firstname "Anna", :lastname "Maria Paganoni", :sessions (41)}, 473 {:firstname "Reda", :lastname "Amir Sofiane Tighilt", :sessions (64)}, 86 {:firstname "Bertus", :lastname "Jeronimus", :sessions (79)}, 491 {:firstname "Ruta", :lastname "Petraitytè", :sessions (64)}, 154 {:firstname "Elvira", :lastname "Romano", :sessions (37)}, 20 {:firstname "Alessio", :lastname "Squassina", :sessions (31)}, 224 {:firstname "Hana", :lastname "Rezankova", :sessions (26)}, 355 {:firstname "Marcin", :lastname "Pe lka", :sessions (36)}, 592 {:firstname "İsmail", :lastname "Meşe", :sessions (14)}, 571 {:firstname "Vladimir", :lastname "Batagelj", :sessions (7)}, 466 {:firstname "Rafik", :lastname "Abdesselam", :sessions (69)}, 72 {:firstname "Astrid", :lastname "D¨urauer", :sessions (82)}, 454 {:firstname "Peter", :lastname "A. Tait", :sessions (43)}, 463 {:firstname "Rabea", :lastname "Aschenbruck", :sessions (41)}, 58 {:firstname "Anna", :lastname "M. Paganoni", :sessions (65)}, 205 {:firstname "Gerard", :lastname "B.M. Heuvelink", :sessions (83)}, 555 {:firstname "Urszula", :lastname "Cieraszewska", :sessions (66)}, 552 {:firstname "Tüzün", :lastname "Tolga İnan", :sessions (23)}, 60 {:firstname "Anna", :lastname "Meloni", :sessions (31)}, 459 {:firstname "Pierpaolo", :lastname "D’Urso ´", :sessions (72)}, 175 {:firstname "Fatemeh", :lastname "Asgari", :sessions (53)}, 322 {:firstname "Laura", :lastname "Anderlucci", :sessions (74)}, 510 {:firstname "Shuang", :lastname "Wu", :sessions (65)}, 27 {:firstname "Alice", :lastname "Barth", :sessions (76)}, 352 {:firstname "Marcela", :lastname "Zembura", :sessions (66)}, 493 {:firstname "S.", :lastname "Uysal", :sessions (30)}, 416 {:firstname "Niel", :lastname "le Roux", :sessions (50)}, 1 {:firstname "A.", :lastname "Balzanella", :sessions (5)}, 69 {:firstname "António", :lastname "Grilo", :sessions (83)}, 101 {:firstname "Cecilia", :lastname "Salvatore", :sessions (38)}, 24 {:firstname "Alexei", :lastname "Vernitski", :sessions (67 30)}, 547 {:firstname "Tongtong", :lastname "Wu", :sessions (71)}, 102 {:firstname "Chadjipadelis", :lastname "Theodore", :sessions (23)}, 385 {:firstname "Maximilian", :lastname "Muschalik", :sessions (54)}, 135 {:firstname "Dianne", :lastname "Cook", :sessions (4)}, 397 {:firstname "Michele", :lastname "Staiano", :sessions (54)}, 490 {:firstname "Ruta", :lastname "Petraityte", :sessions (64)}, 354 {:firstname "Marcelo", :lastname "Silva", :sessions (20 13)}, 360 {:firstname "Margarida", :lastname "G.M.S. Cardoso", :sessions (12)}, 55 {:firstname "Angelos", :lastname "Markos", :sessions (50 39)}, 568 {:firstname "Vincent", :lastname "Audigier", :sessions (57)}, 269 {:firstname "Jeff", :lastname "Goldsmith", :sessions (77)}, 448 {:firstname "Pedro", :lastname "Delicado", :sessions (77)}, 527 {:firstname "Su", :lastname "Hoon Choi", :sessions (9)}, 206 {:firstname "German", :lastname "Aneiros", :sessions (53)}, 165 {:firstname "Etienne", :lastname "Low-Decarie", :sessions (82)}, 387 {:firstname "Mayumi", :lastname "Tanahashi", :sessions (60)}, 85 {:firstname "Berthold", :lastname "Lausen ˙", :sessions (64)}, 225 {:firstname "Helena", :lastname "Bacelar-Nicolau ´", :sessions (10)}, 297 {:firstname "Jozef", :lastname "Pociecha", :sessions (81)}, 39 {:firstname "Ana", :lastname "Maria Rodrigues", :sessions (80)}, 274 {:firstname "Jinwon", :lastname "Heo", :sessions (19)}, 88 {:firstname "Bettina", :lastname "Grün", :sessions (35)}, 217 {:firstname "Giuseppe", :lastname "Giordano", :sessions (7)}, 46 {:firstname "Andrea", :lastname "Diana", :sessions (37)}, 508 {:firstname "Seungyeoun", :lastname "Lee", :sessions (68)}, 149 {:firstname "Edwin", :lastname "Diday", :sessions (5)}, 415 {:firstname "Nicola", :lastname "Pronello", :sessions (28 66)}, 239 {:firstname "Iain", :lastname "Smith", :sessions (22)}, 478 {:firstname "Roberta", :lastname "Siciliano", :sessions (54)}, 157 {:firstname "Eri", :lastname "Hoshino", :sessions (19)}, 345 {:firstname "M.", :lastname "Rui Alves", :sessions (39)}, 300 {:firstname "João", :lastname "Lagarto", :sessions (72)}, 4 {:firstname "Adalbert", :lastname "Wilhelm", :sessions (31)}, 550 {:firstname "Toshiki", :lastname "Sakai", :sessions (60)}, 204 {:firstname "Genevera", :lastname "I. Allen", :sessions (62)}, 470 {:firstname "Raquel", :lastname "Menezes", :sessions (83)}, 77 {:firstname "Barbara", :lastname "Batóg", :sessions (40)}, 106 {:firstname "Chin", :lastname "Pang Ho", :sessions (59)}, 197 {:firstname "Fumio", :lastname "Ishioka", :sessions (60)}, 405 {:firstname "Mitsuyoshi", :lastname "Suzuki", :sessions (19)}, 518 {:firstname "Sonja", :lastname "Greven", :sessions (16)}, 232 {:firstname "Hui", :lastname "Yang", :sessions (64 64)}, 260 {:firstname "Jan", :lastname "Kalina", :sessions (58)}, 267 {:firstname "Jayoeng", :lastname "Paek", :sessions (68)}, 119 {:firstname "Claudia", :lastname "Pisanu", :sessions (31)}, 319 {:firstname "Kyeongah", :lastname "Nah", :sessions (68)}, 534 {:firstname "Tadashi", :lastname "Imanishi", :sessions (60)}, 222 {:firstname "H.", :lastname "Bacelar-Nicolau", :sessions (64)}, 293 {:firstname "José", :lastname "Matos", :sessions (29)}, 95 {:firstname "Cajo", :lastname "J. F. ter Braak", :sessions (8)}, 450 {:firstname "Pedro", :lastname "Filipe Rocha", :sessions (80)}, 329 {:firstname "Lina", :lastname "Oliveira", :sessions (36)}, 144 {:firstname "Düzgün", :lastname "Yıldırım", :sessions (14)}, 504 {:firstname "Scott", :lastname "Sisson", :sessions (52)}, 505 {:firstname "Sebastian", :lastname "Ratzenböck", :sessions (10)}, 176 {:firstname "Fatma", :lastname "Sevinç Kurnaz", :sessions (21)}, 471 {:firstname "Rasool", :lastname "Taban", :sessions (21)}, 349 {:firstname "Manuela", :lastname "Schmidt", :sessions (35)}, 512 {:firstname "Silvia", :lastname "Novo", :sessions (53)}, 192 {:firstname "Francesco", :lastname "Palumbo", :sessions (67 41)}, 54 {:firstname "Angeline", :lastname "Plaud", :sessions (72)}, 92 {:firstname "Brendan", :lastname "McCabe", :sessions (29)}, 221 {:firstname "Guyslain", :lastname "Naves", :sessions (57)}, 141 {:firstname "Douglas", :lastname "C. Montgomery", :sessions (45 13)}, 502 {:firstname "Sara", :lastname "Taskinen", :sessions (55)}, 464 {:firstname "Rafal", :lastname "Kulakowski", :sessions (82)}, 307 {:firstname "Jun", :lastname "Tsuchida", :sessions (13 60)}, 290 {:firstname "Joshua", :lastname "Tobin", :sessions (59)}, 517 {:firstname "Sonia", :lastname "Migliorati", :sessions (33)}, 361 {:firstname "Maria", :lastname "Do Rosario Oliveira", :sessions (21)}, 264 {:firstname "Jasone", :lastname "Ramírez-Ayerbe", :sessions (38)}, 137 {:firstname "Diogo", :lastname "Pinheiro", :sessions (36)}, 356 {:firstname "Marcin", :lastname "Pelka", :sessions (52)}, 327 {:firstname "Leonor", :lastname "Rego", :sessions (20 13)}, 234 {:firstname "Hung", :lastname "Tong", :sessions (22)}, 104 {:firstname "Charles", :lastname "C. Taylor", :sessions (17)}, 353 {:firstname "Marcella", :lastname "Niglio", :sessions (14)}, 15 {:firstname "Aleksandr", :lastname "Koshkarov", :sessions (32)}, 48 {:firstname "Andreas", :lastname "Artemiou", :sessions (17)}, 242 {:firstname "Immanuel", :lastname "M. Bomze", :sessions (10 80)}, 50 {:firstname "Andrzej", :lastname "Dudek", :sessions (36)}, 557 {:firstname "Uwe", :lastname "Siebert", :sessions (31)}, 251 {:firstname "J.", :lastname "Diatta", :sessions (57)}, 394 {:firstname "Michel", :lastname "van de Velden", :sessions (50 39)}, 116 {:firstname "Claudia", :lastname "Czado", :sessions (26)}, 585 {:firstname "Yunfei", :lastname "Long", :sessions (64 64)}, 583 {:firstname "You-Jin", :lastname "Park", :sessions (45 13)}, 75 {:firstname "B.", :lastname "Mirkin et al.", :sessions (69)}, 437 {:firstname "Patrik", :lastname "Janácek ˇ", :sessions (58)}, 516 {:firstname "Sofia", :lastname "Magopoulou", :sessions (44)}, 159 {:firstname "Eric", :lastname "J. Beh", :sessions (55)}, 99 {:firstname "Casper", :lastname "Albers", :sessions (79)}, 540 {:firstname "Theresa", :lastname "Scharl", :sessions (82 71)}, 479 {:firstname "Roberto", :lastname "Ascari", :sessions (33)}, 281 {:firstname "Johane", :lastname "Nienkemper-Swanepoel", :sessions (50)}, 402 {:firstname "Mimi", :lastname "Zhang", :sessions (59)}, 429 {:firstname "Ozge", :lastname "Sahin", :sessions (26)}, 309 {:firstname "K.", :lastname "Hron", :sessions (42)}, 458 {:firstname "Piercesare", :lastname "Secchi", :sessions (16 33)}, 21 {:firstname "Alex", :lastname "Cucco", :sessions (66)}, 388 {:firstname "Metodi", :lastname "Metodiev", :sessions (30)}, 495 {:firstname "Salvatore", :lastname "Ingrassia", :sessions (20)}, 31 {:firstname "Amirah", :lastname "S. Alharthi", :sessions (17)}, 113 {:firstname "Cinzia", :lastname "Di Nuzzo", :sessions (20)}, 32 {:firstname "Amovin-Assagba", :lastname "Martial", :sessions (21)}, 407 {:firstname "Mohamed", :lastname "Hanafi", :sessions (12)}, 398 {:firstname "Michelle", :lastname "Carey", :sessions (65)}, 136 {:firstname "Diogo", :lastname "Alves", :sessions (29)}, 139 {:firstname "Dominique", :lastname "Desbois", :sessions (36)}, 506 {:firstname "Seunghwan", :lastname "Park", :sessions (9)}, 396 {:firstname "Michele", :lastname "La Rocca", :sessions (14)}, 460 {:firstname "Prosper", :lastname "Ablordeppey", :sessions (76)}, 483 {:firstname "Rosangela", :lastname "Ballini", :sessions (81)}, 589 {:firstname "Zoe-Mae", :lastname "Adams", :sessions (50)}, 581 {:firstname "Yoshikazu", :lastname "Yamamoto", :sessions (50)}, 174 {:firstname "Fabien", :lastname "Llobell", :sessions (12)}, 578 {:firstname "Ye-eun", :lastname "Kim", :sessions (9)}, 331 {:firstname "Lisete", :lastname "Sousa", :sessions (61)}, 363 {:firstname "Maria", :lastname "Margarida Lima", :sessions (80)}, 284 {:firstname "Joni", :lastname "Virta", :sessions (14)}, 208 {:firstname "Gersende", :lastname "Fort", :sessions (59)}, 305 {:firstname "Julian", :lastname "Rossbroich", :sessions (26)}, 182 {:firstname "Fernando", :lastname "Silva", :sessions (29)}, 256 {:firstname "Jacques", :lastname "Julien `", :sessions (21)}, 514 {:firstname "Simona", :lastname "Korenjak-Černe", :sessions (5)}, 485 {:firstname "Rosaria", :lastname "Lombardo", :sessions (2 55)}, 214 {:firstname "Giovanni", :lastname "Saraceno", :sessions (11)}, 193 {:firstname "Francisca", :lastname "G. Vieira", :sessions (83)}, 442 {:firstname "Paulo", :lastname "Quaresma", :sessions (13)}, 561 {:firstname "Valeria", :lastname "Vitelli", :sessions (53)}, 241 {:firstname "Ilsu", :lastname "Choi", :sessions (68)}, 314 {:firstname "Klaas", :lastname "Sijtsma", :sessions (27)}, 226 {:firstname "Henk", :lastname "A.L. Kiers", :sessions (35)}, 235 {:firstname "Hyunjoong", :lastname "Kim", :sessions (9)}, 420 {:firstname "Nosheen", :lastname "Faiz", :sessions (30)}, 418 {:firstname "Nihan", :lastname "Acar-Denizli", :sessions (77)}, 262 {:firstname "Jangsun", :lastname "Baek", :sessions (19)}, 263 {:firstname "Jasminka", :lastname "Dobsa", :sessions (35)}, 304 {:firstname "Julia", :lastname "Wrobel", :sessions (77)}, 401 {:firstname "Mikhael", :lastname "Carmona", :sessions (57)}, 40 {:firstname "Ana", :lastname "Moreno", :sessions (83)}, 129 {:firstname "Daniela", :lastname "Silva", :sessions (83)}, 467 {:firstname "Rafika", :lastname "Boutalbi", :sessions (34)}, 445 {:firstname "Paweł", :lastname "Lula", :sessions (66)}, 317 {:firstname "Kotomi", :lastname "Sakai", :sessions (19)}, 294 {:firstname "José", :lastname "Pedro Lopes", :sessions (83)}, 91 {:firstname "Boris", :lastname "Beranger", :sessions (52)}, 364 {:firstname "Maria", :lastname "Prosperina Vitale", :sessions (7)}, 515 {:firstname "Simone", :lastname "Vantini", :sessions (65)}, 412 {:firstname "Nail", :lastname "Chabane", :sessions (64)}, 553 {:firstname "Una", :lastname "Radojicic", :sessions (14)}, 341 {:firstname "Luis", :lastname "Paulo Reis", :sessions (31)}, 117 {:firstname "Claudia", :lastname "Kirch", :sessions (65)}, 523 {:firstname "Stefan", :lastname "Meingast", :sessions (10)}, 172 {:firstname "Fabian", :lastname "Fumagalli", :sessions (54)}, 108 {:firstname "Christian", :lastname "Hennig", :sessions (70)}, 156 {:firstname "Engelbert", :lastname "Mephu Nguifo", :sessions (72)}, 358 {:firstname "Marco", :lastname "Riani", :sessions (70 22)}, 308 {:firstname "Junji", :lastname "Nakano", :sessions (50)}, 531 {:firstname "Surajit", :lastname "Ray", :sessions (28)}, 223 {:firstname "Hae-Hwan", :lastname "Lee", :sessions (9)}, 419 {:firstname "Nobuo", :lastname "Shimizu", :sessions (50)}, 365 {:firstname "Marialuisa", :lastname "Restaino", :sessions (14)}, 181 {:firstname "Fernanda", :lastname "Figueiredo", :sessions (44 40)}, 417 {:firstname "Niels", :lastname "Lundtorp Olsen", :sessions (65)}, 278 {:firstname "Joachim", :lastname "Engel", :sessions (31)}, 56 {:firstname "Aniek", :lastname "Sies", :sessions (30)}, 33 {:firstname "Amy", :lastname "LaLonde", :sessions (71)}, 13 {:firstname "Alba", :lastname "M. Franco-Pereira", :sessions (28)}, 22 {:firstname "Alex", :lastname "Partner", :sessions (67 30)}, 380 {:firstname "Matteo", :lastname "Pegoraro", :sessions (16)}, 257 {:firstname "Jael", :lastname "Champagne Gareau", :sessions (56)}, 338 {:firstname "Luis", :lastname "A. García-Escudero", :sessions (70 70 22)}, 500 {:firstname "Sara", :lastname "Cabral", :sessions (64)}, 168 {:firstname "Eva", :lastname "Ceulemans", :sessions (78)}, 496 {:firstname "Sandra", :lastname "Silva", :sessions (29)}, 347 {:firstname "Magdalena", :lastname "Talaga", :sessions (66)}, 501 {:firstname "Sara", :lastname "Fontanella", :sessions (28 66)}, 90 {:firstname "Bogdan", :lastname "Mazoure", :sessions (64)}, 237 {:firstname "Hélder", :lastname "Sousa", :sessions (84)}, 292 {:firstname "José", :lastname "Campos e Matos", :sessions (84 84)}, 109 {:firstname "Christian", :lastname "Riccio", :sessions (54)}, 216 {:firstname "Giuliano", :lastname "Galimberti", :sessions (74)}, 191 {:firstname "Francesco", :lastname "Denti", :sessions (6)}, 498 {:firstname "Sangwook", :lastname "Kang", :sessions (68)}, 375 {:firstname "Marzia", :lastname "A. Cremona", :sessions (37)}, 525 {:firstname "Stella", :lastname "Hadjiantoni", :sessions (64 64)}, 367 {:firstname "Marilia", :lastname "Antunes", :sessions (61)}, 143 {:firstname "Duarte", :lastname "Rodrigues", :sessions (31)}, 178 {:firstname "Fei", :lastname "Liu", :sessions (5)}, 247 {:firstname "Iva", :lastname "Karafiatova", :sessions (84)}, 328 {:firstname "Liming", :lastname "Liang", :sessions (49)}, 391 {:firstname "Michael", :lastname "P.B. Gallaugher", :sessions (43 43)}, 167 {:firstname "Eun-Kyung", :lastname "Lee", :sessions (49)}, 36 {:firstname "Ana", :lastname "Helena Tavares", :sessions (61)}, 41 {:firstname "Ana", :lastname "Teles-Machado", :sessions (83)}, 474 {:firstname "Regina", :lastname "Bispo", :sessions (83)}, 187 {:firstname "Francesca", :lastname "Di Salvo", :sessions (16)}, 551 {:firstname "Tra", :lastname "Le", :sessions (27)}, 528 {:firstname "Sugnet", :lastname "Lubbe", :sessions (50)}, 376 {:firstname "Masayuki", :lastname "Obatake", :sessions (19)}, 195 {:firstname "Friedrich", :lastname "Leisch", :sessions (82)}, 316 {:firstname "Koji", :lastname "Kurihara", :sessions (60)}, 428 {:firstname "Ozan", :lastname "Kocadağlı", :sessions (14 23)}, 303 {:firstname "Juan", :lastname "C. Vera", :sessions (27)}, 368 {:firstname "Markus", :lastname "Pauly", :sessions (31)}, 560 {:firstname "Valentin", :lastname "Todorov", :sessions (11)}, 565 {:firstname "Veronique", :lastname "Cariou", :sessions (12)}, 310 {:firstname "Katerina", :lastname "M. Marcoulides", :sessions (79)}, 366 {:firstname "Marieke", :lastname "Timmerman", :sessions (79)}, 118 {:firstname "Claudia", :lastname "Nunes Philippart", :sessions (21)}, 522 {:firstname "Stanislav", :lastname "Nagy", :sessions (58 58)}, 150 {:firstname "Eleonora", :lastname "Arnone", :sessions (53)}, 313 {:firstname "Katrĳn", :lastname "Van Deun", :sessions (27)}, 384 {:firstname "Maurizio", :lastname "Vichi", :sessions (76)}, 567 {:firstname "Victor", :lastname "Chepoi", :sessions (57)}, 238 {:firstname "I.", :lastname "Wilms", :sessions (42)}, 196 {:firstname "Fulvia", :lastname "Pennoni", :sessions (79)}, 162 {:firstname "Erin", :lastname "I. McDonnell", :sessions (77)}, 393 {:firstname "Michal", :lastname "Swachta", :sessions (52)}, 184 {:firstname "Filippo", :lastname "Antonazzo", :sessions (59)}, 219 {:firstname "Gonçalo", :lastname "Jacinto", :sessions (20 13)}, 461 {:firstname "Quirin", :lastname "Stier", :sessions (78 26)}, 89 {:firstname "Bo", :lastname "Peng", :sessions (80)}, 100 {:firstname "Caterina", :lastname "Gregorio", :sessions (77)}, 426 {:firstname "Osvaldo", :lastname "Silva", :sessions (64 10)}, 477 {:firstname "Riccardo", :lastname "Scimone", :sessions (33)}, 541 {:firstname "Thomas", :lastname "Whitaker", :sessions (52)}, 351 {:firstname "Marc", :lastname "Ditzhaus", :sessions (18)}, 243 {:firstname "Inyoung", :lastname "Kim", :sessions (68)}, 131 {:firstname "David", :lastname "P. Hofmeyr", :sessions (83)}, 122 {:firstname "Claudio", :lastname "Conversano", :sessions (35)}, 43 {:firstname "Anabela", :lastname "Rocha", :sessions (67)}, 231 {:firstname "Ho", :lastname "Kim", :sessions (49)}, 61 {:firstname "Annabella", :lastname "Astorino", :sessions (38 56)}, 413 {:firstname "Ndèye", :lastname "Niang", :sessions (57)}, 29 {:firstname "Almond", :lastname "Stöcker", :sessions (16)}, 151 {:firstname "Elia", :lastname "Cunial", :sessions (53)}, 369 {:firstname "Markus", :lastname "Zwick", :sessions (31)}, 348 {:firstname "Malgorzata", :lastname "Markowska", :sessions (18)}, 575 {:firstname "Wangshu", :lastname "Tu", :sessions (71)}, 44 {:firstname "Andrea", :lastname "Cappozzo", :sessions (34 6)}, 258 {:firstname "Jaesung", :lastname "Hwang", :sessions (19)}, 250 {:firstname "J.", :lastname "Claramunt Gonzales", :sessions (30)}, 539 {:firstname "Theodore", :lastname "Chadjipadelis", :sessions (44)}, 301 {:firstname "João", :lastname "Paulo Rodrigues", :sessions (83)}, 424 {:firstname "Olivier", :lastname "Cappé", :sessions (59)}, 93 {:firstname "Brígida", :lastname "Mónica Faria ´", :sessions (31)}, 6 {:firstname "Adelaide", :lastname "Freitas", :sessions (76 67)}, 573 {:firstname "Volodymyr", :lastname "Melnykov", :sessions (74)}, 408 {:firstname "Mohamed", :lastname "Nadif", :sessions (32 66 34)}, 563 {:firstname "Vera", :lastname "Afreixo", :sessions (61)}, 111 {:firstname "Christophe", :lastname "Biernacki", :sessions (59)}, 28 {:firstname "Alicia", :lastname "Nieto-Reyes", :sessions (65)}, 456 {:firstname "Petra", :lastname "Laketa", :sessions (58)}, 374 {:firstname "Maryam", :lastname "Al Alawi", :sessions (28)}, 548 {:firstname "Tonio", :lastname "Di Battista", :sessions (37)}, 538 {:firstname "Tanzy", :lastname "Love", :sessions (71)}, 411 {:firstname "Nadia", :lastname "Tahiri", :sessions (32 64)}, 134 {:firstname "Delia", :lastname "Francesca Chillura Martino", :sessions (16)}, 64 {:firstname "Antonio", :lastname "Elías", :sessions (28 65)}, 465 {:firstname "Raffaella", :lastname "Calabrese", :sessions (10)}, 334 {:firstname "Luca", :lastname "Greco", :sessions (11)}, 323 {:firstname "Laura", :lastname "M. Sangalli", :sessions (65 33 53)}, 189 {:firstname "Francesca", :lastname "Ieva", :sessions (77 41)}, 280 {:firstname "Joerg", :lastname "Blasius", :sessions (44)}, 198 {:firstname "Gabriel", :lastname "Martos", :sessions (24)}, 155 {:firstname "Emilio", :lastname "Carrizosa", :sessions (38)}, 295 {:firstname "José", :lastname "Saias", :sessions (13)}, 248 {:firstname "Iven", :lastname "Van Mechelen", :sessions (30)}, 587 {:firstname "Zdenek", :lastname "Sulc", :sessions (26)}, 285 {:firstname "Jorge", :lastname "Arce Garro", :sessions (15)}, 507 {:firstname "Seungyeon", :lastname "Lee", :sessions (68)}, 227 {:firstname "Henrique", :lastname "Siqueira", :sessions (45)}, 476 {:firstname "Riccardo", :lastname "Ievoli", :sessions (72)}, 494 {:firstname "Salvatore", :lastname "D. Tomarchio", :sessions (43)}, 220 {:firstname "Guojun", :lastname "Gan", :sessions (65)}, 103 {:firstname "Charles", :lastname "Bouveyron", :sessions (48)}, 170 {:firstname "Eyke", :lastname "Hüllermeier", :sessions (54 54)}, 51 {:firstname "Andrzej", :lastname "Sokolowski", :sessions (18)}, 25 {:firstname "Alfonso", :lastname "Iodice D’Enza", :sessions (50 39)}, 261 {:firstname "Jan", :lastname "Michael Spoor", :sessions (69)}, 201 {:firstname "Gabriele", :lastname "Soffritti", :sessions (34)}, 590 {:firstname "and\r\nJ.", :lastname "Palarea-Albaladejo", :sessions (42)}, 489 {:firstname "Rui", :lastname "Santos", :sessions (78)}, 166 {:firstname "Eugenio", :lastname "Vocaturo", :sessions (56)}, 447 {:firstname "Pedro", :lastname "Campos", :sessions (81 66)}, 34 {:firstname "Ana", :lastname "Alexandra Martins", :sessions (72)}, 252 {:firstname "J.", :lastname "E. Yukich", :sessions (28)}, 325 {:firstname "Laura", :lastname "Vicente-Gonzalez", :sessions (55)}, 436 {:firstname "Patrick", :lastname "Groenen", :sessions (39)}, 535 {:firstname "Taerim", :lastname "Lee", :sessions (31 49)}, 146 {:firstname "Edoardo", :lastname "Redivo", :sessions (17)}, 228 {:firstname "Heungsun", :lastname "Hwang", :sessions (68)}, 306 {:firstname "Jun", :lastname "Li", :sessions (49)}, 125 {:firstname "Cristina", :lastname "Oliveira", :sessions (80)}, 276 {:firstname "Jivka", :lastname "Ovtcharova", :sessions (69)}, 340 {:firstname "Luis", :lastname "Angel García Escudero", :sessions (34)}, 148 {:firstname "Edward", :lastname "A. Baron", :sessions (84)}, 482 {:firstname "Rosalina", :lastname "Pisco Costa", :sessions (13)}, 588 {:firstname "Zh.", :lastname "Hayrapetyan", :sessions (69)}, 17 {:firstname "Alessandro", :lastname "Bitetto", :sessions (29)}, 312 {:firstname "Katrijn", :lastname "Van Deun", :sessions (27 78)}, 3 {:firstname "Adalbert", :lastname "F.X. Wilhelm", :sessions (41)}, 520 {:firstname "Sophie", :lastname "Dominique", :sessions (12)}, 286 {:firstname "Jorge", :lastname "Mateu", :sessions (37)}, 279 {:firstname "Joao", :lastname "Paulo Martins", :sessions (78)}, 536 {:firstname "Taesung", :lastname "Park", :sessions (68 49 68)}, 12 {:firstname "Agustín", :lastname "Mayo-Iscar", :sessions (34 70 70 22)}, 440 {:firstname "Paul", :lastname "Hofmarcher", :sessions (35)}, 332 {:firstname "Louis", :lastname "Tran", :sessions (22)}, 330 {:firstname "Lisa", :lastname "Steyer", :sessions (16)}, 382 {:firstname "Matthieu", :lastname "Resche-Rigon", :sessions (57)}, 152 {:firstname "Elif", :lastname "Göksu Öztürk", :sessions (80)}, 544 {:firstname "Tom", :lastname "F. Wilderjans", :sessions (26)}, 435 {:firstname "Pascal", :lastname "Préa", :sessions (57)}, 342 {:firstname "Lynne", :lastname "Billard", :sessions (5)}, 2 {:firstname "A.", :lastname "Irpino", :sessions (5)}, 66 {:firstname "Antonio", :lastname "Irpino", :sessions (52 52)}, 484 {:firstname "Rosaria", :lastname "Ignaccolo", :sessions (28)}, 439 {:firstname "Paul", :lastname "D. McNicholas", :sessions (43 43)}, 236 {:firstname "Hyunsuk", :lastname "Kim", :sessions (68)}, 556 {:firstname "Utkarsh", :lastname "J. Dang", :sessions (43)}, 373 {:firstname "Marta", :lastname "Nai Ruscone", :sessions (27)}, 142 {:firstname "Dr.", :lastname "Katrijn Van Deun", :sessions (27)}, 359 {:firstname "Margarida", :lastname "G. M. S. Cardoso", :sessions (72)}, 371 {:firstname "Marta", :lastname "Belchior Lopes", :sessions (61)}, 444 {:firstname "Pawel", :lastname "Piasecki", :sessions (24)}, 570 {:firstname "Vitor", :lastname "Nogueira", :sessions (13)}, 107 {:firstname "Chris", :lastname "Saker", :sessions (67 30)}, 532 {:firstname "Susana", :lastname "Garrido", :sessions (83)}, 23 {:firstname "Alexandre", :lastname "Penha", :sessions (83)}, 230 {:firstname "Hiroshi", :lastname "Yadohisa", :sessions (13)}, 47 {:firstname "Andrea", :lastname "Papola", :sessions (54)}, 526 {:firstname "Stephan", :lastname "van der Westhuizen", :sessions (83)}, 180 {:firstname "Feng", :lastname "Ji", :sessions (79)}, 537 {:firstname "Takehiro", :lastname "Shoji", :sessions (13)}, 158 {:firstname "Eric", :lastname "Beaudry", :sessions (56)}, 350 {:firstname "Marc", :lastname "Comas-Cufí", :sessions (42)}, 35 {:firstname "Ana", :lastname "Catarina Nunes", :sessions (80)}, 127 {:firstname "Daniel", :lastname "Pena", :sessions (25)}, 383 {:firstname "Maurizio", :lastname "Romano", :sessions (35)}, 533 {:firstname "Susana", :lastname "Vinga", :sessions (61)}, 302 {:firstname "Ju-young", :lastname "Park", :sessions (68)}, 564 {:firstname "Veronica", :lastname "Piccialli", :sessions (38)}, 566 {:firstname "Veronne", :lastname "Yepmo", :sessions (72)}, 82 {:firstname "Belen", :lastname "Pulido", :sessions (28)}, 76 {:firstname "B.J.", :lastname "Os", :sessions (30)}, 492 {:firstname "Ryan", :lastname "P. Browne", :sessions (43)}, 215 {:firstname "Giulia", :lastname "Barbati", :sessions (77)}, 97 {:firstname "Carlos", :lastname "Matrán Bea", :sessions (70)}, 277 {:firstname "Joachim", :lastname "Behnke", :sessions (31)}, 19 {:firstname "Alessio", :lastname "Farcomeni", :sessions (17)}, 335 {:firstname "Lucio", :lastname "Barabesi", :sessions (11)}, 57 {:firstname "Anja", :lastname "Ernst", :sessions (79)}, 202 {:firstname "Gabriella", :lastname "Chirco", :sessions (16)}, 68 {:firstname "Antonio", :lastname "Punzo", :sessions (12)}, 452 {:firstname "Pedro", :lastname "Ribeiro", :sessions (29)}, 200 {:firstname "Gabriele", :lastname "Perrone", :sessions (34)}, 11 {:firstname "Agustìn", :lastname "Mayo-Iscar", :sessions (11)}, 115 {:firstname "Clara", :lastname "Yokochi", :sessions (83)}, 339 {:firstname "Luis", :lastname "Angel Garcìa-Escudero", :sessions (11)}, 431 {:firstname "P.", :lastname "Filzmoser", :sessions (42)}, 462 {:firstname "R.", :lastname "Verde", :sessions (65 5)}, 337 {:firstname "Luigi", :lastname "Ippoliti", :sessions (28)}, 255 {:firstname "Jacek", :lastname "Batóg", :sessions (40)}, 503 {:firstname "Sarah", :lastname "Friedrich", :sessions (31)}, 546 {:firstname "Tomáš", :lastname "Kliegr", :sessions (75)}, 9 {:firstname "Aeyeon", :lastname "Lee", :sessions (49)}, 457 {:firstname "Philippe", :lastname "Vieu", :sessions (53)}, 427 {:firstname "Ozan", :lastname "Kocadagli", :sessions (82)}, 145 {:firstname "E.", :lastname "Dusseldorp", :sessions (30)}, 5 {:firstname "Adelaide", :lastname "Figueiredo", :sessions (44 40)}, 244 {:firstname "Inês", :lastname "Oliveira e Silva", :sessions (45)}, 289 {:firstname "Josep", :lastname "A. Martín-Fernández", :sessions (42)}, 112 {:firstname "Chun-Yang", :lastname "Peng", :sessions (45 13)}, 414 {:firstname "Neslihan", :lastname "Gökmen İnan", :sessions (14 23)}, 179 {:firstname "Felix", :lastname "Gnettner", :sessions (65)}, 344 {:firstname "M.", :lastname "Rosário Oliveira", :sessions (36)}, 481 {:firstname "Rosa", :lastname "E. Lillo", :sessions (28)}, 245 {:firstname "Isabel", :lastname "Pereira", :sessions (29)}, 378 {:firstname "Matteo", :lastname "Farnè", :sessions (74)}, 266 {:firstname "Javier", :lastname "Trejos", :sessions (20)}, 324 {:firstname "Laura", :lastname "Trinchera", :sessions (79)}, 446 {:firstname "Pedro", :lastname "Bastardo", :sessions (45)}, 524 {:firstname "Stefano", :lastname "A. Gattone", :sessions (37)}, 254 {:firstname "J.J.", :lastname "Meulman", :sessions (30)}, 404 {:firstname "Minh", :lastname "Quang Tran", :sessions (84)}, 283 {:firstname "Jongho", :lastname "Im", :sessions (9)}, 513 {:firstname "Silvia", :lastname "Pandolfi", :sessions (79)}, 572 {:firstname "Vladimir", :lastname "Makarenkov", :sessions (56 64)}, 83 {:firstname "Bernd", :lastname "Bischl", :sessions (75)}, 138 {:firstname "Dolores", :lastname "Romero Morales", :sessions (38)}, 346 {:firstname "Maciej", :lastname "Luczak", :sessions (24)}, 14 {:firstname "Albert", :lastname "Meco", :sessions (52)}, 455 {:firstname "Peter", :lastname "Filzmoser", :sessions (21 11)}, 265 {:firstname "Javier", :lastname "Arroyo", :sessions (52)}, 449 {:firstname "Pedro", :lastname "Espadinha-Cruz", :sessions (83)}, 333 {:firstname "Luca", :lastname "Bagnato", :sessions (12)}, 569 {:firstname "Vincenzo", :lastname "Giuseppe Genova", :sessions (7)}, 326 {:firstname "Lazhar", :lastname "Labiod", :sessions (32 66 34)}, 45 {:firstname "Andrea", :lastname "Cerioli", :sessions (11)}, 53 {:firstname "Angela", :lastname "Montanari", :sessions (74 51)}, 559 {:firstname "Vadim", :lastname "Zipunnikov", :sessions (77)}, 78 {:firstname "Barbara", :lastname "Hammer", :sessions (54)}, 562 {:firstname "Vanessa", :lastname "Freitas Silva", :sessions (29)}, 542 {:firstname "Tim", :lastname "Friede", :sessions (31)}, 315 {:firstname "Klaus", :lastname "Nordhausen", :sessions (14)}, 480 {:firstname "Rong", :lastname "Pan", :sessions (45 13)}, 132 {:firstname "David", :lastname "Rodríguez Vítores", :sessions (70)}, 26 {:firstname "Ali", :lastname "Mertcan Kose", :sessions (82)}, 123 {:firstname "Cristina", :lastname "Anton", :sessions (22)}, 203 {:firstname "Gannaz", :lastname "Irene", :sessions (21)}, 392 {:firstname "Michael", :lastname "Rapp", :sessions (54)}, 577 {:firstname "Yang", :lastname "Wang", :sessions (74)}, 140 {:firstname "Dongha", :lastname "Kim", :sessions (19)}, 321 {:firstname "Lara", :lastname "Fontanella", :sessions (66)}, 441 {:firstname "Paulo", :lastname "Infante", :sessions (20 13)}, 268 {:firstname "Jean-Marc", :lastname "Ferrandi", :sessions (12)}, 16 {:firstname "Alessandra", :lastname "Menafoglio", :sessions (33)}, 320 {:firstname "Lan", :lastname "Liang", :sessions (33)}, 133 {:firstname "Deborah", :lastname "Rohm Young", :sessions (71)}, 288 {:firstname "Josefa", :lastname "E. Großschedl", :sessions (10)}, 381 {:firstname "Matthias", :lastname "Medl", :sessions (82)}, 163 {:firstname "Esteban", :lastname "Segura", :sessions (20)}, 81 {:firstname "Beate", :lastname "Jahn", :sessions (31)}, 120 {:firstname "Claudia", :lastname "Silvestre", :sessions (12)}, 79 {:firstname "Barbara", :lastname "Japelj Pavešić", :sessions (5)}, 211 {:firstname "Gianpaolo", :lastname "Zammarchi", :sessions (35)}, 38 {:firstname "Ana", :lastname "Margarida Bento", :sessions (84 84)}, 173 {:firstname "Fabian", :lastname "Scheipl", :sessions (6)}, 126 {:firstname "Cristina", :lastname "Tortora", :sessions (22 41)}, 421 {:firstname "Nádia", :lastname "Bachir", :sessions (83)}, 593 {:firstname "Łukasz", :lastname "Smaga", :sessions (18)}, 98 {:firstname "Carlos", :lastname "Soares", :sessions (45)}, 422 {:firstname "Olaf", :lastname "Wolkenhauer", :sessions (31)}, 423 {:firstname "Oldemar", :lastname "Rodríguez Rojas", :sessions (15 15)}, 582 {:firstname "Yoshiro", :lastname "Yamamoto", :sessions (60)}, 554 {:firstname "Ursula", :lastname "Garczarek", :sessions (31)}, 409 {:firstname "Moritz", :lastname "Herrmann", :sessions (6)}, 574 {:firstname "W.H.", :lastname "Moolman", :sessions (67)}, 124 {:firstname "Cristina", :lastname "Lopes", :sessions (80)}, 171 {:firstname "F.", :lastname "Maturo", :sessions (65)}, 87 {:firstname "Bettina", :lastname "Grun", :sessions (71)}, 169 {:firstname "Ewa", :lastname "Genge", :sessions (23)}, 160 {:firstname "Erich", :lastname "Beh", :sessions (2)}, 30 {:firstname "Alya", :lastname "Alzahrani", :sessions (17)}, 400 {:firstname "Miguel", :lastname "de Carvalho", :sessions (10 24)}, 509 {:firstname "Shoji", :lastname "Kajinishi", :sessions (60)}, 207 {:firstname "Gero", :lastname "Szepannek", :sessions (41)}, 434 {:firstname "Paola", :lastname "Cerchiello", :sessions (29)}, 194 {:firstname "François", :lastname "Bavaud", :sessions (18)}, 511 {:firstname "Silvia", :lastname "D’Angelo", :sessions (74)}, 73 {:firstname "Aurea", :lastname "Sousa", :sessions (64 10)}, 486 {:firstname "Rosember", :lastname "Guerra-Urzola", :sessions (27)}, 336 {:firstname "Lucio", :lastname "Palazzo", :sessions (67 72)}, 96 {:firstname "Carlo", :lastname "Cavicchia", :sessions (50)}, 10 {:firstname "Afshin", :lastname "Ashofteh", :sessions (81)}, 272 {:firstname "Jennifer", :lastname "A. Schrack", :sessions (77)}, 499 {:firstname "Sanjeena", :lastname "Dang (Subedi)", :sessions (71)}, 488 {:firstname "Rui", :lastname "Calçada", :sessions (84)}, 386 {:firstname "Mayetri", :lastname "Gupta", :sessions (28)}, 270 {:firstname "Jeffrey", :lastname "Durieux", :sessions (26)}, 576 {:firstname "Wonil", :lastname "Chung", :sessions (49)}, 543 {:firstname "Tobia", :lastname "Boschi", :sessions (37)}, 271 {:firstname "Jenni", :lastname "Niku", :sessions (55)}, 18 {:firstname "Alessia", :lastname "Pini", :sessions (65)}, 395 {:firstname "Michelangelo", :lastname "Ceci", :sessions (7)}, 403 {:firstname "Min", :lastname "Soo Kim", :sessions (9)}, 469 {:firstname "Ralf", :lastname "Munnich", :sessions (31)}, 105 {:firstname "Chiara", :lastname "Masci", :sessions (41)}, 185 {:firstname "Florence", :lastname "Forbes", :sessions (59)}, 52 {:firstname "Angel", :lastname "López-Oriona", :sessions (72)}, 545 {:firstname "Tomasz", :lastname "Gorecki", :sessions (24)}, 114 {:firstname "Cinzia", :lastname "Viroli", :sessions (17)}, 253 {:firstname "J.", :lastname "Palarea-Albaladejo", :sessions (42)}, 209 {:firstname "Giancarlo", :lastname "Ragozini", :sessions (7)}, 147 {:firstname "Eduardo", :lastname "Andre Costa", :sessions (40)}, 425 {:firstname "Onay", :lastname "Urfalioglu", :sessions (45)}, 67 {:firstname "Antonio", :lastname "Pellicani", :sessions (7)}, 296 {:firstname "José", :lastname "Soeiro Ferreira", :sessions (80)}, 318 {:firstname "Kuniyoshi", :lastname "Hayashi", :sessions (19)}, 161 {:firstname "Erika", :lastname "Nakanishi", :sessions (19)}, 372 {:firstname "Marta", :lastname "Monaci", :sessions (80)}, 406 {:firstname "Mohamed", :lastname "Achraf Bouaoune", :sessions (64)}, 438 {:firstname "Patrícia", :lastname "Gois", :sessions (13)}, 71 {:firstname "Arlete", :lastname "Rodrigues", :sessions (45)}, 579 {:firstname "Yongdai", :lastname "Kim", :sessions (19)}, 42 {:firstname "Anabela", :lastname "Afonso", :sessions (20 13)}, 80 {:firstname "Barbara", :lastname "Pawelek", :sessions (81)}, 199 {:firstname "Gabriel", :lastname "Martos Venturini", :sessions (10)}, 591 {:firstname "Ángel", :lastname "López-Oriona", :sessions (25)}, 37 {:firstname "Ana", :lastname "Julieta Morais", :sessions (67)}, 183 {:firstname "Filipe", :lastname "J. Marques", :sessions (83)}, 432 {:firstname "Pablo", :lastname "Montero-Manso", :sessions (25)}, 379 {:firstname "Matteo", :lastname "Farné", :sessions (24)}, 63 {:firstname "Antonio", :lastname "D’Ambrosio", :sessions (27)}, 212 {:firstname "Gianvito", :lastname "Pio", :sessions (7)}, 94 {:firstname "Byungtae", :lastname "Seo", :sessions (68)}, 362 {:firstname "Maria", :lastname "Eduarda Silva", :sessions (40 29 29)}, 8 {:firstname "Adilson", :lastname "Xavier", :sessions (20)}, 246 {:firstname "Isabel", :lastname "Silva", :sessions (29)}, 190 {:firstname "Francesco", :lastname "Bartolucci", :sessions (23 79)}, 549 {:firstname "Torsten", :lastname "Möller", :sessions (10)}, 177 {:firstname "Federico", :lastname "D’Onofrio", :sessions (80)}, 49 {:firstname "Andrej", :lastname "Svetlošák", :sessions (10)}, 390 {:firstname "Michael", :lastname "Fop", :sessions (74)}, 84 {:firstname "Berthold", :lastname "Lausen", :sessions (64 82 67 30 30)}}}