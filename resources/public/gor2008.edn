{:timeslots {1 {:schedule "Wednesday, 10:00-10:45", :day "W", :time "A", :sessions (219)}, 2 {:schedule "Wednesday, 11:15-12:45", :day "W", :time "B", :sessions (85 81 134 57 110 211 31 156 67 129 103 20 24 183 46 205)}, 3 {:schedule "Wednesday, 13:45-14:30", :day "W", :time "C", :sessions (162 163 160 215)}, 4 {:schedule "Wednesday, 14:45-16:15", :day "W", :time "D", :sessions (86 82 22 54 210 120 52 34 127 107 101 175 178 181 199 206)}, 5 {:schedule "Wednesday, 16:30-18:00", :day "W", :time "E", :sessions (87 150 55 118 51 68 63 130 96 155 176 179 192 139 196)}, 6 {:schedule "Thursday, 8:30-10:30", :day "T", :time "A", :sessions (84 91 136 50 113 73 37 61 132 157 98 16 17 190 137 95)}, 7 {:schedule "Thursday, 11:00-12:30", :day "T", :time "B", :sessions (90 94 141 49 116 112 32 64 128 99 148 171 172 138 195 222)}, 8 {:schedule "Thursday, 13:30-14:15", :day "T", :time "C", :sessions (220)}, 9 {:schedule "Thursday, 14:30-16:00", :day "T", :time "D", :sessions (83 203 143 56 117 121 58 60 106 147 14 18 140 204 223)}, 10 {:schedule "Thursday, 16:15-17:00", :day "T", :time "E", :sessions (161 164 165 166)}, 11 {:schedule "Friday, 8:30-10:00", :day "F", :time "A", :sessions (89 92 149 59 119 72 77 71 104 146 19 23 182 78 45 225)}, 12 {:schedule "Friday, 10:30-11:15", :day "F", :time "B", :sessions (221)}, 13 {:schedule "Friday, 11:30-12:15", :day "F", :time "C", :sessions (167 224 168)}, 14 {:schedule "Friday, 13:15-14:45", :day "F", :time "D", :sessions (88 93 142 53 114 122 69 75 70 102 133 185 79 201)}}, :streams {1 {:name "Health Care and Environment", :order 7, :sessions (91 94 203 92 93)}, 2 {:name "Finance and Accounting", :order 5, :sessions (85 81 86 82 87 84 90 83 89 88)}, 3 {:name "Production and Service Management", :order 11, :sessions (134 22 150 136 141 148 143 147 149 146 142 133)}, 4 {:name "Scheduling and Project Management", :order 12, :sessions (57 54 55 50 49 56 59 53)}, 5 {:name "Supply Chain and Inventory Management", :order 14, :sessions (110 211 210 120 118 113 116 112 117 121 119 114 122)}, 6 {:name "Traffic and Transportation", :order 15, :sessions (31 156 67 52 34 51 68 63 73 37 61 32 64 58 60 72 77 71 69 75 70)}, 7 {:name "Applied Probability and Stochastic Programming", :order 1, :sessions (129 127 130 132 128)}, 8 {:name "Business Informatics, Decision Support and Artifical Intelligence", :order 3, :sessions (103 107 101 96 155 157 98 99 106 104 102)}, 9 {:name "Discrete and Combinatorial Optimization", :order 4, :sessions (20 24 175 178 176 179 16 17 171 172 14 18 19 23)}, 10 {:name "Forecasting, Econometrics and Game Theory", :order 6, :sessions (183 181 192 190 182 185)}, 11 {:name "Linear, Nonlinear and Vector Optimization", :order 8, :sessions (139 137 138 140 78 79)}, 12 {:name "Network Optimization", :order 9, :sessions (46 205 199 206 196 95 195 204 45 201)}, 14 {:name "Semiplenary Talks", :order 13, :sessions (162 163 160 215 161 164 165 166 167 168)}, 20 {:name "Plenary Talks", :order 10, :sessions (219 220 221)}, 21 {:name "Awards", :order 2, :sessions (222 223 225 224)}}, :sessions {14 {:name "Branch and Bound", :stream 9, :chairs (12453), :timeslot 9, :papers (33 52 252), :track 13}, 16 {:name "Metaheuristics 1", :stream 9, :chairs (17125), :timeslot 6, :papers (102 496 505 494), :track 13}, 17 {:name "Nonlinear Discrete Optimization 1", :stream 9, :chairs (16315), :timeslot 6, :papers (428 239 235 465), :track 14}, 18 {:name "Discrete Structures", :stream 9, :chairs (), :timeslot 9, :papers (6 86 163), :track 14}, 19 {:name "Optimization with Unreliable Data", :stream 9, :chairs (), :timeslot 11, :papers (121 399 498), :track 13}, 20 {:name "Mixed Integer Linear Optimization 1", :stream 9, :chairs (14973), :timeslot 2, :papers (262 317 71), :track 13}, 22 {:name "Lot-Sizing 1", :stream 3, :chairs (2801), :timeslot 4, :papers (58 411 406), :track 3}, 23 {:name "Combinatorial Algorithms", :stream 9, :chairs (10785), :timeslot 11, :papers (475 160 291), :track 14}, 24 {:name "Geometric Problems 1", :stream 9, :chairs (6404), :timeslot 2, :papers (141 296 571), :track 14}, 31 {:name "Dynamic Routing", :stream 6, :chairs (12952), :timeslot 2, :papers (570 222 577), :track 7}, 32 {:name "Maritime Transport and Logistics 2", :stream 6, :chairs (1462), :timeslot 7, :papers (136 190 590), :track 7}, 34 {:name "Rich Vehicle Routing", :stream 6, :chairs (17183), :timeslot 4, :papers (404 447 469), :track 8}, 37 {:name "Optimization in Postal Logistics", :stream 6, :chairs (42304), :timeslot 6, :papers (230 258 315 319), :track 8}, 45 {:name "Flow and Matching", :stream 12, :chairs (12969), :timeslot 11, :papers (53 178 355), :track 17}, 46 {:name "Railway Networks", :stream 12, :chairs (16315), :timeslot 2, :papers (561 241 551), :track 17}, 49 {:name "Planning and Scheduling in the Process Industries", :stream 4, :chairs (930), :timeslot 7, :papers (128 130 158), :track 4}, 50 {:name "Production Scheduling", :stream 4, :chairs (15150), :timeslot 6, :papers (21 453 425 368), :track 4}, 51 {:name "Uncertainty in Dynamic Routing", :stream 6, :chairs (17165), :timeslot 5, :papers (220 538 550), :track 7}, 52 {:name "Planning Approaches for Dynamic Routing", :stream 6, :chairs (15154), :timeslot 4, :papers (180 204 586), :track 7}, 53 {:name "Timetabling and Staff Scheduling", :stream 4, :chairs (14742), :timeslot 14, :papers (272 165 97), :track 4}, 54 {:name "Shop Floor Scheduling", :stream 4, :chairs (), :timeslot 4, :papers (74 189 372), :track 4}, 55 {:name "Project Scheduling 1", :stream 4, :chairs (125), :timeslot 5, :papers (357 182 305), :track 4}, 56 {:name "Project Scheduling 2", :stream 4, :chairs (5454), :timeslot 9, :papers (548 343 225), :track 4}, 57 {:name "Machine Scheduling and Assembly Line Balancing", :stream 4, :chairs (), :timeslot 2, :papers (3 306 152), :track 4}, 58 {:name "Container Terminal Operation", :stream 6, :chairs (14707), :timeslot 9, :papers (174 304 545), :track 7}, 59 {:name "Heuristics for Complex Scheduling Problems", :stream 4, :chairs (), :timeslot 11, :papers (524 280 191), :track 4}, 60 {:name "Autonomy of Transportation Planning Processes", :stream 6, :chairs (), :timeslot 9, :papers (381 382 420), :track 8}, 61 {:name "Collaborative Transportation Planning", :stream 6, :chairs (1109), :timeslot 6, :papers (265 430 431 326), :track 9}, 63 {:name "Public Transport", :stream 6, :chairs (14588), :timeslot 5, :papers (369 375 490), :track 9}, 64 {:name "Extended Optimization Problems in Transportation", :stream 6, :chairs (15277), :timeslot 7, :papers (148 193), :track 8}, 67 {:name "Air Transport", :stream 6, :chairs (1194), :timeslot 2, :papers (201 205 366), :track 9}, 68 {:name "Generalized Vehicle Routing", :stream 6, :chairs (5965), :timeslot 5, :papers (529 367), :track 8}, 69 {:name "Metaheuristics for Vehicle Routing", :stream 6, :chairs (14755), :timeslot 14, :papers (310 334 400), :track 7}, 70 {:name "Multi Depot Problems in Public Transport", :stream 6, :chairs (1194), :timeslot 14, :papers (452 213 214), :track 9}, 71 {:name "Railway Transport", :stream 6, :chairs (16315), :timeslot 11, :papers (242 515), :track 9}, 72 {:name "Transport of Waste and Dangerous Goods", :stream 6, :chairs (13837), :timeslot 11, :papers (397 172 364), :track 7}, 73 {:name "Maritime Transport and Logistics 1", :stream 6, :chairs (1462), :timeslot 6, :papers (628 301 417 584), :track 7}, 75 {:name "GIS-Based Planning", :stream 6, :chairs (16916), :timeslot 14, :papers (159 275), :track 8}, 77 {:name "Operational Transportation Planning", :stream 6, :chairs (6707), :timeslot 11, :papers (607 293), :track 8}, 78 {:name "Multicriteria Optimization", :stream 11, :chairs (17032), :timeslot 11, :papers (110 274 316), :track 16}, 79 {:name "Global Optimization", :stream 11, :chairs (17097), :timeslot 14, :papers (376 419 627), :track 16}, 81 {:name "Managerial Accounting 1", :stream 2, :chairs (13051), :timeslot 2, :papers (438 162), :track 2}, 82 {:name "Managerial Accounting 2", :stream 2, :chairs (16857), :timeslot 4, :papers (150 195 249), :track 2}, 83 {:name "Valuation", :stream 2, :chairs (14797), :timeslot 9, :papers (217 533 578), :track 1}, 84 {:name "Finance: Methods", :stream 2, :chairs (17220), :timeslot 6, :papers (47 243 303 602), :track 1}, 85 {:name "Investment", :stream 2, :chairs (13656), :timeslot 2, :papers (93 349), :track 1}, 86 {:name "Pricing", :stream 2, :chairs (10309), :timeslot 4, :papers (170 362 444), :track 1}, 87 {:name "Finance: Markets", :stream 2, :chairs (9578), :timeslot 5, :papers (553 472 554), :track 1}, 88 {:name "Financial Accounting", :stream 2, :chairs (17207), :timeslot 14, :papers (474 442 580), :track 1}, 89 {:name "Finance: Algorithms", :stream 2, :chairs (14626), :timeslot 11, :papers (427 478 501), :track 1}, 90 {:name "Finance: Ratings", :stream 2, :chairs (14810), :timeslot 7, :papers (118 308 186), :track 1}, 91 {:name "Planning Approaches for Health Care Systems", :stream 1, :chairs (3524), :timeslot 6, :papers (336 393 418), :track 2}, 92 {:name "Environmental Management ", :stream 1, :chairs (7848), :timeslot 11, :papers (332 155 594), :track 2}, 93 {:name "Reverse Logistics", :stream 1, :chairs (8713), :timeslot 14, :papers (276 359 138), :track 2}, 94 {:name "Incentives and Regulations", :stream 1, :chairs (2650), :timeslot 7, :papers (542 396 485), :track 2}, 95 {:name "Facility Location 3", :stream 12, :chairs (14847), :timeslot 6, :papers (261 267 288), :track 17}, 96 {:name "Data Mining 1", :stream 8, :chairs (14887), :timeslot 5, :papers (312 518 539), :track 11}, 98 {:name "Multicriteria Decision Aids", :stream 8, :chairs (1141), :timeslot 6, :papers (558 95 536), :track 12}, 99 {:name "Marketing and CRM", :stream 8, :chairs (17022), :timeslot 7, :papers (246 297 451), :track 11}, 101 {:name "Modeling Systems and Languages", :stream 8, :chairs (14755), :timeslot 4, :papers (115 157 342), :track 12}, 102 {:name "Development of DSS", :stream 8, :chairs (14853), :timeslot 14, :papers (77 537 20), :track 11}, 103 {:name "AI and Metaheuristics", :stream 8, :chairs (14707), :timeslot 2, :papers (208 482 492), :track 11}, 104 {:name "Games and Business Simulations", :stream 8, :chairs (), :timeslot 11, :papers (314 154 294), :track 11}, 106 {:name "Decision Theory and Risk Analysis", :stream 8, :chairs (454), :timeslot 9, :papers (534 514 111), :track 11}, 107 {:name "Business Intelligence", :stream 8, :chairs (17148), :timeslot 4, :papers (527 568 593), :track 11}, 110 {:name "Inventory Simulation", :stream 5, :chairs (14770), :timeslot 2, :papers (585 216 76), :track 5}, 112 {:name "Contracts", :stream 5, :chairs (17039), :timeslot 7, :papers (278 353 321), :track 6}, 113 {:name "Green SC", :stream 5, :chairs (16963), :timeslot 6, :papers (194 486 423), :track 5}, 114 {:name "Lotsizing", :stream 5, :chairs (10574), :timeslot 14, :papers (330 247 464), :track 5}, 116 {:name "SC Design", :stream 5, :chairs (3974), :timeslot 7, :papers (429 540 572), :track 5}, 117 {:name "Demand", :stream 5, :chairs (6751), :timeslot 9, :papers (450 552), :track 5}, 118 {:name "SC Planning  2", :stream 5, :chairs (14070), :timeslot 5, :papers (226 132 373), :track 5}, 119 {:name "Embedded SDP", :stream 5, :chairs (2651), :timeslot 11, :papers (488 519), :track 6}, 120 {:name "Sourcing 2", :stream 5, :chairs (), :timeslot 4, :papers (606 104), :track 6}, 121 {:name "Inventory", :stream 5, :chairs (2801), :timeslot 9, :papers (328 43 229), :track 6}, 122 {:name "Newsvendor", :stream 5, :chairs (14573), :timeslot 14, :papers (70 78 94), :track 6}, 127 {:name "Stochastic Programming 1", :stream 7, :chairs (), :timeslot 4, :papers (426 588 458), :track 10}, 128 {:name "Stochastic Programming 2", :stream 7, :chairs (12902), :timeslot 7, :papers (224 531 625), :track 10}, 129 {:name "Risk Analysis and Management", :stream 7, :chairs (10023), :timeslot 2, :papers (479 573 446), :track 10}, 130 {:name "Stochastic Models", :stream 7, :chairs (9512), :timeslot 5, :papers (546 253), :track 10}, 132 {:name "Queues", :stream 7, :chairs (17075), :timeslot 6, :papers (506 88 119 379), :track 10}, 133 {:name "Iron and Steel Industry", :stream 3, :chairs (909), :timeslot 14, :papers (435 517 473), :track 12}, 134 {:name "Maintenance", :stream 3, :chairs (17428), :timeslot 2, :papers (105 432 207), :track 3}, 136 {:name "Revenue Management", :stream 3, :chairs (14573), :timeslot 6, :papers (421 202 409 449), :track 3}, 137 {:name "Nonlinear Optimization and Modeling", :stream 11, :chairs (14865), :timeslot 6, :papers (457 289 11), :track 16}, 138 {:name "Nonsmoothness and Generalized Derivatives", :stream 11, :chairs (5218), :timeslot 7, :papers (223 221 461), :track 16}, 139 {:name "Optimization under Uncertainties", :stream 11, :chairs (15195), :timeslot 5, :papers (109 318 363), :track 16}, 140 {:name "Duality", :stream 11, :chairs (5218), :timeslot 9, :papers (454 582), :track 16}, 141 {:name "Services Operations", :stream 3, :chairs (829), :timeslot 7, :papers (414 462 516), :track 3}, 142 {:name "Layout Planning", :stream 3, :chairs (333), :timeslot 14, :papers (466 199 395), :track 3}, 143 {:name "Services Product Design", :stream 3, :chairs (14715), :timeslot 9, :papers (378 416 468), :track 3}, 146 {:name "Process Industries", :stream 3, :chairs (14865), :timeslot 11, :papers (84 360 346), :track 12}, 147 {:name "Flow Line Systems", :stream 3, :chairs (9112), :timeslot 9, :papers (124 562 618), :track 12}, 148 {:name "Capacity Planning", :stream 3, :chairs (), :timeslot 7, :papers (402 101 259), :track 12}, 149 {:name "Services Facility Planning", :stream 3, :chairs (5078), :timeslot 11, :papers (365 463 17), :track 3}, 150 {:name "Lot-Sizing 2 and Cutting", :stream 3, :chairs (4889), :timeslot 5, :papers (269 215), :track 3}, 155 {:name "Business Modeling", :stream 8, :chairs (16898), :timeslot 5, :papers (511 143 470), :track 12}, 156 {:name "Vehicle Routing", :stream 6, :chairs (1109), :timeslot 2, :papers (114 295 609), :track 8}, 157 {:name "Data Mining 2", :stream 8, :chairs (5931), :timeslot 6, :papers (271 535 392 525), :track 11}, 160 {:name "Semiplenary Talk 3", :stream 14, :chairs (7848), :timeslot 3, :papers (621), :track 8}, 161 {:name "Semiplenary Talk 5", :stream 14, :chairs (1131), :timeslot 10, :papers (595), :track 5}, 162 {:name "Semiplenary Talk 1", :stream 14, :chairs (930), :timeslot 3, :papers (617), :track 5}, 163 {:name "Semiplenary Talk 2", :stream 14, :chairs (2448), :timeslot 3, :papers (597), :track 7}, 164 {:name "Semiplenary Talk 6", :stream 14, :chairs (15277), :timeslot 10, :papers (619), :track 7}, 165 {:name "Semiplenary Talk 7", :stream 14, :chairs (9512), :timeslot 10, :papers (599), :track 8}, 166 {:name "Semiplenary Talk 8", :stream 14, :chairs (14637), :timeslot 10, :papers (600), :track 11}, 167 {:name "Semiplenary Talk 9", :stream 14, :chairs (5218), :timeslot 13, :papers (601), :track 5}, 168 {:name "Semiplenary Talk 10", :stream 14, :chairs (16606), :timeslot 13, :papers (605), :track 8}, 171 {:name "Metaheuristics 2", :stream 9, :chairs (16995), :timeslot 7, :papers (256 439 437), :track 13}, 172 {:name "Nonlinear Discrete Optimization 2 / Online Optimization", :stream 9, :chairs (14713), :timeslot 7, :papers (504 508 257), :track 14}, 175 {:name "Mixed Integer Linear Optimization 2", :stream 9, :chairs (14969), :timeslot 4, :papers (347 502 544), :track 13}, 176 {:name "Mixed Integer Linear Optimization 3", :stream 9, :chairs (16880), :timeslot 5, :papers (177 323 401), :track 13}, 178 {:name "Geometric Problems 2", :stream 9, :chairs (16926), :timeslot 4, :papers (268 175), :track 14}, 179 {:name "Geometric Problems 3", :stream 9, :chairs (13424), :timeslot 5, :papers (168 455 183), :track 14}, 181 {:name "Game Theory 1", :stream 10, :chairs (281), :timeslot 4, :papers (507 192 325), :track 15}, 182 {:name "Neural Networks", :stream 10, :chairs (14637), :timeslot 11, :papers (556 107 108), :track 15}, 183 {:name "Business Forecasting", :stream 10, :chairs (55099), :timeslot 2, :papers (16 371 188), :track 15}, 185 {:name "Correlation and Fuzzy Modelling", :stream 10, :chairs (17085), :timeslot 14, :papers (236 391 560), :track 15}, 190 {:name "Game Theory 3", :stream 10, :chairs (16883), :timeslot 6, :papers (28 140 510), :track 15}, 192 {:name "Game Theory 2", :stream 10, :chairs (4796), :timeslot 5, :papers (513 541), :track 15}, 195 {:name "Trees in graphs", :stream 12, :chairs (14923), :timeslot 7, :papers (290 543 361), :track 17}, 196 {:name "Reliability and delays ", :stream 12, :chairs (), :timeslot 5, :papers (495 233 532), :track 17}, 199 {:name "Railway crew scheduling", :stream 12, :chairs (), :timeslot 4, :papers (282 313 348), :track 17}, 201 {:name "Network Design", :stream 12, :chairs (13058), :timeslot 14, :papers (285 48 471), :track 17}, 203 {:name "Closed-Loop Supply Chains and Waste Management", :stream 1, :chairs (), :timeslot 9, :papers (476 460 46), :track 2}, 204 {:name "Applications of graphs", :stream 12, :chairs (12695), :timeslot 9, :papers (238 270 340), :track 17}, 205 {:name "Facility Location 1", :stream 12, :chairs (8853), :timeslot 2, :papers (81 147 203), :track 18}, 206 {:name "Facility Location 2", :stream 12, :chairs (17032), :timeslot 4, :papers (92 398 526), :track 18}, 210 {:name "SC Planning 1", :stream 5, :chairs (), :timeslot 4, :papers (284 608 106), :track 5}, 211 {:name "Sourcing 1", :stream 5, :chairs (), :timeslot 2, :papers (161 181), :track 6}, 215 {:name "Semiplenary Talk 4", :stream 14, :chairs (14031), :timeslot 3, :papers (620), :track 11}, 219 {:name "Plenary Talk Saul Gass", :stream 20, :chairs (14755), :timeslot 1, :papers (626 623), :track 19}, 220 {:name "Plenary Talk Morris A. Cohen", :stream 20, :chairs (5524), :timeslot 8, :papers (622), :track 7}, 221 {:name "Plenary Talk Bernd Liepert", :stream 20, :chairs (1609), :timeslot 12, :papers (624), :track 7}, 222 {:name "Diploma Award", :stream 21, :chairs (14707), :timeslot 7, :papers nil, :track 20}, 223 {:name "Dissertation Award 1", :stream 21, :chairs (15410), :timeslot 9, :papers nil, :track 20}, 224 {:name "Company Award", :stream 21, :chairs (10057), :timeslot 13, :papers nil, :track 7}, 225 {:name "Dissertation Award 2", :stream 21, :chairs (15410), :timeslot 11, :papers nil, :track 20}}, :rooms {1 {:room "J1109"}, 2 {:room "J1105"}, 3 {:room "J2105"}, 4 {:room "J2106"}, 5 {:room "K1003"}, 6 {:room "J1101"}, 7 {:room "K1001"}, 8 {:room "K1002"}, 9 {:room "J1102"}, 10 {:room "H2003"}, 11 {:room "K1004"}, 12 {:room "J2101"}, 13 {:room "H1010"}, 14 {:room "H1012"}, 15 {:room "J2102"}, 16 {:room "H2004"}, 17 {:room "H1013"}, 18 {:room "H2004"}, 19 {:room "H1001"}, 20 {:room "H2001"}, 21 {:room "Room 21"}}, :keywords {2 {:name "Airline Applications", :sessions (67 63 176 136 17 99 19)}, 3 {:name "Analytic Hierarchy Process", :sessions (98 146)}, 5 {:name "Artificial Intelligence", :sessions (103 91 73 157 16 59 104 182 185)}, 6 {:name "Auctions / Competitive Bidding", :sessions (46 61)}, 7 {:name "Capacity Planning", :sessions (134 68 136 116 64 171 146)}, 8 {:name "Combinatorial Optimization", :sessions (134 156 20 24 46 205 34 175 206 63 176 179 196 16 95 171 172 195 203 58 14 18 204 72 77 19 23 45 142 70)}, 10 {:name "Complexity and Approximation", :sessions (110 179 196 95 204 23 45)}, 11 {:name "Computer Science/Applications", :sessions (31 171 104 69 102)}, 12 {:name "Computational Biology", :sessions (204)}, 13 {:name "Convex Optimization", :sessions (17)}, 14 {:name "Continuous Optimization", :sessions (52 137 60 140 78 79)}, 15 {:name "Critical Decision Making", :sessions (155 94 99)}, 16 {:name "Cutting and Packing", :sessions (24 46 178 150 179 16)}, 17 {:name "Data Envelopment Analysis", :sessions (127 91 141)}, 18 {:name "Decision Support Systems", :sessions (31 127 107 101 178 181 199 130 50 61 98 99 203 56 92 59 72 102 133)}, 19 {:name "Decision Theory and Analysis", :sessions (82 127 181 155 84 190 137 90 106 19 88)}, 21 {:name "Development", :sessions (143)}, 22 {:name "Disaster and Crisis Management", :sessions (75 102)}, 23 {:name "Dynamical Systems", :sessions (134 110 52 87 51 155 192 137 18 182)}, 25 {:name "Economic Modeling", :sessions (82 181 118 139 94 148 102)}, 27 {:name "Education and Distance Learning", :sessions (104)}, 28 {:name "Electrical Markets", :sessions (87)}, 29 {:name "Energy Policy and Planning", :sessions (127 203)}, 31 {:name "Environmental Management", :sessions (32 203 92 102)}, 32 {:name "Expert Systems and Neural Networks", :sessions (182)}, 33 {:name "Facilities Planning and Design", :sessions (206 58 149 142)}, 34 {:name "Finance and Banking", :sessions (85 86 84 90 89 185)}, 35 {:name "Financial Modelling", :sessions (85 103 86 87 155 84 90 128 83 89 19 88 185)}, 36 {:name "Flexible Manufacturing Systems", :sessions (148 147)}, 37 {:name "Forecasting", :sessions (31 183 86 210 68 157 90 166 182 122)}, 39 {:name "Fuzzy Sets and Systems", :sessions (211 103 98 148 56)}, 40 {:name "Game Theory", :sessions (82 181 192 190 112 143 121 104 114 185)}, 41 {:name "Global Optimization", :sessions (96 78 79)}, 42 {:name "Graphs and Networks", :sessions (156 20 206 55 155 192 196 195 147 14 18 204 45 75)}, 44 {:name "Group Decision Making and Negotiation", :sessions (81 84 106 185)}, 45 {:name "Health Care", :sessions (51 91 94)}, 47 {:name "Human Resources Management", :sessions (82 83 53)}, 48 {:name "Industrial Optimization", :sessions (52 34 101 50 49 148 92 142 133)}, 50 {:name "International Business", :sessions (99 83 88)}, 52 {:name "Knowledge Engineering and Management", :sessions (157)}, 53 {:name "Large Scale Optimization", :sessions (20 63 71 201)}, 54 {:name "Location", :sessions (205 52 206 91 37 95 149 78 142)}, 55 {:name "Management Information Systems", :sessions (81 107 55 157)}, 56 {:name "Marketing", :sessions (107 155 139 157 99 171 143)}, 57 {:name "Mathematical Programming", :sessions (20 52 176 136 50 73 16 116 172 138 204 71 146 75 102)}, 58 {:name "Medical Applications", :sessions (23)}, 59 {:name "Metaheuristics", :sessions (57 156 67 103 205 22 54 34 101 178 51 63 91 16 171 195 59 53 69 70)}, 60 {:name "Military Operations Research", :sessions (171)}, 61 {:name "Modeling Systems and Languages", :sessions (101 146)}, 62 {:name "Multi-Criteria Decision Aids", :sessions (139 98 104)}, 63 {:name "Multi-Objective Decision Making", :sessions (129 103 127 206 63 61 98 116 77)}, 65 {:name "Network Design", :sessions (67 205 113 195 203 149 45 201)}, 66 {:name "Non-smooth Optimization", :sessions (137 138)}, 67 {:name "Optimization in Financial Mathematics", :sessions (86 139 90)}, 68 {:name "Optimization Modeling", :sessions (210 120 87 130 139 91 136 73 61 190 137 148 143 121 58 167 142 114 122)}, 72 {:name "OR in Sports", :sessions (175)}, 73 {:name "OR/MS and the Public Sector", :sessions (149 75)}, 75 {:name "Production and Inventory Systems", :sessions (134 110 163 22 54 210 150 118 91 50 49 112 148 117 121 147 146 93 114 122 133)}, 76 {:name "Programming, Dynamic", :sessions (57 129 86 206 150 118 132 147 23 93)}, 77 {:name "Programming, Integer", :sessions (134 20 24 46 22 54 175 199 118 176 179 192 196 98 16 17 141 195 60 72 71 19 53 70 201)}, 78 {:name "Programming, Linear", :sessions (63 147 140 59)}, 79 {:name "Programming, Multi-Objective", :sessions (16 140 78)}, 80 {:name "Programming, Nonlinear", :sessions (54 17 137 95 138 146)}, 81 {:name "Programming, Quadratic", :sessions (17 172)}, 82 {:name "Programming, Semidefinite", :sessions (172)}, 83 {:name "Programming, Semi-Infinite", :sessions (138)}, 85 {:name "Programming, Stochastic", :sessions (31 127 128 121)}, 86 {:name "Project Management and Scheduling", :sessions (57 175 55 50 56 59)}, 87 {:name "Quality Management", :sessions (157)}, 88 {:name "Queuing Systems", :sessions (183 132)}, 89 {:name "Reliability", :sessions (181 196 70)}, 90 {:name "Research and Development", :sessions (119)}, 91 {:name "Revenue Management and Pricing", :sessions (81 183 52 136 99 143 117 149)}, 92 {:name "Reverse Logistics / Remanufacturing", :sessions (68 113 17 203 121 93)}, 93 {:name "Risk Analysis and Management", :sessions (129 87 139 84 90 116 106 89 119 72 146 185)}, 94 {:name "Robust Optimization", :sessions (210 87 139 113 116 19 142)}, 95 {:name "Routing", :sessions (31 156 20 34 51 68 37 64 171 172 60 14 59 72 77 71 93 69)}, 96 {:name "Scheduling", :sessions (57 67 183 54 210 199 55 50 16 141 49 64 147 14 59 72 19 53 114 70)}, 97 {:name "Simulation", :sessions (110 67 199 136 73 61 94 128 172 56 58 147 89 119 104 88 133 185)}, 98 {:name "Software for OR/MS Analysis", :sessions (101 55 96 89 102 201)}, 99 {:name "Stochastic Models", :sessions (110 211 129 127 87 130 96 155 132 141 116 128 56 165 93 122 79)}, 100 {:name "Strategic Planning and Management", :sessions (211 73 190 94 141 116 143 106 88)}, 101 {:name "Supply Chain Management", :sessions (134 110 211 22 210 120 52 118 113 190 49 116 112 203 117 121 119 114 122)}, 102 {:name "Sustainable Development", :sessions (129 113 83 92)}, 103 {:name "System Dynamics and Theory", :sessions (155 94 143)}, 104 {:name "Telecommunications", :sessions (132 201)}, 105 {:name "Timetabling", :sessions (46 175 71 53)}, 106 {:name "Transportation and Logistics", :sessions (110 211 31 156 67 46 52 34 199 118 51 68 63 196 50 73 37 61 32 64 58 60 149 72 77 71 69 75 70 201)}, 108 {:name "Variational Problems", :sessions (138)}, 109 {:name "Warehouse Design, Planning, and Control", :sessions (190 117)}, 110 {:name "Web-based Information Systems", :sessions (178)}, 111 {:name "Work Flow Management Systems", :sessions (157 141)}, 113 {:name "Ethics", :sessions (82)}, 117 {:name "Semi-plenary", :sessions (219 162 163 160 215 220 161 164 165 166 221 167 168)}, 120 {:name "Data Mining", :sessions (107 51 96 157 79)}, 121 {:name "Rostering", :sessions (199 141)}, 122 {:name "Analytic Network Process", :sessions (132 102)}}, :papers {3 {:keyword1 96, :keyword3 86, :abstract "We consider single machine scheduling and due date assignment problems in which the processing time of a job depends on its position in a processing sequence. The objective functions include the cost of changing the due dates, the total cost of discarded jobs that cannot be completed by their due dates and, possibly, the total earliness of the scheduled jobs. We present polynomial-time dynamic programming algorithms in the case of two popular due date assignment methods: CON and SLK. The considered problems are related to mathematical models of cooperation between the manufacturer and the supplier in supply chain scheduling.", :title "On single machine scheduling and due date assignment with positionally dependent processing times", :keyword2 76, :authors (5017), :session 57}, 6 {:keyword1 8, :keyword3 0, :abstract "For design of adequate mathematical models of many scientific and applied problems it needs to construct new classes of combinatorial sets. The approach for constructing special types of complex combinatorial sets based on primary combinatorial sets and special mappings is developed. As such sets may be, for example, a permutation set, whose components are elements of another permutation set, a permutation set, whose components are n-tuples, etc.\r\n The report considers the constructive means of description of the combinatorial sets based on the concept of composition k-images of combinatorial sets. The concept uses configurations proposed by C. Berge and general combinatorial circuit represented in the theory of counting of G. Polya. Properties of the sets and their classification are realized. &#1040; number of examples are given.\r\n", :title "Description, classification and design of special combinatorial configurations", :keyword2 0, :authors (16597 8142), :session 18}, 11 {:keyword1 80, :keyword3 0, :abstract "Based on the economic principle, technical efficiency is considered as a matter of rationality and is assumed as a necessary condition for profit-optimization. Due to this assumption, technically inefficient production alternatives are generally excluded. In contrast to this perception, the objective of our study is to demonstrate that it is not reasonable to focus only on technically efficient production alternatives in order to maximize profit. From a traditional perspective, the concept of technical efficiency depends on rare goods and perfect markets and therefore implies strictly positive and constant input/output(i/o)-prices. In reality, however, exist non-rare goods and because of pricing policies also imperfect markets. In the further research the assumptions of strictly positive and constant i/o-prices are dropped. Our analysis is restricted on the implications of quantity discounts as a tool of nonlinear price discrimination regarding the profit function. Thereby, we distinguish between two types of quantity discounts. In the case of all-unit quantity discounts the lower price applies to all units purchased, while in the case of incremental quantity discounts the new price refers only to those units within the corresponding interval. Such price variations cause non-monotonic profit functions. Based on the approach \"`On the Relevance of Technical Inefficiencies\"' of Fandel/Lorth (2006) and under consideration of the respective types of quantity discounts, we illustrate that profit-maximizing production alternatives may imply technical inefficiency. For this purpose, we analyse different price situations and demonstrate that optimal combinations of i/o-relations could be located in the interior of the technology set depending on the topology of profit functions.", :title "Technical Inefficiencies and Profit-Maximization", :keyword2 19, :authors (16581 14865), :session 137}, 16 {:keyword1 37, :keyword3 96, :abstract "Call centre workforce planning is an interesting and challenging problem to tackle because it requires different forms of OR modelling techniques. The demand (i.e. the incoming call arrivals) is subject to predictable and stochastic sources of variation. Throughout the decision hierarchy of workforce planning, call demand forecasting models are a key input to staff scheduling models, whereas queueing models, such as Erlang-C formula, provide a practical method for translating the Poisson stochastic call arrivals into staffing requirements and performance measurement.\r\n\r\nHowever, the input to the queueing models (i.e. the arrival rates) depend on many factors and often experience cycles recurring on various time scales, for example, daily, weekly, monthly and yearly. Furthermore, these factors need to be estimated using forecasting methods, which are therefore subject to some sort of uncertainty.\r\n\r\nThis paper presents results from applying a simulation methodology to investigate the impact of uncertainty in demand forecasts on call centre performance, rather than simply reporting standard forecast error measurements (RMSE, MAPE etc) as is often the case when forecast methods are evaluated.\r\n", :title "The effects of forecasting models in Call Centre workforce planning", :keyword2 88, :authors (16621), :session 183}, 17 {:keyword1 33, :keyword3 73, :abstract "School network planning in urban areas is a difficult task because of unstable number of students over time and space. Particularly if students are free to choose the school to enroll on. It is assumable that there exist substitution patterns between schools. A deterministic student assignment is not appropriate. We present a mathematical programming approach to deal with the Dynamic School Network Planning Problem (DSNPP) with free school choice. The most striking difference of this new approach compared to the literature is that the decision on student allocation and the decision which school to open/close in a given period could not be modeled simultaneously. This is because students are not allocated to schools in a deterministic way. Students are allocated to available (open) schools according to empirical expected choice probabilities based on utility maximization. The school choice probabilities are determined by a mixed multinomial logit model since this is the most convenient way to model flexible substitution patterns between schools. Concerning the mathematical program the school choice probability is a model parameter by definition. Unfortunately they depend on the available schools denoted by a model variable. To solve this conflict we have to consider a two step large scale optimization approach. (i) we enumerate all possible combinations of opened and closed schools (scenarios). A Quadratic Constrained Program has to be solved for all feasible combinations of scenarios and periods yielding the discounted scenario costs per period. (ii) we select one scenario for each period in the way that the total costs over the whole planning horizon and the costs for opening or closing a school are minimized. This approach is applied to the school network of Dresden.", :title "Dynamic School Network Planning in Urban Areas", :keyword2 54, :authors (16639), :session 149}, 20 {:keyword1 25, :keyword3 18, :abstract "The paper is devoted to a methodology for economic clauses development of production sharing agreements (PSA) for oil and gas projects. The methodological approach is illustrated on Krasnoyarsk region example. We use special model tools for selecting agreement parameters based on a tradeoff between the interests of the investor and government.\r\nOur methodology is based on the PSA basic matrix construction. Analysis of a family of surfaces for the main efficiency indicators allows us to find optimal values of the key parameters: the initial part of the compensational production and profit production. \r\n", :title "An Approach for Economic Clauses Development of a Production Sharing Agreement for Oil and Gas Projects", :keyword2 31, :authors (16656), :session 102}, 21 {:keyword1 57, :keyword3 18, :abstract "In the current manufacturing industry, competition is focused on the ability to respond to changing market conditions promptly and flexibly. In the production of electronic equipment the competition is extremely fierce. The market shares are retained or increased by introducing new designs and concepts at an increasing pace. This, on the other hand, leads to a growing product portfolio and together with the clearly shortened product life cycles they present a considerable challenge for efficient steering of the manufacturing processes.\r\n\r\nManagement of the demand-supply network according to the mass customization principles is reality in the mobile terminal manufacturing. Especially the original equipment manufacturers must be able to handle a product portfolio of hundreds of different variants all based on the same core component. Customization covers a wide range of features e.g. software, covers, accessories, manuals and packaging. Furthermore, as the current operations culture is based on an outsourcing-driven paradigm with both local and global networks of partnerships, the manufacturing systems, the production lines are reconfigurable to permit a high frequency of new product designs. One of the main goals is to maintain a high level of flexibility to permit a fast response to changed situations in the market.\r\n\r\nIn this paper, a scheduling problem encountered in the operational management of the flexible manufacturing of mobile terminals is discussed. An MILP-based multi-objective optimization model able to consider raw material availability and customer order specific constraints as well as staff balancing aspects is proposed. Furthermore, the applicability and behaviour of the model is analyzed in an illustrative example.", :title "Scheduling of modular production lines in mobile terminal manufacturing using MILP", :keyword2 96, :authors (16655 16660), :session 50}, 28 {:keyword1 19, :keyword3 68, :abstract "A numerical method to find solutions to the Stackelberg leader-follower problem of facility placement in a competitive new market is presented.  In this game, two competing retail firms enter a new market with known demand.  Both firms select: (1) the placement of its distribution facility, (2) the placement of its retail outlets and (3) regions where marketing efforts should be focused.  These decisions are made to maximize overall profits while assuming the rival firm will do the same as well.  The fixed market demand distribution is known before hand.  Extractable profit from any given point in the market is divided between the two companies with proportions that are a function of the local marketing activity.  Retail outlets placed further from the distribution centre are penalized with a distance-cost function to reflect the transportation costs associated with selling goods at sites far away from the distribution centre.  A separate cost function is assigned to penalize the use of excessive marketing activity for both firms.  A two-sided numerical optimization algorithm is presented for finding equilibrium strategies.  A quasi-Newton method is used to maximize profits for the follower firm.  This follower optimizer is embedded within a genetic optimizer for maximizing leader firm profit.  Preliminary simulation results are detailed in a one-dimensional market with varying market demand conditions.", :title "Competitive Facility Placement for Supply Chain Optimization", :keyword2 101, :authors (16680), :session 190}, 33 {:keyword1 8, :keyword3 0, :abstract "Bei den üblichen Branch-and-Bound-Verfahren der ganzzahligen Optimierung wird jeweils nach einzelnen Variablen verzweigt, z.B. x1  &#8805;  5 versus x1  &#8804;  4, d. h. senkrecht zu den einzelnen Koordinaten. Ed Brocklehurst hat schon 1975 auf der IFORS-Tagung in Japan ein schiefwinkliges Branch-and-Bound-Verfahren vorgeschlagen. Er nimmt Verzweigungen vom Typ x1 + 2x2  &#8805;  11  vs.  &#8804;  10 vor. Brocklehurst berichtete über viel versprechende Testerfahrungen mit seinem Verfahren. Seine Idee fand in der Fachwelt so gut wie keine Beachtung. Es folgte lediglich ein etwas veränderter Vorschlag von Müller-Merbach 1983. Auch die damaligen Erfahrungen waren überzeugend. Ein neues Projekt soll die Erfahrungen vertiefen. Im Vortrag sollen einerseits die Ansätze des schiefwinkligen Branch-and-Bound vorgestellt und darüber hinaus deren potenzielle Vorteile demonstriert werden.", :title "Schiefwinkliges Branch-and-Bound in der ganzzahligen Optimierung", :keyword2 0, :authors (9365), :session 14}, 43 {:keyword1 101, :keyword3 75, :abstract "One of the main issues of supply chain management is to\r\nfind suitable mechanisms to coordinate various members of\r\na supply chain comprising suppliers, manufacturers,\r\ndistributors, wholesalers and retailers in order to\r\nachieve the maximal supply chain profit.  Most of the\r\nprevious literature assumes that the decision makers are\r\nrisk-neutral.  Recently, Keren and Pliskin (2006) study\r\nthe supplier-retailer relationship in a newsvendor problem\r\nwhere the retailer is a risk averse decision maker, in\r\nwhich the demand distribution is a uniform distributed. \r\nThe purpose of this paper is to discuss the effect of the\r\nattitudes toward risk of the retailer on the coordination\r\nin a supply chain under the wholesale price contract and\r\nthe buyback contract respectively.  In a general demand\r\ndistribution, we derive the properties of the proportion\r\nof the supplier’s expected profit to the supply chain’s expected profit in a buyback contract.  Then, using the utility functions, the optimal order quantities placed by a risk-averse retailer are compared with that of a risk neutral retailer in each contract.  We also explore the relationship between the retailer's order quantity and the Pratt’s risk aversion function. ", :title "A Supply Chain Coordination Model with Retailer's Attitudes Toward Risk", :keyword2 68, :authors (16798 10219), :session 121}, 46 {:keyword1 8, :keyword3 31, :abstract "Recently, CO2 emissions mitigation has been interested in a local area. Especially, in Japan, the biomass material use is expanding for CO2 emissions mitigation. Also, there is much wood waste and the material is circulated in our society in accordance with the related regulations.\r\nThe effective use, by which CO2 emissions reduction has to be achieved, is desired. In conventional case, the ways of recycle were wood chips for paper, materials for a power generation and particleboard.\r\nOn the other hand, the hydrogen fuel for the protection of global warming has been attractive.\r\nThe expansion for fuel cell vehicle use and/or that in the chemical manufacturer is projected. It is very important what origin the fuel is.\r\nWe have executed the research and development on bio-H2 fuel which is synthesized from biomass resources.\r\nIn this paper, Yokohama area is selected as a model area, and we optimized the recycle of waste wood pallet so that the processing companies maintain the current profit. In this area, there are 15 processing companies. \r\nIn our model, we interviewed the transaction cost, the material conditions and/or the processing volume to a few companies. The transportation costs and the transaction costs in the conventional cases are considered. Also, the H2 production volume from wood biomass is referred by the experimental test data we executed.\r\nThe annual processing volume is approximately 52,000 t/yr. The transaction cost which the companies received is assumed to be 2000 to 3000JPY/t. \r\nIn this area, the price of purified H2 gas is several hundred yen per 1 Nm3.\r\nIn the case of 150 JPY/Nm3, all the companies can maintain the current profit, and the energy company which owns the H2 production system can operate successfully, too.", :title "An optimization of waste wood recycles in Yokohama area of Japan.", :keyword2 29, :authors (14341), :session 203}, 47 {:keyword1 34, :keyword3 0, :abstract "This paper presents a comprehensive comparison of theory and practice of the most established capital budgeting methods in Germany based on our survey results. For this purpose we have sent questionnaires to CEOs and CFOs of all companies listed in the German all share index (CDAX) to find out which capital budgeting methods are currently used by German managers and how accurately they apply them. We regress the most prominent corporate performance figures, return on equity and total investment return on the application frequency of particular capital budgeting methods to assess whether the usage of such methods has an impact on performance. To the best of our knowledge our paper is the first to exploit this approach. We conclude that German managers do not seem to follow the shareholder value principle when applying capital budgeting methods. Furthermore, we show that executives seem to be hesitant to implement residual income valuation methods as a key tool for the ex post performance measurement of a company. Finally, we provide evidence that the usage of capital budgeting methods and their proper application has a much greater impact on corporate performance than observable personal characteristics of top managers and fundamental properties of their companies. ", :title "Do Managers Follow the Shareholder Value Principle When Applying Capital Budgeting Methods? A Comparison of Theory and Practice Based on German Survey Results and Return", :keyword2 0, :authors (10309 10169), :session 84}, 48 {:keyword1 106, :keyword3 0, :abstract "The transshipment model shows suppliers and buyers and gives a solution for least cost streams of goods from sources to sinks with the means of linear programming techniques. In this model the cost coefficients are constant, being independent from the amount that flows on the arc. But transport markets are characterized by marked economies of scale. So the question arises how to adopt these economies of scale to the transshipment model. We express these economies of scale by cost coefficients cik which decrease with the amount xik that flows on the arc (i,k). We discuss how to characterize these functions. Then we show how to adopt the techniques to generate the first basic solution to the case of falling cost functions: the methods of increasing cost, of the greatest regret and the north-east rule. Then we discuss how to adopt the step to improve a basic solution. We use the technique of dual variables to identity an arc which can enter the basic solution. We must check, whether an arc can leave the basic solution. If not, than we get an improvement, but not a basic solution. We discuss, how to proceed in this non classical case. A simulation study shows, that this non classical case does not appear very often. So the classical techniques of linear programming carry over to the case of falling cost functions.\r\n", :title "Solutions for the Transshipment Model with decreasing cost coefficients", :keyword2 0, :authors (16687), :session 201}, 52 {:keyword1 8, :keyword3 96, :abstract "We present a B\\&B method using combinatorial bounds for solving makespan minimization problems with sequence depend setup costs. One application of this is the laser sharing problem: Some car manufactures use laser welding technology for the assembly of car bodys. The equipment in a welding cell consists of a number of welding robots and one or more laser sources, each of which can supply more than one robot, but only one at a time!\r\nThe question is: \"`How many laser sources are needed to process a given set of welding tasks in a given time?\"'\r\nIn order to answer this question, we present a makespan minimization model and a branch \\& bound algorithm for it. The new feature is that the B\\&B is not LP-based but uses combinatorial TSP-relaxations in order to find vastly improved lower bounds compared to LP-relaxations. This algorithm was able to solve an instance with 20 welding jobs, 3 robots and one, two or three laser sources to optimality in about 15 sec. In contrast to this, the root LP bound for a state-of-the-art time discrete approximation has a gap of 54\\% and needed about 684 sec. to be solved by CPLEX 11's barrier method. The new algorithm is the first that can solve this problem on a real-world-scale (34 jobs).", :title "On the benefits of using NP-hard problems in Branch \\& Bound", :keyword2 95, :authors (16717 16606), :session 14}, 53 {:keyword1 65, :keyword3 0, :abstract " Analysis of survivability of asymmetrical hierarchical flow networks(AHN),under uncertainty conditions,includes consideration of flow distrubution after the arcs failur.In such cases, it is supposed that remaining capacity is known .The garanteed evalution of the functional capability of AHN assumes finding the wrost distrubution of flow in the destructed network.A unique efficiency criterion is not generally defined or known.Here the quality of the network functioning is evaluted by measuring the completeness of demand satisfication.", :title "Circular and radial design comparison in survivability of asymmetrical hierarchical networks", :keyword2 0, :authors (16780 17396), :session 45}, 58 {:keyword1 75, :keyword3 101, :abstract "We consider a capacitated single-level dynamic lot-sizing problem with sequence-dependent setup costs and times that includes product substitution options: Each product can be substituted by certain other products to satisfy demand. Performing substitutions can help reduce the total setup costs and the total duration of setups, which increases the capacity available for production and thus the effective output of the production system. The model is motivated from a real-world production planning problem at a manufacturer of plastic sheets used as an interlayer in windshields. We develop a MIP-based heuristic for a mixed-integer programming formulation of the problem and report computational results.", :title "The Capacitated Lot-Sizing Problem with Sequence-Dependent Setups and Substitution", :keyword2 77, :authors (33231), :session 22}, 70 {:keyword1 75, :keyword3 37, :abstract "We report the results of Newsvendor-type laboratory experiments conducted with two groups of subjects, purchasing managers of major retailers and students. In a first experiment, participants received information on the optimal order quantity after several rounds of ordering. In a second experiment, participants received a one-hour video lecture including an exam before the experiment. Our results show that the two groups of participant react very differently to information and to teaching.", :title "Behavioral Operations - The Effect of Experience on Newsvendor Performance", :keyword2 68, :authors (14573), :session 122}, 71 {:keyword1 42, :keyword3 95, :abstract "The talk presents the generalized directed rural postman problem (GDRPP). This problem is a straightforward generalization of the directed rural postman problem (DRPP). The DRPP consists in finding an optimal postman tour in a digraph, i.e., a least-cost cycle traversing each arc of a specified subset of the digraph’s arcs at least once. The GDRPP is, to the DRPP, what the generalized travelling salesman problem (GTSP) is to the travelling salesman problem (TSP): In the GDRPP, there are several subsets (groups, classes, clusters) of arcs and the requirement is to find a least-cost cycle traversing at least one arc from each subset at least once. The subsets need neither be a partition of the arc set, nor need they be disjoint. The GDRPP is an interesting problem in its own right, but it is also important because many uncapacitated routing problems, especially arc routing problems (ARPs), can be modelled as GDRPPs. Moreover, there are several practically relevant constraints (e.g., alternative modes of servicing road segments) which can be considered when modelling a problem as a GDRPP. The talk presents formulations for the GDRPP as well as transformations of routing problems into GDRPPs, taking into account additional constraints as encountered in practice. Moreover, the results of extensive computational experiments with exact and heuristic solution methods (a branch-and-cut algorithm and a multi-start VND heuristic) are presented.", :title "The Generalized Directed Rural Postman Problem", :keyword2 77, :authors (14973), :session 20}, 74 {:keyword1 96, :keyword3 80, :abstract "A flow-shop batching problem is considered in which the processing times of all jobs on each machine are equal to p and all batch set-up times are equal to s. In such a problem on each machine one has to partition the set of jobs into batches and to schedule the batches. The processing time of a batch is the sum of processing times of operations in the batch. The earliest start time of a batch on a machine is the finishing time of all the jobs in the batch on the previous machine plus the set-up time. The objective is to minimize the makespan. It can be shown that an optimal schedule exists in which all jobs are processed on all machines in the same order. \r\nCheng et al. [2000]  provided an O(n) pseudopolynomial-time algorithm for solving the special case of the problem with two machines where n is the number of jobs. Further results have been derived under the assumption that in an optimal schedule all batches are consistent, i.e. that the partition of the job sequence is the same on each machine. Mosheiov \\& Oron [2004] developed an O(n) algorithm for the general case with two or more machines. Ng & Kovalyov [2007] improved the complexity to the order of square root of n. We provide a polynomial algorithm for this problem which has a complexity of the order of log(n) cube.\r\n", :title "A Flow-Shop Batching Problem", :keyword2 77, :authors (9026), :session 54}, 76 {:keyword1 97, :keyword3 101, :abstract "In this paper inventory management is analyzed as an indivisible, organic part of the supply chain managing process. It can be observed as a critical, and also very costly, segment of ensuring high customer service levels. Thus in today’s competitive economic environment traditional inventory policies should be improved and readjusted to uncertain, dynamic reality. Simulation models enable a priori managing and analyzing a variety of possible results and implication of selected inventory policies. It is important to accentuate the difference between deterministic and stochastic simulation models, which besides certainty also include random effects. The model presented in this paper uses the Monte Carlo simulation method and variables (demand, delivery time and quantity, stock quality, price, etc.) taken as random, in order to depict a harmonization and unavoidable integration of dynamic quantitative analysis and theoretical, qualitative concepts of inventory management. Approximated inventory costs are also included in the model and they naturally depend on the cost of capital, therefore variations during the economic cycle should be observed too. Illustrating the potentials of inventory policy and future effects the model can be successfully exploited in decision making processes. ", :title "Simulation in Inventory Management", :keyword2 99, :authors (16785), :session 110}, 77 {:keyword1 57, :keyword3 98, :abstract "Utility computing (or on-demand computing) is the packaging of computing resources, such as computation, memory, and storage, as a metered service similar to a physical public utility.\r\n\r\nUntil the 80's, massive computing resources  were scarce and  the shared and metered usage of computer power at a central place was quite popular for mathematical programming applications.\r\nThe success story of the PC however terminated most of these businesses, but recently the approach of using shared metered resources is catching on again.\r\nWe will start with a brief overview about the history of utility computing applied to mathematical programming projects, show a few current concepts and available technologies (Sun's Network.com  and Amazon's Computing Cloud), and discuss whether these approaches are\r\nalready suitable for the requirements of (commercial) mathematical programming problems. ", :title "Is Utility Computing  suitable for providing Mathematical Programming Resources", :keyword2 11, :authors (14853), :session 102}, 78 {:keyword1 101, :keyword3 0, :abstract "Demand for fashion products is usually highly uncertain. Often, there is only one possibility for placing a purchasing order before the selling season. In order to improve the traditional newsvendor-type overage-underage trade-off we study a network of two expected profit maximizing retailers selling a fashion product\r\nwhere there is an additional opportunity for redistribution of stock during the selling season. We distinguish between the situation where redistribution is done at the moment when one of the retailers is running out of the stock and the situation where the redistribution time is already determined and fixed before the selling season. We model the demand process at a retailer by a Poisson Process with an uncertain mean and use a Bayesian approach to update the distribution parameter before transshipments are\r\ndone. In an extensive numerical study we compare different\r\nscenarios and we derive insights into the initial purchasing\r\nquantities, the optimal timing of inventory redistribution and the benefit of parameter updating.", :title "Optimal timing of inventory redistribution for fashion products under demand parameter update", :keyword2 99, :authors (9112 9112), :session 122}, 81 {:keyword1 54, :keyword3 8, :abstract "We consider the following bilevel p-median problem. Two companies want to open facilities to service customers. The first company, we call it the Leader, opens p facilities. Later, the second company, we call it the Follower, observes the opened facilities of the Leader and opens own p facilities. Each customer selects one facility from the set of Leader’s and Follower’s facilities according to own preferences. We assume that the company will get a profit if a customer selects its facility. Each company tries to maximize the total profit. They don’t have the same rights. The Leader makes a decision first. After that, the Follower analyzes the Leader’s decision, preferences of the customers, and makes own decision. We get a Stackelberg game for two players, where we wish to maximize the total profit of the Leader. For this game we present a linear bilevel 0-1 program. Genetic algorithm is developed to get near optimal solutions. To obtain upper bounds we introduce an additional constraint into the Follower problem and rewrite this bilevel problem as a linear 0-1 program. Optimal solution for this program we use as an upper bound. Computational results for 100 customers and p=10 are presented.", :title "Upper and lower bounds for the p-median problem with foresight", :keyword2 59, :authors (9027 3190 16792), :session 205}, 84 {:keyword1 75, :keyword3 57, :abstract "A solid theoretical basis related to production planning for different process systems has been established in the literature. However, continuous flow process industries remain least researched with respect to specific theoretical and optimization issues. This development can be explained by a common contrasting of discrete and non-discrete industry types without a proper consideration to the diversity observed within the latter. Yet, a variety of such process systems is observed in oil refineries, in production of chemicals, food, roofing, and glass. In part, this disbalance is a consequence of a univocal acceptance of the classic product-process matrix, which contributes to unawareness of its shortcomings and forecloses promising research directions. It is exacerbated by the mounting body of works that hinder the industry type distinctions and concentrate on discrete manufacturing. \r\n\r\nThe paper considers theoretical and optimization issues related to production planning in continuous process industries with non-discrete units. The purpose of this work is to locate continuous non-discrete production within the theoretical frameworks, discuss its general features and apply planning techniques on a concrete industrial example. Subsequently, two mathematical optimization models are developed for the incumbent production system: the first formulation allows for a better utilization of the production capacity with respect to energy costs and synchronizes production and distribution planning, whereas the second one maximizes the production output regardless of the energy costs involved. The suggested formulations are tested on the real data, analyzing the results and discussing the models’ characteristics, focusing on their practical implications and possible improvements.", :title "Production Planning in Continuous Process Industries: Theoretical and Optimization Issues", :keyword2 7, :authors (16808), :session 146}, 86 {:keyword1 8, :keyword3 0, :abstract "Consider a street network of a city, where each street can be used in both directions. Such a network can be modeled as a graph, where the vertices are given by the intersection points and the edges are given by the streets. The maximum length of a shortest path between a pair of vertices is called diameter of the graph. Now we consider the problem of assigning directions to each edge in such a way that the diameter of the resulting graph is minimized. In this talk we give some bounds on the minimum oriented diameter of a graph with respect to the cardinality of a dominating set.", :title "Bounds for the minimum oriented diameter", :keyword2 42, :authors (16821), :session 18}, 88 {:keyword1 88, :keyword3 0, :abstract "We consider a multi-queue multi-server system with\r\nn servers (processors) and m queues. At the system\r\nthere arrives a stationary and ergodic stream of m\r\ndifferent types of requests with service requirements\r\nwhich are served according to the following k-limited\r\nhead of the line processor sharing discipline: The\r\nfirst k requests at the head of the m queues are\r\nserved in processor sharing by the n processors,\r\nwhere each request may receive at most the capacity\r\nof one processor.\r\n\r\nBy means of sample path analysis and Loynes'\r\nmonotonicity method, a stationary and ergodic state\r\nprocess is constructed, and a necessary as well as\r\na sufficient condition for the stability of the m\r\nseparate queues are given, which are tight within\r\nthe class of all stationary ergodic inputs. These\r\nconditions lead to tight necessary and sufficient\r\nconditions for the whole system, also in case of\r\npermanent customers, generalizing an earlier result\r\nby the authors for the case of a single-server system\r\nwith ordinary head of the line processor sharing and\r\npermanent customers. The gap between the necessary\r\nand sufficient stability conditions is illustrated.\r\n\r\n", :title "On the stability of the multi-queue multi-server processor sharing with limited service", :keyword2 104, :authors (4170 4169), :session 132}, 92 {:keyword1 8, :keyword3 42, :abstract "Network center location problems are basic models in operations research and play an important role in practice and theory. While in classical network center location problem the goal is to determine the optimal location of a facility such that maximum of the (weighted) shortest distance to all customers is minimized, the inverse network center location problem is concerned with modifying the parameters of a given network, like edge lengths or vertex weights, at minimum total cost such that a pre-specified point becomes a center of the network. In this talk we consider the inverse center location problem on a tree network in which we are allowed to increase or decrease the edge lengths within certain bounds. If all costs are equal, then a quadratic time algorithm for the problem under investigation is developed. For arbitrary costs, a cubic time algorithm is designed and analyzed. Finally, it is shown that the problem is solved in linear time, when the network is a path or star graph. ", :title "Exact  Algorithms for Inverse Center Location Problems on Trees", :keyword2 54, :authors (15233 128), :session 206}, 93 {:keyword1 34, :keyword3 0, :abstract "Stock recommendations provided by financial analysts are one of the most important sources of information for financial markets and has therefore been subject to various studies. Our approach differs from existing literature as we focus on the value of such analysts’ releases for private investors. Therefore, we use recommendation data that has been published on an internet platform easily accessible by German speaking private investors. This is in contrast to many existing publications that use a database specially designed for market professionals which primarily consists of recommendations on American stocks. With a number of more than 180,000 recommendations over a time period of ten years our study is by far more comprehensive than other Germany-focused research.\r\n\r\nTo calculate the excess returns of recommended stocks we use the multifactor regression model established by Fama/French (1993). We divide our study into two main parts characterized by time horizons of seven days and one year.\r\nFurthermore, our results are subdivided by the home country of the recommended company, by the intensity with which a stock is covered by analysts and by the reputation of the analyzing institutions.\r\n\r\nOur results partly support existing literature but in some specific sub-samples we discover remarkable new findings that can lead to reassessment of the value of stock recommendations for private investors.\r\nWe find out that in many cases buy recommendations are published too late to create excess returns while sell recommendations provide investment value.\r\nFurthermore, there exist significant differences regarding characteristics of the releases (home country of the company, analysts’ reputation) but in several cases our findings are counterintuitive.\r\n", :title "The Value of Analysts’ Recommendations for Private Investors", :keyword2 0, :authors (9578 16830 16831), :session 85}, 94 {:keyword1 101, :keyword3 0, :abstract "Nowadays, due to innovation, the lifecycle of finished goods have shortened dramatically. The impact of this shortening can often be problematic for service. End of life phase of spare parts starts immediately after production stop. End of life inventory problem deal with final ordering quantities in this phase. In all previous study, just repair policy is considered and alternative policies are left out of consideration. To fill in this gap, the classical final order problem is extended by including the possibility of alternative service called swapping policy. The Extended Final Ordering Problem (EFOP) reads as follows: \"`For a spare part used for service, find the final order quantity and the switching time to alternative policy that minimizes the expected total cost function over a predefined horizon given the possibility of switching to an alternative service policy before the end of the end-of-Life horizon\"'\r\nConsidering a non-homogenous Poisson process, as it is shown to be appropriate to represent the behavior of the final phase demand behavior, we develop a dynamic programming problem to find optimal solution. We assumed that all costs are exponentially discounted to the beginning of the horizon. Even though this assumption makes the problem more complicated but it is essential since in real world price erosion of the spare parts has a promising effect.\r\n", :title "Inventory Control of Spare Parts in the Final Phase", :keyword2 0, :authors (1752), :session 122}, 95 {:keyword1 18, :keyword3 63, :abstract "We consider a standard multicriteria decision making problem with finite numbers of decisions and criteria. For this scenario, many tools have been developed, ranging from outranking methods to multicriteria value functions, reference point methods, and others. Most of them are deterministic. This is not realistic, which precludes their use in scenarios of a strategic nature, which is what the models are designed for. Our contribution allows the payoffs to be random variables, and it develops tools that make the benefits and costs clearly visible to the decision maker in two-dimensional graphs, regardless of the size of the problem. \r\nSuppose that the outcome of decision i evaluated on criterion j is a random variable. For each criterion, the decision maker has specified an aspiration level (or an ideal point) as well as a lower cutoff point below which the decision is considered to perform less than satisfactorily. The probability distribution of the outcome is arbitrary, and it is expected to be modified in a sequence of sensitivity analyses. \r\nFor each decision, it is then possible to compute the expected outcome and the probability that a decision falls short of the prespecified lower cutoff point. Straightforward rules are developed to identify dominated strategies. We then find a single overall value. In particular, we use the weighted sum approach. Each combinations of weights results in a point in an outcome – risk graph for each decision. Plotting such points for all decisions in the graph allows us to identify the nondominated set. The proportion of a decision being included in the nondominated set given a number of reasonable scenarios will then allow the decision maker to define a ranking of decisions that may be a useful aid in the decision-making process. ", :title "Robust Decision Making Under Uncertainty", :keyword2 62, :authors (12245 1646), :session 98}, 97 {:keyword1 47, :keyword3 96, :abstract "This contribution uses a scenario from logistics to show that an evolution strategy approach can significantly add to the improvement of staff scheduling in practice. Rapid, sub-daily planning, which is the focus of our research, is a field which has been neglected in the literature so far. It offers considerable productivity reserves for companies but also creates complex challenges for the planning software. Modifications of the traditional evolution strategy method are required for a successful application to scheduling software. The results are compared to local search and particle swarm optimization.", :title "Sub-Daily Staff Scheduling using an Evolution Strategy", :keyword2 59, :authors (12953), :session 53}, 101 {:keyword1 25, :keyword3 0, :abstract "The size of a company is a significant internal variable determining production capacities, strategy, structure and managerial activities. The company's growth, size, centralization, specialization, formalization, and complexity are interconnected. Size is operationalized in a variety of ways: number of employees, number of products or services, total sales, etc. The interval of the data, as well as the classification of those data, is determined based on the experience, but also subjective perception of researchers. Authors Richard M. Burton and Børge Obel  worked out a special classification based on the number of employees adjusted for their level of professionalization, which measures the information-processing demand of a company. The adjusted-size measure is then mapped into small, medium and large companies. \r\nFocusing on the results of Richard M. Burton and Børge Obel we analyzed the need of introducing fuzzy set theory. We tried to give a contribution based on fuzzy logic to the determination of the company’s size. The idea was the relaxation of crisp gaps between some categories of the company’s size. In our opinion crispness in their classification can be changed by fuzziness. An algorithm of approximated reasoning was developed. It is necessary to emphasize the need of experts for defining the input and output fuzzy variables in the right way.  \r\n", :title "Adding fuzzy logic to a company’s size determination based on the results of Burton and Obel", :keyword2 39, :authors (), :session 148}, 102 {:keyword1 8, :keyword3 0, :abstract "In order to solve combinatorial optimization problems (COP) heuristic methods such as genetic algorithms (GA) can be used. The performance of such algorithms can significantly be increased by adapting them to the specific problem. One option is to replace or complement the random variation operators by problem-specific operators. But it is still open how to select an appropriate operator (from a set of candidates) and its application spot.\r\nThe \"`Genetic Conference (GC)\"' algorithm presented here uses a goal-oriented selection procedure for the operator and its application spot and thus offers a significant improvement over well-known random approaches.\r\n\r\nThe central idea is to combine a GA with a multi-agent system (MAS) in order to profit from the benefits of both approaches: The agents of the MAS enrich the GA with problem-specific methods for evaluating and modifying existing solutions. Each agent manages one of the underlying objects and is responsible for a part of the solution. Solutions to the problem are evaluated individually by each agent regarding various criteria. Based upon this evaluation an agent decides whether his part of the solution still has potential for improvement and chooses an appropriate variation operator. \r\n\r\nThe performance can further be improved by the use of individual agent memories. Each agent can store particularly favourable solution parts to reuse them in the later course of optimization.\r\n\r\nThe GC algorithm was implemented and adapted to three real-life optimization problems. These are: a location planning problem, the optimization of integrated periodic timetables, and a course assignment problem from the university domain. The three case studies have produced valuable results which have successfully been applied in practice.", :title "Integrating multi agent systems and genetic algorithms to solve combinatorial optimization problems", :keyword2 5, :authors (16752), :session 16}, 104 {:keyword1 68, :keyword3 0, :abstract "In this paper, we analyze a dual sourcing inventory model with stochastic lead times and constant demand in which the order quantity is split in some proportion between two non-identical sources of supply. Unlike earlier studies in order splitting literature a multi item model is considered where suppliers offer business volume discount. We proposed a mixed integer programming model to optimize the expected total cost. The model is optimized by determining the reorder point, order quantity and split proportion as decision variables. A solution procedure is also developed for solving the proposed model. ", :title "A Multi-Item Dual-Sourcing Model with Stochastic Lead-Time", :keyword2 101, :authors (16829 2886), :session 120}, 105 {:keyword1 101, :keyword3 8, :abstract "Generally, capital goods, such as military equipment or trains, are repaired by replacement. This means that a subsystem that failed is replaced by a spare. The subsystem can either be discarded or repaired. If it is repaired, then the subcomponent that failed is replaced by a spare. The subcomponent should in turn be repaired or discarded itself. A product is thus seen as a multi-indenture system.\r\nA manufacturer that sold a service contract can be responsible for achieving a certain availability of its products. The installed base can geographically be dispersed, so that it is necessary to have a multi-echelon repair network with locations where spares are located and/or repairs can be performed; e.g., a location per country (echelon 1) and a central depot (echelon 2).\r\nGiven a product design and a repair network, a level of repair analysis (LORA) shows for each component in the product (1) whether it should be discarded or repaired upon failure and (2) where to do that. The objective of the LORA is to minimize the total (variable and fixed) costs, taking into account, for example, that some testers can be used for multiple components.\r\nWe show that the LORA problem can be modelled as a minimum cost flow model with side constraints. This formulation enables us to extend the model to cover, amongst other things:\r\n- A certain probability of successful repair.\r\n- A step function in the fixed costs: If fixed costs are accounted to buy a tester, this tester cannot be used to test an infinite amount of components.\r\nWe performed tests on instances with a size realistic in practice and we can solve them in a reasonable amount of time. We based the tests on cases that we have seen at Thales Nederland, a manufacturer of naval sensors and naval command and control systems.", :title "Modelling extensions to the Level of Repair Analysis Problem as a Minimum Cost Flow Model", :keyword2 77, :authors (36644 2531 16852), :session 134}, 106 {:keyword1 37, :keyword3 0, :abstract "We present a feedforward neural network based apporach to forecast delivery times. The neural network models the distribution of the delivery time on the basis of a discrete probabilty distribution.\r\n\r\nThe forecasts are used to optimize the supply chain, i.e. triggering orders into the production such that the deliver ability and reliability is increased. Project results are presented to exemplify the benefits of the chosen approach.", :title "Forecasting Delivery Times with Neural Probability Distributions", :keyword2 101, :authors (14818 14946), :session 210}, 107 {:keyword1 37, :keyword3 5, :abstract "Our models are typically unfolded over a shorter time window than the original real world process. Thus we have an inconsistency at the beginning and at the end of our modeling. What is the consequence of this inconsistency? The talk presents two different approaches to lower the problem: 1) we can quest for the set of finite time models which are independent of the possible information from the outside time periods, or 2) we can design the finite model time as an expansion of the present time point. We apply the theory to the forecasting of energy prices.", :title "From Infinite Time to Finite Model Building", :keyword2 23, :authors (14818 14946), :session 182}, 108 {:keyword1 5, :keyword3 0, :abstract "Forecasting sales quantities is probably one of the most demanding tasks of a supply chain management. Accurate sales perspectives allow to decrease companies warehouse inventories help to maximize revenues and prohibit under- or over-purchasing of raw materials. Manufacturing or distribution bottlenecks are significantly lowered. As a consequence customer satisfaction is increased due to higher deliver reliability and capability. In addition, the procurement is supported by predicting raw material prices. We applied neural networks incorporat-ing prior knowledge about the application (e.g. temporal structure of sales quantities or market analysis) that are able to deal with fast changing market  dynamics and short product life cycles. \r\nRemarkably, neural networks allow to generate stable forecasts based on very small data sets. This is especially useful for predicting new products for which there is only little data available. In a feasibility study we have applied our neural networks to forecast the demand for the product group of a Siemens business unit. The forecast accuracy of the neural networks is significantly above 75\\% and outperformed conventional methods as used in common ERP-Systems.\r\n", :title "Demand Forecasting based on Recurrent Neural Networks", :keyword2 37, :authors (14817 14818 14946), :session 182}, 109 {:keyword1 94, :keyword3 0, :abstract "In many resource allocation problems, we are faced with environments that change continuously. These changes cause the return values of investment alternatives to vary during the planning horizon. An allocation of resources in such environments must be robust. In this paper we consider a new robust resource allocation problem. The proposed method of this paper consider an investment strategy where different investment alternatives may return in various time cycles and resources can be allocated only at the beginning of each period. We develop a mathematical formulation for the problem of robust resource allocation. The implementation of the proposed method is discussed through a numerical example.", :title "A Robust Optimization Model for Resource Allocation Problem", :keyword2 25, :authors (16854 17404), :session 139}, 110 {:keyword1 14, :keyword3 0, :abstract "Optimality conditions are given for nonlinear bilevel vector\r\noptimization problems in infinite dimensions. A new numerical method based on a multiobjective search algorithm with subdivision technique, is introduced for the determination of global solutions. Numerical results are presented for low dimensional nonlinear problems.", :title "Global Solver for Nonlinear Bilevel Vector Optimization Problems", :keyword2 0, :authors (14660), :session 78}, 111 {:keyword1 19, :keyword3 0, :abstract "The response mode bias is a well known empirical phenomenon in decision theory. Different methods of eliciting von Neumann-Morgenstern utility functions, which are theoretically equivalent, yield different results. This phenomenon occurs in particular when comparing the Certainty Equivalent (CE) Method, in which subjects are asked to provide a fixed monetary equivalent to a lottery, and the Probability Equivalent (PE) Method, in which subjects are asked for a probability which makes them indifferent between  lottery and a fixed payment. Typically in such experiments, subjects using the CE method exhibit a stronger risk seeking behavior, in particular in lotteries involving losses.\r\n\r\nIn this paper, we present results of an experimental study which extends previous studies in two ways: (i) we develop and use an innovative method for cardinal measurement of risk attitudes based n the Arrow-Pratt coefficient, and (ii) the experiment involves lotteries across a wide range of probabilities for winning or losing as ell as different payoffs. \r\n\r\nOur results show a reversal of the response mode bias for lotteries involving low probabilities compared to lotteries involving high probabilities. Replications of the experiments using lotteries both in the gain and loss domain also show that the result is robust across domains (with the expected reversal between gains and losses), and is replicable across several repetitions of the experiment.\r\n", :title "Response mode bias revisited – the \"`Tailwhip\"' effect", :keyword2 93, :authors (454 16856 15649), :session 106}, 114 {:keyword1 106, :keyword3 8, :abstract "We consider a logistics problem which can be seen as an intersection of a vehicle routing problem (VRP) with a graph partitioning problem. Given a set of cities with demand values our objective is to determine a partitioning of the cities into clusters and to compute a TSP solution for the cities in every cluster such that the sum of these tours is minimal. Unlike the classical VRP a common starting point for the vehicle tours is not required. We restrict the total demand values in every cluster with both upper and lower bounds. These do not only reflect capacity constraints but mainly aim for a balanced distribution of demand values between the clusters.\r\n\r\nAs an additional and rather unusual feature we are allowed to omit a certain fraction of cities from the solution. The total demand of the eliminated cities is bounded from above and cities with a demand exceeding a lower bound can not be omitted from the solution.\r\n\r\nOur problem arises in the planning of tours through cities in Austria where empty cigarette packs are collected in a study of the Austrian tobacco industry to produce evidence on the amount of cigarettes which are consumed but not bought in Austria.\r\n\r\nWe developed a heuristic algorithm which at first selects starting points for the tours by a criterion based on the farthest distances from previously determined starting points. Then each remaining city is added to one of the tours by an insertion heuristic which already takes into account the balancing and capacity constraints. The resulting tours are improved by well known methods.\r\n\r\nComputational experiments illustrate the achieved balance of the tours and the quality of the tour heuristic. A comparison to the previously performed tours shows that impressive savings are attained by our solution.\r\n", :title "A Balanced Vehicle Routing Problem", :keyword2 42, :authors (16855 12695), :session 156}, 115 {:keyword1 61, :keyword3 0, :abstract "Modeling systems support a wide collection of established mathematical programming classes through their MP solver clusters. The classical interface between a modeling system and a MP solver consists of passing on information about the constraint matrix and function and derivative evaluations for non-linear problems. With emerging new model types and advanced solver technology the need increased for exchanging more structural model information. We will present GAMS' new extended mathematical programming framework EMP that allows solving new model classes using mature solving technology.", :title "GAMS' Extended Mathematical Programming Framework", :keyword2 0, :authors (14778 7925 10544), :session 101}, 118 {:keyword1 34, :keyword3 37, :abstract "Mit der bevorstehenden Einführung von Basel II steht vor allem die Bewertung der Bonität von Kreditnehmern mittels Ratingverfahren im Fokus der Finanzinstitute. Dabei können entweder externe Ratings von Ratingagenturen oder interne Ratings angewandt werden, die sich aus bankintern entwickelten Ratingverfahren bestimmen. Die vorliegende Arbeit zeigt, wie man aus verschiedenen Ratings ein in gewissem Sinne \"`besseres\"' Rating konstruiert. Dazu betrachten wir den Rating-Status eines Kreditnehmers als zeitstetigen stochastischen Prozess mit endlich vielen Zuständen (den Rating-Klassen) und modellieren die Migrationen zwischen diesen Klassen als einen homogenen Markov-Prozess. Die Eigenschaften eines solchen homogenen Markov-Prozesses sind vollständig durch die Matrix der Migrationsintensität, den sogenannten \"`Generator\"', festgelegt. Da diese statistischen Methoden nicht allgemein bekannt sind, stellen wir diese zunächst kurz vor. Insbesondere zeigen wir, wie sich durch Kombination zweier mehrdimensionaler Migrationsprozesse, die Ratings zweier verschiedener Ratinggeber widerspiegeln, ein gemeinsames besseres Rating konstruieren lässt. Wir zeigen ferner mittels Monte-Carlo-Simulation, dass in der Tat die Qualität des kombinierten Ratings besser ist als jedes einzelne und wenden dann diese Theorie auf konkrete Ratinghistorien von Firmen an, die sowohl von einer großen deutschen Bank als auch von Standard \\& Poor's ein Rating haben. Ferner untersuchen wir, wie das ökonomische Kapital einer Bank durch die unterschiedlichen Schätzungen von Ratingmigrationen beeinflusst wird.", :title "Die optimale Kombination interner und externer Ratings", :keyword2 35, :authors (16866 16867 16869), :session 90}, 119 {:keyword1 76, :keyword3 88, :abstract "We consider a single intersection of roads that is controlled by traffic lights. For each traffic flow f leading to the intersection cameras and/or induction loops measure the number of cars approaching the intersection and their distances as well as the number of cars (qf) waiting at queue f. We model the control in discrete time to acknowledge a fixed switchover time when a light changes from green to yellow to all red. When a light shows green one either keeps it green or turns it into yellow. An optimal policy for controlling the lights in view of minimizing the overall long-run average waiting time is intractable due to the number of states in the high dimensional state space. An optimal control policy acknowledges next to (q1, q2, ..., qF) and the signal state (l), the number of cars that is expected to reach the end of the queue i time units from now (afi). The state is thus (l, (q1, a11, a12, ..., a1I), ..., (qF, aF1, aF2, ..., aFI) ). With only F = 4 traffic flows and I = 5 time units of arrival information the state space consists already of 25 dimensions. Even when no arrival information  is taken into account (I = 0) an MDP approach is hampered by the number of states. An approximate policy is constructed by executing a single policy improvement step over fixed cycle control (FC). Under FC the state space is decomposed into subspaces related to each traffic flow. For each flow in isolation of all other flows we formulate a Markov chain and numerically compute relative values of the states under FC. By simulation we test a new policy based on a single policy improvement step over FC. The results indicate a great reduction of the overall long-run average waiting time compared to FC and exhaustive control, even when no arrival information is taken into account.", :title "An MDP approximation for clever traffic lights that use arrival information", :keyword2 99, :authors (9558), :session 132}, 121 {:keyword1 94, :keyword3 19, :abstract "Intense competition in the current business environment leads firms to focus on selecting the best R\\&D project portfolio among available projects in order to survive and accomplish their sustainable growth in the fierce market place. Achieving this goal is tied down by uncertainty which in inherent in all R\\&D projects and therefore, investment decisions must be made within an optimization framework accounting for unavailability and unreliability of data. In this paper, such a model is developed to hedge against the R\\&D uncertainty. The robust optimization approach is adopted and the problem is formulated as a robust zero–one integer programming model that can handle uncertain parameters to determine the optimal project portfolio. A transformation method is utilized to convert the resulting model into a standard mixed zero-one linear programming model, and an optimization technique is used to solve the problem. An example is used to illustrate the proposed approach.", :title "A Robust Optimization Approach to R\\&D Portfolio Selection", :keyword2 35, :authors (16872 1054), :session 19}, 124 {:keyword1 75, :keyword3 97, :abstract "This paper presents a linear programming approach to analyze and optimize flow lines with limited buffer capacities and stochastic processing times. The basic idea is to solve a huge but simple linear program that models an entire simulation run of a multi-stage production process in discrete time, to determine a production rate estimate. As our methodology is purely numerical, it offers the full modeling flexibility of stochastic simulation with respect to the probability distribution of processing times. However, unlike discrete-event simulation models, it also offers the optimization power of linear programming and hence allows to solve buffer allocation problems. We show under which conditions our method works well by comparing its results to exact values for two-machine models and approximate simulation results for longer lines.", :title "Using linear programming to analyze and optimize stochastic flow lines", :keyword2 78, :authors (16870 10255), :session 147}, 128 {:keyword1 101, :keyword3 75, :abstract "Nowadays, manufacturing in process industries mostly takes place in branched supply networks consisting of several plants which are located at different sites and linked by complex logistics relations and material flows. Thus, a key issue of production planning and scheduling is the coordination of plant operations at different production stages considering the supply of intermediates and their transportation between various plants. This planning effort has to cope with the limited availability of resources as well as conflicting resource allocations and numerous storage and transportation constraints. Time-consuming and expensive setup and cleaning activities require production to be carried out in so-called campaigns. Identical production tasks are repeated in succession to reduce these unproductive times. We present the final results of an application-oriented approach for supply network planning in the chemical industry which is based on a novel network flow formulation of the problem motivated from scheduling theory. The optimization procedure is based on an extended disjunctive graph model and uses a continuous representation of time. Our approach generates a comprehensive schedule for coordinating the production activities at all plants in the network.", :title "Network-wide campaign planning in chemical industry using extended disjunctive graph techniques", :keyword2 96, :authors (14952 909), :session 49}, 130 {:keyword1 96, :keyword3 48, :abstract "In our talk we deal with the short-term planning problem of multistage continuous multiproduct plants. This problem can be decomposed into an operations planning and an operations scheduling problem. The operations planning problem consists in fixing the processing times, the production rates, and the input and output proportions of the continuous operations to be executed. The scheduling of the operations assigns a processing unit and a start time to each operation subject to constraints on the availability of input materials, storage capacities, and sequence-dependent changeover times. The operations planning problem can be formulated as a nonlinear optimization problem of moderate size. The scheduling of the operations is performed using a novel mixed-integer linear programming formulation of the problem.\r\n\r\nTo obtain a feasible production schedule it is necessary to anticipate the maximum inventory stock levels of the intermediate products via an upper bound in the planning model. As a consequence, after the scheduling of the operations, the production rates could often be increased without changing the precedence relationships between the operations. That is why we go back to the operations planning phase, where we re-optimize the operating conditions of the operations in such a way that we can guarantee the existence of a feasible solution to the operations scheduling problem. We proceed with re-scheduling the operations and iterate the planning and scheduling phases until a fixed-point solution has been reached. This closed-loop procedure has been implemented under GAMS using CPLEX and CONOPT as solvers. The method is able to find good feasible schedules for complex benchmark instances within less than five minutes on a standard PC.", :title "An integrated approach to continuous process planning and scheduling", :keyword2 75, :authors (13057 930), :session 49}, 132 {:keyword1 77, :keyword3 0, :abstract "In the consumer goods as in many other industries multi-site production planning has emerged as one of the most challenging problems during the recent years. As a result, the focus in production planning and scheduling is shifting from the management of plant-specific operations to a holistic view of the entire supply chain comprising value adding functions like purchasing, manufacturing and distribution. Consequently, in order to improve the performance of the entire logistic chain, operational planning systems have to be established which allocate the forecasted product demand between plants at various locations, determine the distribution of final products to warehouses or directly to major customers, and generate detailed schedules for manufacturing the required quantities of products at the various sites. The intention of our presentation is to develop an integrated mixed-integer linear programming model for production and distribution planning in consumer goods supply chains. Its specific contributions are the incorporation of cyclical patterns according to the block planning concept proposed by Günther et al. (2006) into the production model and the integration of a distribution model that considers different modes of transportation between the plants and the distribution centres in a supply chain.", :title "A mixed-integer linear programming model for production and distribution planning in consumer goods supply chains", :keyword2 25, :authors (15118), :session 118}, 136 {:keyword1 106, :keyword3 0, :abstract "\tSea Motorways link goods origin and destination places, when the part of transportation is made by regular Sea transport. Transport means are linked on regularity Sea transport basis, to which are linked other transport systems such as railways, road and must be sustainable in technical, technological, organisational and legal aspects.\r\n\tSustainability and optimisation of the main transportation aspects finally influence on decreasing transportation costs and time, increasing cargo safety and security in all aspects and finally increases goods competitiveness.\r\n\tPossible functional and mathematical models, which have to be tested in real transportation processes, opportunities and weaknesses were studied and presented in the Sea Motorways models.\r\n\tSea Motorways as Logistics chain optimisation mechanism can make influence on all production chain and finally on regions economical activity and development. \r\n\tInterfaces on transport mean links are important for theoretical and practical studies, because interfaces have the biggest influence on Sea Motorways function as in logistics chain at all.\r\n", :title "Sea Motorways as Logistics Chain Optimisation Instrument", :keyword2 0, :authors (16882), :session 32}, 138 {:keyword1 92, :keyword3 99, :abstract "This paper deals with the dynamic routing of product returns with quality problems. Several small scaled firms besides the Origianl Equipment Manufacturer (OEM) are available in provision of remanufacturing service. At the end of the process the products will be reselled at the secondary marketplace, such as ebay. The stream of the product returns follow a stochastic process. A central controller is employed to decide to which firm an incoming product is sent to avoid excessive queues in front of some particular firms. We develop models and index-based heuristics to support the dynamic allocation decisions so as to minimise the overall recovering costs for the OEM. The product concerned exemplifies a short-life cycle. Long delay during the remanufacturing process will render a substantial deterioration of reselling prices. Hence, in the paper we contend that the cost incurred for remanufacturing a product should take explicit account of the impact of the long delays in the lead time. Both theoretical and numerical work demonstrate that the effectiveness of the Restless Bandit (RB) approach deployed to the dynamic routing of product returns among multiple agents.  ", :title "Dynamic routing of product returns for remanufacturing", :keyword2 95, :authors (16885), :session 93}, 140 {:keyword1 40, :keyword3 0, :abstract "Für Industrieunternehmen ist es wichtig, ihre Bestellmengen zu optimieren. Sie wirken sich auf die Lagerhaltung und Beschaffung aus und beeinflussen Servicegrad und Produktionsbereitschaft. Fehlerhaft bestimmte Losgrößen führen zu höheren Kosten und Gewinneinbußen, welche die Unternehmensleitung zu vermeiden sucht. Insofern erwartet sie vom Disponenten der Materialwirtschaft, dass er optimale Bestellmengen verwirklicht. Das wird in der Regel durch einen Controller überprüft, welcher der Unternehmensleitung berichtet. Die Interaktion zwischen Disponent und Controller kann durch ein modifiziertes Inspection Game beschrieben werden. Während in Fandel/Trockel 2008 untersucht worden ist, wie das Nash-Gleichgewicht des Disponenten-Controller-Spiels in gemischten Strategien von den fest vorgegebenen Payoffs und der Aufdeckungswahrscheinlichkeit der Unternehmensleitung abhängt, wird in diesem Beitrag analysiert, wie sich die Wahrscheinlichkeiten verändern, mit denen die gemischten Strategien im Gleichgewicht gewählt werden, wenn die Höhe der Strafzahlungen für den Disponenten und den Controller von dem Ausmaß bestimmt werden, in dem die Kosten der fehlerhaften Materialdisposition von denen im Optimum abweichen. Dabei zeigt sich, dass die Strategienkombination (Festlegung der Bestellmenge nach Gutdünken; niedriges Prüfniveau) mit geringeren Wahrscheinlichkeiten als Nash-Gleichgewicht des Spiels auftritt, als wenn die Strafzahlungen für Disponent und Controller unabhängig vom Ausmaß der Kostenabweichung sind.\r\n\r\n(Referenz:\r\nFandel, G., Trockel, J., 2008. Stockkeeping and controlling under game theoretic aspects. Discussion paper, No. 420, FernUniversität in Hagen)\r\n", :title "Der Einfluss von Kostenabweichungen in der Beschaffung auf die Wahrscheinlichkeiten in einem nicht-kooperativen Spiel", :keyword2 109, :authors (16883 16887), :session 190}, 141 {:keyword1 16, :keyword3 0, :abstract "We consider the problem of finding a suitable placement of solar cells on the roof of a building. Since roofs may be of nonrectangular shape and may have obstacles like chimneys, dormers or windows on them, finding an optimal layout is not a trivial task. Mathematically, this setting belongs to the class of cutting and packing problems, with an additional difficulty in the shape of the disposable roof area: existing approaches do not cover our situation where we deal with nonconvex roofs. We develop a mixed integer linear model for this problem and present an enhanced version of the classical bottom-left heuristic. Examples demonstrate that this new approach considerably improves traditional strategies.", :title "Packing Solar Cells on a Roof", :keyword2 0, :authors (2481 16890), :session 24}, 143 {:keyword1 56, :keyword3 0, :abstract "Diffusion of complex products and systems (CoPS) in the private consumer market is combined with uncertainty and specific risk. Because of their unique structure, CoPS are distinguished by a high number of components in hierarchical and interconnected relationships and are project-oriented and customized manufactured (Davies, Hobday 2005). Interconnection between first and later purchases as well as the added value of the combination of product components cause special product development, production and commercialization process. Due to the fact of high product complexity, CoPS have a slowed diffusion (Rogers 1995). Therefore it is essential investigating the diffusion of CoPS and their influencing factors. The use of system dynamics methodology allows the development of complex and dynamic models for analysing the diffusion of CoPS. It is a useful instrument for a better understanding of the problem structure, the feedback, time delays and dynamics between different variables. This paper analyses the network externalities in the diffusion process of CoPS in a System Dynamics model and considers the attitude of private households to high technology products as CoPS. Results of a current field research support the development of the model structure and the validation. \r\n\r\nLiterature:\r\nDavies, A., Hobday, M. (2005): The Business of Projects – Managing Innovation in Complex Products and Systems, Cambridge, Cambridge University Press;\r\nRogers, E. M. (1995): Diffusion of Innovations, United States of America, The Free Press", :title "Influence of adopters attitude on diffusion of complex products and systems", :keyword2 103, :authors (16898), :session 155}, 147 {:keyword1 8, :keyword3 0, :abstract "In this talk we first investigate the inverse 1-median location problem on d-dimensional real spaces in which the task is to modify the coordinates of n existing points at minimum total cost within specific bounds so that a prespecified point becomes the 1-median. We develop O(dn)-time exact solution methods for the problem under investigation, provided that the distances are measured in Manhattan norm or squared Euclidean norm. Moreover, it is shown that a special model of inverse p-facility median location problem can be solved in polynomial time on a d-dimensional real space endowed with the squared Euclidean metric.", :title "Inverse Median Optimization Problems with  Point  Coordinates Variation", :keyword2 54, :authors (16845 128 15233), :session 205}, 148 {:keyword1 106, :keyword3 96, :abstract "Since April 2007 the new EC Regulation No 561/2006 concerning driving hours of drivers in road transport is effective. This regulation restricts the length of time periods for driving and requires minimum breaks and rest periods for drivers. Although compulsory for all member countries of the EC and therefore of high practical importance this regulation has attracted little interest in optimization models for vehicle routing and scheduling so far. Especially the restrictions for the accumulated driving times during several days and the optional extensions of driving times are widely neglected. In this paper the terms of the EC Regulation No 561/2006 are presented and their impact on vehicle routing and scheduling is shown. The restrictions on driving times and the need for breaks are formalized and integrated in an optimization model of the TSPTW. The solution space of the extended model (TSPTW-EU) contains all Hamiltonean circuits which fulfil the restrictions of the regulation relevant for a time period up to one week. The presented model TSPTW-EU describes the planning situation of a driver in case that he is allowed to decide on the sequence of customer visits. If this sequence is fixed by the scheduler in advance, the entire problem of route scheduling has to be solved by him respecting the limitation of driving times and the demand for compulsory rest periods. The approach for extending the TSPTW to the TSPTW-EU is also applicable for the extension of the VRPTW and PDPTW, thus offering a possibility to include the EC-Regulations in vehicle routing and scheduling.", :title "A Model for the Traveling Salesman Problem including the EC Regulations on Driving Hours", :keyword2 95, :authors (15277), :session 64}, 150 {:keyword1 47, :keyword3 40, :abstract "We study the reputational effects on the behavior of a manager, who has newly joined a company and is taking over business from his predecessor, within a game theoretic model. This new manager has to decide about cancelling ongoing projects and replacing them with projects of his own or leaving them as they are. We consider a situation of incomplete information where the manager only has a signal about each project's profitability based on internal accounting information. It is assumed that the manager not only wants to increase company's profit but also his outside market reputation. As a key result it is shown, that for reputational reasons especially high ability managers may have incentives to cancel ongoing projects disregarding any indications about project's profitability. A direct consequence of this is that for well performing companies there may be reasons to hire someone less talented rather than a manager with a reputation of high ability, who is more interested in change than in the company's profit.  Thus, the company owner's hire decision should not only be based on reputation but also on the project specific company performance and the need/disneed for strategic change. \r\n\r\nIn a second step the model is extended to a situation where the owner has to decide whether to keep or fire an incumbent manager based on internal accounting information. It is shown that only in situations where all signals indicate a strategic failure, management turnover truly enforces strategic change.", :title "Reputation and New Managers - Change as an Instrument of Leaving ones Footprint", :keyword2 19, :authors (), :session 82}, 152 {:keyword1 96, :keyword3 0, :abstract "Nowadays, a good balanced assembly line is a very important factor in modern manufacturing companies. Even small differences in assigning of tasks on workstations can cause great profits or losses for producers. The line efficiency, time of the line and smoothness index are the basic measures in estimation of final results. The problem of balance and in single assembly line is discussed. Also a problem of the last station is shown and a modified smoothness index is presented. In the second part of the paper two-sided assembly line is considered. The structure is easy to find in manufacturing factories where the assembly of final products needs a special position. Balance of two-sided lines is more difficult to obtain then for single lines. The two-sided structure consists of mated-stations and the solution depends on  the precedence graph and position constraints. In a one-sided assembly line, if precedence relations are considered appropriately, all the tasks assigned to a station can be carried out continuously without any interruption. However, in a two-sided assembly line, some tasks assigned to a station can be delayed by the tasks assigned to its companion. In other words, idle time is sometimes unavoidable even between tasks assigned to the same station. In this case it is important to introduce additionally measures because the existed smoothness index is to general to describe the final result of the balance. Author of the paper introduces an modified smoothness index for each position of the line and discuss about the efficiency of mated stations. The new measures allow to get a detailed knowledge of the balanced line. As a conclusion, a comparison of final results of single and two-sided assembly line is given ", :title "Single and Two-sided Assembly Line Balancing Problem – Comparison of Final Results", :keyword2 0, :authors (16874), :session 57}, 154 {:keyword1 5, :keyword3 62, :abstract "Starting in the 1950's, it took four decades until \r\ncomputers really became masters in the game of chess. \r\nIn the 80's  the AI community began to transfer\r\ntechniques from computer chess to other games.\r\nIn the meantime there even exist programs that \r\nintelligently play relatively large classes of games \r\n(the human user only has to formulate the rules\r\nof the game). \r\n  \r\nSuch software can also be used to test newly invented games. \r\nWe report on several steps of progress:\r\n* Software from our group helped to design the game FINALE\r\n(published by Noris in 2006; new edition for the European\r\nChampionship 2008)\r\n* Our software explains why the game \"`EinStein würfelt\r\nnicht\"' turned out to be so successful.\r\n* In the last few years there was a breakthrough\r\nin Monte-Carlo type techniques in game tree search (UCT and\r\nothers), allowing to handle much larger classes of games\r\nthan before.\r\n   \r\nIt is only a question of time when the first fully\r\nautomatically invented board game will enter the market.\r\n", :title "Computer-Aided and Automatic Game Inventing", :keyword2 40, :authors (16894), :session 104}, 155 {:keyword1 18, :keyword3 0, :abstract "Concerning increasing carbon emissions and resulting climate change discussions, methods to assess corporate carbon emissions gain importance in research and practice. However, sophisticated methods that model and evaluate all emissions along the life cycle of a product are complex, time consuming, and thus costly. Furthermore, companies need to be responsible for their whole product range. Existing approaches use aggregated figures or ratios and decision support is limited. Planning models on a disaggregated level dispose carbon emissions isolated from other decision variables like costs, use subjective weighting methods or monetize the carbon emissions. However, a transparent and integrated method for decision support does not exist.  \r\nAgainst this background, a concept for the implementation of carbon emission accounting indicators into decision-making processes is developed. The concept exists of different aggregation levels and their connections: On the level of external performance measurement, a company chooses an adequate figure to evaluate its own emission-intensity. To control this intensity, more information is needed. On the level of internal performance measurement, sub-organizational units like sites can be arranged in a portfolio displaying improvement opportunities for economic and ecological aspects. Finally, on the level of internal planning, carbon emissions and costs are improved simultaneously by implementing carbon emissions in existing models. The effects of the chosen improvement options are mapped on the level of internal performance measurement. Within the contribution, the concept as well as an application to a case study will be presented\r\n", :title "Integration of carbon efficiency into corporate decision-making", :keyword2 31, :authors (2650 2651), :session 92}, 157 {:keyword1 98, :keyword3 48, :abstract "AIMMS is an advanced modeling system for building optimization-based decision support applications and sophisticated planning systems. Its intuitive modeling environment enables you to quickly define and modify a mathematical model, and its integrated visualization tools enable you to construct a graphical user interface around it. AIMMS offers links to many solvers (such as XA, CONOPT, CPLEX, Xpress, BARON, etc) and advanced algorithmic capabilities such as column generation, stochastic programming, Benders decomposition, and MINLP outer approximation.\r\n\r\nWe will illustrate with real-life cases how companies in many industries use AIMMS to solve complex business problems. The transparent model definition in AIMMS facilitates interaction with the problem owner, leading to a better model. The mathematical model is easily made into a fully-operational optimization application, enabling business users to experience directly the power of OR.\r\n\r\nWe will also illustrate how universities use AIMMS to teach Operations Research very effectively. Students do not have to learn a programming language. From the start, they can focus on problem analysis and try out various model formulations. The integrated visualization enables quick inspection of results and interactive model refinement.\r\n", :title "Solving Business Problems and Teaching OR with AIMMS", :keyword2 18, :authors (10929), :session 101}, 158 {:keyword1 96, :keyword3 48, :abstract "We consider the problem of scheduling a given set of operations on a multistage continuous multiproduct plant. Such a production plant consists of several multipurpose processing units operated in continuous mode and storage facilities for stocking raw materials, intermediates, and final products. The final products arise from a sequence of chemical or physical operations transforming input materials into one or several output products. During the execution of an operation, the material continuously flows through the processing unit. After the completion of an operation, the processing unit has to be cleaned before the next operation can be started, the cleaning time depending on the operations sequence. The continuous process scheduling problem consists in assigning a processing unit and a start time to each operation in such a way that during the execution of the operation, the processing unit, sufficient amounts of the input materials, and sufficient storage space for stocking the output products are available and a given regular objective function is optimized. For solving this scheduling problem we present a novel mixed-integer linear programming formulation as well as a fast priority-rule based scheduling heuristic. In difference to prior schedule-construction methods, the new heuristic is able to deal with the material-availability and storage-capacity constraints within one phase. Violations of the storage capacities occurring in a partial schedule are resolved via an unscheduling technique that is based on temporary latest start times arising from lower approximations on the inventory profiles. The heuristic is able to find good feasible schedules for complex benchmark instances within a few seconds on a standard PC.", :title "Exact and heuristic methods for continuous process scheduling", :keyword2 75, :authors (930), :session 49}, 159 {:keyword1 42, :keyword3 0, :abstract "The performance of the A*-algorithm for the shortest path problem can be sped up by improving the estimator for the remaining distance to the target. In real world road-network problems, the Euclidian distance (air-line) is often used as an estimator.\r\nThis estimator neglects obstacles like mountains or rivers and can yield too optimistic estimations. These, in turn, lead to more iterations within the A*-algorithm as discussed in [2]. A promising approach to overcome this problem is to incorporate segmentation lines (SegLines) modelling the extent of obstacles, and to use them in order to construct an auxiliary graph yielding a better estimator. While other A*-enhancements (e.g. [3,4]) require heavy preprocessing and/or data storage, this approach relies exclusively on very little additional map data, i.e. the SegLines. First benchmarks in [1] show a speedup of up to 25% (in number of iterations needed by the A*-alg.), depending on the number and quality of SegLines.\r\nThe paper shows techniques for finding SegLines algorithmically, evaluating their impact and how to efficiently make use of them.\r\nReferences: \r\n1. Hahne, F., Nowak, C., Ambrosi, K. (2007) Acceleration of the A*-algorithm for the shortest path problem in digital road maps, Operations Research Proceedings 2007, Saarbrücken.\r\n2. Hahne, F. (2000) Kürzeste und schnellste Wege in digitalen Straßenkarten, Dissertation, Universität Hildesheim.\r\n3. Goldberg, A.V., Harrelson, C. (2004) Computing the Shortest Path: A* Search Meets Graph Theory, MSR-TR-2004-24, MS Research.\r\n4. Sanders, P. Schultes, D. (2005) Highway hierarchies hasten exact shortest path queries, in: Brodal, G.S., Leonardi, S. (eds), Proc. 17th ESA, Springer, 568-579.", :title "Performance of the A*-algorithm with segmentation lines on digital road maps", :keyword2 106, :authors (14704 14705 14803), :session 75}, 160 {:keyword1 8, :keyword3 58, :abstract "A standard problem in intensity modulated radiation therapy (IMRT) is the representation of a given intensity matrix, i.e. a matrix of nonnegative integers, as a nonnegative linear combination of special 0-1-matrices, called segments. These segments can be practically realized by multileaf collimators (MLC) that are used to modulate the radiation. The task of exact decomposition is well studied and a variety of algorithms are available, both for the unconstrained case and the case where technical side constraints are regarded. One important aim is the minimization of the sum of the coefficients of the linear combination, i.e. the delivery time (DT).\r\nThis work deals with an approximation problem and aims at reducing delivery time by allowing certain deviations between the given and the actually realised intensity matrix from the segmentation process. After formulating the approximation problem, we characterize the optimal solutions for one-row matrices and show that the approximation can be carried out in an iterative way. The structural characterization yields a fast algorithm that minimizes the delivery time and then also the deviation.\r\nMoreover, algorithms for the general case (matrices with an arbitrary number of rows) as well as numerical results are presented.\r\n", :title "Approximated matrix decomposition for IMRT planning with multileaf collimators", :keyword2 10, :authors (), :session 23}, 161 {:keyword1 99, :keyword3 106, :abstract "We consider a two-level supply chain structure of one downstream stock keeping unit (SKU) that is supplied with material by two or more preceding SKUs. Objective of our analysis is the replenishement lead time of the downstream SKU induced by the combined performance of the preceding SKUs. The lead time of the latter is influenced by material transformation times as well as material delay times caused by unavailability at a preceding SKU. For every SKU, we assume a periodic-review order-up-to (r,S)-policy with discrete empirically distributed lead times and normally distributed customer demand for the downstream unit. Stochastic dependencies are due to the common demand process where a stock-out of one SKU, for instance through an occurrence of extraordinary high demand, significantly rises the stock-out probability of all other preceding SKUs.\r\nWe discuss several approximation formulas with varying degrees of stochastic dependency and computational effort.\r\n", :title "Stochastic Dependencies in Converging Supply-Chains", :keyword2 100, :authors (13059 1131), :session 211}, 162 {:keyword1 91, :keyword3 0, :abstract "The kind of relationship between decentralized departments determines the objective of coordination as well as the applicability of several coordination instruments. This paper examines two decentralized departments of one company joining a cross-firm value network. These two departments produce and sell two goods being complementary to each other. The focus lies on a situation where one department states the quantity of its product and hence the quantity of the complementary good. The other department can make a specific investment affecting the revenue of both goods by increasing customer demand and willingness to pay. In this context two decisions have to be coordinated: The decision about the produced quantity and the investment decision. Coordination instruments are used to improve the reconciliation between the departments. This paper compares a contribution margin based, a revenue based and a quantity based compensatory payment as coordination instruments for inducing efficient quantity and investment decisions as well as overall profit maximization. Two of the interesting implications are that a revenue based compensatory payment does not directly influence the decision about the produced quantity and a quantity based compensatory payment has no direct effect on the investment decision. As a general result, conditions are identified for which ordained coordination instruments dominate other mechanisms with respect to the expected firm wide profit.", :title "Coordination of Decentralized Departments at Existing Sales Interdependencies", :keyword2 55, :authors (14685), :session 81}, 163 {:keyword1 8, :keyword3 0, :abstract "   In the works of Perepelica V.A., Kochkarov R.A., Sergeeva L.N. the properties of fractal graphs were learned from different points of view. On basis of these works social and economical system models were created and that moves up theoretical development into the category of up-to-date practical model tools.\r\n   The authors extended the classical graph definition by introducing the fractality concept with edge-seed instead of classical vertex-seed substitution.  It made possible to extend the features of existent theory.\r\n   This work suggests an extension of edge-seed fractality concepts considering not only structural changes in form of vertex- or edge-seed substitution, but also integration (reinforcement) of connections between system elements.\r\n   Obviously that structural dynamics is expressed not only by increasing of the system size or the size of a system part, but also by the connection reinforcement between components which interact with each other for a long time.    \r\n   For example, load on communications which are located in the center of the city increases after certain period of time both due to population density increasing and the tear of communications. Relations between social net members consolidate after certain period of time (as a trend).\r\n   For graphs with such structure we created the enumeration methodology, the subgraph allocation algorithm (for subgraphs which have certain structure features) and the seed recognition algorithm.\r\n\r\n", :title "Fractal graph with dynamic connection weights", :keyword2 23, :authors (16806 17361), :session 18}, 165 {:keyword1 105, :keyword3 0, :abstract "In the examination timetabling problem we are given a set of exams, for each exam a list of participating students, a set of time slots in a fixed time horizon, and rooms with certain capacities. The objective is to find a schedule in the given time slots such that no student has two exams simultaneously, the room capacities are satisfied, and several soft constraints are fulfilled as good as possible.\r\nThe problem can be modeled as a resource-constrained project scheduling problem (RCPSP) where the exams correspond to activities and resources are introduced for rooms and students. Based on such a model we propose a two-stage approach where at first a timetable is determined and afterwards a corresponding room assignment is \r\ncalculated. Computational results are reported for real-world instances from the department of economics at the University of Osnabrueck.", :title "Examination timetabling based on resource-constrained project scheduling", :keyword2 96, :authors (14742 16917), :session 53}, 168 {:keyword1 16, :keyword3 0, :abstract "\r\nThe following 2D  covering problem is considered:\r\nLet be given a collection of  rectangles and a target compact polygonal region.\r\nDecide whether there exist translation vectors for the rectangles \r\nsuch that  the union of the translated rectangles cover the target polygonal region, or not.\r\n\r\nIn our investigations  the covering rectangles can  be different from each other,\r\nand the target polygonal region can be  a nonconvex multi-connected  compact object.\r\n\r\nWe construct a mathematical model of the covering problem based on a special function.\r\nThis function is a mathematical tool for the analytical description\r\nof relationships between the collection of translated covering rectangles and the\r\ntarget polygonal region.\r\nIn so doing we formalize a cover criterion using  the \\Phi-function technique, \r\ni.e. if the target polygonal region is completely contained \r\nwithin the union of translated rectangles\r\nthen the constructed \\Phi-function for the region and the complement\r\nof the union of translated rectangles has to have a nonnegative value.\r\n\r\nThis covering problem is multi-extremal and NP-complete.\r\nTherefore, we apply a modification of an exact branch-and-bound algorithm. \r\nWe realize the  search for a covering by constructing a search tree and \r\nby using of appropriate termination  rules. \r\nThe search ends either with  translation vectors for the covering rectangles, \r\ni.e. with a covering,\r\nor with the result that there does not exist  a cover,\r\n or with the statement  that we can not find a cover.\r\n\r\nComputational tests show that the running time\r\nsubstantially depends on the number of rectangles.", :title "Covering a polygonal region by rectangles", :keyword2 8, :authors (16923 11875 8142), :session 179}, 170 {:keyword1 35, :keyword3 0, :abstract "Which information affects actual and future stock performance? Particularly for academics, which puzzle over the reversal effect and the book-to-market effect, it is unavoidable to deal with this question. These two effects are often tried to be explained either with the aid of asset pricing models (systematic risk) or with non-rational behaviour of the market participants – namely an overreaction to past firm performance.\r\nTo analyse, whether investors really overreact to financial performance, or whether they also account for other factors (e.g. growth options), we decompose past individual firm returns into two components. While the tangible return is based on accounting performance measures (tangible information), the intangible return describes the part of stock performance, that cannot be explained by accounting measures of past performance, and thus reflecting further factors, such as intangible assets or future growth options (intangible information).\r\nOur empirical analysis is based on all companies of the DJ EURO STOXX TMI over the period 1997-2006. We find that past accounting performance (tangible return) does not affect future stock returns, and thus, investors react appropriately to accounting performance measures over a longer period (five years). On the other hand, we detect a strong negative relation between the intangible return and future stock performance. It is shown, that this return reversion concerning the intangible return can neither be explained with established asset pricing models (e.g. CAPM) nor in an appropriate degree by means of behavioural explanation approaches. Concluding, we discuss how existing asset pricing models could be adjusted or extended – based on the new findings – to achieve a better explanatory contribution.", :title "Influence of financial and intangible information on stock returns – An empirical analysis of European companies", :keyword2 34, :authors (16875 10309), :session 86}, 172 {:keyword1 106, :keyword3 96, :abstract "Difficult financial situations in most German cities and increasing competition in waste management between private and public companies require an efficient allocation of all resources that are involved in the waste disposal process. The two major resources are waste collection vehicles and crews. They can be assigned to the corresponding planning steps of finding so called waste collection districts and appropriate crew schedules. Each waste collection district is a part of a given overall waste disposal area and represents a determined set of households that have to be disposed on a single day of a given period by one vehicle. Our paper focuses on the optimization of the crew scheduling process where different crews have to be allocated to specific waste collection districts and vehicles respectively. First, we outline the process of waste disposal in Germany and shortly discuss all aspects concerning the scheduling of crews. This includes different crew compositions, i.e. one driver and a variable number of crew members handling the waste bins, territory knowledge and hard rules based on legal or company restrictions for working times or breaks. Soft rules like a balanced age structure within the crews or meeting different desires of employees also have to be considered. Second, we present in detail new integer programming models for this real world crew scheduling problem. In order to handle the complexity of the given NP-hard problem we intend to apply column generation and lagrangean relaxation approaches. Finally, first computational results based on practical data sets and areas of future research like an integrated optimisation of waste collection districts, vehicles and crews are pointed out.\r\n", :title "An Optimization Approach for the Crew Scheduling Problem in Waste Management", :keyword2 77, :authors (), :session 72}, 174 {:keyword1 106, :keyword3 0, :abstract "One of the major planning problems in seaport container terminals is the Berth Allocation Problem. It comprises to determine berthing times and berthing positions for calling vessels. Usually, the decisions are made with respect to service quality objectives, such as the minimization of vessel waiting time or the minimization of tardy departures. \r\n\r\nToday, many container terminals in seaports face high congestion due to tremendous growth rates of maritime container transport. Achieving high service quality becomes more and more difficult for these terminals. Recent studies on the Berth Allocation Problem handle terminal congestion by rejecting vessels if their service can not be fulfilled within preset time windows. \r\n\r\nNevertheless, in practice, vessel operators prefer to use a so called Cut-and-Run option. Cut-and-Run means to start handling of a vessel but interrupt the service once a due date is met, regardless of any unprocessed workload. This enables to keep vessels within the liner service schedules without having to accept a complete rejection at a terminal. Obviously, in presence of a Cut-and-Run option, high service quality means to maximize the processed workload of vessels or, from another point of view, to minimize the unprocessed workload.  \r\n\r\nIn the talk, we present a mathematical formulation of the Berth Allocation Problem with a Cut-and-Run option. We incorporate the assignment of quay crane capacity to vessels into the berth planning. This enables to measure the processed workload of vessels precisely. We present a meta-heuristic which performs well on a set of real world like problem instances.\r\n", :title "The Berth Allocation Problem with a Cut-and-Run Option", :keyword2 0, :authors (13086 14707), :session 58}, 175 {:keyword1 16, :keyword3 0, :abstract "Layouting items in a 2D-constrained container for maximizing item value and minimizing wasted space is a 2D Cutting and Packing problem. We consider this task in the context of layouting news articles on fixed-size pages in a system for delivering personalized newspapers. We compare exhaustive, greedy and simulated annealing methods, in combination with two fitness functions, for generating personalized and aesthetically pleasing layouts of newspaper pages. The personalized newspaper system provides the user relevance of a news article as one component of our fitness function, and enables us to evaluate the aesthetic quality of the generated layouts. Our results indicate that both fitness functions generate aesthetically pleasing layouts.We show that incorporating additional aesthetic measures improves the resulting layout solution.", :title "Automatic Layouting of Personalized Newspaper Pages", :keyword2 110, :authors (16926 16927), :session 178}, 177 {:keyword1 8, :keyword3 57, :abstract "Different kinds of symmetry naturally arise in many integer\r\nprogramming (IP) models for real-world problems, However, they are usually not desirable, since they derogate the performance of state-of-the-art IP-solvers.  We deal with a certain kind of symmetry, for which blocks of 0/1-variables encode an assignment structure.  The permutation of the blocks has no impact on the feasibility and quality\r\nof a solution.  Such symmetries can be found in many combinatorial optimization problems, for instance in the graph coloring problem. Here, colors have to be assigned to vertices, and a permutation of the color classes does not change the structure of a solution.  These kinds of symmetries can be effectively handled with so-called orbitopes, a polyhedral structure for dealing with symmetries.  In order to apply orbitopal symmetry breaking techniques, the symmetry has to be known in advance.  We discuss the complexity of the task to detect orbitopal symmetries for packing and partitioning orbitopes. We present an algorithm that is based on graph isomorphism and analyzes the constraint graph of the IP.  It turns out that in general the detection of orbitopal symmetries is as hard as the graph isomorphism problem for bipartite graphs.  Nevertheless, for some special cases it can be handled in polynomial time. ", :title "Automatic Detection Of Orbitopal Symmetries", :keyword2 77, :authors (16880 17083), :session 176}, 178 {:keyword1 8, :keyword3 0, :abstract "Suppose that a company builds personal computers from various components. Often manufacturers have a choice of several mostly equivalent components such as hard disk drives, motherboards, CD burners, etc.. Most components are compatible with each other, but there are a few incompatible components which cannot feasibly be assembled into final products. The difficulty of managing such compatibility constraints has been noted by, e.g., Balakrishnan & Geunes (2000) and Fordyce (1998).\r\n\r\nBall et al. (2003) propose a network flow model for this where nodes represent components and paths represent product configurations. Consider the set of flows induced by putting nonnegative values on all paths. These flow values represent the frequencies of the corresponding product configurations. The flow through a node is the sum of the values on all paths containing it. It represents the frequency of the corresponding component in the production plan as given by the path flow. When the number of paths is much larger than the number of nodes, it is more convenient to consider the set of node flows instead of that of path flows. In other words, a manufacturer would rather like to track the number of components needed for production than the whole production plan itself. However, when it finally comes to production he would have to reconstruct the plan.\r\n\r\nThis leads us to examine the set of node flows. Ball et al. found characterizations of the node flow cone for some special cases. We extend this work by allowing arbitrary directed networks and bounds on flows. To characterize the node flow cone we present fast combinatorial algorithms for separation, checking validity of inequalities, and computing dimension of the node flow cone itself as well as faces induced by a given valid inequality.", :title "Characterizing Flow through Components in Assembly Networks", :keyword2 42, :authors (56196), :session 45}, 180 {:keyword1 91, :keyword3 0, :abstract "Network Revenue Management models attempt to maximize a reward function when customers buy bundles of multiple resources. The interdependence of resources, commonly referred to as network effects, creates difficulty in solving the problem. The classical technique of approaching this problem has been to use a deterministic LP solution to derive policies for the network capacity problem. Initial success with this method triggered considerable research in possible reformulations and extensions, and this method has become widely used in many industrial applications. A significant limitation of the applicability of these classical models is the assumption of independent demand. In response to this, interest has arisen in recent years to incorporate customer choice into these models, further increasing their complexity. This development drives current efforts to design powerful and practical heuristics that still can manage problems of practical scope.\r\n\r\nIn this context, we introduce a new Approximate Dynamic Programming approach to network revenue management models with customer choice with disjoint consideration sets by approximating the value function of the Markov decision process with a concave function that is separable across resource inventory levels. This approach reflects the intuitive interpretation of diminishing marginal utility of resource levels and allows for significantly improved accuracy compared to currently available methods. The resulting approximation yields provable tighter bounds than previous approaches and is asymptotically optimal as demand, capacity and time horizon scale linearly. In our computational experiments, we exhibit the gain in accuracy and compare policies based upon the proposed new approach with currently available alternatives.\r\n", :title "A New Approximate Dynamic Programming Approach to Network Revenue Management with Customer Choice", :keyword2 57, :authors (16893), :session 52}, 181 {:keyword1 39, :keyword3 0, :abstract "The selection of a right vendor for an organization should not only meet customer requirements and bring profit to the firm, but also help in fulfilling various criteria such as cost, delivery, quality objectives, technical specifications and several performance-related criteria. Thus there is a need for developing a systematic vendor selection process of identifying and prioritising relevant criteria and evaluating the trade-offs between technical, economic and performance criteria. The approach should also reduce time in vendor selection (VS) and develop consensus decision-making.  Hence supplier selection is a multi-criteria problem which includes both tangible and intangible criteria, some of which may conflict. In vendor selection problems, various decision-making situations involve a high degree of fuzziness and uncertainty because the data involved in selection procedure is uncertain and fuzzy. \r\n\r\nVendor selection requires the use of expert judgment using linguistic variables such as \"`good\"', \"`very good\"', \"`poor\"' etc. Assigning an exact number is difficult when data are not available or are fuzzy in nature. A fuzzy representation of the value, therefore, provides a better alternative. To overcome these problems listed above, we propose an efficient method for evaluating Vendor selection based on using Fuzzy Set theoretic approach. In our approach we represent some of the criteria by weights in forms of sigmoid fuzzy numbers (SFN) and some of them in crisp values. We assign different weights to different criteria. These weights represent the uncertainty in data. The vendor selection problem is thus illustrated by our methodology.", :title "Supplier Selection in a Supply Chain under Uncertainty", :keyword2 101, :authors (16744), :session 211}, 182 {:keyword1 96, :keyword3 42, :abstract "We consider a new tree-based method for resource levelling problems (RLP) exploiting some fundamental properties of spanning trees devised by Gabow and Myers (1978). For project scheduling problems with general temporal constraints and the objective to level the resource utilization (e.g. by minimizing the sum of squares\r\nof the resource profile) it can be shown that there is always an extreme point of some order polytope that is a minimizer of objective function f. Considering order network N(O) each extreme point of some order polytope can be represented by a spanning tree T of N(O), where the n + 1 arcs of T correspond to n + 1 linearly independent binding temporal constraints. Given that the project starts at point in time 0, the corresponding linear system of equations has the vertex in question as unique solution. An optimal solution can be determined by consecutively fixing start times of activities such that step by step constraints become binding and the corresponding arcs constitute a spanning tree of N(O). Therefore, our approach enumerates all time feasible spanning trees of all networks N(O) for project network N. The idea is to enumerate inductively all spanning trees T containing some partial tree T' following\r\na depth first search strategy. Each time we disconnect some edge from T' (since the corrsponding tree T'' has been completely researched), we check whether there\r\nis an alternative way to expand T'. If there is an alternative edge we build a new tree via that edge. Otherwise the disconnected edge represents a bridge for\r\nT' and we have found all trees containing T'. Using this bridge concept we exclude the generation of redundant trees. Preliminary results show that the devised approach is promising for instances with up to 20 activities.\r\n", :title "A tree-based enumeration method for resource levelling problems", :keyword2 86, :authors (14828), :session 55}, 183 {:keyword1 8, :keyword3 0, :abstract "In the classical MSSC problem the set of vectors should be split into several clusters and the centers of the clusters should be chosen in such a way that the sum of the squares of the distances from each vector to the center of its cluster would be minimum. For a long time the MSSC problem was thought to be NP-hard but recently it was shown that the proof of this fact contained a mistake. So, the complexity of MSSC is an open problem. \r\nWe consider the variant of MSSC with two clusters when one of the centers of the clusters is fixed and equals zero. This problem is motivated by the following application. Some object can be either in an active or in a passive state. When it is passive all its characteristics are equal to zero, while when it is active they form a non-zero vector. One measures the characteristics vector with some additive noise having zero mean value and wants to determine when the object was active and find out its characteristics vector in this case.\r\nWe proved that this problem is NP-hard and suggest an exact exponential algorithm solving it. Note, that our algorithm is polynomial in the case of the fixed dimension of the vector space. \r\nThe research was partially supported by RFBR grants 06-01-00058, 07-07-00022, and 08-01-00516.", :title "On one variant of MSSC problem", :keyword2 10, :authors (13514), :session 179}, 186 {:keyword1 19, :keyword3 93, :abstract "Reinsurance contracts are used to cover risks of insurance companies. In this regard, the risks are taken over by reinsurers, meanwhile the risks are assigned by insurers.\r\n\r\nAs the choice of a contract depends on the risk preference of an insurer, the aim of the model is to calculate its risk preference and in the following to analyze the robustness of its decision.\r\n\r\nIt can be distinguished between proportional and non-proportional contracts, whereas the main focus here is only on the last type. \r\n\r\nSuch a reinsurance contract has two limits, called deductible and cover. The deductible is the lower limit for coverage and defines the division of loss between insurer and reinsurer. The cover is the upper coverage limit and defines the highest margin a reinsurer is willing to take over.\r\n\r\nWithin the presented model, the optimal coverage limit from the point of insurer is calculated with the help of a hybrid decision model. This model uses a convex combination of upper and lower conditional expected profit as a target function. Furthermore it includes two risk parameters. Therewith it is possible to calculate the coverage limits depending on these risk parameters.\r\n\r\nLikewise, in case of knowledge of special coverage limits, it is possible to calculate the risk parameters and in this connection to identify the risk preference of an insurer. In turn these parameters and preferences can be used as a guidance for calculating coverage limits for future decisions at reinsurance contracts with modified loss distribution.\r\n\r\nIn the course of consideration the results of the robustness check for several characteristic parameters such as reinsurance premium, deductible, cover and profit are presented. The robustness is investigated by the help of stochastic dominance.", :title "Decision Theory in Reinsurance: The calculation of risk preferences and there robustness", :keyword2 67, :authors (16844), :session 90}, 188 {:keyword1 37, :keyword3 0, :abstract "Bei der Ermittlung von Angebotspreisen für gebrauchte Personenwagen wird eine Schätzung benötigt, wie hoch die Verkaufswahrscheinlichkeit bei einem gegebenen Preis ist. Herr Jerenz wählte in seiner Dissertation zur Schätzung ein statistisches Verfahren. Hier werden Ergebnisse basierend auf künstlichen neuronalen Netzen vorgestellt.", :title "Schätzung von Verkaufswahrscheinlichkeiten gebrauchter Pkw", :keyword2 91, :authors (14740), :session 183}, 189 {:keyword1 96, :keyword3 77, :abstract "In many realistic situations, jobs with similarities are grouped into the same family. Whereas negligible setups occur among jobs of the same family, major setups are inevitable on each occasion when the machine switches from one family to another. Batching, on the other hand, refers to the decision of whether or not to schedule similar jobs contiguously. As a result, by integrating batching into the family scheduling model, advantages can be achieved due to the reduced number of setups and higher machine utilization. However, a vast majority of existing literature in this area focuses on the single machine problem. To the best of our knowledge, only special cases of the multi-machine problem have been investigated in the previous studies. The general shop problems still remain as a challenge.\r\n\r\nIn this paper we address the machine scheduling problem involving family setup times and batching decisions. Precisely, the m-machine flow shop system is considered with the objective of minimizing the makespan. For the problem under study, we first present a mathematical formulation which is able to solve small instances. Subsequently, a sophisticated tabu search algorithm is proposed with diverse neighbourhoods. Moves concern critical operations of the same block. Moreover, a block is further refined with the emphasis on batches. It should be noted that a block may contain complete or partial batches, which can be referred to as sub-blocks. Next, various types of moves are developed with respect to sub-blocks. Structural properties are then examined closely, which assist in directing the search process and enable a progressive decrease in makespan.", :title "Solving the Batch Scheduling Problem with Family Setup Times", :keyword2 59, :authors (16949 15326), :session 54}, 190 {:keyword1 106, :keyword3 0, :abstract "Durch die Simulation der ein- und ausgehenden Massenströme eines Kohlekraftwerkes können Verzögerungen in der Ver- und Entsorgungslogistik aufgezeigt werden. Insbesondere im Bereich der maritimen Logistik sind neben Umschlags- und Silokapazitäten weitere schiffstechnische Parameter wie bspw. Gezeiten und Tiefgänge in ein Simulationsmodell mit aufzunehmen.\r\n\r\nVor dem Hintergrund des geplanten Ausbaus der Kapazitäten im Bereich der Kohlekraftwerke einerseits sowie der Schließung der deutschen Steinkohlebergwerke anderseits ist die Analyse der vorhandenen Verkehrsinfrastruktur nach vorhandenen und potenziellen Engpässen unabdingbar, um eine sichere Ver- und Entsorgung eines Kohlekraftwerkes sicher zu stellen. \r\n\r\nHierbei ist eine Betrachtung sämtlicher eingeplanter Verkehrsträger die Grundlage für die Simulation von Güterstromnetzen, da die zunehmenden Güterverkehrsmengen, insbesondere auch die Containermengen, in den Seehäfen sowie im Hinterlandverkehr mit den Kohletransporten um knappe Umschlag- und Transportkapazitäten konkurrieren. \r\n\r\nIm Rahmen einer Logistikstudie zur Ver- und Entsorgung eines Steinkohlekraftwerkes wurde ein Simulationsmodell zur Erstellung und Untersuchung von sicheren Ver- und Entsorgungsplänen unter Beachtung der spezifischen Rahmenbedingungen entwickelt. Besondere Berücksichtigung fanden die Umschlagaktivitäten an der Kaje, da die große Varianz in den Schiffsanläufen zu schwankenden Silobeständen am Kraftwerk sowie zu großen Schiffswartezeiten aufgrund belegter Kajen führen kann. Durch Simulation konnten Engpässe an der Kaje identifiziert sowie alternative Lösungen durch eine Variation der beeinflussbaren Parameter aufgezeigt werden. ", :title "Simulation der wasserseitigen Kraftwerkslogistik", :keyword2 0, :authors (16817 1462), :session 32}, 191 {:keyword1 96, :keyword3 78, :abstract "The steady growth in international trade over many years has resulted in an increased need for freight transportation. It supports production, trade, and consumption activities by ensuring the efficient movement and timely availability of raw materials and finished goods.\r\n The Ship Routing and Scheduling Problem (SRSP) addressed in this paper involves routing a fleet of controlled and chartered vessels, with limited heterogeneous capacities, from an origin to various port customers around the world with known demands and predefined time window constraints. The route cost of a vessel consists of fuel costs (bunker consumption), operation cost, and port due. The objective is to minimize the total cost of serving all customers without violating any constraint. Routing and scheduling of ships requires a significant level of fleet management planning. Any significant improvement of routing and scheduling will result a substantial cost saving.\r\nThis paper proposes an A* search heuristic for SRSP. Solving this type of problems by using an exact algorithm require an enormous time consuming to generate all feasible schedules for each ship. A* algorithm presented in this paper was used to generate a subset of feasible schedules for each ship, where all constraints are satisfied. We found this subset of feasible schedules generated under conditions of A* parameters have encouraging results comparatively to the results  generated by the tabu search presented in [1]. \r\nThe results of a computational investigation such as solution quality and execution time are explored with respect to problem size will all be detailed in the full paper.\r\n", :title "Using A* search algorithm for solving Ship Routing and Scheduling problem with time-window", :keyword2 95, :authors (17418), :session 59}, 192 {:keyword1 19, :keyword3 0, :abstract "A version of one-person and multi-person stopping game with priorities and offers arriving at jump times of Poisson process is considered. Players' rewards depend on the value of the selected offer, discounted by some function of time, and random starting time. The aim of each player is to maximize his optimal mean reward. Differential equations for the game value are obtained.\r\nThe application of this game is as follows. Suppose that there are j businessmen and each of them is interested in finding exactly one project to realize. The businessmen are waiting for the permission to run the business and to realize the projects. They obtain this permission at the same random time M. Therefore, they are not allowed to accept any project up to time M. Until then they can only observe the market and collect information. The businessmen are ordered according to their experience. We assume that at each time only one project is presented and it is presented to the best businessman first. If the project is rejected by some businessman, it is presented to the next one in order. The profit from the project depends on the value of the selected project, discounted by some function of time, and random time when the businessmen obtain the permission for running the business. The aim of each businessman is to accept the most profitable project.\r\n", :title "A version of the Elfving problem with random starting time", :keyword2 40, :authors (16955), :session 181}, 193 {:keyword1 106, :keyword3 7, :abstract "Most freight forwarding companies reduce the capacity of their own vehicle fleet far under the varying total demand limit. Thus, additional outside carriers must be involved in order to gain enough transportation resources for covering the demand. In effect, freight forwarding enterprises have to plan the fulfilment of their requests not merely by routing and scheduling their own fleet but also by selecting transportation tasks to be sourced out by entrusting external freight carriers. Together with engaging an external carrier, the rules of payment for its service (type of sub-contraction) are defined. The resulting transportation problem consists in constructing a fulfilment plan with the lowest total fulfilment costs, assuming a limited size of the own fleet and different predefined types of sub-contraction. Most existing approaches from literature which discuss vehicle routing combined with outsourcing regard only one specific type of subcontracting. In practice, several types of subcontracting occur simultaneously. This contribution describes and explores the complex situation where an own fleet and four types of subcontracting are used for request execution and are integrated into a comprehensive planning problem. This integrated planning problem is presented and analysed. Then, a mathematical model to formalize and solve the problem is introduced. The model is used for the exact optimization of small problem instances of the integrated problem. The computational results provide conclusions with respect to the equilibrium between the amount of self-fulfilment and sub-contraction. In order to investigate long-term questions concerning the appropriate capacity of the own vehicle fleet, the optimization model has been tested for several sizes of the own fleet.", :title "An Optimization Model for Combined Types of Transportation Request Fulfilment", :keyword2 95, :authors (15277 16911), :session 64}, 194 {:keyword1 92, :keyword3 65, :abstract "Sustainable development was articulated by the Brundtland Commission as development that meets the needs of the present without compromising the ability of future generations to meet their own needs.  Recent literature on sustainable logistics networks points to two important questions: (i) How to spot the preferred solution(s) balancing environmental and business concerns? (ii) How to improve the understanding of the trade-offs between these two dimensions? In this paper, after the design of the sustainable reverse logistics network with sustainability considerations, We use articulated methods for the exploration of the eco-efficient frontier. In the articulated methods the Decision Maker interacts with the model until he finds a satisfying solution. Articulated approach enables a decision maker to freely search any part of the efficient frontier by controlling the speed and direction of motion. So based on the decision maker’s desired trade offs between cost and environmental impact improvements, we can explore pareto optimal solutions of the sustainable reverse logistics network to find the best solution for network configurations", :title "Evaluating sustainability of reverse logistics network using articulated methods", :keyword2 102, :authors (16946 17389), :session 113}, 195 {:keyword1 113, :keyword3 0, :abstract "The experimental study presented in this paper explores the effects of ex post audits in capital budgeting processes under different informational and social circumstances. Audits are analyzed in one-shot settings with different preplay information about superior and subordinate as well as under repeated interaction. Consequently, we are able to distinguish between effects of reputation building by the superior and by the subordinate. Moreover, we separate effects of social interaction between the two parties from purely informational effects. This is important as long-term relationships differ from one-shot interactions both with respect to informational and social issues. We find that audits are beneficial for the superiors as audits decrease slack and increase the superior payoff. However, this result is driven by the treatments with one-shot interaction. Surprisingly, in these treatments, only information about the subordinate significantly reduces slack and increases the superior payoff. Finally, we find that social interaction between the two parties plays an important role in the repeated setting as slack strongly increases and the superior payoff strongly decreases relative to the one-shot setting with full information. Our further analysis reveals that this might be due to the fact that audits introduce mistrust into the superior-subordinate relationship.", :title "Audits, Reputation, and Repeated Interaction in a Capital Budgeting Setting", :keyword2 19, :authors (8892 16962), :session 82}, 199 {:keyword1 33, :keyword3 8, :abstract "The facility layout problem is concerned with determining a layout of departments within a building that minimizes the costs of interdepartmental flow of material. \r\nIn the past the rectangular facility layout problem was mainly represented by a quadratic assignment problem or by graph oriented approaches. The main drawback of these approaches is that unequal sizes of departments can not be considered sufficiently. In contrast, the presented slicing tree approach incorporates unequal areas and fixed or flexible width to length ratios of departments. \r\nA slicing tree is a representation of a layout which is generated by recursively dividing an original floor space by guillotine cuts (orthogonal cuts dividing a rectangle totally from one edge to the opposite one). \r\nWe present a slicing tree based MILP approach that is used to determine optimal slicing layouts. Due to the huge computational effort we developed another model with a reduced degree of freedom that determines the optimal layout corresponding to a given slicing tree. This reduced model is integrated into a metaheuristic.", :title "A new, slicing tree based MILP approach for the facility layout problem", :keyword2 54, :authors (), :session 142}, 201 {:keyword1 2, :keyword3 59, :abstract "On the day of operations disruptions can require to recover airline schedules. In the case of disrupted crew schedules the possibilities for recovery are reassignment of the tasks to other crews, calling reserve crews, cancelling and retiming flights. The main objective of the crew recovery problem is to minimize the costs, resulting from calling reserve crews and cancelling and delaying flights. Another important goal is to change the original schedule as little as possible. We present a new method for the crew recovery problem that uses all mentioned recovery possibilities to achieve these goals.\r\nIn the presented method a new neighborhood search for the crew scheduling problem is embedded in a tabu search scheme. Dynamic programming on leg based networks is used for pairing modification and generation of new pairings for reserve crews. We allow slight retiming of flights, if this avoids large modifications of the original schedule. To manage the additional complexity we allow retiming in promising cases - usually after disrupted flights.\r\nWe test our method on different crew schedules and disruption scenarios and show the effects of flight retiming.", :title "Crew Recovery with Flight Retiming", :keyword2 96, :authors (16966), :session 67}, 202 {:keyword1 91, :keyword3 68, :abstract "In this presentation, we investigate an airline network revenue management problem where the task is to find the best capacity allocation of seats to aircraft compartments while keeping the risk of displacing passengers under control. The underlying passenger demand depends on the available choice options of the passengers. We distinguish between the traditional product-sensitive case where customers buy a ticket in a certain booking class if available or do not buy at all and the market-sensitive case where customers make use of having different options for selecting the best ticket. We model the customer choice options via precedence orders described by a parameterized graph. This graph describes the forecasted demand per booking class and buy-down potentials between them. Buy-down means selecting a suitable cheaper booking class if available. The implied demand per booking class depends on the controlled availability of each booking class and the potential transfer (buy-down) of demand from a booking class to adjacent ones. The computation of the demand values per booking class is done by evaluating the buy-down paths in the graph for each origin-destination (OD) pair in the airline network for each decision period. Based on this graph model, we present a mixed integer program for optimizing the total revenue based on the customer choice options and the implied OD demand. The OD demand is obtained in a pre-processing step for which we discuss some dominance principles for restricting the number of values to be pre-calculated. As result, we obtain the optimal availability control over time for each flight and each OD pair and the proposed compartment capacities and related adaptations. We conclude with the discussion of numerical results for real-world problems.", :title "Revenue Optimal Risk-Based Upgrading including Customer Choice Options", :keyword2 57, :authors (12839), :session 136}, 203 {:keyword1 54, :keyword3 59, :abstract "Facility location-network design combines the problems of facility location and network design: to optimize some objective involving clients and facilities, one may build facilities as well as links. We study discrete problems with a budget and a median objective: Given a graph representing an existing network of links and possibly facilities, the goal is to minimize the total travel costs of clients to facilities by building additional links and facilities.  The built elements are selected from a pool of potential links and facilities, each with an associated construction cost, and the total money spent may not exceed the given budget.\r\n\r\nIn this talk we present some local search based heuristics for this problem, including a basic local search, simulated annealing, and some variants of variable neighborhood search.  Additionally, two different types of neighborhoods are discussed and compared.  The results of each heuristic are compared with known optimal solutions to a series of test problems.\r\n", :title "Local Search Based Heuristics for Facility Location-Network Design", :keyword2 65, :authors (8853 607), :session 205}, 204 {:keyword1 48, :keyword3 106, :abstract "The paper focuses on forwarding agencies handling less-than-truckload freight. On the one hand, the performance is influenced by varying transport times between two consecutive points. Surprisingly, traffic information are hardly used within the forwarding industry, even though vehicle location is available in real-time. On the other hand, the performance of these companies is influenced by unknown customer orders, increasingly received shortly before the actual pickup. Consequently, the objective is to avoid lateness of orders and increase equipment utilization.\r\n\r\nSome dynamic routing approaches are solely based on a priori information whereas others are purely dynamic or combinations of both. Various methods consider travel times or customer orders, but rarely both aspects are combined. Furthermore, nearly not one approach considers the specific requirements of the forwarding agencies, for example capacities of inhomogeneous loads and time windows.\r\n\r\nThe objective within a first step was to determine how far and under what premises freight forwarding agencies might benefit from a real-time intelligent planning system. In a second we model a multi-stage mixed integer problem representing the pickup and delivery problem of forwarding agencies with anticipation of both travel times and unknown customer orders. For anticipation of transport times a piecewise constant approximation of beforehand identified time zones is used to maintain the FIFO property. Upon arrival of new information, the reoptimization is triggered. In practice, the problem has to be solved within a certain time, therefore heuristics based on local search methods are developed also. Numerical examples are presented to illustrate the approach.", :title "Design and Optimization of Dynamic Routing Problems with Time Dependent Travel Times", :keyword2 23, :authors (16964), :session 52}, 205 {:keyword1 2, :keyword3 96, :abstract "Airline schedules are created several months in advance to the day of operations. To prevent huge increase in cost caused by disruptions on the day of operations airlines have the possibility to react to disruptions after they occur and to create stable and flexible schedules in advance. Flexible schedules provide more and cheaper possibilities to recover from disruptions. Stability describes the ability of a plan to remain feasible and to give acceptable results under different, sometimes unpredictable, variations of the operating environment without any modifications of the plan. \r\nEfficient airline operations require as stable as possible schedules as well as flexible schedules combined with sophisticated methods for disruption management. In this paper we present our research on stability of airline schedules.\r\nWe describe a model for delay propagation, considering the interdependence between rotations and pairings. In addition to disruptions of individual ground tasks and flights we present a model for delay generation due to airport congestion. We describe methods to measure the stability of aircraft rotations and crew pairings and study the effects of the crew schedule on the stability of aircraft rotations.", :title "Stability of Airline Schedules", :keyword2 97, :authors (1194 1141 1141 1141), :session 67}, 207 {:keyword1 7, :keyword3 0, :abstract "Timely maintenance is an important issue for many companies, especially in the context of an increasing focus on delivering a function instead of just the hardware to perform the function. Decreasing response/reaction time, difficulties with hiring and keeping good repairmen, uncertainty in the calls arriving, and increasing product variety makes multi-skilled workers extremely important. Question to be answered by many companies: what is the optimal set of multi-skilled repair men to timely deal with calls for repair against the lowest cost? Issues to be included are amongst others, work load, travel time, parts storage space in vans, fines for not meeting service agreements, training, and online information.\r\nFor quite some companies, the scale of the problem to be solved goes beyond the size of the problem studied in literature until now and forbids an exact optimal solution at this moment. In our paper, heuristics to support the assignment of skill sets to repairmen and the allocation of repairmen with certain skill sets to repair calls are presented. We applied our heuristics to a case study from practice, where the service company has to start or finish a certain repair job within a certain preset time after the customer had indicated a problem. The service company has to pay a fine to the customer when the above is not realized. Suggestions for further research are given.\r\n", :title "On the optimal cross training of traveling repairmen in situations with corrective maintenance, many skills and different workloads.", :keyword2 23, :authors (3329 3189), :session 134}, 208 {:keyword1 63, :keyword3 0, :abstract "The problem of assigning project to students arises in a number of contexts. A Genetic Algorithm (GA) as an aid for Project Assignment (PA) was considered by R. Harper, et al.. In this work we develop the PA problem for assigning the projects to the students. Here we consider not only  the student's preferences to choose the project but also the supervisor's wishes to select the students. Thus this is a multiobjective project assignment problem. We solve the foregoing problem by GA\r\n", :title "A genetic algorithm for the extension of project assignment problem", :keyword2 0, :authors (16965), :session 103}, 213 {:keyword1 106, :keyword3 89, :abstract "The vehicle scheduling problem, arising in public transport bus companies, addresses the task of assigning buses to cover a given set of timetabled trips with consideration of practical requirements, such as multiple depots and vehicle types as well as depot capacities (MDVSP). A cost-optimal schedule is characterized by minimal fleet size and minimal operational costs including costs for unloaded trips and waiting time. But such vehicle schedules are traditionally computed offline, although disruptions occur frequently during the transportation process. Therefore schedules are not followed as promised and expenses are incurred, e.g. for governmental penalties because of being below contractual minimum service levels.\r\n\r\nWe present offline planning approaches for increasing the delay-tolerance of vehicle schedules. For this purpose we use information from delay-scenarios or probability distributions of the delays. We also propose an approach using no delay information, but guaranteing robustness against a given delay-length. Test results of real timetables are shown and the approaches are compared with regard to planned operational costs and delay-tolerance.", :title "Approaches for Robust Multi Depot Vehicle Scheduling in Public Bus Transit", :keyword2 96, :authors (1194 14161), :session 70}, 214 {:keyword1 96, :keyword3 89, :abstract "We present in detail two heuristic offline approaches that can increase the delay-tolerance of vehicle schedules for the multi-depot vehicle scheduling problem arising in public bus transportation. One approach is based on \"`simulated annealing in the presence of noise\"' (SANE), a single-objective stochastic simulated annealing meta-heuristic, and the other on \"`strength pareto evolutionary algorithm 2\"' (SPEA2), a multi-objective evolutionary algorihm (MOEA). The multi-objective approach uses the two objectives: minimize planned operational costs and minimize penalty costs for not being punctual. In the single-objective heuristic this two objectives are aggregated. Both approaches use probability distributions of the delays and monte-carlo simulation, to evaluate the penalty costs during the solution process. Thus the objective functions are stochastic and special techniques have to be implemented to handle this. We show testresults computed with real-life timetables and compare the approaches with regard to planned operational costs, delay-tolerance and runtime. An important conceptual difference between the approaches is: the bi-objective heuristic gives us a set of non-dominated solutions, but the simulated annealing based computes only one vehicle schedule per run.", :title "Heuristic Approaches for Robust Multi Depot Vehicle Scheduling in Public Bus Transit", :keyword2 59, :authors (14161 16971 1194 16970), :session 70}, 215 {:keyword1 16, :keyword3 0, :abstract "We consider a special type of two-dimensional cutting problem which consists of one rectangular large object and several small rectangular item types. Instances of these item types have to be cut from the large object using only guillotine cuts; the goal is to maximize the value of the items cut. There is no further constraint (e.g. sales constraint) on the number of pieces per item type. This problem type is called a Two-Dimensional Rectangular Unconstrained Guillotineable-Layout Single Large Object Placement Problem (Wäscher et al 2007). Additionally, a single rectangular defect on the large object is introduced. An exact algorithm based on an AND-OR-graph approach (by Morabito, Arenales, Arcaro 1992) is presented to solve this problem, as well as some heuristics to speed up the computation. Computational results of instances from the literature as well as from randomly generated instances are shown.", :title "Two-dimensional guillotineable rectangular cutting problems with a single defect – an AND/OR-graph approach", :keyword2 0, :authors (35421 333 1794), :session 150}, 216 {:keyword1 75, :keyword3 101, :abstract "     For a multi-location inventory system with lateral transshipments (MLIST) we want to define such ordering and transshipment policies that optimise given performance measures for the system. The combination of inventory and logistic questions makes the problem very complex. Some special models for the MLIST have been investigated in the past, whereby the analytical approach was the most common one. In the consequence all considered models were far from reality. Obviously we can not expect to get analytic solutions for more realistic models. One way out is to combine simulation and optimisation. To apply the simulation optimisation approach we need a simulator for the considered system as well as an optimiser, which in our case is a Genetic Algorithm (GA). The GA realises the search through the solution space. A solution of our problem is a vector whose components represent parameter values of the different ordering policies of the locations and the overall transshipment policy. The simulator simulates the behaviour of the system for a given solution and returns an estimation of the corresponding performance criteria. On base of those estimations the GA chooses new solutions and so forth until a stopping condition is fulfilled. Our simulator allows investigating MLIST models with periodic ordering and transshipments at arbitrary time moments. For delivery and transshipments positive lead times are assumed. Cost functions are linear in time and product units with fixed parts. Each location can choose between five policies to serve arriving demand. To realise transshipments various policies are introduced, which differ in their forecast method for the future demand. We describe the simulator, report on numerical experiments and give some hints for further developments.", :title "Simulation Optimisation of Multi-location Inventory Systems with Lateral Transshipments", :keyword2 97, :authors (14770 16973), :session 110}, 217 {:keyword1 102, :keyword3 0, :abstract "Firms are faced increasingly with the requirement of a voluntary disclosure of information about intangibles, social and environmental factors. It has shown that traditional reporting based on accounting standards does not provide sufficiently information about crucial resources of firms like human resources, R&D, customers, or the efficient use of energy. Scientists focused on the development of adequate voluntary reporting system to overcome the shortcoming of balance sheets and income statements. In general, they looked at intangibles, social and environmental factors separately. Hence, two types of additional reports, the intellectual capital report and corporate social responsibility (CSR) report emerged. The purpose of this article is to combine both fields of research, and is focused on the comparison of already developed models, standardized categories, and indicators to measure the disclosure level in a more comprehensive way. The author created a disclosure score for each of the 100 selected EURO STOXX firms. The score is based on a content analysis of annual, CSR and intellectual capital reports in 2006, which allowed to select relevant information by predefined categories and to assess the information according to a specified scale. To examine the value relevance of the voluntary disclosure the cost of equity capital is estimated as proxy variable for information asymmetry. Two different estimation models are applied, the CAPM model and the Ohlsen-Jüttner-Nauroth residual income valuation model. An OLS regression analysis is made to figure out, if a linkage between disclosure score and cost of equity capital exists, and if the combined disclosure score explains the impact of level of voluntary disclosure on information asymmetry better than existing scores.", :title "Voluntary disclosure of information about intangibles, social and environmental factors and its impact on the cost of equity capital: a survey of EURO STOXX companies", :keyword2 0, :authors (16920 17377), :session 83}, 220 {:keyword1 106, :keyword3 95, :abstract "** For considering in the Special Stream \"`Managing Uncertainty in the Planning of Transport\"' (Jörn Schönberger)**\r\nProviding travel times for reducing uncertainty in city logistics planning Planning activities in city logistics require the consideration of varying traffic flows next to a customer oriented service design. Traffic flows in rural areas depend on a large variety of influences that cannot be entirely described with traffic flow models. To our knowledge, the resulting uncertainty in planning is merely insufficiently considered in current standard planning methods. Linear distances as well as roughly estimated travel times depending on the type of the road are used for calculating optimal routes. Thus, the planning reliability and robustness of these routes is thought to be rather low.\r\nIn this contribution, we rely on the concept of Floating Car Data (FCD) for providing dynamic travel times. Different ways of determination of dynamic travel times from a historical travel time database are presented and evaluated in terms of planning quality. We compare routes planned on standard data sets to those resulting from the historical travel time database regarding the actual travel times and the most reliable time prediction.\r\nProviding dynamic travel times results in a rather large amount of input data for planning methods. Thus, cluster analysis is introduced in order to pool roads that show a similar variation of travel times. It is shown that this method can help decrease the amount of planning data significantly without a notable reduction of planning reliability and robustness of the resulting routes.", :title "Providing travel times for reducing uncertainty in city logistics planning", :keyword2 120, :authors (12952 16919 13264), :session 51}, 221 {:keyword1 83, :keyword3 57, :abstract "We study convergence of a semismooth Newton method for\r\nsemi-infinite programming problems (SIP). In fact,\r\nthe semismooth Newton method is applied to a semismooth reformulation of\r\nthe upper and lower level Karush-Kuhn-Tucker conditions of SIP by NCP functions\r\ninto a semismooth system of equations. \r\n\r\nIn the present paper we neither assume strict complementary slackness in the\r\nupper nor in the lower level. The auxiliary functions of the so-called locally reduced\r\nproblem are then not necessarily twice differentiable. Still, we can show\r\nthat a standard second order regularity condition for quadratic convergence of the semi-smooth Newton method\r\nholds under a natural assumption for semi-infinite programs.\r\n", :title "The Semismooth Approach for Semi-infinite Programming without Strict Complementarity", :keyword2 66, :authors (2795 5345), :session 138}, 222 {:keyword1 106, :keyword3 85, :abstract "The routing of customer requests with reusable resources, e.g. swap containers, is mostly associated with decisions about repositioning of these ressources empties’ because of spatial and/or temporal unfitted streams of commodities. If customer requests appear stochastically this allocation task becomes more challenging. We refer to this twofold problem as the Stochastic Swap Container Problem.\r\n\r\nThe allocation of resources is a well-known dynamic service network design problem. On this tactical level, uncertain customer requests can be considered by a stochastic programming approach. Thereupon, the day-to-day routing task demands the current period’s allocation plan for realization. Thus, stochastic variables are respected and tactical information about future situations is incorporated into the operational routing decision.\r\n\r\nThis talk addresses strategies to incorporate stochastic information about demanded resources in order to support the routing decision that may lead to a benefit for the entire Stochastic Swap Container Problem.\r\n", :title "Routing and allocation in deterministic and stochastic environments", :keyword2 95, :authors (12952 9732), :session 31}, 223 {:keyword1 80, :keyword3 83, :abstract "The critical (or optimal) value function of a parametric nonlinear program is nondifferentiable, in general, even for smooth data. However, it is well-known that under strong regularity of critical points or primal-dual optimal solutions, the critical value function v is differentiable with locally Lipschitz derivative Dv and can be represented by the partial derivatives of the Lagrangian with respect to the parameter(s). In economic theory, results of this kind are known as envelope theorems. In this talk, we give envelope theorems under weak assumptions which also guarantee that generalized second-order derivatives of v like the contingent, or Thibault, or Clarke derivative of Dv can be represented in terms of the data of the original optimization problem. It will be shown how to use this in nonsmooth Newton methods and how to apply this to generalized semi-infinite programs. The results were obtained in collaboration with Bernd Kummer (Humboldt University Berlin) and Stephan Bütikofer (University of Zurich).", :title "Envelope theorems and generalized second-order derivatives of critical values", :keyword2 108, :authors (10871), :session 138}, 224 {:keyword1 35, :keyword3 0, :abstract "How to allocate the wealth among the different kinds of assets, in order to maximize the benefit, is the main concern of investment companies. As a classic subject, most of the researches in the literature are related to either selecting a portfolio of projects or a set of securities, while in this paper both are taken into consideration. On the basis of the idea of matching the moments of the asset returns, a scenario generation method is proposed which has used for the multi-stage investment projects and securities portfolio selection. Considering different criterions which are important for the company, potential projects are ranked. Higher ranked projects have more chance to be selected in the stochastic programming model and this is more consistent to the real situation. At the end, to demonstrate the solution procedure with an interpretation of the optimal policies, an illustrative example is solved. ", :title "A Mixed Dynamic Securities and Investment Projects Portfolio Selection Using MCDM & Stochastic Programming", :keyword2 99, :authors (16960 16974), :session 128}, 225 {:keyword1 86, :keyword3 18, :abstract "Many projects are highly complex and quite special in nature. Often, their scope is interdisciplinary and innovative. These characteristics result in a vagueness of goals that is unknown in more classical fields like the scheduling of operational units in industrial production.  As a consequence their methods for scheduling can not always be taken over into project management. Nevertheless, the current methods in project management are almost completely based on fully deterministic data and considerations, ignoring their inherent vagueness. Theoretical approaches, taking into account vagueness that is not of stochastic origin, are usually very limited in scope: they only cover few aspects of the much wider problem. In general, they also are quite theoretical and not yet applicable to realistic problems.  A holistic approach, fully taking into account the vagueness of data in all three phases – modeling, processing and evaluation of results – is not found in the scientific literature up to now.  \r\nSome additional aspects of the current methods of scheduling in project managements should also be investigated more vigorously. For example: The assumptions made about the quality of data and how conflicting goals are handled are subjects that should not be ignored. Finally transparency, clearness, intelligibility and flexibility should be enhanced.\r\nThe goal of this presentation is to demonstrate that a holistic vagueness-aware approach to scheduling in project management is possible. This approach may lead to a more realistic scheduling for real-life projects. Taking into account the characteristic conditions of project management, the gap between theory and reality can be closed.", :title "Vagueness-aware Scheduling in Project Management - Practice-oriented modeling, integration and management of vague data, decision making and evaluation processes", :keyword2 39, :authors (5454), :session 56}, 226 {:keyword1 101, :keyword3 0, :abstract "Up to now, demand fulfillment in make-to-stock manufacturing is usually handled by advanced planning systems which fulfill orders on the basis of simple rules or deterministic planning approaches not taking into account demand fluctuations. The consideration of different customer classes as it is often done today requires more sophisticated approaches explicitly considering stochastic influences.\r\n\r\nIn literature, different streams of stochastic models emerged that deal with demand fulfillment. However, not all of them fit to the specific characteristics in manufacturing, as for example storage of excess capacity and future incoming supplies. In this talk, three different stochastic models – based on the ideas of revenue management, inventory rationing and randomized linear programming – will be discussed and numerically analyzed. Additionally, the approaches are compared to conventional deterministic approaches.", :title "Stochastic Models for Demand Fulfillment in Make-to-Stock Production", :keyword2 76, :authors (14070 2448), :session 118}, 229 {:keyword1 101, :keyword3 75, :abstract "The well–established and hard–to–solve capacitated lot sizing problem (CLSP) describes a situation where a single decision maker has to produce several items in order to meet a given demand in the presence of scarce capacities. Todays real world, however, is a world in which decision makers act in supply chains/networks which makes the situation even more complex. We study the original and new cooperative\r\nCLSP in this paper where the available resources of the players may be used in common and payable transshipments may take place to transport items from one player to the other. We show that cooperating in such a setting is beneficial for all participants so that there is an incentive to form the grand coalition. Consequently, one has to solve problems which have not been treated in the literature before.\r\nFirst, there is the hard–to–solve optimization problem of deciding which player shall produce what amount of items at what point of time, how many items shall be kept on stock when, and when transports of what quantities shall take place among which players such that the total cost of the supply chain is minimized taking into account thorny side constraints due to limited capacity availabilities. Second, there is the hard–to–solve problem of distributing cost shares among the players such that the cost allocation is stable and fair. Both questions are discussed in detail\r\nand answers are given by proposing mathematical programming approaches. For the first problem a Lagrangean relaxation based procedure is provided which yields lower and upper bounds. For the second problem the notion of fairness is defined and the new concept of the minmax core is introduced. A constraint generation algorithm to compute a cost allocation in the minmax core is described.", :title "Solutions and Fair Cost Allocations for Cooperative Lot Sizing with Transshipments and Scarce Capacities", :keyword2 40, :authors (14776 14715), :session 121}, 230 {:keyword1 106, :keyword3 0, :abstract "From cost perspective planning of distribution networks is generally determined by two factors: On the one hand there are costs for transportation of goods. On the other hand there are costs for installation and operation of facilities for production, handling and storage of goods. Optimization of facility location and transportation problems is traditionally carried out in separate models. Facility location models determine the number and location of facilities based on approximate transportation costs. Generally the transportation costs are overestimated in those models. Routing models take these facilities for granted and focus on the optimization of e.g. number and length of tours. Economic and better solutions for facility location and transportation problems can be achieved by considering both problems simultaneously using so-called location routing models. \r\nCommon for distribution networks, for example courier, express and parcel distribution, are facility location decisions where economies of scale occur and where transportation of goods must respect limited vehicle capacity and time windows for pickup or delivery at customers. In this work a location routing model is used for real world distribution networks. The aim of this work is to design solution methods for location routing problems (LRP) for real world applications to achieve better solutions than traditional facility location models and solution methods.\r\n", :title "Location-Routing-Problems in time restrictive distribution networks", :keyword2 54, :authors (9852), :session 37}, 233 {:keyword1 8, :keyword3 106, :abstract "In railway planning, a frequent problem is that a delayed train necessarily delays its crew. To prevent delay propagation along the crew's succeeding trips, a move-up crew may take over the rest of the crew's duty on time.  We address two questions arising from the concept of move-up crews: \r\n\r\nFirstly, during the planning stage, one has to make a tradeoff between robustness gained and additional costs incurred by introducing move-up crews. We show that this problem is related to both a set cover variant with profits for pairs of sets and to the dense k subgraph problem. A subproblem called Maximum Profit Subgraph Problem is discussed for which we present both an efficient exact as well as a 2-approximation algorithm. Based on these results we suggest different heuristics to solve the original problem, depending on the size of the instance.\r\n\r\nSecondly, during daily operations, there may be more delayed crews than available move-up crews. In such situations, dispatchers have to make optimal crew swap decisions, i.e., use available move-up crews to minimize overall passenger delay. For the local case, we give an efficient algorithm. However, optimizing crew swaps over the whole railway network is NP-hard.\r\n", :title "Combinatorial Aspects of Move-Up Crews", :keyword2 0, :authors (16975), :session 196}, 235 {:keyword1 13, :keyword3 80, :abstract "In this talk we present an algorithm that for given precision \\epsilon finds an \\epsilon-approximation for the minimal value of a separable convex function over the mixed-integer points of a polyhedron by calling a certain augmentation oracle based on mixed-integer Graver bases. The running time of this algorithm is polynomial in the encoding length of the input data (including \\epsilon) \r\nand in the number of calls to the oracle. For two-stage stochastic mixed-integer programs with only integer first stage variables, this algorithm even runs in polynomial time in the input length of the problem. \r\n(joint work with Matthias Köppe and Robert Weismantel)", :title "An oracle-polynomial time algorithm for convex mixed-integer minimization", :keyword2 77, :authors (16982), :session 17}, 236 {:keyword1 93, :keyword3 35, :abstract "Estimation of correlations of asset returns lies at the core of modern portfolio management. For the seminal dynamic conditional correlation model of Engle (2002), several generalizations have been proposed recently. In this contribution, we focus on the Flexible dynamic conditional correlation model proposed by Billio et al. (2006). Using both simulation exercises and applications to observed return data, we show that the flexible specification performs well only in very restrictive cases, contradicting the 'flexibility' of the approach. However, our results indicate that model performance can be improved substantially by a particular generalization of the variance specification.", :title "Applied Flexible Correlation Modelling", :keyword2 97, :authors (16981 17004), :session 185}, 238 {:keyword1 57, :keyword3 10, :abstract "Cellular decisions are determined by highly complex molecular interactions. We focus here on interactions in form of signal transduction processes. For such a process we assume that a set of molecules that are important for a biological unit is known. Such a biological unit reacts to external signals or environmental challenges like stimulation or infection. The simplest model of signalling is to collect local data in the form of logical formulas that can be written down in propositional \r\nlogic. The question whether there is a pattern of activations satisfying all formulas is then a SAT problem. Motivated by the study of signal transduction networks in biological applications we introduce a class of SAT problems consisting of 3-literal equivalence clauses plus 2CNF clauses. It is shown that the problems are NP-complete in general, but that a subclass which is relevant \r\nfor the biological application can be solved in polynomial time.", :title "A linear satisfiability algorithm for 3CNF formulas of certain signaling networks", :keyword2 12, :authors (16928 16929 2950 5557), :session 204}, 239 {:keyword1 80, :keyword3 81, :abstract "In mixed-integer nonlinear programming, one typically attempts to define polyhedral approximations for non-linear functions over subregions of the original feasible domain. Of course, the smaller such a subregion, the tighter a polyhedral approximation can be made, but at the expense of considering many additional subregions. We propose to design polyhedral approximations taking into account subdivisions of the value range, i.e. the image of \r\nthe non-linear function. This may yield a much lower number of subdivisions, if the value range is small, and may serve to group subdivisions of the domain by similar values, helping branch-and-bound based solvers avoiding symmetric branches. The value-based decomposition can be formalized as an extended formulation of the convex hull of feasible points conv(x,f(x)). We present a condition when this \r\nreformulation yields exact over- or under-estimators, and examples of non-convex functions that satisfy it. In a purely discrete setting the extended formulation is explicitly characterized for the bilinear functional xy.     ", :title "A value oriented reformuation for a class of MINLP's", :keyword2 77, :authors (16983 16928 16985), :session 17}, 241 {:keyword1 106, :keyword3 16, :abstract "In Umschlagpunkten für den Kombinierten Verkehr werden standardisierte \r\nLadeeinheiten (Container, Wechselbehälter und LKW-Sattelauflieger)\r\nzwischen den verschiedenen Transportmitteln einer Transportkette umgeladen, \r\nu.a. vom Schiff oder LKW auf die Schiene.\r\n Diese Arbeit präsentiert ein Modell und Lösungsverfahren für die Zugbeladeplanung im Kombinierten Verkehr.\r\n\r\nBei der Optimierung der Zugbeladeplanung geht es darum, die Auslastung eine Zuges zu maximieren und gleichzeitig die Kosten zu minimieren. Die Auslastung wird in Anzahl, Länge und Gewicht der aufgeladenen Container gemessen. Kosten entstehen in Form von Transportkosten für den Transport von Containern zu einem der Tragwagen und in Form von Rüstkosten,  wenn Tragwagen umgebaut werden um anders als bisher genutzt zu werden. Die Möglichkeiten einen Tragwagen zu beladen, bestimmen Beladeschemata, die festlegen, wie viele Container-Stellplätze es auf einem Tragwagen gibt, und wie lang und schwer die Container sein dürfen. Eine weitere Nebenbedingung ist die Beschränkung des Gesamtgewichts des Zuges.\r\nEine Lösung des Problems definiert, welche Container aufgeladen werden und die Zuordnung dieser Container auf Tragwagen und Stellplätze. Außerdem müssen für alle Tragwagen die Beladeschemata festgelegt werden. Das Problem wird als lineares Problem formuliert und\r\nmit Hilfe von Standardsolvern, lokaler Suche und einem Dekompositionsansatz gelöst. Es werden Vor- und Nachteile der Lösungsmethoden verglichen.", :title "Optimierung der Zugbeladeplanung im Kombinierten Verkehr", :keyword2 77, :authors (16987 14742), :session 46}, 242 {:keyword1 105, :keyword3 57, :abstract "The train timetabling problem is to find conflict free routes for a set of trains in a given railway network.  In cooperation with Deutsche Bahn AG, we deal with the very large scale problem of constructing such timetables for the German railway network.  A number of restrictions on different train types like freight trains or passenger trains have to be observed, e.g., sequence dependent headway times and station capacities.  In order to handle the normous number of variables and constraints we employ Lagrangean relaxation of the conflict constraints combined with a cutting plane approach.  The model is solved by a bundle method using the primal aggregate for separation as well as a starting point for rounding heuristics.  We present some promising results towards handling a test instance of ten percent of the entire network.", :title "Towards Solving Very Large Scale Train Timetabling Problems by Lagrangean Decomposition", :keyword2 53, :authors (16988), :session 71}, 243 {:keyword1 35, :keyword3 93, :abstract "Textbooks on financial management have emphasized the shortcomings of the payback criterion for decades. However, empirical evidence suggests that in actual capital budgeting procedures the payback method is used quite regularly. Mostly, it is implemented supplementary to net present value or internal rate of return, but small companies tend to rely on payback times as single criterion. A convincing theoretical foundation for the observed use of the payback criterion is lacking. \r\n\r\nThus, our goal is to provide an explanation for the payback criterion's popularity. We demonstrate from a decision theoretical perspective how relying on payback times simplifies investment decisions in modern organizations. Gathering information from different management levels and ensuring the utilization of their individual skills requires a multi-stage capital budgeting process. Accordingly, we consider fundamental organizational features of this process with respect to their impact on the payback method's use. \r\n\r\nFor this purpose, we use almost stochastic dominance (ASD) as modelling device. Firstly, we show that applying this concept allows to include the risk preferences of all relevant decision makers into the analysis. Secondly, it can be shown that conveying these preferences to those who do the preparatory work preceding the final decision can be achieved by means of ASD as well. Hence, by applying almost stochastic dominance we develop a new criterion of investment appraisal coping with major shortcomings of common participative budgeting mechanisms. Further, it turns out that to some extent this new criterion is a generalization of payback times. This finding provides a potential explanation for the payback's persisting prominence.\r\n", :title "A rational for the payback criterion - An application of almost stochastic dominance to capital budgeting", :keyword2 19, :authors (16912 16795), :session 84}, 246 {:keyword1 50, :keyword3 56, :abstract "This paper helps to understand how to form and use a consumer-based brand equity model for improving global business strategies. Because of intense competition in today’s consumer oriented markets, much attention has been devoted to the measurement of consumer-based brand equity by firms. Its importance stems from the firms’ necessity to create strong brands in order to obtain sustainable competitive advantages and to differentiate their products. The Turkish \"`white goods\"' market is also under intense competition. There are four main firms in this market, one of which is German, the market challenger. Besides, new rivals are likely to enter the market. Therefore, it is vital to develop sustainable competitive strategies for all the firms concerned. This research is conducted in a highly industrialized region of Turkey. Three white good brands of the German firm are included in the survey. Consumer-based brand equity models for three brands are formed and validated by means of structural equation modelling approach. Afterwards, global business and marketing strategies are proposed based on the modelling results. ", :title "Measuring Consumer-based Brand Equity by Means of Structural Equation Modelling: A Proposed Model for Improving Global Business Strategies of German \"`White Good Brands\"'", :keyword2 18, :authors (14371 16989), :session 99}, 247 {:keyword1 101, :keyword3 0, :abstract "We consider a scenario, where several suppliers deliver one main manufacturer. The detailed schedules of the parties become deprecated due to machine breakdowns or changing customer preferences. Our goal is to develop a decentralized coordination mechanism that allows to restore feasibility or - at least – to reduce the delay incurred by the ultimate customer. However, confidential information must not be exchanged between the partners. For our prototype we use the SAP PP / DS Optimizer that allows us to handle large-scale scheduling problems and to study the related effects. We show that the coordination scheme enables the whole Supply Chain to act as one virtual enterprise. We underpin the performance of the scheme by presenting some computational results.", :title "Coordination in detailed scheduling", :keyword2 96, :authors (), :session 114}, 249 {:keyword1 19, :keyword3 0, :abstract "Referring to empirical research results, economic literature increasingly addresses the implications of social comparison on incentive contracts by using analytical principal agent models. Contrary to the existing investigations, which are primarily based on the assumption that people merely compare their monetary income with one another, theories of behavioral science suggest that monetary income and effort represent different dimensions of social comparison, which are individually weighted. Within a LEN-framework, the question is discussed how different dimensions of social comparison and their individual weight affect the optimal contract design, assuming that either one agent compares to the principal or multiple agents compare to each other. Status seeking agents are considered who differ with regard to the intensity of other-regarding preferences and the dimensions’ specific relevance. The analysis shows that, if a status seeking agent primarily compares his monetary income, an optimal contract provides additional incentives. In the case of an increasing orientation of the agent towards effort costs a reduction of the incentive intensity is found to be optimal. Given a sufficiently high intensity of other-regarding preferences, situations are identified in which the principal always benefits from the agents’ social comparison, independent of their productivity, by inducing inequity. This is particularly the case if each agent does not equally weight the dimensions of social comparison and if – in the multi-agent setting – a divergent structure of social comparison is assumed. Furthermore, within the scope of a two-agent model, the inclusion of social disutility as additional dimension of social comparison is considered.\r\n\r\n", :title "The Impact of Different Dimensions of Social Comparison in Principal Agent Relationships", :keyword2 25, :authors (16857), :session 82}, 252 {:keyword1 42, :keyword3 0, :abstract "In this presentation we consider the problem of clustering the vertices of a complete, edge weighted graph. The objective is to maximize the edge weights within the clusters (also called cliques). This so called Clique Partitioning Problem (CPP) is NP-complete, but it has several real life applications such as  groupings in flexible manufacturing systems, in biology, in flight gate assignment, etc.. Numerous heuristic and exact approaches as well as benchmark tests have been presented in the literature. Most exact methods use branch and bound with branching over edges. We present tighter upper bounds for each search tree node than those known from literature, improve constraint propagation techniques for fixing edges in each node, and present a new branching scheme.", :title "A New Branch and Bound Algorithm for the Clique Partitioning Problem", :keyword2 8, :authors (12453), :session 14}, 253 {:keyword1 99, :keyword3 0, :abstract "We develop a model of behavior of an investor (under uncertainty and tax exemptions) who wishes to invest in a project of creation of a new firm and faces a timing problem. An optimal rule of investment and its dependence on parameters of the model are obtained. Investigation is based on solving an optimal stopping problem for two-dimensional geometric Brownian motion. We derive the explicit formulas for optimal investment time, optimal tax holidays, investor’s NPV and expected tax revenues from future enterprise into federal and regional budgets. Based on those formulas, an analysis of the influence of tax holidays on investor’s behaviour and tax payments into budgets of different levels is conducted.", :title "Optimal Time to Invest under Tax Holidays", :keyword2 68, :authors (), :session 130}, 256 {:keyword1 8, :keyword3 95, :abstract "We consider the following version of the traveling salesman problem. A set of customers and a depot are given. The set of customers is partitioned into the disjoint subsets. Each subset has a positive weight. A subset of customers is visited if we have visited all customers from this subset. Each customer has a time window when we can visit him. If we arrive too early, then we have to wait. We need to find a Hamiltonian tour which starting and ending at the depot and with minimal total weighted competition time for the subsets. \r\nFor exact solution we develop the dynamic programming method. Unfortunately, it allows us to solve only small instances. So, we apply metaheuristics. Two local search methods Probabilistic Tabu Search and Variable Neighborhood Search are developed for this problem. These methods use a penalty function for the time windows constraints and modify the penalties during the search. Our computational results for Solomon benchmarks (http://myweb.uiowa.edu/bthoa/TSPTWBenchmarkDataSets.htm) indicate that the local search algorithms find exact solutions for small instances and show the same or similar results for higher dimensions.\r\n", :title "Local Search Algorithms for the Generalized Traveling Salesman Problem with Time Windows", :keyword2 59, :authors (3190 16999 39627 17000), :session 171}, 257 {:keyword1 8, :keyword3 95, :abstract "Suppose, that a sequence of objects shall be treated individually in such a way, that the whole solution (collection of treatment decisions) is globally optimal. \r\nThe decision how to treat an object has to be made on the knowledge-basis of the data of exactly k still untreated elements. \r\nEvery time when one object has been dispatched, one new object and its data are published. \r\nThis decision situation is called a lookahead of k objects. \r\n\r\nWe are interested in the influence of this parameter k on the quality of the achieved solution. \r\nThe talk presents simulation and analytic results on the influence of k under certain probabilistic assumptions for several online optimisation problems of that kind:\r\n1. Collecting (already available) objects appearing on a circle by means of (only) forward movements to the next reachable object.\r\n2. Collecting objects on the same circle but now with the choice to change the direction after every collected object.\r\n3. Constructing a shortest travelling salesman tour based on the knowledge of k unvisited towns.\r\n\r\nAnalogous research and investigations have been made for matching and bin packing problems.", :title "On the value of information lookahead in online programming", :keyword2 97, :authors (16796), :session 172}, 258 {:keyword1 54, :keyword3 0, :abstract "In a given decentralized distribution network goods are delivered from a set of distribution centers (DC) over a complex transportation network towards a set of depots. The demand of customers is satisfied by these depots following a direct shipment strategy. The task is to minimize the total distribution costs by finding the optimal number and positions of the depots, while the DC and customers locations are fixed.\r\n\r\nA solution procedure based on a decomposition of the considered two-staged facility location problem is proposed. Subject to the selection of depot locations within this solution procedure a rule-based method for adjusting the existing transportation plan is considered. Through this it was possible to get a realistic estimation of the transportation costs without solving complex vehicle routing problems. For this approach a software prototype was developed. It is now successfully operated by the Deutsche Post AG for planning and optimizing the number and locations of delivery bases within the letter and parcel mail distribution network in Germany.\r\n", :title "Methods for optimizing facility locations in complex distribution networks", :keyword2 0, :authors (), :session 37}, 259 {:keyword1 36, :keyword3 68, :abstract "Until recently, the only considered way, to increase the capacity for bottle neck workshops in semiconductor manufacturing, was to invest in additional machines. In fact, in reality machines often are not in use in spite that the WIP (work-in-progress) quantity of the workshop is high. This typically happens when the process types, that is needed for the WIP, has not been qualified on the machine in question. At the same time, as qualifications take time and hence cost money, we do not want to qualify all process types everywhere.\r\nA tool is needed, which proposes on which machines, process types should be qualified on, in order to obtain a workshop, where the capacity of the machines can be used more efficiently.\r\nFor this, models have been developed to measure the flexibility of the capacity allocation in a workshop. With flexibility we consider the possibility for the workshop operator to flexibly assign jobs such that the workload will be well-balanced on the machines. Furthermore, since machines often break down or need maintenance in semiconductor fabrication plants, it has also been considered that it should be possible to reroute jobs when a machine temporarily become unavailable for processing.\r\nWe will present the flexibility measures that have been developed and give examples how they can be used. Furthermore we will present results from tests indicating that qualifications based on the flexibility measures decreases the production times of the work shops and makes the production of the workshop more robust, i.e. less sensitive for tool breakdowns.\r\n", :title "Flexible Capacity Allocation in Semiconductor Manufacturing", :keyword2 75, :authors (16668), :session 148}, 261 {:keyword1 8, :keyword3 80, :abstract "The literature on discrete facility location often assumes all costs to be linear. In practice, however, it is likely that parts of the cost are non-linear. Convex throughput cost arise, e.g., in facility location models with congestion if customer waiting times are penalized in the \r\nobjective function. Moreover, economies of scale often occur in transportation and give raise to concave transportation cost functions. For both types of non-linearities, this paper investigates a Lagrangean relaxation approach to a multi-type capacitated facility location problem that yields a non-linear knapsack problem as a part of the Lagrangean subproblem. In the first case, the knapsack problem's special concave profit function allows to solve it as a parametric linear program. The second type of knapsack problem shows a convex profit function and can be solved by means of a standard branch-and-bound method that successively refines a piecewise linear approximation by branching. Lagrangean dual bounds on the location problem's objective value are then computed by means of subgradient optimization.", :title "Multi-type facility location with non-linear cost", :keyword2 54, :authors (14847), :session 95}, 262 {:keyword1 8, :keyword3 77, :abstract "The Bandwidth Minimization problem is a classical combinatorial optimization problem. It is formulated as follows: given a graph G=(V,E) on n nodes, find a labeling l such that the maximum difference |l(u)-l(v)|, where (u,v) is an edge in E, is minimized. The problem is NP-hard, even for binary trees. Though much work on the bandwidth problem has been done, the gap between best known lower and upper bounds is still large.\r\nIn this work we report a parallel implementation for solving the bandwidth problem, which combines the best exact method with an efficient heuristic in the parallel solver. Computational results for problem instances with up to 200 nodes are reported.", :title "Parallel Computation for the Bandwidth Minimization Problem", :keyword2 53, :authors (16984 607), :session 20}, 265 {:keyword1 106, :keyword3 63, :abstract "This contribution examines the determination of winning bids in the tendering of trucking contracts. In this scenario, there are two specific features: On the one hand, there are economies of scope between the trucking contracts. This means that for a given bidder, the cost of a single contract depend on which other contracts the bidder wins (e.g. if they are well combinable in a single tour). On the other hand, awarding trucking contracts is a multiple criteria decision. In addition to total transportation cost, the individual performance level of a carrier and the execution requirements specific to each contract have to be taken into account when determining the winning bids. Different requirements may arise from the characteristics of the goods to be transported (e.g. fragile, hazardous) or from different customer needs (e.g. strict time windows).\r\n\r\nIn the transportation procurement literature, approaches considering both economies of scope and multiple decision criteria simultaneously are still missing. We fill this gap by modelling the problem at hand as a combinatorial auction winner determination problem using a set covering formulation with two objective functions (min total cost, max weighted overall contract performance level).\r\n\r\nTo solve the problem, a GRASP based pareto-optimizer is introduced. The algorithm searches for a nondominated solution set and therefore does not require any subjective preference information (e.g an objective weight vector). Nine variants of the algorithm are compared using a set of 810 test instances. The results indicate that during the construction stage, it appears advantageous to consider both objectives, whereas during the local search phase, focusing on one goal tends to result competitive solutions in less computing time.", :title "A Pareto-Optimizer for a Multiobjective Winner Determination Problem in a Combinatorial Procurement Auction for Trucking Contracts", :keyword2 6, :authors (11448 1109), :session 61}, 267 {:keyword1 54, :keyword3 8, :abstract "We study the computational complexity of finding a local optimum for the uncapacitated facility location problems under the neighborhoods obtained by the Swap and Flip procedures. It is shown that the local search problems are tightly PLS-complete. So, the standard local improvement algorithm takes an exponential number of iterations in the worst case regardless of the tie-breaking and pivoting rules used. In the problem of finding a local optimum for a given initial solution, we obtain that the problems are PSPACE-complete.", :title "Complexity of local search for the uncapacitated facility location problems", :keyword2 10, :authors (12530 3190), :session 95}, 268 {:keyword1 16, :keyword3 18, :abstract "The problem of packing different-sized circles and rectangles into the strip of the minimal length is considered. To represent solutions we introduce a so-called 2-contact encoding scheme leading to a finite solution space. Each solution is presented by the permutation of circles and rectangles. Each permutation can be transformed into the packing by a greedy decoding procedure in polynomial time. For solving this NP-hard problem we have developed a probabalistic tabu search algorithm. A quadratic neighborhood based on two operations for permutations is applied. The algorithm adaptively controls the used part of the neighborhood, depending on the frequency of the good solutions found. \r\nWe have tested the developed algorithm on the instances from Stoyan and Yaskov library for the circular strip packing problem. The best known solutions for four instances have been improved by our algorithm. The algorithm has also been tested on random instances for packing circles and rectangles simultaneously. The computational experiments show the effectiveness and efficiency of the proposed method. In some additional cases we compare our solution also to known global solution in the literature.", :title "Probabalistic tabu search for packing circles and rectangles into the strip", :keyword2 59, :authors (16967 3190), :session 178}, 269 {:keyword1 75, :keyword3 0, :abstract "The paper elaborates an algorithm to determine production plans by minimizing inventory holding cost with respect to lot size restrictions and not the sum of setup cost and inventory holding cost, as in mainstream models. Such approach is common in practice and justified by the fact that setup cost are difficult to quantify correctly. Therefore, one prefers to determine optimal production plans by specifying a minimum lot size parameter, instead of using setup cost restrictions. Furthermore, algorithms published so far for various lot size problems do not draw much attention to the structure of the demand inputs. Current paper presents an attempt to reduce the complexity of the algorithm by considering special characteristics of demand values, such as the relation of cumulative demand to the lower bound and jumps in the demand in various periods.\r\nIn the paper we present an efficient dynamic algorithm for a lot size problem where the mini-mum lot size restriction plays the role of the setup cost in the original Wagner/Whitin model. The main idea consists in decomposing the problem into series of sub-problems for smaller time horizons. The selection of such sub-problems and the determination of an optimal com-bination of their sub-horizons are investigated in detail. Furthermore, we study minimal sub-problems for which the inventories are strictly positive within the sub-horizons and inspect the so-called critical periods that help us to reduce the search space drastically. As a result, we provide the explicit recursions to determine optimal solutions for both limited sub-problems (with zero end inventories) and unlimited sub-problems (with variable end inventory that may be positive). Finally, we present computational study and compare our algorithm with other methods.", :title "The single item dynamic lot sizing problem with minimum lot size", :keyword2 76, :authors (14720 14722), :session 150}, 270 {:keyword1 8, :keyword3 0, :abstract "Given a graph with weighted edges and n nodes, the optimum\r\ncooperation problem consists in determining a partition of the graph that maximizes the sum of weights of the edges with nodes in the same class plus the number of  classes of the partition. The problem is also known in the literature as the optimum attack problem in networks. Furthermore, a relevant physics application exists.\r\n\r\nIn the talk, we present a fast exact algorithm for the optimum cooperation problem. Algorithms known in the literature require n-1 minimum cut computations in a corresponding network. By theoretical considerations and appropriately designed heuristics, we considerably reduce the numbers of minimum cut computations that are necessary in practice. We show the effectiveness of our method by presenting results on instances coming from the physics\r\napplication that consists of determining ground states for Potts glasses with a large number of states.", :title "A Fast Exact Algorithm for the Optimum Cooperation Problem", :keyword2 42, :authors (12969 14713), :session 204}, 271 {:keyword1 120, :keyword3 56, :abstract "Supervised classification is an important part of data mining for customer relationship management. The paper proposes a hierarchical reference model for support vector machine based classification within this discipline. The approach balances the conflicting goals of trans-parent yet accurate models and compares favourably to reference classifiers in a large scale empirical evaluation in real-world customer relationship management applications. Recent advances in support vector machine research are incorporated to approach feature, instance and model selection in a unified framework.", :title "A Framework for Customer-Centric Data Mining with Support Vector Machines", :keyword2 37, :authors (9422 5931), :session 157}, 272 {:keyword1 77, :keyword3 0, :abstract "Die Vergabe von Kursplaetzen im Fachbereich Biologie der Universitaet Osnabrueck erfolgt derzeit durch ein manuelles Verteilungsverfahren. Da bestimmte Kurse (Uebungen, Praktika) nur mit beschraenkten Teilnehmerkapazitaeten angeboten werden koennen, ist es nicht moeglich, dass alle Studierenden alle gewuenschten Kurse bekommen. Zur Zeit ordnet der Fachbereich jedes Semester auf der Basis von \r\nPraeferenzlisten der Studierenden und anderer Restriktionen (wie z.B. Studiengang und -semester), den Studierenden manuell einige Kurse zu. \r\nDa sich die Studierenden in der Vergangenheit ueber suboptimale Ergebnisse beklagt haben, wurde nach neuen computerunterstuetzten Verfahren gesucht.\r\n\r\nEs wurde ein automatisches System entwickelt, das die Praeferenzen der Studierenden erfasst und eine moeglichst gute Zuordnung berechnet. \r\nBei dem Zuordnungsproblem sind n Studierende gegeben, die aus m Kursen mittels Praeferenzlisten auswaehlen koennen. Die Kurse haben untere und obere Teilnehmerkapazitaeten sowie feste Termine. Das Ziel besteht darin, den Studierenden so Kurse zuzuordnen, dass\r\n(i) jeder Studierende moeglichst genau seine benoetigte Anzahl an Kursen bekommt,\r\n(ii) die Kapazitaets-Restriktionen der Kurse eingehalten werden, \r\n(iii) die einem Studierenden zugeordneten Kurse keine Zeitkonflikte haben und \r\n(iv) die Praeferenzlisten moeglichst gut beruecksichtigt werden.\r\nZur Loesung dieses NP-schwierigen Problems werden ganzzahlige lineare Programmierung und lokale Suche verwendet.\r\n", :title "Verfahren zur Vergabe von Kursplaetzen mit beschraenkten Teilnehmerkapazitaeten", :keyword2 0, :authors (16888 14742), :session 53}, 274 {:keyword1 79, :keyword3 0, :abstract "Usually, the Pareto-critical points of an unconstrained multicriteria minimization problem are nonisolated. To compute one of these points, we therefore suggest to apply a Levenberg-Marquardt type algorithm to the necessary KKT optimality conditions. For its fast local convergence we provide sufficient conditions for an error bound.\r\nIn addition, we propose two globalized Levenberg-Marquardt algorithms for finding a Pareto-critical point. The first is based on the descent of a merit function using the Levenberg-Marquardt direction. If the objective functions are convex and at least one of them is strongly convex the algorithm is globally convergent. The second algorithm combines the Levenberg-Marquardt direction and a simultaneous descent direction. Global convergence can be shown if all the objective functions are convex. Computational results are presented as well.\r\n\r\n", :title "Levenberg-Marquardt algorithms for unconstrained convex multicriteria optimization.", :keyword2 0, :authors (14587 17041), :session 78}, 275 {:keyword1 22, :keyword3 57, :abstract "If it is necessary to evacuate large parts of a city due to a disaster there will be the need to restructure the traffic routing to ensure a fast and a safe evacuation. For this reason a basic mixed integer evacuation model has been developed. This basic problem of evacuation minimizes the evacuation time while prohibiting conflicts within junctions to a new traffic routing plan. The basic evacuation model is a network flow problem with additional variables for the number and direction of the used lanes and with complicating constraints. Because of the detailed modeling of junctions the computational effort required by standard software is already very high for tiny instances. To deal with realistic instances we propose an algorithm that can manage this problem. The basic evacuation problem describes the flow of evacuees, which means that there is just the direction from the danger zone to the safe zones. It is intuitive that there are few flow crossings desired to lead the flow fast out of the danger zone. The algorithm to solve this basic evacuation problem uses this observation to compute a solution fast. This basic evacuation model cannot only be used for restructuring the routing plan. It can moreover be used to estimate the real evacuation-time, concerning decisions if evacuation is reasonable or if the affected population should rather stay at home and close the windows and doors, for example in case of an chemical accident.", :title "Basic Models and Methods for Evacuation in Urban Areas", :keyword2 73, :authors (16916 14715), :session 75}, 276 {:keyword1 92, :keyword3 75, :abstract "Scarcity of resources, increasing costs of raw materials, growing awareness of environmental performance of firms by customers and rigorous environmental legislation lead to multiple uses of products. An option to bring defectives up to reusable condition is remanufacturing, which is considered in this contribution. I examine a dynamic inventory system with returns. Besides the common options for returns to be stocked or remanufactured, the returns can also be disposed of in this model. Especially the impact of this disposal option for the returned products on the optimal solution were not often analysed, even though it is an important alternative for the production planning of seasonal and end of life products. We consider holding costs for returns and for saleable items and disposal costs. Furthermore, joint setup costs are taken into account if a lot is completely newly produced, completely remanufactured or partially remanufactured and newly produced in one period. This situation can be found in the production of spare parts for automotives, such as clutches and alternators, automates and industrial steel ball bearings. \r\nIn this contribution several optimality conditions are proved. They are the basis for the construction of a polynomial algorithm, which determines how many returns are to be stored, recovered or disposed of, how many products are to be newly produced and which amount of serviceables should be stocked in each period so that the total costs are minimal. \r\nThe proposed algorithm can be used to solve problems with an allowed maximum ending inventory of returns too. Hence the model without disposal option and its algorithm as published by Teunter et al. in 2006 is a special case of the one discussed in this paper.\r\n", :title "Integration of a disposal option in a reverse logistics model with setups and time varying returns and demands", :keyword2 76, :authors (), :session 93}, 278 {:keyword1 101, :keyword3 0, :abstract "In buyer-supplier relationships, firms often expect a level of performance and flexibility that goes well beyond contractual requirements. In fact, supply relations are often governed by so-called relational contracts. These are informal agreements sustained by the value of future cooperation. Although relational contracts persist in practice, research on these types of contracts is only emerging in Operations and Supply Chain Management. This paper studies a two-firm supply chain, where repeated transactions via well-established supply contracts and continued quality-improvement efforts are governed by a relational contract. We are able to characterize an optimal relational contract, i.e., to develop policies for supplier and buyer that structure investments in quality and flexibility in a way that no other self-enforcing contract generates higher expected joint surplus. For this purpose, we study an infinite horizon dynamic game with Markovian dynamics modelling the stochastic influence of the firms’ actions on quality. We examine both quantity-based (quantity flexibility contracts) and price-based returns (buy backs) mechanisms. Hence, a second goal is to compare the performance of different returns mechanisms in the context of relational contracting.", :title "Quantity Flexibility Contracts and Buy Backs in the Context of Relational Contracting", :keyword2 40, :authors (16921 17230), :session 112}, 280 {:keyword1 86, :keyword3 59, :abstract "In this talk we present a Genetic Algorithm for generating efficient solutions for multi objective resource constrained project scheduling problems where contrary regular as well as non regular performance measures have to be respected. The heuristic is similar to the one developed by Alcaraz and Maroto (2006), i.e. the genes of the genotype do not only represent activities of the phenotype but also the decoding scheme and modus. In order to reduce complexity not all Pareto efficient solutions are saved, since a large number of (mostly similar) solutions would usually not be of great help/support for a planer/decision maker. Thus, we propose an \"`adapted Pareto operator\"' which does not accept every solution, but efficient solutions only which differ (substantially) with respect to solution quality and structure. We have applied this procedure to solve the Movie Shoot Scheduling Problem and we report first results.", :title "A Genetic Algorithm for Multi Objective Ressource Constrained Scheduling - Application to the Movie Shoot Scheduling Problem", :keyword2 18, :authors (14755 17029), :session 59}, 282 {:keyword1 106, :keyword3 18, :abstract "Railway crew scheduling deals with the problem of assigning crews to trains of a given schedule at minimal costs while complying with numerous operational and contractual requirements. The determination of an optimal allocation of crew bases as well as suitable staff sizes is an essential step in the overall strategic planning process at railway companies.\r\nThe current planning system at our industry partner Deutsche Bahn (DB) has its focus on operational crew scheduling only and does not allow crew schedule optimization for the evaluation of future timetable drafts. In our research, we are developing a methodology and a DSS prototype for supporting the decision making processes at DB by enabling scenario analyses of future timetables with respect to alternative crew base configurations and service levels.\r\nWe have modeled this \"`strategic\"' crew scheduling problem as a mixed integer program and we have developed a column generation based optimization system. Here, the master problem deals with global constraints such as the distribution of pairings among the crew bases and maximum number of night stops while more detailed and local constraints concerning work time regulations, rests etc. are respected in the sub problems. In contrast to airline crew scheduling problems, railway crews can change trains at every intermediate stop, which vastly increases the number of possible combinations for the pairing generation process and the dimension of the MIP. Since our industry partner DB operates one of the world’s largest and busiest train networks, managing problem size as well as the complex requirements and diverse objectives is rather challenging.\r\n", :title "on.Track – Strategic Railway Crew Scheduling at Deutsche Bahn", :keyword2 96, :authors (14755), :session 199}, 284 {:keyword1 94, :keyword3 68, :abstract "The consideration of uncertainty in production planning systems provides a great advance. Models for production planning that explicitly account for the uncertainty of the data can be expected to generate superior planning decisions as compared to models that disregard uncertainty. \r\nWe present an alternative approach that applies robust planning methods in a hierarchical production planning system. These methods generate robust plans for production planning problems by explicitly incorporating the uncertain data as well as the available flexibility to react to unforeseen events. The necessary modifications of the models are discussed leading to the new model formulations for the aggregate planning level and the lot-sizing level. The main focus lies on the use of stability restrictions in order to dampen planning nervousness.\r\nThe robustness and effectiveness of the developed concept, in comparison with a deterministic planning approach using safety stocks to account for uncertain demand, are demonstrated by numerical results. Since the robust planning approach needs a higher computational effort, the circumstances are being analyzed in which the robust planning approach is advisable. The results show that the new approach achieves significant advantages when less flexibility is available to react to unforeseen events.", :title "Robust hierarchical production planning", :keyword2 101, :authors (1131), :session 210}, 285 {:keyword1 106, :keyword3 98, :abstract "Service network design problems(SNDP) are the main in the transportation and logistics. The main goal is to determine cost minimizing routes and schedules subject to constraints on flows delivery satisfaction, resources availability and service level. One of the main complexities of solving the real-life SNDP deals with mathematical model developing. On the one hand we need guarantee the solution's quality and on the other hand our model must be solved quickly. Our work is devoted to mathematical model developing and solution approach for SNDP. In the core of the model we have MILP solved by using common branch-and-cut methods combined with some heuristic. Integer variables column of the MILP consists of the routes of carrier's vehicles.\r\nThe number of integer variables for real-life problems is rather huge. The feature of the proposed model are the choice of integer variables column (IVC). The main idea consists of generation the number of vehicle routes that cover the transportation network. The number of routes are bounded by some route's parameters - maximal edges number for the route, maximal length. Every route is reversive. Despite these reductions the main task still remains unsolvable for large-scale real problems. Due this problem we propose heuristic consisted of partition the main problem into number of subproblems. Every subproblem's solution is the subcolumn of the main problem's IVC and union of all the subcolumns generates new IVC for the main task. For every specific domain we need to determine the structure and the number of the subproblems. The proposed model and methods implemented in software system allowed to solve service network design problem for many applied domains. The real-life experiments for postal industry are also proposed. \r\n", :title "An Optimization Model for the Service Network Design Problem", :keyword2 53, :authors (17031 17015), :session 201}, 288 {:keyword1 54, :keyword3 0, :abstract "In the facility location problem with hard capacities (CFLP) we are given a set of facilities F, and a set of clients C. Each facility i \\in F has a nonnegative integral capacity ui and can be closed or opened. Cost of opening the facility i is equal to g_i greater equal 0. Each client  j \\in C has a nonnegative integral demand d_j, that must be serviced by opened facilities. Servicing a unit of demand of client j by facility i costs c_{ij}. The objective is to minimize the total cost concerned with opening facilities and servicing all clients. \r\nIt is well known that CFLP is NP-hard. We study a special case of  the problem - CFLP with hard capacities (Uniform CFLP), when all facilities have equal capacities u_i=u. In this paper we describe two different types of  Uniform CFLP.\r\n1. Uniform CFLP with random instances. We assume that elements of matrix (c_{ij}) take random values according to discrete uniform distribution. We construct the fast approximation algorithm to solve Uniform CFLP. A key role in this algorithm belongs to the procedure of finding the minimum-weight perfect matching in graph with random weights. We demonstrate the probabilistic analysis of this procedure and establish conditions of the asymptotical optimality.\r\n2. Uniform  CFLP on path graphs. We assume that F and C are disjoint vertex subsets of a path P=(V,E) with V=F C. The cost c_{ij} is equal to sum of edge lengths in the path from i to j. For solving this problem it is known optimal algorithm with time complexity  n^3m^3+n^5m^2, n=|C|, m=|F| (A.A. Ageev, 2004). We suggest a modification of this algorithm that works in time n^4m^2, that improves the required time on order of magnitude.  \r\nThe work is supported by grand RFBR (project 08-01-00516).\r\n", :title "Approximation and Optimal Algorithms for Uniform CFLP", :keyword2 0, :authors (16961 10785), :session 95}, 289 {:keyword1 14, :keyword3 0, :abstract "Problems and methods presented in this paper synthesize foundations of theory of continuous set partitioning problems (SPP) and optimal control of systems described by ordinary differential equations. In order to mathematically formulate SPP quite often one should take into account the temporal and spatial changes of object or process state. Some of such models concerned with problems of preservation of the environment were learning by our scientists. Mathematical models of problems mentioned above are new from the viewpoint of problem statement and interesting to further generalization and developing of theoretical results which could be used in practice widely. A common SPP could be formulated as follows: it is necessary to partition a given area (set) into a finite number of disjoint subsets that satisfies to certain restrictions so that the objective function reaches an extreme value. We propose a new problem statement, which differs from known ones in the following way: the desired set partition is dynamic in consequence of 1) a function which describes the certain object or process state varies with time; 2) a function, choice of which has an influence on state of this object or process, is defined by partition of considered set each moment of time. This problem amounts to optimal control one for which one should write out the necessary conditions of optimality in the form of Pontryagin maximum principle. The constructed algorithm for solving such problems bases on combining both the methods of solving continuous SPP and methods of optimal control theory. With a view to investigate the properties of solutions of new set partitioning problem we realized the series of computational experiments and made qualitative analysis of obtained results.\r\n", :title "The Features of Solving of the Set Partitioning Problems with Moving Boundaries between Subsets", :keyword2 23, :authors (17011 17059 17058), :session 137}, 290 {:keyword1 8, :keyword3 77, :abstract "Given a directed graph D = (V,A) with a root s in V such that a non-negative weight is associated with each arc in A, we consider the problem for finding a minimum weight k\r\nspanning in-trees rooted at s which cover A. Here the weight of k spanning in-trees is defined as the sum of weights of all arcs contained in these in-trees. We will show that this problem can be solved in polynomial time. For this, we first consider the set of linear inequalities in R^A that coincides with the convex hull P(D) of a |A|-dimensional positive integral vector x such that we can cover A by k spanning in-trees rooted at s such that e in  A is contained in x_e in-trees where R represents the set of reals. After this, we will show that the separation\r\nproblem for this polytope can be solved in polynomial time, which implies the polynomial solvability of the minimum weight in-tree cover problem in conjunction with the ellipsoid method. Furthermore, we will consider the generalization of the minimum in-tree cover\r\nproblem such that the input directed graph has multiple roots. Although this problem is still open, we give the generalization of the lemma presented by Vidyasankar which is used to derive the set of linear inequalities which determine P(D) to the case of multiple roots.", :title "A Polytope for Covering Directed Graphs by In-trees and the Minimum Weight In-tree Cover Problem", :keyword2 42, :authors (3297 17017), :session 195}, 291 {:keyword1 8, :keyword3 0, :abstract "We make several observations on approximation algorithms for some generalizations of TSP that are also NP-hard. The classical TSP consists in finding in given graph a Hamiltonian circuit with minimal (or maximal) total edge weight.  As its natural generalization is a problem of finding m edge-disjoint Hamiltonian circuits in complete weighted graph. The problem is known also as m-Peripatetic Salesman Problem (m-PSP) that was formulated for the first time by J. Krarup in 1975.  Another modification of TSP (called by DCSSP) is a problem of finding  a degree-constrained connected spanning  subgraph with  extreme  total weight of edges in complete weighted graph.  In the report polynomial approximation algorithms with performance guarantees are presented for the minimum-weight 2-PSP on metric distances; for the maximum-weight  2-PSP on symmetric distances; for the minimum-weight 2-PSP on the graph with distances 1 and 2; for the maximum-weight DCSSP.  In the cases of the maximum-weight m-PSP in Euclidean space and of the maximum (or minimum)-weight d-regular DCSSP on random instances polynomial approximation algorithms are also constructed and conditions of asymptotic optimality are established. The results was obtained within RFBR and INTAS grants jointly with author’s colleagues A.A. Ageev, A.E. Baburin, Y.V. Glazkov, A.N. Glebov, and N.M. Korkishko. The work was supported by grants RFBR (projects 08-01-00516  and 07-07-00222).", :title "Approximation Polynomial Algorithms for Some Modifications of TSP", :keyword2 0, :authors (10785), :session 23}, 293 {:keyword1 8, :keyword3 0, :abstract "Probabilistic analysis of fast approximation algorithms for travelling salesman problem (TSP) is the subject of many recent investigations (Karp, Frieze, Radhavan, Gimadi, etc.) and is considered important nowadays. We single out relative error(RE) and failure probability(FP) among characteristics of the algorithms. We obtain estimates of these two characteristics under the assumption that instances are equally distributed. Hence the estimates of  RE and FP depend on the distribution class.\r\nWe demonstrate the probabilistic analysis of the algorithm modification \"`Nearest City\"' (NC) for solving minimum TSP. We consider TSP under the assumption that elements of distance matrix take values unbounded from above and have the normal (different types of truncated normal) and exponential distribution. As a result the estimates of RE and FP are obtained. Moreover the condition of the algorithm asymptotical optimality is found.\r\nThe probabilistic analysis of TSP is useful for vehicle routing problems. We consider k-customer vehicle routing problem (k-VRP) with normal distributed instances. A set of customers has to be served by a fleet of identical vehicles. The vehicles are initially located at a depot. The objective is to find a set of routes such that each route begins at the depot, visits k customers, and then returns to the depot; and the total length of the routes is minimized. We find the approximation solution of k-VRP using algorithm modification NC. We get the estimates of RE, FP and the condition when the algorithm is asymptotically optimal. All obtained results are valid for directed and undirected graphs in the case of TSP as well as of k-VRP. The work is supported by grand RFBR (project 08-01-00516).", :title "On some routing problems with instances unbounded from above", :keyword2 95, :authors (16782 10785), :session 77}, 294 {:keyword1 5, :keyword3 40, :abstract "The report introduces an electronic practical work on the following sections of the course  \"` Matrix games \"': a principle of minimax, graphic methods, bringing matrix game to a problem of linear programming, an iterative method, games with nature, bi-matrix-games. The teaching material of the electronic practical work is done according to the uniform model of the pedagogical script which includes: idea of method, algorithm, example, exercise.\r\nThe training elements are arranged and carried out by means of mathematical applets (written in Java), that gives students an opportunity to visualize the process of decision, constructing and concluding.  The electronic practical work realizes individualized training, releases from routine calculations, solves the problem of visualization. While generalizing spatial experience, comparing theoretical questions with putting them into practice the work forms skills of creative activity due to the prevalence of cognitive approaches of representation of knowledge. .\r\nThe developed programme-methodical complex for the course  \"` Matrix games \"' is included in electronic educational environment ActiveMath [2,3] (DFKI at University Saarland, Germany, project LeActiveMath, http: // www.leactivemath.org, Programs FP6-IST of the European Union).    \r\n1.Goguadze G., Melis E., Izhutkin V., Izulanov Y. Interactively Learning Operations Research Methods with ActiveMath // Abstracts  of the Symposium on Operations Research (OR2003),Heidelberg, 2003, P.159.\r\n2.Melis, E., Goguadze, G., Homik, M., Libbrecht, M., Ullrich C.,Winterstein S., Semantic-Aware Components and Services of ActiveMath. -British Journal of Educational Technology. 2005.\r\n\r\n", :title "Virtual Electronic Practical Work on Matrix Games", :keyword2 27, :authors (16938), :session 104}, 295 {:keyword1 8, :keyword3 106, :abstract "Meta-heuristic methods are widely used for solving NP-Hard combinatorial optimization problems. In this study, we develop a hybrid framework that combines some well-known meta-heuristic methods with exact methods for solving combinatorial optimization problems, which can be formulated in the form of a set-covering problem through Dantzig-Wolfe decomposition. The variables of the Dantzig-Wolfe decomposition master problem are the columns generated by a meta-heuristic method. These columns are then stored in a pool, in which a set-covering problem is solved by an exact solution method for linear/integer programming problems. Hence, the hybrid framework has two important aspects. First, the local search algorithm is provided with a decision support tool using optimization methods. The local search is paused in prespecified intervals and the direction of search (diversification/intensification) is determined according to the solution of the set-covering problem. Second, the pricing problem for the column generation process is implemented using the columns generated in the meta-heuristic method. To test the performance of this generic framework, we conduct experiments on the vehicle routing problem with time windows using tabu-search as the accompanying meta-heuristic method.", :title "Combination of  Meta-Heuristic and Exact Methods for Solving Set-Covering-Type Optimization Problems", :keyword2 59, :authors (16992 406 14274), :session 156}, 296 {:keyword1 16, :keyword3 77, :abstract "We propose a constraint-based approach for the two-dimensional rectangular packing problem with orthogonal orientations. This problem is to arrange a set of rectangles that can be rotated by 90 degrees into a rectangle of minimal size such that no two rectangles overlap. It arises in the placement of electronic devices during the layout of 2.5D System-in-Package integrated electronic systems.\r\n\r\nMoffitt et al. (2006) solve the packing without orientations with a branch and bound approach and use constraint propagation. We generalize their propagation techniques to allow orientations.\r\nOur approach is compared to a mixed-integer program and we provide results that outperform it.", :title "A Constraint-based Approach for the Two-dimensional Rectangular Packing Problem with Orthogonal Orientations", :keyword2 8, :authors (16904 15197 15433), :session 24}, 297 {:keyword1 91, :keyword3 56, :abstract "Revenue management (or yield management) provides methods to control the availability and price of limited capacity resources when demand is uncertain and heterogeneous. Thus, the classical and thereby transaction-focused revenue management seems to maximize short-term revenues. However, it primarily accounts for the short-term willingness to pay. Hence, it does not allow to establish relationships with customers whose customer value is mainly based on indirect or prospective contributions, but not on a high actual willingness to pay. \r\nTherefore, this paper addresses this shortcoming and suggests a conceptual model of revenue management with regard to customer value. Thus, the approach intends to efficiently utilize capacity resources while establishing profitable customer relationships at the same time. The tasks of value-based revenue management are discussed, and process models are developed for the operational tasks. Afterwards, the conceptual model is evaluated with the help of simulation studies. A following sensitivity analysis supports the expectation that considering customer value-related information leads to greater long-term revenue potential than transaction-focused capacity control, especially if short-term willingness to pay and long-term customer value are non-positively correlated. Finally, some concluding remarks and an outlook on remaining research are given.", :title "Incorporation of Customer Value into Revenue Management", :keyword2 2, :authors (17020 17022), :session 99}, 301 {:keyword1 106, :keyword3 0, :abstract "Consider a number of N uniform blocks (e.g. containers) which are stored in a two-dimensional stock. The blocks are piled up on top of each other in stacks and the stacks are positioned in a single row. A feasible setting has the following properties: Each block is positioned either on the ground or on top of another block. Relocation is only possible if the relocated block is the highest block in its stack. \r\nThe blocks relocation problem is the following: The N blocks have to be retrieved from the stock (e.g. to be loaded onto a truck or ship) in a given order. Blocks can be accessed only if they are free, i.e., if there are no other blocks on top. Thus, throughout the retrieving process relocations may become necessary to keep the predefined order. The problem is: Minimize the number of relocations. This question is related to the pre-marshalling problem. The main difference is that in pre-marshalling the relocation process is separated from the retrieving process, whereas in blocks relocation we allow to relocate while we are retrieving. Applications are found, e.g., in container storage or handling of pallets.\r\nIn this talk, we present two binary linear programs to model the blocks relocation problem. A first approach covers the situation completely but for the price of dealing with a large model. In a second approach, we apply a set of meaningful additional assumptions. This allows us to reduce the problem size and to gain results for larger instances. Furthermore, to address real-time problems, we propose a heuristic method based on a priority rule. Finally, we present computational results for both, the exact model and the heuristic and compare them with results provided in literature. \r\n", :title "The blocks relocation problem", :keyword2 57, :authors (16889 5931), :session 73}, 303 {:keyword1 34, :keyword3 0, :abstract "Financing a privately owned home is certainly one of the major and most demanding financial goals an uncountable number of households strive for. The whole process of financing usually requires a period of saving necessary to get the desired or required amount of equity, followed by the purchase of a house and the amortisation time of the debt, most often borrowed in the form of mortgages. During the initial savings period the household will still live in a rented home. Given limited resources, particularly a given planned amount of monthly income, one of the most important aspects for many families is the point in time when all the debt is finally redeemed. Unfortunately, this point in time is at risk, as unanticipated changes in income or financing costs may enforce a longer time for repaying. In this paper, we address this risk, which is a risk in the dimension of time, for the first time. To structure and analyse the risk we set up a basic model which captures the most important risk factors for typical households, particularly changes in interest and inflation rates. \r\n\r\nWe consider six major risk factors: house price, income, rent, maintenance and interest rates for savings and loans respectively. The analysis of the complex interactions of those variables provides first insight in the risk structure of the process of combined saving and financing. As the model is too complex to derive analytical results we conduct simulations based on real and artificially generated data. This provides insight into the distribution of time needed to complete the process as a result of different scenarios. \r\n", :title "How long does it take to finance a privately owned home? A six variable model", :keyword2 0, :authors (14810 9096), :session 84}, 304 {:keyword1 33, :keyword3 68, :abstract "An increasing amount of the worldwide container traffic force container terminal providers to extend their capacities. To manage this, new container terminals are built or the capacity of existing ones is expanded using modern container handling technologies. To ensure an efficient operation of the reorganized terminals an appropriate layout of a container terminal is essential. We examine mathematical models and their solution methods to provide decision support for the strategic planning of container terminal layouts.  Based on continuous formulations for the facility layout problem we develop a specific model for the layout design of container terminals. Simulation studies are used to evaluate the solution quality and the adequacy for container terminal layout design.", :title "Decision Support for Strategic Layout Planning of Container Terminals", :keyword2 97, :authors (15361 1194 1141), :session 58}, 305 {:keyword1 86, :keyword3 98, :abstract "The resource-constrained project scheduling problem RCPSP can be described as follows. Given is a set of non-interruptible activities, a set of precedence constraints among these activities, and a set of scarce resources. Each activity requires a prescribed amount of time and a prescribed amount of each resource during execution. Sought is a baseline schedule, i.e. a start time for each activity, such that (a) the precedence constraints are fulfilled, (b) for every resource, at no point in time the total requirement exceeds the available capacity, and (c) the total project duration is minimized.\r\n\r\nFor this problem, a large variety of exact and heuristic solution methods has been presented in the literature. In our talk, we report on the results of an experimental performance analysis where we have compared recent versions of commercial project management software packages against the best of these solution methods. For our analysis, we have used all 1440 RCPSP instances of the standard test set PSPLIB. ", :title "Project Scheduling with Precedence Constraints and Scarce Resources: An Experimental Analysis of Commercial Project Management Software", :keyword2 55, :authors (125 17023), :session 55}, 306 {:keyword1 96, :keyword3 0, :abstract "The research concerns the problem of selecting and executing a set of jobs, modeling customer orders, on a set of parallel identical machines to maximize revenue. Each job is described by the release time, at which it becomes available, and the processing time, for which it has to be performed without preemption. All jobs selected for execution in a system have to be completed before their deadlines. Moreover, due date is defined for each job, which determines its latest finishing time resulting in full revenue. If job completion time exceeds its due date, the revenue is decreased by the weighted tardiness, which represents the fine paid by a system owner to a customer for feasible delay. The goal is to select a subset of jobs and to schedule them between release times and deadlines on identical parallel machines in order to maximize the total revenue. Since the problem under consideration is NP-hard, we propose the simulated annealing method (SA) for solving it efficiently. The solution is represented as an assignment of jobs to machines. The sequence of a subset of jobs on a particular machine is determined by the list scheduling approach. SA starts with a heuristic schedule and interchanges or shifts jobs between machines depending on the neighborhood definition. The metaheuristic is additionally equipped with the intensification and diversification procedures. We compared the time efficiency and solution quality of SA and the exact method as well as the list scheduling algorithm in computational experiments, performed for a set of randomly generated input instances of various characteristics in terms of the distribution of release times, due dates and deadlines over time.", :title "Metaheuristic Approach to Revenue Maximization on Parallel Machines", :keyword2 59, :authors (6621 17025), :session 57}, 308 {:keyword1 34, :keyword3 0, :abstract "It is useful for investors including banks to be able use corporate ratings as an index to measure the credit risk of each company. But Corporate ratings by 4 major rating agencies such as Moody's, S\\&P, JCR and R\\&I are based on the quantitative data and qualitative information in Japan.\r\nUnfortunately investors do not obtain that qualitative information completely.\r\nThere are urgent needs to make clear the rating method by rating agencies.\r\nThere have been many works to make clear the determinant structure with rating ranks using the methods like multiple regression method. But it becomes clear that it is difficult to find the structure using multiple \r\nregression method.\r\nWe have proposed the method to evaluate the determinant structure of corporate ratings given by the above four agencies using a neural network method with the quantitative data (financial and accounting data) only.\r\nIn this paper we examine the structural stability over periods of rating method by 4 rating agencies using neural networks with the data for six years from 2001 to 2006 in Japan.", :title "Empirical Study on the structural stability of corporate ratings by Neural networks approach in Japan", :keyword2 0, :authors (14775 14943 17174), :session 90}, 310 {:keyword1 59, :keyword3 106, :abstract "The open vehicle routing problem (OVRP) is a variant of the classical vehicle routing problem (VRP) where vehicles need not return to the depot after serving the last customer on the tour. Recently, the OVRP with time windows (OVRPTW) has been defined, requiring customers to be delivered within specified time windows. We have implemented different local search and large neighborhood search strategies which have been proposed for vehicle routing problems to solve the OVRP and the OVRPTW. We present the experiences of our computational study based on standard instances from the literature regarding the impact of different components and parameterizations of the heuristics, such as neighborhoods, construction methods and metaheuristic controls, on the quality of the solutions which improve on previously published results for the two problems.", :title "Recent results and a computational study on neighborhood search strategies for open vehicle routing problems", :keyword2 95, :authors (14762 14755 17035), :session 69}, 312 {:keyword1 120, :keyword3 0, :abstract "Classification methods work best when all training cases are uniquely labeled and when the number of cases grossly exceeds the number of features available.  \r\nIn real world applications concerning classification of the expected behavior \r\nof clients, of the expected performance of firms or products, to name just a few,  \r\ndata sparseness may occur for many reasons. This clearly reduces the potential performance of \r\nvery powerful classifiers like distance-kernel based Support Vector Machines (SVM).\r\nAssuming that the data observed so far are not erroneous, i.e. falsely labeled, etc., one \r\nmight wonder whether it is possible to replicate to some extend what humans are accomplishing \r\nwith ease in some contexts, namely generalizing from a few (often complicated) examples\r\ninto many more valid examples. Such human skills may not include correct labeling of cases\r\nbut may be limited to the recognition of some broader set membership.    \r\nA possible approximation to such a task is generating fictitious training data \r\nby means of dissimilarity measures which are not identical with the distances. This may\r\nbe aided by using one-class support vector data description for the entire data, without \r\nthe need of finding a separating function between classes. Next, the new fictitious data fitting \r\ninto such data description are trained alongside the original (labeled) examples \r\nusing semi-supervised SVM, which attempt to assign class labels to the new data.\r\nWe compare experiments with such procedures of creating and evaluating fictitious \r\ntraining data using an empirical data set.     ", :title "Data similarity in classification and fictitious training data generation", :keyword2 0, :authors (14887 14955), :session 96}, 313 {:keyword1 106, :keyword3 0, :abstract "In the Dutch railway network, there are about 20 disruptions per day on average. These disruptions can be caused by the infrastructure malfunctions, the weather, third parties, and the operator itself. In the Dutch situation, the infrastructure manager ProRail is responsible for modifications in the timetable. However, the rolling stock circulation and the crew schedules are the responsibility of the operators. The main Dutch railway operator, NS, changes these schedules in its Operational Control Centers. Currently, there is no decision support at all in these centers. We will present an algorithm that we have developed for crew rescheduling.\r\nWe formulate the crew rescheduling problem as a set covering model with side constraints considering a subset of duties and tasks. Although choosing a good subset is a far from trivial task, we were able to do so and in this way the required computation time is in the order of magnitude of a couple of minutes.\r\nOur solution approach consists of a combination of Lagrangian Relaxation and column generation techniques. The Lagrangian Dual problem is solved with a subgradient algorithm, where in each iteration a trivial Lagrangian subproblem is solved. Moreover, a Lagrangian heuristic is applied to obtain feasible solutions. This heuristic replaces greedily every original duty with a new one. To generate new duties, a so-called pricing problem is solved, which selects duties based on dual information from the Lagrangian problem. In this case, the pricing problem can be solved as a resource constrained shortest path problem.\r\nIn this presentation, we will present computational experiments with our crew rescheduling algorithm on some real-world and generated instances, where the latter are based on real-world situations.", :title "An Algorithm for Railway Crew Rescheduling", :keyword2 96, :authors (17026 5932), :session 199}, 314 {:keyword1 27, :keyword3 97, :abstract "Das Unternehmensplanspiel ComPAQ (Computersimulation Produktion, Absatz und Qualität) wird seit Ende 2004 als Seminar in der Lehre an der Wirtschaftswissenschaftlichen Fakultät im Rahmen des Diplom- und Masterstudiums eingesetzt. Das didaktische Konzept umfasst dabei einen Planspielteil sowie begleitende Maßnahmen zur Vertiefung der Lerninhalte. Im Planspielteil sind über mehrere Perioden aufeinander aufbauende, komplexe Entscheidungen in diversen Unternehmensbereichen zu treffen. Fünf Aktiengesellschaften werden dabei jeweils von einer Gruppe Studierender geführt und stehen im Absatzbereich in einer oligopolistischen Konkurrenzsituation. Als begleitende Maßnahmen sind Strategien zu entwickeln, Produktkosten und -preise zu kalkulieren sowie die Unternehmensentwicklung gegenüber dem Aufsichtsrat zu rechtfertigen. Ergänzend findet eine Übung statt, um die Verbindungen zwischen dem theoretisch Erlernten und dem im Planspiel praktisch angewendeten Wissen zu verdeutlichen. Das Seminar wird seitens der Studierenden als besonders lehrreich bewertet. Auch die Nebeneffekte, die durch eine Arbeit im Team an einer komplexen Aufgabe erfahren werden, wie bspw. die notwendige Zeiteinteilung und Koordinationsfähigkeiten, sowie der intensive Umgang mit Programmen zur Unterstützung des Entscheidungsprozesses, verdeutlichen den hohen Nutzen, den diese Art der Lehre mit sich bringt.", :title "Unternehmensplanspiel ComPAQ (Computersimulation Produktion, Absatz und Qualität)", :keyword2 11, :authors (17036), :session 104}, 315 {:keyword1 106, :keyword3 0, :abstract "The planning of postman tours is an important task in postal distribution. The simplest formulation of this problem is the Chinese Postman Problem where one has to find the shortest tour through an incomplete undirected weighted graph that goes along each of its edges at least once. \r\nIn a strategic context – e.g. while planning the optimal locations for transfer points – it is not necessary to know the actual way the postmen have to go. The only thing that one is interested in here is the length of such a tour. Since it is not practical to solve a Chinese Postman Problem only to calculate its length we will derivate a formula that approximates the length of its optimal solution. This formula consists of two parts: the total length of all edges of the graph and the length of the additional edges to make the graph Eulerian. Inputs are a random graph with a given number of vertices that represent the crossroads in the street network and a radius that specifies the length of the longest edge in that way that each pair of vertices is connected if and only if the Eucledian distance between them is not longer than the given radius. In the first approach we will consider the vertices to be uniformly distributed over a square area.", :title "The Length of a Tour a Postman has to go", :keyword2 95, :authors (), :session 37}, 316 {:keyword1 79, :keyword3 41, :abstract "The big square small square (BSSS) method is a well-known branch-and-bound technique for optimization problems with two variables which results in one or more epsilon optimal solutions. Applications can be found for instance in facility location problems on the plane.\r\n\r\nIn vector optimization or multicriteria optimization, we are dealing with several objectives and we want to find all efficient or Pareto optimal solutions. As an extension of epsilon optimal solutions in single criteria problems, there are also several concepts of epsilon efficient solutions in multicriteria optimization problems.\r\n\r\nOur aim is a generalization of the BSSS method for multicriteria optimization problems. We will present an algorithm which results in a subset of the feasible region with the following two properties: (1) all efficient solutions are contained in the output set and (2) all points of the output set are epsilon efficient solutions.\r\n\r\nThe algorithm will be demonstrated on bicriteria obnoxious location problems on the plane. Furthermore, numerical results will show the efficiency of the proposed method even for large problem instances.", :title "The Big Square Small Square Method for Multicriteria Optimization", :keyword2 54, :authors (17032 1601), :session 78}, 317 {:keyword1 77, :keyword3 0, :abstract "Gomory mixed-integer cuts (GMICs) are a fundamental part of state-of-the-art optimization software. Considerable research has been carried out on techniques which aim at strengthening GMICs. In particular, these approaches modify the underlying simplex tableau rows by constructing combinations of them or by performing a sequence of pivots respectively. We briefly describe these strengthening techniques and discuss implementation details. Furthermore, we present computational results to demonstrate the practical usefulness of the discussed techniques.", :title "Strengthening Gomory mixed-integer cuts", :keyword2 57, :authors (13538 9272 9631), :session 20}, 318 {:keyword1 68, :keyword3 62, :abstract "Increasing CO2 emissions and the emerging scarcity of fossil raw materials bring resource efficient concepts more and more into the focus of public interest. One resource efficient concept was realized in the German \"`bio-energy village\"' Jühnde by using biomass instead of conventional energy sources to meet the electricity and heat demand. Electricity and heat are produced by burning biogas in a combined heat and power generator (CHP). Liquid manure and crops, cultivated on the agricultural land around the village, are the feedstock for the generation of the biogas in the anaerobic digestion plant for district heating. The electricity is fed to the national electricity grid. The idea of a nearly self-sustaining village based on biomass energy sources could be an important basis for a resource efficient energy strategy. \r\nFor estimating the economic consequences of a bio-energy village for a region, techno-economic optimisation models can be used. They provide the \"`cost optimal\"' energy supply and demand system over a given planning horizon. Any modelling is subject to various sources of uncertainty, but especially the use of natural resources is subject to many uncertainties like seasonal changes, crop rotation, crop failure or varying yields. Therefore it is the main part of our work to analyse the various types of uncertainties and to reflect them in a mass and energy flow optimisation model.", :title "BioEnergy Planning – Uncertainties in the Decision Model", :keyword2 93, :authors (15195), :session 139}, 319 {:keyword1 106, :keyword3 0, :abstract "Some providers of postal or parcel services promise high levels of service to their customers, e.g., next day delivery, resulting in tight lead times. To meet these high service levels, complex logistics networks need to be planned and operated. Such networks are typically divided into transportation of letters or parcels from customer locations to a local sorting terminal (collection), inter-terminal transportation, and transportation from a terminal to customer locations (delivery). Within postal logistics networks the interaction of processing at and transportation between different kinds of facilities plays a vital role. Normally, collection and initial sorting, as well as inter-terminal transportation and final sorting need to be finished before certain cut-off times. Thus, guaranteeing the subsequent transportation to start on time.\r\n\r\nThe talk presents various optimization problems within the part of a postal logistics network where collection takes place. Then, two of those problems are presented in more detail. First, the allocation of customers to sorting terminals and, second, the optimization of collection tours. Both problems not only consider service time windows at customer locations and at terminals but also sorting capacities at the sorting terminals. For both problems appropriate mathematical models and solution methods will be discussed.", :title "Optimization of postal collection networks", :keyword2 95, :authors (), :session 37}, 321 {:keyword1 101, :keyword3 0, :abstract "Zur Performancemessung von Lagersystemen wird häufig eine Vielzahl von Kenngrößen herangezogen. Dazu zählt, neben den üblichen Größen wie mittlerer Bestand im System und verschiedenen Servicegraden zur Evaluierung der Lieferfähigkeit, auch die vor allem im ingenieurwissenschaftlichen Bereich geprägte Kenngröße des mittleren Lieferverzugs. Bei dieser Kenngröße handelt es sich um die Zeit, die ein Kunde im Durchschnitt auf seine Bestellung warten muss, wenn das betrachtete Lager bei Eingang der Bestellung nicht lieferfähig ist. Im Rahmen der Kennlinientheorie wird versucht, die Zusammenhänge zwischen den einzelnen Kenngrößen durch eine Kennlinie visuell darzustellen. Dabei steht vor allem der Zusammenhang zwischen den Kenngrößen mittlerer Bestand und mittlerer Lieferverzug im Fokus der Betrachtung, der zum einen mithilfe approximativer Methoden geschätzt, aber auch durch eine numerische Analyse exakt ausgewertet werden kann. Bisherige Arbeiten konzentrieren sich allerdings lediglich auf die Ableitung dieser Kennlinie für einstufige Systeme, wobei stets restriktive Annahmen bezüglich der genutzten Dispositionsregel und der auftretenden Prozessunsicherheiten getroffen werden müssen.\r\nDieser Beitrag beschreibt die Vorgehensweise zur exakten Bestimmung des Zusammenhangs zwischen Bestand und Lieferverzug in einem mehrstufigen, seriellen System. Dabei ist festzustellen, dass es zwischen dem mittleren Bestand im System und dem Lieferverzug keinen eineindeutigen Zusammenhang gibt. Zur Bestimmung der Kennlinie ist es daher notwendig, die effizienten Dispositionsparameter auf den einzelnen Stufen mithilfe der Erkenntnisse aus der mehrstufigen Sicherheitsbestandsplanung zu identifizieren, die für einen gegebenen mittleren Bestand den mittleren Lieferverzug minimieren.", :title "Zur Erweiterung der Kennlinientheorie auf mehrstufige Lagersysteme", :keyword2 0, :authors (2801 14883), :session 112}, 323 {:keyword1 77, :keyword3 0, :abstract "The Graph Partitioning problem is the problem of partitioning the\r\nvertices of a given graph into at most k clusters maximizing\r\nthe weight of the edges between different clusters.\r\n\r\nAn integer linear programming formulation is reconsidered that was\r\ndismissed in the past in particular because of its inherent symmetry,\r\nalbeit having the advantage to directly deal with sparse graphs.\r\nThis formulation contains binary variables for the edges as well\r\nas (vertex-indexed) characteristic vectors of the clusters, and\r\ncan be seen as an extended formulation.\r\n\r\nRecently however polyhedral methods to address\r\nsymmetry in certain integer programs have been developed. The special\r\npolytopes called Orbitopes fit the symmetry arising in our formulation,\r\nand have been studied in particular with respect to computational aspects.\r\nThis led to Orbitopal Fixing, a method for fixing variables in\r\na branch-and-bound tree solely exploiting the symmetry of the model.\r\n\r\nWe provide a computational evaluation of this approach, and\r\ncompare it to other formulations as well as a comparison of\r\nOrbitopal Fixing to other symmetry handling approaches like\r\nIsomorphism Pruning.\r\n\r\nThis is joint work with Volker Kaibel and Marc Pfetsch.\r\n", :title "Breaking model symmetry for Graph Partitioning", :keyword2 0, :authors (17028), :session 176}, 325 {:keyword1 18, :keyword3 40, :abstract " In the well-known paper of a Nobel Prize winner in economics in 2005 Aumann R. (Aumann R.J. and Maschler M. Game Theoretic Analysis of bankruptcy Problem from the Talmud / / Journal of Economic Theory, 1985, 36, p. 195-213.) addresses the problem (which at least is two thousand years old) of the distribution of material resources among the creditors. It has been shown that with using the theory of cooperative games many cases of solving in property and financial disputes from the Bible can be explaned. \r\n   Therefore, we propose other methods of decision-making on the distribution of material resources. The foundation of these methods is based on the principles of economic equilibrium, are determined by evaluative functions. Different types of evaluative functions determine the appropriate distributions. Particulary this distribution may be proportional (rating) or alternative for the proportional one. The proposed models provide a balance and find compromises in solving various social and economic problems. \r\n", :title "Search for Intelligent Methods of Equilibrium Distribution", :keyword2 25, :authors (16633), :session 181}, 326 {:keyword1 18, :keyword3 106, :abstract "Especially in courier transport logistics with ad-hoc one-way shipping orders, carriers with a sparse volume of orders are faced with the problem of dead-head trips, which results in non competitive prices. Medium and small-sized companies, which in contrast to larger companies usually operate for a regionally bounded customer base, may compensate for this competitive disadvantage by allying with each other to a collaboration network and provide services cooperatively. Our experience with the development of a distributed real-time internet-based collaborative DSS for a specific network has shown that the success of such a network is highly depending on two issues: the opportunity to realize a sufficient number of orders which can be fulfilled more efficiently by a partner while this number is depending on the acceptance of the compensation scheme.\r\n\r\nIn this paper we show how logging the transactions over time allows a simulation of the collaboration process with various reward functions and can be used to analyze the behaviour of the partners and to design and evaluate alternative compensation schemes and to compare these with alternative organizational settings or planning scenarios: non-distributed collaborative planning by a central dispatch and individual non-collaborative planning by all partners.", :title "Planning in Networks of Independent Carriers: A Simulation Study", :keyword2 97, :authors (14755), :session 61}, 328 {:keyword1 92, :keyword3 75, :abstract "Product recovery gains increasing importance in spare parts acquisition, especially during the post product-life-cycle (PLC) service period. Considering product recovery in addition to traditional procurement options (final order, extra production) makes the underlying stochastic dynamic planning problem even more complex. An efficient heuristic for solving the problem is developed and used to evaluate and measure the contribution to procurement flexibility that can be expected from product recovery.", :title "A Heuristic Approach for Integrating Product Recovery into Post PLC Spare Parts Procurement", :keyword2 85, :authors (2801 17039), :session 121}, 330 {:keyword1 101, :keyword3 40, :abstract "In this talk, a new auction mechanism for the coordination of supply chain planning is presented. We consider a supply chain consisting of one buyer and one supplier and assume that the operational planning of both parties can be modeled by multi-level dynamic uncapacitated lot-sizing problems. The necessary data for planning is only privately known by the parties. \r\nIn the first step of the mechanism, the buyer generates a set of different supply proposals. These proposals indicate supply quantities whose implementation potentially yields an improved solution for the whole supply chain. In the second step, the best proposal out of this set is selected using a sealed bid double auction. Both analytical and numerical results about the solution quality of this mechanism are provided. \r\n", :title "Coordination of Lot-Sizing in Supply Chains by an Auction Mechanism", :keyword2 68, :authors (14869), :session 114}, 332 {:keyword1 102, :keyword3 48, :abstract "The metals producing industries, i.e. the iron and steel and the non-ferrous metals industries, are important consumers of primary resources and responsible for large amounts of emissions of the climate relevant carbon-dioxide. As coke and coal are important resources concerning their value and quantity the named industry sectors have a long tradition in aiming on an improvement of the resource efficiency in their production planning. This is done either minimizing the necessary coke and coal input or maximizing the production output from a given input. As the use of coke and coal is also responsible for the major part of the CO2-emissions, the companies in these sectors have a natural interest in reducing these climate relevant emissions.\r\n\r\nIt is therefore aim of this contribution to apply planning approaches for production and recycling processes in the iron- and steel and the zinc industry to determine the influence the carbon resources have due to their economic value and compare such economic considerations with results from an minimization of the carbon-dioxide emissions. \r\n\r\nWe focus on case studies of two companies recycling residues accruing in the primary and secondary steel production to produce pig iron for foundries and a zinc-oxide that can be used in the zinc electrolysis. Based on a problem adequate modeling of the production processes linear resp. mixed integer planning approaches are used to determine the contribution margin maximal input-mix resp. the contribution marginal master plan of the process. \r\n\r\nThe results show that the resource usage of coke already clearly dominates the further cost components. For the considered case studies using the CO2-emission minimization as the overall planning objective does not lead to further major reductions. \r\n\r\n", :title "Production Planning under Economic and Ecologic Objectives – A comparison in Case Studies from Metals Production", :keyword2 31, :authors (8713 17047 1219), :session 92}, 334 {:keyword1 106, :keyword3 11, :abstract "We present MEFISTO (Metaheuristic Framework for Information Systems in Transport Optimization), a pragmatic framework for transport optimization algorithms that has been jointly developed by the authors and is integral part of logistics planning solutions provided by PTV AG. Starting from the requirements analysis, we present design aspects that have led to the architecture of the framework. Several metaheuristics have been implemented on top of a common set of local search operators. In particular, we focus on a variant of Granular Tabu Search and the adaptation scheme used therein. For the case of vehicle routing problems where a subset of orders consists of pickup and delivery transports, we present a specialized local search procedure. Results on rich problems with real world constraints and objectives are given.", :title "MEFISTO: A pragmatic metaheuristic framework for adaptive search with a special application to pickup and delivery transports", :keyword2 59, :authors (17043 17045 17042), :session 69}, 336 {:keyword1 54, :keyword3 59, :abstract "The location planning of emergency service stations is crucial, especially in the populated cities with heavy traffic conditions such as Istanbul. In this paper, we propose a Backup Double Covering Model, a variant of the well-known Maximal Covering Location Problem, which requires two types of services to plan the emergency service stations. The objective of the model is to maximize the total population serviced within t1 and t2 minutes (t1 smaller t2) using two distinct emergency service stations where the total number of stations is limited. Our aim in doing so is to provide a backup station in case no ambulance is available in the closer station. Since this problem is intractable for large-scale instances we propose a Tabu Search (TS) approach to find good solutions in reasonable computation time. Three initialization approaches are utilized for comparison: random, a steepest-ascent algorithm, and an LP relaxation-based heuristic. In order to test the effectiveness of the proposed method, we conduct an extensive experimental study on a large number of randomly generated data set with different sizes and number of stations. We observe that the TS algorithm provides good results fast in comparison with the solutions obtained using OPL Studio 5.5 with CPLEX 11.0, a high performance optimization software. Finally, we apply our TS approach for planning the emergency service stations in Istanbul on the data obtained from the Directorate of Instant Relief and Rescue at Istanbul Metropolitan Municipality and discuss the results. ", :title "A New Model and Tabu Search Approach for Planning the Emergency Service Stations", :keyword2 68, :authors (16945 2423 692), :session 91}, 340 {:keyword1 8, :keyword3 0, :abstract "We consider the classical 0-1 knapsack problem with an additional disjunctive relation on pairs of items represented by a conflict graph. This means that adjacent vertices in the graph correspond to items that may not be packed together in the knapsack. Clearly, every feasible solution of this knapsack problem constitutes a stable (independent) set in the conflict graph. While this feature has been studied for bin packing problems it is a new concept for knapsack problems.\r\n\r\nSince the combination of two NP-complete problems does not make them any easier, we look for special structures of the conflict graph that allow exact solution methods with pseudopolynomial running time. Currently, we are successful for trees and more general for graphs with bounded treewidth, as well as for chordal graphs. For all these cases dynamic programming schemes can be developed which follow a bottom-up approach through a certain tree representation of the considered graph. For graphs with bounded treewidth we use a tree decomposition, in particular, we exploit the properties of nice tree decompositions. For chordal graphs, we base the dynamic programming scheme on its representation as a clique tree. Furthermore, for these special cases we currently derive also fully polynomial approximation schemes (FPTAS).\r\nFurther investigations are under way.         ", :title "Knapsack Problems on a Conflict Graph", :keyword2 42, :authors (12695 17055), :session 204}, 342 {:keyword1 18, :keyword3 59, :abstract "Real world combinatorial optimization problems are in general rich in the sense that the solution space is heavily constrained by constraints of different types and the objective is aggregating several measures. Often these components become apparent only during system development/programming after some intermediate model/system - a so-called prototype - has been analyzed by the problem owner. For such problems and environment indirect search and especially the GIST-approach (greedy indirect search technique) have shown to be a powerful concept: here the domain knowledge (data, constraints and objectives) which is evolving during system development is separated from solver intelligence (meta-heuristic search strategies) and thus can be developed independently. In this paper we describe the concept and experimental development of a software-framework for agile evolutionary development of GIST-based decision support systems. \r\n\r\n", :title "AgileGIST – a framework for iterative development and rapid prototyping of DSS", :keyword2 61, :authors (14755 17057), :session 101}, 343 {:keyword1 86, :keyword3 0, :abstract "The situation in R\\&D-departments is characterized by a stochastic arrival process. Arrived projects compete for scarce resources, e. g. employees and equipment, and are stochastic in terms of their content (number of activities, activity durations). Each project has an externally assigned due date and the objective is to minimize the weighted tardiness of the projects. We will present the results of a simulation study where a set of priority rules from the literature is tested on problem instances which are generated according to different problem parameters. The focus will be on the effectiveness of the rules under different levels combinations of the parameters as well as the impact of the parameters on the objective function.", :title "Scheduling of multiple R \\& D projects in a stochastic dynamic environment", :keyword2 97, :authors (16877 829), :session 56}, 346 {:keyword1 61, :keyword3 75, :abstract "Realistic modeling of complex production processes typically involves nonlinearities leading to challenging optimization problems. We present several nonlinear programming features in AIMMS which can contribute to the efficient solution of such problems. Among others, we mention the Nonlinear Presolve, which allows to improve and speed up solving NLP and MINLP, as well as the Nonlinear Multistart, which generates multiple starting points, clusters them and reports the best locally optimal solutions. We illustrate such features using a real case originating in the petrochemical industry. \r\n", :title "Production process optimization using nonlinear programming features in AIMMS", :keyword2 80, :authors (10297), :session 146}, 347 {:keyword1 8, :keyword3 77, :abstract "One of the most challenging problems in OR is the traveling tournament problem (TTP), a sports league scheduling problem: An even number of n teams plays a double-round-robin tournament, i.e., each team plays against each other team twice, once at home and once away. The schedule is tight meaning that all games have to take place in 2n-2 time slots. Specific to the TTP is that teams travel directly from one away game to the next without returning home. The task is to minimize the overall distance traveled by all teams, while the number of consecutive away and consecutive home games must not exceed a given bound U.\r\n\r\nIn 1999, K. Easton, G. Nemhauser, and M. Trick presented one of the very few exact solution algorithms for the TTP. Their approach is based on branch-and-price (BaP), where the subproblem consists of finding a tour for each team, i.e. the sequence of visited locations. \r\n\r\nWe present a new BaP algorithm with the following properties: Repeater constraints (the game 'A against B' cannot be followed by the game 'B against A') are taken into account using dynamic constraint generation techniques. The subproblem is reformulated as an elementary shortest-path problem (SPP) with resource constraints. This problem is again transformed into a simple SPP over an appropriately defined large state space. Using bidirectional search and reduced cost variable fixing techniques, the solution process is accelerated significantly compared to the constraint programming methods used by Easton et al. New branching rules for the so-called circular instances are devised using arguments from finite group theory. As a result of these improvements, several new lower bounds and some new optimal solutions were computed for knowingly hard instances of the TTP from the literature.", :title "A new branch-and-price algorithm for the traveling tournament problem", :keyword2 72, :authors (4161), :session 175}, 348 {:keyword1 77, :keyword3 121, :abstract "Employees of transportation companies are typically facing duties at irregular times, and work on all days of the year. The duty roster of an employee has to obey several rules which are written down in labour agreements, such as the number of free days per year and the maximum amount of work permitted in certain periods. The company usually has one simple goal, the assignment of a suitable person to each duty.\r\n\r\nThe goal of our work was to set up a model for duty rosters that covers all labour agreements of our industrial partner, a major German railway company. However, for realistic size instances the model - a linear mixed-integer program - turns out to be too complex for a black-box use of modern standard MIP solver. To this end, we suggest several decoupling techniques to reduce its computational complexity. \r\n\r\nThe solutions are then evaluated in terms of the stability of the rosters. How much of the plans is still valid, once real-world effects (such as illness of employees or changes by the company) are randomly entering the scene? Numerical results for test instances are presented. \r\n\r\n", :title "Optimization and Simulation of Duty Rosters for Railway Crews", :keyword2 97, :authors (16315 17138 17115 17071 13046), :session 199}, 349 {:keyword1 35, :keyword3 0, :abstract "Index Funds, Exchange Traded Funds and Derivatives give investors access to well diversified index portfolios. These index-based investment products exhibit low fees, which makes them an attractive alternative to actively managed funds. Against this background, a new class of stock indices has been established based on the concept of \"`Fundamental Indexation\"'. The selection and weighting of index constituents is conducted by means of fundamental criteria like total assets, book value or number of employees. This thesis deals with the examination of the performance of fundamental indices in the German equity market. Therefore a backtesting of five fundamental indices is conducted over the last 20 years. Furthermore the index returns are analysed under the assumption of an efficient as well as an inefficient market. Index returns in efficient markets are explained by applying the three factor model for stock returns by FAMA/FRENCH (1993). The results show that the outperformance of fundamental indices is partly due to a bigger risk exposure, particularly to companies with a low level of valuation. By loosening the assumption of market efficiency a return drag of capitalisation weighted indices can be deduced. Given a mean-reverting movement of prices, a direct connection between market capitalisation and index weighting lead to inferior returns. To conclude, fundamental indices are a valuable supplement to the universe of passive investment products. The index methodology implies an investment strategy that benefits from well known market anomalies like the value effect without relying on active portfolio management.                                                           ", :title "Examination of the Concept of Fundamental Indexation \"`in the German Market\"'", :keyword2 0, :authors (17060), :session 85}, 353 {:keyword1 75, :keyword3 0, :abstract "Screening contracts are a common approach to solve supply chain coordination problems under asymmetric information. Previous research in this area shows that asymmetric information leads to supply chain coordination deficits. We extend the standard framework of lotsizing decisions under asymmetric information by allowing investments in setup cost reduction. We find that asymmetric information leads to an overinvestment in setup cost reduction. Yet, the overall effect on supply chain performance is ambiguous. We show that these results holds for a wide variety of investment functions.", :title "Setup Cost Reduction and Supply Chain Coordination in Case of Asymmetric Information", :keyword2 101, :authors (2801 16934), :session 112}, 355 {:keyword1 42, :keyword3 10, :abstract "Complexity of approximating and computational complexity of the size of a maximum (minimum) maximal induced matching are investigated for some special classes of graphs (bipartite graphs, planar line graphs of planar bipartite graphs). An induced matching is a set of pairwise non-adjacent edges such that their end-vertices induce a 1-regular subgraph. An induced matching M is maximal if no other induced matching contains M.", :title "On complexity of approximating the maximum and minimum maximal induced matchings", :keyword2 8, :authors (11988 17066 9516), :session 45}, 357 {:keyword1 86, :keyword3 0, :abstract " The history of modern project management practically has begun with the invention of the network scheduling techniques. One of the pioneers was the PDM (Precedence Diagramming Method). In this paper a generalization of the original PDM  Least Cost Scheduling Problem will be presented. The following extensions will be discussed on the basis of the original problem: activities van be both splittable and non-splittable, both minimal and maximal type of precedence relationships are allowed in the network, relationship lead-lag times can be a function of the predecessor or successor activities, earlier accomplishments of milestones are rewarded, later accomplishments are penalized. \r\nThe applied algorithm is traced back to the solution of minimal cost flow problem. \r\n", :title "A Generalized Least Cost Scheduling Problem", :keyword2 0, :authors (17064), :session 55}, 359 {:keyword1 92, :keyword3 0, :abstract "Besides increasing raw material prices and disposal costs as well as strict environmental legislation and civil pressure, the reduction of operational costs for remanufacturing used products can be a further strong argument to enforce remanufacturing activities.\r\n\r\nIn this paper we analyze a deterministic product recovery system where used products are returned from the market to the manufacturer with a fix rate. There they are stored and then remanufactured to bring them to an \"`as good as new\"' condition. The remanufactured products are used to satisfy a given constant market demand. Since some products get lost at the market, only a fraction of the demand is returned to the manufacturer. So, demand is greater than the return rate and new products need to be produced as well. Remanufacturing and production occur lot wise and with an infinite rate. One production lot is followed by a number of remanufacturing lots.\r\n\r\nMost previous papers assume equal sized remanufacturing lots. We can show that this assumption does not hold for the basic product recovery system. If multiple remanufacturing lots are used, the last one will always be smaller than the preceding ones. The relation between the last lot and the others is restricted by the return fraction. Considering this restriction, we develop a simple optimization algorithm that minimizes average costs per time unit. In 50.8% of one million tested instances we can observe a cost reduction by removing the assumption of equal sized lots. Probability of cost reduction increases with rising return fraction and is almost 100% for instances with a return fraction higher than 75%. \r\n\r\nThese results can be of great interest for manufacturers which pick up used products from the market to remanufacture them.", :title "Unequal sized lots in a deterministic product recovery system under constant demands and returns", :keyword2 75, :authors (16925), :session 93}, 360 {:keyword1 93, :keyword3 0, :abstract "This study aimed to optimize the investments for risk management of a company. Specifically, we developed the quantitative model of risk assessment for a chemical plant and clarified the correlation between the impact of each safety measure and the degree of risk reduction by applying the Analytic Hierarchy Process. \r\nTo obviate disasters is inseparable from generating profit for a company due to serious rekindling of interest in CSR (Corporate Social Responsibility), sustainability, and compliance. However, valuation technique for safety, intangible factor, is not yet established, because of their quantization limits: such as measuring the outcome of investments for risk management, and quantifying the economical efficiency concerning safety of a chemical plant. Establishing those analytical methods and valuation technique is pressing issue for safety manager of a company. \r\nIn this study, a quantitative model of risk assessment for a chemical plant was developed, and characteristic risk of the plant was quantified based on concrete risk management programs and on the consensus of safety supervisors of the plant. In addition, the degree of risk reduction was evaluated based on the percent complete of each safety measure for risk management. Furthermore, cost effectiveness of each safety measure was clarified, which could lead up to optimize the investments for risk management.\r\n", :title "An Optimization of Investments for Safety-Intangible Factor", :keyword2 3, :authors (), :session 146}, 361 {:keyword1 42, :keyword3 0, :abstract "The line connectivity problem (LCP) is the following: Given is a graph, a set of terminal nodes, and a set of simple paths (lines) with nonnegative costs. The goal is to find a minimum cost subset of lines such that all terminal nodes are connected, i.e, for each pair of terminal nodes there exists a path using only edges covered by lines.\r\nThis problem is a generalization of the well-known Steiner tree problem, in which all lines have length one. LCP occurs, for instance, in line planning of public transport.\r\n\r\nThe talk discusses the complexity and integer programming formulations of LCP. We point out differences and similarities to the Steiner tree problem. It turns out that in contrast to the Steiner tree problem LCP is NP-hard even for the case that all nodes in the graph are terminal nodes.  Furthermore, we analyze generalizations of valid inequalities for the Steiner tree problem, e.g., Steiner cut inequalities and Steiner partition inequalities. Inequalities obtained by straight-forward transformation can be strengthened and define facets under additional constraints on the lines, which are satisfied if all lines have length one. We also consider a directed cut and\r\na flow formulation for LCP.", :title "The Line Connectivity Problem", :keyword2 0, :authors (15059 14923 17083), :session 195}, 362 {:keyword1 67, :keyword3 76, :abstract "We study the existence of a numeraire portfolio for a discrete time financial market with proportional transaction costs. In an incomplete market without frictions, consistent prices for derivative securities can be obtained by taking the expectation of the claim with respect to a certain probability measure under which the discounted asset prices  become martingales. The numeraire portfolio allows to replace this change of measure by a change of numeraire. For models with transaction costs, the concept of a martingale measure and thus the concept of a numeraire portfolio have to be modified. Without transaction costs a well known \r\napproach is to find the growth optimal portfolio (but the numeraire portfolio might not exist). With some modifications and under reasonable conditions, using methods of dynamic programming we show that the same approach works for our model.", :title "Option pricing under transaction costs", :keyword2 34, :authors (12951), :session 86}, 363 {:keyword1 94, :keyword3 67, :abstract "Customer Lifetime Value (CLV) and Customer Equity (CE) are core concepts in relationship marketing. Several models have been proposed by researchers to measure CLV and CE. Not only new models are required to accurately estimate CLV, but also decision making models must be employed to assist managers in making right marketing decisions. In this paper, a situation is considered in which different customer segments and various marketing channels are available. A mathematical model is developed to maximize CE (or aggregated CLV) of the company. We adopt robust optimization approach to cope with the uncertainty which is inherent in all uncertain decision making environments. We then solve our model and analyze it based on numerical results. ", :title "A Robust Optimization approach to Customer Equity Maximization", :keyword2 56, :authors (16977 17395 16872), :session 139}, 364 {:keyword1 18, :keyword3 95, :abstract "A considerable amount of dangerous goods is being moved in Europe to support a satisfactory quality of life and sustainable development to society, but at the same time causing a significant exposure of civilians to the risks related to this kind of transport. Statistics\r\navailable from the European commission shows an increment of dangerous goods transported.  Diverse transportation means are normally used to move dangerous cargo: rail, road, water and air. However, road transportation is the most used transport mode since it provides higher\r\nflexibility, and  door-to-door deliveries. Unfortunately road transport implies the movement of dangerous goods in areas where people live and work. Therefore planned routes for dangerous goods must be traded off with population exposures to accident risks and transport efficiency. A high amount of dangerous goods transported on the road dramatically increases the population's exposure to accidents risks. The consequence of an accident can be devastating and include mortality, contamination of the surroundings, damage of property or infrastructure. At the same time logistics and transport operators demand faster delivery to minimize capital tied-up costs. Previous research has shown the application of heuristic techniques to plan routes that minimize risks while taking into account the efficiency factors. This research aims to apply such a method in combination with GIS to develop a decision support system able to plan safe and efficient routes. It discusses the importance of developing a cooperative platform where public authorities and private industries can track dangerous goods and enforce the laws concerning dangerous goods transportation. The same system should be adopted to perform preventive and resiliency management.", :title "The CaSSandra project, Computing Safe and Efficient Routes with GIS", :keyword2 93, :authors (16697 17072), :session 72}, 365 {:keyword1 54, :keyword3 106, :abstract "In this talk we consider a multi-period location problem using geographic as well as demographic data. In particular we look at the problem of locating petrol stations in Germany. Since the demand for petrol (and thus also petrol stations) is changing over time, a time dynamic model is considered. We estimate the demand from geographic and demographic data. Future demographic data is forecasted by time series methods. For the location problem itself, the planning region is divided into smaller subregions and the optimization procedure decides whether to open or close stations in a subregion. Territories are designed using a line partitioning approach. To get a balanced territory design with respect to demand we use geographic data, such as crossroads together with the length of the incident streets (the length of the streets is assumed to correlate with the demand). The whole demand generated in a subregion is partially reassigned to adjacent regions by a gravity model, which takes the number of existing locations and the distance between the regions into account. Finally the resulting demand for each region is split evenly between the own and the competing facilities. The talk ends with some conclusions on how demographic data can support a location decision in the case of insufficient direct data.", :title "Location Planning using Geographic and Demographic Data", :keyword2 65, :authors (5078 14667 14979 11829), :session 149}, 366 {:keyword1 2, :keyword3 65, :abstract "The central issue in the air cargo industry is the generation of an optimal flight schedule. Such a flight schedule simultaneously defines a company's market potential and allocates its resources. Due to its complexity, the planning process is decomposed into several steps that are traditionally executed in a sequential manner.\r\n\r\nWe present a novel model which has been developed in course of a feasibility study for a \"`freighter network planning system\"' at a major cargo airline. The model integrates the three steps flight selection, aircraft rotation and cargo routing. Its aim is to maximize the network-wide profit by determining the best combination from a list of mandatory and optional flights, assigning the selected flights to aircrafts and identifying optimal cargo flows. Feasible aircraft rotations and cargo flow connections are generated using two resource-constrained shortest-path algorithms. The integrated model is formulated as a MIP and solved iteratively using column generation.\r\n", :title "Air Cargo Network Planning – An integrated model for a major carrier", :keyword2 106, :authors (14755), :session 67}, 367 {:keyword1 95, :keyword3 92, :abstract "The vehicle routing problem with simultaneous delivery and pick-up (VRPSDP) is an extension of the capacitated vehicle routing problem in which shipments have to be transported from the depot to customer locations and other shipments have to be trucked from customer locations to the depot. Each customer requires a simultaneous delivery and pick-up of goods by the same vehicle. The VRPSDP is a basic problem in reverse logistics: In addition to the distribution process to the customers, re-usable goods have to be transported in the reverse direction. We implement a Branch-and-Cut approach and study how it can be applied to the solution of the VRPSDP. The computational tests have been performed on known benchmark instances for the CVRP. Some of the benchmark problems are solved to optimality for the first time. ", :title "A Branch-and-Cut Approach to the Vehicle Routing Problem with Simultaneous Delivery and Pick-up", :keyword2 106, :authors (9524 5965), :session 68}, 368 {:keyword1 86, :keyword3 106, :abstract "Integrated production and distribution scheduling problems are faced by many industries which have to deal with products that have a limited lifespan, e.g. milk, eggs or bio-chemicals. These products expire unless they are delivered within a certain time period after their production. Additionally, customers may specify time windows within which they prefer their goods to be supplied. This especially occurs when the products are needed as raw materials for further productions steps and the deliveries must meet the customers' production schedules. Since the production facility and the means of transportation are limited resources, generally not all of the customers may receive the delivery within their time windows and/or product lifespan. This poses the problem of choosing a subset of customers to include in the delivery schedule.\r\n\r\nIn traditional approaches production planning and the subsequent transportation scheduling are considered separately and independently from each other. In this talk we will discuss an integrated model for production and distribution scheduling with a single production plant, a single transporter (which has non-negligible traveling times) and a fixed customer sequence. Moreover, we will offer extensions of this model such as allowing arbitrary customer sequences or multi-vehicle scenarios with the aim of incorporating more realistic restrictions from practice. We will present heuristics to solve the combined production and transportation planning problem and illustrate that this combination is beneficial for the considered models.", :title "Integrated Production and Distribution Scheduling under Lifespan and Time Window Restrictions", :keyword2 96, :authors (15150), :session 50}, 369 {:keyword1 106, :keyword3 78, :abstract "In this presentation we introduce a new approach for\r\ndetermining the routes and frequencies of the lines of\r\nan urban public transport system. The objective is to\r\nmaximize the expected number of passengers which\r\nmainly depends on the travel time service quality.\r\nWhether a passenger uses the public transport system or not\r\ndepends on the (expected) travel time taking into\r\naccount that more than one alternative can exist\r\nto arrive his or her destination. We apply a\r\ndiscrete choice model to derive the probability\r\nthat an alternative is taken which is required to\r\nobtain the expected number of passengers. We show how\r\nthe discrete choice model can be included in a\r\nlinear optimization problem. Moreover, we present\r\nsome computational results on the basis of the\r\nCity of Dresden. ", :title "Line Optimization in Urban Public Transport Systems in Consideration of Mode-Selection and Route-Decision", :keyword2 53, :authors (14873 14588), :session 63}, 371 {:keyword1 37, :keyword3 0, :abstract "Based on computer simulations the authors show the usability of intervention models combined with traditional SARIMA models to analyze and forecast times series with calendar and memory effects. The article gives an overview on estimation procedures and variable selection strategies using statistical tests like the Wald-test. Results of competing forecasting methods will be evaluated using simulated daily time series. The proposed procedure demonstrates the advantage of traditional time series techniques to analyze calendar effects.", :title "SARIMAX-Models to forecast time series with calendar effects: a computer simulation", :keyword2 0, :authors (55099 14637), :session 183}, 372 {:keyword1 96, :keyword3 0, :abstract "In this study, a new bottleneck-based heuristic (BBH) is developed for the reentrant job shop scheduling problem (RJSSP) to minimize the makespan. The classical job shop assumes that each job visits a machine only once. In practice, this assumption is often violated making the reentrant job shop come into prominence in recent years. The principle characteristic of a reentrant job shop is that a certain job may visit a specific machine or a set of machines more than once during the process flow, which can be observed in many real-world production systems, particularly in high-tech industries such as semiconductor manufacturing. The proposed BBH is adapted from the shifting bottleneck heuristic (SBH) and tailored to the needs of the RJSSP. As in the SBH, the problem is decomposed into a number of single machine subproblems, and additionally a specialized sequencing algorithm is proposed for the solution of subproblems so that the large-scale RJSSPs can be handled conveniently. To evaluate the performance of the BBH, a comparison with well-known dispatching rules has been made on a case study in a textile factory. Computational results indicate that the BBH can achieve a better tradeoff between solution quality and computational time compared to the dispatching rules.\r\n\r\n\r\n", :title "A new bottleneck-based heuristic for reentrant job shops: A case study in a textile factory", :keyword2 75, :authors (2857), :session 54}, 373 {:keyword1 101, :keyword3 75, :abstract "The paper presents a new problem class, the Economic Lot and Supply Scheduling Problem (ELSSP). The ELSSP deals with the simultaneous vehicle routing and production planning and is an extension of the classical ELSP.\r\nFor the ELSSP hold the same assumptions as for the ELSP. A single capacitated production facility is assumed, on which several items have to be produced. But in addition to the ELSP the production of the items requires item specific input-materials, which have to be sourced from geographically dispersed suppliers by a given fleet of vehicles. For the production a base period approach with a power of two policy is assumed.\r\nIt is the aim of the ELSSP to determine the delivery quantities of the input-materials, the routes for the deliveries, the production sequence of the items and the production lot sizes in order to minimize the average transportation and inventory holding costs.\r\nTo solve the described problem the junction point method from Yao and Elmaghraby for the solution of the ELSP under a power-of-two policy (PoT) is modified and extended in order to consider the vehicle routing problem caused by the deliveries of the input-materials.\r\n", :title "The Economic Lot and Supply Scheduling Problem under a Power-of-Two Policy", :keyword2 106, :authors (1131), :session 118}, 375 {:keyword1 2, :keyword3 0, :abstract "Each day Airlines facing with the problem of delays and disruptions. It’s impossible to make any strictly accurate forecasts of the delays, but nevertheless it’s helpful to understand the nature of each of the delay, which conditions influence on the amount of the delay, which parameters of the flight (time, weekday, season and etc.) are more \"`sensible\"' to the delays at the particular airport. Combining and analyzing all these different parameters by data mining instruments, such as discretization, clustering and decision trees gives us an advantage to receive required rules and patterns of the available data and gives a possibility to have a powerful instrument in our hand, by which predictions can be done and as a result a timetable can be improved.", :title "Delay mining based forecasting for scheduled passenger transportation", :keyword2 0, :authors (17073 1194), :session 63}, 376 {:keyword1 14, :keyword3 99, :abstract "We consider the solution of technical optimization problems involving highly time-consuming calculations. Usually, these possibly multiobjective optimization problems come along with almost no knowledge about the behaviour of the objective functions and many local optima. In most cases, the problems are not sufficiently solvable by traditional gradient-based optimization methods. Instead, surrogate-based heuristics provide a bundle of effective techniques to find the global optimum of black-box functions. The benefit of these algorithms is the fast convergence towards the global optimum at a minimum number of function evaluations, whereas a drawback originates from the significant overhead produced by the algorithm itself.\r\n\r\nIn this paper, we present EMMOA, a surrogate-based optimization method for multiobjective optimization of black-box functions. The iteration process starts with some points generated by a Latin hypercube approach. Repeatedly, a model is trained to fit the existing data and exploited to find new points which are likely to yield better results. Several models are used for multiobjective optimization. The way new points are chosen from the models is of crucial importance for the convergence of the algorithm: the exploitation of the model and the investigation of unexplored regions of the feasible set have to be balanced.\r\nWe examine the performance of EMMOA at a real-world problem and at several test functions. Proposals for effective implementation and the use of the algorithm are made.", :title "Numerical Experience in Optimization of Costly Technical Applications with Surrogate-Based Optimization Algorithms", :keyword2 41, :authors (16918 17076), :session 79}, 378 {:keyword1 21, :keyword3 40, :abstract "This paper examines the relation between Industrial Product-Service Systems and innovative business models. Industrial Product-Service Systems constitute a problem solution for Business-to-Business markets, customized for individual customers' needs along the Industrial Product-Service System life cycle. They are characterized by an integrated and mutually determining process of both planning and developing as well as of provisioning and usage of goods and services. Thus, we develop a model restricted to two periods, the design and the operating phase, to analyze Industrial Product-Service Systems. During the first period the design activity, viewed as an investment in valuable resources, takes place. In the second period the benefits of this investment are realized. As the amount and nature of changes to the initial design cannot be determined ex ante, product development takes place within an incomplete contract framework. Owing to the incomplete character of this framework, business models are needed to define ownership rights and responsibilities. Therefore, we argue that the design of Industrial Product-Service Systems and business models are interrelated decisions. Particularly, we develop several business models for Industrial Product-Service Systems: product-oriented, use-oriented and result-oriented. While in the product-oriented business model the customer buys and operates the technical equipment and thus possesses ownership rights, in the result-oriented business model the ownership rights maintain with the supplier, who also operates the machine. In the use-oriented model the supplier guarantees the technical availability of the equipment. We determine adequate business models for specific Industrial Product-Service Systems in a profit maximizing framework.", :title "On the Relation Between Industrial Product-Service Systems and Business Models", :keyword2 100, :authors (14865 14863), :session 143}, 379 {:keyword1 122, :keyword3 99, :abstract "Bottleneck analysis is a classical part of research in the field of performance analysis of heavy loaded systems. We reconsider standard closed exponential networks with cyclic structure where the number of customers grows unboundedly.\r\nWe study the cycle time and sojourn time of customers in the stationary system and characterize the influence of the slowest server on the customers' behaviour.\r\nThe main results are an invariance property of the conditional  distribution for the successive sojourn times given the cycle time and a non-standard central limit theorem for the successive sojourn times during a customer's cycle.\r\nThe talk is on joint work with Christian Malchin and Ryszard Szekli.\r\n", :title "Bottleneck analysis for networks: The impact of heavy traffic on cycle times", :keyword2 88, :authors (17075), :session 132}, 381 {:keyword1 106, :keyword3 0, :abstract "In transport logistics, routing is usually done by a central instance that is solving the optimisation problem of finding the best solution to cover the current set of orders with the current set of vehicles under constraints such as punctuality, vehicle utilisation etc.\r\n\r\nApproaches have been suggested recently which change this paradigm towards a distributed approach with autonomous entities deciding on their own. Autonomous entities denote, in this case, the vehicles as well as the goods. When each of the entities makes its own route decisions, it has to consider multiple parameters, which are partially static (e.g. distances) and partially dynamic. An example for a dynamic parameter is the knowledge about vehicle availability that goods need for their decisions.\r\n\r\nThe work presented here is based on the information exchange concept DLRP (Distributed Logistic Routing Protocol), which has been proposed before. Within that framework, the concept of weighted multiplicative parameter aggregation is now introduced for the route decisions made by autonomous entities. In this parameter aggregation, the value range of each parameter is first projected to a common range to achieve fairness between the parameters, and then the parameters are aggregated into a weighted product that provides a measure of the route quality with respect to the importance of all contributing measures. The concept will be validated by simulation of dynamic logistic scenarios.", :title "Weighted multiplicative parameter aggregation for distributed routing in transport logistics", :keyword2 95, :authors (17079 17611 17082), :session 60}, 382 {:keyword1 106, :keyword3 14, :abstract "One way to handle growing dynamics and complexity of logistics systems is to shift from a central planning to decentralised, autonomous control strategies. The concept of autonomous control is the main research area of the German Collabo-rative Research Centre 637 \"`Autonomous Cooperating Logistic Processes – A Paradigm Shift and its Limitations\"'. Within this CRC, a new concept for dynamic transport networks is developed, which is designed to match goods and vehicles and to continuously make route decisions within a dynamic transport environment. Here, each object makes its own decisions. It is called Distributed Logistics Routing Protocol – DLRP. \r\nIn order to evaluate this new concept, it is obvious to compare it to the traditional solutions of the Vehicle Routing Problem. But there are crucial differences between the two problem formulations: the VRP is a static problem while the DLRP is designed for a dynamic environment, the two formulations have different goal functions (total vehicle distance vs. vehicle distance, package distance, punctuality ...) and the nets are topologically different. For the comparison of both designated algorithms, one single problem definition is given in this article, which both sides can cope with. Based on this definition, an adaption of the DLRP for the static problem is described. The sub-goals of the logistic objects in the DLRP and the target of the traditional algorithms are assimilated and a mathematical connection is given. Finally simulation results of both approaches based on the described adapted VRP are confronted and discussed.", :title "An Autonomous Control Concept for Adapted Vehicle Routing Problems", :keyword2 95, :authors (17079), :session 60}, 391 {:keyword1 35, :keyword3 0, :abstract "Interest rate data exhibits a high degree of serial correlation. When using even simple affine term structure models - like the Vasicek (1977) model - this results in a Fisher information matrix close to singularity. Here the standard deviation of  the parameters controlling the mean of the process is going to explode.  In this paper we investigate this problem in a Bayesian context. We apply Markov Chain Monte Carlo simulation techniques in connection with regularized priors, as proposed in Schotman/vanDijk (1991) and  Pooter et al. (2006), to simulate the joint posterior distribution of the model parameters. With these priors we derive a proper posterior, however the standard deviations of the estimates remain high. In addition priors are constructed to reduce these highly volatile parameter estimates.\r\n\r\nSecond, when considering times series from the fixed income sector we observe yields for different maturities. In financial econometrics two approaches are used to estimate the model parameters: either by assuming that all yields are observed with market micro-structure noise or that some time series are observed without noise. The second contribution of this paper is an in-depth investigation of these approaches. We demonstrate that if the percentage of market-micro structure noise is low, the latter approach provides us with reliable parameter estimates and the computational burden is low compared to the first approach. This econometric analysis, including a stability analysis, is performed with simulated data.", :title "Term Structure Estimation and Highly Persistent Processes in a Bayesian Context", :keyword2 34, :authors (17085), :session 185}, 392 {:keyword1 120, :keyword3 0, :abstract "Overpayment is an quality issue in insuarnce industries related to processes and customer relationships. The reasons for this are manifold, e.g. due to good will. Target of a ex post analysis of closed and settled claim files is detecting systematic structures which led to overpayments. Based on manual claim file inspection a data base is created as basis for the application of data mining algorithms including neuronal nets. \r\nFor the business relations tree algorithms are useful. It was shown on realistic data, how the algorithms work. The results given by the trees were validated and cross checked and analysed for sensitivity and robustnes. Finally a best practise process was proposed for an implementation in the industries.", :title "Detecting Overpayment Structures with Data Mining", :keyword2 87, :authors (15381), :session 157}, 393 {:keyword1 17, :keyword3 45, :abstract "In standard DEA models, input/output values must be algebraically adjusted depending on their expert-based interpretation. For example, in an input-oriented model relative technical efficiency decreases when input values increase but, sometimes, there are some inputs that must be interpreted on the contrary: the greater their values the greater the efficiency. The corresponding values of these \"`positive'\" inputs can be easily rescaled (algebraic transformation) in order to make DEA interpret them correctly. This procedure is impossible when: i) imprecise values for the inputs/outputs are considered, ii) their interpretation depends on the context (other input/output values) and iii) their interpretation must admit nuances within specific ranges (different interpretations depending on their values).\r\nIn this paper we propose a new expert-driven fuzzy inference engine to evaluate the input/output interpretation (modifying their values) the in a Monte-Carlo DEA input-oriented model (CCR or BCC). This procedure designs automatically the algebraic model to be solved by DEA in a Monte-Carlo simulation model, where input/output values are fitted to specific statistical distributions. Fuzzy rules are designed based on dependence relationships (DRs) defined by the experts. DRs determine the input/output interpretation depending on the context (input/output values). The technical efficiency of decision making units (DMUs) is evaluated in terms of probability (DMU probability of being efficient) once the simulation process stops (mean squared error).\r\nIn order to validate the model, technical efficiency of 72 small mental heath areas has been evaluated in an uncertain environment once the basic guidelines for input/output interpretation were defined by experts.\r\n", :title "Dynamic interpretation of input/output values in DEA", :keyword2 5, :authors (6218 7503), :session 91}, 395 {:keyword1 68, :keyword3 48, :abstract "In this paper, a variety of well-known allocation problem is considered and applied on a giant real world company operating in the automotive supply chain.  In this case, the current equipment installation and transporting materials within the facility is considered and the problem is formulated as a large scale mixed integer linear programming (MILP) problem to determine optimal installation scheme of equipment in order to lower movements of WIP within shop floor and minimize operating costs, or, equivalently, maximize the productivity of the total system. The result of the illustration shows the significant amount of 70\\% decrease in the total transportation distance which has not only resulted in significant traffic and transportation cost decrease, but has also led to a major revision in the transportation vehicles employed. The resulting MILP problem is solved via a heuristic search algorithm and its results is compared with the optimal results generated by CPLEX solver. The computational results and managerial implications follow.", :title "Traffic and Cost Diminution: A Case Study of the Allocation Problem Application", :keyword2 33, :authors (17086 16872), :session 142}, 396 {:keyword1 45, :keyword3 15, :abstract "   This paper analyses the effects of the introduction of the new Austrian performance-oriented inpatient payment system in 1997 on the treatment of patients with knee-joint problems. Using statistical models on the data from 1997 – 2006, we disclosed several major effects: 1) the number of patients increased by about 30%, 2) the length of stay decreased by about 28%, and 3) the number of reported reimbursement points increased by 50%. We furthermore found differences among patients treated in different counties due to the county-specific reimbursement system features. However, the overall trend in the treatment of patients with knee-joint problems can only be partly explained by the reimbursement system. More risky recreational sports and the aging population might also be responsible for the rise in the number of patients. However, big ticket technologies such as MRIs and CTs positively influenced the diagnosis and treatment of patients with knee joints too. Furthermore, new minimal invasive operation methods allow for better, quicker, and less painful treatment of patients with knee joints which could also be responsible for the increase in the number of patients treated and their decrease in the length of stay in hospitals.", :title "Using statistical models to analyze the incentives of the Austrian performance-oriented reimbursement system", :keyword2 25, :authors (770 2713 17089), :session 94}, 397 {:keyword1 8, :keyword3 106, :abstract "Difficult financial situations in most German cities and increasing competition in waste management between private and public companies require an efficient allocation of all resources that are involved in the waste disposal process. The two major resources are waste collection vehicles and crews. They can be assigned to the corresponding planning steps of finding so called waste collection districts and appropriate crew schedules. Each waste collection district is a part of a given overall waste disposal area and represents a determined set of households that have to be disposed on a single day of a given period by one vehicle.\r\n\r\nIn our talk we focus on the optimal districts as well as on the optimal routing of vehicles. The overall goal consists in minimizing the number of districts in order to achieve a minimal number of vehicles/crews in daily action. Various requirements have to be satisfied for practical waste management. Naturally, we have to dispose the waste of all households in time. Furthermore, we have to handle other constraints like limited vehicle capacities and limited daily working time of the staff which bounds the operation time available for routing a vehicle per day. To improve the acceptance of the waste collection schedule by the citizens, districts are required to be \"`clustered\"'. We outline first results from an ongoing joint project together with waste disposal companies, we discuss the relation of our NP-hard real-world problem to classical Arc Routing Problem and we compare various approaches for simultaneous or separate planning of districts and routes. We present preliminary computational experience for a particular Integer Programming model solved by Branch-and-Cut and we finish the talk with some concluding remarks on future research.", :title "Optimization Approaches for Capacitated Clustered Vehicle Routing in Waste Management", :keyword2 95, :authors (15375 13837), :session 72}, 398 {:keyword1 54, :keyword3 76, :abstract "The dispersion problems are about locating a set of agents in the candidate locations such that an appropriate measure of performance is improved. In some applications of the dispersion problems, like obnoxious facility problem, maximizing the minimum distance or the sum of the distances between the agents is sufficient, whereas in other applications, taking into consideration the connectivity among the agents can be necessary. Two such examples are the security guard placement in a site and the placement of wireless network access points (WAPs) in a building. In both examples, the dispersion of the agents may not be sufficient as the sole performance measure. In case of guard placement, it is desirable to ensure that a guard is visible to the other guards for increased security. Similarly in wireless network design, the service level is improved if a WAP can access the other WAPs. In this work we try to solve the location problem by maximizing the minimum distance between the agents and the sum of their connectivity. We discuss three solution approaches. The first one is a greedy heuristic. Using the solution of the greedy heuristic as the initial lower bound, we propose the second approach, which is based on tree search with bounding.  As the last solution approach, we present a constraint-based local search method. We conduct a computational study on a set of problems related to security guard placement and wireless mesh network design. To test the performance of the proposed approaches, we also report our results on maxmin and maxsum dispersion problems compiled from the literature.", :title "Dispersion and Connectivity in Location Problems", :keyword2 8, :authors (10362 406 17096), :session 206}, 399 {:keyword1 2, :keyword3 8, :abstract "The crew pairing problem is about finding the set of least costly flight sequences (pairings) for crews such that each scheduled flight is covered. In this study, we consider a robust version of the pairing problem. That is, the selected pairings not only cover the regular flights but also provide solutions to cover some extra flights, which may or may not be introduced to the flight schedule during operation at a later point in time. The crew pairing problem is usually solved by column generation methods, where the pricing subproblem becomes a multi-label shortest path problem. To solve the considered robust model, we propose four column generation approaches. Each of these approaches requires modifications to the multi-label shortest path problem for pricing. We present these modified pricing problems along with the associated labels and the domination rules. The complexity of solving the resulting multi-label shortest path problem grows exponentially as the number of flights (nodes in the network) increases. To overcome this curse of dimensionality, we propose two approximate rules based on the so-called score calculation. These approximate rules are used for early pruning of the paths on the processed nodes. Although these approximate rules reduce the number of paths drastically, the optimal solution may be missed due to the coarse structure of these pruning rules. Next to the approximate rules, we also propose an exact rule for refined pruning of the paths in the network. This exact rule is applied, when the approximate rules do not yield a pairing that improves the objective function value. Using actual data from a local airline, we present the performance of our solution approach through a computational study.", :title "Solving the Pricing Subproblem in a Robust Airline Crew Pairing Model for Managing Extra Flights", :keyword2 77, :authors (17040 17088 16992 406 10133 14274 1177 11344 17091), :session 19}, 400 {:keyword1 95, :keyword3 106, :abstract "The Vehicle Routing Problem (VRP) determines a set of vehicle routes originating and terminating at a single depot such that all customers are visited exactly once and the total demand of the customers assigned to each route does not violate the capacity of the vehicle. The objective is to minimize the total distance traveled by all vehicles. An implicit primary objective is to use the least number of vehicles. The Vehicle Routing Problem with Time Windows (VRPTW) is a variant of VRP in which lower and upper limits for delivery times for each customer are imposed. The arrival at a customer outside the specified delivery times is either penalized (soft time windows) or strictly forbidden (hard time windows). In the Stochastic Vehicle Routing Problem, the customer demands and/or the travel times between the customers may vary. In this study, we address the Time-dependent Vehicle Routing Problem with hard time windows. Time-dependency is the result of different traffic conditions in different time intervals throughout the scheduling horizon. We tackle this problem using an Ant Colony Optimization approach proposing a new visibility function. This function is based on the Clark and Wright savings measure and the time compatibility between the customers. The time compatibility is measured with possible arrival times to a customer given the customers’ time-windows and the corresponding time interval(s). The performance of the proposed algorithm is tested on the well-known benchmark instances from the literature.", :title "An Ant Colony Algorithm for Time-dependent Vehicle Routing Problem with Time Windows", :keyword2 59, :authors (17034 2423), :session 69}, 401 {:keyword1 2, :keyword3 8, :abstract "A typical airline crew pairing problem aims at selecting a set of flight sequences (pairings) for crews such that each flight in the regular schedule is covered by one crew. In this work, we consider the management of potential extra flights that can possibly be introduced to the regular flight schedule during operation at a later point in time. Without delaying or canceling any existing flight, we try to handle these extra flights within the regular schedule and refer to the resulting mathematical model as a robust airline crew pairing model. The objective function of the robust model involves not only the regular pairing costs but also the opportunity costs for failing to cover the extra flights. Due to the large number of variables (pairings), a typical crew pairing model is usually solved by column generation methods. Before applying column generation to the proposed robust model, we first discuss several procedures to cover the extra flights by a given set of feasible pairings. However, these procedures introduce extra column-dependent constraints to the model. That is, as new columns are added by column generation to the model, the number of constraints may also increase. Similarly if a column is removed from the model, then some of these extra constraints may be deleted. To handle this dynamic change in the size of the model, we propose four column generation approaches. The main idea behind these approaches is to generate a set of pairings (column pool) so that the number of constraints can be fixed. We also pay special attention to introduce into the column pool those pairings that can be used for covering the extra flights. We illustrate the proposed column generation approaches on a set of actual data acquired from a local airline.", :title "Column Generation Approaches to a Robust Airline Crew Pairing Model for Managing Extra Flights", :keyword2 77, :authors (17088 16992 17040 406 10133 14274 1177 11344 17091), :session 176}, 402 {:keyword1 48, :keyword3 0, :abstract "The paper will deal with price regulation scheme on the basis of return over costs regulation. Return over costs is scheme of natural monopoly regulation, which is in principle different form the model of regulation on the basis of rate of return. It derives the barrier for the not exceedement of reasonable profit only from the part of the regulated entity’s input activities, namely from the volume of investment. This undesirably motivated monopoly to disproportionate increase of capital investment, which was of course contra productive.\r\n\r\nReturn over costs regulation sets the maximum profit margin for regulated firm on the basis of its overall costs. We can see that there is certain analogy between this form of regulation and regulation on the basis of the rate of return. However the difference is that return over costs regulation does not prefer particular cost group, but uses the overall costs. \r\n\r\nThe idea, that firm’s profit is in this case some kind of function of its costs is of course mystification. This scheme, however, effectively hinders natural monopoly from asserting such combination of its supply and monopolistic market price, which would allow it to make inappropriate profit in comparison with exerted costs.\r\n\r\nIn general, return over costs regulation constructs reasonable profit margin for the regulated entity on the basis of the proportional portion of its total expended costs. This proportional portion is defined by the RoC parameter. So primary it encourages the producer to produce greater volume of supply by the lower price, which is increasing social welfare.\r\n", :title "Cost-oriented models of network industries price regulation", :keyword2 25, :authors (12763 12604), :session 148}, 404 {:keyword1 95, :keyword3 8, :abstract "Solving the Vehicle Routing Problem (VRP) is a key to efficiency in transportation and supply chain management. The VRP is a computationally hard problem that comes in many guises. The VRP literature contains thousands of papers, and VRP research is regarded as one of the great successes of OR. An industry of routing tool vendors has emerged. Exact optimization methods of today cannot consistently solve VRP instances with more than 50-100 customers in reasonable time, which is generally a small number in real-life applications. For industrial problem sizes, and if one aims at solving a variety of VRP applications, approximation methods is the only viable approach. In this talk, a brief motivation and introduction to the VRP will be given. We then describe how industrial requirements motivate extensions to the basic, rather idealized VRP models that have received most attention in the research community, and how such extensions can be made. At SINTEF, industrial variants of the VRP have been studied since 1995. Our efforts have led to the development of a generic VRP solver that has been commercialized through a spin-off company. As an illustration, a description of the underlying, rich VRP model and the selected uniform algorithmic approach, which is based on metaheuristics, is given. Examples of applications will be presented, along with results from computational experiments. There is still a need for VRP research to meet industrial requirements, particularly for large-scale instances and complex, rich VRP variants, for instance in the context of routing in combination of inventory management and fleet composition. Examples of ongoing projects will be given. In conclusion, we point to future trends and important issues in further VRP research.", :title "Industrial Vehicle Routing", :keyword2 48, :authors (899), :session 34}, 406 {:keyword1 75, :keyword3 0, :abstract "We present a solution approach for a variant of the dynamic multi-level capacitated lot sizing problem with linked lot sizes (MLCLSP-L). The MLCLSP-L combines features of both aggregated lot sizing models with \"`big time buckets\"' and more detailed scheduling-oriented models with small time buckets. In an iterative fashion, our Fix-and-Optimize approach solves a series of mixed-integer programs. In each of these programs all real-valued variables are treated, but only a small and iteration-specific subset of binary setup variables is optimized. A numerical study shows that the algorithm provides high-quality results and that the computational effort is moderate.", :title "A Fix-and-Optimize Heuristic for the Multi-Level Capacitated Lot Sizing Problem with Linked Lot Sizes", :keyword2 0, :authors (13866), :session 22}, 409 {:keyword1 91, :keyword3 0, :abstract "Manufacturing companies in a make-to-order environment sell customer oriented products which consume a limited amount of hosted resources during their production process. Usually, a company offers more than one product, faces a stochastic demand, and a time-varying price for these products. The latter cannot entirely be set autonomously by the company because of competitors. The decision the company has to make for an incoming order is whether to accept or reject the order, depending on the remaining capacity, the contribution margin of the order and the orders expected for the future. The most relevant differences of the presented problem and the \"`classical\"' airline revenue management are on the one hand the existence of significant variable costs and on the other hand the capacity utilization. While in airline revenue management the capacity utilization is always one unit, this is not the case for the presented problem.\r\nIn our contribution we will discuss if the methods for the airline revenue management are applicable to the make-to-order environment. After giving an overview about the requirements a decision support system ought to fulfill to improve the accept/reject decision of incoming orders in a make-to-order environment, we will discuss first results and challenges in applying methods of revenue management to a case study of a high performance alloy manufacturer. \r\nSpecific challenges include the integration of the highly customized orders with heterogeneous lead times and capacity utilization into the accept/reject decision process. In addition, depending on the types of forecasted orders, changing bottlenecks in the production network and the high variance in demand and relative contribution margins need to be considered.\r\n", :title "Revenue Management in a Make-to-Order Environment: specific challenges and solution approaches", :keyword2 7, :authors (14851 2651 13503), :session 136}, 411 {:keyword1 75, :keyword3 59, :abstract "The presented model is a simplified representation of the production process of semi-conductors, in particular the testing phase. In order to perform a special testing operation several machines are available. Usually the machines are not identical and do not fulfill a transitivity condition, i.e. for example product 1 can be processed on machine A or B but not on C and product 2 can be processed on machine B or C but not on A. Furthermore, the selected machine has to be configured with an according setup component which is a second type of resource with a limited availability. In general, the number of different setup components is considerably smaller than the number of different products. The aim is to determine how the production lots should be scheduled and assigned to machines such that delays and costs are minimized. So the resulting problem is a capacitated lot sizing problem with sequence-dependent setup times and parallel (non-identical) machines.\r\nWe developed a mixed-integer program representing the above situation. Special formulations are necessary to avoid sub-cycles in the setup process similar to the travelling salesman problem. Furthermore, the limitation of exact algorithms are investigated and heuristic as well as metaheuristic solution strategies have been developed and analyzed based on randomly generated test instances.", :title "Lot-sizing with a scarce setup resource on parallel machines", :keyword2 77, :authors (13889), :session 22}, 414 {:keyword1 121, :keyword3 96, :abstract "An important aspect of airport operations is the planning of\r\npassenger flows through the terminal. This presentation addresses to the analysis of workforce staffing for check-in systems. Due to demand and capacity restrictions, we categorize different types of staffing problems dependent on the planning horizon, the demand variability, the heterogeneity of the check-in systems, as well as labor law and contract restrictions.\r\n\r\nIn the considered application, check-in services are provided for different airlines. The operator requirement per small time period depends on the flight schedule and the contracts with the respective airlines, which leads to a time-varying demand. To meet this demand in each time period, a given number of operators has to be assigned to shifts and tours. Very flexible employee contracts result in a large number of possible shifts and tours.\r\n\r\nDifferent mixed integer programming (MIP) formulations are presented for this tour scheduling problem with a planning horizon of 15 days. The mixed integer programs are implemented using the General Algebraic Modeling System (GAMS)  and are solved by the standard solver CPLEX. Numerical examples compare the different formulations.\r\n", :title "Mixed-integer formulations for the tour scheduling problem at check-in counters", :keyword2 77, :authors (10255), :session 141}, 416 {:keyword1 100, :keyword3 0, :abstract "In recent years, manufacturers of serial parts have been facing changing business condi-tions, e.g. shortening product life cycles or the increasing demand for product variants. If suppliers of assembly systems offer solutions for these challenges to their customers, promising business models can emerge. Therefore, a variety of \"`Product-Service Sys-tems\"' has to be developed, which requires a stronger integration of the supplier of as-sembly systems into the use of the assembly system and hence into the production phase of the customer. Therefore, beside technical solutions, suppliers of assembly systems have to develop customer-oriented service packages for the entire life cycle of assembly systems. These might range to the point of a transfer of the complete responsibility for the operation of the assembly system to the supplier. To offer such solutions, suppliers of assembly systems have to restructure their previous activities extensively. Due to the financial risk connected herewith, decision models are required, which identify and as-sess the impacts resulting from the implementation of \"`Product-Service Systems\"'. As-pects like time delay, due to the reorganisation of the marketing department or the set up of adequate human resources have to be considered, just as the transfer of market risks to the supplier in \"`Pay on Production\"' models. The aim of this contribution is to develop a generic system dynamics model for the analysis of long-ranging consequences due to the implementation of \"`Product-Service Systems\"' and for the assessment of alternative service designs. The practical usability of the tool will be pointed out in an industrial case study.", :title "Simulation-based Strategic Planning of Product-Service Systems for the Assembly Industry", :keyword2 103, :authors (16924 17103), :session 143}, 417 {:keyword1 100, :keyword3 97, :abstract "\r\nDue to the manageable size- in terms of space and throughput- of most hinterland terminals, Operation Research techniques are rarely used in daily operations. Instead, work is mostly done intuitively. Overcoming this lack of optimization on tactical and operational level represents a potential for improving terminal efficiency.\r\n\r\nIn this paper, we focus on rail-road terminals and deal with the question \"`Which terminal activities or combination of activities need for optimization in order to improve the overall terminal efficiency?\"'\r\n\r\nIn a first step, tactical and operational decision problems of each area were defined separately. Further, heuristics were chosen to solve the decision problems of each area. Due to the existing dependencies between the different terminal activities, heuristics combining related problems were also considered. Finally all operating procedures were simulated and compared.\r\n\r\nThe results show that fundamental insights into factors affecting terminal performance are still lacking. Especially the impact of terminal configuration on operation strategies need more research. Which heuristic or combination of heuristics results in a favorable overall terminal performance and when is it useful to abandon the heuristics and to rely on intuition, has therefore to be analyzed individually for each terminal configuration. \r\n", :title "Assessing optimization opportunities for hinterland rail-road terminals: A simulation based procedure", :keyword2 68, :authors (17037 8436), :session 73}, 418 {:keyword1 45, :keyword3 0, :abstract "Das vor einiger Zeit vorgestellte (r,s,q)-Modell zur Modulversorgung der Stationen eines Krankenhauses mit medizinischem Verbrauchsmaterial soll um die vorgelagerte Stufe der Lagerhaltung im Zentrallager des Klinikums erweitert werden. Es entsteht eine zweistufige divergierende Distributionsstruktur mit einem Zentrallager und n nicht identischen Stationslagern, ein so genanntes One-Warehouse-N-Retailer-Problem. \r\nFolglich sieht sich das Zentrallager einer Periodennachfrage gegenüber, welche sich aus n voneinander unabhängigen Bestellprozessen, beschreibbar durch entsprechende Bernoulliverteilungen, zusammensetzt. Das Zentrallager seinerseits agiert gemäß einer (r,s,nq)-Politik. \r\nDer Vortrag skizziert einen Ansatz, bei dem die gesamten krankenhausinternen Bestände unter Einhaltung einer Servicelevelbeschränkung minimiert werden.\r\n", :title "Die krankenhausinterne Versorgung mit medizinischem Verbrauchsmaterial", :keyword2 75, :authors (17093 14707), :session 91}, 419 {:keyword1 41, :keyword3 0, :abstract "Global optimization problems arise in various research and application areas such as engineering design, telecommunications, and molecular biology.  Obtaining good solutions for those hard problems in an efficient way has been a challenging issue.  A number of solution methodologies have been proposed for global optimization problems with various characteristics.  However, the performance of a methodology is generally problem-dependent.  As an alternative approach, we are in the process of developing a multiagent environment for global optimization (MANGO).  This is an ongoing project that involves the design of an extensible and flexible multiagent platform, in which autonomous and heterogenious agents solve global optimization problems cooperatively.  Each agent in this system asynchronously executes an optimization algorithm and has some specific cooperative behavior so that it communicates with other agents during its execution. Various protocols are being designed for providing flexibility in agent cooperation. Also, the system is being designed as an extensible one so that new agents can be registered and adapted. In this study, we present an overview of the MANGO project and illustrate our progress by solving a set test problems compiled from the literature.", :title "MANGO: A Multiagent Environment for Global Optimization", :keyword2 0, :authors (17097 17104 17106 406), :session 79}, 420 {:keyword1 77, :keyword3 95, :abstract "The synchronization of available transport capacities and waiting commodities is a crucial aspect of operational freight transport planning. Freight transport capacities are provided by vehicles traveling along known paths through a transport network. Commodities represent transport requests. \r\nIn vehicle routing, the travel paths of the vehicles are adapted to the origins and destinations of waiting commodities. A vehicle travel path optimization is executed (vehicle-oriented flow optimization). In multi-commodity network flow optimization, the travel paths of the packages are optimized without considering any pre-specified vehicle paths or locations (package-oriented flow optimization). \r\nWe consider a situation in which both the vehicles and the packages provide a fixed travel path through a given network. It has to be decided for each step in a package path which vehicle is used to bridge an arc in the network. Thereby, a vehicle must offer a service from the origin of the arc to the destination of the arc. This decision situation is modeled as a mixed-integer linear program. We report about the derivation of the model and provide results observed in computational experiments in which the scarceness of transport resources as well as the costs structure associated with the network is varied.\r\n", :title "Matching Commodity and Transport Resource Paths", :keyword2 106, :authors (17079), :session 60}, 421 {:keyword1 91, :keyword3 2, :abstract "An airline has to decide whether to accept an incoming customer request for a seat in the airplane or to reject it in hope that another customer will request the seat in a later state of the booking process who will pay more. The capacity control as one of the instruments of revenue management gives a solution to this decision problem. In the existence of strategic alliances the capacity control changes. We propose a capacity control process, which is based on the existence of a single resource and two airlines in a strategic alliance. The determination of booking limits as control variables in the capacity control is realized with the aid of real options. A simulation model will be introduced to simulate the booking process for the strategic alliance. In an iterative process the booking limits are calculated with simulation-based optimization. The results of the simulations-based optimization will be compared with the results of a FCFS-approach.", :title "Option-based Revenue Management Procedures for Strategic Alliances", :keyword2 97, :authors (17052 14715), :session 136}, 423 {:keyword1 101, :keyword3 0, :abstract "Supply chains are characterized by fragmentation, centralisation and reverse logistics. From the perspective of sustainable development in the evaluation of these processes not only the economic performance but also the environmental dimension has to be considered. Traditionally, the economic performance is expressed by financial (e.g. total cost) as well as nonfinancial (e.g. customer service) measures. The sustainable performance is obtained by adding the environmental performance. This leads to a three-dimensional decision criterion total cost – customer service – environmental impact. Companies only consider the environmental perspective as far as legislative regulations exist. Further, when the environmental perspective is considered this is generally done at the business level, i.e. for a single manufacturing location or for a specific transportation process. Besides, due to external and internal drivers environmental topics become important for supply chains. These drivers can be customer pressure, legislative requirements or internal cost reduction initiatives. We develop an evaluation framework, including the economic and environmental dimension, that is used to verify the advantage of existing best practice supply chains. We illustrate our framework by a case study of an international supply chain from the electronics industry. From the perspective of economic performance an assemble-to-order (ATO) strategy turned out to be optimal because the reduction of safety inventory dominated the increase of transport. If the environmental performance is included it has to be checked whether the ATO strategy remains optimal. For the performance evaluation a multi-criteria decision making approach as well as the cost evaluation of the environmental impacts are applied.", :title "Evaluation framework for sustainable supply chain processes", :keyword2 102, :authors (16963 17095 2391 17105), :session 113}, 425 {:keyword1 48, :keyword3 75, :abstract "The modern car factory generally consists of three main production shops. The body shop where the body of the car is built, paint shop where the car body is painted and the assembly line where the car is assembled. The paper is considering the car body assembly line in the body shop stage. This line consist of lines of the robotic stages where body is constructed. The main criteria for the car factory is the throughput rate maximization which on the car sequence entering the production lines. The car sequence is constructed in the production planning phase. During the production process the original planned sequence is disturbed by the asynchronous working the assembly lines and quality audits. The quality inspections take some time and for several cases it is done by picking up the part from the sequence and returning it to the sequence later on. There are also buffers between the production lines where the sequence could be reestablished. The car sequencing problem was widely considered in the literature. The problem was formulated and described in different ways depends on the stage point from which it was analyzed in the car producing factory. Practical car sequencing problem was considered and taken from the real car plant. The goal was to maximize the total completion time in the body shop. From the scheduling point of view it is total completion time criterion for the car sequence. From the complexity point of view the general car sequencing problem is NP-hard in the strong sense. In the paper the special case flow shop problem is considered where the sequence restore is considered. The simulation experiment has been performed and some heuristics algorithms were proposed. These algorithms were compared in the computational experiment due to their effectiveness.", :title "Car sequencing problem in the car factory body shop", :keyword2 96, :authors (4224), :session 50}, 426 {:keyword1 29, :keyword3 18, :abstract "The liberalization of the European energy market now enables big gas customers and public utilities to build a portfolio of different gas suppliers und purchase constracts. The covering of the gas demand, which is heavily temperature dependent, can be optimized by combining base load contracts, open gas delivery contracts, and the use of the capacity of gas underground storages and local pipe storages. We present a Two Stage Stochastic Mixed Integer Linear Programming Model for the optimization of the gas purchase under uncertain demand and spot market prices including the design and operation mode of pipe storages and underground storage capacities and costs of transportation. The model is integrated in the decision support system SAPHIR which comprises modules for data management, scenario generation, portfolio optimization and risk analysis for strategic and operational gas purchase portfolio planning. ", :title "A stochastic optimization model and a decision support system for strategic and operational gas purchase portfolio planning", :keyword2 85, :authors (9272 17107 1141), :session 127}, 427 {:keyword1 35, :keyword3 98, :abstract "Die Optimierung von Portfolios wird zunehmend unter Berücksichtigung von quantilsabhängigen Risikomaßen wie beispielsweise dem VaR oder dem CVaR angestrebt. Optimierungsverfahren sind für realistische Problemstrukturen und –größen häufig nicht geeignet, daher bieten sich etwa simulationsbasierte heuristische Methoden an. Derartige Ansätze werden bereits in Managementsoftware zur Verfügung gestellt.\r\nDie beiden führenden Softwarelösungen, die Simulation und heuristische Methoden kombinieren und auf finanzorientierte Problemstellungen fokussieren, sind RiskOptimizer von Palisade und OptQuest von OptTek Systems. Beide Programme arbeiten mit Metaheuristiken zur Ermittlung möglichst guter Lösungen, RiskOptimizer mit einem genetischen Algorithmus, OptQuest basiert auf einer Kombination aus Tabu- und Scattersearch. Zur Ermittlung der verwendeten Simulationsergebnisse werden sowohl Monte Carlo als auch Latin-Hypercubeverfahren eingesetzt. Insbesondere die Einbindung beider Programme in die Oberfläche des in Unternehmen weit verbreiteten Programms MS-Excel begründet ihre Attraktivität für die praktische Anwendung.\r\nAnhand eines Beispiels, basierend auf umfangreichen Kapitalmarktdaten, werden im Rahmen einer empirischen Analyse die vorgestellten Programme hinsichtlich Kriterien wie Güte der ermittelten Lösung, Laufzeitverhalten und Flexibilität im Einsatz getestet und bewertet. Aufbauend auf den Ergebnissen der sowohl theoretischen als auch anwendungsorientierten Analyse werden Empfehlungen gegeben abgeleitet hinsichtlich der Eignung eines Einsatzes simulationsbasierter Heuristiken und ggf. der Softwareauswahl zur Ermittlung möglichst optimaler Portfolios.\r\n", :title "Ermittlung optimaler Portfolios unter Berücksichtigung quantilsabhängiger Risikomaße – Methoden und Softwarevergleich", :keyword2 97, :authors (16884), :session 89}, 428 {:keyword1 77, :keyword3 0, :abstract "Recovered paper nowadays is the most important resource in the paper production. Before recovered paper can be used to produce new paper from it, it is mingled with water to pulp. Then it has to be prepared in several steps. One of these steps is the so-called fine screening, where the pulp is especially cleaned from tacky particles, called stickies. These impurities could cause much trouble in the later paper manufacturing process, resulting in production losses. In this process, the suspension is piped through a multi-stage screening system, usually consisting of three up to six screens.\r\n \r\nThe aim of our work is to find the optimal layout of such a screening system and simultaneously the optimal adjustment of each of the built-in screens depending on the composition of the pulp. This problem is mathematical challenging because of the combination of the nonlinearities arising from the screening process itself and its combinatorial nature originating from the choice of the layout.\r\n \r\nIn order to solve this MINLP, we approximate the nonlinear functions by piecewise linear ones, and incorporate these in our model, resulting in an MILP, which for example can be solved by state-of-the-art branch-and-cut algorithms. For this purpose we introduce two approaches. On the one hand the bivariate nonlinear functions resulting from the screening process are approximated on triangular grids. On the other hand we develop a technique for transforming these functions to functions of one variable, and methods for approximating these. We determine the resulting approximation error of the original two-dimensional function and demonstrate the advantages of the later technique. Numerical results for several test instances are presented.", :title "Linearization Methods for the Optimization in Recovered Paper Production", :keyword2 92, :authors (17071 2481 16315 13046), :session 17}, 429 {:keyword1 100, :keyword3 99, :abstract "This work considers the strategic flexibility and capacity planning under uncertain demands in production networks of automobile manufacturers. We present a deterministic and a stochastic model, which extend existing approaches, especially by an anticipation scheme for tactical workforce planning. This scheme is compared to an extended formulation of the deterministic model, which incorporates workforce planning via detailed shift models. The stochastic model is efficiently solved by an accelerated decomposition approach. The solution approach is integrated into a decision support system, which calculates minimum-cost product allocations and capacity plans. We present an industrial case study which indicates that our anticipation scheme makes only a small error compared to the more detailed modelling approach and keeps the stochastic model solvable for hundreds of scenarios.", :title "Anticipating tactical workforce planning in strategic network planning in the automotive industry under uncertainty", :keyword2 7, :authors (17110 9272), :session 116}, 430 {:keyword1 106, :keyword3 97, :abstract "In this talk, we discuss cooperative transportation planning problems. This type of problems arises, for example, in the food industry where several food manufacturers are interested in sharing their vehicles to reduce fleet costs. We are interested in comparing cooperate scenarios with non-cooperative scenarios. A mixed integer programming formulation for the researched problem that takes constraints like capacity of the vehicles, time windows for delivery, maximum driver hours, and depots into account is presented. When the capacity offered by the vehicles is too small then vehicles of a specialized shipping company are used to send the transportation orders directly to customers. We suggest a two-phase approach that assigns first transportation orders to vehicles and then determines appropriate routes for each vehicle. The approaches are embedded into a rolling horizon scheme. Discrete-event simulation is used to assess its performance. We present results of computational experiments. ", :title "Simulation-based Performance Assessment of  Cooperative Transportation Planning Algorithms", :keyword2 68, :authors (17112), :session 61}, 431 {:keyword1 106, :keyword3 0, :abstract "Only few efforts have been spent on the coordination of plans and operations of independent carriers in an intermodal transportation chain. But this lack of collaboration affects the performance of the whole transportation chain. \r\nThus, a suitable coordination scheme has been developed to overcome this suboptimality. The basic idea of the scheme is that the participating parties iteratively exchange transportation plans to identify an improvement of the whole transportation chain. Thereby, the parties keep their individual planning domain private and do not disclose any critical information.\r\nIn this talk ideas for the identification of promising proposals will be presented as well as numerical tests to evaluate the performance of the coordination scheme.\r\n\r\n\r\n\r\n", :title "Collaborative Planning in Intermodal Freight Transportation", :keyword2 68, :authors (17109), :session 61}, 432 {:keyword1 8, :keyword3 75, :abstract "Industrial production lines consist of components that gradually wear off. Planned maintenance seeks to schedule maintenance activities in which these components are replaced before they malfunction. The objective is to minimize the total number of maintenance activities within the planning horizon such that no uncontrolled breakdowns occur and limited time resources are not exceeded. This foresighted approach reduces the total number of machine breakdowns and increases the reliability of the production system. Consequently, a significantly higher overall efficiency of the production plan is obtained. The practically-motivated and theoretically-elaborated work models the problem as a capacitated, collinear-covering problem. In contrast to many stochastic approaches in literature, deterministic lower bounds on the durability of each component are used since the respective distribution functions are usually kept as a business secret and hence, are unknown to real-world applications. In order to evaluate the efficiency of the proposed algorithm, computational results are analyzed.", :title "Solving the planned maintenance problem to optimality", :keyword2 77, :authors (14800), :session 134}, 435 {:keyword1 97, :keyword3 48, :abstract "Production and logistics processes in companies of the iron and steel industry are complex systems, which has made the use of discrete-event simulation (DES) an often times appropriate means for providing decision support in process optimization or capacity extension. As descriptive models with quantity and time based key measures, DES allows for the identification of weaknesses or the evaluation of improvement measures. However, its shortcomings lie in a lacking connection to the primary targets of a company (e.g. profit, net present value, market value), which ultimately pose the basis for a management decision concerning organizational changes or investments.\r\nThe particular characteristics of steel production processes hold as a good example for trade-offs and wrong decisions that arise from decision making based on operational (quantity and time based) objectives. In our contribution, we apply the case of a German steel manufacturer to reveal the shortcomings of traditional DES and present an approach to include value oriented figures in such models.\r\n", :title "Simulation with monetary figures for decision support in the iron and steel industry", :keyword2 18, :authors (13489 2651 13503), :session 133}, 437 {:keyword1 60, :keyword3 8, :abstract "Force structure modeling is a key tool for investigating fleet size and manning options for current and potential Canadian Air Force fleets.  The model of choice within the Canadian Air Force for most of the last decade has been the Air Force Structure Analysis (ASTRA) model. The ASTRA model provides a systematic method of determining the required force structure (e.g., fleet size, yearly flying rate, number of crews, etc.) given a set of operational requirements (e.g., force employment scenarios, air crew training requirements, maintenance schedules, etc.). The ASTRA model has been used with great success over the last few years.\r\n\r\nThis paper presents the second generation ASTRA model, known as ASTRA Mk II. Characteristics new to the second generation model are: 1) increased flexibility and transparency of the model; and 2) implementation of a bi-directional analysis capability, that makes it possible to determine the feasible region of operational requirements given a force structure. The first element resulted in merging several fleet-specific ASTRA models into a single generic model and implementing it in the MATLAB/Simulink environment. The properties of this environment  were vital to increasing model flexibility and transparency by providing a visual representation of the model design.\r\n\r\nThe bi-directional capability was implemented with a genetic algorithm. It was chosen because of its ability to search multi-dimensional solution spaces, simultaneous evaluation of multiple solutions, and the ability to handle complex non-continuous models. The solution space for the relationship between fleet size and maintenance parameters for a hypothetical fleet is presented, with a discussion of the potential impacts on logistics, operations and planning.", :title "A second generation air force structure analysis model - ASTRA Mk II", :keyword2 7, :authors (16995 17050), :session 171}, 438 {:keyword1 44, :keyword3 0, :abstract "In an experiment, we model two stylized facts about capital budgeting practice. First, budgeting has long been recognized as susceptible to gaming and building slack. Second, firms' headquarters do not centralize all investment decisions, but give decision making authority over some projects to division managers. Although centralization versus delegation is an important organizational issue in capital budgeting practice, theoretical research on budgeting has rarely analyzed their relative benefits.\r\n\r\nIn the experiment, under centralization, headquarters announces a budget limit, the manager gives a cost report, and headquarters decides on the project. Under delegation, headquarters allocates a budget to the manager, and the manager is authorized to decide about the project. In accordance with standard theory, we find no significant behavioural effects of the organizational design when budgets are binding, i.e. when headquarters is committed to the budget limit or the allocated budget, respectively. In contrast, with a non-binding budget, slack is significantly smaller under delegation, although this does not translate into a significantly higher payoff to headquarters. Further analysis reveals that a manager's behaviour is influenced, in a non-trivial way, by the organizational design. In particular, under centralization, a manager's cost report is significantly positively correlated with headquarters' budget announcement, whereas, under delegation, there is no such relationship. \r\n\r\nOur evidence suggests that allocating capital to a manager under delegation, compared to the mere announcement of a budget limit under centralization, tends to alleviate gaming in budgeting processes and to make the behaviour of the people involved be more level-headed.", :title "Centralization versus Delegation in an Experimental Capital Budgeting Setting", :keyword2 0, :authors (9667 8892), :session 81}, 439 {:keyword1 59, :keyword3 11, :abstract "There are many practical problems in which groups of similar subjects are to be retrieved from large data sets; these are called clustering problems. Because of the complexity of many clustering problems, meta-heuristics are often used to obtain high quality solutions within reasonable time limits. However, although tabu search has proved to be a successful methodology for solving optimization problems, applications to clustering problems are rare. In this paper, we construct a tabu search approach and compare it to the existing approaches k-means (Punj and Stewart, 1983) and simulated annealing (Brusco et al., 2003). Tabu search returns solutions of very high quality, also if constraints on feasible solutions are imposed. It is also generally more robust than simulated annealing: its solution quality depends to a lesser degree on the exact chosen parameter values or on randomized steps in the search process.", :title "A Tabu Search Approach to Clustering", :keyword2 56, :authors (), :session 171}, 442 {:keyword1 19, :keyword3 50, :abstract "Co-authored by: \r\n(i) Dr. Jan Thomas Martini, Universität Bielefeld, tmartini@wiwi.uni-bielefeld.de\r\n(ii) Prof. Dr. Rainer Niemann, Universität Graz, rainer.niemann@uni-graz.de\r\n\r\n\r\nRelated-party sales account for a\r\nsubstantial fraction of international transactions. Thus, within\r\nmultinational groups (MNGs) the international co-ordination of\r\ndecisions and the allocation of taxable income among different legal\r\nentities becomes vital. Transfer prices (TPs) are typically a device\r\nof both co-ordination and international tax planning.\r\n\r\nTax authorities have been aware of TPs' potential misuse to shift\r\nprofits to low-tax jurisdictions. Formula apportionment~(FA) is\r\nproposed as a solution for this problem. Under FA, a common tax base\r\nis calculated and divided among the host countries in accordance\r\nwith given apportionment factors. However, this implies that under\r\nFA income is shifted by changing economic decisions instead of\r\ntaking advantage of accounting options.\r\n\r\nThe goal of our paper is to analyze the impact of different\r\ncombinations of tax allocation and managerial accounting regimes on\r\ninvestment and production decisions. We show that it is ambiguous\r\nwhether or not MNGs favor the introduction of FA. The reason is that\r\neconomic decisions are distorted depending on the group's\r\norganizational structure. A prominent result of our analysis is that\r\nFA offsets the advantages of decision decentralization because it\r\nreverses the separation of responsibility areas.", :title "Transfer pricing or formula apportionment? Tax-induced distortions of multinationals investment and production decisions", :keyword2 35, :authors (16795), :session 88}, 444 {:keyword1 35, :keyword3 37, :abstract "The relative value arbitrage rule, also known as pairs trading, is a well established speculative investment strategy on financial markets. Today, especially hedge funds use pairs trading as a long/short investment strategy. Based on relative mispricing, pairs trading strategies create excess returns if the spread between two normally co-moving stocks is away from its equilibrium path and is assumed to be mean reverting, i.e. deviations from the long term spread are only temporary effects. In this situation, pairs trading suggest to take a long position in the relative undervalued stock, while the relative overvalued stock should be shortened. The formation of the pairs ensues from a cointegration analysis of the historical prices. Consequently, pairs trading represents a form of statistical arbitrage. However, economic reasons might cause the spread to widen even more instead of coming back to equilibrium, implying simple pairs trading signals to be wrong. To overcome this problem of detecting temporary in contrast to longer lasting deviations from spread equilibrium, this paper bridges the literature on Markov regime-switching and the scientific work on statistical arbitrage to develop useful trading rules for pairs trading. Empirical results indicate that the price ratios can be modelled by a mean reverting process. However, the mean of the price ratio seems to switch between different levels and traditional technical trading approaches often fail to indentify profit opportunities. Therefore, we apply a Markov regime-switching model with switching mean and switching variances to detect such phases of imbalances. The developed investment strategy is applied to the investing universe of the DJ EUROSTOXX 600, whereof appropriate pairs are selected.", :title "A regime-switching relative value arbitrage rule", :keyword2 34, :authors (16953 14545), :session 86}, 446 {:keyword1 76, :keyword3 99, :abstract "In this contribution we focus attention on risk-sensitive optimality in discrete-time Markov decision chains under additional constraints, i.e. we assume that to each transition of the Markov chain a pair of transition \r\nrewards, say the principle and auxiliary reward, is accrued. \r\nSince we intend to fully capture the variability-risk features of the problem, we assume that the streams of principle and auxiliary transition rewards generated by \r\nthe Markov reward chain are evaluated by an exponential utility functions, i.e. by utility functions with constant risk sensitivity.\r\nOur task is to maximize average utility generated by the stream of principle transition rewards on condition that the average utility generated by auxiliary rewards is nonsmaller than a given value. For Markov decision chains with finite state and action spaces we suggest policy iteration method for finding optimal policy in the class \r\nof stationary randomized control policies.\r\n \r\n", :title "Constrained Risk-Sensitive Markov Decision Chains", :keyword2 93, :authors (10023), :session 129}, 447 {:keyword1 106, :keyword3 59, :abstract "\r\nWhile in location planning it is often assumed that deliveries are made on a direct-trip basis, in fact deliveries, e.g., to the different supermarkets belonging to a specific chain or to retail outlets of any kind, usually are performed as round-trips. Therefore, it is often necessary to combine the two issues of locating a depot and of planning tours in one problem formulation. \r\nA neural network approach based on a self-organizing map is proposed for solving such single-depot location-routing problems in the plane. Some modifications which rely on ideas from Tabu Search can be shown to be especially useful for increasing the number of feasible solutions found by the self-organising map approach. ", :title "Combined Location-Routing Problems - A Neural Network Approach", :keyword2 95, :authors (17056), :session 34}, 449 {:keyword1 91, :keyword3 0, :abstract "A specific challenge of make-to-order manufacturing lies in selecting those orders that allow for maximizing the total contribution margin given a fixed capacity. In case demand exceeds capacity, it can be beneficial to decline current orders, such that more profitable orders can be accepted.\r\nParticularly in the steel industry and for high performance alloy manufacturers, this becomes a complex task as a result of the high variance of contribution margins and capacity requirements of orders.\r\nNetwork revenue management approaches have been successfully applied to support order acceptance decisions. In particular, bid-price based heuristics can be used to estimate the input oriented opportunity costs of order acceptance. The central prerequisite of applying bid-price based approaches is an accurate forecast, since forecasting errors may deteriorate the performance of the bid price policy. To this end, if the realization of demand does not match the forecast, approaches which dynamically adjust the bid-prices seem to be promising. This results in a dynamic bid-price policy. The objective of this paper is to provide an extension to traditional bid-price based revenue management in make-to-order steel manufacturing. Based on an analysis of the effects that erroneous forecasts have on the performance of bid-price policies, we will use artificial intelligence techniques to expand standard bid-price approaches and present the results of a comparative study.\r\n", :title "Dynamic Bid-Price Policies for Make-to-Order Revenue Management", :keyword2 0, :authors (2651 4263 13503 15390), :session 136}, 450 {:keyword1 109, :keyword3 101, :abstract "We analyze a two-echelon inventory system with one warehouse, one retailer and a priority customer class that is directly delivered from the warehouse. The customer demands can be arbitrarily distributed. At both stockpoints, the inventory management is according to a reorder-point policy with periodic review and fixed replenishment order sizes. Under this assumption, we present a discrete-time Markov chain model to describe the inventory positions. With this model, for a given critical inventory level at the warehouse, the service levels for both customer classes can be computed.", :title "An Exact Model of a Two-Echelon Inventory System with Priority-Different Customer Classes", :keyword2 75, :authors (14801 6751), :session 117}, 451 {:keyword1 15, :keyword3 56, :abstract "One of the most critical decisions in customer relationship management approaches, interactive marketing campaigns, and in direct marketing activities is the assignment of customers to groups with similar response characteristics. This decision usually is based on previous purchase behavior, occupation, income, and other socio-demographic variables. This information from different sources is likely to provide managers with conflicting indications of group memberships.\r\n\r\nIn our study we utilize a multi sensor clustering and a rough sets approach (Pawlak (1982)) for assigning individuals to groups. In a second step we outline the combination of different assignment recommendations by means of the transferable beliefs model (Dempster (1967), Shafer (1976), Smets (1988)).\r\n\r\nFor an empirical application we rely on a set of transaction data recorded from a customer loyalty program and additional information describing the card holders.  \r\n\r\nReferences:\r\nDempster, A. (1967). Upper and lower probabilities induced by a multi-valent mapping. Annals of Mathematical Statistics 38, 325–339.\r\n\r\nPawlak, Z. (1982). Rough sets. International Journal of Computer Science 11, 341–356.\r\n\r\nShafer, G. (1976). A mathematical theory of evidence. Princeton, New Jersey: Princeton University Press.\r\n\r\nSmets, P. (1988). Belief functions. In P. Smets, E. H. Mamdani, D. Dubois, and H. Prade (Eds.), Non-Standard Logics for Automated Reasoning, pp. 253–286. London: Academic Press.\r\n\r\n\r\n", :title "Enhancing Target Group Selection Using Transferable Beliefs", :keyword2 18, :authors (17098 17121), :session 99}, 452 {:keyword1 8, :keyword3 77, :abstract "The Depot Management Problem (DMP) consists in the\r\nassignment of vehicles of a public transport or railway company to parking positions in a depot and to timetabled trips.  Such companies have many different types of vehicles, and each timetabled trip can be performed by buses of some of these types.  For instance, some vehicles have special lifting devices for disabled people and are required on certain trips. Other lines demand small vehicles because\r\nthey do not have a big demand, while other lines need large ones, specially during periods of heavy traffic.\r\n\r\nThe management of such task is non-trivial due to the topology of depots. The parking positions are organized in tracks, which work as one- or two-sided stacks or queues in rail-bound traffic.  So, accessing a vehicle from the middle of such a track would require a shunting move, which is undesirable and must be avoided.  Assigning decent parking positions to the vehicles is a central issue in depot\r\nmanagement and a key to the smooth operation of a public or rail transport company.\r\n\r\nIn the talk we discuss integer programming formulations for some combinatorial problems related to DMP. The simplest versions are modeled as constrained assignment problems, and optimal solutions for real-world instances can be obtained with standard optimization tools, as SCIP or CPLEX. Advanced versions of the problem deal with many periods, which have to be solved in an integrated way. As a consequence, they require more complex models and, eventually, more advanced solving strategies.", :title "Solving the Depot Management Problem", :keyword2 106, :authors (16980 14923), :session 70}, 453 {:keyword1 96, :keyword3 0, :abstract "This study addresses two main problems in scheduling component placement operations for collect-and-place type printed circuit board (PCB) assembly machines, i.e. constituting placement tours and determining placement sequences within each tour. In this work, an efficient clustering algorithm to create placement tours and two modified nearest neighbor (MNNH) algorithms to determine placement sequences within these tours are proposed. The objective is to minimise the assembly cycle time per board. The clustering algorithm generates equal size tours, the size of which is determined by the number of nozzles on the machine head. This quality enables generating as minimum tours as possible for each PCB and decreases the cycle time considerably. The algorithm subdivides PCB placement area by using horizontal dividing lines and constitutes clusters within these subareas. The proper number of dividing lines to obtain the best cycle time for each PCB is found automatically by the algorithm. This approach creates homogeneous and compact clusters and enables the machine head to complete the placement tours within less time by more benefiting from the rotational cycle time. Another advantage of this approach compared to distance or density based algorithms in the literature is prevention of the deterioration that occurs towards the last clusters produced by those algorithms. The MNNH algorithms reduce the travel time of the machine head in the y-direction compared to well known NNH algorithm in the literature. The first MNNH algorithm gives the best cycle times with the proposed clustering algorithm. Computational experiments show that the proposed algorithms provide a significant reduction in both cycle time and computation time. Corresponding author: Özgür Kulak", :title "Scheduling component placement operations for collect-and-place type PCB assembly machines", :keyword2 0, :authors (17122), :session 50}, 454 {:keyword1 78, :keyword3 0, :abstract "We look at the problem described in 1992 by Davidov and Davidova, where for a given real matrix A we want to know whether every real matrix B with the same sign pattern as A has a nonnegative, nonzero element in its null-space. Such a matrix A is called sign-central. Davidov and Davidova gave a natural characterization of sign-central matrices that was proven by a rather long argument. In this paper we present a direct and simple proof showing that the aforementioned characterization of sign-central matrices can be seen as a consequence of the strong duality theorem of linear programming.", :title "A Simple New Proof for a Characterization of Sign-Central Matrices using Strong Duality", :keyword2 0, :authors (17063), :session 140}, 455 {:keyword1 8, :keyword3 0, :abstract "Territory design is the problem of grouping small geographic areas called basic areas (e.g., counties, zip code areas) into larger geographic clusters called territories such that the latter fulfill relevant planning criteria. These criteria can either be economically motivated (e.g., average sales potentials, workload or number of customers) or have a demographic background (e.g., number of inhabitants, voting population). Moreover, spatial restrictions are often demanded. \r\n\r\nThe problem we discus is motivated by the new recycling directive WEEE of the EC. The core of this law is, that each company which sells electronic products in a European country has the obligation to recollect and recycle an amount of returned items which is proportional to the market share of the company. In Germany, for one type of products, the so called white goods (e.g., dry-cleaners, washing machines, fridges), a territory design approach is followed. However, as the EC wants to avoid that a recycling corporation gains a monopoly in some region of Germany, all basic areas which are allocated to the same corporation should be geographically as dispersed as possible. That is, one of the classical criteria for territory design problems, compactness, is completely inverted. \r\nFor this problem, we first review the initial mathematical programming model. Afterward, we introduce improvements of the model which include strategies for fixing variables as well as valid inequalities. Moreover, we discuss a simplified version of the problem which allows us to obtain tight and easy to compute bounds for the original problem. Finally, computational results will be presented that underline the model improvements.", :title "New Results for the Maximal Dispersion Territory Design Problem", :keyword2 77, :authors (12140 1116 5078), :session 179}, 457 {:keyword1 68, :keyword3 80, :abstract "We examine real-life problems, which arise from operative planing in waste water management over a finite horizon. This mathematical decision support is highly desirable but leads to very hard problems. These problems are typically large nonlinear mixed integer network problems with a special structure, where most constraints are continuous nonlinear. Especially in the sewer system many constraints are non-continuous. We particularly consider the mathematical aspects of these non-continuous constraints and discuss difficulties in modeling. We model the problem in GAMS and discuss different strategies for solving this kind of problems.\r\n", :title "Modeling Strategies for MINLP network optimization problems arising from wastewater management", :keyword2 66, :authors (14780), :session 137}, 458 {:keyword1 85, :keyword3 63, :abstract "Optimization problems depending on a probability measure\r\ncorresponds to many real-life applications. Of course, if the \"`underlying\"' probability measure is known, then these problems can be solved (at least approximately) by nonlinear numerical methods. However, it happens rather often that this probability measure is unknown and some statistical estimate is employed to obtain at least\r\nestimates of the optimal value and optimal solution. A great effort has been paid to investigation of these estimates as well as to the investigation of the stability (considered with respect to probability measure space). Especially, attention has been also paid to the case when empirical measure substitutes the theoretical one.\r\n\r\nIn the talk we focus on \"`classical\"' stochastic programming\r\nproblems with recourse. Employing the stability results obtained by the Wasserstein metric, we introduce assumptions for the exponential convergence rate.\r\nOur results cover also the case when the Lipschitz property of the \"`outer\"' problem is not fulfilled. To obtain new results we introduce also conditions under which the inner problem is well defined. We generalize by this the condition of fixed complete recourse matrices. The multiobjective optimization theory is employed to obtain this result.\r\n\r\n\r\n\r\n", :title "Stochastic Programming Problems with Recourse via Empirical Estimates", :keyword2 99, :authors (), :session 127}, 460 {:keyword1 92, :keyword3 18, :abstract "The consumption of electrical and electronic goods is increasing worldwide. Technology and functionality improvements continuously raise the replacement rate of this kind of appliances resulting in a growing amount of discharged products which need to be properly treated and disposed. This contribution focuses on the implementation of the European Directive on Waste of Electrical and Electronic Equipment (WEEE) in Denmark and specifically addresses the problem of assigning waste or, more precisely, the different fractions of waste at the individual collection stations to the so-called collective schemes which perform the waste treatment for the producers and distributors of the electrical and electronic products. This assignment must guarantee that all disposed WEEE is collected throughout the entire country. The task is performed annually by an institutional agency called WEEE-System and has to be carried out in a way that not privileges any of the collective schemes. The aim of the study is allow the WEEE-System to evaluate possible configurations such that the determined assignment matches the objectives of the involved actors, e.g. the municipalities, the collective schemes and logistics service providers. The problem is solved through a mixed integer linear programming (MILP) modelling approach which takes the market share of the member companies represented in the collective schemes into account. We present a decision support tool into which the optimization model was incorporated and numerical results for the current configuration in Denmark.", :title "A MILP for configuring reverse networks for electric and electronic waste", :keyword2 65, :authors (909), :session 203}, 461 {:keyword1 66, :keyword3 0, :abstract "In a recent article [1] a globalization scheme for a local nonsmooth Newton method from Kummer [2] was proposed. This globalized method is particularly suited for nonlinear optimization problems with only one time continuously differentiable objective function and constraints. We show interesting applications from (generalized) semi-infinite optimization, which lead to such problems. We work out the necessary technical details for the application of the abstract globalized algorithm from [1] to nonlinear optimization problems and give numerical results for test problems from (generalized) semi-infinite optimization.\r\n\r\nReferences:\r\n[1] S. Bütikofer, Globalizing a nonsmooth Newton method via nonmonotone path search, Mathematical Methods of Operations Research (2008), DOI: 10.1007/s00186-008-0219-8\r\n[2] D. Klatte and B. Kummer, Nonsmooth Equations in Optimization, Kluwer, (Dordrecht-Boston-\r\nLondon 2002)\r\n", :title "A globalized nonsmooth Newton method, applications and numerical results", :keyword2 83, :authors (), :session 138}, 462 {:keyword1 100, :keyword3 111, :abstract "Process reengineering has become one of the most relevant issues in industrial production planning, where principles of Lean Management or Total Quality Management have found successful applications. In the last decade, the area of services has increasingly come into the focus of restructuring. Widespread trends towards globalization as well as towards reengineering of service supply chains by insourcing and outsourcing have led to completely new process structures of services. Typically in services, but likewise in some traditional industrial production systems, planning has to deal with both uncertain demand and uncertain processing times. Taking an example of material logistics in OP-preparation as a starting point, we introduce basic models focused on the investigation of process structure modifications with a focus on the relevant stochastics. Differently from comparable production models, we investigate uncertain demands and capacity requirements so as to take into account influences of nontangibility and external factors on service processes. Methodically, we use a transaction cost approach comparable to the concept of Lee/Tang (1997) for supply chain restructuring, and we develop static models taking into account regular working cost and intervention cost. Our approach disposes of restricting assumptions on process conditions like queue disciplines or stochastic independences.", :title "Models for Reengineering Service Processes", :keyword2 99, :authors (17090 17120), :session 141}, 463 {:keyword1 33, :keyword3 0, :abstract "One of the most important strategic decisions of a service provider relates to the customer-value oriented design of the ultimate service package, i.e. the question of what to offer and how to deliver it. We consider the service design problem in the service shop sector that includes hotels and restaurants, retail shops, wholesalers, and repair services for cars and household goods. In 2004, these industries generated 17\\% of the gross value added (GVA) in Germany. \r\n\r\nThe key decisions in service shop design relate to facility location, service process configuration, product variety and pricing. Alternative service facilities typically compete for customer demand with each other where a facility’s attractiveness to a customer is determined by criteria such as convenience/accessibility, responsiveness, product assortment/quality, and price level. However, the underlying design decisions of the seller have heretofore been treated independently in different research streams of production operations management, service management and marketing. We present a profit-oriented optimization model and solution methods to simultaneously accommodate the key design decisions in service shop planning. Our approach is applied   to a case study on retail service design.\r\n", :title "Integrating Service Facility Location, Process Design, and Product Variety Management for Service Shops", :keyword2 91, :authors (63162), :session 149}, 464 {:keyword1 101, :keyword3 0, :abstract "Supply chain optimization has emerged as an important topic in almost all industries with vertical disintegration. In the automotive industry such supply chains are prevalently composed of independent agents with specific preferences, e.g. distinct firms or profit centers in holdings. In either case, one must expect that no single party has control over the entire chain, and no partner has the power to optimize the whole chain by hierarchical planning. Under such decentralized decisions a way to improve supply chain performance is achievable through coordination and synchronization.\r\nThe field of collaborative planning offers novel coordination concepts for such situations; particularly without relying on partner’s private information (i.e. costs or capacities). We characterize issues in such concepts in automotive supply chains under asymmetric cost allocations. Here, and as well in other industries, few assembly sites (mostly owned by OEM's) are linked to multiple suppliers in a converging structure. We find, that under such setting, an iterative negotiation-based process based on counter-proposals is little different to upstream-planning, as local supplier-side savings have comparatively small effects. We study further how renegotiation opportunities in collaborative planning interact with the hold-up problem (i.e. at least one party performs relationship-specific investments), as a further characteristic in the automotive industry.\r\n", :title "Collaborative Planning: Issues with asymmetric cost and hold-up in automotive supply chains", :keyword2 75, :authors (17117), :session 114}, 465 {:keyword1 77, :keyword3 0, :abstract "Currently, an aircraft's flight path is computed on the basis of a given \"`airway-graph\"' which can be considered as streets in the sky on which planes were allowed to fly. In this setting the best possible route can be found by using standard shortest path algorithms.\r\nIn the future, it will be allowed to use flight paths without the consideration of this graph. A more extensive problem of finding the best path is the consequence. This is known as the Free Flight Problem. For computing the optimal flight path several aspects such as weather conditions (especially wind), overflying costs and restricted air spaces need to be considered. \r\n\r\nModelling these aspects, the problem of finding the optimal path becomes a nonlinear mixed-integer problem. \r\nIn order to solve this problem using techniques from discrete optimization we discretize the time.\r\nWe show that the remaining nonlinearities can be approximated by piecewise linear functions on triangular grids. For this approximation of a two-dimesional function, we have to partition the underlying domain into triangles. These triangles have to be ordered in a special manner. We show possible techniques of finding such an ordering. \r\nWith the help of additional binary variables, the whole problem can be transformed into a mixed-integer linear program.\r\nThe obtained time-discretized mixed-integer linear program for the Free Flight Problem can be solved with common branch-and-cut algorithms. Furthermore, we reduce the complexity of the problem with some techniques.\r\nComputational results are presented, and compared with solutions obtained by nonlinear mixed-integer solvers.", :title "Free Flight Optimization", :keyword2 2, :authors (17115 16315 13046), :session 17}, 466 {:keyword1 33, :keyword3 94, :abstract "Facility layout problem is a well-researched one since it plays an important role in manufacturing systems. There are optimal and heuristics algorithms that have been proposed to solve the problem. Optimal algorithms can not produce optimal solutions for the problems with more than 20 departments. Hence, heuristics have been generally used. In our application, unequal-sized departments were handled. First of all, the existing facility layout algorithms in the literature is introduced and analyzed. The second step of the study is the determination of the most effective facility layout for a company operating in metal industry. A computer-aided layout planning tool, VIP-PLANOPT 2006, has been used to generate a new facility layout design as an alternative to the company’s current facility layout design. The software consists of four cost functions. They differ from each other according to cost (relationship) matrix which is allowed to be either symmetric or non-symmetric by the software. In our application, our cost matrix is non-symmetric. At the end of the study, results of the generated layout alternative and existing layout have been compared with each other and the most suitable one for real working environment has been chosen.", :title "A Facility Layout Application On a Firm Operating in Metal Industry", :keyword2 48, :authors (13171), :session 142}, 468 {:keyword1 56, :keyword3 91, :abstract "Zunehmend kann eine wachsende Bedeutung von Dienstleistungen in Industrieunternehmen beobachtet werden. Physische Produkte werden vielfach um kundennahe Angebote erweitert, um sich gegenüber Wettbewerbern zu differenzieren, so dass ein innovatives Leistungsprogramm durch Sach-, Dienstleistungen und hybride Produkte beschrieben werden kann. Verbunden mit dieser kundennahen Leistungsprogrammerweiterung ist es von großer Bedeutung, nicht nur die Erlöse einzelner Produkte zu betrachten, sondern das gesamte Produktprogramm deckungsbeitrags- bzw. ergebnismaximal zu gestalten. Erfolgversprechend können Sach- und Dienstleistungen zu hybriden Produkten kombiniert werden, indem aufbauend auf einem detaillierten Produktentwicklungsprozess sowohl externe als auch interne Produktinformationen berücksichtigt werden. Diese können als Nutzen- und Kostenbestandteile kaufrelevanter Merkmalsausprägungen in ein Optimierungsmodell zur Bestimmung optimaler Sach-, Dienstleistungen und deren Kombinationen einfließen. Zielpreise für die simultan bestimmten Leistungsvarianten können dann als Optimierungsergebnis im Rahmen der Konstruktion, einer Produktmodifikation oder der Gestaltung eines Ertragsmodells genutzt werden.\r\nEinsatzmöglichkeiten eines Optimierungsmodells zur Bestimmung eines deckungsbeitragsmaximalen Leistungsprogramms für hybride Produkte werden im Rahmen eines innovativen Produktentwicklungsprozesses vorgestellt und kritisch gewürdigt. Eine Fallstudie veranschaulicht die Konfiguration dieser Sach- und Dienstleistungen durch Bestimmung optimaler Varianten und zugehöriger Preise.", :title "Optimale Konfiguration hybrider Leistungsbündel", :keyword2 68, :authors (15182 13335 10057), :session 143}, 469 {:keyword1 95, :keyword3 59, :abstract "In this study, a decision support system (DSS) has been developed in Microsoft Visual Studio .NET environment using C#. It solves single-depot open vehicle routing problems (OVRPs) for the personnel of a major bank call center operating in Istanbul. Geographical coordinates of the call center headquarters (HQ) and agents’ home addresses are obtained from Google Earth, and then converted into 2-dimensional planar coordinates with the HQ being the origin. The distance matrix is calculated using Euclidean distances. The DSS reads the weekly work schedule of all 337 agents of the call center from an Excel worksheet, and reports the beginning and ending times of different shifts, which apply to the work schedule. It allows the user to select from a database the names of the agents to be used in the routing. The call center has signed a contract with a personnel carrier company, which provides as many vehicles with heterogeneous capacities as needed. There are two equivalent types of OVRP to be solved, one for the pickup of agents from their homes before the start of their shift and one for their return from the HQ after their shift ends. In both cases, vehicle tours are subject to a time limit of two hours of commuting. We resort to a tabu search algorithm with 1-0 move, 1-1 exchange, 2-Opt, and 2-2 exchange operators and with strategic oscillation to solve the respective OVRP instance for each shift. In our presentation, the DSS developed for this personnel transportation problem will be demonstrated. In addition, vehicle tour lengths and durations that yield from the implementation of the proposed routes on actual road distances will be compared to the theoretical results obtained by the DSS with Euclidean distances.", :title "An Open Vehicle Routing Application for the Personnel of a Call Center", :keyword2 106, :authors (17124 3397 3455), :session 34}, 470 {:keyword1 15, :keyword3 19, :abstract "Launching a new product under an existing brand name is a strategic decision problem for all the firms. This risky decision depends highly on consumer based brand equity which is assumed to affect the success of new products through the perceptions of consumers. Therefore, the valuation methods used for new product launching decisions should include the results obtained from consumer based brand equity measurement. Additionally, valuation methods may no longer depend on traditional fundamentals but rather future expectations. Real options analysis is one of the valuation methods which can assess the embedded opportunities such as intangible assets of the firms in this decision process. The aim of this paper is to propose a two-stage approach for integrating consumer based brand equity to the decision process of new product launches. In the first stage of the research, consumer based brand equity is measured by means of structural equation modeling. In the second stage, real options method is applied by using the results obtained from the first stage. This integrated approach is used in the decision process of new product launching for a leader \"`white good\"' brand in Turkey. ", :title "Linking Consumer Based Brand Equity to New Product Launches: An Integrated Approach", :keyword2 35, :authors (643 14371 17123), :session 155}, 471 {:keyword1 104, :keyword3 65, :abstract "Modern optical telecommunication networks consist of several layers. The optical fiber connections between the nodes comprise the lower, physical network layer. Along the paths in this fiber network optical connections, so-called light-paths, can be established. These light-paths form an upper, logical network layer, in which the data traffic is routed. The bandwidth of a light-path depends on the optical and electronic equipment installed at its ends. Different light-paths may have different bandwidths. Furthermore, each fiber can carry only a limited number of light-paths.\r\n\r\nIn the multi-layer network design problem we seek for a cost minimal such network for a given traffic forecast. This involves finding the right number of parallel fibers for each physical link, the topological layout and the dimensioning of the light-paths, the installation of the optical and electronic components at the nodes, and the routing of the traffic demands in the resulting logical network. Depending on the specific application, network survivability issues, special routing policies, or other technical restrictions must be considered as well.\r\n\r\nIn this talk, we report on our experience with mixed-integer linear programming approaches for multi-layer network design problems gathered from several research projects at ZIB. We show how to formulate and solve such problems as mixed-integer linear programs, illustrate model reduction techniques and strong cutting planes that exploit the multi-layer network structure, and present some specially tailored integer-programming based heuristics, that proved to be efficient in practice. Finally, we discuss the results of a computational study based on realistic instances, which show the effectiveness of our techniques.", :title "Multi-layer telecommunication network optimization", :keyword2 77, :authors (13058 12177 12185 12184 12231), :session 201}, 472 {:keyword1 28, :keyword3 0, :abstract "Over the past years the importance of natural gas, which is used for both the generation of power and heat, has risen in the energy industry. At the same time the ongoing liber-alization of natural gas markets and the development of wholesale markets for gas have induced new challenges for electric utilities. We compare the impacts on a portfolio sub-ject to an increase in natural gas prices with two different analytical approaches. It can be shown that the change in the value of the portfolio of a utility with respect to a rise in electricity prices, taking into account the merit order, is much higher than the portfolio delta in a conventional approach. By contrast the change in the portfolio value with re-spect to an increase of natural gas prices is much smaller in the merit order approach. Using risk quantification techniques the effect of these observations on a risk measure of a portfolio is identified.", :title "Impacts of liberalized natural gas markets – A risk management perspective", :keyword2 93, :authors (17005 14845), :session 87}, 473 {:keyword1 48, :keyword3 0, :abstract "Retaining cost-related competitiveness in the iron and steel industry is a task of two measures: Maintaining adequate plant utilization due to the high capital intensity and managing variable costs, which are increasingly affected by a significant portion of energy related costs.\r\nFor the galvanizing of strip metal, strips of different quality and dimension are welded together and passed through a zinc bath in a continuous process. Process parameters such as heating or speed vary dependent upon product specifications.  An uncoordinated sequencing of products in terms of these specifications leads to frequent time and energy consuming adjustments of the process parameters.  In our contribution, we will identify the economic potentials of a model-based sequencing which minimizes energy costs while ensuring a predefined throughput. The approach is based upon the asymmetric TSP with stochastic input parameters.\r\n", :title "Energy cost based sequence planning of a refinement plant in the iron and steel industry", :keyword2 0, :authors (17118 2651 13489), :session 133}, 474 {:keyword1 97, :keyword3 0, :abstract "International accounting for pension obligations is one of the most complex issues in accounting. The international accounting standard 19 \"`employee benefits\"' offers several ways to cope with actuarial gains and losses. Actuarial gains and losses are unavoidable to a certain level and may cause high fluctuations in pension costs. \r\n\r\nTherefore, the corridor approach as usual treatment in IAS 19 has been developed in order to smooth pension costs. The corridor approach consists in accumulating all actuarial gains and losses outside the financial statements. Only if the sum exceeds a (positive or negative) amount (i.e. the corridor), the excess has to be recognised within profit or loss. The excess can even be amortized over the expected remaining worklives of the pension plan’s employees. On the other hand there exist the equity approach where actuarial gains and losses are be recognised immediately within equity and never in the profit and loss account. The recent US approach can be regarded as a hybrid of corridor and the equity approach. In March 2008 the International Accounting Standards Board issued a discussion paper with three possible solutions to solve the problem. Some of these approaches cause a rise in complexity because of the additional elements in the system on accounting for pensions.\r\n\r\nThe paper concentrates on the unavoidable and artificial sources of pension cost fluctuation as well as the ability of the approaches mentioned above to smooth pension cost. Therefore we define a smoothing criterion and perform an Monte Carlo simulation study. As a result, we suggest a way to avoid complexity and to get moderate smoothing. At least the solution presented can be regarded as more compatible with decision usefulness than the other approaches.", :title "Smoothing effects of different ways to cope with actuarial gains and losses under IAS 19", :keyword2 35, :authors (13364), :session 88}, 475 {:keyword1 8, :keyword3 0, :abstract "We consider two problems: SVP (\"`Subset  Vector Problem\"') and CSVP (\"`Constrained Subset  Vector Problem\"') that can be stated as follows:\r\n\r\nSVP: given the set of n k-dimensional vectors V={v1,... vn}\r\nand a number m less or equal n. Find set W={w1,... wm} - subset of V consisting of m vectors, so that it maximizes the Euclidean norm of sum vector S = w1+w2+...wm.\r\n\r\nCSVP: given the set of n k-dimensional vectors V={v1,... vn}\r\nand numbers m, l, such that l(m-1) less than n. Find set W={w1,... wm} - subset of V consisting of m vectors and satisfying condition that for each pair vi and vj of vectors in W the relation on indicies |i-j| greater than l holds, so that it maximizes the Euclidean norm of sum vector S = w1+w2+...wm.\r\n\r\nCSVP arises from a problem of recognizing repeated signal in noisy network. SVP is its particular case with l=1.\r\n\r\nIn [1] it was shown that both problems are NP-hard in general case (when k is an input parameter of the problem). Pseudopolinomial algorithm when k is a fixed number was provided for integer inputs.\r\n\r\nWe show that in case when k is a fixed number, both problems are polinomially solvable, providing combinatorial algorithm with time complexity O(k^2 * n^{2k})  (for SVP).\r\n\r\nWe also present new pseudopolinomial algorithm for integer inputs based on Dynamic Programming approach. It has O(kmn(2mb)^k) complexity, where b is maximal absolute value of vectors' components.\r\n\r\nThe work was supported by grants RFBR (projects 08-01-00516  and 07-07-00222).\r\n\r\n1. A.E. Baburin, E. Kh. Gimadi, N. I. Glebov and A. V. Pyatkin. The problem of finding a subset of vectors with the maximum total weight // Journal of Applied and Industrial Mathematics, Vol. 2, No 1, 2008. P. 32-38.\r\n\r\n", :title "On Subset Vector Problem with Maximal Euclidean Norm of Sum", :keyword2 76, :authors (13863 10785), :session 23}, 476 {:keyword1 92, :keyword3 0, :abstract "Remanufacturing and refurbishing strategies do not only hold ecological, but often also economic advantages. For OEMs of high value products, product recycling strategies seem to be promising. For products with short life cycles and many product variants including common parts, component recycling strategies seem to be advantageous. However, in order to capture arising economic potentials by sale of remanufactured products or by substitution of new components, the recycling strategies have to be implemented into forward production planning processes. Because of uncertainties in quantity and state of returned products, complexity of planning procedures increases tremendously.\r\n\r\nAgainst this background, a hierarchical concept for integration of product take-back measures into production planning of OEMs is developed. In the presentation we focus on the integration of product and component recycling processes in demand and production planning. If product and component recycling strategies are applied simultaneously, interdependencies between planning processes and rivalry for returned products are to be regarded.\r\n\r\nWithin the contribution a corresponding planning model regarding all product recycling options as well as uncertainties concerning the product take-back and the distribution of recycled goods is developed. The allocation of returned products into recycling options as well as the impact on component demand is assessed. The concept and model is applied on the case of a manufacturer that is applying product as well as component recycling strategies simultaneously.\r\n", :title "Production Planning with common parts under uncertainty in Closed-Loop Supply Chains", :keyword2 101, :authors (15188 2650 2651), :session 203}, 478 {:keyword1 35, :keyword3 93, :abstract "If we trade in stock markets we are interested in buying at low prices and selling at high prices. There are competitive online algorithms which can be used to solve this type of problem. The effectiveness of these online algorithms is analyzed from a worst case point of view. One objective of the paper is to give average case results using historical XETRA DAX data. Moreover we compare the results of the online trading algorithm to an optimal algorithm and to other heuristic trading algorithms.", :title "Empirical Analysis of Online Trading Algorithms", :keyword2 97, :authors (15362 8824), :session 89}, 479 {:keyword1 63, :keyword3 102, :abstract "The aim of this paper is to present a binary integer programming model for crop planning under uncertainty in the presence of contract quotas. Agricultural production under or above the quota targets receives penalizations, therefore it is discouraged. The penalizations are modeled with the help of loss functions. A numerical example is studied for the case of linlin loss functions.\r\nThe model is a multiple objective programming model that takes into account various risks as climate risks and market risks. Starting from it, one formulates several single objective models:\r\n-\tthe average loss minimization model\r\n-\tthe expected return maximization model\r\n-\tthe financial risk minimization model\r\n-\tthe loss-return-risk tradeoff model\r\nWe analyze losses associated to the optimal production plans that try to comply to the target production quotas versus various parameters of the average loss minimization model.\r\n", :title "A loss function approach to crop planning in the presence of production quotas", :keyword2 93, :authors (14957 9663), :session 129}, 482 {:keyword1 5, :keyword3 39, :abstract "Investment managers would like to have high return and/or low risk by optimal allocation of their investments among different assets. To realize this idea, a proper portfolio model must be designed. Portfolio modeling intends to maximize the expected return under a given risk level and/or minimize risk under a given return level. In most of existing portfolio selection models, the decision maker (DM) should confirm that all of the information available (or needed) is brought to bear on the problem at hand. In real world, most of needed data are incomplete and suffer some ambiguity and vagueness; thus they decisions must be made under conditions of uncertainty. \r\nWith the introduction of the fuzzy set theory, it was realized that imperfect knowledge of the returns on the assets and uncertainty involved in the behavior of financial markets may be captured by means of fuzzy quantities and/or fuzzy constraints. Existing fuzzy portfolio selection models are mainly oriented to partial fuzzification of deterministic linear programming models. Solutions of these models suffer from high computational complexity resulting from the conversion of fuzzy linear programming models into standard crisp one. In this situation, a better solution can be obtained by applying meta-heuristics, such as immune algorithms (IA). The use of IA in fuzzy portfolio optimization allows us to find a near-optimal solution with a computational complexity less than the existing methods. In this paper, the expected returns are assumed to be triangular fuzzy numbers. Taking into consideration above mentioned, in this paper, a fuzzy portfolio selection problem based on fuzzy linear programming solved by IA is considered. Numerical examples are given to demonstrate the effectiveness of our proposed method.", :title "Solving a fuzzy portfolio selection with an Immune Algorithm", :keyword2 35, :authors (17341 17084 17108), :session 103}, 485 {:keyword1 103, :keyword3 100, :abstract "Due to environmental problems such as widely acknowledged man-made global warming, governments in OECD have set ambitious goals to reduce CO2-emissions. Especially the automobile industry has been in the focus of these new regulations. For a car manufacturer the question arises what consequences these new regulations may have concerning model policy and technology development. In the past, the majority of customers did not purchase eco-friendly cars, but opted for larger vehicles like Sports Utility Vehicles. It seems to be difficult to fulfill both customers’ preferences and governmental regulations. Therefore, the goal of this contribution is to assess how the automobile market will be affected and how a manufacturer should cope with this situation in the long term. \r\n\r\nRegarding the present situation we find a highly complex and dynamic environment that includes several uncertainties. Therefore, a simulation model to analyze the situation and possible future developments is proposed. The model displays the interaction of manufacturers and customers with regard to technical measures that aim at meeting CO2-emission goals. Customer reactions have to be incorporated, too. Thereby it is assumed that customers base their decision, which model and drive train to buy, on available information about offered products and their experience with cars presently in use. A car manufacturer decides which technology to offer projecting past purchasing decisions into the future combined with its own anticipations about future success of new technologies. \r\n\r\nThe paper aims to assess different scenarios of changing drive train technologies and purchasing behavior, in order to develop strategies for a manufacturer to meet emissions regulations without losing market shares.", :title "Feedback effects of regulations for the reduction of CO2-emissions from road transport", :keyword2 97, :authors (14924 2650 2651), :session 94}, 486 {:keyword1 65, :keyword3 101, :abstract "Latest discussions have shown that there is significant criticism on the use of 1st generation bio-fuels in Germany. Reasons are for instance that the cultivation of the required biomass results in ecological damage and increasing food prices worldwide. The use of 2nd generation synthetic bio-fuels promises to overcome these shortages, due to a higher biomass recovery and technical advantages. However, when it comes to designing production networks for 2nd generation bio-fuels, decision makers are challenged by uncertainties regarding the availability of biomass, the new production technologies and the changes in fuel-demand. \r\nIn terms of the logistical system design, the trade-off between economies of scale and transportation costs is to be analyzed when deciding about centralized or decentralized plant concepts. Besides the transportation costs, the assessment of the two concepts is based on information about the investments and the operating costs for different capacities. Since several unit operations are still in their development phase, the investments and operating costs can only be estimated based on the available technical descriptions. The complexity of material conversion within divergent and cyclic structures demands for technical models to adequately simulate the energy and material flows. \r\nAgainst this background, a robust dynamic planning approach for the selection of technologies and planning of network structure will be presented, incorporating the specific uncertainties and technical information for the production of 2nd generation bio-fuels.\r\n", :title "Sustainable network design for the production of 2nd generation synthetic bio-fuels", :keyword2 94, :authors (14870 2650 2651), :session 113}, 488 {:keyword1 101, :keyword3 0, :abstract "In present design processes in research and development several companies with different roles are involved. As an example the development of complex embedded systems for automobile electronics can be mentioned. Complex embedded systems are characterized by a modular design of different interacting hard- and software components. Currently it is state-of-the-art in the system industry that these components are delivered by specialized suppliers to a system integrator.\r\nHowever, inappropriate contracts and insufficient incentive structures lead to a decreasing flexibility within the development process. For instance, suppliers tend to estimate the technical performance of their components in a conservative way.\r\nIntensified by existing uncertainties, differing objectives of the partners and asymmetric information, this leads to inefficiencies in the design process and the design of the embedded system itself. Furthermore, this increases economic risk for suppliers and integrators. Overcoming these difficulties requires improved coordination between the partners before and during the development process.\r\nIn light of these challenges, approaches for improvement of collaborative development of complex embedded systems through applying business contract models and mechanisms of supply chain management will be presented. It is the aim to increase flexibility and to decrease inefficiencies in development processes through the implementation of such methods.", :title "Coordination of Decentralized Embedded System Development Processes", :keyword2 90, :authors (15178 2650 2651 17048 17087), :session 119}, 490 {:keyword1 8, :keyword3 63, :abstract "This work deals with the problem of optimizing timetables in complex public transport networks. The focus lies on the connections between different transportation companies, where passengers transfer between vehicles. The main goal of our research is to improve the contentment of these passengers: we try to enhance the convenience of the given timetable by applying small changes to the departure times of the vehicles. This is different from previous research work in the sense that we propose an interactive optimization process, which directly involves the traffic planner. Our method does not simply try to minimize waiting time, but to maximize convenience.\r\nWe propose a multi-criteria approach, since every meeting point of two transportation lines generates an optimization goal on its own. The problem is modelled as a Quadratic Semi-Assignment Problem that is known to be NP-hard. Different types of constraints guide the optimization process, e.g. by forcing the algorithm to improve individual transfers or to maintain the status quo at a station. \r\nThree different meta-heuristic approaches will be presented, namely Ant Colony Optimization, a Genetic Algorithm and Simulated Annealing, which can be used to solve this multi-criteria optimization problem. Furthermore, a Mixed Integer Programming approach is introduced that is solved by ILOG CPLEX. The advantages and disadvantages of these algorithms are compared with respect to the quality of their solutions.", :title "Multi-criteria optimization for regional timetable synchronization in public transport", :keyword2 59, :authors (16873 17136 17128 2427 15433), :session 63}, 492 {:keyword1 35, :keyword3 59, :abstract "Different criteria are considered from decision maker's view in project selection problem. There exist some conflicts between these criteria. In this way selecting the most suitable projects while establishing a trade off between those criteria requires high attention. Project selection problem belongs to a class of combinatorial optimization, and NP-hard problems due to its complexity and high volume of computation. Obtaining an optimal solution for this complex, large-sized problem in reasonable computational time by using traditional approaches and optimization tools is extremely difficult. Motivated by the above considerations, in this paper a novel hybrid multi-objective ant colony optimization (HMACO) based on Pareto concept is proposed for project selection problem which aims to maximize total benefits while total risk and total cost are minimized, simultaneously. Finally result of the proposed algorithm are compared with a well known multi objective algorithm namely NSGA II. Various performance metrics are applied on outputs of several test problems in order to verify the efficiency of the proposed algorithm. Performance metrics show encouraging results by the means of the quality of the solutions obtained.", :title "A hybrid multi objective ant colony optimization for project selection problem", :keyword2 5, :authors (17401 17084 2229), :session 103}, 494 {:keyword1 96, :keyword3 77, :abstract "Paint shop problems occur in various settings in industry where product colors are chosen by each customer individually. Typical examples are the automobile industry or the steel production. In general, the goal for paint shop problems is to obtain an order of the given jobs with long subsequences of the same color subject to many constraints.\r\n\r\nThe problem presented in this talk is a real-life multi-stage paint shop problem. Metal sheets, referred to as jobs, have to be painted on several machines in a row with machine and job specific colors. For every job the assignment of the colors to the machines is fixed, that is, colors cannot be interchanged between machines. Due to  the production technique, every job has identical processing times on all machines and the job order is the same for all machines. Using the same color on a machine longer than a certain threshold allows a fast color change on that machine. Otherwise, a color change is only possible with an additional idle time. Further constraints, like restrictions on the difference of the widths for consecutive jobs, may also lead to additional idle times. The objective is to minimize the sum of the overall idle times.\r\n\r\nFor practical reasons only algorithms with a running time of at most few minutes are acceptable. Due to the complicated and partly history dependent constraints in the problem, this seems to allow only heuristical algorithms. An approach using genetic algorithms with integrated local search heuristic is presented. Different adjustments, like different crossover and mutation methods, are evaluated on real-life instances. The quality of these solutions is compared with lower bounds obtained by means of a mixed integer program.", :title "Multi-Stage Paint Shop Scheduling with History Dependent Set-Up Times", :keyword2 59, :authors (17125 17134 14969), :session 16}, 495 {:keyword1 10, :keyword3 42, :abstract "Spreading processes on networks can often be mapped onto network reliability problems. The computational complexity of the event that the spreading process reaches some given subset K of the nodes is well studied as it reduces to the classical K-terminal reliability problem. In the context of spreading processes, however, one is often interested in more global properties of the spreading process, such as the expected spreading size or the probability of a high-impact spreading. In this paper, we discuss the complexity of these problems on two types of networks, with weighted respectively unweighted nodes. Whereas the direct Monte-Carlo approach is an FPRAS for the expected spreading size in the unweighted case, we show that, unless P equals NP, there is no FPRAS for estimating the probability of large spreadings (in the weighted as well as the unweighted case). Furthermore, we show that estimating the expected spreading impact in a weighted network is of the same computational complexity as estimating s-t reliability.", :title "Computational Complexity of Impact Size Estimation for Spreading Processes on Networks", :keyword2 89, :authors (17127 17063), :session 196}, 496 {:keyword1 79, :keyword3 59, :abstract "In electronics, 2.5D System-in-Package (SiP) is an integration of heterogeneous electronic components on several modules which are stacked or folded vertically. This integration meets modern requirements for miniaturized electronic systems but still lacks adequate design automation tools. We propose an optimization approach to 2.5D SiP design automation.\r\n\r\nThe design of SiP includes two optimization problems, i.e. the partitioning and the placement problem. The partitioning problem is to divide the components onto the module sides whereas the placement problem is to position the components on each module side.\r\n\r\nSimulated Annealing is often used for similar problems in other electronics layout problems, for instance in very large scale integration (VLSI). We apply simulated annealing to both the partitioning and placement problem.\r\n\r\nWe extend the multiobjective simulated annealing and introduce the concepts of objective-driven moves and adaptive move selection which support the algorithm to find better solutions. Objective-driven moves intelligently perturb the intermediate solutions of simulated annealing according to an objective function of the optimization problem. An adaptive process evaluates the success of the moves and regulates their selection. The goal is to apply successful moves more often.\r\n\r\nWe evaluate our concepts of objective-driven moves and adaptive move selection for the partitioning and placement problem and present numerical results showing improvements of the solution quality in both problems. As the concepts are problem-independent they can be applied to other optimization problems.\r\n", :title "Multiobjective Simulated Annealing with Adaptive Objective-Driven Neighbourhoods for 2.5D System-in-Package Design", :keyword2 16, :authors (17021 16904 17132 2427 15433), :session 16}, 498 {:keyword1 94, :keyword3 0, :abstract "Time-cost tradeoff problems have been studied extensively in the past. In a typical setting, a feasible project plan has to respect precedence constraints between the jobs and meet a fixed deadline, while the duration of each job depends linearly on the costs invested for this job.  This classical model reflects essential aspects for real-world project scheduling problems. It is known to be solvable even for large instances by a combinatorial algorithm. As the algorithm is based on a min-cost flow, it preserves integrality.\r\n\r\nYet, in real-world applications the data is subject to uncertainty. We integrate this aspect by allowing a limited fluctuation for the slope and intercept of the linear cost function. Since projects normally only need to be carried out once, a robust approach stands to reason. The classical strict notion of robustness yields a solution, which is feasible for any scenario, but has unacceptably high costs. To avoid this drawback, we allow a solution to be recovered to a certain extent after the data has been changed. Our form of restricted recovery is motivated by a practical observation. One may hire extra resources for recovery. But one may not unlimitedly withdraw from contracts fixed in the planning phase.\r\n\r\nWe show that this recoverable robust time-cost tradeoff problem can be transformed equivalently into a linear program of size polynomial in the input data. Its dual problem is a variant of the min-cost flow problem. Unlike the deterministic problem, the recoverable robust time-cost tradeoff in general has no integral optimal solution even for basic non-series-parallel precedence graphs. For series-parallel graphs of precedence constraints we give a combinatorial algorithm, which yields integral solutions. ", :title "The Recoverable Robust Time-cost Tradeoff Problem", :keyword2 96, :authors (17092 14969), :session 19}, 501 {:keyword1 34, :keyword3 0, :abstract "The contributions of Markowitz (1952, 1959) initiated the modern portfolio selection theory but in practical applications the resulting portfolios are frequently unbalanced caused by estimation errors of the input parameters. In case of short selling restrictions, many stocks are not even contained in the optimized portfolio, otherwise there are extremely large absolute portfolio weight values. In 1998 Michaud developed a new procedure called \"`Resampled Efficiency\"' to achieve more balanced and more intuitive portfolios. Using this approach the estimation errors are incorporated in the resulting portfolio weights. Furthermore, many suggestions how to estimate the input parameters for the Markowitz optimization or the resampled efficiency can be found in literature.\r\n\r\nWe compare the performance of the fundamental optimization procedures by Markowitz and Michaud using six sub-strategies (e.g. historical estimation, Bayes estimation, minimum variance strategy, equally weighted strategy) by means of a two-stage simulation procedure similar to Kempf and Memmel (2003): First we draw 100 times \"`true parameters\"' for the expectation and the variance-covariance-matrix of the returns. Then, we simulate returns on the basis of the true parameters. Therefore, we draw 100 return histories for every true parameter. Each return history consisting of 60 monthly returns represents the actual observable realizations. We apply all estimation strategies on these realizations and measure the performance of the resulting portfolios in comparison to the optimized portfolios using the \"`true parameters\"'. We determine which strategy performs best and give recommendations for estimation methods and optimization procedures. \r\n", :title "Simulation-based Analysis of Portfolio Building Strategies", :keyword2 97, :authors (14626 14627 17135), :session 89}, 502 {:keyword1 8, :keyword3 86, :abstract "We consider the Turnaround Scheduling Problem as it occurs e.g. in chemical manufacturing, where entire production units are shut down for comprehensive inspection and renewal on a regular basis. \r\n\r\n\r\nIn a turnaround a huge number of interdependent jobs must be\r\nexecuted by maintenance groups (resource types). The processing time of a job is flexible in the sense that it decreases with increasing number of resources, whereas the work is increasing in the number of resources. Furthermore resource type depending work shifts have to be respected. \r\nSeveral resources are rented in a constant amount for the whole project duration which results in high service cost.\r\n\r\n\r\nA feasible schedule consists of a feasible temporal assignment of resource units to jobs and a feasible sequencing for all of them. The goal is to find feasible schedules of minimum cost for a given project duration. This problem can be interpreted as a generalization of the Time-Cost Tradeoff Problem and a resource leveling problem for malleable jobs.\r\n\r\n\r\nIn this talk, we present our new model based on an integer programming formulation with an exponential number of variables that indicate a configuration for a subset of jobs for a shift. A configuration for a subset of jobs is an assignment of resources to each job of one resource type\r\nwith respect to capacity and precedence constraints. Solving this model in reasonable time means to solve the pricing problem efficiently. We will present some benchmark results in which we compare the solution of the integer programming formulation with a fast real-world heuristic which we developed before.\r\n\r\n", :title "Branch-and-Price Algorithm for the Turnaround Scheduling Problem", :keyword2 77, :authors (14976 14969), :session 175}, 504 {:keyword1 8, :keyword3 82, :abstract "The quadratic linear ordering problem naturally generalizes various optimization problems, such as bipartite crossing minimization or the betweenness problem, which includes linear arrangement. These problems have important applications in, e.g., automatic graph drawing and computational biology. We present a new polyhedral approach to the quadratic linear ordering problem that is based on a linearization of the quadratic objective function. Our main result is a reformulation of the 3-dicycle inequalities using quadratic terms, the resulting constraints are shown to be face-inducing for the polytope corresponding to the unconstrained quadratic problem. We exploit this result both within a branch-and-cut algorithm and within an SDP-based branch-and-bound algorithm. Experimental results for bipartite crossing minimization show that this approach clearly outperforms other methods.\r\n\r\n(Joint work with Angelika Wiegele and Lanbo Zheng.)", :title "Exact Algorithms for the Quadratic Linear Ordering Problem", :keyword2 81, :authors (14917), :session 172}, 505 {:keyword1 59, :keyword3 57, :abstract "There is a useful connection between vibrations damping and combinatorial optimization. When energy source of an oscillator is cut, its amplitude reduced and gently converges to zero, because energy is dissipated by friction and other resistances. A detailed analogy with vibrations damping in mechanical vibration provides a framework for optimization (finding the minimum of a given objective function) of properties of very large and complex systems. In this article we briefly review the central constructs in combinatorial optimization and vibration damping and then develop the similarities between the two fields. Finally To test the power of vibration damping optimization (VDO) algorithm, we used the algorithm on traveling salesman problems (TSP) with as many as several cities.", :title "Vibration Damping Optimization", :keyword2 8, :authors (805), :session 16}, 506 {:keyword1 99, :keyword3 0, :abstract "In this talk we try to identify the performance behavior of stochastic networks based on external observations of the customers.\r\n\r\nWe consider open networks of queues with random routing. At each node we observe the external input process and the external departure process of customers which constitute general point processes. Our aim is to estimate the densities of the service time distributions at the nodes. Our approach relies on spectral analysis methods for point processes and uses periodogram-based nonparametric estimators. We show consistency and asymptotic normality for our estimators.", :title "Nonparametric inference for networks of queues", :keyword2 88, :authors (17137), :session 132}, 507 {:keyword1 40, :keyword3 18, :abstract "Weighted simple games are probably the most important subclass of simple games. It is well known that every simple game can be represented as intersection of weighted games. It nevertheless becomes of interest to ask how efficiently this can be done for a given simple game. The concept of dimension is based on the fact each simple game can be expressed as a finite intersection of weighted simple games. The question of efficiency leads to the definition of dimension.\r\n\r\nGiven a particular subclass of simple games, we firstly study whether it is possible to express every simple game as an intersection of games in that subclass. We make an exhaustive study for significant subclasses of simple games like e.g.: homogeneous, linear, weakly linear, strong or proper games. By duality we extend this concept of dimension to that of codimension, which allows to efficiently expressing a simple game as union of games.\r\n\r\nWe secondly investigate the existence of minimal subclasses of weighted games for which every simple game can be expressed as the intersection of games belonging to the subclass. We prove that, in fact, there exists a minimum subclass with such a property, which leads us to introduce a fundamental new concept of dimension.  A further generalization is also obtained by considering the union instead of the intersection as the main operation.  \r\n\r\nThe results we will present emphasize the extent to which the study of the dimension constitutes a bridge between the theory of simple games and hypergraphs and other theories related to operational research like: reliability, artificial intelligence and decision support systems.\r\n", :title "A minimum dimensional class for simple games", :keyword2 89, :authors (17044 11762), :session 181}, 508 {:keyword1 8, :keyword3 81, :abstract "In many practical applications, the task is to optimize a non-linear\r\nfunction over a well-studied polytope P as, e.g., the matching\r\npolytope or the travelling salesman polytope (TSP). In this talk, we\r\nfocus on quadratic objective functions.  Prominent examples are the\r\nquadratic assignment and the quadratic knapsack problem; further\r\napplications occur in various areas such as production planning or\r\nautomatic graph drawing.  In order to apply branch-and-cut methods for\r\nthe exact solution of such problems, they have to be\r\nlinearized. However, the standard linearization usually leads to very\r\nweak relaxations. On the other hand, problem-specific polyhedral\r\nstudies are often time-consuming.  Our goal is the design of general\r\nseparation routines that can replace detailed polyhedral studies of\r\nthe resulting polytope and that can be used as a black box.  As\r\nunconstrained binary quadratic optimization is equivalent to the\r\nmaximum cut problem, knowledge about cut polytopes can be used in our\r\nsetting. Other separation routines are inspired by the local cuts that\r\nhave been developed by Applegate, Bixby, Chv\\'atal and Cook for faster\r\nsolution of large-scale traveling salesman instances.  By extensive\r\nexperiments, we show that both methods can drastically accelerate the\r\nsolution of constrained quadratic 0/1 problems.", :title "Speeding up General Solution Algorithms for Binary Quadratic Problems", :keyword2 57, :authors (14713 14917 15058), :session 172}, 510 {:keyword1 100, :keyword3 40, :abstract "Expectation formation of economic agents plays a crucial role for the way we can\r\nunderstand how forecasts are made and markets work. Experimental studies on expectations are limited to stable environments. Independently of the focus of those studies,\r\ni.e. whether rigid time series are forecasted or the subjects interact in a market and\r\nthe realizations depend on their forecasts, the data generating processes and market\r\nreaction functions respectively are stable in most studies. Since most time series and\r\nmarkets often are subject to structural breaks and regime shifts this limitation is unrealistic. We plan to explain individual and average behavior in experimental environments\r\nwhich are affected by structural changes.\r\n", :title "Behaviour in Unstable Environments", :keyword2 19, :authors (281), :session 190}, 511 {:keyword1 23, :keyword3 42, :abstract "The paper deals with modeling and simulation of dynamic value networks – complex systems of stand-alone business entities that bond together, more or less tightly, through exchange of goods, services, and money. Value networks exhibit a complex dynamic behavior, which results from superposition of two distinct mechanisms – formation of a network out of available components, and changes in performance of individual components over time. \r\n\r\nThe strategic control of a value network is exercised primarily through selection of the core, value-added competencies that the enterprise either has access to or can develop in a certain time. Optimum selection requires quantitative understanding of how quickly the critical competencies can be developed and how these competencies affect a \"`bonding potential\"' of the respective business components within the network (i.e., how attractive these components are to potential suppliers, buyers and partners). Having an operational model of the value network behavior, with the capability to predict the changes in the network configuration as a result of the changes in the individual node performance, is thus a crucial prerequisite for effective management of the network performance.\r\n\r\nWe propose a stochastic model of the dynamic behavior of a value network, which combines Ulf Grenander’s general pattern theory with stochastic extension of Jay Forrester’s system dynamics to model a network configuration and individual node performance, respectively. The model is generic enough to cover value networks in diverse industries. We explore – and illustrate with several practical examples – how  the definition of local \"`energies\"' associated with individual bonds affect the simulated network behavior.", :title "Modeling and Simulation of Dynamic Value Networks", :keyword2 99, :authors (), :session 155}, 513 {:keyword1 40, :keyword3 0, :abstract "The cost-sharing problem is widespread. Production companies distribute overhead costs to different departments and products. Passenger transport companies set ticket prices. A group of customers allocates the charges to each one of them for using or building a common infrastructure. These are just some of many examples of cost-sharing problem. The central question is how to distribute the cost? The cost allocation should be fair so that all parties can agree with. An other important issue is that it should be stable against the changes of the cost function. \r\n\r\nFrom the mathematical point of view, the cost-sharing problem is a kind of game, in which the common cost is allocated to the players, where the cost function is implicitly given by a mixed integer program. Using tools from cooperative game theory, like f-nucleolus and some new variations, we can formulate it as the problem of successively solving some small number of linear programs. Each linear program has an exponential number of constraints in the number of players and the cost function as coefficients. In this way we can compute fair ticket prices in public transport, where all passengers of an OD-pair is considered as a player. As application we consider the Dutch IC railway network. This network has 23 stations. There are 2 to the power 253 possible coalitions of players. The problem is NP-hard and the LPs cannot be explicitly written down. Using constraints generation method we can overcome this difficulty.", :title "Cost-sharing problem: Fair ticket price in public transport", :keyword2 77, :authors (16972 14923 10996), :session 192}, 514 {:keyword1 93, :keyword3 19, :abstract "Der Risikobegriff wird in der Betriebswirtschaftslehre durch die betrieblichen Funktionsbereiche und Branchen bestimmt. Entsprechend der Risikosichtweise werden unterschiedliche betriebswirtschaftliche qualitative und quantitative Modelle angewendet, um das Risiko bei der Entscheidungsfindung zu identifizieren und zu quantifizieren. Die Erarbeitung von Modellklassen für Risikoidentifikation und -bewertung schafft eine wissenschaftlich fundierte Grundlage für eine geeignete Modellwahl im Rahmen der Entscheidungsfindung. Um diese Modellwahl zu treffen, werden in diesem Arbeitspapier die Modellklassen definiert und die Anforderungen an Modellklassen für Risikoidentifikation und -bewertung sowie die Entwicklung von Modellklassen diskutiert. Hierfür werden zunächst aufbauend auf der Definition von Modellklassen deren Zielsetzung, der Kontext und die Strukturgleichheit erörtert. Zum anderen werden die Vorgehensweise zur Entwicklung von Modellklassen und Ansätze für einen möglichen Modellierungsvergleich vorgestellt.\r\n\r\n\r\nLiteratur:\r\n\r\nBamberg G, Coenenberg AG (2002) Betriebliche Entscheidungslehre. 11 Aufl. Vahlen, München\r\n\r\nRosenkranz F, Mißler-Behr M (2005) Unternehmensrisiken erkennen und managen: Einführung in die quantitative Planung. Springer, Berlin Heidelberg New York\r\n\r\nSchütte R (1998) Grundsätze ordnungsmäßiger Referenzmodellierung: Konstruktion konfigurations- und anpassungsorientierter Modelle. Gabler, Wiesbaden\r\n\r\nStrahringer S (1996) Metamodellierung als Instrument des Methodenvergleichs. Shaker, Aachen\r\n\r\nZschocke D (1995) Modellbildung in der Ökonomie: Modelle-Information-Sprache. Vahlen, München\r\n", :title "Entwicklung von Modellklassen für Risikoidentifikation und -bewertung", :keyword2 100, :authors (17111 16898), :session 106}, 515 {:keyword1 77, :keyword3 95, :abstract "One of the most significant measures for costs in rail freight transportation is the number of train kilometers, that is, the number of trains times the distance they travel. In order to reduce the number of train kilometers, the aim is to find routes for the cars through the network from their origin via possibly visited intermediate shunting yards to their destination, such that the cars travel as a bundle and the utilization of the trains is as high as possible. We present a new model for this car routing problem arising at Deutsche Bahn AG. The model is based on a multi-commodity min-cost flow formulation. It is a variant of the well studied blocking problem. However, several new aspects have to be additionally taken into account which reflect today's operation of the German railroad system. Among them are constraints on the structure of the paths of the cars as well as several different types of capacity constraints. The model is formulated as an integer programming problem. Solutions are obtained using commercial standard software and promising computational results for several instances are presented.\r\n", :title "Routing cars in rail freight service", :keyword2 106, :authors (17138 16315), :session 71}, 516 {:keyword1 17, :keyword3 0, :abstract "Data Envelopment Analysis (DEA) is a generally accepted methodology for efficiency measurement with numerous applications in the service sector. However within these applications an important characteristic of service productions is often neglected: the integration of the customer in the production process. This presentation discusses a DEA based methodology which especially takes into account the customer’s influence on production.\r\n\r\nFrom the service provider’s point of view the customer can be seen as an external stochastic factor which is not under the producer’s control but may have significant influence on the production process. In order to ensure fair performance evaluation of the decision making units (DMUs) this uncertainty in production should explicitly be considered in efficiency measurement. For example one can imagine that a consultant requires varying consulting time for selling the same insurance to different customers. The reason could be the different needs for counseling of the customers. This means that for different customers i.e. service productions the producer needs different amounts of input to produce the same amount of output which - in part - is attributable to the external factor.\r\n\r\nThus we cannot describe a DMU by a single observation of input output data. We rather describe the DMU by a sample of observations or by the underlying empirical distribution of the input output data. To consider these data in DEA we introduce chance constraints in DEA models. We then construct an efficiency function for each DMU which is the basis for an aggregated efficiency measure.", :title "A Data Envelopment Analysis approach for service productions under uncertainty", :keyword2 0, :authors (), :session 141}, 517 {:keyword1 75, :keyword3 0, :abstract "Production processes in the Iron and Steel Industry are characterized by order driven manufacturing. Due to hundreds of possible alloys and surface treatments as well as arbitrary product dimensions the planning situation is highly complex. \r\nTo face complexity, orders are coded after acceptance. In this, there are decision rules which assign one specific set of production parameters regarding the whole chain of production to a specific customer order. Production plans are generated based on coded production orders.\r\nOn the other hand the technical production system comprises degrees of freedom in the manufacturing process. Since material can be reformed with and without cutting waste, it is possible to satisfy a specific customer order with a set of different materials, resp. production orders.\r\nUsing static order coding, available degrees of freedom in the production system are not considered, which leads to inefficiencies in the manufacturing process. In our contribution we provide a framework to determine the range of possible production orders based on technical possibilities and restrictions. Furthermore we introduce a concept to embed variable production orders to sequence planning and master production planning.\r\n", :title "Modelling Order Based Production Alternatives in the Iron and Steel Industry", :keyword2 0, :authors (17130 2651 13503), :session 133}, 518 {:keyword1 98, :keyword3 0, :abstract "An evaluation framework to systematically prepare comparative reviews of statistical software packages is developed. The process model uses a hierarchy of reference requirements to structure the complex of \"`statistical models and methods.\"' The requirements for five of these methods (i.e., Linear Regression, Analysis of Variance, Classification and Regression Trees, Feedforward Artificial Neural Networks and Cluster Analysis) are specified in detail. At first the hierarchy of requirements is refined top-down. For this purpose the methods are presented by means of the original literature. In a second step the requirements are validated and completed bottom-up on the basis of the software and manuals to be evaluated.\r\n\r\nThree commercial statistical software packages (SPSS 15.0.1, STATISTICA 7.1 and S-PLUS 8), two commercial data mining programs (Clementine 11.1 and Insightful Miner 8) and two open source programs (R 2.6.2 and RapidMiner 4.0) are evaluated to demonstrate the usefulness of the framework. In means of aggregated score profiles R 2.6.2 and STATISTICA 7.1 outperform the others, mainly because they cover a wide spectrum of flexible algorithms.", :title "A Comparative Review of Software to Support Statistical Data Analysis", :keyword2 0, :authors (17077), :session 96}, 519 {:keyword1 93, :keyword3 97, :abstract "The fortunes of individual firms are linked together via similar economic and industry-specific conditions. As a result, the financial defaults of firms are often correlated and cluster in time. The bulk of research in the finance literature has investigated positive default correlation between firms, i.e., the likelihood of a firm’s default increases after defaults of other firms. This paper studies the opposite phenomenon, namely negative default correlation between two firms. This means that if one firm defaults, the other firm may have a lower probability of defaulting, thus benefiting from the other firm’s default. Based on empirical data from automotive suppliers, we demonstrate that negative default dependencies between suppliers may often exist and that these can have significant consequences for the buying firm. We use copula functions, a method of representing joint distribution functions with particular marginals, to capture the default dependency between automotive suppliers and simulate various negative default dependency scenarios. We also conduct a comparative static analysis illustrating the significant impact of negative default correlation in the automotive supplier industry. Our findings should spur managers to analyze their supplier portfolios with respect to default dependencies, and to take this phenomenon into consideration when making sourcing decisions.", :title "Negative default dependencies: Do automotive suppliers benefit from their competitors' default?", :keyword2 101, :authors (17140 14813 14709), :session 119}, 524 {:keyword1 96, :keyword3 5, :abstract "Shop scheduling, such as flow shop, hybrid flow shop, job shop, and open shop, have received increasing attention from researches. In recent years, a multi-objective model for flow shop, hybrid flow shop, or job shop scheduling is considered as a new trend in the literature. Up to now, there is no study considering a multi-objective open shop scheduling problem. Motivated by the above considerations, this paper considers an open job shop scheduling problem that minimizes bi-objectives, namely total flow time and weighted tardiness. Due to its complexity, this problem is ranked in the class of NP-hard ones. In this case, traditional approaches cannot reach to an optimal solution in a reasonable time. Thus, we propose a modified well-known and efficient meta-heuristic method, called particle swarm optimization (PSO), in order to solve the given problem. Finally, we compare our computational results with a well-known multi-objective genetic algorithm, namely NSGA II. The outputs show the encouraging results in the form of the solution quality.", :title "A Multi-Objective Particle Swarm Optimization for an Open shop Scheduling Problem Minimizing the Total Flow Time and Weighted Tardiness", :keyword2 59, :authors (17084 2229 805), :session 59}, 525 {:keyword1 120, :keyword3 5, :abstract "Data mining algorithms are widely used in variety of industries to provide information from the valuable data. The increasing need of customer information, in a multi actor environment, results in a rapid increase in the perceived value of data mining. This paper will elicit information about the main data mining process and represent a data mining application in the Service Sector. The customer data consists of customer attributes and their loyalty indices, which will give us a path of customer attributes to the loyalty level. The analytical tool selected for this data mining application is decision trees, which is commonly used in both academic and industrial purposes for classification and profiling analysis. Integration of customer data collected in the company and customer surveys allow the analysis of loyalty trends. This study aims to construct a framework for the development of an expert system that will predict the possibility of loyalty for each subscription as an aid for customer services", :title "Loyalty Prediction through Decision Tree Analysis", :keyword2 52, :authors (13767), :session 157}, 526 {:keyword1 54, :keyword3 33, :abstract " Manufacturers need to satisfy consumer demands in order to compete in a real world. This requires locating production plants or warehouses to deliver goods or products to final costumers in order to meet an efficient performance of a supply chain network. Substantial numbers of exact and heuristic solution methods are proposed for solving facility location problems. In this paper, a multi-objective dynamic multi-commodity capacitated facility location problem is considered. This hybrid mathematical model simultaneously minimizes a conditional value-at-risk (CVaR) measure and cost function of a location-allocation problem is developed and extended. Furthermore, other aspects of a location-allocation problem (i.e., multi-period, multi-product, capacity, inventory, and reverse logistic network) are included in the proposed mathematical model. In general, this proposed model allows periodical interaction between logistic elements, such as producers, distribution centers, warehouses, and customers known as facilities. This interaction provides the optimal efficiency for a spatial network in order to minimize the related costs with respect to underlying criteria. On the other hand, the model is to find the minimum CVaR measure allowing for more detailed risk aversion modeling. We believe that solving simultaneously the CVaR measure with other location allocation objectives provides a promising approach to multi-objective location problems. Finally, through an illustrative example, we offer insights on the output of the model and the way it can be implemented to solve the hybrid problem. The computational results obtained from the proposed model demonstrate that the interactions between facility efficiencies may be substantial in some cases.", :title "A Mathematical Model for a Multi-Objective Dynamic Multi-Commodity Capacitated Facility Location Problem with CVaR Criterion", :keyword2 63, :authors (17108 805 17084), :session 206}, 527 {:keyword1 18, :keyword3 0, :abstract "Energiehändler nutzen eine zentrale Marktdatenbank auf Basis des Data-Warehouse-Konzepts, die ihnen den Zugriff auf unterschiedliche Zeitreihen und Terminkurven über verschiedene Dimensionen ermöglicht. Die stetig wachsende Anzahl der in der Datenbasis verfügbaren Datenobjekte sowie zusätzliche fachliche Erweiterungen führen dazu, dass die ursprüngliche Struktur zur Beschreibung der Menge aller Datenobjekte den Anforderungen nicht mehr genügt. In der Arbeit wird ein konzeptioneller Lösungsansatz präsentiert, der die Komplexität des Datenmodells bei gleichzeitiger Beibehaltung der inhaltlichen Eigenschaften reduziert und dadurch Performanceverbesserungen realisiert, wie mit einer prototypischen Umsetzung gezeigt wird. Im Rahmen der vorgenommenen Modellierung wird zudem eine geeignete Metadatenhaltung vorgeschlagen, die den Usern des Systems neue Navigations- und Suchmöglichkeiten zur Verfügung stellt. Dazu werden unterschiedliche Möglichkeiten einer auf einer Ontologie basierenden Verschlagwortung gegenübergestellt und bewertet. ", :title "Ein konzeptioneller Ansatz zur Strukturierung von Marktdaten im Energiehandel", :keyword2 55, :authors (17148 15045), :session 107}, 529 {:keyword1 7, :keyword3 106, :abstract "Today, most transports in industrial practice are announced very late, so that carriers do not have leeway for optimization. However, it can be shown in a static environment that transport planning processes with delivery windows outperform those that follow the ABC approach. Nonetheless, existing methods still have deficits, especially regarding rolling horizons and uncertainty. Uncertainty exists in the amount of goods to be transported, which may differ significantly from the amounts announced earlier. Furthermore, unexpected truck downtime when picking up goods is a major cost driver. Practitioners have pointed out ways to cope with these circumstances. First, assessments can be made regarding the amount of goods to be transported. Besides the short-term calls, mid-term calls are available which are very reliable. Using that information, assumptions can be made on the likelihood of deviation. In addition to that, it is known that the amount of goods to be transported increases significantly towards the end of a month, thus creating a kind of seasonality. Waiting times at suppliers are known from the past for certain days of the week and certain times of day. To prevent specific tours from ending up in several highly frequented spots in a row, this experience can be used to create tours that minimize forecasted downtime variance. The development of a heuristic to solve this problem is ongoing work. The tabu search implementation of the general problem without consideration of uncertainty is already available and serves as a basis. The next step is to consider that most carriers rely on different kinds of subcontractors who offer different degrees of flexibility. This will be subject to further research and an outlook will be given.", :title "Milk run optimization with delivery windows and hedging against uncertainty", :keyword2 37, :authors (17008), :session 68}, 531 {:keyword1 97, :keyword3 0, :abstract "Empirical testing of random number generators includes goodness-of-fit tests with many numbers. Tests involve sorting and classification of the numbers. We study the effects of different sorting routines on the computation time of these tests of uniformity and propose improvements of the performance. \r\n\r\nMathematics Subject Classification (MSC 2000):\r\n62G10 Nonparametric hypothesis testing\r\n65C60 Computational problems in statistics\r\n65C10 Random number generation\r\n", :title "Sorting and goodness-of-fit tests of uniformity in random number generation", :keyword2 85, :authors (12902), :session 128}, 532 {:keyword1 42, :keyword3 106, :abstract "We consider the situation of a disturbed railway network. In case of disturbances, many decisions have to be made to find a disposition timetable which is feasible and minimizes the inconvenience for the passengers. The inconvenience of a passenger is measured as the delay he has when reaching his final destination. This delay can be approximated by a combination of the (properly weighted) number of missed connections and by the sum of all arrival delays of all trains.\r\n\r\nThe rolling stock circulations are usually determined in the strategic planning phase after the lines and the timetable have been fixed. In the delay management models discussed in the literature, the rolling stock circulations are always assumed to be fixed. We relax this assumption and allow changes in the vehicle schedules if they lead to a better disposition timetable. This might make sense when an (important) trip which has been assigned to a delayed train can be operated by another (punctual) train.\r\n\r\nWe present an integer programming model for the delay management problem integrating the rolling-stock-circulation decisions, investigate its complexity and suggest bounds and solution approaches.", :title "Integrating Rolling Stock Circulations into the Delay Management Problem", :keyword2 77, :authors (12935 1601 16975), :session 196}, 533 {:keyword1 35, :keyword3 0, :abstract "In Deutschland unterliegen Kursgewinne ab 2009 unabhängig von der Haltedauer einer einheitlichen Abgeltungssteuer in Höhe von 25\\% zzgl. Solidaritätszuschlag. Vor diesem Hintergrund stellt sich die Frage, wie diese persönliche Steuer bei der Unternehmensbewertung in die DCF Verfahren einbezogen werden können und welche Zusammenhänge zwischen den einzelnen Verfahren der Unternehmensbewertung in Abhängigkeit von der Finanzierungspolitik bestehen. \r\n\r\nIn der Literatur wird auf dieses Problem bislang nur unzureichend eingegangen. So wird in den Beiträgen von Langenkämper (2000), Dinstuhl (2002), Laitenberger (2003), Baetge/Niemeyer/Kümmel (2005), Braun (2005), Drukarczyk/Schüler (2007) der Zusammenhang zwischen den Kapitalkosten verschuldeter und unverschuldeter Unternehmen sowie den verschiedenen DCF Verfahren für die Regelungen des Halbeinküfteverfahrens untersucht, wobei Kursgewinnsteuern nicht berücksichtigt werden. Clubb/Doran (1992) bestimmen für eine wertabhängige Finanzierungspolitik den durchschnittlichen Kapitalkostensatz gemäß dem Free Cash Flow (FCF) Verfahren bei Zugrundelegung des Britischen Steuersystems unter Berücksichtigung von Kursgewinnsteuern. Die Autoren gehen allerdings vereinfachend und letztlich nicht zufriedenstellend davon aus, dass alle Änderungen des Marktwertes des Unternehmens mit Kursgewinnsteuern belastet werden. In der Literatur zur Analyse der Auswirkungen der deutschen Steuerreform 2008 auf die Unternehmensbewertung wird das Problem der Kursgewinnsteuern weitgehend ausgeklammert. Infolgedessen ist bislang ungeklärt, welchen Einfluss die die Einführung der Kursgewinnsteuer auf die Bewertungsformeln der DCF Verfahren haben. In dem vorliegenden Beitrag wird versucht, diese Lücke zu schließen.\r\n", :title "Unternehmensbewertung bei wertabhängiger und autonomer Finanzierung unter Berücksichtigung einer Kursgewinnsteuer", :keyword2 0, :authors (), :session 83}, 534 {:keyword1 44, :keyword3 0, :abstract "Although negotiation, in its various forms, occurs frequently and is used by everyone, generally the parties fail to reach agreements that maximize joint outcomes. In fact many agreements are suboptimal. Formally stated, negotiators often fail to reach Pareto optimal solutions when there is integrative potential that expand the pie and yield higher joint outcomes. \r\nNegotiation literature includes extensive research with different approaches that endeavour to identify the factors that affect negotiation process and outcomes. Framing of conflicts and power are two widely acknowledged factors. The literature has provided evidences that unequal power leads to suboptimal solutions and while powerful parties try to reach agreements that divides the resources proportional to their power, low power parties tend to resist agreements that reflect power imbalance. It was also found that while loss frame produces less cooperation, more demands, fewer concessions and more impasse, counterparts’ gain frame induces more concession and less demands especially in case of an own gain frame. However, experimental evidence on how frame conditions will affect  individual/mutual outcomes in power-asymetric negotiations is rare. \r\nIn this study, the effect of gain/loss frames on the allocation of resources and the integrativeness of agreements is examined. In order to investigate this issue, we conducted an experimental study. The experimental design manipulated negotiators’ frame (gain vs. loss) as between-subjects variable and power (high & low) as a within subject variable. Relying on the results, we are able to figure out  how negotiator frames affect individual/mutual outcomes when power is unequally distributed.\r\n\r\n", :title "The Effect of Framing and Power Imbalance on Negotiation Behaviors and Outcomes", :keyword2 19, :authors (17144 643), :session 106}, 535 {:keyword1 111, :keyword3 55, :abstract "Process Mining techniques allow for extracting information from event logs obtaining of Information Systems. One of the most important problems that Mining Process techniques seek to resolve is automatically induce an \"`As-is model\"' that best represents the actual execution of the business process. This paper proposes (1) a general model of the problem of induction of business processes represented as a Bayesian approximation problem, (2) the conditions of existence and uniqueness of optimal solutions, and (3) specification of a general method to numerically compute the solution.\r\n", :title "Process Mining and Bayesian Approximation of Business Processes", :keyword2 120, :authors (), :session 157}, 536 {:keyword1 77, :keyword3 0, :abstract "Establishing a consensus journal ranking is important for measuring the\r\noutcome of research activities.\r\nIn this paper we explore the possibility of deriving consensus rankings\r\nby solving consensus optimization problems, characterizing consensus\r\nrankings as suitable complete order relations minimizing average\r\nKemini-Snell distance to the individual rankings. This optimization\r\nproblem can be expressed as a binary programming problem which can\r\ntypically be solved reasonably efficiently.\r\n                          \r\nWe present consensus rankings derived from a subset of the Harzing\r\njournal quality list using the commercial mathematical programming\r\nsolver CPLEX. Furthermore, we compared the results to three open\r\nsource mixed integer linear programming solvers namely COIN-OR\r\nSYMPHONY, the GNU Linear Programming Kit (GLPK) and lp\\_solve.", :title "Deriving Consensus Rankings from Journal Ratings", :keyword2 0, :authors (16672), :session 98}, 537 {:keyword1 122, :keyword3 22, :abstract "The design and optimization of comfortable decision support systems becomes more and more important. One example of a global network environment is the CENETIX (Center for Network Innovation and Experimentation) of the NPS Monterey.\r\nWithin such a complex structure the use and adaptation of decision support instruments is highly recommanded.\r\nOne disadvantage of such complex systems is that they often consist of a large amount of heterogeneous single applications that are inefficiently integrated into the overall process. This happens as such processes tend to grow over time, caused by an increase of complexity and supplementary demands by users for further functionalities, which leads to demands of new applications that are added to the system and need not always be compatible to the legacy applications. This results in process inefficiencies such as breakings in the media chain, high coordination effort, redundancy and an inefficient handling of information as the processing time increases. In case of threat on a critical infrastructure element, a fast and flexible acquisition, processing, and allocation of information are crucial. Flexibility, fast adaptability, and high process efficiency are central characteristics of a Service Oriented Architecture (SOA) which qualifies it to be used in the context of OR analysis and decision support processes in order to protect optimally the critical infrastructure. This contribution gives an introduction in SOA as well as an overview of an integration of SOA-elements within the analysis of complex critical infrastructures. We combine an approach from an operational point of view together within a service-orientated framework within such a complex decision support process of an OR/MS-decision support analyst. ", :title "Network based decision support within CENETIX", :keyword2 18, :authors (4796 17151 17152), :session 102}, 538 {:keyword1 106, :keyword3 45, :abstract "In diesem Vortrag präsentieren wir die Auswirkungen verschiedener Wartestrategien auf die Antwortzeiten für den Notfalltransport von Patienten in das Krankenhaus.  \r\n\r\nEin Großteil der medizinischen Behandlungen erfolgt in Krankenhäusern, Ambulanzen und bei niedergelassenen Ärzten. Menschen, die medizinischer Betreuung bedürfen und aufgrund Ihres Zustandes eine qualifizierte Begleitung benötigen, werden mit  dem Rettungs- bzw. Krankentransportwagen von oder zur behandelnden Einrichtung transportiert; Diese Transporte werden in Österreich von gemeinnützigen Organisationen wie dem Roten Kreuz durchgeführt. \r\n\r\nDabei wird für die unterschiedlich dringlichen Transportaufträge die gleiche Flotte verwendet. Es sind in der Regel 80 \\% - 90 \\% der Transportaufträge im Voraus bekannt und können somit in einer a-priori Planung berücksichtigt werden.  Zusätzlich auftretende medizinische Notfälle sind nicht im Voraus bekannt und werden mit der gleichen Fahrzeugflotte abgewickelt.  Dadurch  wird der aktuelle  voraus geplante Transportplan gestört - es kommt zu spontanen Umplanungen. Wenn ein medizinischer Notfall auftritt, wird das nächstgelegene freie Fahrzeug, das für den regulären Patiententransport vorgesehen wäre, zu diesem Notfall geschickt. Danach wird das Restproblem für die bekannten Transportaufträge neu geplant. \r\n\r\nWir integrieren dynamische Wartestrategien in die Abwicklung der bekannten Transportaufträge. Durch die Anwendung dieser Strategien konnte unter Verwendung von Realdaten gezeigt werden, dass die Antwortzeit bei Notfällen reduziert werden kann. ", :title "Dynamische Wartestrategien bei kombinierter Planung regulärer Patiententransporte und Notfalltransporte", :keyword2 95, :authors (17150 2769), :session 51}, 539 {:keyword1 120, :keyword3 99, :abstract "Web usage mining involves using data mining techniques in the discovery of web navigation patterns from web log data. The idea is that the analysis of the sequence of web pages requested by users within a particular web site may provide a better understanding and prediction of users' behavior and may thus be used to improve the design of web sites. It has, however, been shown that traditional data mining algorithms may not be suited for the discovery of web usage patterns. An approach that has been used extensively views a particular web user's navigation pattern on a web site as a Markovian process. A limitation of this simple model is that it does not take into account differences in user preferences. To overcome this, a discrete latent variable setting has been suggested. More specifically, the finite mixture of Markov chains allows the clustering of individuals into different behavioral segments characterized by different patterns of change.In particular for this type of mixture models, the EM algorithm has become the standard iterative method to obtain ML estimates. However, despite its simplicity, this algorithm may present some problems. Besides being extremely slow in convergence, it can converge to local maxima or saddle points. Because the E-step of the EM algorithm has to go through all the observations, with massive data sets it may be intractable in terms of estimation time. This paper discusses and implements heuristics variants of the EM algorithm that alleviate the E-step and introduce stochastic jumps to avoid premature convergence to local optima.  In our web mining empirical application the variants of the Stochastic EM algorithm were those that have shown more promising results in particular for data sets with very large size.  \r\n\r\n", :title "EM-based algorithms for Web mining massive data sets", :keyword2 41, :authors (17147 17153), :session 96}, 540 {:keyword1 101, :keyword3 93, :abstract "Supply chain design and management has recently gained a lot of interest as the coordination of production-distribution systems plays critical role to obtain competitive advantage in global business environment. In this study, the design and operation of a supply chain (SC) consisting of several suppliers, distribution centers, customers, production plant, and the associated distribution systems is considered in a three-stage modeling framework. First, the possible suppliers are evaluated by using Analytic Hierarchy Process (AHP) to identify the most appropriate out sources, thus to scrutinize the long term strategic decisions of the firm. Then, a mathematical model is constructed with  the selected suppliers in the first step, and other decision variables such as the location of  warehouses to distribute finished products to customers, alternative transportation choices and their capacities from suppliers to manufacturer, and from manufacturer to customers. The output of the analytical model provides to determine the decision variables yield to minimize the total cost in supply chain while maximizing the profit. Finally, uncertainties and risk factors associated to the different design and operation options along the production-distribution activities of the firm are analyzed using Failure Mode and Effect Analysis (FMEA). Then, the first problem formulation is modified by considering the consequences of some improvements on the critical risk factors on the supply chain network, thus the final model is obtained.  The optimal solution of the modified model enables us to reach the best configuration of the supply chain network obtained by using a mixed integer programming technique.", :title "A Three–stage Model for the Design of Supply Chain Networks: Supplier Selection, Risk Analysis, and Optimization", :keyword2 57, :authors (4256), :session 116}, 541 {:keyword1 42, :keyword3 23, :abstract "We introduce the so-called class of multilayered games on networks. They are defined on time-discrete systems which are  considered to be finite. If we formulate the optimal control problems with infinite time horizon for such systems game theoretical aspects become more and more important. We introduce a certain graph theoretic structure to calculate the optimal behaviour.\r\n\r\nAlgorithms for determinig these optimal control strategies are presented. Furthermore we determine the optimal mean cost cycles which are closely related with the dynamical systems.\r\nWe conclude with two concrete examples in the field of multilayered games on special resource networks.", :title "Multilayered Network Games - Algorithms for Solving Discrete Optimal Control Problems - Theory and Examples", :keyword2 40, :authors (9694 4796), :session 192}, 542 {:keyword1 45, :keyword3 0, :abstract "Reforms initiated in the early nineties of the Russian health care system have been unsuccessful, leading to an under financed and disorganized system. However, until recently, health care reform has not been a federal policy priority. \r\nIn 2005, the Priority National Project - Health was designed and enacted for the years 2006-2007. After a description of the initial situation (an hybrid and ineffective health care system), this paper describes the measures in this project and evaluate some of the initial results. \r\nDespite dire needs, this project may only yield limited results. For example, the allocation of additional funds for improved salaries in the primary care sector and for hi-tech equipment seems to repeat past errors. Additionally, piecemeal increases in resources, channeled through a broken system, will not replace real reform, and will not solve issues of spacial inequalities in the delivery of health care in Russia. Possible paths for future reform will be presented as the conclusion to this presentation.", :title "Current Changes in the Russian Health Policy - Does Windfall Money Really Help?", :keyword2 0, :authors (17155), :session 94}, 543 {:keyword1 65, :keyword3 59, :abstract "The Diameter-Constrained Minimum Spanning Tree Problem looks for a minimum cost spanning tree, subjected to pre-defined constraints on the number of edges that can integrate the path between any pair of nodes.\r\nThis problem typically models network design applications where all vertices must communicate with each other at a minimum cost, while meeting a given quality requirement. Normally, the diameter constraint is imposed in order to limit the number of arcs between any pair of note, guarantying a certain level of service with respect to net performance. \r\nIn order to find optimal or near-optimal solutions to solve this problem, several kinds of heuristics were implemented. In the first place it was developed, the Nearest Neighbour Heuristics which follows the procedure suggested by Prim to generate a Minimum Spanning Tree, with an additional test for the edge inclusion. We found that better solutions can be obtained if this procedure is run n times, since it depends on the starting vertex. The other heuristics developed to solve the problem followed a strategy based on relations that can be established between this problem and the hop constrained minimum spanning tree. These procedures were also implemented with random elements. Instead of adding the best choice at any stage, the edge added is chosen randomly from the best p available edges.\r\nA genetic algorithm was also developed for this problem. For this kind of problem representing a solution for this algorithm is not natural. For that reason, we developed an expanded graph where each edge is a feasible path in the original network that satisfies the length restriction.\r\nIn this paper we intend to present the computational results obtained so far with the implementation of this heuristics.\r\n", :title "Heuristics for The Diameter-Constrained Minimum Spanning Tree Problem", :keyword2 42, :authors (16891), :session 195}, 544 {:keyword1 105, :keyword3 8, :abstract "Each semester, a university has to deal with three timetabling problems: Curriculum based course timetabling, exam timetabling, and post enrollment based timetabling.\r\n\r\nThe first problem consists of scheduling lectures in such a way that no two courses of a curriculum take place simultaneously, and that\r\nevery course gets assigned an appropriate room.  Exam timetabling is to evenly spread exams so that the students of all curricula have sufficient preparation times. The third problem deals with assigning all students to various small exercise groups. All these problems have a lot of practical side constraints, but even their most basic\r\nvariants are known to be NP-complete.\r\n\r\nWe present a new integer programming model for curriulum based timetabling, which can be extended to a model exam timetabling. With this model we are able to solve problem instances of the size of big universities (e.g., Berlin's technical university), with up to more than 4000 courses.  In contrast to previous approaches we decompose the problem, however, without losing any optimal solution. That is,\r\nour apporach is principally exact. A key to this decomposition is to add inequalities to the first stage formulation which ensure a feasible solution when solving the second stage. A polyhedral investigation leads to studying the partial transversal polytope for which we give a complete description of its facets. We report on\r\ncomputational experience from universities and from a well-known benchmark test set coming from the second international timetabling competition.\r\n", :title "Optimal University Course Timetabling", :keyword2 77, :authors (14969 17158), :session 175}, 545 {:keyword1 106, :keyword3 0, :abstract "With ever increasing rates of containerization and volume of container\r\ntransportation, the need for an efficient use of resources is\r\nobvious. In particular, producing good container stowage plans for\r\nhuge modern vessels is a non-trivial task. These plans describe the\r\nexact position on the ship at which each container will be loaded, and\r\npossibly re-stowed during the journey. In practice a host of\r\nconstraints has to be obeyed when placing a container, ranging from\r\nsafety considerations for hazardous materials, ship stability, and the\r\nneed for balancedly loading/unloading the vessel in each port with a\r\ngiven number of cranes. One goal is to have a quickest process in each\r\nharbor, but this is only part of the overall objective of maximizing\r\nrevenues from all transported containers.\r\n\r\nCurrent disposition software tools basically provide the planner with\r\na graphical representation of the vessel and its load along the\r\njourney, however, they cannot actively produce a decision suggestion.\r\nIn fact, an automated stowage planning is still considered entirely\r\nout of reach by planners.\r\n\r\nIn this talk, we divide the problem into a coarse and a fine planning\r\n(which reflects current practice), and present approaches for both\r\nstages. While the fine planning is rather straight forward (but needs\r\nto respect a lot of technical details), we emphasize the first stage\r\nfor which we propose models based on coloring problems on particular\r\ngraphs. We report on first experiments with real-world data from a\r\nmajor container line.\r\n\r\n", :title "Towards Optimal Stowage Plans for Huge Container Vessels", :keyword2 8, :authors (17134 14969), :session 58}, 546 {:keyword1 18, :keyword3 0, :abstract "This paper aims at the valuation of natural gas storage facilities. It enhances the model of (Boogert and De Jong 2006), by the additional consideration of future markets. Thereby Least Square Monte Carlo Simulations are used to determine the value of a storage facility, a methodology, first proposed by (Longstaff and Schwartz 2001) for the valuation of financial options. Beside the main technical restrictions like maximum withdrawal and injection capacities and working gas volume the derived valuation model considers the spot and future market for natural gas. For these purposes in a first step consistent spot and future prices are simulated combining the pricing models of (Weber 2007) and (Gibson and Schwartz 1990) on historical price data. In a second step the storage value is determined applying Least Squares Monte Carlo Simulation on the simulated prices and an exemplary German case study. \r\n\r\nReferences:\r\nBoogert, A. /De Jong, C. (2006). Gas storage valuation using a Monte Carlo method. London, School of \tEconomics, Mathematics and Statistics Birkbeck College Univ. of London.\r\nGibson, R. /Schwartz, E. S. (1990): Stochastic convenience yield and the pricing of oil contingent claims, in: In: The journal of finance: S.\r\nLongstaff, F. A. /Schwartz, E. S. (2001): Valuing American options by simulation: A simple least-squares approach, in: REVIEW OF FINANCIAL STUDIES 14(1): S. 113-147.\r\nWeber, C. (2007): Strompreismodellierung - Berücksichtigung empirischer Verteilungen für nicht-speicherbare Güter am Beispiel Elektrizität, in: Essener Unikate 29(1): S. 92-101.\r\n\r\n\r\n", :title "Gas storage valuation via Least Squares Monte Carlo Regression including future markets", :keyword2 68, :authors (14838 14845 17005), :session 130}, 548 {:keyword1 86, :keyword3 0, :abstract "PERT Network has been well-known as a famous tool in analyzing a completion time of project. PERT is analyzed with deterministic processing time, but usually the processing times are fluctuated under such changes in circumstance as machine failure, procurement of resource, weather and so on. \r\nIn Hagstrom(1990), the processing times are assumed to be stochastic and mutually independent, and he proposes an algorithm for computing exact distributions. In his algorithm, we compute the longest project time distribution until the next node recursively under the condition that the longest project times are given to nodes in some subset of all nodes. In this case, as the number of processes increases, the computation times increase rapidly.\r\nIn this paper, we assume that the arrow diagram is separable, that is, the set of processes are divided into several subsets, whose are connected with precedence constraints, and we propose an algorithm for deriving an exact project time distribution in this type of PERT network. First we compute the exact project time distribution for each subset of processes, by using Hagstrom's algorithm, and then by using the results we derive the exact overall project time distribution. Numerical examples show that the computation times in the proposed algorithm are much smaller than those in original Hagstrom’s algotithm.\r\n", :title "An Efficient Algorithm for an Exact Project Completion Time Distribution in a Stochastic PERT Network", :keyword2 99, :authors (17159 17163), :session 56}, 550 {:keyword1 23, :keyword3 59, :abstract "Transportation planning in realistic scenarios has to deal with a dynamic uncertain environment. The actual state of all planning relevant information can be estimated and be the base of a static planning environment, which is often the base for classic planning algorithms. If the environment differs from the one used for planning, either by a wrong estimation or due to the dynamic in the environment the actual plan has to be adapted. This is an actual research subject. Different technologies like agents or metaheuristics and their possible integration are in the discussion [1]. It is often argued that multiagent systems can be fruitful in more dynamic environments. It is still an open question how this dynamic can be measured effectively and to what degree of dynamism classical approaches are competitive, if the assumption mentioned above is true, at all.\r\nIn our current research we empirically compare a classical tour planning algorithm, namely tabu-search, with a multiagent system to find preliminary answers to the previously introduced research question. We choose the well-known problem instances of the MDVRPTW, which is a complex transportation problem. This problem class allows a lot of different changes in the planning environment, and thus allows a more general discussion of metrics for dynamics as a common approach, only adding new customers. In our work we are going to discuss evaluation metrics, which is omitted here for the lack of space, present, and discuss solutions by both approaches and their adequacy depending on the degree of dynamic in a given environment.\r\n\r\n1.Langer, H., et al. Integration von Software-Agenten und Soft-Computing-Methoden für die Transportplanung. in 9 Sym. Softwareagenten und Soft Computing. 2006 Ilmenau\r\n", :title "Transportation planning in dynamic environments", :keyword2 106, :authors (17165 17186), :session 51}, 551 {:keyword1 6, :keyword3 106, :abstract "We consider an iterative combinatorial auction of slots to run trains through a railway network. In contrast to the classical setting, slots can mutually exclude or require each other, such that AND and XOR-constraints on bundles of bids arise. This turns the winner determination problem into a complex discrete optimization problem. It also raises a number of auction design questions, in particular, on bounding the number of rounds or bids. We propose a multi-round vickrey auction for railway slots. It can be shown that in this auction, truthful bidding is a dominant strategy and produces efficient allocations, even in the presence of constraints on allocations. These properties are, however, lost when constraints on the submission of bids such as, e.g., lowest bids, are imposed.\r\n\r\n", :title "Vickrey Auctions for Railway Tracks", :keyword2 8, :authors (14771 14923), :session 46}, 552 {:keyword1 101, :keyword3 0, :abstract "We study the supply chain execution of a spare parts inventory system that consists of multiple demand classes and multiple stock locations in the geographical region. The orders in the higher priority class need to be satisfied within a smaller service deadline (i.e. service lead time), whereas the service deadlines for other demand classes increase according to their priority class. Demand order arrives as a single unit and for a specific priority class, it can be served from any stock location that is within the given service deadline for that specific demand class. The spare parts at all stock locations are being maintained according to a (R, s, S) policy. In such a situation we devise a dynamic rationing policy for supply chain execution.  The rationing policy is devised by following the concept of quantity based revenue management (i.e. dynamic programming formulation of multi-period model) with additional considerations of multiple geographically dispersed stock locations and continuous stock replenishment. The research is motivated by the spare parts service system of a major computer equipment manufacturer that faces multiple demand classes for their spare parts logistics system. ", :title "A Stock Rationing Policy for the Spare Parts Supply Chain Execution with Multiple Stock Locations and Multiple Demand Classes.", :keyword2 91, :authors (1024 4229), :session 117}, 553 {:keyword1 23, :keyword3 94, :abstract "The recent turmoil in financial markets following the subprime crisis has shown that today’s international integrated financial markets are probably efficient, yet that they tend to react violently to false parameter assumptions (e.g. default probability of debt obligations). The concept of robustness, as developed in mathematical and engineering control theory during the last decades (e.g. Zhou and Doyle, 1998) may provide an interesting generalizing interpretation here. Control theory has shown that there is always a trade-off between the sensitivity of a control system and its robustness (cf. e.g. Safonov, 1981, Doyle et al., 1988). The sensitivity of the system describes its reactions to disturbance signals. The lower the integral loss function over the so-called transfer or sensitivity function, the less a system is affected by disturbances such as demand fluctuations, and the more efficient is the control. The economic equivalent clearly is the maximisation of welfare, which results in an efficient economic system. And a well-designed financial market is expected to provide an efficient control system for capital allocation.\r\nRobustness by contrast is defined as stability of the control system in the presence of model uncertainty (deviations in the model parameters like default probabilities). So if the analogy holds, ascertaining that capital markets provide efficient, i.e. welfare-optimal solutions, implies that markets must have limitations with respect to robustness. This general concept is illustrated using a rather aggregated dynamic sectoral growth model for industrial production and capital allocation. \r\nThis approach goes beyond the concepts of robust portfolio optimization given that the system level is considered instead of individual portfolios.\r\n", :title "Efficiency vs. robustness of markets - Insights from control theory", :keyword2 35, :authors (14845), :session 87}, 554 {:keyword1 28, :keyword3 99, :abstract "Limited liquidity is a key restriction for portfolio optimization in most electricity markets. Hence, standard models for decision problems have to be adapted to cope with this situation. This paper shows an approach dealing with this situation by including a liquidity function into the standard mean-variance model going back to Markowitz. This leads to a stochastic quadratic optimization problem.\r\nThe main purpose of the paper is to address simultaneously trading in spot and future markets. The model determines the optimal relation of quantities traded in the spot- and in the futures markets. Here the spot markets are taken to be more liquid than the futures markets but also more volatile. The time discretization is monthly for the futures trading volumes. The spot market quantity indicates the volume for the whole delivery period regarded in the model. The appropriate choice of the parameters for this kind of models is crucial. The paper shows possibilities to determine the parameters for liquidity, risk and the covariances.\r\nAn application of the model is done for the optimal hedging strategy for power generators. For this, the case of base electricity for delivery in 2008 on the German power exchange EEX is considered. Thereby different generation technologies and different portfolio sizes are regarded.\r\n", :title "Optimal hedging strategies under limited liquidity in electricity markets", :keyword2 68, :authors (14799 14845), :session 87}, 556 {:keyword1 37, :keyword3 0, :abstract "Neural networks (NN) have received increasing attention in time series forecasting, with over 5000 ISI referenced publications in computer science, engineering and management. Of the most encouraging results in Management Science, the studies by Tang and Fishwick (1991, 1993), Faraway und Chatfield (1995, 1998), and Hill, O’Connor et al. (1994, 1996) are among the most highly cited. Despite their valid and reliable experimental design, analysing the conditions under which NN perform well against established statistical benchmarks, their optimistic results regarding the performance of NN were not confirmed by other authors using similar NN architectures on similar data. Consequently, research has indicated ambiguous results on the forecasting performance of NN. This raises doubt whether the original experiments can be replicated, and whether the performance can be attributed to the NN, the dataset, the methodology employed or the skills of their modellers.\r\n\r\nDespite a consensus among researchers that replication studies are vital in advancing scientific knowledge, replications in forecasting are rare. As a consequence we attempt to replicate the results of highly influential papers on NN forecasting, in order to evaluate their validity and reliability as well as progress in modelling NN over the past 20 years. As many of the modelling choices explicitly or implicitly made by the authors were not documented sufficiently to allow replication, we extend the replication to explore the sensitivity of the modelling choices made by the authors. While we confirm findings that NN provide a competitive approach to forecasting on a given dataset, we identify methodological problems from the random weight initialisations that may prohibit replications of NN studies in general.\r\n", :title "Challenges in replicating neural network studies – an enquiry into the effect of random initialisations for the replication of prominent empirical forecasting studies", :keyword2 32, :authors (6752), :session 182}, 558 {:keyword1 62, :keyword3 3, :abstract "The European Union (EU) is a geo-political and economic community covering a large portion of the European continent. To join the EU, a country must go through an extensive screening process and conform to a series of fairly demanding Copenhagen criteria established by the European Council. These criteria include political, economic and community standards. Each standard is comprised of the criteria tree. The screening process is intended to determine how well a candidate is prepared to join the EU. \r\nThis study presents a Multi-Criteria Decision Analysis (MCDA) model to be used to screen and evaluate eight countries identified by the European Commission as either \"`candidate\"' or \"`potential candidate\"'. Candidate countries which include Croatia, Macedonia and Turkey have already applied for a membership and are involved in negotiations. Potential candidates which include Albania, Bosnia and Herzegovina, Kosovo, Montenegro and Serbia are interested in a membership and are promised a prospect of the EU membership.\t\r\nDecision makers (DMs) are required to consider a vast amount of information concerning the objective and subjective criteria in their decision process. Soft SWOT is a MCDA model that captures the DMs’ beliefs through a series of intuitive and analytical methods such as the analytic hierarchy process (AHP) and strengths, weaknesses, opportunities, and threats (SWOT) analysis. A defuzzification method is used to obtain crisp values from the subjective judgments provided by multiple DMs. These crisp values are synthesized with Entropy and the theory of displaced ideal to assist the DMs in their screening process by plotting the candidate states in a four-zone SWOT graph and considering their Euclidean distance from the \"`ideal state.\"'", :title "A Soft Multi-Criteria Decision Model for Evaluating Candidate States to the European Union", :keyword2 39, :authors (13415 17164 1141), :session 98}, 560 {:keyword1 40, :keyword3 5, :abstract "We present a knowledge revision system through communication in multi-agent system from Fuzzy set theoretical point of view, \r\nand by which we show that all agents can agree on a truth degree of a sentence.\r\nThe agents have \r\nthe knowledge model associated with the Kripke semantics for the multi-modal logic {\\bf S5_n}.\r\nEach agent sends approximate information on Fuzzy sets associated with  membership functions \r\nunder agent's private information with accuracy to \\varepsilon.\r\nWe show that consensus on the Fuzzy sets among\r\nall agents\r\ncan still be guaranteed in the communication; \r\ni.e., all the Fuzzy sets associated with  membership functions under agent's private information are equal among the agents after long running communication.", :title "Agreement in Communication through Robust Messages", :keyword2 44, :authors (5988), :session 185}, 561 {:keyword1 106, :keyword3 105, :abstract "Periodic railway timetabling is \"`as hard as MIPLIB\"'. Despite considerable speed-ups of standard solvers, still the most powerful algorithms make use of problem-specific valid inequalities. In the past, there have been proposed several classes of valid inequalities, some of which had no effect in practical computations.\r\n\r\nWe provide one new class of valid inequalities. In contrast to the most popular valid inequalities, our new inequalities do not live in the first, but in the second Chvatal closure. Hereby, they are suited to prove infeasibility of an instance which has non-empty first Chvatal closure.\r\n\r\nFor another class of well-known inequalities, we establish that they are contained in arbitrarily high Chvatal closures. Hence, we give the first explicit proof that the Chvatal rank of periodic railway timetabling instances is not bounded by any instance-independent constant.", :title "Polyhedral Investigation of Periodic Railway Timetabling", :keyword2 8, :authors (17188), :session 46}, 562 {:keyword1 36, :keyword3 76, :abstract "An automotive plant consists of the body and paint shop, and the final assembly with product specific buffers of limited capacities in between.\r\n\r\nWe associate the periods of our planning horizon, typically weeks or months, with the stages and use a Dynamic Programming approach to find a cost-optimal solution for the production of P products on L production lines considering technical restrictions, labor legislation and in-plant agreements. To reduce its complexity we disaggregate our approach into several subproblems and focus on distributing the workload between the lines in the paint shop in a certain period given the product demands from the final assembly, the capacities of the production lines and the corresponding buffers.\r\n\r\nWe model the problem as a classical transportation problem where lines supply and products ask for production capacity; buffers have to be introduced as suppliers as well as demanders. Additionally we introduce suppliers to model the opening stocks and a dummy demander to balance the transportation problem.\r\n\r\nThe resulting transportation graph is rather sparse because transportation is restricted to only a few arcs representing production to fulfill demand and increase the buffer stock, unused line and buffer capacity as well as fulfilling next shift's demand from the buffer and storing inventory for future shifts. The arcs are valued with appropriate production and storage costs.\r\n\r\nBy introducing suppliers and demander appropiately we can consider an upper bound for the overall buffer capacity and achieve a classical transportation problem again. Its solution can be used as a part of a decision inside our Dynamic Programming approach which enables us to solve real-world instances in acceptable time and quality.", :title "Production Chain Planning in the Automotive Industry", :keyword2 42, :authors (5965), :session 147}, 568 {:keyword1 56, :keyword3 120, :abstract "In today’s competitive business environment, the ability to identify profitable customers, keep their loyalty at long term, and expand existing relationships are key competitive factors. Thus, Business Intelligence (BI) system is fast becoming a strategic differentiator for today’s leading organizations. It has been shown that the BI concept may contribute towards improving the quality of decision-making in an organization, better customer service, and some increase in customers’ loyalty. To meet these factors, companies across various industries have made Customer Relationship Management (CRM) one of the leading business strategies in order to integrating sales, marketing, and service. On the other hands, in the early 1980s, the concept of relationship management in marketing area increased its importance. Accurate evaluation of customer profitability and targeting the most profitable customers are critical elements for the success in marketing.  In this paper, we will discuss about different aspects of customer segmentation as one of important subsystems of business intelligence that it can help to meet CRM objectives will be discussed. These subsystems help to develop effective strategies for different customer clusters, improve marketing strategies for business, and increase market share and profitability. Therefore, customer segmentation in a strategically fashion may have an influential role on effective support for management decision making.", :title "Customer segmentation and its role in marketing decision support as a subsystem of business intelligence", :keyword2 18, :authors (17201 17206), :session 107}, 570 {:keyword1 106, :keyword3 0, :abstract "This presentation introduces a specific real-world variant of the well-known Dynamic Vehicle Routing Problem (DVRP). Due to the DVRP, goods have to be delivered under extreme time pressure because of their high perishability. Moreover, tour planning has to make particular effort in providing high quality service. Consequently, the minimization of service time, i.e., the time difference between request arrival and request delivery, has to be integrated into the objective function. Clearly, this applies to various applications in business such as managing the subsequent delivery of newspapers or real-time dispatching of repair men. This presentation proposes a new real-time approach for an efficient distribution of perishable goods. In order to handle incoming requests, a dynamic tour planning procedure is applied. In other words, in order to reduce service time, information about past requests is used. The forecasted demands are integrated into tour planning by the generation of artificial requests. Hence, vehicles are led to local areas where the occurrence of future requests is likely. The efficiency of the applied instruments is analyzed using computational experiments. These experiments base their analysis on a real-world situation where the subsequent deliveries of a German newspaper vendor are managed.", :title "Real-time distribution of perishable goods using past request information to forecast future demand", :keyword2 37, :authors (14856 14800 14792), :session 31}, 571 {:keyword1 16, :keyword3 0, :abstract "A tree search algorithm for the two-dimensional Strip Packing Problem (2D-SPP) is presented. The 2D-SPP requires packing a set of rectangles completely into a strip of given width such that the total length of the arrangement is minimized. A guillotine cutting constraint may be stipulated or not. A special variant of tree search is carried out, called partition-controlled tree search (PCTRS). This one makes the search both efficient and divers caring for a sufficient search width as well as for a suitable degree of foresight. Different basic packing heuristics are employed that are tailored to the guillotine case and to the non-guillotine-case, respectively. Excellent results were achieved, e.g., for the well-known Hopper and Turton instances in short computing times. ", :title "A Tree Search Algorithm for Solving the Two-Dimensional Strip Packing Problem", :keyword2 0, :authors (17204 6404), :session 24}, 572 {:keyword1 101, :keyword3 94, :abstract "We develop a multi-objective stochastic programming model for supply chain design under uncertainty, using interactive approaches. Demands, supplies, processing and transportation costs are all considered as the uncertain parameters, which will be revealed after building the sites at the strategic level. The decisions about the optimal flows are made at the tactical level depending upon the actual values of uncertain parameters. It is also assumed that the suppliers are unreliable with time-dependent distributions. The proposed model accounts for the minimization of both the expected total cost and the risk, reflected by the variance of the total cost and the downside risk or the risk of loss. Finally, different interactive multi-objective techniques with explicit or implicit trade-off information given such as SWT and STEM methods are used to solve the proposed multi-objective model.     ", :title "Interactive multi-objective stochastic programming approaches for designing robust supply chain networks", :keyword2 63, :authors (3974), :session 116}, 573 {:keyword1 93, :keyword3 0, :abstract "Extending the approach of Jouini et al. we define set-valued measures of risk and its acceptance sets. Using a new duality theory for set-valued convex functions we give dual representation theorems. Moreover, we introduce new examples for set-valued measures of risk using primal and dual descriptions.", :title "Set-valued measures of risk", :keyword2 0, :authors (6948 6896), :session 129}, 577 {:keyword1 11, :keyword3 106, :abstract "In this contribution we consider a real-life vehicle routing problem from the CEP market where one has to deal with uncertainties. Already its static version is hard to solve: It consists of serving pickups from or deliveries to customers with multiple depots, thereby respecting various constraints as vehicle capacity and suitability, multiple time windows of orders, availability of resources. The objective function is a weighted sum of different costs, including fixed costs for used vehicles, route lenght-, duration-, and load-dependent costs, and penalty costs for violated soft constraints. In the practical application one has to deal with uncertainties that appear in various forms: New orders arrive over the time and can be canceled again, customers to visit could not be met and so have to be revisited later, order quantities can change, what becomes known in advance or not until realisation. Not least the time schedule of the routes is subject to change due to uncertain service and travel times. Because of these a priori incomplete and uncertain information about the problem instance the process of creating route plans is a dynamic one: Existing plans permanently have to be adapted to the current situation and extended to cover added information. We describe this dynamic planning process, its modules and their interaction. The core of our approach consists of an algorithm component that provides algorithms for adapting and repairing plans in real-time as well as for creating new plans and permanently improving the current plan in use. The main idea of our algorithmic concept is to create robust plans, that are plans which can be easily adapted to new situations without loosing their solution quality. We describe our sampling-based algorithms used for this purpose.", :title "A Real-Life Vehicle Routing Problem under Uncertainty: Model, Planning Process, Algorithmic Aspects", :keyword2 18, :authors (17189), :session 31}, 578 {:keyword1 47, :keyword3 0, :abstract "This paper sheds some light on the role of human capital and tangible capital based measures in assessing the value of equity. Firm valuation in accounting research concentrates on the residual income (RI) model of Ohlson (1995), where market value of equity is driven by its book value and subsequent RI. By disaggregating RI into a value added component and a cost component one can assess the question, whether these components are also relevant for firm valuation. We disaggregate RI into the tangible capital based (VATC), the human capital based (VAHC) and the combined tangible and human capital based value added (VATH) as well as tangible capital costs (CCO) and human capital costs (PCO).\r\nThe resulting multiple regressions are applied to a sample containing Germany, France, United Kingdom, Italy, Switzerland and Netherlands over the time period of 1990 to 2006 with 1,645 firms and 8,319 observations. To consider the influence of the cost of equity we apply four definitions: (1) long term capital asset pricing model (CAPM), (2) short term CAPM, (3) risk free interest rate plus 5\\%, and (4) constant interest rate of 12\\%. Further, high intangible firms might show different results in the disaggregated valuation models in comparison to low intangible firms. Therefore, four different definitions of high and low intangible firms are applied, which are based on two different SIC code definitions, the market-to-book-ratio and the ratio of human capital to tangible capital costs.\r\nFindings show some significance for the disaggregated models VATC, VAHC and VATH; but the results are indeed influenced by country, time, definition of cost of equity and high vs. low intangible firms. The study delivers some evidence for the relevance of human capital information for firm valuation.", :title "Does Human Capital and/or Tangible Capital Matter in Firm Valuation? A Transnational Empirical Approach", :keyword2 50, :authors (14797 15003), :session 83}, 580 {:keyword1 50, :keyword3 0, :abstract "Intangible resources such as brands, customer relations, technology and human capital are becoming increasingly important for corporate competitiveness. Mergers \\& acquisitions (M\\&A) are one of the few mechanisms available to acquire these intangible resources. Both SFAS 141 published in 2001 and IFRS 3 published in 2004 changed the way in which M&As are reflected in financial statements. All business combinations have to be accounted for under the purchase method. The purchase price allocation provides one of the rare opportunities for recognizing intangible resources.\r\n\r\nThe purpose of this paper is to analyse how intangible resources are recognized in purchase price allocations. The sample consists of both the 51 biggest American and European M&As since the introduction of the new accounting standards. All sample companies reported detailed purchase price allocations. An in-depth analysis and evaluation of the notes to the financial statements is conducted: (1) the amounts assigned to tangible and intangible assets and goodwill are analysed. (2) We further investigate the type of intangibles disclosed, applied methods of valuation, determination of useful life and disclosure on goodwill. (3) It is explored which factors contribute to the recognition of intangible assets and goodwill.\r\n\r\nThe paper shows that the intangible assets including goodwill account for more than half of target’s total assets at fair value. M&As are mainly driven by customer-related, marketing-related and contract-based intangible assets. In contrast to their American counterparts European firms additionally attach importance to human capital. Results also indicate that accounting for intangible assets may be manipulated by acquiring firms and reliability of information disclosed is limited.", :title "Disclosure of intangibles in purchase price allocations - An explorative comparative empirical study of US-GAAP and IFRS M&A transactions", :keyword2 100, :authors (17207 15003), :session 88}, 582 {:keyword1 79, :keyword3 0, :abstract "A well discussed approach to duality in multiobjective programming is to assign to a vector optimization problem a set-valued dual problem, whose objective map is a hyperplane.\r\nHowever, if the dual problem itself is regarded as a new primal problem, it is not possible to achieve a satisfying (strong) duality assertion due to the fact, that the new primal problem is not convex. Additionally, its dual would be naturally set-valued and not vector-valued, as the original problem is.\r\nIn order to obtain symmetry in multicriteria duality theory we derive a vector-valued - and convex - optimization problem, called the \"`geometric dual\"', from the set-valued one and present a mapping that allows us to relate weakly efficient points of the dual image set to weakly efficient and exposed faces of the primal image set.\r\nTo this vector optimization problem a corresponding set-valued dual problem can be assigned. Again, the geometric dual of the dual problem and its relations\r\nto the primal problem can be studied. We show that this second geometric dual problem is closely related to the original vector optimization problem.\r\nWe motivate our results from the special case of the linear vector optimization problem with respect to any pointed and polyhedral convex ordering cone. Strong duality assertions are proven with the help of the Farkas Lemma and its direct conclusions, only. Properties of the coupling functions are pointed out. To generalize our results for a larger class of convex vector optimization problems, a variant of a\r\nFenchel-Rockafellar duality theorem for set-valued optimization problems is introduced.\r\n", :title "Symmetry in duality theory for vector optimization problems", :keyword2 14, :authors (), :session 140}, 584 {:keyword1 5, :keyword3 0, :abstract "The N.E.W. Corridor is at its starting phase. This is  a Northern East-West freight corridor that links China, Kazakhstan, Russia, Finland, Sweden and Norway to the East Coast of the United States first by train to Narvik port and then by ship. This implies an increased container traffic through Narvik in the short and middle terms which will prompt the purchase of a second quay crane as a prerequisite in tackling the new situation. An operational problem of how to schedule these two cranes arises and must be dealt with. In this paper, a methodology was developed for solving the problem of scheduling a two quay cranes with non-interference constraints. This is an application of the general framework proposed by Der-Horng Lee et al. (2006) where the NP-completeness of this problem was proved, thus the use of heuristics is appropriate. First, a mathematical formulation of the problem will be provided, and then a genetic algorithm (GA) approach will be adopted in order to obtain near optimal solutions. Finally, computational experiments on GAs with different features will be conducted to determine the best strategy. The main focus of this paper is to develop a user friendly tool that can solve this type of scheduling problem while giving the user some degree of freedom to experiment with parameters and obtain solutions in real time. The developed solution takes user-friendliness into account making it useful for operators at Narvik Container terminal.", :title "A Genetic Algorithm Approach for Quay Crane Scheduling with Non-interference Constraints in Narvik Container Terminal", :keyword2 0, :authors (17212 17210 17101), :session 73}, 585 {:keyword1 23, :keyword3 106, :abstract "Planning and control of logistic processes is more and more determined by an increasing complexity and dynamical behaviour of the underling production networks. Global supply chains and the atomisation of orders drive this development. In order to streamline logistic processes it is necessary to analyse the associated dynamic effects with respect to the stability of the whole network. However, in many aspects methods and tools for a comprehensive analysis of the dynamical behaviour of large-scale logistics networks are missing. Our research project aims to develop stability criteria for networks that are based on the concept of stability radius. The stability radius of a system reflects the magnitude of the smallest possible disturbance, which destabilises the system. A real-world logistics scenario of a pump set manufacturer motivates this approach. In order to analyse the stability of large-scale logistics networks it is essential to obtain networks of lower size, which can be handled. Therefore we propose to use capable approximation techniques that retain the structural properties of networks. In this talk we present a coordinated approach of two different approximation techniques to decide which components of the network need to be modelled in detail. On the one hand we use a ranking scheme to quantify the importance of the components. This is done by an extended ranking scheme that is based on the scheme used by Google. On the other hand different time scales are used to model the long-term behaviour of the fast dynamics of components. These time scales occur in a natural manner within the network. To assess the theoretical results we use a simulation model of the real-world scenario. \r\n", :title "Analysis of the dynamics of large-scale logistics networks", :keyword2 10, :authors (17143), :session 110}, 586 {:keyword1 54, :keyword3 14, :abstract "Die Bemessung des wirtschaftlichen Aufwands zur Herstellung von einer authentischen Information über einen logistischen Prozess kann kaum über die Informationsgehalt der entsprechenden Daten, mithin über die Entropie der Information, bemessen werden, sondern eher über den Energieaufwand zur Beschaffung der entsprechenden Daten, mithin über die Entropie im Prozessablauf. Insoweit erscheint die Entropie als Metrik für die Informationsbeschaffung hilfreich, aber unzulänglich als Metrik für alternative Entscheidungen über die Führung von betrieblichen Prozessen.\r\nEs wird ein neues relatives Entropiemaß eingeführt, in dem für eine Zielfunktion der jeweils einzusparende Energieeinsatz mit der Informationsentropie verknüpft wird. \r\nFür logistische Prozesse hat sich die Verfügbarkeit von Identitäten mit Hilfe von Kennzeichnungen allgemein durchgesetzt. Dabei werden sogar temporale Identitäten, die nur für einen Prozessabschnitt relevant sind, zusätzlich zu kardinalen Identitäten und ordinalen Identitäten sowie nominalen Identitäten und symbolischen Identitäten nebeneinander verwendet. Dazu ist die authentische Uhrzeit für eine Ereignisfeststellung kein Luxus, sondern allgemein verfügbar.\r\nFür eine ubiquitäre Ortsfeststellung und die verbundene Feststellung einer Transportrichtung gibt es die automatische Lokalisierung. Diese Option wird genau dann ohne personellen Mehraufwand verfügbar, wenn bestimmte Bedingungen erfüllt werden.\r\nJeder Zustand der Auftragserfüllung kann dann jederzeit mit diesem Vorgehen korrekt nach Identität, Ort und Zeit eingeschätzt werden. Damit erreicht die bisher weiche Rückkopplung unmittelbar aus dem Prozessgeschehen in die inner- und zwischenbetriebliche Auftragsplanung endlich die geforderte Qualität.\r\n", :title "Entropiereduktion in Planung und Durchsetzung von innerbetrieblichen Transporten durch automatische Ortsbestimmung RTLS", :keyword2 101, :authors (17170), :session 52}, 588 {:keyword1 17, :keyword3 19, :abstract "Data Envelopment Analysis (DEA) is a nonparametric methodology to measure the performance of organizations (decision making units, DMU). Each DMU is characterized by a set of inputs and outputs. DEA measures are originally not depending on a priori judgments of the valuation of inputs and outputs. Extended DEA models introduce additional restrictions, e.g. cone ratio models, assurance region approaches or virtual weight analysis. These models are based on the assumption that a decision maker defines bounds for the weights. This presentation demonstrates that in case of a stochastic DEA framework it is not necessary to assume a priori judgements. \r\n\r\nThus, this contribution discusses a DEA-based methodology that considers uncertainty in efficiency measurement. Instead of comparing one single observation for each DMU with the production possibilities we will use a sample of observations, which describes the production possibilities of the DMU itself. Using this information we are able to derive preference relations between inputs and outputs from observed production data. These implicit weight restrictions permit a differentiated performance measurement of DMUs.\r\n\r\n", :title "Revealed preferences in stochastic DEA", :keyword2 85, :authors (14890), :session 127}, 590 {:keyword1 31, :keyword3 0, :abstract "The drive for greener shipping is very high on the agenda of the International Maritime Organization (IMO), the European Commission and many individual coastal states. In particular, reduction of emissions, both from greenhouse gases (GHG), such as CO2, CH4 and others, and also from SO2 and NOx emissions, as well as others, is a goal that is clearly stated and very pressing. However, reductions in emissions may have ramifications as regards the logistical supply chain, as for instance measures such as speed reduction or others will generally entail costs, such as in-transit inventory and others (eg, more ships to carry the same cargo). Industry circles have also voiced the concern that low-sulphur fuel in SECAs (these are the so-called \"`sulphur emissions control areas\"' that exist in some parts of the world- eg. the Baltic or the North Sea) may make maritime transport (and in particular short-sea shipping) more expensive and induce shippers to use land-based alternatives (mainly road), even though shifting cargo from land to sea is a policy goal. A reverse shift of cargo from sea to land would ultimately increase the overall level of CO2 emissions along the intermodal chain.\r\nThis paper will take a look at tradeoffs that are at stake in the goal for greener shipping and present models that can be used to evaluate these tradeoffs.  Examples will be presented.\r\n", :title "Logistics - Emissions Trade-Offs in Maritime Transport", :keyword2 106, :authors (17213), :session 32}, 593 {:keyword1 56, :keyword3 0, :abstract "In current research literature involving product family of different quality levels, it is impossible to offer a niche product that target low end consumers and shut out high end consumers, due to the utility function employed assuming that low quality can always be compensated by low price and that high price can always be accepted if quality is sufficiently high. We use another commonly accepted utility function to represent the idea that consumers have a minimum threshold of acceptable quality, independent of price, and a maximum threshold of acceptable price, independent of quality. We discover that niche product targeting low end consumers is optimal under certain conditions. We also find that development intensive products can be differentiated at different quality levels, contrary to predictions from established models. In addition, our model explains the existence of \"`buffer consumers\"', a phenomenon observed in industry, but not explainable with existing models in literature. Finally the existence of functionality thresholds makes adding a low end version product much more attractive, by eliminating cannibalization. We discover that the key results are robust regardless of the cost structure. Other related issues such as, the impact of component commonality on product differentiation, the impact of functionality thresholds on introduction sequence, the impact of changes in cost and market parameters on portfolio are also investigated.", :title "The Impact of Functionality Thresholds on Market Segmentation and Product Differentiation", :keyword2 0, :authors (13649), :session 107}, 594 {:keyword1 31, :keyword3 0, :abstract "We will present a general optimization model which allows determining internal prices of materials and emissions. The model includes different types of environmental constraints and aspects. Besides taxation of emissions it considers emissions trading as well as environmental threshold values which might be related to products, machine times and input factors. Potential environmental damage is included through valuation coefficients as the outcome of different valuation methods. Within the model, different production and recycling activities can be chosen to yield a given output combination at minimum costs. Sensitivity analysis and parametric programming provide opportunities to identify abatement or penalty costs of emissions and cost surpluses for the use of materials. These results are applied to set up an internal pricing scheme for environmental impacts of production and recycling which fulfils the requirements of being correct and robust. Robustness is needed for stable pricing schemes even when the mix of products demanded by customers change significantly. The model’s implications on corporate decision making will be illustrated by some numerical results.", :title "Integration of environmental aspects of production and recycling into internal pricing", :keyword2 0, :authors (1658 17254), :session 92}, 595 {:keyword1 117, :keyword3 0, :abstract "The area of manufacturing operations management has received much attention from the operations research community in the past decades and this has resulted in a large spectrum of models addressing issues such as manufacturing layout and design, production planning, production/inventory management, transportation management. One of the primary benefits of these quantitative models has been to enhance our understanding of the behavior of manufacturing systems and of the trade-offs involved in decision making pertaining to operations management issues. They have also led to the development of decision support systems that are now widely used in companies. These models have relied on various operations research techniques such as combinatorial optimization, mathematical programming, stochastic models, queuing models, dynamic and stochastic programming. More recently, service operations management has become a new application area for the operations research community. Topics such as call centers management, health care management have led to an intensive research effort that has already given rise to successful applications. In this talk, we will review some important models developed in manufacturing and service operations management and emphasize the links between these models.", :title "Manufacturing and service operations management: a comparison of issues and models", :keyword2 0, :authors (3419), :session 161}, 597 {:keyword1 117, :keyword3 0, :abstract "In this presentation we discuss the operational management of supply chains under volatile and dynamic demand typical for high-tech high volume markets, such as mobile phones and LCD-TV's. We start with a summary of the main theoretical findings from multi-item multi-echelon inventory systems under stationary demand. From these findings we derive control mechanisms under stochastic dynamic demand. These mechanisms are compared with more classical approaches derived from the application of (I)LP and associated heuristics under a rolling schedule paradigm. From this we discuss strategic and tactical managerial issues, such as Customer Order Decoupling Points, Service Level Agreements and inventory capital deployment. This discussion motivates us to return to more theoretical considerations considering the control of multi-item multi-echelon inventory systems under stochastic dynmaic demand. Finally we discuss possible directions for further research.", :title "Supply chain operations planning under stochastic dynamic demand", :keyword2 75, :authors (21084), :session 163}, 599 {:keyword1 117, :keyword3 0, :abstract "Recent developments in stochastic programming on incorporating risk functionals, scenario tree generation and reduction, and dual decomposition algorithms are discussed in connection with and motivated by stochastic optimization models for electricity portfolio and risk management. The objective of such models consists in maximizing the expected overall revenue and, simultaneously, in minimizing risk. Stochasticity enters the models (at least) with uncertain demand and spot (and derivative) prices. We discuss results for a mean-risk optimization model of a price-taking retailer.", :title "Mean-risk optimization of electricity portfolios", :keyword2 99, :authors (12975), :session 165}, 600 {:keyword1 117, :keyword3 0, :abstract "From its foundation, Operational Research (OR) has made many substantial contributions to practical forecasting in organisations. Equally, researchers in other disciplines have influenced forecasting practice. Over the last twenty-five years forecasting has developed as a discipline with its own journals. While the effect of this increased specialisation has been a narrowing of the scope of OR's interest in forecasting, research from an OR perspective remains vigorous. OR has been more receptive than other disciplines to the specialist research published in the forecasting journals, capitalising on some of their key findings. In this presentation I first identify the particular topics of OR interest over the past 25 years. These are contrasted with the achievements in other disciplines, in particular econometrics and the newly emerging area of forecasting itself. ", :title "Forecasting and Operational Research - a Review", :keyword2 37, :authors (15364), :session 166}, 601 {:keyword1 117, :keyword3 0, :abstract "Metric regularity sits at the heart of variational analysis, capturing the idea of a posteriori error bounds for constraint systems. Two simple examples - alternating projections and matrix pseudospectra - nicely illustrate the interplay between metric regularity and computation. For both convex and nonconvex sets, the method of alternating projections exemplifies a theme emphasized by Demmel, relating conditioning, the distance to ill-posedness, and algorithmic speed (and incidentally proves a fundamental extremal principle of Mordukhovich). The pseudospectral mapping from a square matrix to the eigenvalues of all nearby matrices is a robust and practical numerical tool: its Lipschitz behavior follows from a striking recent semi-algebraic Sard-type result of Ioffe, describing the prevalence of metric regularity.", :title "Metric Regularity Illustrated", :keyword2 68, :authors (10724), :session 167}, 602 {:keyword1 35, :keyword3 0, :abstract "In this paper, we examine a model in which a divisionalized firm contracts with two risk-neutral, effort-averse managers to operate their divisions and make relationship-specific investment decisions. On the one hand, the firm is able to commit to profit sharing in order to induce interdivisional trade. On the other hand, contracts can also base on divisional performance measures provided an underlying allocation of the interdependence effect. The latter has an impact on the interdivisional trade and hence on the surpluses earned by both divisions. In line with the transfer pricing literature, we discuss a centralized and a decentralized setting with respect to the allocation authority. Allocation decisions can be made by the firm as well as by the division managers in a negotiated setting. Thus, the paper analyzes the role of interdependence effects within the framework of performance measurement and incentive schemes when managers make noncontractible investments and also possess private information. From the perspective of incentive effects, we show that compensation schemes and allocation mechanisms are separable coordination instruments and derive conditions under which one mechanism is dominated by the other. Specially, these conditions depend on (i) the structure of the underlying private information and (ii) personal costs by the managers. Consequently, we identify settings in which a firm is better off by disregarding transfer prices as an allocation tool and rather implementing appropriate compensation schemes.", :title "Performance Measurement, Compensation Schemes, and Allocation of Interdependence Effects", :keyword2 44, :authors (17220 17259 17260), :session 84}, 605 {:keyword1 117, :keyword3 0, :abstract "A disruption of a railway system, e.g. due to malfunctioning infrastructure or rolling stock, may imply that temporary less or no railway traffic can be accommodated on certain routes. In such a situation, disruption management involves quickly determining effective measures to uphold as much as possible service for the passengers. These measures require adapting the timetable, and rescheduling the rolling stock and the crews. Since time is a crucial factor, the corresponding optimization problems have to be solved as quickly as possible. Therefore heuristic approaches are required. An inherent complication in a disrupted situation is the fact that the duration of the disruption is not known in advance. Thus the rescheduling problems have to be solved several times if the disruption lasts longer or shorter than expected earlier. This presentation presents further details of disruption management. It also describes models and solution methods, as well as experiments that were carried out based on instances of Netherlands Railways, the largest passenger railway operator in the Netherlands.\r\n", :title "Railway disruption management", :keyword2 0, :authors (), :session 168}, 606 {:keyword1 101, :keyword3 0, :abstract "This article analyzes dual sourcing decisions under stochastically dependent supply and demand uncertainty: A manufacturer faces the trade-off between investing in unreliable high margin offshore source and reliable low margin source, the latter allowing for producing responsively contingent on the actual demand and offshore supply conditions. Cost thresholds for both types of capacity determine the optimal resource allocation: single offshore sourcing, single responsive sourcing and dual sourcing are optimal sourcing strategies. We show that responsive capacity provides a lower bound for, and, if active, determines the overall service level irrespective of the form of stochastic dependence. The selection decision for responsive capacity is shown to be more robust against offshore capacity cost reductions than the selection decision for offshore capacity against responsive capacity cost reductions. The optimal responsive capacity investment increases if correlation between supply and demand states decreases. Nevertheless, in the case of perfectly positively correlation, responsive capacity still may be valuable as it provides a hedge against demand uncertainty. We extend the optimality of the sourcing strategy to a broad class of supply uncertainty constructs.\r\n", :title "Dual Sourcing – Responsive Hedging Against (Interrelated) Supply and Demand Uncertainty", :keyword2 0, :authors (17264), :session 120}, 607 {:keyword1 106, :keyword3 0, :abstract "Even though recent advances in exact and heuristic optimization methods make it possible to compute optimal or near optimal solutions for benchmark problems significantly more than 100 customers, most commercial VRP-Solvers are still based on relative simple Algorithms. One reason for this might be that optimal or near optimal VRP solutions are often at the border to the infeasible region of the search space, so that they have the drawback of being very sensitive to uncertainty which is not covered by the model: Even little changes induced by the inherent uncertainty of the system (i.e. driving times, demands, service times, etc.) can easily lead to situations in which these solutions violate the constraints of the real world. It seems to be that most of the real world VRP-Solvers are using following assumption to handle this problem. When visualizing computer generated solutions in a decision support system, less optimized solutions might give the dispatcher more flexibility for modification so that he can add his knowledge about the uncertainty of the system easier. In other words: To manage risk and uncertainty, this strategy uses of a kind of implicit flexibility, which might luckily comes up with not hard optimized solutions generated by a weak solver. In contrast to this broadly used strategy, this paper introduces an approach that tries to produce both flexible and cost effective solutions in an explicit way using state of the art concepts for efficient VRP-Solvers. Therefore we present a general applicable methodology to quantify flexibility and risk of a tour or sub tour. The flexibility or risk function is integrated in several Multi-Objective Optimization Algorithms for VRP as an independent criterion that is used additionally to a regular cost function. ", :title "Managing both Costs and Uncertainty with Multi-Objective Optimization Algorithms for Rich Vehicle Routing Problems", :keyword2 63, :authors (6707), :session 77}, 608 {:keyword1 75, :keyword3 0, :abstract "Advanced Planning and Scheduling systems help Supply Chain Management organizations deal with the conflicting goals of satisfying customer demands on time and maintaining a sufficient safety stock level, while simultaneously controlling production and inventory costs. Manufacturing industries, such as the food, beverage and pharmaceutical industries, have additional challenges to which Ilog Plant PowerOps (PPO) is particularly well-adapted. PPO enables modeling complex manufacturing processes with several production levels, from raw materials to the finished products, including storage tank management and various cleaning policies. Model consistency is enforced by the fact that PPO is a completely integrated planning and scheduling system. Moreover, this software offers a powerful and user-friendly graphical interface and provides a complete integration with ERP systems.", :title "Integrated Planning and Scheduling in Food and Beverage and Pharmaceuticals, using ILOG Plant Powerops", :keyword2 96, :authors (), :session 210}, 609 {:keyword1 59, :keyword3 0, :abstract "In this study, we propose a new population-based meta-heuristic algorithm based on the electromagnetism-like mechanism (EM) for solving capacitated vehicle routing problems with time windows (CVRPTW). Vehicle routing problems (VRP) have long been analyzed in detail within the last few decades and CVRPTW is a variant of the general VRP which imposes a time constraint for each customer to be served. Since CVRPTW has shown to be of strongly NP-hard structure, exact optimization procedures are only restricted to relatively small instances. Recently being implemented in some typical NP-hard VRPs, EM has been shown to provide promising results. In principle, EM algorithm simulates attraction and repulsion of charged particles in order to converge to an optimum and has been originally proposed for solving continuous optimization problems. However, here we have utilized the random-key concept to modify EM algorithm to solve a known combinatorial optimization problem like CVRPTW. Performance of the proposed hybrid algorithm has been compared with a hybrid genetic algorithm (GA) using several benchmarking problems. The computational results show the promising strength of the EM algorithm but much research is still needed for tuning in the parameters such as population size and hybridization techniques.", :title "A new Electromagnetism-like Mechanism Algorithm for Vehicle Routing Problems with Time Windows", :keyword2 95, :authors (15313 15322), :session 156}, 617 {:keyword1 117, :keyword3 0, :abstract "The design of optimal auctions is recognized as an intriguing issue in auction theory, first studied by Myerson (1981) for the case of single item auctions. There, the goal is to design an auction that maximizes the seller's expected revenue. More generally, optimal mechanism design is concerned with coordinating the selfish behavior of noncooperative agents,  while minimizing the total expected cost for the mechanism designer. In this talk, we will review the basic concepts and some key results for optimal mechanism design, including the famous revenue equivalence theorem. We will then study the design of optimal mechanisms in a setting where job-agents compete for being processed on a single machine that can only handle one job at a time.\r\n\r\n(Based on joint work with B. Heydenreich, D. Mishra, R. Müller, and R. Vohra)\r\n", :title "Optimal Mechanisms for Scheduling Problems", :keyword2 0, :authors (1019), :session 162}, 618 {:keyword1 75, :keyword3 0, :abstract "In this paper, we focus on a heuristic for assembly lines of large products like planes, printing machines, or turbines. A special characteristic of these assemblies is that most processing steps have to be performed by teams of workers with different skills. In addition, the numbers of workers in these teams are not fixed. Depending on the release and due dates of the products and the given per-shift supply of workers with different skills an optimal assignment of workers to processing steps has to be found. Because of the large amount of constraints and the tight limits for the schedule computation times, we developed a simulation-based heuristic for this problem. First, we build a simulation model from all relevant production data without user interaction. Then, we determine a feasible solution based on the maximum number of workers possible. In a third step, the production plan is \"`stretched\"' to reduce the number of workers as much as possible. We developed a prototype implementation for the heuristic which was successfully tested with real production data from the aviation industry.", :title "A simulation-based heuristic for the workforce scheduling problem of complex assembly lines", :keyword2 96, :authors (17302 17305 17306), :session 147}, 619 {:keyword1 117, :keyword3 0, :abstract "In recent years, the transportation of goods on road networks has shown a significant increase, wehereas the \r\ncapacity of road networks increases only moderately due to \r\nenvironmental and political restrictions. Together with recent introductions of toll charges in several countries and discussions about congestion charges in various cities there is a pressure for cutting down transportation costs by reducing total travel distance. While the basic vehicle routing problem (VRP) as well as appropriate exact and heuristic solution methods have been considered in the \r\nliterature for decades, recent research has followed two lines (1) Various extensions of VRPs have been suggested that include all kinds of real world constraints (e.g. periodic delivery, multiple time windows etc.) forming so called rich VRPs. Furthermore, the simultaneous optimization of transportation and other decision problems (e.g. inventory management, location decisions, or cutting \r\nand packing) has been tackled leading e.g. to inventory routing problems, location routing problems, or VRPs with loading constraints. (2) The increasing availability of geographical information systems (GIS) and electronic data about customer locations has made it necessary to solve large VRP. This has lead to an ever growing body of literature on metaheuristic solution procedures that give \r\ngood compromise solutions within a reasonably short time.\r\nOne of the recent metaheuristics is variable neighborhood search (VNS), which is characterized by a systematic change between intensified search in a certain area (local search) and diversification steps (shaking). This method has \r\nproven very competitive in the area of vehicle routing. In this talk a non-comprehensive survey will be provided on applications of VNS on rich VRPs.", :title "VNS approaches for rich und real world vehicle routing problems", :keyword2 0, :authors (), :session 164}, 620 {:keyword1 117, :keyword3 0, :abstract "Developing planning applications based on tailor-made MIP-models is becoming more and more attractive for the industry. Project managers contact research institutes or specialized commercial companies and describe their needs. Before starting a major investment it is usual to prove the concepts with a limited budget and time frame. Researchers on the other hand want to explore challenging optimization problems that may require long term investigation and respective funding. \r\n\r\nThis talk presents ways to pitch for industry projects with mixed integer programming, to prove initial concepts, to derive research topics from the MIP-models proposed for the project and to get money for the respective research. The topic is illustrated with MIP-models from realistic cases.\r\n", :title "Selling Industry Projects and Related Research Projects with Mixed Integer Programming", :keyword2 0, :authors (), :session 215}, 621 {:keyword1 117, :keyword3 0, :abstract "Sustainable Construction (SC) addresses a wide array of built environment issues such as energy and climate change; water, wastewater, and stormwater; materials; waste and emissions; land planning and use; building and ecological system health; and economic and social impacts.  Each of these issues is inherently complex and when they are combined in the course of evaluating strategies for a specific building project or cluster of building projects, determining the optimal solution is difficult if not impossible due to the interplay of physical and temporal constraints, the consideration of scale, the wide array of actors and the wide variety of units of measurement, to name but a few.  Additionally Sustainable Construction addresses issues on a life cycle basis and consequently there is a temporal dimension that must be included in the articulation of many of the challenging problems encountered in built environment design. This paper describes how Operations Research (OR) can be applied to support the complex decision making environment faced by SC.  OR can potentially contribute to the resolution of complex SC decisions in two ways.  First, OR can provide approaches for expressing many SC problems as physical and mathematical statements that can provide insight and clarity in better understanding the problem and its physical and temporal boundary conditions. Second, OR can potentially provide the techniques for resolving SC problems, thus providing a currently missing technical foundation for decision making.   An example of the type of problem that OR can potentially articulate and resolve is climate change, to which the built environment is often cited as contributing about 40% of the global warming gases being emitted by human activities.", :title "The Potential Application of Operations Research to Sustainable Construction", :keyword2 0, :authors (17274), :session 160}, 622 {:keyword1 117, :keyword3 0, :abstract "The Operations Research field is at a historical turning point.  The drive for analytical rigor and research excellence has succeeded in generating a stream of high quality research and researchers.  And yet, the relevance of what we do for managers and its value to society is being questioned, now more than at any time in our past.  At the same time, as global enterprises face fundamental economic, environmental and social changes, the need for solutions to problems that Operations Research can contribute to has never been greater.  In this talk I will reflect on where Operations Research can and should go in order to meet the challenges and realize the opportunities.  I will consider factors such as;  the globalization of production and distribution in most industries, the proliferation of low cost, fully networked information and communication technologies,  the final stages in the shift to a service-oriented economy, and the emergence of new research paradigms that incorporate economics, incentives and behavioral considerations.  I will base my remarks on personal experience derived from implementing Operations Research based solutions with leading global companies in Aerospace, Defense, Automobile, Semiconductor, Telecommunications and Logistics industries.", :title "Operations Research at the Crossroads: Opportunities and Challenges to Support Global Enterprise", :keyword2 0, :authors (17485), :session 220}, 623 {:keyword1 117, :keyword3 0, :abstract "We review our recent efforts to develop a history of OR viewed as a timeline description of events, people, and other influences. To date, we have identified over 400 such items extending over 400 years. We discuss a biased sample of such items that relate\r\nto the question: How did OR get from there to here? We include answers to the following OR trivia:\r\nWho first solved the general n-point facility location problem when he was 16 years old?\r\nWho wrote the first book on OR methods and when was it published?\r\nWhen was the first OR journal published and who sponsored it?\r\nWhy did the economist T.C. Koopmans give $40,000 (a third of his Nobel 1975 prize in economics) away?\r\n", :title "An Annotated Timeline of Operations Research", :keyword2 0, :authors (), :session 219}, 624 {:keyword1 117, :keyword3 0, :abstract "To be Announced.", :title "Global Business at KUKA Group", :keyword2 0, :authors (), :session 221}, 625 {:keyword1 99, :keyword3 0, :abstract "Formulating stochastic models in a modeling language and deploying it to end-users has long been a challenge in practice. In this presentation we will review how both scenario-based and independent variables stochastic models can be effectively formulated in a modeling language, such as MPL. Several formulations of SP models will be demonstrated.\r\n", :title "Stochastic Programming for Modeling Languages", :keyword2 0, :authors (3843), :session 128}, 626 {:keyword1 117, :keyword3 0, :abstract "Opening addresses\r\n  -  Prof. Dr. Horst Hanusch, Vice-President of the University of Augsburg\r\n  -  Prof. Dr. Thomas Spengler, President of the German Operations Research Society (GOR)\r\n  -  Prof. Dr. Bernhard Fleischmann, Chair of the Program Committee\r\n\r\nAwards ceremony \r\nAwards are conferred by the chairmen of the jury:\r\n  -  GOR Diploma Award: Prof. Dr. Christian Bierwirth\r\n  -  GOR Doctoral Theses Award: Prof. Dr. Hans-Ulrich Küpper\r\n  -  GOR Company Award: Prof. Dr. Brigitte Werners\r\n\r\n\r\n\r\n   ", :title "Opening Session", :keyword2 0, :authors (5524), :session 219}, 627 {:keyword1 14, :keyword3 0, :abstract "By the innovation and development of technology, high processor computers took place to do the work which the human did in the past. For instance, classification or detection problems in real-world such as credit card frauding, account management, portfolio optimization, or life sciences such as biological experiments, prediction of cancer risk, finding patterns in genes or identification of proteins can be given as an example. This helped human beings and industry to save time and finances. With the help of mathematical modelling and computer science, experimental data are analyzed and data mining tools developed. \r\nReal-world data can be supplied from a heterogeneous kind of source. In such case, multiple kernels are more convenient to use for a good accurcay. Recent applications (Lanckriet et al 2004) showed the need for multiple kernel learning because of its interpretibility and efficiency. \r\nWe propose a novel method to find infinitely many kernel combinations for learning problems with the help of infinite and semi-infinite optimization regarding all elements in kernel space. This helps to study variations of combinations of kernels when considering heterogeneous data in real-world applications. Looking at all infinitesimally fine convex combinations of the kernels from the infinite kernel set, the margin is maximized subject to an infinite number of constraints with a compact index set and an additional (Riemann-Stieltjes) integral constraint due to the combinations. After a parametrisation in the space of probability measures it becomes semi-infinite. We analyze the conditions which satisfy the Reduction Ansatz and discuss the type of distribution functions of the kernel coefficients within the structure of the constraints and our bilevel optimization problem.\r\n", :title "Infinite Kernel Learning by Semi-infinite Optimization", :keyword2 120, :authors (3524 11028), :session 79}, 628 {:keyword1 106, :keyword3 0, :abstract "The Port of Rotterdam is one of the ports of Germany!\r\nResearch to support innovation in the port-related global supply chains are often inspired by aspects like security, sustainability or profitability. \r\n\r\nThe enabling IT technology offers possibilities to integrate the different aspects. In the presentation an overview will be given of some of the research projects that are currently carried out in the Port of Rotterdam.\r\n", :title "Innovations in port-related supply chains", :keyword2 0, :authors (3589), :session 73}}, :users {125 {:firstname "Norbert", :lastname "Trautmann", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (55)}, 128 {:firstname "Rainer", :lastname "Burkard", :department "Institute of Optimization and Discrete Mathematics", :institution "Graz University of Technology", :country "Austria", :sessions (205 206)}, 281 {:firstname "Ulrike", :lastname "Leopold-Wildburger", :department "Statistics and Operations Research", :institution "Karl-Franzens-University", :country "Austria", :sessions (214 181 190)}, 333 {:firstname "Gerhard", :lastname "Wäscher", :department "Fakultät für Wirtschaftswissenschaft", :institution "Otto-von-Guericke Universität Magdeburg", :country "Germany", :sessions (150 142)}, 406 {:firstname "Ilker", :lastname "Birbil", :department "Econometric Institute", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (156 206 176 19 79)}, 454 {:firstname "Rudolf", :lastname "Vetschera", :department "Dept. of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (106)}, 607 {:firstname "Gerhard", :lastname "Reinelt", :department "Institut for Computer Science", :institution "University of Heidelberg", :country "Germany", :sessions (205 20)}, 643 {:firstname "Gül Gökay", :lastname "Emel", :department "Business Administration", :institution "Uludag University", :country "Turkey", :sessions (155 106)}, 692 {:firstname "Tonguc", :lastname "Ünlüyurt", :department "Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (91)}, 770 {:firstname "Marion", :lastname "Rauner", :department "Faculty of Business, Economics, and Statistics", :institution "University of Vienna", :country "Austria", :sessions (94)}, 805 {:firstname "Reza", :lastname "Tavakkoli-Moghaddam", :department "Department of Industrail Engineering", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (206 16 59)}, 829 {:firstname "Rainer", :lastname "Kolisch", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (141 56)}, 899 {:firstname "Geir", :lastname "Hasle", :department "Mathematics and Cybernetics", :institution "SINTEF Digital", :country "Norway", :sessions (34)}, 909 {:firstname "Martin", :lastname "Grunow", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (49 203 133)}, 930 {:firstname "Christoph", :lastname "Schwindt", :department "Institute of Management and Economics", :institution "Clausthal University of Technology", :country "Germany", :sessions (162 49)}, 1019 {:firstname "Marc", :lastname "Uetz", :department "Applied Mathematics ", :institution "University of Twente ", :country "Netherlands", :sessions (162)}, 1024 {:firstname "Rob", :lastname "Zuidwijk", :department "Technology Operations Management", :institution "RSM Erasmus University", :country "Netherlands", :sessions (117)}, 1054 {:firstname "Mohammad", :lastname "Modarres", :department "Department of Industrial Engineering", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (19)}, 1109 {:firstname "Giselher", :lastname "Pankratz", :department "Dept. of Information Systems", :institution "FernUniversität - University of Hagen", :country "Germany", :sessions (156 61)}, 1116 {:firstname "Elena", :lastname "Fernandez", :department "Statistics and Operations Research", :institution "Technical University of Catalonia", :country "Spain", :sessions (179)}, 1131 {:firstname "Heinrich", :lastname "Kuhn", :department "Operations Management", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (211 210 118 161)}, 1141 {:firstname "Leena", :lastname "Suhl", :department "Dept. Business Information Systems", :institution "University of Paderborn", :country "Germany", :sessions (67 127 98 58)}, 1177 {:firstname "Y. Ilker", :lastname "Topcu", :department "Industrial Engineering", :institution "Istanbul Technical University", :country "Turkey", :sessions (176 19)}, 1194 {:firstname "Natalia", :lastname "Kliewer", :department "Information Systems", :institution "Freie Universitaet Berlin", :country "Germany", :sessions (67 63 58 70)}, 1219 {:firstname "Otto", :lastname "Rentz", :department "Economic Engineering", :institution "institute of industrial production", :country "Germany", :sessions (92)}, 1462 {:firstname "Hans-Dietrich", :lastname "Haasis", :department "", :institution "ISL, Institute of Shipping Economics and Logistics", :country "Germany", :sessions (73 32)}, 1601 {:firstname "Anita", :lastname "Schöbel", :department "TU Kaiserslautern", :institution "Fachbereich Mathematik", :country "Germany", :sessions (196 78)}, 1609 {:firstname "Axel", :lastname "Tuma", :department "Faculty of Business Administration ", :institution "University of Augsburg", :country "Germany", :sessions (221)}, 1646 {:firstname "Vladimir", :lastname "Marianov", :department "Electrical Engineering", :institution "Pontificia Universidad Catolica de Chile", :country "Chile", :sessions (98)}, 1658 {:firstname "Peter", :lastname "Letmathe", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (92)}, 1752 {:firstname "Rommert", :lastname "Dekker", :department "", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (122)}, 1794 {:firstname "Marcos", :lastname "Arenales", :department "Dept of Applied Mathematic and Statistics", :institution "universidade de São Paulo", :country "Brazil", :sessions (150)}, 2229 {:firstname "Masoud", :lastname "Rabbani", :department "Department of Industrial Engineering", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (103 59)}, 2391 {:firstname "Werner", :lastname "Jammernegg", :department "Department of Information Systems and Operations", :institution "WU Vienna University of Economics and Business", :country "Austria", :sessions (113)}, 2423 {:firstname "Bülent", :lastname "Çatay", :department "Faculty of Engineering and Natural Sciences", :institution "Sabanci University", :country "Turkey", :sessions (91 69)}, 2427 {:firstname "Michael", :lastname "Schröder", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (63 16)}, 2448 {:firstname "Herbert", :lastname "Meyr", :department "Department of Supply Chain Management", :institution "University of Hohenheim", :country "Germany", :sessions (163 118)}, 2481 {:firstname "Mirjam", :lastname "Duer", :department "Mathematics", :institution "University of  Augsburg", :country "Germany", :sessions (24 17)}, 2531 {:firstname "Matthieu", :lastname "van der Heijden", :department "Operational Methods for Production and Logistics", :institution "University of Twente", :country "Netherlands", :sessions (134)}, 2650 {:firstname "Grit", :lastname "Walther", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (113 94 203 92 119)}, 2651 {:firstname "Thomas", :lastname "Spengler", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (136 113 94 203 92 119 133)}, 2713 {:firstname "Michaela", :lastname "Schaffhauser-Linzatti", :department "Business Administration", :institution "University of Vienna", :country "Austria", :sessions (94)}, 2769 {:firstname "Karl", :lastname "Doerner", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (51)}, 2795 {:firstname "Oliver", :lastname "Stein", :department "Institute of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (138)}, 2801 {:firstname "Karl", :lastname "Inderfurth", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University of Magdeburg", :country "Germany", :sessions (22 112 121)}, 2857 {:firstname "Seyda", :lastname "Topaloglu Yildiz", :department "Industrial Engineering", :institution "Dokuz Eylul University", :country "Turkey", :sessions (54)}, 2886 {:firstname "Mohammad Reza", :lastname "Akbari Jokar", :department "Department of Industrial Engineering", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (120)}, 2950 {:firstname "Robert", :lastname "Weismantel", :department "Department of Mathematics", :institution "ETH Zurich", :country "Germany", :sessions (204)}, 3189 {:firstname "Simme Douwe", :lastname "Flapper", :department "", :institution "Technische Universiteit Eindhoven", :country "Netherlands", :sessions (134)}, 3190 {:firstname "Yury", :lastname "Kochetov", :department "Information Technology", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (205 178 95 171)}, 3297 {:firstname "Naoki", :lastname "Katoh", :department "Department of Informatics", :institution "Kwansei Gakuin University", :country "Japan", :sessions (195)}, 3329 {:firstname "Rob", :lastname "Broekmeulen", :department "OPAC", :institution "TU Eindhoven", :country "Netherlands", :sessions (134)}, 3397 {:firstname "Deniz", :lastname "Aksen", :department "College of Administrative Sciences and Economics", :institution "Koç University", :country "Turkey", :sessions (34)}, 3419 {:firstname "Yves", :lastname "Dallery", :department "", :institution "Ecole Centrale Paris", :country "France", :sessions (161)}, 3455 {:firstname "Selcuk", :lastname "Savas", :department "Industrial Engineering", :institution "Koc University", :country "Turkey", :sessions (34)}, 3524 {:firstname "Gerhard-Wilhelm", :lastname "Weber", :department "Faculty of Engineering Management, Chair of Marketing and Economic Engineering", :institution "Poznan University of Technology", :country "Poland", :sessions (91 79)}, 3589 {:firstname "Jo", :lastname "van Nunen", :department "Department Decision and Information Sciences", :institution "RSM Erasmus University", :country "Netherlands", :sessions (73)}, 3843 {:firstname "Bjarni", :lastname "Kristjansson", :department "", :institution "Maximal Software", :country "Iceland", :sessions (128)}, 3974 {:firstname "Kai", :lastname "Furmans", :department "IFL", :institution "University of Karlsruhe", :country "Germany", :sessions (116)}, 4161 {:firstname "Stefan", :lastname "Irnich", :department "Chair of Logistics Management, Gutenberg School of Management and Economics", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (175)}, 4169 {:firstname "Andreas", :lastname "Brandt", :department "Wirtschaftswissenschaftliche Fakultät, Institut of Operations Research", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (132)}, 4170 {:firstname "Manfred", :lastname "Brandt", :department " Optimization ", :institution " Konrad-Zuse-Zentrum für Informationstechnik Berlin (ZIB)", :country "Germany", :sessions (132)}, 4224 {:firstname "Grzegorz", :lastname "Pawlak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (50)}, 4229 {:firstname "Moritz", :lastname "Fleischmann", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (117)}, 4256 {:firstname "Gonca", :lastname "Tuncel", :department "Department of Industrial Engineering", :institution "Dokuz Eylul University", :country "Turkey", :sessions (116)}, 4263 {:firstname "Derya", :lastname "Eren Akyol", :department "Department of Industrial Engineering", :institution "Dokuz Eylul University ", :country "Turkey", :sessions (136)}, 4796 {:firstname "Stefan Wolfgang", :lastname "Pickl", :department "Department of Computer Science", :institution "UBw München COMTESSA", :country "Germany", :sessions (192 102)}, 4889 {:firstname "Horst", :lastname "Tempelmeier", :department "Supply Chain  Management and Production", :institution "University of Cologne", :country "Germany", :sessions (150)}, 5017 {:firstname "Vitaly", :lastname "Strusevich", :department "School of Computing and Mathematical Sciences", :institution "University of Greenwich", :country "United Kingdom", :sessions (57)}, 5078 {:firstname "Stefan", :lastname "Nickel", :department "Institute for Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (179 149)}, 5218 {:firstname "Petra", :lastname "Huhn", :department "", :institution "", :country "Germany", :sessions (138 140 167)}, 5345 {:firstname "Aysun", :lastname "Tezel Özturan", :department "Department of Mathematics", :institution "Hacettepe University", :country "Turkey", :sessions (138)}, 5454 {:firstname "Wolfgang Anthony", :lastname "Eiden", :department "", :institution "", :country "Germany", :sessions (56)}, 5524 {:firstname "Bernhard", :lastname "Fleischmann", :department "Production&SCM", :institution "Universität Augsburg", :country "Germany", :sessions (216 218 219 220)}, 5557 {:firstname "Klaus", :lastname "Truemper", :department "", :institution "University of Texas at Dallas", :country "United States", :sessions (204)}, 5931 {:firstname "Stefan", :lastname "Voss", :department "Wirtschaftsinformatik/Information Systems", :institution "University of Hamburg", :country "Germany", :sessions (73 157)}, 5932 {:firstname "Dennis", :lastname "Huisman", :department "Econometric Institute", :institution "Erasmus University", :country "Netherlands", :sessions (199)}, 5965 {:firstname "Jürgen", :lastname "Zimmermann", :department "Operations Research", :institution "TU Clausthal", :country "Germany", :sessions (68 147)}, 5988 {:firstname "Takashi", :lastname "Matsuhisa", :department "BUSAIKU BUHI Foundation for Scientific Research", :institution "Mathematical Research Institute", :country "Japan", :sessions (185)}, 6218 {:firstname "Carlos Ramón", :lastname "García Alonso", :department "Management", :institution "ETEA, Business Administration Faculty. University of Córdoba. Spain", :country "Spain", :sessions (91)}, 6404 {:firstname "Andreas", :lastname "Bortfeldt", :department "Dept. of Management Science", :institution "University of Magdeburgagen", :country "Germany", :sessions (24)}, 6621 {:firstname "Malgorzata", :lastname "Sterna", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (57)}, 6707 {:firstname "Andreas", :lastname "Reinholz", :department "", :institution "AROpt Consulting", :country "Germany", :sessions (77)}, 6751 {:firstname "Michael", :lastname "Manitz", :department "Technology and Operations Management, Chair of Production and Supply Chain Management", :institution "University of Duisburg/Essen", :country "Germany", :sessions (117)}, 6752 {:firstname "Sven F.", :lastname "Crone", :department "Department of Management Science", :institution "Lancaster University Management School", :country "United Kingdom", :sessions (182)}, 6896 {:firstname "Andreas", :lastname "Hamel", :department "Mathematics", :institution "University Halle-Wittenberg", :country "Germany", :sessions (129)}, 6948 {:firstname "Frank", :lastname "Heyde", :department "Institute of Mathematics and Scientific Computing", :institution "University of Graz", :country "Austria", :sessions (129)}, 7503 {:firstname "Vicente", :lastname "Fernández", :department "Busines administration", :institution "ETEA-Faculty of Busines administration", :country "Spain", :sessions (91)}, 7848 {:firstname "Nicole", :lastname "Sunke", :department "Chair of Business Administration, Construction Management and Economics", :institution "University of Siegen", :country "Germany", :sessions (160 92)}, 7925 {:firstname "Alex", :lastname "Meeraus", :department "", :institution "GAMS Development Corporation", :country "United States", :sessions (101)}, 8142 {:firstname "Yuri", :lastname "Stoyan", :department "Department of Mathematical Modeling and Optimal Design", :institution "Institute for Mechanical Engineering Problems of the National Academy of Sciences of Ukraine", :country "Ukraine", :sessions (179 18)}, 8436 {:firstname "Manfred", :lastname "Gronalt", :department "Institute of Production and Logistics", :institution "University of Natural Resources and Life Sciences", :country "Austria", :sessions (73)}, 8713 {:firstname "Magnus", :lastname "Fröhling", :department "Faculty of Economics", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (92 93)}, 8824 {:firstname "Günter", :lastname "Schmidt", :department "", :institution "Saarland University", :country "Germany", :sessions (89)}, 8853 {:firstname "Cara", :lastname "Cocking", :department "Department of Computer Science", :institution "University of Heidelberg", :country "Germany", :sessions (205)}, 8892 {:firstname "Markus", :lastname "Arnold", :department "Department of Social Economics", :institution "Universität Hamburg", :country "Germany", :sessions (81 82)}, 9026 {:firstname "Peter", :lastname "Brucker", :department "", :institution "University of Osnabrueck", :country "Germany", :sessions (54)}, 9027 {:firstname "Ekaterina", :lastname "Alekseeva", :department "INFORMATION TECHNOLOGIES", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (205)}, 9096 {:firstname "Thomas", :lastname "Burkhardt", :department "Campus Koblenz, IfM", :institution "Universitaet Koblenz-Landau", :country "Germany", :sessions (84)}, 9112 {:firstname "Stefan", :lastname "Minner", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (147 122)}, 9272 {:firstname "Achim", :lastname "Koberstein", :department "Information and Operations Management", :institution "European University Viadrina Frankfurt (Oder)", :country "Germany", :sessions (20 127 116)}, 9365 {:firstname "Heiner", :lastname "Müller-Merbach", :department "Wirtschaftswissenschaften", :institution "Universität Kaiserslautern", :country "Germany", :sessions (14)}, 9422 {:firstname "Stefan", :lastname "Lessmann", :department "School of Business and Economics", :institution "Humboldt-University of Berlin", :country "Germany", :sessions (157)}, 9512 {:firstname "Rüdiger", :lastname "Schultz", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (130 165)}, 9516 {:firstname "Igor", :lastname "Zverovich", :department "", :institution "RUTCOR, Rutgers University", :country "United States", :sessions (45)}, 9524 {:firstname "Julia", :lastname "Rieck", :department "Operations Research Group", :institution "University of Hildesheim", :country "Germany", :sessions (68)}, 9558 {:firstname "René", :lastname "Haijema", :department "Operations Research and Logistics", :institution "Wageningen University", :country "Netherlands", :sessions (132)}, 9578 {:firstname "Gregor", :lastname "Dorfleitner", :department "Dep. of Finance", :institution "University  of Regensburg", :country "Germany", :sessions (85 87)}, 9631 {:firstname "Uwe", :lastname "Suhl", :department "DSOR Lab", :institution "Universität Paderborn", :country "Germany", :sessions (20)}, 9663 {:firstname "Constanta Zoie", :lastname "Radulescu", :department "Research", :institution "National Research R&D in Informatics", :country "Romania", :sessions (129)}, 9667 {:firstname "Robert", :lastname "Gillenkirch", :department "Department of Finance, Accounting and Taxes", :institution "Georg-August-University of Göttingen", :country "Germany", :sessions (81)}, 9694 {:firstname "Dmitrii", :lastname "Lozovanu", :department "Institute of Mathematics and Computer Science", :institution "Academy of Sciences of Moldova", :country "Moldova, Republic of", :sessions (192)}, 9732 {:firstname "Thomas", :lastname "Huth", :department "Decision Support Group", :institution "Braunschweig Institute of Technology", :country "Germany", :sessions (31)}, 9852 {:firstname "Halil Ibrahim", :lastname "Guenduez", :department "Deutsche Post Chair of Optimization of Distribution Networks", :institution "RWTH Aachen University", :country "Germany", :sessions (37)}, 10023 {:firstname "Karel", :lastname "Sladky", :department "Department of Econometrics", :institution "Institute of Information Theory and Automation, Academy of Sciences of the Czech Republic", :country "Czech Republic", :sessions (129)}, 10057 {:firstname "Brigitte", :lastname "Werners", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (143 224)}, 10133 {:firstname "Kerem", :lastname "Bulbul", :department "Manufacturing Sys. & Industrial Eng.", :institution "Sabanci University", :country "Turkey", :sessions (176 19)}, 10169 {:firstname "Sebastian", :lastname "Lobe", :department "", :institution "University of Regensburg", :country "Germany", :sessions (84)}, 10219 {:firstname "Huy", :lastname "Chhaing", :department "Graduate School of Economics", :institution "Osaka University", :country "Japan", :sessions (121)}, 10255 {:firstname "Raik", :lastname "Stolletz", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (141 147)}, 10297 {:firstname "Ovidiu", :lastname "Listes", :department "", :institution "AIMMS", :country "Netherlands", :sessions (146)}, 10309 {:firstname "Klaus", :lastname "Röder", :department "", :institution "University of Regensburg", :country "Germany", :sessions (86 84)}, 10362 {:firstname "Birol", :lastname "Yüceoglu", :department "Information Technologies", :institution "Migros T.A.Ş.", :country "Turkey", :sessions (206)}, 10544 {:firstname "Michael", :lastname "Ferris", :department "Computer Sciences Department", :institution "University of Wisconsin", :country "United States", :sessions (101)}, 10574 {:firstname "Hartmut", :lastname "Stadtler", :department "Institute for Logistics and Transport", :institution "University of Hamburg", :country "Germany", :sessions (114)}, 10724 {:firstname "Adrian S.", :lastname "Lewis", :department "", :institution "Cornell University", :country "United States", :sessions (167)}, 10785 {:firstname "Edward", :lastname "Gimadi", :department "Discrete Optimization in Operations Research", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (95 23 77)}, 10871 {:firstname "Diethard", :lastname "Klatte", :department "IBW", :institution "Universität Zürich", :country "Switzerland", :sessions (138)}, 10929 {:firstname "Frans", :lastname "de Rooij", :department "", :institution "AIMMS", :country "Netherlands", :sessions (101)}, 10996 {:firstname "Martin", :lastname "Grötschel", :department "Vice President", :institution "Konrad-Zuse-Zentrum für Informationstechnik, ", :country "Germany", :sessions (192)}, 11028 {:firstname "Sureyya", :lastname "Ozogur-Akyuz", :department "Department of Mathematics Engineering", :institution "Bahcesehir University", :country "Turkey", :sessions (79)}, 11344 {:firstname "Dilek", :lastname "Tuzun", :department "Systems Engineering", :institution "Yeditepe University", :country "Turkey", :sessions (176 19)}, 11448 {:firstname "Tobias", :lastname "Buer", :department "Logistics, Tourism and Service Management", :institution "GUtech", :country "Oman", :sessions (61)}, 11762 {:firstname "Josep", :lastname "Freixas", :department "Matemàtiques", :institution "Universitat Politècnica de Catalunya", :country "Spain", :sessions (181)}, 11829 {:firstname "Hans-Peter", :lastname "Ziegler", :department "Operations Research und Logistik", :institution "Universität des Saarlandes", :country "Germany", :sessions (149)}, 11875 {:firstname "Tatiana", :lastname "Romanova", :department "Department of Mathematical Modeling and Optimal Design", :institution "Institute for Mechanical Engineering Problems of the National Academy of Sciences of Ukraine", :country "Ukraine", :sessions (179)}, 11988 {:firstname "Yury", :lastname "Orlovich", :department "Department of Discrete Mathematics and Algorithmics, Faculty of Applied Mathematics and Computer Science", :institution "Belarusian State University", :country "Belarus", :sessions (45)}, 12140 {:firstname "Jörg", :lastname "Kalcsics", :department "School of Mathematics", :institution "University of Edinburgh", :country "United Kingdom", :sessions (179)}, 12177 {:firstname "Arie", :lastname "Koster", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (201)}, 12184 {:firstname "Christian", :lastname "Raack", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (201)}, 12185 {:firstname "Sebastian", :lastname "Orlowski", :department "Optimization", :institution "atesio GmbH", :country "Germany", :sessions (201)}, 12231 {:firstname "Roland", :lastname "Wessäly", :department "", :institution "atesio GmbH", :country "Germany", :sessions (201)}, 12245 {:firstname "H.A.", :lastname "Eiselt", :department "", :institution "University of New Brunswick", :country "Canada", :sessions (98)}, 12453 {:firstname "Florian", :lastname "Jaehn", :department "Management Science and Operations Research", :institution "Helmut-Schmidt-University - University of the Federal Armed Forces Hamburg", :country "Germany", :sessions (14)}, 12530 {:firstname "Alexander", :lastname "Plyasunov", :department "Information Technology Department", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (95)}, 12604 {:firstname "Michal", :lastname "Fendek", :department "Department of Operations Research and Econometrics", :institution "University of Economics in Bratislava", :country "Slovakia", :sessions (148)}, 12695 {:firstname "Ulrich", :lastname "Pferschy", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (156 204)}, 12763 {:firstname "Eleonora", :lastname "Fendekova", :department "Department of Business Economics", :institution "University of Economics in Bratislava", :country "Slovakia", :sessions (148)}, 12839 {:firstname "Thomas", :lastname "Winter", :department "Department of Mathematics, Physics, and Chemistry", :institution "Beuth Hochschule für Technik Berlin", :country "Germany", :sessions (136)}, 12902 {:firstname "Thomas", :lastname "Morgenstern", :department "IWI Informatik und Wirtschaftsinformatik", :institution "Hochschule Karlsruhe – Technik und Wirtschaft", :country "Germany", :sessions (128)}, 12935 {:firstname "Michael", :lastname "Schachtebeck", :department "Institute for Numerical and Applied Mathematics", :institution "University of Goettingen", :country "Germany", :sessions (196)}, 12951 {:firstname "Jörn", :lastname "Sass", :department "Fachbereich Mathematik", :institution "TU Kaiserslautern", :country "Germany", :sessions (86)}, 12952 {:firstname "Dirk Christian", :lastname "Mattfeld", :department "Business Information Systems", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (31 51)}, 12953 {:firstname "Volker", :lastname "Nissen", :department "Information Systems", :institution "TU Ilmenau", :country "Germany", :sessions (53)}, 12969 {:firstname "Diana", :lastname "Fanghaenel", :department "Fachbereich Elektrotechnik/Informatik", :institution "Universität Kassel", :country "Germany", :sessions (204 45)}, 12975 {:firstname "Werner", :lastname "Römisch", :department "Department of Mathematics", :institution "Humboldt-University Berlin", :country "Germany", :sessions (165)}, 13046 {:firstname "Alexander", :lastname "Martin", :department "Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (199 17)}, 13051 {:firstname "Gunther", :lastname "Friedl", :department "TUM Business School", :institution "Technische Universität München", :country "Germany", :sessions (81)}, 13057 {:firstname "Hanno", :lastname "Sagebiel", :department "Institute of Management and Economics", :institution "Clausthal University of Technology", :country "Germany", :sessions (49)}, 13058 {:firstname "Andreas", :lastname "Bley", :department "Mathematics", :institution "Uni Kassel", :country "Germany", :sessions (201)}, 13059 {:firstname "Thomas", :lastname "Wensing", :department "", :institution "INFORM GmbH", :country "Germany", :sessions (211)}, 13086 {:firstname "Frank", :lastname "Meisel", :department "", :institution "Christian-Albrechts-University", :country "Germany", :sessions (58)}, 13171 {:firstname "Murat", :lastname "Baskak", :department "Industrial Engineering", :institution "Istanbul Technical University", :country "Turkey", :sessions (142)}, 13264 {:firstname "Stephan", :lastname "Meisel", :department "Carl-Friedrich Gauss Department", :institution "University of Braunschweig", :country "Germany", :sessions (51)}, 13335 {:firstname "Niels", :lastname "Becker", :department "Department of Economics", :institution "Ruhr-University Bochum", :country "Germany", :sessions (143)}, 13364 {:firstname "Matthias", :lastname "Amen", :department "Chair for Quantitative Accounting & Financial Reporting", :institution "Bielefeld University", :country "Germany", :sessions (88)}, 13415 {:firstname "Mariya", :lastname "Sodenkamp", :department "", :institution "University of Paderborn", :country "Germany", :sessions (98)}, 13424 {:firstname "Artem", :lastname "Pyatkin", :department "", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (179)}, 13489 {:firstname "Niklas", :lastname "Labitzke", :department "Department of Production and Logistics Management", :institution "University of Technology Braunschweig", :country "Germany", :sessions (133)}, 13503 {:firstname "Thomas", :lastname "Volling", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (136 133)}, 13514 {:firstname "Artem", :lastname "Pyatkin", :department "", :institution "Sobolev Institute of Mathematics,", :country "Russian Federation", :sessions (179)}, 13538 {:firstname "Franz", :lastname "Wesselmann", :department "Decision Support & OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (20)}, 13649 {:firstname "CHENGXIN", :lastname "QU", :department "Logistics Production and Service Department ", :institution "ESSEC", :country "France", :sessions (107)}, 13656 {:firstname "Hermann", :lastname "Locarek-Junge", :department "Lehrstuhl für BWL, insbes. Finanzwirtschaft ", :institution "TU Dresden", :country "Germany", :sessions (85)}, 13767 {:firstname "Şenay", :lastname "Sadıç", :department "", :institution "University of Porto", :country "Portugal", :sessions (157)}, 13837 {:firstname "Uwe T.", :lastname "Zimmermann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (72)}, 13863 {:firstname "Ivan", :lastname "Rykov", :department "Theoretical cybernetics", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (23)}, 13866 {:firstname "Florian", :lastname "Sahling", :department "Chair of Production Management", :institution "University of Kaiserslautern", :country "Germany", :sessions (22)}, 13889 {:firstname "Christian", :lastname "Almeder", :department "Chair for Supply Chain Management", :institution "European University Viadrina", :country "Germany", :sessions (22)}, 14031 {:firstname "Robert", :lastname "Klein", :department "Chair of Analytics & Optimization", :institution "University of Augsburg", :country "Germany", :sessions (215)}, 14070 {:firstname "Alfred", :lastname "Taudes", :department "Information Systems and Process Management", :institution "Vienna University of Economics and Business Administration", :country "Austria", :sessions (118)}, 14161 {:firstname "Stefan", :lastname "Kramkowski", :department "Decision Support & OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (70)}, 14274 {:firstname "Guvenc", :lastname "Sahin", :department "Faculty of Engineering and Natural Sciences, Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (156 176 19)}, 14341 {:firstname "Kiyoshi", :lastname "Dowaki", :department "", :institution "Tokyo University of Science", :country "Japan", :sessions (203)}, 14371 {:firstname "Cagatan", :lastname "Taskin", :department "Business Administration", :institution "Uludag University", :country "Turkey", :sessions (155 99)}, 14545 {:firstname "Roland", :lastname "Mestel", :department "Banking and Finance", :institution "University of Graz", :country "Austria", :sessions (86)}, 14573 {:firstname "Ulrich", :lastname "Thonemann", :department "Supply Chain Management", :institution "Universtiy of Cologne", :country "Germany", :sessions (136 122)}, 14587 {:firstname "Pradyumn Kumar", :lastname "Shukla", :department "", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (78)}, 14588 {:firstname "Knut", :lastname "Haase", :department "Institut f. Verkehrswirtschaft, Lehrstuhl BWL, insb. Verkehr", :institution "Universität Hamburg", :country "Germany", :sessions (63)}, 14626 {:firstname "Franziska", :lastname "Feilke", :department "Finanzwirtschaft", :institution "TU Braunschweig", :country "Germany", :sessions (89)}, 14627 {:firstname "Marc", :lastname "Gürtler", :department "Finanzwirtschaft", :institution "TU Braunschweig", :country "Germany", :sessions (89)}, 14637 {:firstname "Ulrich", :lastname "Küsters", :department "Wirtschaftswissenschaftliche Fakultät", :institution "Katholische Universität Eichstätt-Ingolstadt", :country "Germany", :sessions (183 166 182)}, 14660 {:firstname "Johannes", :lastname "Jahn", :department "Department of Mathematics", :institution "University of Erlangen-Nuremberg", :country "Germany", :sessions (78)}, 14667 {:firstname "Bernhard", :lastname "van Bonn", :department "Transportation Logistics", :institution "Fraunhofer Institute for Material Flow and Logistics IML", :country "Germany", :sessions (149)}, 14685 {:firstname "Christian", :lastname "Lohmann", :department "Bergische Universität Wuppertal", :institution "Juniorprofessur für Controlling", :country "Germany", :sessions (81)}, 14704 {:firstname "Felix", :lastname "Hahne", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (75)}, 14705 {:firstname "Curt", :lastname "Nowak", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (75)}, 14707 {:firstname "Christian", :lastname "Bierwirth", :department "", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (103 91 222 58)}, 14709 {:firstname "Philipp", :lastname "Koziol", :department "Fakultät für Wirtschaftswissenschaften", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (119)}, 14713 {:firstname "Frauke", :lastname "Liers", :department "Department Mathematik", :institution "FAU Erlangen-Nuremberg", :country "Germany", :sessions (172 204)}, 14715 {:firstname "Alf", :lastname "Kimms", :department "Mercator School of Management", :institution "University of Duisburg-Essen, Campus Duisburg", :country "Germany", :sessions (136 143 121 75)}, 14720 {:firstname "Irena", :lastname "Okhrin", :department "Juniorprofessur in Information & Operations Management", :institution "European University Viadrina", :country "Germany", :sessions (150)}, 14722 {:firstname "Knut", :lastname "Richter", :department "Faculty of Economics", :institution "St. Petersburg State university", :country "Russian Federation", :sessions (150)}, 14740 {:firstname "Stefan", :lastname "Gnutzmann", :department "GR/VY", :institution "Daimler AG", :country "Germany", :sessions (183)}, 14742 {:firstname "Sigrid", :lastname "Knust", :department "Institute of Computer Science", :institution "University of Osnabrück", :country "Germany", :sessions (46 53)}, 14755 {:firstname "Ulrich", :lastname "Derigs", :department "Information Systems and Operations Research", :institution "University of Cologne", :country "Germany", :sessions (219 67 199 101 61 59 69)}, 14762 {:firstname "Ulrich", :lastname "Vogel", :department "Department of Information Systems and Operations Research", :institution "University of Cologne", :country "Germany", :sessions (69)}, 14770 {:firstname "Peter", :lastname "Köchel", :department "Fakultät für Informatik", :institution "TU Chemnitz", :country "Germany", :sessions (110)}, 14771 {:firstname "Thomas", :lastname "Schlechte", :department " ", :institution "LBW Optimization GmbH", :country "Germany", :sessions (46)}, 14775 {:firstname "Katsuaki", :lastname "Tanaka", :department "Faculty of Business Administration", :institution "Setsunan University", :country "Japan", :sessions (90)}, 14776 {:firstname "Julia", :lastname "Drechsel", :department "Mercator School of Management, Chair of Logistics", :institution "University Duisburg-Essen", :country "Germany", :sessions (121)}, 14778 {:firstname "Jan-Hendrik", :lastname "Jagla", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (101)}, 14780 {:firstname "Klaas", :lastname "Eggert", :department "Institut für Angewandte Mathematik", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (137)}, 14792 {:firstname "Simon", :lastname "Goertz", :department "Faculty of Economics", :institution "University of Wuppertal", :country "Germany", :sessions (31)}, 14797 {:firstname "Frank", :lastname "Schiemann", :department "", :institution "Lehrstuhl Rechnungswesen/Controlling, TU Dresden, Fakultät Wirtschaftswissenschaften", :country "Germany", :sessions (83)}, 14799 {:firstname "Oliver", :lastname "Woll", :department "", :institution "Universitaet Duisburg-Essen", :country "Germany", :sessions (87)}, 14800 {:firstname "Stefan", :lastname "Bock", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (134 31)}, 14801 {:firstname "Lars", :lastname "Fischer", :department "Department of Supply Chain Management and Production", :institution "University of Cologne", :country "Germany", :sessions (117)}, 14803 {:firstname "Klaus ", :lastname "Ambrosi", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "Universität Hildesheim", :country "Germany", :sessions (75)}, 14810 {:firstname "Ursula", :lastname "Walther", :department "FB 1", :institution "Berlin School of Economics and Law", :country "Germany", :sessions (84 90)}, 14813 {:firstname "Christoph", :lastname "Bode", :department "Lehrstuhl für Logistikmanagement", :institution "WHU - Otto Beisheim School of Management", :country "Germany", :sessions (119)}, 14817 {:firstname "Ralph", :lastname "Grothmann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (182)}, 14818 {:firstname "Hans Georg", :lastname "Zimmermann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (210 182)}, 14828 {:firstname "Thorsten", :lastname "Gather", :department "Operations Research Group", :institution "Clausthal Institute of Technology", :country "Germany", :sessions (55)}, 14838 {:firstname "Bastian", :lastname "Felix", :department "", :institution "Universitaet Duisburg-Essen", :country "Germany", :sessions (130)}, 14845 {:firstname "Christoph", :lastname "Weber", :department "", :institution "Universität Essen", :country "Germany", :sessions (87 130)}, 14847 {:firstname "Andreas", :lastname "Klose", :department "Department of Mathematics", :institution "Aarhus University", :country "Denmark", :sessions (95)}, 14851 {:firstname "André", :lastname "Hintsches", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (136)}, 14853 {:firstname "Franz", :lastname "Nelissen", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (102)}, 14856 {:firstname "Francesco", :lastname "Ferrucci", :department "WINFOR (Business Computing and Operations Research)", :institution "University of Wuppertal", :country "Germany", :sessions (31)}, 14863 {:firstname "Alexander", :lastname "Richter", :department "Business Administration and Production Management", :institution "Ruhr University Bochum", :country "Germany", :sessions (143)}, 14865 {:firstname "Marion", :lastname "Steven", :department "Business Administration and Production Management", :institution "Ruhr-University Bochum", :country "Germany", :sessions (137 143 146)}, 14869 {:firstname "Martin", :lastname "Albrecht", :department "Process and Information Management", :institution "Paul Hartmann AG", :country "Germany", :sessions (114)}, 14870 {:firstname "Anne", :lastname "Schatka", :department "Institut für Produktion und Logistik", :institution "TU Braunschweig", :country "Germany", :sessions (113)}, 14873 {:firstname "Michael", :lastname "Klier", :department "Institute for Transport and Economics", :institution "TU Dresden", :country "Germany", :sessions (63)}, 14883 {:firstname "Tobias", :lastname "Schulz", :department "Chair for Production and Logistics", :institution "Otto-von-Guericke University Magdeburg", :country "Germany", :sessions (112)}, 14887 {:firstname "Ralf", :lastname "Stecking", :department "Fakultät II - Institut für VWL und Statistik", :institution "Universität Oldenburg", :country "Germany", :sessions (96)}, 14890 {:firstname "Andreas", :lastname "Kleine", :department "Operations Research", :institution "FernUniversität in Hagen (University of Hagen)", :country "Germany", :sessions (127)}, 14917 {:firstname "Christoph", :lastname "Buchheim", :department "Fakultät für Mathematik", :institution "Technische Universität Dortmund", :country "Germany", :sessions (172)}, 14923 {:firstname "Ralf", :lastname "Borndörfer", :department "Optimization", :institution "Zuse-Institute Berlin", :country "Germany", :sessions (46 192 195 70)}, 14924 {:firstname "Jörg", :lastname "Wansart", :department "", :institution "Institute for Production and Logistics Management", :country "Germany", :sessions (94)}, 14943 {:firstname "Hideki", :lastname "Katsuda", :department "School of Business Administration", :institution "Kinki University", :country "Japan", :sessions (90)}, 14946 {:firstname "Christoph", :lastname "Tietz", :department "Corporate Technology, CT IC 4", :institution "Siemens AG", :country "Germany", :sessions (210 182)}, 14952 {:firstname "Markus", :lastname "Meiler", :department "Production Management", :institution "Technical University Berlin", :country "Germany", :sessions (49)}, 14955 {:firstname "Klaus Bruno", :lastname "Schebesch", :department "Faculty ofEconomics, Filiala Zalau", :institution "Vasile Goldis University, Arad, RO", :country "Romania", :sessions (96)}, 14957 {:firstname "Marius", :lastname "Radulescu", :department "Mathematical Statistics", :institution "Institute of Mathematical Statistics and Applied Mathematics", :country "Romania", :sessions (129)}, 14969 {:firstname "Marco", :lastname "Lübbecke", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (175 16 58 19)}, 14973 {:firstname "Michael", :lastname "Drexl", :department "", :institution ".", :country "Germany", :sessions (20)}, 14976 {:firstname "Jens", :lastname "Schulz", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (175)}, 14979 {:firstname "Konstantin", :lastname "Horstmann", :department "Transportation Logistics", :institution "Fraunhofer IML", :country "Germany", :sessions (149)}, 15003 {:firstname "Thomas", :lastname "Guenther", :department "Lehrstuhl Rechnungswesen/Controlling", :institution "TU Dresden, Fakultät Wirtschaftswissenschaften", :country "Germany", :sessions (83 88)}, 15045 {:firstname "Daniel", :lastname "Kilimann", :department "Lehrstuhl für Wirtschaftsinformatik & OR", :institution "Universität Duisburg Essen", :country "Germany", :sessions (107)}, 15058 {:firstname "Marcus", :lastname "Oswald", :department "", :institution "University of Heidelberg", :country "Germany", :sessions (172)}, 15059 {:firstname "Marika", :lastname "Neumann", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (195)}, 15118 {:firstname "Hans-Otto", :lastname "Guenther", :department "Industrial Engineering", :institution "Pusan National University", :country "Korea, Republic of", :sessions (118)}, 15150 {:firstname "Christian", :lastname "Viergutz", :department "Institut für Informatik", :institution "Universität Osnabrück", :country "Germany", :sessions (50)}, 15154 {:firstname "Joachim R.", :lastname "Daduna", :department "", :institution "Hochschule für Wirtschaft und Recht Berlin Berlin", :country "Germany", :sessions (52)}, 15178 {:firstname "Kerstin", :lastname "Schmidt", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (119)}, 15182 {:firstname "Urs", :lastname "Pietschmann", :department "Faculty of Management and Economics", :institution "Ruhr-University Bochum", :country "Germany", :sessions (143)}, 15188 {:firstname "Jenny", :lastname "Steinborn", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (203)}, 15195 {:firstname "Harald", :lastname "Uhlemair", :department "Chair of Production and Logistics", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (139)}, 15197 {:firstname "Michael", :lastname "Schroeder", :department "Optimization", :institution "Fraunhofer Institute for Industrial Mathematics", :country "Germany", :sessions (24)}, 15233 {:firstname "Behrooz", :lastname "Alizadeh", :department "Department of Mathematics", :institution "Sahand University of Technology", :country "Iran, Islamic Republic of", :sessions (205 206)}, 15277 {:firstname "Herbert", :lastname "Kopfer", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (64 164)}, 15313 {:firstname "Erdal", :lastname "Emel", :department "Industrial Engineering Department", :institution "Uludag University", :country "Turkey", :sessions (156)}, 15322 {:firstname "Alkin", :lastname "Yurtkuran", :department "Industrial Engineering Department", :institution "Uludag University", :country "Turkey", :sessions (156)}, 15326 {:firstname "Liji", :lastname "Shen", :department "", :institution "WHU -- Otto Beisheim School of Management", :country "Germany", :sessions (54)}, 15361 {:firstname "Jörg", :lastname "Wiese", :department "DS&OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (58)}, 15362 {:firstname "Esther", :lastname "Mohr", :department "Advanced Business Analytics", :institution "BASF Business Services GmbH", :country "Germany", :sessions (89)}, 15364 {:firstname "Robert", :lastname "Fildes", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (166)}, 15375 {:firstname "Ronny", :lastname "Hansmann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (72)}, 15381 {:firstname "Andreas", :lastname "Thümmel", :department "FB MN", :institution "Hochschule Darmstadt", :country "Germany", :sessions (157)}, 15390 {:firstname "Kai", :lastname "Wittek", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (136)}, 15410 {:firstname "Hans-Ulrich ", :lastname "Küpper", :department "Institut für Produktionswirtschaft und Controlling", :institution "Ludwig-Maximilians-Universität München", :country "Germany", :sessions (223 225)}, 15433 {:firstname "Karl-Heinz", :lastname "Küfer", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (24 63 16)}, 15649 {:firstname "Lea M.", :lastname "Wakolbinger", :department "Department of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (106)}, 16315 {:firstname "Armin", :lastname "Fügenschuh", :department "MINT", :institution "Brandenburg Technical University", :country "Germany", :sessions (46 199 17 71)}, 16566 {:firstname "Ramin", :lastname "Sahamie", :department "Lehrstuhl für Produktion und Logistik", :institution "Universität Augsburg", :country "Germany", :sessions (177 212)}, 16581 {:firstname "Susanne E.", :lastname "Zapp", :department "Business Administration and Production Management", :institution "Ruhr-University Bochum", :country "Germany", :sessions (137)}, 16597 {:firstname "Igor", :lastname "Grebennik", :department "Systems Engineering", :institution "Kharkiv National University of Radio Electronics", :country "Ukraine", :sessions (18)}, 16606 {:firstname "Jörg", :lastname "Rambau", :department "Fakultät für Mathematik, Physik und Informatik", :institution "LS Wirtschaftsmathematik", :country "Germany", :sessions (14 168)}, 16621 {:firstname "Xi", :lastname "Chen", :department "Management Science", :institution "Lancaster University Management School", :country "United Kingdom", :sessions (183)}, 16633 {:firstname "Sergey", :lastname "Astrakov", :department "", :institution "Design Technological Institute of Digital Techniques, Novosibirsk State University", :country "Russian Federation", :sessions (181)}, 16639 {:firstname "Sven", :lastname "Müller", :department "Transport Business Economics", :institution "Karlsruhe University of Applied Sciences", :country "Germany", :sessions (149)}, 16655 {:firstname "Janne", :lastname "Roslof", :department "School of Telecommunication and e-Business", :institution "Turku University of Applied Sciences", :country "Finland", :sessions (50)}, 16656 {:firstname "Sergey", :lastname "Lavlinskiy", :department "Operations Research Department", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (102)}, 16660 {:firstname "Frank", :lastname "Pettersson", :department "Heat Engineering Laboratory", :institution "Åbo Akademi University", :country "Finland", :sessions (50)}, 16668 {:firstname "Carl", :lastname "Johnzen", :department "CMP-Georges Charpak", :institution "Ecole des Mines de Saint-Etienne", :country "France", :sessions (148)}, 16672 {:firstname "Stefan", :lastname "Theussl", :department "Raiffeisen RESEARCH", :institution "Raiffeisen Bank International AG", :country "Austria", :sessions (98)}, 16680 {:firstname "Andrew", :lastname "Sun", :department "UTIAS", :institution "University of Toronto", :country "Canada", :sessions (190)}, 16687 {:firstname "Richard", :lastname "Vahrenkamp", :department "Dep. Economics and Management", :institution "University of Kassel", :country "Germany", :sessions (201)}, 16697 {:firstname "Luca", :lastname "Urciuoli", :department "Industrial Management Engineering Logistics", :institution "Lund University of Technology", :country "Sweden", :sessions (72)}, 16717 {:firstname "Cornelius", :lastname "Schwarz", :department "Chair of Business Mathematics", :institution "University of Bayreuth", :country "Germany", :sessions (14)}, 16744 {:firstname "Rakesh", :lastname "Verma", :department "Operations management Group", :institution "NITIE", :country "India", :sessions (211)}, 16752 {:firstname "Roland", :lastname "Hesse", :department "", :institution "mentz datenverarbeitung", :country "Germany", :sessions (16)}, 16780 {:firstname "Vahid", :lastname "Hashemi", :department "Mathematics,Statistics and Computer science", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (45)}, 16782 {:firstname "Anastasia", :lastname "Shakhshneyder", :department "Mechanic-Mathematical department", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (77)}, 16785 {:firstname "Aleksandra", :lastname "Marcikic", :department "", :institution "University of Novi Sad, Faculty of Economics Subotica", :country "Serbia", :sessions (110)}, 16792 {:firstname "Nina", :lastname "Kochetova", :department "Operation Research ", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (205)}, 16795 {:firstname "Dirk", :lastname "Simons", :department "", :institution "University of Mannheim", :country "Germany", :sessions (84 88)}, 16796 {:firstname "Matthias", :lastname "Tinkl", :department "Diskrete Mathematik, Optimierung und Operations Research ", :institution "Institut für Mathematik", :country "Germany", :sessions (172)}, 16798 {:firstname "Kanthen K", :lastname "Harikrishnan", :department "School of Applied Mathematics Faculty of Enggineering", :institution "Nottingham University Malaysia Campus", :country "Malaysia", :sessions (121)}, 16806 {:firstname "Taras", :lastname "Beschastnyi", :department "Applied Mathematics", :institution "Dnipropetrovsk National University", :country "Ukraine", :sessions (18)}, 16808 {:firstname "Krystsina", :lastname "Bakhrankova", :department "Applied economics", :institution "SINTEF - Technology and society", :country "Norway", :sessions (146)}, 16817 {:firstname "Kerstin", :lastname "Lange", :department "", :institution "ISL  - Institute of Shipping Economics and Logistics", :country "Germany", :sessions (32)}, 16821 {:firstname "Martin", :lastname "Lätsch", :department "Zentrum für Angewandte Informatik (ZAIK) ", :institution "Universität zu Köln ", :country "Germany", :sessions (18)}, 16829 {:firstname "Mahboobeh", :lastname "Sheikh Sajadieh", :department "Department of Industrial Engineering", :institution "Islamic Azad University-South Branch", :country "Iran, Islamic Republic of", :sessions (120)}, 16830 {:firstname "Georg", :lastname "Mikula", :department "Finance and Accounting", :institution "Vienna University of Economics and Business Administration", :country "Austria", :sessions (85)}, 16831 {:firstname "Tomas", :lastname "Kana", :department "Finance and Accounting", :institution "Vienna University for Economics and Business Administration", :country "Austria", :sessions (85)}, 16844 {:firstname "Maik", :lastname "Wagner", :department "", :institution "Friedrich Schiller University Jena", :country "Germany", :sessions (90)}, 16845 {:firstname "Fahimeh", :lastname "Baroughi Bonab", :department "Institute of  Mathematics B", :institution "Graz University of Technology", :country "Austria", :sessions (205)}, 16852 {:firstname "Marco", :lastname "Schutten", :department "MB / OMPL", :institution "University of Twente", :country "Netherlands", :sessions (134)}, 16854 {:firstname "Mohammad Ebrahim", :lastname "Nikoofal", :department "Department of Industrial Engineering", :institution "Iran University of Science and Technology", :country "Iran, Islamic Republic of", :sessions (139)}, 16855 {:firstname "Gerald", :lastname "Hubmann", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (156)}, 16856 {:firstname "Christopher", :lastname "Schwand", :department "", :institution "IMC Fachhochschule Krems", :country "Austria", :sessions (106)}, 16857 {:firstname "Ulrich", :lastname "Schäfer", :department "Lehrstuhl für Controlling", :institution "Philipps-Universität Marburg", :country "Germany", :sessions (82)}, 16866 {:firstname "Ronja", :lastname "Walter", :department "Statistik", :institution "TU Dortmund", :country "Germany", :sessions (90)}, 16867 {:firstname "Swaantje", :lastname "Casjens", :department "", :institution "TU Dortmund", :country "Germany", :sessions (90)}, 16869 {:firstname "Thomas", :lastname "Mollenhauer", :department "", :institution "TU Dortmund", :country "Germany", :sessions (90)}, 16870 {:firstname "Katja", :lastname "Schimmelpfeng", :department "Lehrstuhl für Beschaffung und Produktion", :institution "Universität Hohenheim", :country "Germany", :sessions (147)}, 16872 {:firstname "Farhad", :lastname "Hassanzadeh", :department "Department of Industrial Engineering", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (139 19 142)}, 16873 {:firstname "Ingmar", :lastname "Schüle", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (63)}, 16874 {:firstname "Waldemar", :lastname "Grzechca", :department "Faculty of Automatic Control, Electronics and Computer Science", :institution "The Silesian University of Technology", :country "Poland", :sessions (57)}, 16875 {:firstname "Manuel", :lastname "Wittmann", :department "Fakultät für Betriebswirtschaft, Lehrstuhl Rechnungswesen und Controlling", :institution "Hochschule München", :country "Germany", :sessions (86)}, 16877 {:firstname "Philipp", :lastname "Melchiors", :department "Lehrstuhl für technische Dienstleistungen und Operations Management", :institution "Technische Universität München: Fakultät für Wirtschaftswissenschaften", :country "Germany", :sessions (56)}, 16880 {:firstname "Timo", :lastname "Berthold", :department "", :institution "Fair Isaac Germany GmbH", :country "Germany", :sessions (176)}, 16882 {:firstname "Paulauskas", :lastname "Vytautas", :department "Shipping", :institution "Klaipeda university", :country "Lithuania", :sessions (32)}, 16883 {:firstname "Guenter", :lastname "Fandel", :department "FernUniversitaet in Hagen, Fakultaet fuer Wirtschaftswissenschaft", :institution "Zentrum fuer Produktionsoekonomie und Entscheidungsmanagement", :country "Germany", :sessions (190)}, 16884 {:firstname "Jens", :lastname "Kanacher", :department "", :institution "Ruhr Universität Bochum", :country "Germany", :sessions (89)}, 16885 {:firstname "Li", :lastname "Ding", :department "Durham business school", :institution "Durham University", :country "United Kingdom", :sessions (93)}, 16887 {:firstname "Jan", :lastname "Trockel", :department "FernUniversität in Hagen", :institution "Center for Production Economics and Decision Support", :country "Germany", :sessions (190)}, 16888 {:firstname "Frauke", :lastname "Böckmann", :department "Department of Mathematics/Computer Science", :institution "University of Osnabrueck", :country "Germany", :sessions (53)}, 16889 {:firstname "Silvia", :lastname "Schwarze", :department "Institute of Information Systems", :institution "University of Hamburg", :country "Germany", :sessions (73)}, 16890 {:firstname "Nicole", :lastname "Nowak", :department "", :institution "TU Darmstadt", :country "Germany", :sessions (24)}, 16891 {:firstname "Alcinda", :lastname "Barreiras", :department "Mathematic", :institution "ISEP", :country "Portugal", :sessions (195)}, 16893 {:firstname "Arne Karsten", :lastname "Strauss", :department "Warwick Business School", :institution "University of Warwick", :country "United Kingdom", :sessions (52)}, 16894 {:firstname "Ingo", :lastname "Althofer", :department "Institut Angewandte Mathematik", :institution "Fakultaet Mathematik und Informatik", :country "Germany", :sessions (104)}, 16898 {:firstname "Magdalena", :lastname "Missler-Behr", :department "BTU Cottbus", :institution "LST für Planung und Innovationsmanagement", :country "Germany", :sessions (155 106)}, 16904 {:firstname "Martin", :lastname "Berger", :department "Optimization", :institution "Fraunhofer Institute for Industrial Mathematics", :country "Germany", :sessions (24 16)}, 16911 {:firstname "Melanie", :lastname "Bloos", :department "Chair of Logistics", :institution "Bremen University", :country "Germany", :sessions (64)}, 16912 {:firstname "Hermann", :lastname "Jahnke", :department "Fakultät für Wirtschaftswissenschaften", :institution "Universität Bielefeld", :country "Germany", :sessions (84)}, 16916 {:firstname "Sarah ", :lastname "Bretschneider", :department "Mercator School of Management - Fachbereich Betriebswirtschaft", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (75)}, 16917 {:firstname "Lok Lam", :lastname "Mak", :department "", :institution "University of Osnabrueck", :country "Germany", :sessions (53)}, 16918 {:firstname "Martin", :lastname "Stöcker", :department "Fakultät Mathematik, Professur Wirtschaftsmathematik", :institution "Technische Universität Chemnitz", :country "Germany", :sessions (79)}, 16919 {:firstname "Jan Fabian", :lastname "Ehmke", :department "Management Science", :institution "Otto-von-Guericke University", :country "Germany", :sessions (51)}, 16920 {:firstname "Nadine", :lastname "Vorsatz", :department "", :institution "FHTW Berlin", :country "Germany", :sessions (83)}, 16921 {:firstname "Michaela", :lastname "Hoehn", :department "Production Management", :institution "WHU - Otto Beisheim School of Management", :country "Germany", :sessions (112)}, 16923 {:firstname "Guntram", :lastname "Scheithauer", :department "Mathematik", :institution "Technische Universität Dresden", :country "Germany", :sessions (179)}, 16924 {:firstname "Marcus", :lastname "Schröter", :department "Industry and Service Innovations", :institution "Fraunhofer Institut for Systems and Innovation Research", :country "Germany", :sessions (143)}, 16925 {:firstname "Kirsten", :lastname "Seeger", :department "Faculty of Business and Economics, Chair of Business Management, esp Industrial Management ", :institution "TU Dresden", :country "Germany", :sessions (93)}, 16926 {:firstname "Thomas", :lastname "Strecker", :department "DAI-Labor", :institution "Technische Universität Berlin", :country "Germany", :sessions (178)}, 16927 {:firstname "Leonhard", :lastname "Hennig", :department "DAI-Labor", :institution "Technische Universität Berlin", :country "Germany", :sessions (178)}, 16928 {:firstname "Utz-Uwe", :lastname "Haus", :department "", :institution "Cray EMEA Research Lab", :country "Switzerland", :sessions (17 204)}, 16929 {:firstname "Kathrin", :lastname "Niermann", :department "FMA-IMO", :institution "Otto-von-Guericke University Magdeburg", :country "Germany", :sessions (204)}, 16934 {:firstname "Guido", :lastname "Voigt", :department "Production and Logistic", :institution "Otto-von-Guericke University", :country "Germany", :sessions (112)}, 16938 {:firstname "Victor", :lastname "Izhutkin", :department "Applied Mathematik", :institution "National Research University Moscow Power  Engineering Institute", :country "Russian Federation", :sessions (104)}, 16945 {:firstname "Ayfer", :lastname "Basar", :department "Industrial Engineering ", :institution "Istanbul Technical University ", :country "Turkey", :sessions (91)}, 16946 {:firstname "Farzad", :lastname "Dehghanian", :department "department of Industrial engineering", :institution "Amirkabir university of technology", :country "Iran, Islamic Republic of", :sessions (113)}, 16949 {:firstname "Udo", :lastname "Buscher", :department "Industrial Management", :institution "TU Dresden", :country "Germany", :sessions (54)}, 16953 {:firstname "Michael", :lastname "Bock", :department "Banken und Finanzierung", :institution "Karl-Franzens-Universität Graz", :country "Austria", :sessions (86)}, 16955 {:firstname "Anna", :lastname "Krasnosielska", :department "Faculty of Mathematics and Information Science", :institution "Warsaw University of Technology", :country "Poland", :sessions (131 181)}, 16960 {:firstname "Sohrab", :lastname "khatabakhsh", :department "Industrial Eng.", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (128)}, 16961 {:firstname "Alexander", :lastname "Kurochkin", :department "mechanic-mathematical ", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (95)}, 16962 {:firstname "Dominik", :lastname "Schreiber", :department "", :institution "Georg-August University of Göttingen", :country "Germany", :sessions (82)}, 16963 {:firstname "Heidrun", :lastname "Rosic", :department "Institute for Production Management", :institution "Vienna University of Economics and Business Administration", :country "Austria", :sessions (113)}, 16964 {:firstname "Sascha", :lastname "Wohlgemuth", :department "Lehrstuhl für Verkehrssysteme und -logistik", :institution "Technische Universität Dortmund", :country "Germany", :sessions (52)}, 16965 {:firstname "Mohammad Bagher", :lastname "Ahmadi", :department "Mathematics", :institution "Shiraz University", :country "Iran, Islamic Republic of", :sessions (103)}, 16966 {:firstname "Felix", :lastname "Pottmeyer", :department "DS & OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (67)}, 16967 {:firstname "Anton", :lastname "Rudnev", :department "Department of Mathematics and Mechanics", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (178)}, 16970 {:firstname "Christian", :lastname "Meier", :department "", :institution "University of Paderborn", :country "Germany", :sessions (70)}, 16971 {:firstname "Lars", :lastname "Hackstein", :department "Transportation Logistics", :institution "Fraunhofer Institute for Material Flow and Logistics", :country "Germany", :sessions (70)}, 16972 {:firstname "Nam Dung", :lastname "Hoang", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (192)}, 16973 {:firstname "Christian Andreas", :lastname "Hochmuth", :department "Manufacturing Coordination and Technology", :institution "Bosch Rexroth AG", :country "Germany", :sessions (110)}, 16974 {:firstname "Kamran", :lastname "Rezaie", :department "", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (128)}, 16975 {:firstname "Holger", :lastname "Flier", :department "Institute of Theoretical Computer Science", :institution "ETH Zürich", :country "Switzerland", :sessions (196)}, 16977 {:firstname "Hamidreza", :lastname "Koosha", :department "Industrial Engineering Faculty", :institution "Ferdowsi University of Mashhad", :country "Iran, Islamic Republic of", :sessions (139)}, 16980 {:firstname "Carlos", :lastname "Cardonha", :department "", :institution "IBM Research", :country "Brazil", :sessions (70)}, 16981 {:firstname "Frederik", :lastname "Bauer", :department "Empirical Economics and Applied Statistics", :institution "Bremen University ", :country "Germany", :sessions (185)}, 16982 {:firstname "Raymond", :lastname "Hemmecke", :department "Institut für Mathematische Optmimierung", :institution "Universität Magdeburg", :country "Germany", :sessions (17)}, 16983 {:firstname "Dennis", :lastname "Michaels", :department "Institute for Operations Research", :institution "ETH Zuerich", :country "Switzerland", :sessions (17)}, 16984 {:firstname "Khoa", :lastname "Vo", :department "", :institution "Institute of Computer Science, University of Heidelberg", :country "Germany", :sessions (20)}, 16985 {:firstname "Anton", :lastname "Savchenko", :department "Institut für Mathematische Optimierung", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (17)}, 16987 {:firstname "Florian", :lastname "Bruns", :department "Institute of Computer Science", :institution "University of Osnabrück", :country "Germany", :sessions (46)}, 16988 {:firstname "Frank", :lastname "Fischer", :department "Mathematics and Natural Sciences", :institution "University of Kassel", :country "Germany", :sessions (71)}, 16989 {:firstname "Ömer", :lastname "Akat", :department "", :institution "", :country "Afghanistan", :sessions (99)}, 16992 {:firstname "Ibrahim", :lastname "Muter", :department "School of Management", :institution "University of Bath", :country "United Kingdom", :sessions (156 176 19)}, 16995 {:firstname "Gregory", :lastname "Hunter", :department "Centre for Operational Research and Analysis", :institution "Defence Research and Development Canada", :country "Canada", :sessions (171)}, 16999 {:firstname "Elena", :lastname "Kopylova", :department "", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (171)}, 17000 {:firstname "Dmitry", :lastname "Ivnitsky", :department "", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (171)}, 17004 {:firstname "Martin", :lastname "Missong", :department "FB07 Wirtschaftswissenschaft", :institution "Universität Bremen", :country "Germany", :sessions (185)}, 17005 {:firstname "Andreas", :lastname "Fritz", :department "", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (87 130)}, 17008 {:firstname "Carsten", :lastname "Böhle", :department "Wirtschaftsinformatik, insb. CIM", :institution "Universität Paderborn", :country "Germany", :sessions (68)}, 17011 {:firstname "Tetyana", :lastname "Shevchenko", :department "Calculating Mathematics and Mathematical Cybernetics", :institution "Dnepropetrovsk National University, the faculty of applied mathematics", :country "Ukraine", :sessions (137)}, 17015 {:firstname "Alexey", :lastname "Martyushev", :department "", :institution "None", :country "Russian Federation", :sessions (201)}, 17017 {:firstname "Naoyuki", :lastname "Kamiyama", :department "Architecture and Architectural Engineering", :institution "Kyoto University", :country "Japan", :sessions (195)}, 17020 {:firstname "Tobias", :lastname "von Martens", :department "Fakultät Wirtschaftswissenschaften", :institution "TU Dresden", :country "Germany", :sessions (99)}, 17021 {:firstname "Uwe", :lastname "Nowak", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (16)}, 17022 {:firstname "Andreas", :lastname "Hilbert", :department "Fakultät Wirtschaftswissenschaften", :institution "Technische Universität  Dresden", :country "Germany", :sessions (99)}, 17023 {:firstname "Philipp", :lastname "Baumann", :department "Department of Industrial Engineering and Operations Research", :institution "University of California, Berkeley", :country "United States", :sessions (55)}, 17025 {:firstname "Jacek", :lastname "Juraszek", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (57)}, 17026 {:firstname "Daniel", :lastname "Potthoff", :department "Econometric Institute", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (199)}, 17028 {:firstname "Matthias", :lastname "Peinhardt", :department "Faculty of Mathematics (IMO)", :institution "University Magdeburg", :country "Germany", :sessions (176)}, 17029 {:firstname "Elisabeth", :lastname "von Jagwitz", :department "", :institution "Universität zu Köln", :country "Germany", :sessions (59)}, 17031 {:firstname "Sergey", :lastname "Yurkevich", :department "", :institution "Ramax International", :country "Russian Federation", :sessions (201)}, 17032 {:firstname "Daniel", :lastname "Scholz", :department "Fakultät für Mathematik", :institution "Georg-August Universität Göttingen", :country "Germany", :sessions (206 78)}, 17034 {:firstname "U. Mahir", :lastname "Yıldırım", :department "Industrial Engineering", :institution "Istanbul Bilgi University", :country "Turkey", :sessions (69)}, 17035 {:firstname "Katharina", :lastname "Reuter", :department "", :institution "University of Cologne", :country "Germany", :sessions (69)}, 17036 {:firstname "Jürgen", :lastname "Bloech ", :department "Chair of Production and Logistics", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (104)}, 17037 {:firstname "Thouraya", :lastname "Benna", :department "Department for Economics and Social Sciences, Production and Logistics", :institution "University of Natural Resources and Applied Life Sciences, Vienna", :country "Austria", :sessions (73)}, 17039 {:firstname "Rainer", :lastname "Kleber", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University of Magdeburg", :country "Germany", :sessions (112 121)}, 17040 {:firstname "Duygu", :lastname "Tas", :department "Department of Industrial Engineering", :institution "MEF University", :country "Turkey", :sessions (176 19)}, 17041 {:firstname "Andreas", :lastname "Fischer", :department "Department of Mathematics", :institution "Technische Universität Dresden", :country "Germany", :sessions (78)}, 17042 {:firstname "Robert", :lastname "Scheffermann", :department "", :institution "FZI Forschungszentrum Informatik", :country "Germany", :sessions (69)}, 17043 {:firstname "Werner", :lastname "Heid", :department "", :institution "PTV AG", :country "Germany", :sessions (69)}, 17044 {:firstname "Dorota", :lastname "Marciniak", :department "", :institution "Polish Academy of Sciences", :country "Poland", :sessions (181)}, 17045 {:firstname "Frank", :lastname "Radaschewski", :department "Software Development Logistics", :institution "PTV AG", :country "Germany", :sessions (69)}, 17047 {:firstname "Frank", :lastname "Schwaderer", :department "Institute for Industrial Production (IIP)", :institution "Universitaet Karlsruhe (TH)", :country "Germany", :sessions (92)}, 17048 {:firstname "Stefanie", :lastname "Öhl", :department "Institute of Computer and Communication Network Engineering", :institution "Technical University of Braunschweig", :country "Germany", :sessions (119)}, 17050 {:firstname "Mark", :lastname "Rempel", :department "Centre for Operational Research and Analysis", :institution "Defence Research and Development Canada", :country "Canada", :sessions (171)}, 17052 {:firstname "Michaela", :lastname "Graf", :department "Mercator School of Management, Chair of Logistics", :institution "University Duisburg-Essen", :country "Germany", :sessions (136)}, 17055 {:firstname "Joachim", :lastname "Schauer", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (204)}, 17056 {:firstname "Martin", :lastname "Schwardt", :department "", :institution "Lübecker Hafen-Gesellschaft mbH", :country "Germany", :sessions (34)}, 17057 {:firstname "Jan", :lastname "Eickmann", :department "Information Systems and Operations Research", :institution "University of Cologne", :country "Germany", :sessions (101)}, 17058 {:firstname "Larysa", :lastname "Koriashkina", :department "Calculating Mathematics and Mathematical Cybernetics", :institution "Dnepropetrovsk National University, the faculty of applied mathematics", :country "Ukraine", :sessions (137)}, 17059 {:firstname "Elena", :lastname "Kiseleva", :department "Calculating Mathematics and Mathematical Cybernetics", :institution "Dnepropetrovsk National University, the faculty of applied mathematics", :country "Ukraine", :sessions (137)}, 17060 {:firstname "Max", :lastname "Mihm", :department "Lehrstuhl für Finanzwirtschaft und Finanzdienstleistungen", :institution "TU Dresden", :country "Germany", :sessions (85)}, 17063 {:firstname "Rico", :lastname "Zenklusen", :department "Department of Mathematics", :institution "ETH Zurich", :country "Switzerland", :sessions (196 140)}, 17064 {:firstname "Levente", :lastname "Mályusz", :department "Construction Management and Technology", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (55)}, 17066 {:firstname "Gerd", :lastname "Finke", :department "", :institution "University Joseph Fourier", :country "France", :sessions (45)}, 17071 {:firstname "Christine", :lastname "Hayn", :department "Discrete Optimization, Mathematics", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (199 17)}, 17072 {:firstname "Jonas", :lastname "Tornberg", :department "City and Mobility", :institution "School of Architecture", :country "Sweden", :sessions (72)}, 17073 {:firstname "Valentina", :lastname "Avrutova", :department "DS & OR Lab", :institution "Paderborn University", :country "Germany", :sessions (63)}, 17075 {:firstname "Hans", :lastname "Daduna", :department "Department of Mathematics", :institution "University of Hamburg", :country "Germany", :sessions (132)}, 17076 {:firstname "Bernd", :lastname "Luderer", :department "Professur für Wirtschaftsmathematik", :institution "TU Chemnitz", :country "Germany", :sessions (79)}, 17077 {:firstname "Tobias", :lastname "Kley", :department "Quantitative Methoden der Wirtschaftsinformatik", :institution "Westfälische Wilhelms-Universität Münster", :country "Germany", :sessions (96)}, 17079 {:firstname "Bernd-Ludwig", :lastname "Wenning", :department "Communication Networks", :institution "University of Bremen", :country "Germany", :sessions (60)}, 17082 {:firstname "Carmelita", :lastname "Görg", :department "", :institution "University of Bremen", :country "Germany", :sessions (60)}, 17083 {:firstname "Marc", :lastname "Pfetsch", :department "Discrete Optimization", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (176 195)}, 17084 {:firstname "Hadi", :lastname "Panahi", :department "Department of Industrail Engineering", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (103 206 59)}, 17085 {:firstname "Leopold", :lastname "Sögner", :department "Economics and Finance", :institution "Institute of Advanced Studies", :country "Austria", :sessions (185)}, 17086 {:firstname "Hamidreza", :lastname "Moheghi", :department "Industrial Engineering", :institution "University of Bojnord", :country "Iran, Islamic Republic of", :sessions (142)}, 17087 {:firstname "Rolf", :lastname "Ernst", :department "Institute of Computer and Communication Network Engineering", :institution "Technical University of Braunschweig", :country "Germany", :sessions (119)}, 17088 {:firstname "Elvin", :lastname "Coban", :department "Industrial Engineering ", :institution "Sabanci University", :country "Turkey", :sessions (176 19)}, 17089 {:firstname "Achim", :lastname "Zeileis", :department "Department of Statistics and Mathematics", :institution "Wirtschaftsuniversität Wien", :country "Austria", :sessions (94)}, 17090 {:firstname "Marcus", :lastname "Schweitzer", :department "Fachbereich 5", :institution "University of Siegen", :country "Germany", :sessions (141)}, 17091 {:firstname "Husnu", :lastname "Yenigun", :department "", :institution "Sabanci University", :country "Turkey", :sessions (176 19)}, 17092 {:firstname "Christina", :lastname "Büsing", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (19)}, 17093 {:firstname "Angela", :lastname "Herrmann", :department "Department of Business Administration", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (91)}, 17095 {:firstname "Yvan", :lastname "Nieto", :department "Enterprise Institute", :institution "University of Neuchâtel", :country "Switzerland", :sessions (113)}, 17096 {:firstname "Ozgur", :lastname "Gurbuz", :department "Faculty of Engineering and Natural Sciences", :institution "Sabanci University", :country "Turkey", :sessions (206)}, 17097 {:firstname "Figen", :lastname "Öztoprak", :department "Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (79)}, 17098 {:firstname "Ralf", :lastname "Wagner", :department "Int. Direct Marketing", :institution "University of Kassel", :country "Germany", :sessions (99)}, 17101 {:firstname "Trond", :lastname "Hammervoll", :department "", :institution "Harstad University College", :country "Norway", :sessions (73)}, 17103 {:firstname "Christian", :lastname "Lerch", :department "Industrial and Service Innovations", :institution "Fraunhofer Institute for Systems and Innovation Research", :country "Germany", :sessions (143)}, 17104 {:firstname "Ak&#305;n", :lastname "Günay", :department "Computer Engineering", :institution "Bo&#287;aziçi University", :country "Turkey", :sessions (79)}, 17105 {:firstname "Gerald", :lastname "Reiner", :department "Department of Information Systems and Operations", :institution "Vienna University of Economics and Business", :country "Austria", :sessions (113)}, 17106 {:firstname "Pinar", :lastname "Yolum", :department "", :institution "", :country "Turkey", :sessions (79)}, 17107 {:firstname "Dirk", :lastname "König", :department "", :institution "Rechenzentrum für Versorgungsnetze Wehr GmbH", :country "Germany", :sessions (127)}, 17108 {:firstname "Hooman", :lastname "Malekly", :department "Department of Industrial Engineering", :institution "Islamic Azad University - South Tehran Branch", :country "Iran, Islamic Republic of", :sessions (103 206)}, 17109 {:firstname "Carolin", :lastname "Püttmann", :department "Institut für Logistik und Transport", :institution "Universität Hamburg", :country "Germany", :sessions (61)}, 17110 {:firstname "Ralf", :lastname "Bihlmaier", :department "Research & Development", :institution "Daimler AG", :country "Germany", :sessions (116)}, 17111 {:firstname "Sana", :lastname "Mehicic Eberhardt", :department "Lehrstuhl für Planung und Innovation", :institution "BTU Cottbus", :country "Germany", :sessions (106)}, 17112 {:firstname "Ralf", :lastname "Sprenger", :department "Chair of Enterprise-wide Software Systems", :institution "University of Hagen", :country "Germany", :sessions (61)}, 17115 {:firstname "Andrea", :lastname "Peter", :department "Department of Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (199 17)}, 17117 {:firstname "Thomas", :lastname "Staeblein", :department "", :institution "Daimler AG", :country "Germany", :sessions (114)}, 17118 {:firstname "Udo", :lastname "Vogeler", :department "Controlling", :institution "Salzgitter Flachstahl GmbH", :country "Germany", :sessions (133)}, 17120 {:firstname "Lars", :lastname "Petersen", :department "Business Management", :institution "Alanus University of Arts and Social Sciences", :country "Germany", :sessions (141)}, 17121 {:firstname "Jörg", :lastname "Schwerdtfeger", :department "DMCC", :institution "Universität Kassel", :country "Germany", :sessions (99)}, 17122 {:firstname "Serol", :lastname "Bulkan", :department "Industrial Engineering", :institution "Marmara University", :country "Turkey", :sessions (50)}, 17123 {:firstname "Pinar", :lastname "Özkeserli", :department "Business Administrations", :institution "Uludag University", :country "Turkey", :sessions (155)}, 17124 {:firstname "Deniz ", :lastname "Kosucuoglu", :department "Industrial Engineering", :institution "Bogazici University", :country "Turkey", :sessions (34)}, 17125 {:firstname "Wiebke ", :lastname "Höhn", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (16)}, 17127 {:firstname "Marco", :lastname "Laumanns", :department "", :institution "Bestmile SA", :country "Switzerland", :sessions (196)}, 17128 {:firstname "Alexander", :lastname "Radev", :department "", :institution "Nielsen", :country "United Kingdom", :sessions (63)}, 17130 {:firstname "Matthias Gerhard", :lastname "Wichmann", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (133)}, 17132 {:firstname "Bogdan", :lastname "Stroe", :department "Optimierung", :institution "Fraunhofer ITWM", :country "Germany", :sessions (16)}, 17134 {:firstname "Felix G.", :lastname "König", :department "", :institution "TomTom International B.V.", :country "Germany", :sessions (16 58)}, 17135 {:firstname "Martin", :lastname "Hibbeln", :department "", :institution "Finanzwirtschaft, TU Braunschweig", :country "Germany", :sessions (89)}, 17136 {:firstname "Anca", :lastname "Dragan", :department "", :institution "", :country "Germany", :sessions (63)}, 17137 {:firstname "Cornelia", :lastname "Wichelhaus", :department "Institute of Applied Mathematics", :institution "University of Heidelberg", :country "Germany", :sessions (132)}, 17138 {:firstname "Henning", :lastname "Homfeld", :department "Mathematik", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (199 71)}, 17140 {:firstname "Stephan", :lastname "Wagner", :department "Department of Management, Technology, and Economics", :institution "Swiss Federal Institute of Technology Zurich (ETH Zurich)", :country "Switzerland", :sessions (119)}, 17143 {:firstname "Thomas", :lastname "Makuschewitz", :department "", :institution "BIBA - Bremer Institut für Produktion und Logistik GmbH at the University of Bremen", :country "Germany", :sessions (110)}, 17144 {:firstname "Ali Fehmi", :lastname "Unal", :department "Business Administration", :institution "Uludag University", :country "Turkey", :sessions (106)}, 17147 {:firstname "Maria", :lastname "Cortinhal", :department "Dep. Métodos Quantitativos para Economia e Gestão, ISCTE - IUL / Centro IO, Portugal", :institution "ISCTE-IUL/CIO", :country "Portugal", :sessions (96)}, 17148 {:firstname "Carsten", :lastname "Felden", :department "Fakultät für Wirtschaftswissenschaft", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (107)}, 17150 {:firstname "Günter", :lastname "Kiechle", :department "Mobile und Web-basierte Informationssysteme", :institution "Salzburg Research Forschungsgesellschaft", :country "Austria", :sessions (51)}, 17151 {:firstname "Dan ", :lastname "Dolk", :department "Information Sciences", :institution "NPS Monterey", :country "United States", :sessions (102)}, 17152 {:firstname "Alexander", :lastname "Bordetsky", :department "Information Sciences", :institution "NPS Monterey", :country "United States", :sessions (102)}, 17153 {:firstname "José G.", :lastname "Dias", :department "BRU - Business Research Unit", :institution "ISCTE - Instituto Universitário de Lisboa", :country "Portugal", :sessions (96)}, 17155 {:firstname "Benoit", :lastname "Mathivet", :department "School of Slavonic and East European Studies", :institution "University College London and Paris1 Univ.", :country "United Kingdom", :sessions (94)}, 17158 {:firstname "Gerald", :lastname "Lach", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (175)}, 17159 {:firstname "Koichi", :lastname "Nakade", :department "Department of Civil Engineering and Systems Management", :institution "Nagoya Institute of Technology", :country "Japan", :sessions (56)}, 17163 {:firstname "Kazuki", :lastname "Takenouchi", :department "", :institution "Komatsu LTD.", :country "Japan", :sessions (56)}, 17164 {:firstname "Madjid", :lastname "Tavana", :department "Management", :institution "La Salle University", :country "United States", :sessions (98)}, 17165 {:firstname "René", :lastname "Schumann", :department "Computer Science, Information Systems and Simulation", :institution "Goethe Universität Frankfurt", :country "Germany", :sessions (51)}, 17170 {:firstname "Werner", :lastname "NiemeyerStein", :department "", :institution "ReadPost Gesellschaft", :country "Germany", :sessions (52)}, 17174 {:firstname "Motohiro", :lastname "Hagiwara", :department "School of Commerce", :institution "Meiji University", :country "Japan", :sessions (90)}, 17183 {:firstname "Jan", :lastname "Dethloff", :department "Mgmt. Science & Operations Mgmt., School of International Business", :institution "Hochschule Bremen / University of Applied Sciences", :country "Germany", :sessions (34)}, 17186 {:firstname "Ingo J.", :lastname "Timm", :department "Institute of Computer Science", :institution "Goethe-University Frankfurt", :country "Germany", :sessions (51)}, 17188 {:firstname "Elmar", :lastname "Swarat", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (46)}, 17189 {:firstname "Axel", :lastname "Simroth", :department "Operations Research", :institution "Fraunhofer Institute for Transportation and Infrastructure Systems", :country "Germany", :sessions (31)}, 17201 {:firstname "Alireza", :lastname "Soroush", :department "Industrial Engineering", :institution "Tarbiat Modares University", :country "Iran, Islamic Republic of", :sessions (107)}, 17204 {:firstname "Tobias", :lastname "Fanslau", :department "", :institution "Univ. of Hagen, Germany", :country "Germany", :sessions (24)}, 17206 {:firstname "Ardeshir", :lastname "Bahreininejad", :department "", :institution "Tarbiat Modares University", :country "Iran, Islamic Republic of", :sessions (107)}, 17207 {:firstname "Christian", :lastname "Ott", :department "Lehrstuhl Betriebliches Rechnungswesen/Controlling", :institution "TU Dresden, Fakultät Wirtschaftswissenschaften", :country "Germany", :sessions (88)}, 17210 {:firstname "Wei", :lastname "Solvang", :department "Department of Industrial Engineering", :institution "Narvik University College", :country "Norway", :sessions (73)}, 17212 {:firstname "Moulay Hicham", :lastname "Hakam", :department "Department of Building, Production and Engineering Design", :institution "Narvik University College", :country "Norway", :sessions (73)}, 17213 {:firstname "Harilaos", :lastname "Psaraftis", :department "", :institution "Technical University of Denmark", :country "Denmark", :sessions (32)}, 17220 {:firstname "Michael", :lastname "Krapp", :department "Quantitative Methods", :institution "University of Augsburg", :country "Germany", :sessions (84)}, 17230 {:firstname "Martin A. ", :lastname "Lariviere", :department "Managerial Economics and Decision Sciences", :institution "Northwestern University, Kellogg School of Management", :country "United States", :sessions (112)}, 17254 {:firstname "Sandra", :lastname "Wagner", :department "", :institution "", :country "Germany", :sessions (92)}, 17259 {:firstname "Wolfgang", :lastname "Schultze", :department "Accounting", :institution "University of Augsburg", :country "Germany", :sessions (84)}, 17260 {:firstname "Andreas", :lastname "Weiler", :department "Accounting", :institution "University of Augsburg", :country "Germany", :sessions (84)}, 17264 {:firstname "Fabian", :lastname "Sting", :department "Chair of Production Management", :institution "WHU Otto Beisheim School of Management", :country "Germany", :sessions (120)}, 17274 {:firstname "Charles J. ", :lastname "Kibert", :department "", :institution "Powell Center for Construction & Environment", :country "United States", :sessions (160)}, 17302 {:firstname "Oliver", :lastname "Rose", :department "Institute of Applied Computer Science", :institution "Dresden University of Technology", :country "Germany", :sessions (147)}, 17305 {:firstname "Martin", :lastname "Majohr", :department "Faculty of Mechanical Engineering", :institution "Dresden University of Technology", :country "Germany", :sessions (147)}, 17306 {:firstname "Michael", :lastname "Völker", :department "Professur für Technische Logistik", :institution "Dresden University of Technology", :country "Germany", :sessions (147)}, 17341 {:firstname "Ashkan", :lastname "Malekly", :department "Department of Industrial Engineering", :institution "Islamic Azad University - North Tehran Branch", :country "Iran, Islamic Republic of", :sessions (103)}, 17361 {:firstname "Alexander", :lastname "Firsov", :department "Applied Mathematics", :institution "DNU", :country "Russian Federation", :sessions (18)}, 17377 {:firstname "Wolfgang", :lastname "Singer", :department "", :institution "FHTW Berlin", :country "Germany", :sessions (83)}, 17389 {:firstname "Saeed", :lastname "Mansour", :department "department of Industrial engineering", :institution "Amirkabir university of technology", :country "Iran, Islamic Republic of", :sessions (113)}, 17395 {:firstname "Amir", :lastname "Albadvi", :department "School of Engineering, Industrial Engineering Department", :institution "Tarbiat Modarres University", :country "Iran, Islamic Republic of", :sessions (139)}, 17396 {:firstname "Hassan", :lastname "Salehi Fathabadi", :department "School of Mathematics,Statistics and Computer science", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (45)}, 17401 {:firstname "Seyed Amir Hooman", :lastname "Hasani Farmand", :department "", :institution "Department of Industrial Engineering, University of Tehran", :country "Iran, Islamic Republic of", :sessions (103)}, 17404 {:firstname "Mehdi", :lastname "Deiranlou", :department "Department of Industrial Engineering", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (139)}, 17418 {:firstname "Khaled Moh.", :lastname "Alhamad", :department "Applied Studies", :institution "PAAET", :country "Kuwait", :sessions (59)}, 17428 {:firstname "Stefan", :lastname "Helber", :department "Inst. f. Produktionswirtschaft", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (134)}, 17485 {:firstname "Morris A.", :lastname "Cohen", :department "Manufacturing and Logistics Operations and Information Management Department", :institution "The Wharton School University of Pennsylvania", :country "United States", :sessions (220)}, 17611 {:firstname "Andreas", :lastname "Timm-Giel", :department "Communication Networks", :institution "University of Bremen", :country "Germany", :sessions (60)}, 21084 {:firstname "Ton", :lastname "de Kok", :department "School of IE", :institution "TUE", :country "Netherlands", :sessions (163)}, 33231 {:firstname "J Christian", :lastname "Lang", :department "", :institution "-", :country "Germany", :sessions (22)}, 35421 {:firstname "Andréa", :lastname "Vianna", :department "Computation", :institution "UNESP - Bauru", :country "Brazil", :sessions (150)}, 36644 {:firstname "Rob", :lastname "Basten", :department "", :institution "Twente University", :country "Netherlands", :sessions (134)}, 39627 {:firstname "Chih-Jen", :lastname "Lin", :department "Department of Computer Science", :institution "National Taiwan University", :country "Taiwan, Province of China", :sessions (171)}, 42304 {:firstname "Patrick", :lastname "Sebastian", :department "I2M, UMR CNRS 5295", :institution "Université de Bordeaux", :country "France", :sessions (37)}, 55099 {:firstname "Andreas", :lastname "Scholze", :department "International Accounting", :institution "Osnabrück University", :country "Germany", :sessions (183)}, 56196 {:firstname "Maren", :lastname "Martens", :department "", :institution "Landshut University", :country "Germany", :sessions (45)}, 63162 {:firstname "Eric", :lastname "Schoen", :department "Department of Biosystems", :institution "University of Leuven", :country "Belgium", :sessions (149)}}}