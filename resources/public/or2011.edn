{:timeslots {1 {:schedule "Wednesday, 9:00-11:00", :day "W", :time "A", :sessions (123)}, 2 {:schedule "Wednesday, 11:30-13:00", :day "W", :time "B", :sessions (57 197 211 203 251 124 118 267 215 133 48 105 240 85 220 187 142 51 161 222 101 75)}, 3 {:schedule "Wednesday, 13:30-15:00", :day "W", :time "C", :sessions (55 198 227 202 252 125 115 269 264 134 81 104 77 246 177 219 143 146 162 223 98 159)}, 4 {:schedule "Wednesday, 15:30-16:15", :day "W", :time "D", :sessions (156 155 154 157 272)}, 5 {:schedule "Wednesday, 16:30-18:00", :day "W", :time "E", :sessions (73 196 213 229 253 126 120 113 265 138 88 103 79 247 221 175 52 145 163 169 96 160)}, 6 {:schedule "Thursday, 08:30-10:00", :day "T", :time "A", :sessions (271 71 201 206 209 254 131 117 122 217 139 65 241 189 185 181 64 164 224 99 238)}, 7 {:schedule "Thursday, 10:30-11:15", :day "T", :time "B", :sessions (152)}, 8 {:schedule "Thursday, 11:30-13:00", :day "T", :time "C", :sessions (150 61 194 214 210 255 256 128 112 218 136 67 90 84 191 192 50 225 167 94 109)}, 9 {:schedule "Thursday, 13:30-15:00", :day "T", :time "D", :sessions (239 200 195 208 204 257 258 129 119 266 137 82 182 190 245 141 147 168 226 95 107)}, 10 {:schedule "Thursday, 15:30-16:15", :day "T", :time "E", :sessions (232 231 230 233 158)}, 11 {:schedule "Friday, 08:30-10:00", :day "F", :time "A", :sessions (78 62 212 228 259 261 130 121 268 38 76 242 207 172 92 144 53 165 170 89 108)}, 12 {:schedule "Friday, 10:30-11:15", :day "F", :time "B", :sessions (237 235 236 234)}, 13 {:schedule "Friday, 11:30-12:30", :day "F", :time "C", :sessions (60 149 205 260 127 114 216 243 186 179 270 140 148 166 171)}, 14 {:schedule "Friday, 13:30-15:00", :day "F", :time "D", :sessions (153)}}, :streams {5 {:name "Continuous optimization and control", :order 4, :sessions (57 197 55 198 73 196 71 201 61 194 200 195 78 62 60)}, 6 {:name "Decision analysis, decision support", :order 6, :sessions (251 252 253 254 255 256 257 258 259 261 260)}, 7 {:name "Discrete optimization, graphs and networks", :order 5, :sessions (211 203 227 202 213 229 206 209 214 210 208 204 212 228 149 205)}, 9 {:name "Financial modeling, risk management, banking", :order 9, :sessions (267 215 269 264 265 217 218 266 268 216)}, 11 {:name "Energy, environment and climate", :order 7, :sessions (124 125 126 131 128 129 130 127)}, 12 {:name "Game theory, computational and experimental economics", :order 10, :sessions (133 134 138 139 136 137 38)}, 13 {:name "Location, logistics, transportation and traffic", :order 14, :sessions (85 220 187 246 177 219 247 221 175 189 185 181 84 191 192 182 190 245 207 172 92 186 179 270)}, 14 {:name "Metaheuristics and biologically inspired approaches", :order 18, :sessions (75 159 160 238)}, 15 {:name "OR in industry, software applications, modeling languages", :order 13, :sessions (240 77 79 241 90 82 242 243)}, 17 {:name "Production management, supply chain management", :order 16, :sessions (161 222 162 223 163 169 164 224 225 167 168 226 165 170 166 171)}, 24 {:name "Health, life sciences, bioinformatics", :order 11, :sessions (48 81 88 65 67)}, 26 {:name "Network industries and regulation", :order 12, :sessions (105 104 103 76)}, 29 {:name "Scheduling, time tabling and project management", :order 15, :sessions (142 51 143 146 52 145 64 50 141 147 144 53 140 148)}, 30 {:name "Stochastic programming, stochastic modeling and simulation", :order 8, :sessions (118 115 120 113 117 122 112 119 121 114)}, 31 {:name "Accounting and revenue management", :order 17, :sessions (101 98 96 99 94 95 89)}, 34 {:name "Forecasting, neural nets and fuzzy systems", :order 19, :sessions (109 107 108)}, 38 {:name "Plenary lectures", :order 1, :sessions (123 152 153)}, 39 {:name "Semi-plenary lectures", :order 2, :sessions (156 155 154 157 232 231 230 233 158 237 235 236 234)}, 40 {:name "Award winner sessions", :order 3, :sessions (272 271 150 239)}}, :sessions {38 {:name "Computational economics II", :stream 12, :chairs (29577), :timeslot 11, :papers (701 1017 987), :track 19}, 48 {:name "OR applied to health care I", :stream 24, :chairs (770), :timeslot 2, :papers (262 586 466), :track 20}, 50 {:name "Stochastic project scheduling", :stream 29, :chairs (829), :timeslot 8, :papers (930 1278 591 1237), :track 27}, 51 {:name "Scheduling with speeds", :stream 29, :chairs (1019), :timeslot 2, :papers (901 454 627 823), :track 27}, 52 {:name "Healthcare scheduling", :stream 29, :chairs (14742), :timeslot 5, :papers (1056 717 818 855), :track 26}, 53 {:name "Scheduling algorithms", :stream 29, :chairs (5838), :timeslot 11, :papers (1025 146 985 100), :track 27}, 55 {:name "Convergence principles and stability", :stream 5, :chairs (9547 11954), :timeslot 3, :papers (383 390 697 784), :track 8}, 57 {:name "KKT systems and related topics ", :stream 5, :chairs (17041), :timeslot 2, :papers (402 935 764 399), :track 8}, 60 {:name "Recent advances in nonlinear optimization methods", :stream 5, :chairs (13402), :timeslot 13, :papers (296 888), :track 8}, 61 {:name "Fast gradient methods", :stream 5, :chairs (25671), :timeslot 8, :papers (321 640 590 1452), :track 8}, 62 {:name "Optimization and control in the financial sector", :stream 5, :chairs (3524), :timeslot 11, :papers (139 489 556 1268), :track 9}, 64 {:name "Project scheduling", :stream 29, :chairs (930 5965), :timeslot 6, :papers (369 1085 1305 692), :track 27}, 65 {:name "Bioinformatics I", :stream 24, :chairs (10115), :timeslot 6, :papers (1074 1370 127 137 1307), :track 20}, 67 {:name "Bioinformatics II", :stream 24, :chairs (11835), :timeslot 8, :papers (297 1162 1059 1413 1132), :track 20}, 71 {:name "Bilevel programming and MPECs", :stream 5, :chairs (7687), :timeslot 6, :papers (305 452 953), :track 8}, 73 {:name "Nonsmooth optimization I", :stream 5, :chairs (20607), :timeslot 5, :papers (313 772 786 868), :track 8}, 75 {:name "Routing and scheduling", :stream 14, :chairs (3542), :timeslot 2, :papers (275 1013), :track 31}, 76 {:name "Optimization in gas networks", :stream 26, :chairs (26282), :timeslot 11, :papers (563 920 1262), :track 21}, 77 {:name "Real-world applications of mathematical optimization - opportunities and challenges ", :stream 15, :chairs (), :timeslot 3, :papers (886 922 180 937), :track 22}, 78 {:name "Vector- and set-valued optimization", :stream 5, :chairs (6948), :timeslot 11, :papers (1098 1001 386), :track 8}, 79 {:name "Impact of algebraic modeling languages", :stream 15, :chairs (10542), :timeslot 5, :papers (184 387 867 1204), :track 22}, 81 {:name "OR applied to health care II", :stream 24, :chairs (1256), :timeslot 3, :papers (59 219 465 1310), :track 20}, 82 {:name "Optimization in the energy industry", :stream 15, :chairs (10542), :timeslot 9, :papers (603 873 1337 1440), :track 22}, 84 {:name "Dynamic vehicle routing", :stream 13, :chairs (13264), :timeslot 8, :papers (752 656 1338 669), :track 23}, 85 {:name "Rich vehicle routing I", :stream 13, :chairs (14755), :timeslot 2, :papers (634 890 619 911), :track 23}, 88 {:name "OR applied to health care III", :stream 24, :chairs (829), :timeslot 5, :papers (1199 1318 228), :track 20}, 89 {:name "Reporting and controlling", :stream 31, :chairs (29398), :timeslot 11, :papers (908 765), :track 30}, 90 {:name "Advances in modeling languages", :stream 15, :chairs (3753 3843), :timeslot 8, :papers (1381 1382 1415 267), :track 22}, 92 {:name "Discrete optimization and railway traffic I", :stream 13, :chairs (13837 16315), :timeslot 11, :papers (1004 1256 1003 678), :track 25}, 94 {:name "Quantitative accounting", :stream 31, :chairs (13364), :timeslot 8, :papers (1286 976 1125), :track 30}, 95 {:name "Accounting and hospital management", :stream 31, :chairs (2713), :timeslot 9, :papers (728 441 910 1453), :track 30}, 96 {:name "Integrating revenue management and customer relationship management", :stream 31, :chairs (29191), :timeslot 5, :papers (863 1292 1157), :track 30}, 98 {:name "Customer choice modeling and game theory in revenue management", :stream 31, :chairs (22994), :timeslot 3, :papers (1209 588 789), :track 30}, 99 {:name "Revenue management applications", :stream 31, :chairs (26490), :timeslot 6, :papers (1206 1213 1249), :track 30}, 101 {:name "Capacity control and pricing", :stream 31, :chairs (26841), :timeslot 2, :papers (460 687 955 1347), :track 30}, 103 {:name "Energy networks planning and operation", :stream 26, :chairs (2650), :timeslot 5, :papers (1309 1416 1361), :track 21}, 104 {:name "Modeling network structure and dynamics", :stream 26, :chairs (17127), :timeslot 3, :papers (1418 1050 1244 1331), :track 21}, 105 {:name "Regulation and market models", :stream 26, :chairs (26084), :timeslot 2, :papers (1010 663 1007 1220 972), :track 21}, 107 {:name "Neural networks", :stream 34, :chairs (9422), :timeslot 9, :papers (1253 240 1455), :track 32}, 108 {:name "Finance", :stream 34, :chairs (9082), :timeslot 11, :papers (1332 185), :track 32}, 109 {:name "Applications", :stream 34, :chairs (19080), :timeslot 8, :papers (1254 1302 1379 1458 207), :track 32}, 112 {:name "Queuing systems II", :stream 30, :chairs (29044), :timeslot 8, :papers (133 155), :track 15}, 113 {:name "Queuing systems I", :stream 30, :chairs (26485), :timeslot 5, :papers (46 220 516), :track 16}, 114 {:name "Queuing systems III", :stream 30, :chairs (29332), :timeslot 13, :papers (29 287 528), :track 15}, 115 {:name "Stochastic control", :stream 30, :chairs (26045), :timeslot 3, :papers (179 1409 671 95 1384), :track 15}, 117 {:name "Stochastic optimization II", :stream 30, :chairs (3240), :timeslot 6, :papers (216 929 327 1339), :track 15}, 118 {:name "Stochastic optimization I", :stream 30, :chairs (26602), :timeslot 2, :papers (1447 217 666 851 1290), :track 15}, 119 {:name "Stochastic optimization III", :stream 30, :chairs (3122), :timeslot 9, :papers (568 569 1269), :track 15}, 120 {:name "Applications of stochastic optimization I", :stream 30, :chairs (29581), :timeslot 5, :papers (30 1023 1031), :track 15}, 121 {:name "Applications of stochastic optimization II", :stream 30, :chairs (25676), :timeslot 11, :papers (111 530 695 1171), :track 15}, 122 {:name "Simulation and inventory control", :stream 30, :chairs (3654), :timeslot 6, :papers (193 199 1308 1018), :track 16}, 123 {:name "Bertsimas: Performance analysis in stochastic systems", :stream 38, :chairs (6147), :specialroom "B-10, Video-Transmission G-201", :timeslot 1, :papers (1424), :track 1}, 124 {:name "Energy and emission markets", :stream 11, :chairs (29511), :timeslot 2, :papers (793 410 1252), :track 14}, 125 {:name "Grid integration of renewable energy", :stream 11, :chairs (29511), :timeslot 3, :papers (1208 1230 1329 883), :track 14}, 126 {:name "Hydropower planning", :stream 11, :chairs (9537), :timeslot 5, :papers (791 829 795 848), :track 14}, 127 {:name "Stochastic modelling in energy markets", :stream 11, :chairs (28461), :timeslot 13, :papers (1285 767), :track 14}, 128 {:name "Systems models in energy and agricultural markets", :stream 11, :chairs (4796), :timeslot 8, :papers (1030 1103 1042 887), :track 14}, 129 {:name "Multi-objective decisions in energy markets", :stream 11, :chairs (8513), :timeslot 9, :papers (840 1140 1087), :track 14}, 130 {:name "Portfolio and expansion planning", :stream 11, :chairs (29523), :timeslot 11, :papers (755 1122 86), :track 14}, 131 {:name "Decision support for energy and environmental systems", :stream 11, :chairs (12515), :timeslot 6, :papers (862 1078 231), :track 14}, 133 {:name "Experimental economics I", :stream 12, :chairs (4796), :timeslot 2, :papers (738 1077 1095 1121), :track 19}, 134 {:name "Experimental economics  II", :stream 12, :chairs (29320), :timeslot 3, :papers (819 1015 1063 1299), :track 19}, 136 {:name " Game theory III", :stream 12, :chairs (12659), :timeslot 8, :papers (264 451 501 1115), :track 19}, 137 {:name "Computational economics ", :stream 12, :chairs (29725), :timeslot 9, :papers (1106 1184), :track 19}, 138 {:name "Game theory I", :stream 12, :chairs (29610), :timeslot 5, :papers (977 1335 596 1116), :track 19}, 139 {:name "Game theory II", :stream 12, :chairs (25341), :timeslot 6, :papers (690 969 875 1363), :track 19}, 140 {:name "Scheduling applications", :stream 29, :chairs (5838), :timeslot 13, :papers (959 1084 1104), :track 26}, 141 {:name "Logistics scheduling", :stream 29, :chairs (6251), :timeslot 9, :papers (346 710 1123 1374), :track 26}, 142 {:name "Service scheduling", :stream 29, :chairs (125), :timeslot 2, :papers (459 1303 613 852), :track 26}, 143 {:name "Sports scheduling", :stream 29, :chairs (22798), :timeslot 3, :papers (794 720 153 861), :track 26}, 144 {:name "Production scheduling", :stream 29, :chairs (29746), :timeslot 11, :papers (711 1364 1367 1101), :track 26}, 145 {:name "Job-shop scheduling", :stream 29, :chairs (19271), :timeslot 5, :papers (773 230 771 813), :track 27}, 146 {:name "Scheduling with additional constraints", :stream 29, :chairs (5236 12695), :timeslot 3, :papers (406 417 481), :track 27}, 147 {:name "Scheduling approaches", :stream 29, :chairs (15101), :timeslot 9, :papers (143 616 691 762), :track 27}, 148 {:name "Scheduling analysis", :stream 29, :chairs (), :timeslot 13, :papers (440 632 792), :track 27}, 149 {:name "Heuristics and exact algorithms", :stream 7, :chairs (29429), :timeslot 13, :papers (367 739 732), :track 10}, 150 {:name "GOR PhD Awards 2011", :stream 40, :chairs (1141), :timeslot 8, :papers (1443 1446 1444), :track 7}, 152 {:name "Judd: Large-scale dynamic programming", :stream 38, :chairs (29300), :specialroom "B-10, Video-Transmission G-201", :timeslot 7, :papers (1425), :track 1}, 153 {:name "Pulleyblank: Twenty-first century decision making", :stream 38, :chairs (10871), :specialroom "B-10, Video-Transmission G-201", :timeslot 14, :papers (1426), :track 1}, 154 {:name "Embrechts: Risk management", :stream 39, :chairs (28011), :specialroom "", :timeslot 4, :papers (1431), :track 5}, 155 {:name "Isler: Revenue management", :stream 39, :chairs (5078 13364), :timeslot 4, :papers (1432), :track 3}, 156 {:name "Nesterov: Convex optimization", :stream 39, :chairs (7687), :timeslot 4, :papers (1435), :track 2}, 157 {:name "Vetschera: E-negotiations", :stream 39, :chairs (281), :timeslot 4, :papers (1437), :track 6}, 158 {:name "Brailsford: Healthcare analytics", :stream 39, :chairs (770), :timeslot 10, :papers (1428), :track 6}, 159 {:name "Combinatorial optimization problems", :stream 14, :chairs (14675), :timeslot 3, :papers (835 673 486), :track 31}, 160 {:name "Metaheuristics in practice", :stream 14, :chairs (518), :timeslot 5, :papers (1420 442 1131), :track 31}, 161 {:name "Lotsizing", :stream 17, :chairs (13866), :timeslot 2, :papers (664 1016 1166 1312), :track 28}, 162 {:name "Perishability", :stream 17, :chairs (23114), :timeslot 3, :papers (165 324), :track 28}, 163 {:name "Scheduling & queueing", :stream 17, :chairs (10255), :timeslot 5, :papers (398 928 1376 1225 893), :track 28}, 164 {:name "Assembly & maintenance", :stream 17, :chairs (26613), :timeslot 6, :papers (776 1218 1176 1316 1028), :track 28}, 165 {:name "Production planning", :stream 17, :chairs (909), :timeslot 11, :papers (735 550 1357 1043), :track 28}, 166 {:name "Aggregate production planning", :stream 17, :chairs (1131), :timeslot 13, :papers (495 1173 1345), :track 28}, 167 {:name "Coordination", :stream 17, :chairs (25170), :timeslot 8, :papers (1344 817 1058 777 540), :track 29}, 168 {:name "Closed loop supply chains", :stream 17, :chairs (26613), :timeslot 9, :papers (445 1126 523 1371 658), :track 28}, 169 {:name "Inventory I", :stream 17, :chairs (3329), :timeslot 5, :papers (923 768 1102 878), :track 29}, 170 {:name "Inventory II", :stream 17, :chairs (29657), :timeslot 11, :papers (967 1203 1120), :track 29}, 171 {:name "Inventory III", :stream 17, :chairs (3791), :timeslot 13, :papers (514 1392), :track 29}, 172 {:name "Freight transportation II", :stream 13, :chairs (12695), :timeslot 11, :papers (66 351 1146 708), :track 24}, 175 {:name "Airline, airport and air traffic management", :stream 13, :chairs (22409), :timeslot 5, :papers (135 1160 517 147), :track 25}, 177 {:name "Location problems II", :stream 13, :chairs (12245), :timeslot 3, :papers (600 1186 1207 1380), :track 24}, 179 {:name "Container logistics", :stream 13, :chairs (15277), :timeslot 13, :papers (197 808), :track 24}, 181 {:name "Urban traffic and transportation", :stream 13, :chairs (29461), :timeslot 6, :papers (827 1343 1365 856), :track 25}, 182 {:name "Routing problems", :stream 13, :chairs (4161), :timeslot 9, :papers (1387 416 236 994), :track 23}, 185 {:name "Healthcare and humanitarian logistics", :stream 13, :chairs (2769), :timeslot 6, :papers (319 638 1283), :track 24}, 186 {:name "Service networks and freight forwarding", :stream 13, :chairs (14707), :timeslot 13, :papers (1081 1057 608 308), :track 23}, 187 {:name "Vehicle, fleet and crew scheduling", :stream 13, :chairs (10539), :timeslot 2, :papers (552 542 686 311), :track 25}, 189 {:name "Pickup and Delivery / Dial-a-Ride", :stream 13, :chairs (20539), :timeslot 6, :papers (1009 1034 1070), :track 23}, 190 {:name "Tolls and prices", :stream 13, :chairs (15277), :timeslot 9, :papers (401 1111 797 1233), :track 24}, 191 {:name "Freight transportation I", :stream 13, :chairs (22160), :timeslot 8, :papers (721 942 385 913), :track 24}, 192 {:name "Public transport planning", :stream 13, :chairs (14588), :timeslot 8, :papers (724 1049 1148 173), :track 25}, 194 {:name "Continuous optimization I", :stream 5, :chairs (28749 48141), :timeslot 8, :papers (1093 1274 85 1242), :track 9}, 195 {:name "Continuous optimization II", :stream 5, :chairs (1601), :timeslot 9, :papers (948 1227 1330 1234), :track 9}, 196 {:name "Linear optimization and extensions", :stream 5, :chairs (21172), :timeslot 5, :papers (642 1020 1235 649), :track 9}, 197 {:name "Optimal control I", :stream 5, :chairs (16165), :timeslot 2, :papers (636 633 1320), :track 9}, 198 {:name "Optimal control II", :stream 5, :chairs (29106), :timeslot 3, :papers (205 896 1414 470), :track 9}, 200 {:name "Nonsmooth optimization II", :stream 5, :chairs (20607), :timeslot 9, :papers (1033 1114 354), :track 8}, 201 {:name "Optimal control III", :stream 5, :chairs (18584), :timeslot 6, :papers (268 520 68 116), :track 9}, 202 {:name "Multicriteria optimization ", :stream 7, :chairs (29288), :timeslot 3, :papers (145 493 815 661), :track 11}, 203 {:name "The travelling salesman problem", :stream 7, :chairs (29130), :timeslot 2, :papers (747 895 163), :track 11}, 204 {:name "Nonlinear integer programming ", :stream 7, :chairs (26471), :timeslot 9, :papers (659 341 983 1008), :track 11}, 205 {:name "Combinatorial Optimization II", :stream 7, :chairs (29472), :timeslot 13, :papers (325 787 811), :track 11}, 206 {:name "Network flow problems", :stream 7, :chairs (29602), :timeslot 6, :papers (254 653 891 1100), :track 10}, 207 {:name "Path problems and route planning", :stream 13, :chairs (26752), :timeslot 11, :papers (543 931 457 1067), :track 23}, 208 {:name "Mixed applications of combinatorial optimization ", :stream 7, :chairs (26311), :timeslot 9, :papers (847 1189 547 322), :track 10}, 209 {:name "Applications in logistics", :stream 7, :chairs (14923), :timeslot 6, :papers (897 946 988 1066), :track 11}, 210 {:name "Decomposition techniques", :stream 7, :chairs (14969), :timeslot 8, :papers (652 876 1022 1011), :track 11}, 211 {:name "Applications in telecommunication", :stream 7, :chairs (29545), :timeslot 2, :papers (1124 1217 1002), :track 10}, 212 {:name "Robust and inverse optimization", :stream 7, :chairs (29580), :timeslot 11, :papers (407 1091 836 1172), :track 10}, 213 {:name "Mixed integer programming with engineering applications", :stream 7, :chairs (19441), :timeslot 5, :papers (788 1200 1272 1377), :track 10}, 214 {:name "Combinatorial optimization with industrial applications", :stream 7, :chairs (29680), :timeslot 8, :papers (1029 1349 1266), :track 10}, 215 {:name "Lending and default risk", :stream 9, :chairs (29556), :timeslot 2, :papers (405 1422 1210 964), :track 18}, 216 {:name "Risk pricing", :stream 9, :chairs (29754), :timeslot 13, :papers (629 1183 1378), :track 17}, 217 {:name "VaR, risk measures and portfolio insurance", :stream 9, :chairs (29247), :timeslot 6, :papers (892 1355 655), :track 17}, 218 {:name "Market quality and efficiency", :stream 9, :chairs (29669), :timeslot 8, :papers (1423 965 478 1275), :track 17}, 219 {:name "Crew and driver scheduling", :stream 13, :chairs (3301), :timeslot 3, :papers (837 1165 1408 854), :track 25}, 220 {:name "Location problems I", :stream 13, :chairs (), :timeslot 2, :papers (641 698 1060 1041), :track 24}, 221 {:name "Location problems III", :stream 13, :chairs (28288), :timeslot 5, :papers (864 939 1205 737 177), :track 24}, 222 {:name "Automotive", :stream 17, :chairs (2651), :timeslot 2, :papers (281 1113 1064 1215), :track 29}, 223 {:name "Network design & transshipment", :stream 17, :chairs (14707), :timeslot 3, :papers (824 1314 1079 821), :track 29}, 224 {:name "Allocation", :stream 17, :chairs (4229), :timeslot 6, :papers (412 841 727 870 898), :track 29}, 225 {:name "Divers", :stream 17, :chairs (16036), :timeslot 8, :papers (606 1110 842), :track 28}, 226 {:name "Variety & finance", :stream 17, :chairs (9703), :timeslot 9, :papers (869 1179 1247 397), :track 29}, 227 {:name "Integer programming I", :stream 7, :chairs (29748), :timeslot 3, :papers (475 828 1368 944), :track 10}, 228 {:name "Integer programming II", :stream 7, :chairs (23511), :timeslot 11, :papers (182 1080 1202), :track 11}, 229 {:name "Combinatorial optimization I", :stream 7, :chairs (25677), :timeslot 5, :papers (154 404 551 874), :track 11}, 230 {:name "Bühlmann: Statistics and optimization", :stream 39, :chairs (6147), :timeslot 10, :papers (1429), :track 4}, 231 {:name "Costa: Practice of supply chain management", :stream 39, :chairs (12769), :timeslot 10, :papers (1430), :track 3}, 232 {:name "Leyffer: Mixed-integer nonlinear optimization", :stream 39, :chairs (29300), :timeslot 10, :papers (1433), :track 2}, 233 {:name "Voss: Matheuristics", :stream 39, :chairs (518), :timeslot 10, :papers (1438), :track 5}, 234 {:name "Alderson: Organized complexity in networks", :stream 39, :chairs (17127), :timeslot 12, :papers (1427), :track 6}, 235 {:name "Munson: Environmental models", :stream 39, :chairs (4796 29511), :timeslot 12, :papers (1434), :track 3}, 236 {:name "Tragler: Drugs and optimal control", :stream 39, :chairs (7687), :timeslot 12, :papers (1436), :track 5}, 237 {:name "Weismantel: Mixed-integer optimization", :stream 39, :chairs (13046), :timeslot 12, :papers (1439), :track 2}, 238 {:name "New approaches", :stream 14, :chairs (29691), :timeslot 6, :papers (570 279 350 1402 1315), :track 31}, 239 {:name " GOR / SVOR PhD Awards 2011", :stream 40, :chairs (1141 9103), :timeslot 9, :papers (1445 1454), :track 7}, 240 {:name "Applications in manufacturing", :stream 15, :chairs (5078), :timeslot 2, :papers (106 1075 132 1257), :track 22}, 241 {:name "Software and modeling languages", :stream 15, :chairs (19332), :timeslot 6, :papers (573 734 970 553), :track 22}, 242 {:name "Applications in logistics", :stream 15, :chairs (14688), :timeslot 11, :papers (307 719 615 1046 963), :track 22}, 243 {:name "Industrial applications", :stream 15, :chairs (3578), :timeslot 13, :papers (444 496 1192), :track 22}, 245 {:name "Railway operations and dispatching", :stream 13, :chairs (28600), :timeslot 9, :papers (1083 499 950 1348), :track 25}, 246 {:name "Rich vehicle routing II", :stream 13, :chairs (15802), :timeslot 3, :papers (617 754 344 295), :track 23}, 247 {:name "Rich vehicle routing III", :stream 13, :chairs (10538), :timeslot 5, :papers (368 693 161 1062 1086), :track 23}, 251 {:name "Group decision making I", :stream 6, :chairs (2983), :timeslot 2, :papers (239 979 1325), :track 12}, 252 {:name "Group decision making II", :stream 6, :chairs (9827), :timeslot 3, :papers (1411 1296 1353), :track 12}, 253 {:name "Complexity in decision making", :stream 6, :chairs (29693), :timeslot 5, :papers (580 211 1250 1311), :track 12}, 254 {:name "Multiple criteria decision making I", :stream 6, :chairs (23706), :timeslot 6, :papers (472 943 498 605), :track 12}, 255 {:name "Multiple criteria decision making II", :stream 6, :chairs (9212), :timeslot 8, :papers (464 435 1406), :track 12}, 256 {:name "Theoretical developments in decision analysis", :stream 6, :chairs (29345), :timeslot 8, :papers (675 907 716 558), :track 13}, 257 {:name "Decision analysis for marketing", :stream 6, :chairs (29686), :timeslot 9, :papers (158 1270 1195), :track 12}, 258 {:name "Decision making under uncertainty", :stream 6, :chairs (24093), :timeslot 9, :papers (1174 1082 1354), :track 13}, 259 {:name "Data envelopment analysis I", :stream 6, :chairs (23155), :timeslot 11, :papers (370 468 1221 703), :track 12}, 260 {:name "Data envelopment analysis II", :stream 6, :chairs (29292), :timeslot 13, :papers (533 479), :track 12}, 261 {:name "Decision support applications", :stream 6, :chairs (24622), :timeslot 11, :papers (781 917 1139), :track 13}, 264 {:name "Risk measures and risk management", :stream 9, :chairs (2573), :timeslot 3, :papers (491 89 796 1276), :track 18}, 265 {:name "Portfolio optimization", :stream 9, :chairs (11260), :timeslot 5, :papers (490 680 759 1212), :track 17}, 266 {:name "Investment decision I", :stream 9, :chairs (27647), :timeslot 9, :papers (339 415 1340 33), :track 17}, 267 {:name "Banking, corporate finance and financial forecasting I", :stream 9, :chairs (2127), :timeslot 2, :papers (623 1240 607 90), :track 17}, 268 {:name "Investment decision II", :stream 9, :chairs (10811), :timeslot 11, :papers (57 303 330 1255), :track 17}, 269 {:name "Banking, corporate finance and financial forecasting II", :stream 9, :chairs (19731), :timeslot 3, :papers (518 650 1222), :track 17}, 270 {:name "Discrete optimization and railway traffic II", :stream 13, :chairs (13837 16315), :timeslot 13, :papers (957 1136 1397), :track 25}, 271 {:name "GOR Master Awards 2011", :stream 40, :chairs (16870), :timeslot 6, :papers (1449 1450 1451), :track 7}, 272 {:name "Wissenschaftspreis der GOR", :stream 40, :chairs (10057), :timeslot 4, :papers nil, :track 7}}, :rooms {1 {:room "B-10"}, 2 {:room "F-101"}, 3 {:room "F-104"}, 4 {:room "F-109"}, 5 {:room "F-118"}, 6 {:room "F-121"}, 7 {:room "F-109"}, 8 {:room "G-201"}, 9 {:room "G-204"}, 10 {:room "G-217"}, 11 {:room "G-221"}, 12 {:room "E-21"}, 13 {:room "F-123"}, 14 {:room "F-174"}, 15 {:room "F-175"}, 16 {:room "F-123"}, 17 {:room "F-150"}, 18 {:room "F-123"}, 19 {:room "E-18"}, 20 {:room "F-172"}, 21 {:room "F-109"}, 22 {:room "G-209"}, 23 {:room "F-121"}, 24 {:room "F-101"}, 25 {:room "F-104"}, 26 {:room "F-153"}, 27 {:room "F-152"}, 28 {:room "F-180"}, 29 {:room "F-118"}, 30 {:room "G-212"}, 31 {:room "G-220"}, 32 {:room "G-220"}}, :keywords {2 {:name "Airline Applications", :sessions (101 77 219 98 175 99 141 53 140 148)}, 3 {:name "Analytic Hierarchy Process", :sessions (259 268)}, 5 {:name "Artificial Intelligence", :sessions (88 181)}, 6 {:name "Auctions / Competitive Bidding", :sessions (134 218 137 190)}, 7 {:name "Capacity Planning", :sessions (161 222 219 146 223 145 64 224 256 168 95 76 165 166 171)}, 8 {:name "Combinatorial Optimization", :sessions (203 220 142 161 75 227 202 177 219 143 223 159 213 229 253 163 206 209 117 65 238 214 210 67 191 192 50 208 204 182 245 147 212 228 242 172 92 144 149 205 186 179 270 148)}, 10 {:name "Complexity and Approximation", :sessions (203 142 202 143 146 196 145 201 206 65 61 208 182 190 147 212 144)}, 12 {:name "Computational Biology", :sessions (81 65 238 67)}, 13 {:name "Convex Optimization", :sessions (211 264 146 217 61 194 50 119 78 62 92 60)}, 14 {:name "Continuous Optimization", :sessions (57 197 55 198 73 196 221 254 117 194 200 195 62 76)}, 16 {:name "Cutting and Packing", :sessions (177 229 195 147 121 172 148)}, 17 {:name "Data Envelopment Analysis", :sessions (48 105 109 266 259 130 260)}, 18 {:name "Decision Support Systems", :sessions (251 51 161 252 269 253 126 79 254 131 241 185 99 255 90 208 107 261 242 260 243 186 148)}, 19 {:name "Decision Theory and Analysis", :sessions (251 118 133 134 98 253 138 254 255 256 94 257 258 119 266 153)}, 22 {:name "Disaster and Crisis Management", :sessions (48 185 121)}, 23 {:name "Dynamical Systems", :sessions (133 51 75 104 201 225 109 107 78)}, 25 {:name "Economic Modeling", :sessions (124 267 105 134 138 79 201 139 164 128 257 258 38)}, 28 {:name "Electrical Markets", :sessions (57 125 77 126 120 103 137 82 62 130 127)}, 29 {:name "Energy Policy and Planning", :sessions (251 124 105 125 115 126 103 122 181 128 109 129 82 130)}, 30 {:name "Enterprise Resource Planning Systems", :sessions (112)}, 31 {:name "Environmental Management", :sessions (124 131 128 168)}, 32 {:name "Expert Systems and Neural Networks", :sessions (109 107)}, 33 {:name "Facilities Planning and Design", :sessions (223 159 221 204 92)}, 34 {:name "Finance and Banking", :sessions (118 267 215 269 264 265 217 218 109 266 62 268 38 216)}, 35 {:name "Financial Modelling", :sessions (118 267 215 133 269 264 265 217 218 94 266 226 95 107 62 268 207 216)}, 36 {:name "Flexible Manufacturing Systems", :sessions (147 166)}, 37 {:name "Forecasting", :sessions (124 267 269 126 109 168 107 108 127)}, 38 {:name "Forestry Management", :sessions (259)}, 39 {:name "Fuzzy Sets and Systems", :sessions (202 238 136 268 108)}, 40 {:name "Game Theory", :sessions (133 220 51 134 98 73 138 139 136 167 94 137 190 38 205)}, 41 {:name "Global Optimization", :sessions (177 175 200 195 38 172)}, 42 {:name "Graphs and Networks", :sessions (203 220 77 229 145 206 209 65 210 255 256 191 208 204 62 212 228 207 53 149 205)}, 44 {:name "Group Decision Making and Negotiation", :sessions (251 252 139 136)}, 45 {:name "Health Care", :sessions (48 81 88 221 52 160 136 67 95)}, 47 {:name "Human Resources Management", :sessions (253 140)}, 48 {:name "Industrial Optimization", :sessions (105 240 161 79 169 164 214 50 82 141 76 144 165 243 166)}, 52 {:name "Knowledge Engineering and Management", :sessions (252)}, 53 {:name "Large Scale Optimization", :sessions (79 164 61 210 195 141 226 76 149)}, 54 {:name "Location", :sessions (220 246 177 221 206 238 128 191 192 205 186)}, 55 {:name "Management Information Systems", :sessions (134 89)}, 56 {:name "Marketing", :sessions (197 96 109 257 130 108)}, 57 {:name "Mathematical Programming", :sessions (57 220 55 227 269 104 246 73 265 88 79 175 163 71 209 185 210 90 200 195 208 182 212 228 38 242 165 243 148)}, 59 {:name "Metaheuristics", :sessions (240 85 187 161 75 202 246 177 159 126 247 175 163 160 189 238 191 195 172 53 149 243)}, 60 {:name "Military Operations Research", :sessions (253 247 172)}, 61 {:name "Modeling Systems and Languages", :sessions (77 79 241 90 82 242)}, 63 {:name "Multi-Objective Decision Making", :sessions (267 202 246 159 126 265 88 96 160 254 189 255 256 129 266 78 259)}, 65 {:name "Network Design", :sessions (211 104 223 206 181 256 191 190 76 242 270)}, 66 {:name "Non-smooth Optimization", :sessions (57 55 73 71 194 200)}, 67 {:name "Optimization in Financial Mathematics", :sessions (264 265 217 129 119 266 78 268)}, 71 {:name "OR in Development", :sessions (185 261)}, 72 {:name "OR in Sports", :sessions (143 260)}, 73 {:name "OR/MS and the Public Sector", :sessions (252 115 221 185 181 214 190)}, 74 {:name "Parallel Algorithms and Implementation", :sessions (85 75 227 247 206 92)}, 75 {:name "Production and Inventory Systems", :sessions (240 161 222 104 77 223 120 163 169 122 164 224 99 225 167 168 226 121 144 53 165 170 114 243 166 171)}, 76 {:name "Programming, Dynamic", :sessions (240 101 202 115 134 103 163 169 122 152 50 119 182 121 171)}, 77 {:name "Programming, Integer", :sessions (211 240 142 227 125 104 219 143 146 213 229 221 52 117 65 241 64 214 210 67 208 204 266 137 182 190 141 147 212 228 242 92 144 60 149 270)}, 78 {:name "Programming, Linear", :sessions (240 85 187 222 252 125 196 229 120 88 241 64 210 136 149 179 166)}, 79 {:name "Programming, Multi-Objective", :sessions (202 162 254 194 78)}, 80 {:name "Programming, Nonlinear", :sessions (57 124 55 81 73 213 175 71 61 194 256 195 204 226 121 76 60 149)}, 81 {:name "Programming, Quadratic", :sessions (126 127)}, 82 {:name "Programming, Semidefinite", :sessions (161 55 264 177 213 200)}, 83 {:name "Programming, Semi-Infinite", :sessions (73 196 200 204)}, 84 {:name "Programming, Sequential Quadratic", :sessions (60)}, 85 {:name "Programming, Stochastic", :sessions (118 125 115 196 120 103 247 221 117 164 119 82 121 242 127)}, 86 {:name "Project Management and Scheduling", :sessions (142 252 64 50 140 148)}, 87 {:name "Quality Management", :sessions (222 104 122 164)}, 88 {:name "Queuing Systems", :sessions (115 113 175 52 163 122 181 164 112 258 121 114)}, 89 {:name "Reliability", :sessions (222 103 163 206 164 194 112 147)}, 91 {:name "Revenue Management and Pricing", :sessions (101 98 96 224 99 168 89)}, 92 {:name "Reverse Logistics / Remanufacturing", :sessions (161 190 168)}, 93 {:name "Risk Analysis and Management", :sessions (267 215 115 264 120 117 122 217 167 94 258 119 266 226 62 268 170 127 216)}, 94 {:name "Robust Optimization", :sessions (211 75 125 115 264 104 196 88 117 217 241 194 225 94 245 147 226 62 212 165)}, 95 {:name "Routing", :sessions (85 187 142 247 52 189 181 210 255 192 182 245 242 207 172 92 186 179)}, 96 {:name "Scheduling", :sessions (240 187 142 51 143 146 88 103 175 52 145 163 209 185 64 164 192 50 245 141 147 172 144 53 243 186 140 148)}, 97 {:name "Simulation", :sessions (124 118 133 48 105 51 134 104 223 98 159 253 113 103 131 122 181 164 224 99 256 112 218 90 94 257 258 168 130 121 207 114 216)}, 98 {:name "Software for OR/MS Analysis", :sessions (79 241 90 119)}, 99 {:name "Stochastic Models", :sessions (123 118 267 240 51 222 101 198 125 115 269 219 223 113 265 103 175 52 117 122 164 224 112 67 50 167 258 226 62 268 170 127 114 166)}, 100 {:name "Strategic Planning and Management", :sessions (251 253 221 128 191 225 167 109 82 95)}, 101 {:name "Supply Chain Management", :sessions (161 222 252 162 223 169 241 164 224 225 167 190 168 226 165 170 166 171)}, 102 {:name "Sustainable Development", :sessions (105 254 128 129 261)}, 103 {:name "System Dynamics and Theory", :sessions (105 253 128)}, 104 {:name "Telecommunications", :sessions (211 105 104 113 109 147 121)}, 105 {:name "Timetabling", :sessions (142 143 192 245 92)}, 106 {:name "Transportation and Logistics", :sessions (203 85 220 187 222 246 177 219 162 159 138 247 221 175 71 209 189 185 181 210 256 90 84 191 192 129 182 190 245 141 242 207 172 92 165 186 179 270 140)}, 108 {:name "Variational Problems", :sessions (57 55 198 201 117 194 200)}, 109 {:name "Warehouse Design, Planning, and Control", :sessions (77 169)}, 115 {:name "Problem Structuring Methods", :sessions (252 164 208)}, 120 {:name "Data Mining", :sessions (203 215 177 254 67 109 62 108)}, 121 {:name "Rostering", :sessions (219 52 209 140)}, 122 {:name "Analytic Network Process", :sessions (261)}, 124 {:name "Machine Learning", :sessions (124 122 241 256 107 108 60)}, 125 {:name "OR in Agriculture", :sessions (269 246 160 254 128 257 261)}, 126 {:name "Optimal Control", :sessions (197 101 198 265 201 224 61 167 200 62)}, 127 {:name "Agent Systems", :sessions (118 156 155 154 157 138 271 122 238 150 94 239 258 95 232 231 230 233 158 130 38 237 235 236 234)}, 133 {:name "Engineering Optimization", :sessions (240 213 164 214 192 195 261 243)}, 134 {:name "Equilibria", :sessions (51 125 115 138 139 192 137)}, 136 {:name "Water Management", :sessions (197 213 126 120 160 82 141)}}, :papers {29 {:keyword1 88, :keyword3 97, :abstract "Approximate formulas of the variance of the waiting-time (also called as delay-time variance) in a renewal-input general-service-time single-server (GI/GI/1) system play an important role in practical applications of the queueing theory. However, there exists almost no literature on the approximate formulas of the delay-time variance in the GI/GI/1 system. The goal of this paper is to present an approximate formula for the delay-time variance. Our approach is based on the combination of the diffusion process approximation for the unfinished work developed in [1] and a higher-moment relationship between the unfinished work and the waiting time. To derive the latter relationship, we apply Miyazawa’s rate conservation law [2] for the stationary point process. Our approximate formula is shown to converge to the exact result for the Poisson-input system as traffic intensity goes to the unity. The accuracy of our approximation is validated by simulation results. \r\n\r\nReferences\r\n[1] Y. Takahashi, Y. Shikata, and A. Frey, “Diffusion approximation for a web-server system with proxy servers,” Proceedings of OR 2010 Munich, I.6.TC-15-3, pp.1--6 (to be published in Springer-Verlag)\r\n[2] M. Miyazawa, “Rate conservation laws: a survey,” Queueing Systems, 15(1-4), pp.1--58 (1994).\r\n", :title "Approximate Formula of Delay Time Variance in Renewal Input General Service Time Single Server Queueing System", :keyword2 99, :authors (25364 25363 25356), :session 114}, 30 {:keyword1 85, :keyword3 75, :abstract "In the real-world situation, the uncertainties and the decision process are stochastic due to their evolution over time. Two-stage stochastic mixed integer linear programming with recourse (2S-MILP) is one of the most promising methods to model this dynamic stochastic process. \r\n\r\nIn this contribution, a novel dynamic 2S-MILP formulation for the evolving multi-period multi-uncertainty (MPMU) is developed and a corresponding method, a rolling horizon strategy (RHS) is proposed. In order to reduce the computation effort, the immediate future with the known probability distributions is modeled by a tree of scenarios of various uncertainties within a time horizon I1 whereas the distant future is represented by the expected values (EVs) within a time horizon I2. Both I1 and I2 are rolling along the unlimited time axis due to the evolution of MPMU. When all the parameters of MPMU are the same in every rolling step, the RHS is preferred to be called moving horizon strategy (MHS). For the planning / scheduling problems under static information of MPMU within a fixed horizon, e.g., I1 and I2 are fixed, a scenario group based approach (SGA), the semi-dynamic form of RHS with shrinking the second stage, is proposed for the ergodic process on the scenario tree composed by these uncertainties. The underlying approaches are implemented to a real-world medium-term production planning problem of a multi-product batch plant and numerical simulations show the performances for different combinations of uncertainties.", :title "Two-stage stochastic mixed integer linear programming", :keyword2 78, :authors (25019), :session 120}, 33 {:keyword1 35, :keyword3 67, :abstract "In this paper, we demonstrate ways of using MOEAs so they incorporate the methods and constraints often encountered by portfolio managers.  By this we mean selecting stocks based on fundamentals, e.g. price/earnings and price/book, position limits, cardinality constraints, market capitalization constraints, e.g. the fund must be able to be classifed as large-cap, turnover, style - growth or value - and risk.\r\n\r\nWe use our first MOEA to maximize the fundamental scores of the stocks selected, constrain the number of stocks that can be held (minimum and maximums), make sure the capitalization constraint and if need be the style constraint is met (in our case two portfolios are generated each quarter: one large-cap and the other large-cap growth).  The results of this MOEA are passed to the second stage where risk, position limits and turnover are managed.\r\n\r\nA first pass at managing risk is done via a standard mean-variance optimization (MVO) that incorporates the position and turnover constraints.  The portfolio with the best Sharpe ratio and geometric mean becomes the portfolio of record for the next 3 months.\r\n\r\nA second risk method is based on an MOEA that trades off return and kurtosis.  This MOEA also incorporates the position and turnover constraints.  The best portfolio here is determined by adjusting the Sharpe ratio to account for kurtosis.\r\n\r\nThe large-cap portfolio is formed quarterly for 30 years and is compared to a common large-cap benchmark (the S&P 500).  The large-cap growth portfolios are computed quarterly for 16 years and are compared to the Russell 3000 growth index.\r\n\r\nIn each case, on a risk-adjusted basis, the MOEA portfolios outperform their benchmarks while staying within their constraints.  ", :title "An Extended Use of MOEAs in Stock Portfolio Construction and Optimization", :keyword2 63, :authors (27647), :session 266}, 46 {:keyword1 88, :keyword3 97, :abstract "Suppose that there are two classes and that an arriving (class-1 or class-2) request finds n1 class-1 and n2 class-2 requests (including the arriving one) in a single-server system. We then propose a new prioritized limited processor-sharing (PS) rule, under which class-1 requests individually and simultaneously receive m/(m*n1+n2) of the service capacity, while class-2 requests 1/(m*n1+n2) of that; if m*n1+n2<=C. Otherwise (m*n1+n2>C), the arriving request will be queued in the corresponding class waiting room or rejected. Here, m (>=1) denotes the priority ratio, and C (<=infty) the service-facility capacity. Our rule includes the Kleinrock’s priority PS rule [1] as a special case (C=infty), and the limited PS rule [2] as a special case (m=1, and say n2=0). Performance measures of practical interest are evaluated via simulation. When a request arrives at [or departs from] the system, the extension [shortening] of the remaining sojourn time is calculated. Chasing these events and calculations enables us to analyze performance for our prioritized limited PS rule, which is realistic in the time-sharing system (TSS) with a sufficiently small time-slot.\r\nReferences\r\n\tL. Kleinrock, \"Time-shared systems: a theoretical treatment,\" J. of ACM, vol.14 (2), pp.242--261 (1967).\r\n\tG. Yamazaki and H. Sakasegawa, “An optimal design problem for limited sharing systems, Management Science, vol.33(8), pp.1010--1019 (1987).\r\n", :title "Prioritized Limited Processor-Sharing System with its Performance Analysis", :keyword2 99, :authors (25364 27700 25356), :session 113}, 57 {:keyword1 35, :keyword3 93, :abstract "In this paper we are concerned with the single-period portfolio optimization problem in the mean-risk framework. Our goal is to develop an integrated portfolio selection method which takes into consideration the recent positive evolution of the risky assets that are not comprised in the portfolio available at the moment of the decision.  Our method aims to replace one of the assets in the initial portfolio (whose performance has dropped lately) with an asset which recently has better performances. Our method consists of the following steps. First, we partition the available set of securities in clusters composed by similar assets by applying the Principal Component Analysis to reduce the number of variables that characterize the assets. Secondly, depending on the risk profile of the investor, we choose the criterion to be used for selecting the most suitable security in each cluster. Then we focus on deciding which one of the selected assets will be chosen to replace the less performing asset in the initial portfolio by applying the Analytical Hierarchy Process with four key criteria: return, risk, liquidity and suitability. Finally, the optimization step is performed. We propose a single-period bi-objective model in which the risk is taken into account first, by considering an utility function which captures the attitude towards risk of the decision maker and second, by optimizing the portfolio through minimizing a new quantile based risk measure. The new risk measure is defined using the modified loss distribution according to the decision maker's loss aversion preferences. Practical issues, such as transaction costs, are incorporated in the model. Related optimization models which generate equivalent representations of the efficient frontier are also given.", :title "Portfolio optimization with a new quantile-based risk measure and prior stock selection", :keyword2 67, :authors (10811), :session 268}, 59 {:keyword1 45, :keyword3 0, :abstract "With rising incomes, changes in demographic profiles in developed economies, convergence of life styles, long waiting periods to seek elective medical procedures, global supply and demand imbalances in the provision of healthcare, international trade in healthcare services sector has witnessed a rapid growth. The ASEAN nations, especially Singapore, Thailand, the Philippines, and Malaysia, have been aggressive in promotion themselves as a hub of healthcare services. During the past two decades, and especially after the 1997 Asian Financial Crisis, the Thai Government made concerted efforts to make the services sector more tradable and thus strengthening the resilience of the economy. The capacity of Thailand’s healthcare sector to participate in the global trade in services, primarily, depends on the quality and quantum of healthcare infrastructure and availability of qualified professional healthcare staff. Similarly, other demand side as well as the institutional factors play equally important role in enhancing a country’s attractiveness as a hub of healthcare services\r\n\r\nThe primary objective of this paper is to investigate the opportunities and challenges for Thailand in expanding export of healthcare services. The paper briefly examines Thailand’s regional as well as global position in export of healthcare services and the current status of Thailand’s healthcare system with a view to assess the country’s ability to explore export opportunities and address the challenges that these opportunities may bring. \r\n\r\nAs opposed to the goods trade, due to their unique inherent characteristics, healthcare services are traded through four distinct delivery modes.  Given that trade in healthcare services can be materialised using different modes of delivery, the paper provides a critical appraisal of the factors that underpin trade in healthcare services via each mode. This analysis provides an insight into the mode-specific factors that drives and/or drags Thailand’s export in healthcare services. An attempt is made to provide an appraisal of the extent to which the healthcare services sector has succeeded in utilising these modes to expand trade in healthcare services. This exercise provides a fitting platform to critically examine each mode of delivery in terms its associated challenges and opportunities. The paper makes an attempt to devise mode-specific as well as across-modes strategies for Thailand’s healthcare sector and outlines a way forward to enhance export competitiveness of Thailand’s healthcare services in increasingly contested markets for healthcare services.\r\n", :title "Export of Health Services: An Assessment of Thailand's Potential", :keyword2 0, :authors (14005 27877), :session 81}, 66 {:keyword1 106, :keyword3 96, :abstract "In the outbound supply chain of finished automobile trade; distribution to the overseas markets is mostly carried out using deep-sea maritime logistics. Many shipping companies operating a fleet of RORO car-carriers have nowadays vertically integrated to become Third-party logistics providers (3PL) and manage the entire transport chain from factory to the dealer. The problem involves the tactical planning required by such an organization regarding the transportation/route planning and scheduling of these ships to meet their customers’ requirements. A planning problem may consist of integrated planning of three types of cargoes: The cargo of carmakers that have completely outsourced their logistics, mandatory spot cargoes and optional spot cargoes. For the first type of cargoes the company has to manage inventory stocks of cargoes at the ports at both ends apart from transportation planning. For the second and third type of cargo, it has to manage only the transportation. The problem thus becomes an extension to the inventory maritime routing discussed in the literature and involves combined planning of inventory routing as well as spot cargoes. The decision variables are the number of calls at each port, time windows for arrival, which ships to make which call, the amount of automobiles to be loaded at each call, etc. The itinerary of the ships should also include the mandatory cargoes of second type and if profitable, the third type of spot cargoes. The objective would be to minimize costs related to transportation and inventory costs at the terminals, while maximizing the profits through optional cargoes. The constraints are the inventory stock limits at the ports, Time-windows for loading and discharging at each port, ship capacities, etc.", :title "An integrated finished automobile logistics planning model; an extension of inventory maritime routing problem", :keyword2 95, :authors (27701 28092), :session 172}, 68 {:keyword1 10, :keyword3 126, :abstract "The research is aimed to development of approximate methods in nonlinear dynamics on A.M.Lyapunov methodology background. The stability theory methods, with asymptotic approach allow to establish the comparison method in reference to fundamental modelling, optimization, control problems in complex systems dynamics, to get the extension of reduction principle for general qualitative analysis, covering critical cases (quasi-Tikhonov’s systems).\r\nOriginal model, adequate to real process, as a rule is very complex, multi-disciplinary; and it is leading to nonlinear highly-dimensional, multi-connected problem. The existence of processes with different characteristic times is generating the additional difficulties in study by numerical methods; it is causing the specific problems of computing process stability (the badly conditioned matrixes). This generates the need of system decomposition, of reduction to shortened subsystem, giving qualitatively equivalent shortened model. The fundamental problem is arising: the development of regular algorithm for the building and substantiation of decomposed models acceptability.\r\nThe constructed approach (founded on stability/singularity postulates, on parametric stability methodology of N.G.Chetayev, P.A.Kuzmin, L.K.Kuzmina) allows to develop optimal manners of mathematical modelling, to establish the approximate methods in exact analysis. With reference to engineering practice this approach gives the theoretical substantiation of the approximate models and theories in strict solving problems of optimization and control for systems with multi-times scales. Developed approach is very effective in mathematical modelling and analysis problem for multi-scale, multi-disciplinary systems.\r\nThe author thanks RFFI for support of the work.\r\n", :title "Chetayev Stability Postulate in complex Systems Dynamics", :keyword2 23, :authors (40725), :session 201}, 85 {:keyword1 14, :keyword3 66, :abstract "During the talk  sufficient conditions  to get the lower semi-continuity of the multifunction of admissible solution in a parametric program  are given in terms of the lower limit of the  Hoffman constant. It will be shown that the multifunction is lower semi-continuous at these parameters at which the  lower limit of the Hoffman constant are positive.", :title "The positiveness of lower limits of the Hoffman constant in parametric polyhedral programs", :keyword2 13, :authors (28749), :session 194}, 86 {:keyword1 97, :keyword3 56, :abstract "In this talk we report results from a research project in which we have dealt with quantitatively modeling and simulating the diffusion of innovations (QuaSiMoDI). Our agent-based approach distinguishes itself from predecessors in that it allows for multiple rivaling products, it is geared towards convenience consumer products, consumers’ (re-) purchase decisions as well as points of sale choices are explicitly modeled, spatial aspects are considered, and various marketing measures with respect to targeting, timing and pricing can be combined for analyzing purposes. From a technical point of view, we have opted for a discrete event approach, because it avoids the difficulty to determine the sequence of events. We have experimented with several types of social networks as well as with diverse mechanisms for the exchange of information within the social network (“word of mouth”). The applicability of the simulation tool is exemplified by the (potential) introduction of a second generation biofuel on the Austrian market. Individual preference data for consumer agents used in these simulation runs has been collected by means of an adaptive conjoint analysis.", :title "An agent-based simulation of diffusion processes of frequently purchased consumer products", :keyword2 127, :authors (4357 15688 9171 454 15649), :session 130}, 89 {:keyword1 35, :keyword3 93, :abstract "Second order Stochastic Dominance (SSD) has a well recognised importance in portfolio selection, due to its connection to risk-averse behaviour theory. Recently proposed SSD-based portfolio models assume that a reference distribution is available; then, a portfolio is constructed, whose return distribution dominates the reference with respect to\r\nSSD. We analyse the effectiveness of such strategies in the context of enhanced indexation.\r\nEmpirical results support three main conclusions. First, the portfolios chosen by the SSD based models consistently outperformed the indices and the traditional index trackers. Secondly, the SSD based models do not require imposition of cardinality constraints since naturally a small number of stocks are selected. Finally, the SSD based models are robust with respect to changes in the scenario set and thus little or no rebalancing is necessary.", :title "Enhanced Indexation and Downside Risk Control", :keyword2 67, :authors (22875), :session 264}, 90 {:keyword1 34, :keyword3 35, :abstract "The recent crisis has reaffirmed the need to strengthen the procedures for monitoring banks with respect to their overall performance and the risks to which they are exposed. Within this context, the development of methodologies for undertaking sound analyses of bank performance is clearly of major practical importance. Multicriteria decision support techniques are well suited for this purpose. While multicriteria techniques are mostly used in a decision aiding/making context, this paper demonstrates how they can also be employed in an explanatory framework, which is of major importance in the area of banking management. In particular, in this paper multicriteria analysis methods are used to evaluate the financial performance of a sample of European banks over the period 2006-2009. The sample consists of 146 banks from 21 European countries, described over a set of financial ratios. In order to validate the obtained results and the associated findings under different evaluation schemes, we use three popular multicriteria approaches. These include a value function model, an outranking approach, and a variant of the envelopment analysis cross-efficiency model. Simulation and linear programming techniques are used to implement the evaluation process. The obtained results provide useful insights on the performance of the banks, the effects of the recent crisis, the relationship between bank performance and their size and country of origin, the stability of the evaluations over time and the factors that describe the dynamics of bank performance over time.", :title "Performance evaluation of european banks using multicriteria analysis techniques", :keyword2 63, :authors (2127 28773), :session 267}, 95 {:keyword1 29, :keyword3 85, :abstract "China's strong economic growth over the past 30 years has fueled its thirst for oil? therefore the oil supply security has become a threat to economic, political and military security. We select the public stockpiles, being built by China, and disruption tariffs as the elementary instruments mandated by government to reduce China’s vulnerability to the economic damage caused by oil import disruptions. Similarly, there exist many potential policies that resemble a tariff to maintain oil supply security. Quotas, subsidies, gasoline rationing and energy efficiency standards differ from a tariff in terms of their economic efficiency and equity. A Markov decision process model is developed to optimize China's oil stockpile\\tariff policies for maintaining oil supply security. The features of China are considered, such as the high capacity construction cost and the acroeconomic loss generated by spike of oil price. It is shown that the model is Markovian and a deterministic optimal policy exists. Then a recursive procedure is designed to get the optimal stockpile/tariff policies over time. These policies are compared from the viewpoint of benefit to China. The computational results indicate that stockpile/tariff policies should be selected preferably according to oil supply elasticity and China should adopt these policies with major oil imported counties jointly. We hope the results can favor policymakers of China.", :title "Comparison of China's policy instruments to maintain oil supply security", :keyword2 73, :authors (28801), :session 115}, 100 {:keyword1 96, :keyword3 0, :abstract "This work deals with the modeling and optimization of hospital evacuations where a number of patients have to be evacuated from a hospital building using resources such as stretchers and wheelchairs. Here, only static situations are considered such as an impending flood or a bomb in the vicinity of the hospital that has to be disarmed. The problem is modeled as a multi-mode resource-constrained project scheduling problem with transfer times where assistants, equipment, as well as the infrastructure of the hospital are modeled as resources while patients are modeled as activities. A MIP formulation, a tabu search algorithm as well as first results for this problem will be introduced.", :title "Modeling and Optimizing Hospital Evacuations", :keyword2 0, :authors (19076 14742), :session 53}, 106 {:keyword1 96, :keyword3 59, :abstract "The steel industry provides a wide field of application concerning instruments for Operations Research, particularly with regard to scheduling problems. The following scheduling problem arises in the heat treatment of steel plates. Given a single machine (a roller furnace) with finite capacity and a set of individual products (steel plates), the objective is to find a sequence which minimizes the total completion time. Due to many different technical, physical and logistical restrictions, this problem cannot be found in the scheduling literature in explicit form. It can be described as a kind of resource constrained scheduling problem with sequence dependent setup procedures. The main differences relative to classical resource constrained problems are that it is a continous process (so no batching), the entry point of the furnace is different from its exit point, the plates have to leave the furnace in the same order as they entered it and the predefined holding times must never be exceeded. In addition, a kind of setup procedure has to be considered in cases when two consecutive plates need different heat treatment temperatures. Depending on the temperature deviation, these plates have to kept a specific distance from each other in the furnace. \r\n\r\nThe problem can be formulated as a mixed integer linear program (MILP). Since it cannot be solved in polynomial time, a genetic algorithm is developed in order to provide heuristic solutions. These solutions can be used as benchmark solutions when testing new algorithms.\r\n", :title "Scheduling steel plates on a roller furnace", :keyword2 48, :authors (28756 5078), :session 240}, 111 {:keyword1 104, :keyword3 16, :abstract "Nowadays every firm either big or small uses telecommunication networks at different amounts and ways in order to continue their existence and complete their daily tasks and operations. Firms in other words customers can lease or buy required amount of network resource from telecommunication network suppliers to complete their operations. In this project, we investigate an optimization problem of telecommunication intermediaries. Intermediaries can acquire capacity from market of telecommunication backbone providers who offer different pricing and quality of service schemes. Then, they sell purchased capacity to end-users in order to gain some pro fit. Unfortunately, customers' demand are not known in advance. Therefore, intermediaries may end up having either slack capacity or unsatisfied customer demands. In this research, to overcome mentioned issues two-stage stochastic integer programming approach is proposed. In this methodology, first stage decision variables are which backbone provides to be chosen to acquire capacity. The second stage decision variables are which customers demand to be satisfied , and in which purchased capacity has to be utilized to in oder to satisfy realized demands by considering QoS request of each customer. Interestingly, scenario aggregated formulation of this problem leads to special case of well-known two dimensional bin packing model. To goal of the paper is to develop analytical method or heuristic algorithm to solve indicated problem effectively. Than evaluated performance of suggested method by using well known measures such as Expected Value of Perfect Information (EVPI) and Value of Stochastic Solution (VSS). It is also aimed to test stability of algorithm under different pricing and demand structure.", :title "Profit Maximization for Intermediaries in Telecommunication Networks Considering Quality of Service (QoS) and Capacity Constraints under Stochastic Demand", :keyword2 85, :authors (19359 15215 13270), :session 121}, 116 {:keyword1 126, :keyword3 108, :abstract "We consider the optimal control problem of the solidification process in metal casting. Liquid metal is placed into the work cavity of a mould with a prescribed configuration. A special setup is used to crystallize the metal. The mould is slowly moving among the furnace and begins to dip into liquid aluminum that has a relatively low temperature and thus is cooling the metal. At the same time the mould receives heat from the furnace and this heat doesn't allow the crystallization process to run too fast. The crystallization process is affected by different phenomena such as heat loss due to heat radiation, gain of energy by the mould due to expanse of heat radiation from aluminum and furnace, heat exchange between liquid aluminum and the mould.\r\n\r\nThe complication of the problem is that the metal can be present simultaneously in two phases: solid and liquid. The optimal control problem is to choose a regime of metal cooling at which the solidification front is close to a preset shape (namely, a plane orthogonal to the vertical axis of the object) and moves sufficiently slowly (at a speed close to the preset one). The time-dependent speed of the mould that moves along the furnace is the control function.\r\n\r\nThe process is described by a three-dimensional unsteady heat equation. Density of materials, their heat capacity and thermal conductivity depend on the temperature and are discontinuous in the border between the metal and the mould.\r\n\r\nThe optimal control problem was solved numerically using the gradient method. An effective method based on the Fast Automatic Differentiation is proposed for the evaluation of the cost functional gradient. The work was supported by the Program for Fundamental Research of Presidium of RAS P17, by RFBR No. 11-01-12136-ofi-m-2011.", :title "On the controlling of liquid metal solidification in foundry practice", :keyword2 23, :authors (18584 11599), :session 201}, 127 {:keyword1 77, :keyword3 8, :abstract "Finding structure in and making sense of a text in an unknown language without punctuation is a challenging problem, both in linguistics and in computational biology, where the texts are biopolymer sequences. We present first results on a new approach based on the minimum string cover problem.\r\n\r\nA string cover of a set of strings is a set of substrings such that concatenations of these substrings produce the original strings. The minimum string cover (MSC) problem consists of finding a cover with minimum cost under a given cost function. The standard problem is the unit cost case, where the goal is to minimize the number of different substrings. \r\n\r\nWe present the first integer linear program (ILP) of polynomial size for the problem, and additionally a practical branch-and-bound method to solve non-trivial MSC instances, based on a novel lower bound for MSC via shortest paths. \r\n\r\nWe extend the algorithm to find minimum partial covers, that is, covers that may contain up to a certain number of uncovered positions in the input strings. We experimentally evaluate the performance of our algorithm against the ILP approach.\r\n\r\nFinally, we discuss the challenges encountered when modeling real-world parsing problem with the MSC, which are less of a computational nature and more about choosing appropriate cost functions based on the nature of the data and on the biological questions involved. First results and experiences will be presented.\r\n\r\n\r\n\r\n", :title "Algorithms for the Minimum String Cover Problem and Applications to Biopolymer Sequences", :keyword2 12, :authors (28986 28964 28982), :session 65}, 132 {:keyword1 76, :keyword3 48, :abstract "The  Stochastic  Dynamic Distance Optimal Partitioning(SDDP)problem is based on a problem in industry, which contains an optimal conversion of machines. In successive stages parts (of different types) must be produced. For this purpose, the machines have to be converted into states, which are in accordance with the types of the parts. Initially, probability functions of the requirements of the parts are given. The realiza- tions of the requirements for a stage are known at the beginning of the stages (before the decision for the conversion of machines has to be made). The objective is to  minimize the expected cost of the conversions of the machines over the stages altogether (or in the case of an infinite horizon, the average expected cost per stage).\r\n\r\n   The SDDP problem is an extremely complex Operations Research problem. It shows several connections with other problems of OR and informatics such as stochastic dynamic transportation and facility location problems or k-server problems.\r\n\r\n  The formulation of distance properties for DA stochastic dynamic programming problems and corresponding statements led to the fact that the use of lazy algorithms is sufficient in order to compute optimal solutions of SDDP problems.\r\n    Under the assumptions of identical basic costs (in other words, of  unit distances), the average one-step reward functions of SDDP problems modelled as DA MDPs do not depend on the decisions. Optimal decisions then imply an ''almost-partial order'' of the states and the complexity of computing optimal decisions can be reduced. \r\n     Based on the last facts, the question of how the optimal decisions vary if the  basic cost change is of interest. This means a parametric analysis should be utilized in relation to variable cost. \r\n\r\n\r\n\r\n\r\n\r\n\r\n", :title "The Stochastic Dynamic Distance Optimal  Partitioning  Problem", :keyword2 99, :authors (28823), :session 240}, 133 {:keyword1 88, :keyword3 99, :abstract "\r\n\r\nThe performance analysis of a machine repair system having on line units along with mixed standby units under the care of single unreliable server is suggested. Whenever any unit fails, it is immediately replaced by a standby unit if available. In case when all standbys are used, the failure of remaining on line units occurs in degraded fashion. The server is turned on when there are N or more failed units present in the system; it is turned off when the system has no failed unit. The server is subject to breakdowns and repairs. The life time and repair time of failed units and the server are exponentially distributed. The governing equations are constructed using appropriate birth-death rates. After taking Laplace transform of set of equations, we employ matrix method to determine transient probabilities. Various performance indices such as expected number of standby units, expected number of failed units, probability of the server being idle, busy or broken down etc. are determined. Expressions for the Cost function, system reliability and mean time to failure of the server are established. Numerical results are provided for various system characteristics to examine the effects of different parameters.\r\n\r\n\r\n", :title "N-Policy for Unreliable Server Machine Repair System with Mixed Standbys ", :keyword2 89, :authors (28992 28990), :session 112}, 135 {:keyword1 106, :keyword3 96, :abstract "This work deals with the outbound luggage handling problem at airports. For each departing flight it is necessary to decide at which facility the handling of the bags should take place and when the handling should start. Bags arrive from check-in counters and from feeding flights for different outbound flights. If the handling of an outbound flight has not started, the bags will be stored in storage spaces. After the start of the handling, the bags are transported by a transport system e.g. conveyor belts, to the handling facilities. There the bags will be loaded into containers, pallets or carts for the transport to the aircraft. The existing handling resources are scarce and have to be used in an efficient way respecting the locations of the facilities and the parking positions of the aircrafts.\r\nThe presented problem is a dynamic, near real-time assignment problem. The developed solution approach should be robust to changing input data (e.g. delays, position changes) during the operations. The problem has a multi criteria objective function, since quality and efficiency issues have to be combined.\r\nWe present important requirements for the real world usage of the model and discuss different solution techniques. One solution method is a heuristic approach oriented on the logic of GRASP (Greedy randomized adaptive search procedure). Another solution method is a decomposition approach. The problem is divided into different sub problems. The sub problems are: determine handling time, assign area of handling and handling facilities. The area of handling is a geographical region and consists of several handling facilities. Each sub problem can be stated and solved as a MIP. The solution approaches are tested with real world data from Frankfurt Airport.\r\n", :title "Scheduling of outbound luggage handling at airports", :keyword2 59, :authors (22119 11799), :session 175}, 137 {:keyword1 12, :keyword3 10, :abstract "In computational phylogenetics, supertree methods assemble phylogenetic trees with non-identical but overlapping taxon sets, into a larger supertree: These supertrees contains all taxa of all input trees and describes the evolutionary relationship of these taxa. This problem can be formalized in different ways, to cope with contradictory information in the input. In particular, there exist methods based on encoding the input trees in a matrix, and graph-based methods with polynomial runtime. Evaluations have shown that the matrix representation methods will compute supertrees of better quality but, unfortunately, the underlying problems are computationally hard.\r\n\r\nI will present numerous result concerning a particular supertree framework, namely Matrix Representation with Flipping (MRF). The input trees are encoded in a 0/1/?-matrix, and we search for a minimum set of 0/1-flips such that the resulting matrix admits a directed perfect phylogeny. This is an NP-hard problem. First, I will present results on the parameterized complexity of the problem: If all input trees share the same set of taxa, then the problem is fixed-parameter tractable (FPT); but otherwise, the problem is hard also from the parameterized standpoint. Next, I will show that the problem is inapproximable. Then, I will present a data reduction as well as an Integer Linear Programming (ILP) formulation for the problem which, unfortunately, both do not work well in practice. On the positive side, I will present a novel heuristic for the problem, named FlipCut supertrees. Initial evaluations of the this heuristic are extremely promising, as reconstructed supertrees are of very good quality, and the method is orders of magnitude faster than any other method in our evaluation.\r\n", :title "Reconstructing Supertrees: The Matrix Representation with Flipping Problem and the FlipCut Heuristic", :keyword2 8, :authors (28978), :session 65}, 139 {:keyword1 14, :keyword3 42, :abstract "This talk presents recent research contributions in cooperative game theory, eco-finance and gene-environment networks, their dynamics, modeling and optimization. Motivations, applications and interpretations are from the sectors of finance, environment, medicine, education, development and international collaboration. We include uncertainty in polyhedral and ellipsoidal forms, and as stochastic differential equations as well. For turning from time-continuous to -discrete models, we use advanced Heun and Milstein schemes, respectively. We present hybrid models and use stochastic hybrid control. Further, we deal with cooperative ellipsoidal games, a class of transferable utility games where the worth of each coalition is an ellipsoid instead of a real number. Here, we study sharing problems under ellipsoidal uncertainty. We introduce the ellipsoidal core and study properties of this solution concept. Our talk pays a special attention to the optimization and control aspects, with an emphasis on mixed discrete-continuous and topological features; it ends with a conclusion, an outlook and invitation to future investigations.\r\n\r\n", :title "The OR of Eco-Finance Networks and Cooperative Game Theory under Uncertainty", :keyword2 35, :authors (19185 22326 20485 3524 26768 35072), :session 62}, 143 {:keyword1 96, :keyword3 36, :abstract "New mixed integer programming models are proposed for deterministic batch or cyclic scheduling in flow shops with parallel machines and finite in-process buffers. The flow shop is capable of processing different parts types and each part must be processed by at most one machine in each stage. When a machine finishes to process a part and the downstream buffer is full the machine is blocked. Machine blocking may also happen due to failures or prescheduled downtime events such as preventive maintenance, change of consumables, prescheduled production runs, etc. \r\n\r\nThe following scheduling modes are compared and the corresponding models are provided: \r\ngeneral scheduling, where any input sequence of parts is allowed;\r\nbatch scheduling, where parts of a given type are scheduled consecutively;\r\ncyclic scheduling, where a minimal part set is repetitively scheduled;\r\ncyclic-batch scheduling, where in each run of minimal part set, parts of a given type are scheduled consecutively.\r\nIn the cyclic scheduling mode, the minimal part set is first determined, i.e., the smallest subset of parts in the same proportion as the overall production target.\r\n\r\nModels for scheduling with all machines continuously available for processing throughout the entire scheduling horizon as well as for scheduling with an arbitrary pattern of machine availability due to prescheduled downtimes are provided. Numerical examples modeled after a real-world flexible flow line scheduling in electronics manufacturing are presented and results of computational experiments are reported. The results indicate that when set up times are negligible, the cyclic scheduling outperforms acylic batch scheduling and is more robust, in particular cyclic schedules better utilize machine availability periods around downtime periods.\r\n", :title "Batch vs. Cyclic Scheduling of Flexible Flow Shops by Mixed Integer Programming", :keyword2 77, :authors (1327), :session 147}, 145 {:keyword1 8, :keyword3 39, :abstract "The paper is devoted to solving multicriteria discrete optimization problems using the combination of the generalized algorithms of discrete optimization and the Bellman-Zadeh approach to decision making in a fuzzy environment.\r\nThe generalized algorithms (for example, P. Ekel and F. Neto, Algorithms of discrete optimization and their application to problems with fuzzy coefficients, Information Sciences, 176, 2006) are based on combining formal and heuristic procedures. They flexibly deal with objective functions and constraints (do not require their analytical specification) and provide one with quasi-optimal solutions after a small number of steps, thus overcoming the NP-completeness of discrete problems.\r\nThe application of the Bellman-Zadeh approach permits one to implement the principle of guaranteed result and to provide the constructive lines in obtaining harmonious solutions of multicriteria optimization problems via computationally efficient analysis of maxmin models (for example, W. Pedrycz, P. Ekel, and R. Parreiras, Fuzzy Multicriteria Decision-Making: Models, Methods, and Applications, Wiley, 2011).\r\nIn the paper, the uncertainty of initial information and evaluation of decision consequences, including their monocriteria and multicrietria risks, are treated by the construction and analysis of particular and aggregated payoff matrices. The first results in this field are reflected in (P. Ekel, J. Martini, and R. Palhares, Multicriteria analysis in decision making under information uncertainty, Applied Mathematics and Computation, 200, 2008).\r\nThe results of the paper are illustrated by the solution of several classes of power engineering problems.\r\n", :title " Algorithms of multicriteria discrete optimization and their applications", :keyword2 79, :authors (29036 29084 29045 27436 29038), :session 202}, 146 {:keyword1 96, :keyword3 0, :abstract "In this work we analyze a specific permutation flow-shop problem that additionally integrates sequence-dependent setup-times. In permutation flow -shop systems it is assumed that between different production stages the applied job sequences are not allowed to be changed. Consequently, only non-delay schedules are considered. Moreover, significant delays are caused by setup activities that occur for every product changeover. Since these activities are assumed to be sequence-dependent, the overall efficiency of a found schedule significantly depends on the resulting setup activities. Such kind of production systems can be frequently found, for instance, in the chemical industry, in the food industry, or in branches that face considerable capital commitment costs (like production processes of the steel industry). \r\nFrequently, buffer-reducing JiT-policies are applied in order to efficiently control these production processes. Therefore, in the considered model the minimization of the resulting total weighted tardiness is pursued. Owing to the resulting problem complexity and the limited computational time, the application of exact solution approaches is not promising. \r\nTherefore, two specifically designed meta heuristics are proposed. Specifically, a tabu search approach that makes use of a variable neighborhood is applied as well as a fast genetic algorithm. Both algorithms are widely tested by reference to a specifically designed set of challenging benchmark instances. Moreover, detailed comparisons with further state-of-the-art solution algorithms are provided. ", :title "Minimization of total weighted tardiness in permutation flow-shops with sequence-dependent setup times", :keyword2 59, :authors (17331 14800 5590), :session 53}, 147 {:keyword1 2, :keyword3 106, :abstract "Two nonlinear optimization models are introduced to tackle the Collision Avoidance Problem in ATM. It is known that a conflict situation occurs when the minimum safety distance between two aircraft is lost. So, given a set of aircraft configurations where speed, angle of motion and position are known, the aim of the first model consists of providing a new configuration such that all conflicts in the airspace are avoided. For achieving this goal, the aircraft can do three types of maneuvers: angle, velocity and altitude changes. The most difficult one is the angle change, being the subject of our proposal, such that some nonlinearities appear in eight blocks of constraints. Taking a geometric construction as support, a highly MINLP model is introduced for avoiding the conflict, such that the aircraft in conflict are forced to change their heading angle, so the objective function to optimize consists of minimizing the sum of the angle variations. Some particular cases are considered in the model to avoid unstable situations due to null denominator and false conflicts that would force the aircraft to change their angles without being in a real conflict situation. Once the first model is solved, the second step consists of solving a continuous quadratic model to calculate the optimal times on a given horizon where each affected aircraft (i.e., each one that has been forced to change its configuration) can turn again for reaching the predicted destination point. The objective function for the second model consists of minimizing the sum of the Euclidean distances between the aircraft updating them through the given time horizon. We report the computational experience that we have obtained so far while solving the problem by using a state-of-the-art MINLP optimization engine.", :title "Nonlinear optimization models for aircraft collision avoidance with horizontal maneuvers based on heading angle changes", :keyword2 80, :authors (29039 152 139), :session 175}, 153 {:keyword1 72, :keyword3 96, :abstract "In sports scheduling, a team is said to have a break when it plays two home (or two away) matches in a pair of consecutive rounds. Breaks are quite common in sports competitions, and are often one of the most important constraints in sports scheduling. In this contribution, we generalize this concept by also considering pairs of nonconsecutive rounds. We motivate this generalization with examples from football and traveling tournament scheduling. We show that a set of home-away patterns minimizing the number of generalized breaks cannot be found in polynomial time, unless P=NP. For the special case where all teams have the same set of breaks, the decision version becomes polynomially solvable; the optimization version remains NP-hard. For this special case, we also provide a lower bound for the number of generalized breaks for a given break set, thereby generalizing a classical result by De Werra that says any single round robin schedule for 2n teams, will have at least 2n-2 breaks.", :title "Breaks, cuts, and patterns", :keyword2 10, :authors (9583 6251), :session 143}, 154 {:keyword1 8, :keyword3 77, :abstract "In 1965 Edmonds provided the first complete description of the polyhedron associated with a combinatorial optimization problem: the matching polytope. As the matching problem is equivalent to the stable set problem over line graphs, many researchers tried to generalize Edmonds' result by considering the stable set problem over super classes of line graphs: the quasi-line graphs and the claw-free graphs. However, as testified also by Grötschel, Lovász, and Schrijver in their textbook (1988), ``in spite of considerable efforts, no decent system of inequalities describing the stable set polytope for claw-free graphs is known''.\r\n\r\nRecently the interest in claw-free graphs have been revived by Chudnovsky-Seymour decomposition theorem of claw-free graphs (2004). Indeed Chudnovsky and Seymour and then Eisenbrand, Oriolo, Stauffer, and Ventura completed the polyhedral description of the stable set polytope for the quasi-line graphs.\r\n\r\nHere, we provide an explicit linear description of the stable set polytope of claw-free, not quasi-line, graphs with stability number greater than three and with no 1-join. \r\n\r\nThanks to a Chvátal's theorem on composition of stable set polyhedra for graphs admitting 1-joins and to Cook's description of the stable set polytope for graphs with stability number two, only the description of the stable set polytope for claw-free graphs with stability number three is now needed to solve this longstanding open problem.", :title "The stable set polytope of claw-free graphs with stability number greater than three", :keyword2 42, :authors (1459 22799 4099), :session 229}, 155 {:keyword1 30, :keyword3 97, :abstract "We consider a hierarchical queueing system with two customer types (A and B) and two server types (A and AB). The AB servers are able to serve both A and B customers and are thus more expensive to employ. \r\n\r\nWe focus on fairly small call-centres (mostly up to 40 servers) with a majority of A-customers, who may gain economies of scale from using a hierarchical system rather than have dedicated staff for each of the two customer.\r\n\r\nWe seek to identify routing rules that enable us to achieve simultaneously the following objectives: (i) achieve a good server level (at most 10% of customers wait more than 20 seconds), (ii) keep server utilisation reasonable (below 80%) for both groups, (iii) equalise the utilisation level of both server groups and (iv) keep staffing costs down.\r\n\r\nWe demonstrate that the most commonly employed routing rules cause a conflict between the second and third objective: staffing levels which equalise the utilisation rate of the two server groups cause significant differences in service level between the two customer groups.\r\n\r\nA more sophisticated \"push\" routing rule achieves both objectives, but requires a large proportion of AB servers. In this rule, A-customers are directed towards AB servers when the utilisation level of the A-servers exceeds a certain threshold.\r\n\r\nOur main contribution is a \"pull-style\" rule which is fair to both customers and servers while limiting the number of AB servers and allowing a reduction in total staffing. In this rule, A-customers are directed towards AB servers when the utilisation level of the AB servers falls below a certain threshold, i.e. AB-servers \"pull\" A-customers when they are idle. Numerical examples indicate a reduction of up to 10% of staffing levels for small call centres.\r\n", :title "Server allocation in a hierarchical call centre", :keyword2 88, :authors (2690 12662 29044), :session 112}, 158 {:keyword1 25, :keyword3 97, :abstract "Estimation and analysis of segment-specific consumer preferences within the framework of choice-based conjoint analysis is commonly carried out by using Finite Mixture Multinomial Logit (FM-MNL) models. While MNL models suffer from the Independence of Irrelevant Alternatives (IIA) assumption, Finite Mixture Multinomial Probit (FM-MNP) models are able to capture segment-specific dependencies within and between choice sets by allowing the off-diagonal elements of the segment-specific covariance matrices to be non-zero. By constraining those segment-specific covariance matrices to be diagonal matrices, the FM-MNP model degenerates to the Finite Mixture Independent Probit (FM-IP) model, which provides results almost identical to the FM-MNL model. \r\n\r\nIn this contribution, we compare FM-MNP and FM-IP models in an experimental setting using the number of segments, the similarity between segments, the relative segment masses and the underlying correlation structure as experimental factors to give recommendations for the application of both model types under different scenarios. In particular, we address two questions: First, which of the two model types performs better under a respective scenario concerning model fit, parameter recovery and forecasting accuracy? And second, which of the experimental factors do significantly influence the model performance and if, how do those dependencies look like? The models are estimated by maximizing a log-likelihood function using an Expectation-Maximization algorithm. A comparison of the models under the respective scenarios illustrates the superiority of the FM-MNP model over the nested FM-IP model with respect to the performance measures. We further show that some experimental factors have a significant impact on model performance.\r\n", :title "Finite Mixture MNP versus Finite Mixture IP Models: A Comparison of Fit, Partworth Recovery and Predictive Validity", :keyword2 56, :authors (29040 18006), :session 257}, 161 {:keyword1 95, :keyword3 59, :abstract "The multiple depot vehicle routing problem with mix pickups and deliveries is often met in real-life scenarios of transportation logistics, but it has not received much attention by researchers. In the multiple depot problems, it is hard to allocate borderline customer to appropriate depot. In the past, borderline customers were allocated by the heuristic. In this paper, a genetic algorithm is supposed to allcate them. Then tabu search algorithm is employed to solve the single depot vehicle routing problem with mix pickups and deliveries. The proposed algorithm was successfully applied to benchmark instances in the literature, generating new best solutions. ", :title "A hybrid metaheuristic for the multiple depot vehicle routing problem with mix pickups and deliveries", :keyword2 106, :authors (29055 29871 29482), :session 247}, 163 {:keyword1 8, :keyword3 42, :abstract "We describe the implementation of an exact algorithm to solve \r\nsmall to medium-sized asymmetric traveling salesman problems with time\r\nwindows.\r\n\r\nThe algorithm combines a simple but effective heuristic to construct\r\na first tour with strong bounding at the root node and a subsequent\r\nbranch-and-bound search, which uses a hashtable-based\r\ndomination rule to prune large parts of the search space.\r\nBounding strategies are selected adaptively, so the algorithm\r\nruns quickly on a wide range of problem instances.\r\n\r\nWe present results of our algorithm on four sets of problem\r\ninstances from the literature and compare it to four different state-of-the-art\r\napproaches to solve the ATSPTW. Our algorithm is able to solve\r\nall instances solved by these approaches as well as about 20\r\npreviously unsolved instances.\r\n", :title "An exact adaptive branch and bound algorithm for the ATSPTW", :keyword2 106, :authors (23875 12428), :session 203}, 165 {:keyword1 101, :keyword3 0, :abstract "This study develops a single-warehouse, multi-store distribution model for a deteriorating product and aims to set inventory policies for both the warehouse and the stores. The demand for the product in the stores is constant and varies from one store to another. The stores can have different order quantity and inventory period. The model minimises the total cost of the system including ordering cost, inventory carrying cost and deterioration cost for both the warehouse and the stores. In order to solve the model a heuristic method using genetic algorithm is developed and some numerical examples are solved and discussed. The optimal solutions in both integrated and individual approach are presented to evaluate the results of the integration.", :title "A single-warehouse multi-store distribution system for a deteriorating item with different order quantity and inventory periods for the stores", :keyword2 106, :authors (24969 23038), :session 162}, 173 {:keyword1 54, :keyword3 0, :abstract "Although fare zones are applied for public transport networks in nearly every city all over the world the literature is lacking of quantitative planning approaches which involve the design of zones and the determination of the corresponding tarif. We propose a new fare and tarif zone planning problem. The objective is to maximise expected overall revenue taking into account contigous tarif zones and discrete tarif-levels. The approach proposed is general in the vein that the expected revenue can be determined by any arbitrary demand model. Here we employ a random utility model because of its appealing theoretical underpinning. Moreover, due to their realistic performance, random utility models are dominant in the demand modelling literature (particularly in public transport). We perform computational studies which show that the model is applicable to real world instances. ", :title "A new tarif planning problem for public transport", :keyword2 106, :authors (14588 16639), :session 192}, 177 {:keyword1 54, :keyword3 0, :abstract "Motivated by a problem in carbon capture and storage, we consider the problem of dividing a geographic region into sub-regions so as to minimize the maximum workload of a collection of facilities providing service over that region. We assume that the cost of servicing a demand point is a monomial function of the distance to its assigned facility and that demand points follow a continuous probability density. We show that, when our objective is to minimize the maximum workload of all facilities, the optimal partition consists of a collection of circular arcs that are induced by a multiplicatively weighted Voronoi diagram. When we require that all sub-regions have equal area, the optimal partition consists of a collection of hyperbolic arcs or quartic curves. This allows us to solve the partitioning problem quickly and without discretizing the service region.  We show that the dual of this infinite-dimensional problem has a natural interpretation:  the dual variables correspond to \"prices\" for a facility to serve a demand point, and our objective is to determine a set of prices such that the entire region is \"purchased\" by the facilities, i.e. that the market clears.  Finally, we give some computational results and an approximation algorithm for the related problem in which facility locations, as well as their assignment to the region, are permitted to vary.", :title "Dividing a territory among several facilities", :keyword2 14, :authors (28288), :session 221}, 179 {:keyword1 85, :keyword3 0, :abstract "We present a  method for\r\noptimal   policy  calculation of  stochastic control  problems whose value functions are convex.\r\nProblems of this type  appear in   many applications and encompass\r\n important examples arising in  the area of optimal stopping and\r\n in the framework of control,   based on\r\n partial observations.\r\nGiven\r\nconvexity of  value functions, we suggest a basis-free modification\r\nof the classical least-squares approach.", :title " A   least squares Monte Carlo method  for problems of optimal stochastic control with  convex  value functions", :keyword2 0, :authors (26045), :session 115}, 180 {:keyword1 109, :keyword3 0, :abstract "SSI Schäfer Noell GmbH is a leading supplier of automated warehouse solutions. In 2009, we planned a distribution center for a large distributor in the US, which is currently being installed. The DC includes a high bay warehouse and several connected automated picking areas. In this paper we will focus on one of these picking areas. \r\nParameters are as follows: demand for every item is stochastic, buffer capacity in the picking area is limited and replenishment capacity is also limited. Manufacturing time and setup time have to be considered in the replenishment process.  \r\nThe problem occurred that both the number of storage locations and the replenishment capacity are limited, and a violation of these capacity constraints would generate huge extra costs.  The Task can be categorized as a capacitated lot sizing problem with the usual extensions. Some project specific issues make it difficult to adopt the existing heuristics, and therefore a specific lot sizing algorithm is developed.\r\n", :title "Inventory optimization in an automated picking system", :keyword2 75, :authors (29091), :session 77}, 182 {:keyword1 8, :keyword3 77, :abstract "A subset S of nodes of an undirected graph G = (V, E) is a clique if the subgraph G (S) induced by S is complete and S is a maximal set. Clique subgraphs have diameter equal to 1 and maximum edge-density. If G (S) is not complete but has a low diameter and a high edge-density, S is a set of strongly interconnected nodes which may be interpreted as a clique relaxation. Clique relaxations are used to identify cohesive groups of actors in social networks and to detect functional modules in protein interaction networks.\r\nIn this talk we present integer programming formulations for diameter-constrained clique relaxation problems and report the computational results obtained with them on sets of randomly generated graphs. \r\n", :title "Models and algorithms for diameter-constrained clique relaxation problems", :keyword2 42, :authors (24129 24132), :session 228}, 184 {:keyword1 61, :keyword3 98, :abstract "From the beginning in the 1970s at the World Bank till today, GAMS, the General Algebraic Modeling System, has evolved continuously in response to user requirements, changes in computing environments and advances in the theory and practice of mathematical programing. We will outline several recent enhancements of GAMS supporting efficient and productive development of optimization based decision support applications.", :title "Recent Enhancements in GAMS", :keyword2 57, :authors (14898 10542), :session 79}, 185 {:keyword1 37, :keyword3 39, :abstract "Regarding usual regression models, deviations between observed data and estimated values from models are taken as observation errors, and it is assumed that the error fluctuations may follow a probability distribution. But in some cases, it is difficult to conceive that the deviations to the data obtained through systems such as economic systems, management systems, etc. are only caused by the observation errors. In this study, it is assumed that discrepancy between the estimated values and the data observed by the analytical models is caused by the structure of systems with fuzziness. In general, for the data used in fuzzy regression models, most of them are treated with ordinary non-fuzzy data. Regarding models with fuzzy data as well, only output is usually expressed with fuzzy numbers, so that models having input and output with fuzziness have not been discussed. In case systems are accompanied by human subjective uncertainty, it is considered that the fuzziness is included into both data supplied to the systems and data obtained from the systems. In this paper, we propose a regression model for fuzzy input-output data. The fuzzy regression model is found by solving two LP problems, both Min- and Max-problems, made up with provided data, and each of them indicates upper and lower bounds of possibility for solutions. Even in a special case as fuzzy numbers degenerate into usual non-fuzzy data, this model is applicable. In this system, we try to formulate a fuzzy regression model with fuzzy data and verify its effectiveness, applying it to the prediction and control of sale prices. From this, by obtaining the possibility linear regression model and taking fuzziness into account, we will be able to do more effectively the prediction and control of sale prices.", :title "Formulation of a Sale Price Prediction Model Based on Fuzzy Regression Analysis", :keyword2 56, :authors (29079), :session 108}, 193 {:keyword1 88, :keyword3 99, :abstract "The economic order quantity model, developed by Harris in 1913, has been broadly applied in industry. The basic model allows for determining the replenishment strategy of an inventory which minimizes purchase, delivery and storage costs. While the single-part inventory problem is well understood, both in a deterministic and a stochastic setting, many issues of optimal inventory management in the multi-part inventory case remain unresolved, most prominently in the stochastic setting. Here, we focus on a two-product inventory management problem. Different purchase, delivery and storage costs are assumed for the parts, which leads to different optimal replenishment policies. Moreover, demand is completely coupled: this means that each demand requires both parts and can only be satisfied if both inventories are non-empty. This coupling is a natural assumption if the parts are assembled into a single product. Prior to assembly, parts are possibly collected into a kit container for reducing material handling time and enhancing product quality, hence the term kitting buffer is used. \r\nThe inventory problem is studied in a Markovian setting. Reordering times are phase-type distributed while product demand is modeled by a Poisson process. If a part inventory is empty upon arrival of a demand, it cannot be satisfied immediately and the sale is lost. In terms of cost, we account for holding, shortage and purchase costs, the latter being an increasing concave function of the number of parts purchased. While no exact closed form formula can be found, computationally efficient numerical techniques are used which yield the cost of the inventory fast for any parameter setting. By numerical examples, we determine optimal reordering thresholds under various parameter settings. ", :title "Economic order quantity of a kitting process with stochastic demand and reordering times", :keyword2 75, :authors (29021 7336), :session 122}, 197 {:keyword1 8, :keyword3 0, :abstract "In container terminals at sea ports, all containers are stored in a yard before being loaded on a ship or after having been unloaded from a ship. The containers in the yard are piled up in stacks. Several adjacent stacks form a bay, while a certain number of adjacent bays form a block. Due to several reasons, containers have to be retrieved from a block in a predefined order which is unknown at the time the containers are stored. But since only the topmost container on a stack can be accessed by a crane, considerable time can be lost during retrieval with reshuffling blocking containers. The problem of finding a sequence of crane movements in order to retrieve all containers from a block in a predefined order with a minimum of crane movement time is called the container retrieval problem.\r\n\r\nWe developed a tree search heuristic based on a natural classification scheme of crane movements that is able to solve the container retrieval problem for typical problem dimensions in very short computation times. A comparison with the approach recently published by Lee and Lee (2010) shows that the heuristic is a very competitive method for solving the container retrieval problem. The mean crane operating time for the tested problem instances could be reduced by 15.70 %, the average number of crane moves was reduced by 8.64 %, while the calculation speed could be drastically improved from several hours to less than 10 seconds on average, the latter being especially important for the application in container terminals where the retrieval decisions have to be made in short periods of time.", :title "A tree search heuristic for the container retrieval problem", :keyword2 106, :authors (29102 6404), :session 179}, 199 {:keyword1 97, :keyword3 127, :abstract "There is a need for a theoretical explanation to enrich our understanding of the fundamental processes underlying Quality Management (QM) implementation. Almost all existing models of QM-Productivity relationships are top-down, equation-based and statistical, focusing on the associated effects (i.e. results not the acting process) of QM on productivity. They are more in the form of variance theories indicating an increase in X leads to an increase in Y not process theories pointing out how a process unfolds. The basic objective of this research is to address this lack of explanatory models by developing a process theory for QM-Productivity relationship.\r\n\r\nThe Multi-Agent Quality Model (MAQM), the output of this research, is a bottom-up, agent-based model of QM in an organization environment. To maintain the generality of the model, care is taken to develop an “intellective”, abstract model. Intellective models are founded on a theoretical abstraction of the reality. To do so, MAQM is based on a fusion of learning concepts in QM, organization science and computer science. Learning in QM includes learning from past experiences of success or failure, adaptation to and satisfying customer wants, learning from customer complaints and learning from continuous improvement of internal processes or necessary corrective actions within an organization. In MAQM, the environment is modeled as an agent called Customer generating different problems and the organization is modeled as a multi-agent system (MAS) trying to solve these Customer problems and to learn from problem solving through experiential learning and a reinforcement learning algorithm. Different scenarios modeling the effects of QM principles on organizational performance are tested within this setting.\r\n", :title "An Agent-Based Simulation of the Relationship between Quality Management and Productivity", :keyword2 87, :authors (29083 29104), :session 122}, 205 {:keyword1 14, :keyword3 126, :abstract " We consider the optimization problem of dividends and risk exposures of a firm in the diffusion model with linear costs.\r\nDividends are paid from the reserve of the firm to the shareholders, and the cumulative amount of dividends up to time $t$  is represented by an increasing stochastic process.\r\nWe take the risk  control with a positive risk level in consideration,   where a portion  of the reserve is paid for reinsurance. The policy is a pair of dividends and risk exposures.\r\nGiven a policy, the dynamics of the reserve process  is described by the  SDE with the  profit and the linear cost function.\r\n\r\n\r\nThe objective of the firm is to construct an optimal policy so as to\r\nmaximize the expected present value of dividend payments up to  bankruptcy.\r\n\r\n\r\nOur approach consists in finding a classical solution $v$ of the   variational\r\ninequality associated with this \r\nproblem.\r\nUsing the viscosity solutions technique, we develop the penalty method  to obtain a concave solution $u$ of the penalty equation.\r\nThe key is that it is interpreted as a kind of Hamilton-Jacobi-Bellman equation.\r\nWe can prove  the existence of $v$  as the limit of $u$, and analyze  the  free boundary $x^*$ for $v$.\r\nThe\r\noptimal policy of dividend payment and risk exposure is shown to exist in terms of the SDE  with\r\nreflecting barrier conditions for $x^*$. \r\n\r\n\r\n", :title "Optimal  dividend and risk control in   diffusion models with linear costs", :keyword2 99, :authors (29106), :session 198}, 207 {:keyword1 34, :keyword3 0, :abstract "In recent years, there has been an increase in the number and value of securities class actions (SCAs), attracting the attention of various stakeholders such as investors, managers, policy makers, lawyers, etc. A small but growing number of academic studies has also focused on the factors influencing the amount of settlement, the causes and consequences of SCAs, and the stock price movements. The present study employs an alternative approach to extend the literature, by examining the possibility of developing classification models to forecast securities class actions filed against U.S. firms. The development of such models, although quite important has not received attention compared to other financial decision making classification problems such as bankruptcy prediction and credit risk assessment where hundreds of papers have been published. The models are estimated using operational research techniques. More detailed we use multicriteria-decision aid techniques (MCDA) which are based on mathematical programming. These MCDA based models have various theoretical advantages over ones developed with traditional statistical and econometric methods (e.g. discriminant analysis, logistic regression). Furthermore, various applications from the field of finance (e.g. bankruptcy prediction, credit risk assessment, acquisitions prediction) reveal that the MCDA models tend to outperform the ones developed with traditional methodologies. Information about SCAs is collected from Stanford Law School Securities Class Action Clearinghouse, while financial data about the firms are obtained from OSIRIS database of Bureau van Dijk. The study covers the period 2000-2010. \r\n", :title "Multicriteria decision aid models for the prediction of securities class actions", :keyword2 37, :authors (29108 5086 30074 2128), :session 109}, 211 {:keyword1 97, :keyword3 18, :abstract "Military decision makers are facing new challenges, such as more asymmetric warfare and irregular forces, which yield new demands on their support tools. For the analysis of military operational plans, we find that multiple alternatives from morphological analysis combined with the methodology of a qualitative cross-impact matrix (CIM) can describe and analyze the internal dynamics of the plan. The constructed CIM can be used as input to an operations research tool that enables analysis and comparison of military plans. In this context, a plan is a sequence of activities performed by a military force that together will lead to a desired end state. The CIM consists of values describing how each pair of activities within a plan affect one another. These values have previously been assigned by subject matter experts, but to reduce problems related to traceability and subjectivity, we will propose simulation for generating the values. The aim is to use models as simple as possible without losing too much accuracy in the results. The simulation state is made up of collective states of a plan’s objects, e.g. actors and environmental objects, and makes up the conditions under which the activities will be executed. An activity’s execution can change the plan objects’ states and hence also the simulation state. The conditions are then altered for the remaining activities and thus they are impacted by this event. A value representing to what extent the activity affects another is calculated for each pair of activities. Preliminary results indicate that the proposed method is practicable and beneficial in terms of its suggested advantages but needs further examination. Creating the necessary models is costly and must be taken into consideration when continuing the evaluation.", :title "Simulating the interrelationships of military plan activities", :keyword2 60, :authors (28947 29837 29836), :session 253}, 216 {:keyword1 85, :keyword3 0, :abstract "We present a sequential nonsymmetric Branch and Fix Coordination algorithm for solving medium and large scale multi-stage mixed 0-1 optimization problems under uncertainty. The uncertainty is represented via a nonsymmetric scenario tree.  An information structuring for scenario cluster partitioning of this nonsymmetric scenario tree is also presented, given the general model formulation of a multi-stage stochastic mixed 0-1 problem. The basic idea consists of explicitly rewriting the nonanticipativity constraints (NAC) of the 0-1 and continuous variables in the stages with common information. We decide the stage break to generate the number of cluster submodels. As a result an assignment of the constraint matrix blocks into independent scenario cluster models is performed by a so-called cluster splitting-compact representation. This partitioning allows to generate  a new information structure to express the NAC which link the related clusters, such that the explicit NAC linking the submodels together is performed by a splitting variable representation. The new algorithm has been implemented in a C++ experimental code that uses the open source optimization engine  COIN-OR, for solving the auxiliary linear and mixed 0-1 cluster  submodels. We give computational evidence of the model tightening effect that have preprocessing techniques in stochastic integer optimization as well, by using the probing and Gomory and  cuts identification and appending schemes of the optimization engine for solving also stochastic mixed 0-1 problems. Some computational experience is reported to validate the new proposed approach.", :title "On solving  strong  multi-stage nonsymmetric stochastic mixed 0-1 problems", :keyword2 77, :authors (139 23051 22499 1527), :session 117}, 217 {:keyword1 85, :keyword3 0, :abstract "In this paper we present a set of approaches for stochastic optimizing of immunization strategies based on risk averse measures as alternatives to the optimization of the objective function expected value, i.e., in the so-called risk neutral environment.  The risk averse measures to consider whose validity is analyzed in this work are as follows: min-max regret,  mean-risk immunization,  two-stage and multistage Value-at-Risk strategy,  two-stage  Conditional Value-at-Risk  strategy,  two-stage  and multistage stochastic dominance strategy, and the new ones two-stage and multistage mixture of VaR & stochastic dominance, and as a result the multistage LP problem becomes a multistage mixed 0-1 stochastic model. Most of these measures require from the modeler a threshold for the objective function related to each scenario (the recent ones even allow a set of objective function so-called profiles) and a failure probability  for not reaching the threshold. Uncertainty is represented by a scenario tree and is dealt with both two-stage and multi-stage stochastic (linear and) mixed integer models with complete recourse. We will test the different risk averse strategies presented in the paper by using, as a pilot case, the optimization of the immunization strategies in fixed-income security portfolios under some sources of uncertainty. The main difference of the bond portfolio strategies that are proposed in the work and the models that have been encountered in the  literature is that we consider an investor who wishes to invest in a market with coupon bonds with different risk of default. ", :title "Modern multistage risk measures for immunizing fixed-income portfolios under uncertainty", :keyword2 99, :authors (29119 139 23051 22499), :session 118}, 219 {:keyword1 12, :keyword3 0, :abstract "Regression methods are used to explain the relationship between a single response variable and one or more explanatory variables. Graphical methods are generally the first step and are used to identify models that can be explored to describe the relationship.  Although linear models are frequently used and they are easy to use, many important associations are not linear and require considerably more analytical effort. \r\n\r\nThis study is focused on nonlinear models.  To perform statistical inference in this setting, we need to account for the error structure of the data. The experiment design for the nutrition data that we use called for each subject to be studied under two different values of the explanatory variable. However, some subjects did not complete the entire study and, as a result, data were available for only one value of the explanatory for some subjects. \r\n\r\nThe bootstrapping method will be used to re-sample the data points with replacement, and these samples will be used with nonlinear parametric model. The confidence intervals for the parameters of the nonlinear model will be calculated with the reflection method for the nutrition data set. The break point of the spline regression will be determined for the same data set.\r\n\r\nAlthough the nutrition data set will be used for this study; the basic ideas can be used in many other settings in areas such as education, engineering and biology.  \r\n", :title "Analysis of two different  regression models and bootstrapping", :keyword2 80, :authors (29050), :session 81}, 220 {:keyword1 88, :keyword3 0, :abstract "In the design and analysis of any queueing system, one of the main objectives is to reduce congestion which is measured in terms of average queue (system) length, average waiting time in the queue and blocking probability. There are several approaches to reduce congestion and most commonly used approaches are either controlling the arrival rates or service rates. In this paper we take up the second approach and apply it to a batch service queue. We consider a single server queue with finite-buffer where customers arrive according to Markovian arrival process and are served in batches of minimum size 'a'  with a maximum threshold value 'b'. The service times of the batches are arbitrarily distributed and dependent on the size of the batch. Using the embedded Markov chain and supplementary variable methods, we obtain the joint distribution of the number of customers in the queue and number with the server at arbitrary-epoch.  We also   obtain distributions of the number of customers in the system, in the queue, undergoing service with the server. Our numerical studies have established the fact that serving batches with service rates depending on the size of the batches leads to reduction in the values of average queue (system) length, average waiting time in the queue and blocking probability. This model has potential application in computer-communication network, telecommunication and manufacturing systems.", :title "Performance analysis of a finite-buffer batch-service queue with batch-size-dependent service under Markovian arrival process", :keyword2 99, :authors (29088 29138), :session 113}, 228 {:keyword1 78, :keyword3 45, :abstract "The process of drawing decision boundaries around classes for separating patterns in data is called masking.  A classifier partitions multidimensional space into decision regions belonging to different classes.  One of the more popular methods for solving such discriminant analysis problems from a prediction point of view is to use brain-like learning systems, e.g., the artificial neural network (NN) method.  The current study seeks to build linear programming (LP) models for separating patterns in data.  The method uses LP to construct and train a higher order LP network.  We propose a sequential masking algorithm using different masking functions for different classes and/or in different passes to classify patterns in data.  A pattern is never reclassified more than once in this algorithm.  We apply our LP masking algorithm, as well as NN and decision tree classifiers, to two databases.  One is a breast cancer database involving nine attributes, with two classes emerging in breast cytology diagnoses: benign or malignant.  The other is a diabetes detection database involving eight attributes, with two diagnostic classes: negative or positive.  The NN model involves a multi-layered perceptron trained by a back-propagation algorithm.  The initial results obtained suggest that our proposed algorithm performs at least as well as, if not better than, the NN and decision tree classifiers.  This appears to be an important finding given that, in particular, NN models are far better referenced in the discriminant analysis literature for their predictive power compared to that of LP models.  The proposed LP masking algorithm proves to be effective in dealing with the two health classification problems.", :title "A Proposed Linear Programming Masking Algorithm for Pattern Classification: Application to Health Databases", :keyword2 5, :authors (25361 20382), :session 88}, 230 {:keyword1 7, :keyword3 0, :abstract "In this study, we consider a capacity expansion problem in a Fixed Job Scheduling (FJS) environment. In FJS, jobs having predetermined ready times and deadlines are to be scheduled on identical parallel machines. Each job should start its processing as it enters the system, otherwise it cannot be processed. The problem is frequently observed in manufacturing and service environments. The problem is studied separately under two main headings in literature: tactical and operational. The tactical FJS problem minimizes the total cost of machines that will process all jobs in the system, whereas the operational problem selects a subset of jobs for processing that will maximize the total weight for a predetermined number of machines. Traditionally, tactical FJS is used for capacity planning. However, due to its nature, the problem assumes stability of the system for long periods of time, requires long term forecasts of job reservations, and ignores cancellations or possible changes. In our study, we consider the optimal capacity expansion plan and FJS decisions simultaneously. For this purpose, we develop a mathematical model that integrates the structural properties of tactical and operational FJS models and handle both job weights and machine costs. An exact solution algorithm is proposed for the problem, which runs in polynomial-time. The algorithm is based on a combination of tactical and operational solutions. The algorithm could be executed at the beginning of each planning period, and will yield the optimal capacity expansion level for that period. The study is supported by the Scientific and Technological Research Council of Turkey (TUBITAK).", :title "Optimal Capacity Expansion in Fixed Job Scheduling", :keyword2 96, :authors (19095), :session 145}, 231 {:keyword1 31, :keyword3 0, :abstract "There is a growing body of literature acknowledging that respondents to Discrete Choice Experiments often use simplifying strategies, like ignoring one or several attributes to provide with their choices. This paper analyses the reliability of the stated non-attendance approach in the context of environmental valuation using a simulation experiment and real data employed determining the externalities of onshore wind power generation in Germany.\r\n\r\nThe simulation experiments are focused on various issues related to stated non-attendance. First of all, the difference between the effects of choice card and serial non-attendance on the variances of estimated parameters is analysed.  The second issue analysed in the simulation experiment is the inferred non-attendance. In order to infer the possible non-attendance the classical approach proposes the use of coefficient of variation. The second simulation experiment is then devoted to the analysis of the threshold value for this coefficient.\r\n \r\nFinally, all these results obtained in the theoretical part based on simulations are applied to the estimation of a Random Parameter Logit (RPL) model using data from a choice experiment aiming at measuring of externalities of onshore wind power generation in Westsachsen, a region in the eastern part of Germany.\r\n\r\nThe results show that the type of stated non-attendance (serial and choice card) really has an impact on the variances of estimated coefficients of an RPL and that the threshold for the coefficient of variation to be used varies considerably with percentage of respondents who ignored an attribute. Finally, the estimations based on real data reveal that models that take the inferred attribute non-attendance into account result in a better performance.\r\n", :title "Non-attendance in choice experiments in the context of environmental valuation: A simulation experiment", :keyword2 0, :authors (12515 29150 29157), :session 131}, 236 {:keyword1 95, :keyword3 8, :abstract "Logistics is everywhere and everything in logistics can be optimized! However, many of the arising optimization problems are NP-hard, implying that in real life logistics approximations are indispensable.\r\n\r\nIn this talk, we concentrate on two routing problems in the field of logistics: One being a routing problem in a supply chain when delivering goods from suppliers through production sites and distribution centers to customers, the other being a generalized packet routing problem in the warehouse. The objective in both such problems is to minimize costs, which arise, e. g., from transportation, storage, or time restrictions. Various constraints make the two problems NP-hard. For the first problem such constraints contain unsplittability of orders, minimum throughputs for warehouses, or non-linear transport cost. For the second problem, we extend the general packet routing problem in basically two ways: Firstly, we introduce operating times for every packet in every node; secondly, we give each packet sets of nodes from which one node for every set has to be visited.\r\n\r\nWe model the two logistic routing problems as mixed integer programs, thereby discussing new algorithmic challenges and open problems.", :title "NP-Hard Routing Problems in Logistics", :keyword2 106, :authors (29153), :session 182}, 239 {:keyword1 19, :keyword3 29, :abstract "Strategic decisions in society are often based on vision of the ideal-type future, e.g. the 2000 Watt society and 1 ton CO2 society visions in the Swiss electricity sector. Different groups of stakeholders often propose and support different vision. Whilst some aspects of such visions are in fundamental conflict, the implementation (i.e. resource allocation for implementation) aspects may offer a space for compromise. We present a novel approach for analytical support of such visions-based decisions. This approach estimates if several visions intersect or are mutually exclusive with respect to the resource allocation options. It identifies the conflicting aspects between the visions and suggests options for reaching consensus. The case of the 2000 Watt society and 1 ton CO2 society visions in the Swiss electricity sector are used as examples.", :title "Analytical support of visions-based decisions: the cases of 2000 Watt and 1 ton CO2 visions in the Swiss electricity sector", :keyword2 44, :authors (23706 24091 24093), :session 251}, 240 {:keyword1 32, :keyword3 0, :abstract "In this research the Self-Organizing Map (a.k.a. Kohonen Maps) is applied to the analysis of the interrelationships and dynamic of three important markets: exchange rates (FOREX), oil (Brent) and Gold. The map is trained with approximately 2500 input patterns corresponding to daily data of five variables, namely US $/€, US $/Yen and US $/£ official exchange rates, Brent price and Gold price. An initial map is built and later refined after some input data preprocessing. Viscovery SOMine® is used for the computation and results visualization. The results show the existence of distinct clusters of prototypes corresponding to different time intervals. Each time interval corresponds to different relative values of the input variables. The map, thus, captures the dynamics of these variables. Out-of-sample quantization error is lower for the exchange rates than for the oil and gold prices. It is recommended to re-calibrate the map periodically so as to incorporate the most recent data and thus keep it updated.", :title "Self-Organizing Map of Exchange Rates and Oil and Gold Prices", :keyword2 0, :authors (29159 29211 9590), :session 107}, 254 {:keyword1 42, :keyword3 65, :abstract "Networks are used to model a variety of real life applications. One measure used to evaluate networks is the maximum flow that can be sent through the network from a pre-defined source node to a pre-defined destination node. \r\n\r\nConventionally, network elements are assumed to remain functional at all points in time. However in real life applications like telecommunication networks and transportation networks, network elements can break down and become non-functional from time to time. Such networks are modeled as reliable networks, in which each network element is assigned a reliability value which is the probability with which that element is functional in the network. At any point in time therefore, only a sub-network of the original network, called a network state, is functional.  The value of maximum flow in different network states can be different and since each network state is observed with a certain probability, the maximum flow through a reliable network is a random variable. \r\n\r\nThe problem of computing the probability mass function of maximum flow through a reliable network is NP-hard. Exact algorithms for this problem are either based on state space enumeration, or require enumeration of all paths or cuts between the source and the destination node. In this paper, we present a state space enumeration based algorithm called TOP-DOWN. It computes the probability mass function in decreasing order of maximum flow values. This order of enumeration makes this algorithm attractive for reliable networks in which element reliabilities are high such as in telecommunication networks. We compare our algorithm with a path based algorithm and show that it solves problems much faster and is thus able to handle much larger problem sizes than such algorithms.\r\n", :title "Computing the probability mass function of the maximum flow through a reliable network", :keyword2 89, :authors (18644 220), :session 206}, 262 {:keyword1 45, :keyword3 97, :abstract "Due to an increasing number of mass casualty incidents, their high complexity and uniqueness, decision makers need Operations Research-based policy models for training emergency staff on planning \tand scheduling at the incident site. We develop a discrete event simulation policy model which is applied by the Austrian Samaritan Organization. By calculating various emergency scenarios from realistic small, simple, urban to a rather big complex, remote mass casualty ones, our policy model helps enhance the quality of planning and outcome. Furthermore, the organization of an advanced medical post can be improved in order to decrease fatalities as well as quickly treat and transport injured individuals to hospitals. \r\n\r\nThe purpose of this paper is to analyze the best balanced strategies to manage staff of ambulance services for maximizing quick treatment of patients and fast evacuation of the incident site as well as for minimizing the number of fatalities. Using a realistic predetermined disaster scenario, players act in the experiment as on site commanders to decide on sending staff to triage, to different treatment rooms for care and on-site transportation, as well as to transportation to hospitals. We investigate to what extent players succeed in the simulation and improve over time. Furthermore, we examine differences among player groups such as students and practitioners.\r\n", :title "A disaster planning management game for ambulance services: experimental analysis of players’ strategies and success", :keyword2 22, :authors (24823 770 281 29181 29182), :session 48}, 264 {:keyword1 40, :keyword3 0, :abstract "We are concerned with the class of transferable utility games that are positive integer multiples of some directed simple game. The players in this class of games are assumed to face an integer allocation problem. An example is an electoral committee voting for the allocation of a number of indivisible cabinet seats. We show that the nucleolus of such a game with respect to the set of nonnegative integer payoff vectors is composed of the images of a particular element of this set under all symmetries of the game. The element weakly preserves the desirability relation between the players and belongs to a comparably small subset of admissible payoff vectors. We derive from this result an algorithm for computing the nucleolus. We thereby obtain the integer nucleolus of the game, i.e. the nucleolus with respect to the game's integer imputation set, whenever this set is nonempty and, hence, there is at most one winning player. The algorithm proceeds by implicit\r\nenumeration.", :title "An Algorithm for Computing the Integer Nucleolus of Multiples of Directed Simple Games", :keyword2 0, :authors (28944), :session 136}, 267 {:keyword1 97, :keyword3 18, :abstract "Mathematical models and computer simulations of pedestrian movement\r\nserve to better understand the flow of a crowd in applications that range from the best placement of an advertisement billboard to risk analysis when planning large events. The majority of those models are restricted to aggregate crowds of individuals neglecting the influence of social groups. Only recently has the development of group models within a crowd become a new focus. New models emerge, but the proplems of validation and comparability have not yet been adressed. In this paper we suggest and demonstrate a number of basic tests with the gaol to ensure a minimum\r\nquality standard for group models. The tests are mostly qualitative or visual. E.g.: Do people walk abreast as suggested by social communication models? Are they capbable of splitting and reuniting when navigationg an obstacle like a column? We also propose a comparison to fundamental diagrams extracted from a field study by Oberhagemann and a quantitative test based on a laboratory experiment. We apply all test scenarios to our own pedestrian stream simulator to prove the feasibility of our suggestions.", :title "How to validate group models in pedestrian stream simulators: Proposal for basic tests", :keyword2 106, :authors (26752), :session 90}, 268 {:keyword1 126, :keyword3 0, :abstract "This paper considers a class of optimal control problems that allows jumps in the state variable. We present the necessary optimality conditions of the Impulse Control Maximum Principle based on the current value formulation. By reviewing the existing impulse control models in the\r\nliterature, we point out that meaningful problems do not satisfy the sufficiency conditions. In particular, such problems either have a concave cost function, contain a fixed cost, or have a control-state\r\ninteraction, which have in common that they each violate the concavity property of the underlying model. The implication is that the corresponding problem in principle has multiple solutions that satisfy the necessary optimality conditions. Moreover, we argue that problems with fixed cost do not satisfy the conditions under which the necessary optimality conditions can be applied. However, we design a transformation, which ensures that the application of the Impulse Control Maximum Principle still provides the optimal solution. Finally, we show for the first time that for some existing models in the literature no optimal solution exists.", :title "Impulse Control in Operations Research: Necessary Optimality Conditions, Sufficiency and Existence", :keyword2 0, :authors (29186 10538 23254), :session 201}, 275 {:keyword1 59, :keyword3 8, :abstract "In this paper we investigate how evolutionary algorithms (EAs) for solving the vehicle routing problem (VRP) can be improved by distribution. Our investigations are based on a generic distributed EA for the VRP, which consists of autonomous processes that create heterogeneous evolutionary environments, perform evolution on separate populations of chromosomes, and communicate asynchronously through occasional migrations of chromosomes. In accordance with our aim, the considered algorithm is purely evolutionary, i.e. it is based only on evolutionary operators and migration, thus not relying on any auxiliary heuristic such as local search. The paper presents experiments where our distributed EA has been tested on some benchmark VRP problem instances. The experiments clearly show that the algorithm, when adequately configured and tuned, can achieve a superlinear speedup. Thus indeed, distribution can considerably improve an EA for the VRP, not only by executing some operations in parallel, but also by producing better results for the same total number of operations. Such improvement is possible because a set of heterogeneous and fairly isolated evolutionary processes can assure more diverse search for solutions than a single process.", :title "Designing an efficient distributed evolutionary algorithm for the vehicle routing problem", :keyword2 74, :authors (2474 10386), :session 75}, 279 {:keyword1 59, :keyword3 0, :abstract "Tabu search (TS) is often an algorithm of choice to solve hard combinatorial optimization problems. It is a modification of local search which provides a strategy for escaping locally optimal solutions by accepting worsening moves if no improving moves are available. Since it is based on neighborhood search, TS requires a large number of iterations to move from one region of the solution space to another. Also, since it works by maintaining and checking a tabu list, TS iterations are expensive. In large combinatorial optimization problems, the number of locally optimal solutions is large, and often these solutions are far from each other given a neighborhood graph structure for the problem. Hence unless one is lucky enough to start with an initial solution that is “close” to an optimal solution, TS has little chance of obtaining an optimal solution within reasonable time. In this paper, we present a heuristic called diversified local search (DLS). The basic idea in the algorithm is similar to multiple-start local optimization (MSLO). There are however two key differences between them. First, in MSLO, the number of initial solutions from which the algorithm is started is fixed, while in DLS, there is no a-priori limit on the number of such initial solutions. Second, initial solutions in MSLO are chosen at the beginning, while the initial solutions in DLS are chosen in an adaptive manner so as to thoroughly explore all areas of the solution space. We present a comparison of the results obtained from TS and DLS on traveling salesman problems with up to 1500 nodes to demonstrate that DLS comprehensively outperforms TS for these problems. We show that often within a few minutes DLS generates solutions that are better than the best solution that TS encounters in an hour.", :title "Diversified local search", :keyword2 0, :authors (24105 220), :session 238}, 281 {:keyword1 87, :keyword3 89, :abstract "FMEA is a systematic process meant for reliability analysis. Nowadays FMEA is mainly applied in industrial production of automobiles as well as their mechanic or electronic components, and etc. FMEA improves operational performance of the production cycles and reduces their overall risk level. Consequently, FMEA anticipates, evaluates and reduces risk of failures that may occur during the life time of a system. Risk is measured in terms of Risk Priority Number (RPN), which is an index obtained by multiplying three risk parameters: occurence, severity and detection. RPN indicates a global value of each potential failure. All failures are prioritized according to these RPN values and corrective actions for reducing these risks are planned and applied. From this standpoint;  applying an FMEA to a production cycle means following a series of successive steps: analysis of the process or product in every single part, list of identified potential failures, evaluation of their occurence, severity (in terms of effects of the failure to the process and to the surroundings) and detection technique, global evaluation of the problem and identification of the corrective actions and control plans that could eliminate or reduce the chance of the potential failures. Based on these brief definitions given above,  this research is carried out in order to integrate process FMEA with a real case study in an OEM supplier that produces sealing strips for local and foreign automotive manufacturers. The main objective of the process FMEA application is to reduce high customer complaints and scrap rates of the process. In this study, potential failures are classified, high risks in the process are identified, and corrective actions are determined for the automotive OEM supplier. \r\n", :title "Implementation of failure mode and effects analysis (FMEA) in an automotive supplier", :keyword2 101, :authors (23890 29194), :session 222}, 287 {:keyword1 88, :keyword3 75, :abstract "In this talk we present an analytical approach to derive the exact\r\nperformance measures of closed queueing networks with finite waiting buffers and processing times following phase type distributions. These queueing networks are analyzed by modeling complete systems as Markov chains. We point out how blocking states are modeled and present the implementation of the approach. Lastly, the computation time is investigated.", :title "Exact analysis of closed queueing systems with phase-type distributed service times and finite buffers", :keyword2 99, :authors (29197), :session 114}, 295 {:keyword1 106, :keyword3 63, :abstract "In this talk we present a metaheuristic approach to solve a new bi-objective routing problem. The problem consists of designing a set of routes, each passing through a central depot, while minimizing total costs. We present a bi-objective mathematical formulation for the problem at hand, which is solved using a metaheuristic based on the concepts derived from Large Neighborhood Search.\r\nThe Bi-objective Capacitated m-Ring-Star Problem (B-CmRSP) consists of designing a set of m rings through a subset of nodes within a given graph. When designing those routes additional constraints with respect to capacity have to be considered. The first objective typically refers to minimizing ring costs, i.e. costs related to the length of the resulting rings. Furthermore for nodes that do not lie on a ring, additional assignment costs need to be taken into consideration. These two goals are conflicting by nature and lead to a bi-objective formulation of the problem at hand. Routing problems in general have been an active field of research within the last decades. More recently, other than just focusing on pure routing related issues, problem variants have been investigated, also taking into account location and issues related to the resulting coverage. Typical applications for the problem at hand can be found in the context of school bus routing, design of routes for medical services (i.e. disaster relief operations), network design of fiber optic communication networks, the location of post boxes, etc.\r\n", :title "Large Neighborhood Search for solving the Bi-Objective Capacitated m-Ring-Star Problem", :keyword2 54, :authors (15802 10538), :session 246}, 296 {:keyword1 77, :keyword3 80, :abstract "Mixed integer nonlinear programming is a challenging optimization area. It\r\ncombines continuous nonlinear and mixed integer programming, which are both\r\non their own difficult topics. Although there exists lots of different\r\napplications only few efficient solution methods are yet developed and most of\r\nthem are hardly applicable for realistic test cases.\r\nWe present a new solution approach that is derived from continuous SQP\r\nalgorithms.  To guarantee global optimality for convex problems the method is\r\nstabilized by outer approximation techniques. Comparative numerical results\r\nfor 55 test cases arising from applications in petroleum industry and 100\r\nnonlinear and often non-convex academic problems indicate that the proposed\r\nmethod is very efficient in terms of the number of function evaluations. This\r\nis the main performance criterion for realistic engineering applications based\r\non time-consuming simulation models. In contrast to most other available\r\nsolution techniques for solving mixed-integer nonlinear programs the presented\r\nalgorithm is based on the successive solution of mixed integer quadratic\r\nprograms. Since the efficient solution of these subproblems is nontrivial but\r\nof major importance for our solution approach, we also focus on solution\r\nmethods for convex mixed-integer quadratic programs. Especially the\r\nconstruction of cutting planes is investigated.\r\n", :title "Mixed-Integer Nonlinear Programming based on Mixed-Integer Quadratic Approximations", :keyword2 84, :authors (8334 23909 23745), :session 60}, 297 {:keyword1 120, :keyword3 77, :abstract "In many applications today the number of features for which data is collected is much larger than the sample size based on which inference is made. This is particularly true for applications in bioinformatics, like for example micro arrays, genome wide association studies (GWAS) or next generation sequencing. However, the theory presented in this talk is of general interest in any data mining context, where the number of \"interesting\" features is expected to be small. \r\n\r\nThe notion of asymptotic Bayes optimality under sparsity (ABOS) is introduced, and in a regression setting conditions are given under which certain model selection criteria are ABOS. In particular mBIC and mBIC2 are introduced, two modifications of BIC which in case of an orthogonal design matrix control the family wise error and the false discovery rate, respectively. Both for mBIC and mBIC2 conditions are given under which each criterion is ABOS.\r\n\r\nIn practice model selection based on criteria like mBIC can be formalized as a mixed integer program. In the context of a comprehensive simulation study on GWAS the performance of mBIC and mBIC2 is compared with single marker test approaches. We also discuss some strategies how to deal with the huge number of models. \r\n", :title "Modifications of BIC for data mining under sparsity ", :keyword2 12, :authors (10115), :session 67}, 303 {:keyword1 34, :keyword3 99, :abstract "We consider a financial market with a risk-free money market account and a finite number of   risky assets. We assume that the real-world prices of the risky assets are multivariate log-normally distributed with a non-singular valid correlation matrix. The mean and standard deviation per time unit of the return differences on these risky assets, as well as the volatility of the return, are chosen as (possibly time dependent) parameters. The obtained representation includes two of the most popular return models, namely the Black-Scholes and the Vasicek (Ornstein-Uhlenbeck) models. Solving the required martingale conditions, we construct an explicit state-price deflator, called Black-Scholes-Vasicek (BSV) deflator. Based on three multivariate normal integral identities of independent interest, we use it to derive in a unified and elementary probabilistic algebraic manner the price of several multiple risk options. We obtain general analytical pricing formulas for the multivariate maximum (minimum) option as well as the multivariate maximum spread option. These are used to price related options including the best of assets or cash, the rainbow call on the maximum option and some double triggered options that are of importance in business applications.", :title "The algebra of option pricing: Theory and application", :keyword2 35, :authors (22048), :session 268}, 305 {:keyword1 66, :keyword3 106, :abstract "The O-D (origin-destination) matrix refers to the demand of traffic in a road network.\r\nThe O-D matrix adjustment problem is a bilevel optimization problem which consist\r\nof attempting to determine this matrix from an outdated one. Most of the work in this topic\r\nhas been based on assuming that the traffic assignment problem admits a unique optimal\r\nflow in a certain neighborhood. Given that the requirements to obtain uniqueness are usually very strong, designing\r\nnecessary optimality conditions for the problem appears to be crucial, considering the\r\nfact that the bilevel optimization problem is typically nonsmooth and nonconvex even in\r\nthe linear case. To the best of our knowledge, only Fritz-John’s type necessary optimality\r\nconditions have been derived so far for the O-D matrix adjustment problem. In this talk,\r\nwe present an approach to obtain Karush-Kuhn-Tucker type optimality conditions based on\r\nthe variational analysis of the value function and feasible set-valued mapping of the traffic\r\nassignment problem.", :title "Variational analysis and optimality conditions for the O-D matrix adjustment problem", :keyword2 80, :authors (21172 7687), :session 71}, 307 {:keyword1 106, :keyword3 77, :abstract "This paper describes an approach and a case study for a decision support system (DSS) in the form of a MILP-model. The topic faces the tactical distribution planning of a central warehouse. The main issue is to reorganize the delivery of shipments after major changes in the network structure and the average amount of shipments. This question consists of four different decision problems:\r\n1.\tSelection of dispatch types: Shipments could be delivered using resources of the in-house fleet, by freight forwarders with basic agreements, by carriers, or by parcel services.\r\n2.\tSelection of tours: Which ZIP-area-codes should be grouped to tours? One ZIP could be part of several tours and one tour consists of several ZIPs. The key is to ensure that tours include ZIPs with small inter-distances and that the average time of the tour is smaller than a given capacity in minutes. The tour-definition takes place in advance of the optimization.\r\n3.\tWeek schedules for in-house fleet: How often should possible tours be carried out regarding a week schedule and which tour should use what resource type?\r\n4.\tResource-planning: How many resources of each type are needed?\r\nThese decision problems are merged into a simultaneous optimization model, which is implemented and solved with ILOG Cplex. As a prerequisite we describe a technique to bring different types of data to the same level of detail. As the ZIP-tour-assignment takes place in advance, this part is a static simulation, which is done by comparing the solutions of models with different sets of input parameters.\r\n\r\nThe DSS provides an optimized selection of dispatch types for shipments of a weight category and a ZIP, the selection of given tours, a week schedule for the in-house fleet, and an average demand of each resource type.", :title "Dispatch-Type-Selection, Tour-Assignments and Resource-Planning of a Central Warehouse Distribution Problem", :keyword2 18, :authors (29216), :session 242}, 308 {:keyword1 106, :keyword3 0, :abstract "Service networks represent service systems which contain multiple independent servers executing individual tasks. Service networks are planned with the aim to meet the customer demand better than any single multitasking server. Service networks take efficiency from closely incorporating the customer into the service process. An example is the 24/7 unmanned post station network, which offers high flexibility to customers provided they are able to move to stations and operate the machines. In some networks, mobile services are offered by servers moving to the customers. An example is a home care service that supplies persons in need. Generally, mobile services are provided at a place designated by the customer. A mobile service may also require a joint operation of several servers at a certain place and/or a certain point in time.\r\n\r\nWe model a service network representing customer locations as nodes and servers as heterogeneous vehicles to differentiate between various skills of staff members. Customer visits take a certain duration and may obey to prescribed time windows. In order to optimize the network operation, we solve a vehicle routing and scheduling problem. Different requirements regarding the synchronization of servers (vehicles) can be involved in such a problem.A temporal synchronization means that several vehicles have to visit the customer at a same time, or in a prescribed order of time. A spatial synchronization means that the point of service synchronization is either prescribed or a matter of planning. In this talk we present a MIP model for the routing problem of two vehicles under variable synchronization demand and time windows where either the sum of tour lengths or the maximum tour duration is minimized. We also present first computational results.", :title "Spatial and temporal synchronization of mobile servers in service networks", :keyword2 0, :authors (29217 14707 13086), :session 186}, 311 {:keyword1 106, :keyword3 59, :abstract "Nearly all published algorithms for vehicle routing problems (VRPs) consider a fixed assignment of vehicles and drivers, that is, assume that one and the same driver operates a vehicle throughout the complete planning horizon. Although there are cases where this assumption is appropriate, in many real-world applications it is usual that drivers switch vehicles. In particular, this is the case in long-distance road transport. The so-called slip seating is common practice and constitutes a pillar of success in US-American advanced truckload firms.\r\n\r\nWhereas simultaneous vehicle and crew scheduling for situations with a given timetable is a quite well-studied application area, there are only very few papers on simultaneous vehicle and crew ROUTING and scheduling problems.\r\n\r\nThis is most probably due to the fact that abandoning the assumption of a fixed driver-vehicle assignment introduces intricate interdependencies between tours. Basically, both drivers and vehicles are non-autonomous objects whose movements in space and time must be synchronized in order to be able to visit customers and fulfil requests. Such interdependencies and the resulting synchronization constraints cannot be adequately dealt with by standard VRP heuristics.\r\n\r\nThe talk presents a heuristic solution procedure for simultaneous vehicle and crew routing and scheduling for partial and full load long-distance tramp transports by lorry. The complete EU social legislation on driver working, driving, and rest hours is taken into account. Results of extensive computational experiments with real-world data from several major German freight forwarders are reported.\r\n", :title "Simultaneous Vehicle and Crew Routing and Scheduling for Partial and Full Load Tramp Transports", :keyword2 95, :authors (14973 9524 773 22897), :session 187}, 313 {:keyword1 66, :keyword3 14, :abstract "We consider the Generalized Nash Equlibrium Problem (GNEP) from a structural and computational point of view. In GNEP the players' feasible sets may depend on the other players' strategies, and hence the players may share common constraints.These obstacles lead us to the dual notion of Fritz-John (FJ) points for GNEP which include generalized Nash equilibria. Here, FJ points can not be replaced by Karush-Kuhn-Tucker (KKT) points due to the possible violation of the constraint qualifications. It is crucial for our approach that we represent FJ points together with some dual variables as solutions of some underdetermined nonsmooth system of equations. We prove that the primal-dual set of FJ points constitutes generically a Lipschitz manifold. Its dimension depends on the number of shared constraints. For the computation of FJ points we suggest a projection method for finding solutions of a general underdetermined semismooth system of equations F=0. Despite of the fact that in the smooth and/or determined case the rate of convergence is quadratic, only linear convergence can be expected here. This is due to the nontrivial geometry of the corresponding solution set. Under the strong full-rank assumption we show the local convergence at a linear rate of the projection method.\r\nApplying the latter to GNEP, we prove that the strong full-rank assumption is satisfied for generic data functions. We conclude that in the generic case the projection method converges linearly towards FJ points.", :title "On Structure and Computation of Generalized Nash Equilibria", :keyword2 40, :authors (20607), :session 73}, 319 {:keyword1 22, :keyword3 0, :abstract "Hazards of natural disasters persist to endanger humanity. Recent catastrophes (e.g. 2011 earthquakes in Japan) revealed coordination deficits in terms of scheduling and allocation of resources. Particularly, disaster management has to cope with time pressure, resource shortages, informational uncertainty, and the interdependence of scheduling and allocation tasks. This study addresses these challenges by proposing a set of non-linear binary optimization models and their corresponding solution heuristics, which are subsequently evaluated computationally.\r\nBased on requirements from practice, we define three optimization models that seek to minimize harm under the following premises: a) incidents and rescue units are spatially distributed; b) rescue units possess specific capabilities which limit their usability, and c) processing is non-preemptive. The first model assumes that an incident can be processed by at most one rescue unit with a specific capability at a time, and that information (processing times, severity of incidents, and travel times) is deterministic. The second model accounts for co-allocation of rescue units to incidents, which appears when incidents require various, differently skilled rescue personnel. The third model assumes that information underlies non-probabilistic uncertainty, which we address by fuzzy set theory and optimization.\r\nDrawing on insights from machine scheduling, we prove that all three models are NP-hard. For each of the three models, we suggest a Monte-Carlo simulation using the software MATLAB. The results are statistically analyzed and benchmarked against a greedy heuristic. Our results argue for a set of recommendations that use heuristics scenario-dependently.", :title "Centralized Scheduling and Resource Allocation in Natural Disaster Management", :keyword2 18, :authors (29224 29226 29227), :session 185}, 321 {:keyword1 13, :keyword3 0, :abstract "We derive a randomized version of the Mirror-Prox method for solving some structured matrix saddle-point problems, such as the maximal eigenvalue minimization problem. Deterministic first-order schemes, such as Nesterov's Smoothing Techniques or standard Mirror-Prox methods, require the exact computation of the exponential of a matrix at every iteration, limiting the size of the problems they can solve. Our method allows us to use stochastic approximations of a matrix exponential. We prove that our randomized scheme decreases significantly the complexity of its deterministic counterpart for large-scale matrix saddle-point problems. Numerical experiments illustrate and confirm our theoretical results.", :title "A randomized Prox-method for solving structured matrix saddle-point problems", :keyword2 0, :authors (19677 19615 26854), :session 61}, 322 {:keyword1 42, :keyword3 115, :abstract "The increasing interest in electronic platforms for generating and networking social contacts induced a higher sensibility in this form of interaction. Therefore social networks created scientific awareness and it became more and more a challenge to analyse personal characteristics of actors in relation to other actors within the network. Primarily the study of social networks was done in social sciences but nowadays it is interdisciplinary. In most instances conventional concepts are sufficient to receive a good impression about structural properties of a network. However, there is an obvious disadvantage in using these concepts: only a fraction of the network-data and thus only limited structural information is included when analysing and evaluating connection-properties of actors. One new branch of research is based upon the information-abiding embedding of the network into an overall probability distribution – a proper way to make an integrated study. Using axiomatic consolidated findings in information theory now it is possible to appraise the information content not only of the complete network but also of subnets in any required size. The core of this contribution is the description of a innovative method to identify informational redundancies in sub-networks concerning information theoretical measures. Redundant structures in social networks are possible as well as intended, but with growing complexity of the network they result in time consuming and computationally intensive calculations. The presented approach makes it possible to shrink the complex network without any loss of information. A proper entropy-based measure verifies the so-called structural equivalence between the original and the reduced network.", :title "An entropy-based method to reduce complexity in social network analysis", :keyword2 10, :authors (26311 26286), :session 208}, 324 {:keyword1 79, :keyword3 0, :abstract "Integrated production and distribution planning has received a lot of attention throughout the years and its economic advantages over a decoupled approach is well documented. However, for highly perishable products this integrated approach has to include, further than the economic aspects of supply chain optimization, the intangible value of customers’ willingness to pay, which is related to product freshness. Hence, in this work we explore, through a multi-objective framework, the potential advantages of integrating these two intertwined planning problems at an operational level for this kind of products. We formulate integrated and decoupled models for the case where perishable goods have a fixed and a loose shelf-life in order to analyze the difference between the type of perishable products and planning decision process. Computational results for an illustrative example show that the Pareto front of the integrated approach strongly dominates the Pareto front of the decoupled one for both classes of perishable products. The economic savings that the coupled analysis entails is smoothed as we aim to deliver fresher products. Nevertheless, in the fixed shelf-life case for a 70% mean remaining shelf-life of delivered products we may reach savings around 42%. The explanation regarding the fact that the gap between the integrated and the decoupled approach tends to smooth for very high freshness standards, may be due to the reason that in the latter case no inventory is allowed since we are working completely under a JIT policy, turning the problem at hand so constrained that the integrated and coupled solutions are rather the same. The multi-objective framework proved to be essential to draw these multi-perspective conclusions.", :title "Operational Supply Chain Planning of Perishable Products in a Multi-Objective Framework", :keyword2 101, :authors (23114 15118 17649), :session 162}, 325 {:keyword1 8, :keyword3 0, :abstract "         We consider the competitive facility location problem, where two rival firms (Leader and Follower) open facilities sequentially and each client selects one of the open facilities according to his preferences. The problem is to find a facility location for the Leader which maximizes its profit taking into account the best answer of the Follower. We formulate model as bilevel integer programming problem. Like every bilevel programming problem, it includes the upper level problem (Leader’s problem) and the lower level problem (Follower’s problem). We consider so-called optimal non-cooperative  solutions to the problem, where from all possible optimal solutions to Follower’s problem we choose the solution which yields the smallest value of the objective function Leader’s problem. The way of construction of an upper bound for optimal values of the Leader’s profit is proposed. The algorithm consists of construction the classical facility location problem and finding an optimal solution of the problem. The optimal value of the problem gives the upper bound. Also we propose an algorithm for constructing an approximate solution to the competitive facility location problem. The algorithm amounts to local ascent search with a neighborhood of a particular form. The procedure starts searching from an initial approximate solution obtained simultaneously with the upper bound. The output of this algorithm is an approximate solution in the form of local maximum. Our computation results illustrate the good quality of the obtained solutions.", :title "Local search algorithm for competitive facility location problem", :keyword2 54, :authors (22874), :session 205}, 327 {:keyword1 99, :keyword3 8, :abstract "We put forward an algorithm to solve linearly-constrained two-stage stochastic problems with a nonlinear objective function. It is based on the\r\nTwin Node Family (TNF) concept involved in the Branch-and-Fix Coordination\r\nmethod. These problems have continuous and binary\r\nvariables in the first stage and only continuous variables in the second\r\nstage. On the basis that the nonanticipativity constraints are fulfilled by TNF strategy, an algorithm to solve these problems is designed, which is implemented in C++ with the help\r\nof the Cplex library.  Numerical results are reported.", :title "Solving linearly-constrained nonlinear stochastic problems", :keyword2 14, :authors (15051), :session 117}, 330 {:keyword1 35, :keyword3 0, :abstract "In «The Black Swan: The Impact of The Highly Improbable» N. N. Taleb concludes that modern economic models badly describe reality for they are not able to forecast such crisis in advance. All extraordinary events, e.g. crises, are named by the author “The Black Swans”. Thus, the author confirms that modern science almost doesn’t have tools to predict such unusual events. \r\nWe have tried to present the processes occurring on the exchange in the form of two random processes, one of which occurs frequently (normal mode) and the other – rarely (crisis). Then we estimated the average gain with the different probabilities of correct recognition of these processes and used the resulting estimates for the actual processes on the exchange (the S&P 500 index data from 1999 till 2009). \r\nWe’ve got the following answer: if frequent, regular processes are detected correctly even with a probability higher than 1/2, it almost always allows to have a positive average gain. This very phenomenon seems underlies the reluctance of people to expect crises and do not try to identify them. \r\nAlso we extended basic mathematical model allowing player to learn on his own behavior and to receive an award for the ‘correct’ behavior.\r\nOne of our main conclusions is that there is no need to live in the paradigm of an impending crisis because it is impossible to predict the time of the crisis and there is no such need because in a series of regular mass events recognition of such events is much easier and the exact recognition of all process does not really matter. Also, as pointed out by Norbert Wiener, the stock exchange is based on man’s decisions and the prediction of his behavior will lead to the closing of the stock exchange or he will change his behavior strategy.", :title "Is it so bad that we cannot recognize black swans?", :keyword2 0, :authors (28091 38976), :session 268}, 339 {:keyword1 35, :keyword3 34, :abstract "This paper examines the optimal investment timing decision problem of a firm subject to an endogenous debt financing capacity constraint. We show that the investment thresholds have a U-shaped curve with the debt capacity constraint, in that they are increasing with the constraint for high-liquidity firms while decreasing for low-liquidity firms. Although the financing constraint distorts investment timing, it may encourage the constrained levered firm to overinvest compared with the nonconstrained levered firm. Our result fits well with the related problems involving the internal financing constraint. ", :title "Optimal investment timing under debt financing capacity constraint", :keyword2 19, :authors (2266 8187), :session 266}, 341 {:keyword1 77, :keyword3 8, :abstract "We discuss in this talk SDP relaxations for unconstrained binary quadratic program, linear equality constrained quadratic binary program and quadratic knapsack problem. Based on derived necessary and sufficient conditions for the zero duality gap, we propose new schemes to underestimate the duality gap by some distance measures. We show that the SDP bound can be improved by an amount proportional to the distance measure and the minimum positive eigenvalue of certain modified matrix. We also establish the connection between the computation of the distance measure and the cell enumeration of hyperplane arrangement in discrete geometry. ", :title "Improvement of SDP bounds for 0-1 quadratic programs", :keyword2 83, :authors (18887), :session 204}, 344 {:keyword1 106, :keyword3 125, :abstract "In this paper, we are trying to introduce a combinatorial model from routing and blending problems. Vehicle routing problem (VRP) is an old and well-known optimization problem that has been developed for many special cases. Blending too is an optimization problem that deals with the knowhow of mixing raw materials to produce a product with a minimum cost. This research presents a mathematical model related to blending and vehicle routing problems based on a scenario of blending wheat from different silos to obtain an acceptable food value of wheat, concentrating on minimizing the total route that the vehicles should travel between silos. This model can be considered attractive because all the silos can simultaneously work as a customer and/or a depot as follows: Since wheat quality (food value) varies in different silos, each silo should obtain some wheat from other silos and blend it with its own to balance the quality (food value); this way it is a customer. On the other hand, when other silos ask for wheat from this silo, it has the role of a depot. So, the model answers this question that how much wheat to which customer (silo) via what route should each silo send so that the cost is minimized while the nutrition (food value) remains balanced. This model has been implemented for a limited area and results have shown its efficiency.", :title "A mixed mathematical model of blending and routing problems", :keyword2 57, :authors (29233 31871 30896), :session 246}, 346 {:keyword1 96, :keyword3 48, :abstract "Even though rail transportation is one of the most fuel efficient forms of surface transportation, fueling costs are the single highest operating cost head for railroad companies. For larger companies with several thousands of miles of rail network, the fuel costs often run into several billions of dollars annually. The railroad fueling problem considered in this paper has three distinct cost components. Fueling stations usually charge a location dependent price for the fuel in addition to a fixed contracting fee over the entire planning horizon. In addition, railroad company must also bear incidental and notional costs for each fuelling stop. It is imperative that the number of fueling stops between an origin and destination should be restricted to avoid unnecessary delays. This paper proposes a mixed integer linear program model that determines the optimal strategy for contracting and purchase schedule decisions that minimizes overall costs under certain reasonable assumptions. This model is tested on a large, real-life problem instance. Model performance was significantly enhanced by decomposition and introducing several MIP cuts. This paper compares the efficiency of different MIP cuts in order to reduce the run-time. Lastly, the paper concludes with an observation that even though the problem scale was expected to diminish the model performance, it was indeed noted that run-time and memory requirements are fairly reasonable. It thus establishes that this problem must be looked beyond the prism of heuristics and other approximate algorithms for actual implementation at railroad companies.", :title "Experience of Optimizing Fueling Decisions for Locomotives in Railroad Networks", :keyword2 53, :authors (27696), :session 141}, 350 {:keyword1 59, :keyword3 0, :abstract "In many theoretical and empirical investigations heuristic methods are the subject of investigations for optimizations problems in order to get good and valid solutions. In 2001 with \"Harmony Search\" a new nature-inspired meta-heuristic was published. Applied to various types of optimization problems, for example structural design problems, improvements over other heuristics were made. Motivated by the question whether these heuristics represents a new class of meta-heuristics or whether they are only another representation of a well-known technique, a couple of investigations were made. \r\nThis presentation will show that for the class of binary optimization problems this new natur-inspired heuristic is \"equivalent\" to an evolutionary algorithm. ", :title "Harmony Search for Binary Optimization Problems", :keyword2 0, :authors (29244), :session 238}, 351 {:keyword1 60, :keyword3 41, :abstract "The last couple of years have seen an alarming increase in the incidence of piracy near Somalia. Both the Somali East Coast and the Gulf of Aden are high-risk areas. The Gulf of Aden is an important shipping lane due to its location. The fact that it is a relatively narrow area, hemmed in between the Horn of Africa and the Yemeni coast, means that traffic flows in only two directions. Because of these factors, convoying merchant vessels through the Gulf of Aden is one of the solutions to the problem of piracy. This paper discusses a mathematical model how to optimize the number of merchant vessels that can be protected by a single warship in such a situation. With this model a convoying system can be generated and through simulation effectiveness of such a system can be quantified.\r\n\r\n", :title "Convoying against Piracy", :keyword2 59, :authors (25893 25731), :session 172}, 354 {:keyword1 83, :keyword3 0, :abstract "We consider a canonically perturbed system of (in general) infinitely many inequalities defined by continuously differentiable functions in finite or infinite dimension. Calmness of the solution set map of this system is characterized, on the one hand, by uniform linear convergence of a suitable iterative procedure for solving an associated bounded-norm system of linear inequalities and, on the other hand, by a certain constraint qualification. We also show how to apply this to the optimal set map in semi-infinite optimization.", :title "Calmness of feasible and optimal solution maps in semi-infinite optimization", :keyword2 108, :authors (11954 10871), :session 200}, 367 {:keyword1 8, :keyword3 77, :abstract "We develop an algorithm for solving the linear ordering problem (LOP). LOP can be formulated as a binary integer linear programming and is known to be NP-hard. It has a large number of applications (including triangulation of input-output matrices, minimizing total weighed completion time in one-machine scheduling, and aggregation of individual preferences). The algorithm is based on the Lagrangian relaxation, which is solved by the subgradient method. Since the total number of the constraints that should be relaxed in the Lagrangian relaxation problem is too large (order n cubed) to handle, we propose a modified subgradient method that ignores a part of the constraints and gradually adds constraints whose Lagrangian multiplier vector is likely to be positive at the optimal solution. In addition, this contributes to lessen a computational burden arising from the update of Lagrangian multiplier vector. \r\nWe also propose an idea to improve ordinary pegging test based on Lagrangian relaxation by using the structure of LOP. Our computational results show that the improved pegging test works better than an ordinary pegging test. However, for computational time, there is no notable difference between the improved pegging test and the ordinary pegging test. We utilize the information obtained from the improved pegging test for modifying a relaxed solution in an attempt to get a good incumbent in an early stage. We also tested some local search methods that fit with the above modification.\r\n", :title "Lagrangian Relaxation and Pegging Test for Linear Ordering Problems", :keyword2 53, :authors (29256 29255 29260), :session 149}, 368 {:keyword1 106, :keyword3 59, :abstract "The Vehicle Routing Problem is the problem of designing the optimal set of routes, which are travelled by a fleet of vehicles to serve a given set of customers. A VRP is defined on a graph whose nodes are the location of customers plus a central depot, and the coefficient matrix of arcs usually represents distance, travel cost, or travel time between the nodes. In classic VRPs, vehicles are allowed to travel only one tour, but in Vehicle Routing Problems with Multiple Use of Vehicles (VRPM) which is a branch of the classic routing problem, vehicles are allowed to perform one or more than one routes. Therefore, vehicles have operating duration constraints (e.g. work shifts), and above the common objective of minimizing total travel distance, it is important to minimize the number of the vehicles. The studies on VRPM problems are few. Their solution quality becomes critical when the travel times between graph nodes are uncertain. There are several papers on stochastic travel times in vehicle routing problems, but in this research we model the VRPM problem with stochastic times, using Chance-Constrained Programming approach to tackle these stochastic factors, and finally design a Variable Neighborhood Search (VNS) heuristic to solve their large-scale instances. Results show this algorithm is capable to solve large-scale instances fast. Also, we run a few tests on the results to show their accuracy and give some conclusions. Simulation shows that importing the uncertainty to a VRPM problem can reduce systems cost significantly, as well as reducing the percentage of violating the operating duration constraints.", :title "A New Model and Heuristic Algorithm for Multi-trip Vehicle Routing Problems with Stochastic Travel Times", :keyword2 85, :authors (29251 20821), :session 247}, 369 {:keyword1 86, :keyword3 7, :abstract "We consider resource-constrained project scheduling problems where the activities can be interrupted during their execution and generalized precedence relationships between the activities have to be taken into account. While there exists a considerable body of papers dealing with the case of job preemptions in machine scheduling, preemptive resource-constrained scheduling has received much less attention in the open literature. On the other hand, there are many practical scheduling problems where resource units have to be allocated to divisible activities over time. Examples of such applications are aggregate capacity planning involving order splitting, lot streaming in detailed scheduling, or the remote dispatch of controllable electric appliances like heating or cooling facilities. In this talk we develop a classification of project scheduling problems with interruptable activities, which distinguishes between discrete and continuous preemptions, rigid and flexible reallocations of resource units when interrupted activities are resumed, and different types of precedence relationships between activities. Based on this classification, we discuss the expressive power of the different problem settings, identify reduction relationships among them, and sketch the borderline between polynomially solvable and intractable problems. Furthermore, we present a new concept of schedule representation, which is based on trajectories in the unit hypercube. This concept can be applied to the most general problem types and allows for a geometric interpretation of precedence relationships and resource constraints.", :title "Project scheduling with activity preemptions: Problem classification and representation of schedules", :keyword2 96, :authors (29248 930), :session 64}, 370 {:keyword1 63, :keyword3 3, :abstract "A multicriteria sorting method based on data envelopment analysis (DEA) is developed to facilitate selection of R&D projects to be funded by a grant program. Even though DEA is used extensively for ranking; to our knowledge this study is the first attempt utilizing DEA for sorting. Although proposed method also specifies ranking of projects, sorting is judged to provide more robust and confident results for the problem. R&D project selection criteria hierarchy and point allocation guide are derived to measure and quantify performance of projects. The weight intervals of the criteria obtained from analytic hierarchy process are employed as assurance region to prevent inappropriate weight assignment. Motivated from the fact that derived criteria constitute inputs and outputs of R&D projects; two DEA based threshold estimation models and five assignment models are developed. The difference between the threshold estimation models is optimistic evaluation of reference set utilizing the most favorable weights or more fair evaluation by restricting optimal weight dispersions. The methodological disparities between the assignment models are implementation of efficiency restrictions to reference set and assessing unevaluated projects simultaneously or individually. Rather than demanding technical and preferential information directly from decision makers, a reference set composed of previous decisions is used to identify the global judgments. The proposed approach and well known sorting method UTADIS are applied to a case study to analyze the projects submitted to the institution in 2009. It is concluded that proposed methods are more stable than UTADIS and integrated use of second threshold estimation model with fourth assignment model provides the most appropriate results.", :title "A DEA based sorting approach for private sector R&D projects", :keyword2 17, :authors (29258 51317), :session 259}, 383 {:keyword1 80, :keyword3 82, :abstract "We are interested in sensitivity and stability analysis of solution sets of optimization problems under set or cone constraints. A main motivation behind our work is the analysis of semidefinite programs (SDPs). \r\nFor polyhedral constraint-sets, a classical topic, a lot of research has been done. We wish to expand the sensitivity analysis in this field to a more general field including nonpolyhedric cones.", :title "Stability of nonlinear programs with cone constraints", :keyword2 66, :authors (29264), :session 55}, 385 {:keyword1 54, :keyword3 100, :abstract "Network design decisions concern facility location and demand allocation. They are steered by given capacity, sourcing and demand conditions and various costs. The latter include fixed and variable costs for network configuration (e.g. facility construction) and operation (e.g. transportation). Typically, network design models assume fixed facility operating costs. This is an oversimplification of many practical cases, as operating costs often depend on the utilization level of a facility. We address this issue by considering facility sizing decisions and variable operating costs in a two-echelon network. In each echelon and at each potential site, a new facility can be established for a group of product families. Each family occupies a given storage area, whose size is to be selected from a discrete set of capacity levels. A multi-period setting is considered due to the long term nature of network design decisions. The model also includes the possibility of expanding the capacity of facilities established in previous periods to adjust the network capacity to future needs. Demand is assumed to have been forecasted for all the periods of the time horizon. Facility operating costs depend on the type of storage area installed in a given location for a product family as well as on the total quantity of product stored there. The goal is to design a two-level network so as to maximize the total profit over the time horizon. In order to obtain tight formulations, alternative models using different sets of decision variables and/or constraints are proposed. The usefulness of the new models is investigated for a set of randomly generated instances by analysing the lower bound of their linear relaxations and the time required to solve them to optimality using a general solver.", :title "A multi-period two-level network design problem with facility sizing decisions", :keyword2 65, :authors (23789 1256 9684), :session 191}, 386 {:keyword1 79, :keyword3 0, :abstract "In this talk we introduce a notion of pseudogradient for vector valued function. This notion is an adaptation to the vector problem of the notion of pseudogradient, which is a well-known concept in the modern critical point theory. After showing the basic properties of vector pseudogradient (descent directions, representation of “minimal” vector pseudogradient)  we present an applications of this notion concerning a method deal with vector optimization problems. We develop an algorithm to find the critical points of a box-constrained multi-objective optimization problem. The proposed algorithm is an interior point method based on suitable directions (given by the vector pseudogradient) that play the role of gradient-like directions for the vector objective function. This method does not rely on an ‘‘a priori’’ scalarization and is based on a dynamic system defined by a vector field of descent directions given by the vector pseudogradient. We prove that the limit points of the solutions of the considered system satisfy the Karush–Kuhn–Tucker (KKT) first order necessary condition for a box-constrained multi-objective optimization problem. Finally, we consider some test problems where we apply the proposed computational method.", :title "A notion of vector pseudogradient with applications in vector optimization", :keyword2 23, :authors (14133), :session 78}, 387 {:keyword1 61, :keyword3 53, :abstract "Algebraic modeling languages (AMLs) play an important role in optimization and its industrial usage. They ensure the robustness, stability, and data checks needed in industrially stable software, and they accelerate the development and improvement of solvers. AMLs reduce the development risk by allowing easily to switch from a local to a global NLP solver. Implementing polylithic solution approaches is possible without huge development efforts. Finally, AMLs reduce the project duration, simplify maintenance and increase the lifetime of optimization software.\r\n\r\nBased on the Greek monolithos (stone consisting of one single block) Kallrath (2009) introduced the term polylithic for modeling and solution approaches in which MIP or non-convex NLP problems are solved by tailor-made methods involving several models and/or algorithmic components. A monolithic model is just one model with data, variables and constraints and one solve statement. In contrast, a polylithic model contains a set of models connected in their data flow of input and output data, i.e., the solution of one model is input to another one, e.g., for initializing variables, or deriving bounds on them. Examples of polylithic models are decomposition approaches, column generation and Branch&Price,  or hybrid techniques in which constructive heuristics and local search improvement methods are coupled with exact MIP algorithms to produce feasible points and tight lower and upper bounds. Polylithic sub-models and their connection establish a tailor-made algorithm. \r\n\r\nReferences:\r\n\r\nJ. Kallrath. Combined Strategic Design and Operative Planning in the Process Industry. Computers and Chemical Engineering, 33:1983-1993, 2009.", :title "The Impact of Algebraic Modeling Languages on Optimization - Polylithic Modeling and Solution Approaches", :keyword2 48, :authors (17621), :session 79}, 390 {:keyword1 14, :keyword3 0, :abstract "Bilevel programming problems are optimization problems where a\r\nfunction is minimized subject to the graph of the solution set\r\nmapping of a parametric optimization problem (the so called lower\r\nlevel problem). To investigate such problems they need to be\r\nreplaced with another one e.g. using optimality conditions for the\r\nlower level problem in form of a generalized equation. For the\r\nresulting problem, M- and S-type optimality conditions are derived\r\nusing new constraint qualifications.\r\n", :title "Optimality conditions for bilevel programming problems", :keyword2 66, :authors (21172 7687), :session 55}, 397 {:keyword1 75, :keyword3 99, :abstract "Accurate response and postponement are two strategies for a firm to deal\r\nwith demand uncertainty and better match supply with demand. Under ac-\r\ncurate response, reactive capacity could be used for customized make-to-order (MTO) production according to customer demands. On the other hand, using postponement a firm could perform the non-postponed activities speculatively and use reactive capacity only to customize the final product thereby enhancing the profitability of accurate response. Surprisingly existing research in the areas of accurate response and postponement does not address this potential. In this paper we aim to fill this gap by proposing a stylized model for accurate response by postponement.\r\nSpecifically, we analyze a situation where a manufacturer is faced with un-\r\ncertain demand for a product during a short selling season. The manufacturer has three supply options. First, it can manufacture and offer a standardized version of the product. Second it can use postponement by manufacturing a standard component speculatively and customizing it once demands are revealed at the beginning of the selling season. Third, it can produce customized products in a pure make-to-order fashion during the selling season. This situation is modeled as an extension of a newsvendor problem. Our main research question is then to analyze specifically under which conditions postponement is part of the optimal supply strategy and more generally what kinds of supply strategies will arise in different model settings.\r\n", :title "Accurate response by postponement", :keyword2 80, :authors (9703), :session 226}, 398 {:keyword1 75, :keyword3 57, :abstract "In the process industries make-and-pack production is used to produce, e.g. food and beverages, chemicals and metal products. This type of production process allows the fabrication of a wide range of products in small amounts with the same equipment. While this helps companies to respond quickly to market trends, producing many different products increases the complexity of short-term production planning. \r\nIn this paper we consider a real-world production process (cf. Honkomp et al. 2000) comprising sequence-dependent changeover times, multipurpose storage units with limited capacities, quarantine times, batch splitting, partial equipment connectivity, and transfer times. The planning problem consists in computing a production schedule such that a given demand of packed products is fulfilled, all technological constraints are satisfied, and the production makespan is minimized. None of the models known from the literature covers all technological constraints that occur in such make-and-pack production processes. To close this gap we develop an efficient mixed-integer linear programming model which is based on a continuous time domain and general precedence variables. We propose novel types of symmetry-breaking constraints and logical cuts in order to improve the performance of the model. In an experimental analysis, we show that moderate-sized instances can be solved to optimality in short CPU times. Moreover, we compare the model against a priority-rule based heuristic known from the literature.\r\n", :title "A continuous-time MILP-approach to short-term scheduling of make-and-pack production processes", :keyword2 8, :authors (17023 125), :session 163}, 399 {:keyword1 57, :keyword3 0, :abstract "Complementarity problems arise in a variety of engineering and economic applications. Their solution is often based on a reformulation as a system of equations. For this purpose nonsmooth complementarity functions are of particular interest. We first present some new facts on nonsmooth homogeneous functions. Based on this properties for a class of nonsmooth complementarity functions are derived. This is useful for obtaining results on local superlinear convergence under weakened conditions.", :title "On properties of homogeneous complementarity functions", :keyword2 0, :authors (14587 17041), :session 57}, 401 {:keyword1 106, :keyword3 40, :abstract "Todays traffic situations in big cities are still far from being satisfactory. The situation is particularly dramatic in the rising mega-cities of Asia, Middle-, and South-America. It is a well known fact that selfish behavior of traffic participants is one of the main reasons that leads to inefficient traffic outcomes. Since every traffic participant solely aims at minimizing her individual travel time, the overall outcome is less efficient, e.g., in terms of the total average travel time, as if everybody would have been routed according to a centrally coordinated routing scheme. Thus, reducing traffic congestion via toll pricing has been a central topic in the operations research and transportation literature and, recently, it has been implemented in several cities all over the world. It is well known that tolls equal to the marginal edge costs of the system optimal solution (marginal cost pricing) induce a socially optimal equilibrium flow. Since in practice it is not feasible to impose tolls on every edge of a given traffic network, we study the resulting mathematical problem of computing tolls on a predefined subset of edges of the network so as to minimize the total travel time of the induced equilibrium flow. We first present an analytical study for the special case of parallel edge networks highlighting the intrinsic complexity and non-convexity of the resulting optimization problem.  We also present algorithms for general networks for which  we systematically test the solution quality for large-scale network instances. Finally the related optimization problem of computing tolls subject to a cardinality constraint on the number of edges that have tolls is discussed.", :title "Computing Network Tolls with Support Constraints", :keyword2 10, :authors (26950 26518 20420), :session 190}, 402 {:keyword1 66, :keyword3 66, :abstract "Based on recent advances in quasiconvex analysis, we will present new optimality conditions for Generalized Nash equilibrium problems (GNEP) with quasiconvex lower semicontinuous objective function.\r\n\r\nApplications of quasiconvex analysis and GNEP to electricity markets will also be considered : indeed in order to modelize deregulated spot electricity markets, various models have been proposed. Most of them correspond to a GNEP in which an Independent System Operator (ISO) plays a central role. Our aim is to consider quadratic bid functions together with transmission losses in the GNEP. Under some reasonable assumptions we deduce some qualitative properties for the ISO’s problem. In the two islands type market, the explicit formula for the optimal solutions of the ISO’s problem are obtained and we show the existence of an equilibrium.\r\n\r\n\r\n", :title "Generalized Nash equilibrium problem in the quasiconvex case : New optimality conditions and application to electricity markets", :keyword2 28, :authors (29274), :session 57}, 404 {:keyword1 8, :keyword3 77, :abstract "In many cases, combinatorial problems or at least their linear\r\nrelaxations can be formulated in the form of linear systems of\r\nequations and inequalities where the inequalities are given by a\r\npolynomial separation oracle. We will discuss a relaxation-type\r\nalgorithm which solves such systems in polynomial time. The\r\nalgorithm uses a basic procedure which projects current infeasible\r\nsolutions onto halfspaces induced by nonnegative linear\r\ncombinations of the inequalities until it finds a feasible\r\nsolution or detects that the dimension of the space can be reduced\r\nwithout lost of a feasible 0,1 solution. The basic procedure\r\nguarantees that current solutions never leave the affine subspace\r\ngenerated by the equations. As we will see, this property makes it\r\npossible to use separation oracles.", :title "Combinatorial applications of a polynomial relaxation-type algorithm for linear inequalities", :keyword2 78, :authors (6281), :session 229}, 405 {:keyword1 120, :keyword3 93, :abstract "As investors throughout the world are continuously seeking investment opportunities with higher returns and less risk, a new lending paradigm has emerged: peer-to-peer (P2P) lending. The driving force behind this new paradigm is nothing but the might of the Internet to bring lenders and borrowers together in a social platform, thus cutting traditional financial institutions out of the equation; benefiting both the lenders and the borrowers. P2P market volume has already exceeded billions of dollars since it started in mid-2000s, and it is predicted that P2P lending shall continue to enjoy even higher market volumes in the near future. In this study, which is the first of its kind, we propose a support vector machine (SVM) based classification method for identifying risky borrowers in P2P lending. The data we use come from the popular P2P lending platform lendingclub.com, which has intermediated loans in the US in excess of quarter billion dollars within the past several years. In P2P lending, the lenders assume the risk of defaults in general, so an attractive feature of lending via lendingclub.com is that the platform allows lenders to spread out their investment across hundreds of borrowers, thereby reducing risk considerably. In our methodology, we introduce and utilize several novel features including estimated fund time ratio. Our results indicate that our SVM-based scoring method significantly outperforms the traditional FICO credit scores in identification of risky borrowers, which in turn suggests that P2P lending seems to have different dynamics than lending via banks and similar financial institutions. ", :title "Identifying Risky Borrowers in Peer-to-Peer Lending", :keyword2 34, :authors (29277 29276), :session 215}, 406 {:keyword1 96, :keyword3 13, :abstract "The problem of scheduling a set of jobs on a single machine under given technological precedence constraints is considered. Before a job is ready for processing on the critical machine, it must undergo some preprocessing treatment. The preprocessing treatment is dynamic process in which the speed of the change of the preprocess state depends on an amount of resource. We assume that the speed can be described as some function of resource amount. The total consumption of resource at each moment is limited. The time which is needed to pass from the initial state to the final one is called a job ready time. The objective is to minimize the makespan. Such a problem appears e.g., in steel mill systems, where ingots (before hot rolling on the blooming mill) have to achieve the required temperature in the preheating process in soaking pits. The computational complexity of the problem and its solution properties are examined. Due to the proved properties, the difficult dynamic problem of the optimal resource allocation (for a fixed job schedule) was reduced to a task of convex programming. Some approximation algorithms of constructing job schedule along with their experimental and worst case analyses are also presented.", :title "Machine scheduling problem with job dynamic ready times", :keyword2 10, :authors (5236 28782), :session 146}, 407 {:keyword1 57, :keyword3 77, :abstract "Mixed-integer programming models often assume that the problem data is known precisely.  In reality, this may not always be the case,\r\nand some of this data may be subject to uncertainty or measurement error. Taking the uncertainty into account leads to Robust Mixed Integer Programming problems. These are then conventionally solved by reformulation as nominal, non-robust problems.  We propose a direct method to separate split cuts for a class of robust mixed-integer programs with polyhedral uncertainty sets. The method generalizes the well-known cutting plane procedure of Balas for both best- and worst-case robustness assumtions, i.e. robust MIP and generalized MIP problems. Computational experiments show that applying cutting planes directly for the robust problem is computationally favorable to the reformulation approach.", :title "Split Cuts for Robust Mixed-Integer Optimization", :keyword2 94, :authors (29278 16928), :session 212}, 410 {:keyword1 25, :keyword3 29, :abstract "The high pollutant activity of power and industrial installations and the limits imposed by the Kyoto Protocol have induced Europe to introduce the Emission Trading Scheme (EU-ETS) in order to curb CO2 emissions. However, the application of this cap and trade system have caused both direct (cost of CO2 allowances) and indirect (increase of electricity price) costs for energy intensive industries participating in this program. Moreover, the absence of an international CO2 agreement may distort European international trades that are mainly represented by carbon-intensive exports. This may be an incentive for energy intensive industries to relocate their production activities in non-regulated countries. This phenomenon is referred to as the carbon-leakage effect  (see Demailly and Quirion, 2006, Ponssard and Walker, 2008, Meunier and Ponssard, 2010).\r\nIn this paper  we investigate the effects of EU-ETS directives on the cement industry with a particular focus on the Italian market, the second European cement producer. The Italian cement sector is analyzed through a Cournot oligopolistic equilibrium model. We adopt a technological representation of the market in order to have a direct control of the different sources of cost (energy, raw materials and CO2 allowances and transportation) and the factors (such as a partial allowance grandfathering as foreseen by Directive 2009/29/EC) that may induce or refrain companies to displace their emissions. Italy has several coastal plants which are the most exposed to carbon leakage. For this reason, in this analysis, a key role is played by transportation costs that are particularly high in this sector.\r\n", :title "Evaluating the carbon leakage effect on the Italian cement sector", :keyword2 80, :authors (23724 9925 12583 29282), :session 124}, 412 {:keyword1 101, :keyword3 0, :abstract "One of the main assumptions in research on designing supply contracts is that decision makers act in a way that maximizes their expected profit.  A number of laboratory experiments demonstrated that this assumption does not hold -- specifically, faced with uncertain demand, decision-makers place orders that systematically deviate from the expected-profit maximizing levels. We add to this body of knowledge by demonstrating that ordering decisions also systematically depend on individual contract parameters, and developing a behavioral model that captures this systematic behavior. We proceed to test our behavioral model with two different experiments, and use the data to derive empirical model parameters for individual subjects.  We then test our approach in an additional out-of-sample experiment that confirms that indeed, contracts designed using the behavioral model perform much better than contracts designed using the standard model.", :title "Designing Supply Contracts for Empirical Retailers", :keyword2 0, :authors (14573), :session 224}, 415 {:keyword1 34, :keyword3 67, :abstract "During the last two years the client base of online trading companies has significantly grown. Such companies allow small investors to access the stock market at advantageous rates. Since small investors buy and sell stocks in moderate amounts, they should take fixed transaction costs, minimum transaction units, and dividends into account when selecting their portfolio. In this paper we consider the small investor’s problem of investing capital in stocks in such a way that the risk is minimized and a certain rate of return is guaranteed.\r\n\r\nPortfolio optimization models known from the literature are designed for institutional investors and do not consider the above mentioned characteristics. We therefore develop efficient extensions to four portfolio optimization models in order to make them applicable for small investors. We consider one non-linear model which uses the variance as risk measure (MV model) and three linear models which use the minimum return (MiniMax model), the mean absolute deviation from the portfolio return (MAD model), and the conditional value at risk (CVaR model) as risk measure. We extend all models such that piecewise constant transaction costs, minimum transaction units and dividends are considered.\r\n\r\nWe apply the different models from the perspective of a Swissquote client who invests in Swiss stocks. Our computational study shows that the CPU time to solve the MV and the MAD model is highly sensitive to problem parameters, and can exceed 30 minutes. The MiniMax and the CVaR model, however, are always solved in less than 10 seconds. All models generate portfolios which yield in average higher returns than the Swiss Performance Index (SPI). However, the return of the SPI shows a considerably lower variance.", :title "Portfolio selection models for small investors", :keyword2 77, :authors (17023 125), :session 266}, 416 {:keyword1 10, :keyword3 95, :abstract "We present our work on the conflict-free routing of vehicles through a network of guideways. Conflicts are defined in a natural way, i.e., vehicles cannot occupy the same resource at the same time. The task is to find a routing consisting of a route selection and a schedule for each vehicle, in which all vehicles arrive at their destinations in minimal time.\r\n\r\nSuch conflict-free routing algorithms are needed in various applications in logistics and transportation. The most direct application is the routing of Automated Guided Vehicles in warehouses and in industrial harbors. Other related application settings are the routing of ships in canal systems, locomotives in shunting yards or airplanes during ground movement at airports.\r\n\r\nAlgorithms for conflict-free routing often follow a sequential routing paradigm. Sequential routing policies consider the vehicles in some given priority order and select route and schedule with earliest arrival time while avoiding conflicts with previously routed vehicles. Such algorithms are popular, because they are computationally efficient and often lead to good routings. However, the outcome strongly depend on the priorities and the worst-case guarantees for sequential policies are very bad.\r\n\r\nWe will present theoretical and simulation-based results to clarify this discrepancy. For this purpose, we introduce a natural basic model for conflict-free routing of a group of k vehicles. On the negative side, we show that this problem is hard to solve to optimality, even on path topologies. This is also true for finding the optimal priorities for sequential routing. On the positive side, we show how to find good priorities for sequential routing, leading to the first algorithm with approximation guarantee sublinear in k.", :title "On Sequential Algorithms for Conflict-Free Vehicle Routing ", :keyword2 8, :authors (19582), :session 182}, 417 {:keyword1 96, :keyword3 0, :abstract "In many supply chains, e.g. in the automotive industry, the manufacturer´s shipping instructions oblige the supplier to deliver components in specific load carriers such as pallets or lattice boxes. This research investigates the single-machine scheduling problem of a supplier who produces multiple jobs with individual due dates for several manufacturers. Each manufacturer uses his own specific load carriers and provides the supplier with these load carriers. Therefore, load carrier availability is an exogenous parameter for the supplier. The supplier´s earliness-tardiness scheduling problem with family-dependent batch setup times is formulated as a MIP model. Load carrier availability is incorporated by introducing an additional penalty cost and additional constraints. NP-hardness of the resulting optimization problem suggests the use of heuristic solution procedures. Heuristic solution approaches are presented and evaluated in a numerical study.", :title "Scheduling with Load Carrier Constraints", :keyword2 77, :authors (29263), :session 146}, 435 {:keyword1 18, :keyword3 42, :abstract "DEX is a method for the development of qualitative multi-attribute decision models and the evaluation of alternatives. DEX is based on a hierarchic aggregation of attributes, using utility functions that are defined by decision rules. As we strived to use DEX to solve different types of decision problems, we found out that the influences that we were trying to model did not always form a hierarchical structure needed to solve problems with DEX. In addition to hierarchical relations, we encountered networks with feedback loops. For instance, such networks occur in modelling and evaluation of dynamic systems. To tackle these kinds of decision problems, we have generalized the DEX method to capture influences in terms of general networks. In DEX, the influences are transmitted across the whole model in a single calculation on each node – a hierarchical structure represents an acyclic directed network. In the generalised method, we introduce a cyclic network, where in the first step, we transmit and aggregate values across a predetermined acyclic network and in the next steps across all remaining connections. Because the extended models include cycles, the evaluation method becomes iterative – the calculation can be repeated until a convergent state has been achieved or a pre-determined number of steps have been completed. These concepts are illustrated on a use case of the assessment of maize cropping systems.", :title "Extending DEX decision models: From hierarchies to networks", :keyword2 19, :authors (29287 12646), :session 255}, 440 {:keyword1 2, :keyword3 96, :abstract "Airport controllers are faced with complex tasks every day to ensure safe operations at airports while meeting the various different objectives. There is already a need for sophisticated decision support systems to help controllers to handle the complexity of their tasks if the benefits are to be maximised. This is likely to become even more important in future, with the expected growth in the air transportation sector. One of the challenging tasks which are faced is the airport ground movement problem: guiding aircraft around the airport’s surface to their destinations, in a timely manner, while ensuring conflict-free routings. Since online solutions are often needed (requiring speed and the ability to cope with a changing situation), sequential routing and scheduling algorithms, which consider one aircraft at a time, can be advantageous. Obviously, the performance of such algorithms can depend upon the sequence of consideration of the aircraft, which is often assumed to be first-come-first-served. The focus of this research is to analyse the effects of different heuristics to find better sequences in which to consider aircraft. However, a greatly increased solution time is often the price for improved solution quality. Results of an analysis of a routing and scheduling algorithm will be presented, utilising real data from Zurich Airport. These show that sophisticated heuristics can substantially improve the solution with comparatively little additional computational time. Furthermore, the approach aims to modify relatively few existing routes as it progresses, in order to minimise the workload of the controllers in communicating changes in an online environment.", :title "Exploration of the ordering for a sequential airport ground movement algorithm", :keyword2 18, :authors (22855 21636), :session 148}, 441 {:keyword1 45, :keyword3 35, :abstract "As an opportunity to reduce costs and increase efficiency, hospitals within a region are increasingly co-operating horizontally to form a network. Solely the introduction of a more performance-orientated fixed-pricing system for inpatient treatment (DRG-System) in Germany in 2003 has led to a rising number of co-operations among hospitals. Therefore, especially management accounting tools have come more into focus as they strive not only profitability but also efficiency.\r\nThe problem discussed in this paper consists in the economic reallocation of the case-mix among a network of hospitals subject to capacity, organizational, and legal restrictions. Not only do the reallocations require time (and money), but so do the negotiations with planning institutions of the local governments and health insurance companies. So when making reallocations one has to look at a longer period of time (> 1 year). Consequently, one has to consider other factors as well, such as changing case-mix and costs – yet alone due to demographic developments – as they have an impact on the results. So far however, these considerations have been somewhat neglected in existing research. \r\nTo fill this gap, a multi-periodic model for the reallocation of the case-mix and capacity-planning will be introduced. Furthermore, the model will be extended by modifications. After application, the results will answer questions such as what impact statuary and organizational motivated requirements have on the allocation of case-types and specialization of departments and locations over time. \r\n", :title "Multi-periodic Case-Mix-Optimization in a Hospital Network ", :keyword2 7, :authors (26158), :session 95}, 442 {:keyword1 125, :keyword3 59, :abstract "The Broye region in Western Switzerland frequently faces problems of water scarcity during spring and summer months caused by irrigation demands for vegetable and potato production. Today, water withdrawals from surface water bodies in this region are usually banned if rivers flow rates fall below environmental thresholds. Irrigation bans increase the investment planning uncertainty for farmers. Due to the latter and due to the nonlinearity of climate-plant-management interactions, the decision-making process is highly complex and traditional optimization methods are not applicable. Against this background, we propose in this study a bio-economic modeling approach to simulate different management strategies in potato production in Western Switzerland. Embed in genetic algorithms (GAs) we apply an integrated model consisting of CropSyst as process-based, daily time-step crop growth model and an economic decision model at field-level. The GAs maximize the certainty equivalent in potato cultivation which takes not only the profit margin but also production risks into account. Six management decision variables are optimized considering optimal nitrogen fertilization amount, optimal fertilization timing and allocation as well as optimal irrigation strategy under current and future climate conditions. In addition, we compare the effects of higher water prices with different irrigation bans scenarios on the profitability and water use in potato production under both climate scenarios. By using GAs, this approach allows a direct linking of the crop growth model to the economic decision model and accounts also for production risks which are important in crop management decision making. ", :title "Modeling Complex Crop Management-Plant Interactions in Potato Production under Climate Change", :keyword2 136, :authors (29195 29291 30001), :session 160}, 444 {:keyword1 133, :keyword3 59, :abstract "In this research, we consider the problem of minimizing both energy consumption and cycle time simultaneously in printed circuit board (PCB) manufacturing while keeping the predetermined quality of the PCB. Here, we focus on inner layer scrubbing process since this process requires a moderately large amount of power, especially, at the dry step. The degree of adhesion between interlayers in multilayer printed circuit board manufacturing is the very significant factor in product reliability. The inner layer scrubbing process in PCB manufacturing is the process that, by using brushes and certain chemicals, removes debris such as oxide or fingerprints frequently occurring on surface of tin core (inner materials or inner circuit board) in order to improve the adhesion. So, this process makes the surface of copper rough to stick liquid photo resist (LPR) and dry film well. Through these ways, the heat shock and defective adhesion can be minimized in advance. Thus, in this research, a heuristic approach is applied to the inner layer scrubbing process in order to find the optimal operating conditions which minimize both energy consumption and cycle time simultaneously while keeping the productivity because the cycle time of this process depending on the conveyor speed conflicts the power used for exsiccating PCB. After constructing a statistical model for the process, the performance of several different approaches are also investigated and compared to that of the heuristic approach by providing numerical examples.", :title "Application of a Heuristic Approach to Minimization of Energy Consumption in Printed Circuit Board Manufacturing", :keyword2 48, :authors (29239), :session 243}, 445 {:keyword1 92, :keyword3 91, :abstract "We consider infinite horizon inventory policies for a company which satisfies customer demand by either selling or leasing a product. If the product is leased, it can be leased for a different number of periods. The customer demand follows a Poisson process whose mean is a function of the price. The company has manufacturing, refurbishing and remanufacturing options for building-up inventory. The new products and the products returned by the customers that are subject to a remanufacturing or refurbishing process are collected into the same finished goods inventory. It is assumed that significantly worn-out ones among the returned products are disposed of from the system. In the model, we consider an (S-1, S) type policy for controlling the inventory and determine the optimal inventory level as well as the optimal leasing and selling price of the product. Our analytical model assumes that a used product can return to the system infinitely many times.\r\n\r\nWe use the optimal price and inventory levels obtained from the analytical model in a simulation model which considers the more realistic case of a finite number of returns. We calculate the average profit per unit time including revenue from leasing and sales, inventory holding costs in the system, backorder and lost sales costs. We discuss the results of the analytical model and compare them with the simulation model results, and provide insights for the decision makers.\r\n", :title "Leasing and Remanufacturing Strategies with Pricing and Inventory Control", :keyword2 75, :authors (29219 23883 15094), :session 168}, 451 {:keyword1 40, :keyword3 0, :abstract "Nucleolus is a single point solution concept of cooperative transferable utility(TU)game.In recent past several authors had applied cooperative TU games for solving various problems like power transmission loss allocation, routing in public transport, cost-saving allocation in vehicle routing. The well known approach to determine the nucleolus of the cooperative TU game is to apply a sequence of linear programs. In this paper a new concept called conjugate coalition is introduced and it becomes an important subset of dropped coalitional constraint set. If conjugate of any active coalition is not active till the present state then it can be eliminated and its corresponding coalitional constraint must be dropped in the subsequent linear programs. Another dropping set will be the set of all finite union of active disjoint coalitions provided their respective union is not active till the present state. Finally in the second set of unions their conjugates are also to be considered and added to the list of dropped coalitional constraints if they are not active till the present state.  The information about fixation of player’s contribution can be known by using the conjugate of active coalitions. One example of five player cooperative TU game, discussed in the paper illustrates the importance of conjugate coalitions. \r\nSome authors have studied the dropping of constraints but the concept of conjugate makes it easy to detect such coalitions and thus answers the central question of identifying coalition at an iteration whose excess cannot be improved further without harming the position of worse off coalitions. It has been proved that the dropped coalition set will become the complete set, i.e. if any coalition does not belong to this established dropped set then it does not have any chance to be ignored. This has been tested for three to five player cooperative TU games. \r\n", :title "Role of conjugate coalition and union of coalitions in computing the nucleolus of a cooperative TU games", :keyword2 78, :authors (29221), :session 136}, 452 {:keyword1 57, :keyword3 0, :abstract "Consider a bilevel programming problem, i.e. an arbitrary upper level problem and its variable being the solution of another minimization problem (lower level) which has a parameter-dependent linear objective function and a polyhedral feasible set. Under certain assumptions, this bilevel programming problem can be reformulated into an equivalent problem with one objective function. Therefore, the optimal value of the lower level is expressed as a function depending on the upper level variable. This, compared with the lower level objective, acts as a constraint in the reformulation. But since the optimal value function lacks in useful properties such as differentiability, it will be substituted.\r\n\r\nAs a minimum of linear functions, the optimal value function is concave which is essential for the solution approach. Consider the lower level problem. Its objective provides a lower bound if one considers only a selection of feasible points. One question is how to expand this set of feasible points in order to improve the approximation.\r\n\r\nThe algorithm provides a method that interchangeably solves the surrogate problem (in order to find an optimal solution) and the lower level problem (in order to check feasibility and, if necessary, find a suitable point for the above mentioned set). Conditions for both local and global optimality will be presented.", :title "An algorithm for solving a class of bilevel programming problems", :keyword2 0, :authors (28996 7687), :session 71}, 454 {:keyword1 96, :keyword3 0, :abstract "In this talk we consider the concept of smoothed performance guarantees and apply it to the quality of local optima. Smoothed analysis was introduced by Spielman and Teng (JACM 2004) as a hybrid between worst case and average case analysis, to explain the good behavior of algorithms that have a bad worst case performance. Up to now, smoothed analysis has been mainly applied to the running time of algorithms. We will use smoothed analysis to investigate the approximation ratio of an algorithm, that is, the ratio between the value of an approximate solution and the optimal solution value. In the last decade, there has been a strong interest in understanding the worst case behavior of local optimal solutions. We extend this research by investigating whether or not this worst case behavior is robust. We will apply the concept of smoothed performance guarantees to several local optima for some scheduling problems.\r\n\r\nJoint work with Tobias Brunsch, Heiko Röglin (University of Bonn), and Cyriel Rutten (Maastricht University).", :title "Smoothed jumping through the neighborhood", :keyword2 0, :authors (29203), :session 51}, 457 {:keyword1 106, :keyword3 42, :abstract "Microscopic crowd simulation can help to anticipate hazardous situations and prevent their developement. A lot of research in the field focuses on modelling individual pedestrians, although substantial studies emphasize the existence of social groups within crowds. It is also known that social groups strongly influence the crowd movement in some situations and presumably do in many others.\r\n\r\nWe present a simulation model based on a cellular automaton that is calibrated and tested for individual pedestrians and describe how to incorporate social groups. This brings up new issues like the separation of groups. In our first model we observe that unrealistically many separations occur when a group approaches an obstacle. A backtracking algorithm, where people go back to the location of the separation and reunite with their group, mitigates the effect. However, the problem cannot be completely overcome without a collective decision process within the group.\r\n\r\nIn this work we improve our simulation model with such a collective decision process. Graph-based routing around obstacles allows a collective decision of all group members on which way to take. We explain the routing mechanism for groups and illustrate the results on the basis of an example scenario. The graph-based routing also gives greater control to the designer of social behavior in the simulation. We discuss the possibilities and limitations of this model.\r\n", :title "Social groups and graph-based routing in a crowd simulation", :keyword2 97, :authors (29183 26752 26750), :session 207}, 459 {:keyword1 8, :keyword3 0, :abstract "In an ongoing industry cooperation with a call center company we consider the problem of scheduling call center agents with heterogeneous skill profiles based on a prediction of the incoming call stream.\r\nThe problem turns out to be inapproximable, so we derive an (I)LP formulation with exponentially many variables and a greedy algorithm which provides solutions in polynomial time making use of the fact that the calls form interval graphs in which maximum independent sets can be found in linear time.\r\nWhile the resulting algorithm in theory only yields a logarithmic approximation guarantee, our experimental evaluation on real-world data from our industry partner shows that for those instances we get upper and lower bounds that are at most a very small constant factor apart.\r\nWe also develop synthetic instance generators for which by construction the optimum solution is known and evaluate our algorithm on those instances.\r\nFor our concrete application scenario, the (exact) solution of the ILP formulation or even the LP relaxation is not a viable option due to the size of the respective problem instances (thousands of calls, hundreds of skill profiles, thousands of potential shifts). \r\nFor smaller problem instances we employed a commercial state-of-the-art LP solver and show that the solutions computed by our algorithm are even closer than our dual fitting lower bounds can prove. We also briefly report on our findings of the employment of a primal-dual algorithm;\r\nunfortunately, its performance on real-world problem instances was much less satisfactory.", :title "Callstream-based scheduling", :keyword2 10, :authors (29294 29295), :session 142}, 460 {:keyword1 91, :keyword3 0, :abstract "Revenue management (RM) involves the optimal allocation of capacity constrained resources to stochastic demand. In a network environment, the bid price strategy is widely used to control the availability of products that consume one or more resources.\r\nIn this presentation, we introduce new approaches to compute time-dependent bid prices that tackle several limitations of current methods. First, the frequency to update the bid prices during the booking horizon is arbitrary. As a result, we can incorporate wider time intervals compared to other techniques to allow multiple booking requests in a time period. In our model, we discretize the booking horizon into T time periods, not necessarily of the same length. Whenever the booking process enters a time period t, the control policy takes new bid prices. Within each time period, bid prices stay fixed. Second, we propose new mathematical programming formulations that are based on DLP, either directly or by introducing slack variables to compute the bid prices. These formulations are very efficient since they only grow linearly with respect to the size of the problem. We assess the performance through simulation runs where the control policy can be re-optimized as the booking process proceeds, since information about observed demand realizations can be used to improve the bid prices.\r\n", :title "Improved Bid Prices for Multistage Network Revenue Management", :keyword2 126, :authors (50532), :session 101}, 464 {:keyword1 19, :keyword3 18, :abstract "The most common problem in Multi-criteria Decision-Making (MCDM) is ranking alternatives. The basic inputs to the considered problem are (1) the (nxK) pay-off table containing the n alternative evaluations for K criteria, and (2) the preference relationship between the K criteria provided by the decision-makers. In this presentation the author will show that pair-wise comparison methods like AHP, Electre, or Promethee do not provide the correct rankings in many practical situations. Among other failure mechanisms to be analysed during the presentation are illogical rank-reversals appearing between pairs of alternatives when third irrelevant alternatives are added, removed, or change values. For this analysis two cases are considered of ordinal rank data or score data derived from the pay-off table; for obtaining score data the German grading scale with 6 points is used. In this way the pay-off table with different scales and units is replaced by a dimensionless (nxK) table in which the alternatives are evaluated on a common dimensionless rank or score scale. It is shown that in this setting the correct way for ranking the alternatives is to combine additively the ranks or scores for all criteria, in accordance with the preference relationship. Furthermore the causes of the observed failure mechanisms of pair-wise comparison methods are examined.", :title "Why pair-wise comparison methods may fail when establishing MCDM rankings ", :keyword2 63, :authors (9212), :session 255}, 465 {:keyword1 45, :keyword3 0, :abstract "Numerous publications have examined various aspects regarding health-consciousness of individuals, such as smoking behavior or the use of alcohol and drugs. Only few authors however, have tried to combine different aspects to obtain an overall index of a person's health awareness. A notably number of studies studying the health awareness of individuals has referred to students as this population group is considered to show above-average health awareness. The aim of this contribution is, first, to create an index representing the health awareness of students which combines six different aspects of \"health-related behav-ior\". These aspects cover smoking, dieting, alcohol consumption, doing sports, sleeping hab-its and preventive health care activities (e.g. vaccinations, health check-ups). In a second step, we analyze to which extent this index is influenced by various exogenous factors using multiple regression. These factors include, for example, the sex of the individuals and the health awareness of the individuals’ parents. The data were collected through structured oral interviews based on randomly selecting stu-dents in Austria. Overall, more than 2,500 students were interviewed.\r\n", :title "Students’ health awareness and its determinants", :keyword2 0, :authors (23438 7405), :session 81}, 466 {:keyword1 17, :keyword3 0, :abstract "Since 1997, Austrian hospitals are confronted with an activity-based hospital financing, the so called LKF-system. This activity based system has been designed to finance inpatient care based on so-called LKF credit points. The LKF points are determined according to an Austrian specific DRG-catalogue, so-called LDFs, with credit points being assigned to particular diagnoses and treatments, basically representing average cost per diagnoses and treatment in the inpatient care unit, respectively. Over the last decade, the LKF system has seen many structural changes, resulting in the re-calculation of credit points, the consolidation, inclusion as well as deletion of individual LDFs.\r\nThis paper suggests a framework for assessing productivity changes across public acute care hospitals in Austria between 1999 and 2009 and decomposing productivity changes into changes in technical efficiency and changes in technology, the latter being currently under observation due to the assumption of a positive relationship between technical progress and cost increase. Previous productivity studies in the Austrian hospital sector have revealed productivity differences across the Austrian hospital sector, with macro variables providing no significant explanation, as well as artificial rather than actual technical progress, mainly resulting from the use of LKF credit points in the output vector.\r\nIncluding data up to 2009 the aim of this contribution is to investigate whether, first, there has been a significant technology progress over the observation period, second, the findings are robust with regard to the efficiency measure used and, third, technology changes vary across the Austrian hospitals and can be explained using micro explanatory variables.\r\n", :title "Technology as cost driver in health care", :keyword2 45, :authors (7405 23440 14020), :session 48}, 468 {:keyword1 17, :keyword3 0, :abstract "Efficiency scores of ex-post production activities are generally measured relative to an estimated production frontier. Data Envelopment Analysis (DEA) is a well-established non-parametric method to measure these (in-) efficiencies of such observed activities for some comparable decision-making-units (DMUs). More recent developments lead from the classical form of self-appraisal to the so-called peer-appraisal evaluating cross-efficiencies. If the cross-efficiency matrix is established under the assumption of constant returns to scale (CCR model), then all (in-) efficiency scores are non-negative. However, negative entries can occur in a cross-efficiency matrix under the assumption of variable returns to scale (BCC model), a fact rarely mentioned in DEA literature.\r\nAfter developing the necessary mathematical models in this paper, we demonstrate the above effect for a concrete example of automotive suppliers. One peer punishes some DMUs with negative cross-efficiencies. It will be shown how the problem of negative cross-efficiencies can be faced. This avoidance has two consequences for the proper peer. His efficiency must decrease while his return to scale can increase, to which degree are these conjoint effects desirable for automotive suppliers?", :title "Negative cross-efficiencies versus returns to scale - An application for automotive suppliers", :keyword2 0, :authors (29296 9874 25442), :session 259}, 470 {:keyword1 126, :keyword3 0, :abstract "An optimal control problem is studied for a nonlinear reaction-diffusion system from population dynamics. The three equations describes the behavior of a trophic chain consisting of a predator, a pest and a plant species. A pesticide is introduced in the ecosystem. It is regarded as a control variable. The purpose is to minimize the pest density and to maximize the plant density. The existence of the optimal solution is established and some necessary optimality conditions are found.", :title "An optimal control problem for a  tri-trophic chain system with diffusion", :keyword2 108, :authors (23461), :session 198}, 472 {:keyword1 18, :keyword3 0, :abstract "We study the ranking of multi-attribute options. Each option is described by multiple qualitative attributes. Each option also belongs to an ordered class. Options that belong to the same class are almost equally appreciated by the decision maker. In this way, decision maker’s preferences are defined qualitatively and options are ranked only partially. To model the preferences and obtain a full ranking of options, qualitative preferences are mapped into quantitative ones. Current approaches, such as the Qualitative-Quantitative (QQ) method, transfer the quantitative classification problem into a regression one by using linear regression, thus obtaining linear function for ordering of the preferences. QQ performs well for linear and monotone preferences; however it underperforms in cases of non-linear preferences, especially when the linear approximation is inadequate. To address this problem, we modify the QQ method by introducing copulas as an aggregation utility instead of linear regression.\r\nCopulas are functions which manage to capture the non-linear dependences among random variables. To use copulas, we will consider the attributes as random variables. As most of the theory is based on the bivariate copulas, we construct a hierarchical structure of bivariate copulas in order to model the dependences between the attributes and the classes. Such a hierarchical structure allows us to define a copula-based non-linear quantile regression function that we use for ranking of preferences.\r\nIn this paper we investigate the performance of this method when employing different hierarchical structures of copulas. Our findings show that copulas can be successfully used for modeling of different non-linear preferences with respect to different hierarchical structures.", :title "Ranking of qualitative decision options using copulas", :keyword2 19, :authors (28859 12646), :session 254}, 475 {:keyword1 77, :keyword3 0, :abstract "When applied to an integer linear program, the group-theoretical approach constructs its relaxation, an optimization problem over a finite Abelian group, whose set of feasible solutions forms a corner polyhedron. Vertices and facets of such polyhedra are contained in vertices and facets of the master corner polyhedron (MCP), which is the convex hull of solutions to a group equation. A great amount of research has been devoted to facets of the MCP and generating effective cuts from them for the original program, but no real progress has been made in studying its vertices since Gomory's seminal paper [1]. This work focuses on vertices.\r\n\r\nWe introduce two combinatorial operations and prove that they transform vertices of the MCP to adjacent vertices. This implies that every MCP is determined by some subset of its vertices, from which all others can be built with the use of these operations; we call them support vertices. We prove that the class of support vertices of all MCPs on a group is invariant under the group automorphisms and describe their vertex structure and minimal vertex bases. The set of vertices of any MCP is partitioned into orbits; new operations map each orbit onto another orbit; some orbits consist of support vertices, while the others are free of them. A vertex basis is any system of the orbit representatives under the stabilizer subgroup at the right-hand-side element of the group equation acting on support vertices. The calculation manifests that these bases are often much smaller in cardinality compared to the total number of vertices. Among other results, we characterize geometrically irreducible points of the MCP, which makes clear why some of them fail to be vertices, establish some properties of the nontrivial facets passing through a given vertex, construct new points in these facets, and prove that the MCP is of diameter 2.\r\n\r\nReferences.\r\n1. Gomory R. E., Some polyhedra related to combinatorial problems. Linear Algebra Appl., 2, N 4, 451-558, 1969.", :title "Vertex structure of master corner polyhedra", :keyword2 0, :authors (29095), :session 227}, 478 {:keyword1 34, :keyword3 0, :abstract "The often reported empirical success of trend-following technical timing strategies, which contradicts efficient market hypothesis, still seems puzzling. Despite reporting mixed results, previous academic research predominantly admits some prediction power. However, authors struggle to substantiate this conclusion and rather vaguely refer to insufficient market efficiency or unknown hidden patterns in asset price processes. This work contributes to clarifying the issue. We systematically trace back timing success to the statistical characteristics of the underlying's asset price process. Price characteristics are modeled by standard time series models. Four major impact factors are studied: return autocorrelation, trend as well as volatility and its clustering. Our fifth possible source of impact, the degree of market efficiency, eventually turns out to be irrelevant. As an example for a trading rule we use simple moving averages (SMA) for different intervals. These strategies are applied to simulated asset price data to allow for systematic parameter variations. Subsequently, we test the same strategies on real market data using non-parametric historical simulations and compare the results. Evaluation is done by an extensive selection of statistical-, return-, risk-, and performance measures calculated from the simulated return distributions.\r\nOur study shows that the empirical success of SMA-timing strategies can largely be explained by statistical parameters of the underlying asset price process. Neither inefficient markets nor hidden price patterns are necessary. We also conclude that empirical timing success does not indicate prediction power.\r\n", :title "The Trend is not Your Friend! - A Demystification of Empirical Timing Success based on Asset Price Characteristics and its Compatibility with Market Efficiency", :keyword2 0, :authors (21117 14810), :session 218}, 479 {:keyword1 17, :keyword3 0, :abstract "Die Ausgaben im Gesundheitswesen steigen in allen europäischen Ländern seit Jahren kontinuierlich an, so beispielsweise in Deutschland von 967 PPP-$ (8,4 % vom BIP) im Jahr 1980 auf 3737 PPP-$ (10,5 % vom BIP)im Jahr 2008. Somit sind Sparmaßnahmen und ein effizienter Einsatz der Ressourcen in diesem Bereich unausweichlich. Eine Möglichkeit, die vorhandenen Ineffizienzen aufzuzeigen, ist der Vergleich von europäischen Gesundheitssystemen  miteinander. Eine in der Literatur und speziell in dem Gesundheitssektor weit verbreitete Methode zur Effizienzanalyse von Wirtschaftseinheiten ist die 1978 von Charnes, Cooper und Rhodes entwickelte Data Envelopment Analysis (DEA). Die durch die DEA-Methode bestimmten relativen (In-)Effizienzen von Wirtschaftseinheiten lassen jedoch keine Prognose über die mögliche zukünftige Entwicklung zu. An dieser Stelle setzt der vorliegende Beitrag auf, in dem erstmals Entwicklungstendenzen prognostiziert werden. Hierzu werden ausgewählte europäische Gesundheitssysteme mittels DEA analysiert und ihre zukünftige Performance mit geeigneten Schätzmethoden vorhergesagt. Diese Vorhersagen mögen dann als Basis für Handlungsempfehlungen an die Entscheidenden dienen.", :title "Wie (in-)effizient wird das deutsche Gesundheitssystem? Eine zukunftsgerichtete DEA-Bewertung", :keyword2 0, :authors (29292 9874), :session 260}, 481 {:keyword1 96, :keyword3 77, :abstract "We consider the scheduling of multiple products of a soft-drink production facility with three different production lines. There are multiple products produced on these lines and a sequence-dependent setup is required when the product type changes. These production lines have different rates of production for each product and for each product there is a set of production lines it can be produced. We want to schedule the production lines to produce the weekly demand of each product so that the productivity of the lines is maximized or alternatively total labor time spent is minimized. We penalize the deviations from the demand according to the importance of the product. We have to give the lot-size and the sequence decision at the same time not only because of the sequence dependent setup times but also some other restrictions. Because of the limited number molds, at any time the variety of products on production that requires the same mold type cannot exceed the available number of molds of that type.  The other restriction is that the number of shifts available and it has to be devoted to three lines during a day. We developed a network flow model for the problem and applied on a small problem set. ", :title "Lot-sizing and scheduling on parallel production lines with sequence-dependent setup times", :keyword2 7, :authors (25065), :session 146}, 486 {:keyword1 33, :keyword3 97, :abstract "One of the toughest facility location problems is the location-allocation problem, which comprises of two elements: Location: where to locate the central facilities; and Allocation: which subsets of the demand should be served from each facility. The Euclidean uncapacitated location allocation problem involves generating m new facilities to be located in , that will serve n fixed demand points.\tIn a previous study, we developed an Ant Colony Optimization (ACO) for this problem where the number of facilities m is unknown (Arnaout, 2011). In this study, we modify ACO to account for the stochastic nature of the problem, where customers’ demands follow uniform distributions. ACO was modeled using simulation, and then the algorithm’s parameters were optimized using a combination of metaheuristic procedures in order to attain superior solutions. \r\nIn summary, this study addresses the Stochastic Euclidean location-allocation problem with an unknown number of facilities, and an objective of minimizing the fixed and transportation costs. This is a NP-hard problem and in this paper, a three-stage ACO algorithm is used and modeled using discrete even simulation to capture the randomness of customers’ demand.  ACO’s performance is evaluated by comparing its solutions to the solutions generated using deterministic data. The results show that simulation was able to identify better facility allocations where the deterministic solutions would have been unsuccessful due to the randomness of genuine customers’ demands.\r\nUp to our best knowledge, there does not exist published work that addressed the problem with unknown m under stochastic times, nor research that modeled ACO using discrete event simulation and used optimization with simulation to determine the ACO parameters.  ", :title "Metaheuristics for the Euclidean location-allocation problem with stochastic demand and unknown number of facilities", :keyword2 59, :authors (29302), :session 159}, 489 {:keyword1 120, :keyword3 99, :abstract "CMARS is an alternative approach to the well-known data mining tool Multivariate Adaptive Regression Splines (MARS). It is based on a penalized residual sum of squares (PRSS) for MARS as a Tikhonov regularization (TR) problem. CMARS treats this problem by a continuous optimization technique, in particular, the framework of Conic Quadratic Programming (CQP). These convex optimation problems are very well-structured, herewith resembling linear programs and, hence, permitting the use of interior point methods. On the other hand, Stochastic Differential Equations (SDEs)  are widely used to  represent noisy and  real world problems. They play an important role in  the many field of science such as finance, physics and biotechnology. These equations, however, are usually hard to represent and to resolve by a computer. In order to identify  them in a simplified manner,  we aim to use CMARS method. The theoretical results of this study may lead new implementation in science, technology and especially for finance.", :title "CMARS Method for Stochastic Differential Equations", :keyword2 13, :authors (22442 10957 3524), :session 62}, 490 {:keyword1 34, :keyword3 63, :abstract "Recent literature has proved that many classical very important pricing models (Black and Scholes, Heston, etc.) and risk measures (VaR, CVaR, etc.) may lead to pathological meaningless situations, since traders can build sequences of portfolios whose risk level tends to -? and whose expected return tends to +?, i.e., (risk=-?,return=+?). Such a sequence of strategies may be called good deal. This paper focuses on the risk measures VaR and CVaR and analyzes this caveat in a discrete time complete pricing model. We go beyond existence properties. Indeed, under quite general conditions the explicit expression of a good deal is given, and its sensitivity with respect to some possible measurement errors is provided too. We point out that a critical property is the absence of short sales. In such a case we first construct a shadow riskless asset (SRA) without short sales and then the good deal is given by borrowing more and more money so as to invest in the SRA. It is also shown that the SRA is interested by itself, even if there are short selling restrictions.\r\nThe findings may be useful to researchers, regulators, supervisors and traders. In particular, traders may build portfolios with a high return/risk ratio in a easy manner, since discrete time models are easy to apply in practice", :title "Unbounded multiple-criteria discrete time portfolio choice problems", :keyword2 67, :authors (29310), :session 265}, 491 {:keyword1 34, :keyword3 67, :abstract "Distributions with infinite expectation may be related to some important Actuarial and Financial Problems such as Operational Risk Management, Investment Decisions, Insurance, etc. Nevertheless, Coherent or Expectation Bounded Risk Measures such as AVaR or DPT cannot be extended for these distributions because they become infinite. VaR is the only risk measure that one can use, but it is not sub-additive which may be caveat leading to non-diversified solutions in practical problems.\r\nThis paper deals with this topic and construct risk measures that are sub-additive and may apply for distributions with infinite expectation. A Representation Theorem is given, which allows us to provide appropriate risk optimization methods and algorithms as well as estimation techniques.", :title "Heavy tails and risk measures", :keyword2 93, :authors (10171), :session 264}, 493 {:keyword1 8, :keyword3 0, :abstract "This study deals with sectorization problem arising in cartography, which is a particular case of partition problem. Consider a geographical map divided into elements (neighborhoods, agglomeration, towns, cities, regions, etc.), each one being attached with multiple statistical information such as surface area, population, number of customers, etc. The aim is to partition the map into balanced sectors. It means that the amount of statistical information in each sector is balanced by comparison to the other sectors. The sectorization problem is NP-hard and it is close to location-allocation problem, political districting problem and graph partitioning problem. Given the number of sectors to build, we focus on the bicriteria sectorization problem that is stated as a bicriteria optimization problem. \r\nTo solve optimally the studied problem we develop a branch and bound algorithm, incorporating lower bound, upper bound, stronger dominance relations and cut generation processes. A lower bound is computed by \r\nrelaxation of the integrity constraints. Moreover, an upper bound is obtained by using a two-phase heuristic algorithm: on the first phase, we utilize a greedy algorithm to build an initial solution; on the second phase, we utilize a local search algorithm to improve the initial solution. Computational analysis on randomly generated instances is conducted to evaluate the lower and upper bounds, the dominance relations and cut generation processes. Compared with solving mixed integer programming model by CPLEX 12, the performance of the branch-and-bound algorithm is given. \r\n", :title "A branch and bound algorithm for a bicriteria sectorization problem", :keyword2 0, :authors (29171 11001 382), :session 202}, 495 {:keyword1 48, :keyword3 101, :abstract "In the current globalized environment, a trend for larger-capacity, more efficient manufacturing units that serve huge areas has been experienced in many industries.  Similarly, a pattern for the closure of smaller, flexible manufacturing units in remote areas is becoming evident. The proposed work provides a novel MILP model for production planning that specifically addresses the settings of small manufacturing units in remote areas. In particular, the model provides an efficient representation of the impact of transportation costs in such systems as well as the impact of introducing or maintaining flexibility in the production process. A make-or-buy representation that takes into account the effects of remote areas is also incorporated into the model. In addition to the optimization of the planning process, the model can assist in the formulation of strategic reconfigurations in order to better respond to the emerging environment. To this end, the effects of proposed solutions in auxiliary objectives such as responsiveness and vendor independence are also assessed.  To evaluate the proposed ideas, a decorative and industrial paints manufacturing unit in Cyprus is used as a case study.", :title "Aggregate production planning for low-demand, remote manufacturing systems", :keyword2 36, :authors (12346 14554 9066), :session 166}, 496 {:keyword1 18, :keyword3 96, :abstract "In this paper we present a mathematical model (mixed integer programming) for supporting the decisions in the system of steam production using multiple industrial boilers in a tomato company. The decisions in this system are related to boilers functioning profile (start-up, warm-up and shutdown moments), fuel replenishment (transportation and inventory control) and fuel composition consumed in the boilers. These decisions normally are taken based on practical experience of people involved, instead of any decision tool based on optimization; as a result, unnecessary costs are likely incurred. In the literature review, decision tools were not found to this system; therefore, the objective of this study was to develop an optimization model to support the mentioned decisions aiming to minimize the main variable costs linked to the decision makers. The General Lot Sizing and Scheduling Problem was the main reference for building the model, which was implemented in GAMS syntax and solved by the CPLEX. The model adjustments and its validation were performed through a case study carried out in a large tomato company in Brazil. The preliminary outcomes of the model application showed better economic results than those achieved in the real operation.", :title "A mathematical model for supporting the decisions of the steam production system in a tomato company", :keyword2 48, :authors (2168 28706), :session 243}, 498 {:keyword1 18, :keyword3 0, :abstract "To compare objects or alternative decisions one must evaluate a quality of each object. A real-valued scalar, which is corresponded to the object, is called an integral indicator. The integral indicator of the object is a convolution of the object features. Expert estimations of one expert or an expert group could be indicators, too.\r\nWe consider a problem of indicator construction as following. There is a set of objects, which should be compared according to a certain quality criterion. A set of features describes each object. This two sets are given together with an «object/feature» matrix of measured data. We accept a linear model of the convolution: the integral indicator is the linear combination of features and their weights.\r\nTo do that we use the expert estimates of both indicators and weights in\r\nrank scales. To compute indicators according to the linear model, one can use the expert set of weights. Our goal is to match the estimated and the computed integral indicators by maximizing a rank correlation between them.\r\nWe consider the set of the estimated indicators and the set of the estimated weights as two cones in spaces of indicators and weights, respectively. Our goal is to find the set of weights such that the distance between this set and the cone of the expert-given weights must be minimum. Using the found weights we compute the set of indicators such that the distance between this computed set and the cone of the expert-given indicators must be minimum, as well.\r\nThis methodology is used for the Clean Development Mechanism project evaluation. The project partners have to prove that their project can yield\r\nemission reductions in developing countries. The proposed integral indicators are intended to evaluate the environmental impact of this projects.", :title "Integral Indicators and Expert Estimations of Ecological Impact", :keyword2 120, :authors (29315 19525), :session 254}, 499 {:keyword1 106, :keyword3 8, :abstract "We consider the problem of allocating classification tracks in a rail freight classification yard for trains with predetermined arrival and departure times. An extension where individual cars can temporarily be stored on a special subset of the tracks is considered. We have modeled the problem using integer programming and solve real-world problem instances from the Hallsberg Rangerbangard hump yard in Sweden, which is operated by Green Cargo.\r\n\r\nIn a rail freight transportation network, a classification or shunting yard is a central distribution point where incoming freight cars are collected and rebuilt into new freight trains. To operate a shunting yard, one needs to plan the humping sequence of incoming trains, the allocation of classification tracks to cars, and which departing order to use.\r\n\r\nAlthough there are several possible strategies on how to operate a shunting yard, we focus on the case where\r\n1) there are no constraints on the order of cars of outgoing trains,\r\n2) the construction of outgoing trains is completed on the classification tracks, and\r\n3) where the departure yard is used to store trains ready for departure.\r\nThis mode of operation is common when freight is mainly routed through several shunting yards before reaching their final destination. An important subproblem in this case is to decide which classification track should be used for which outgoing train, where not every train fits on every track.\r\nBecause the last car of an outgoing train may arrive much later than the first, it frequently happens that there are not enough classification tracks available. Therefore, a subset of so called mixed tracks is used for temporary storage of cars of different trains.", :title "The Hump Yard Track Allocation Problem", :keyword2 96, :authors (16975 29034 29317 19047), :session 245}, 501 {:keyword1 40, :keyword3 0, :abstract "Simple bargaining problems can be identified with quasi–additive cooperative games. Then the Shapley value induces a Shapley rule on simple bargaining problems that coincides with the equal surplus sharing solution. The axiomatic characterization of the value is easily translated to this rule. The advantages of the Shapley rule over the proportional rule in this setup become apparent. \r\n\r\nWe consider here simple bargaining problems endowed with an a priori coalition structure such that each union is given its own utility, obtained under the assumption of cooperation of all its members. We discuss the use of the Shapley rule in this context and the main options available to the agents: individual behaviour, cooperative behaviour, isolated unions behaviour, and bargaining through unions. The latter two recall, respectively, Aumann–Drèze and Owen’s treatments of cooperative games with a coalition structure. A numerical example illustrates the discussion.\r\n", :title "The Shapley rule for simple bargaining problems with a coalition structure", :keyword2 44, :authors (22964 11884), :session 136}, 514 {:keyword1 75, :keyword3 0, :abstract "As the after-market service industry’s prospects grow, it is becoming imperative for the OEMs to satisfy their customer’s varying service requirements and do so economically. Differentiating the demand into different classes according to their service requirement and using inventory rationing to fulfill the demand is one technique to accomplish this. However, inventory rationing provides a high service level to the higher priority class at the expense of lower class’ service level. In this research, we consider two customer classes with varying service requirements and propose an inventory policy that provides better service level or fill rate to the lower class as well.\r\nWe assume that demand from both the classes follows a Poisson process and is differentiated only by the penalty cost of not satisfying that class’ demand. We propose a modification to the separate stock (bin) policy where the inventory is replenished jointly. Our modification allows the higher class to borrow from the lower class’s bin when its own stock runs out. However, the lower class demand is backordered as soon as its own bin is empty, even if there is inventory in the higher class’ bin.\r\nIn this way we reserve some stock for both the classes but give priority to the higher class by allowing it to use the lower class’ stock. Under the assumption of fixed lead time, the exact expression for the average inventory cost is developed and optimal parameters are determined.  Numerical results show that the policy provides a much higher service level to the lower class, compared to inventory rationing, at a slightly higher cost.\r\n", :title "A new separate-bin policy for inventory control of multi-priority demands in a continuous review environment", :keyword2 101, :authors (3051 29325 29326), :session 171}, 516 {:keyword1 88, :keyword3 104, :abstract "In the computer-communication field, we frequently encounter a situation in which the processor sharing (PS) rule is adopted for a time-shared server next to the first-come-first-serve (FCFS) rule.  There has been much work on the Poisson-input general-service M/GI/1 (PS) system.  However, there have been few results for a general-input general-service G/GI/1 (PS) system. We deal with this general G/GI/1 (PS) system. We show that the cost-equation analysis enables us to derive the relationship between the mean (time-average) unfinished work and the mean (customer-average) sojourn time. Our relationship is then applied to extend and generalize the previous results, e.g., Brandt et al.'s relationship [1] between the mean (customer-average) sojourn times under the FCFS and PS rules, and Kleinrock's conservation law [2] for the M/GI/1 (PS) system. \r\n<BR />\r\nReferences:<BR />\r\n[1] A. Brandt and M. Brandt, \"A sample path relation for the sojourn times in G/G/1 --- PS systems and its applications,\" Queueing Systems, vol.52, pp.281--286 (2006).<BR />\r\n[2] L. Kleinrock, Queueing Systems : Computer Applications, vol.II, Wiley, New York (1976).", :title "A Cost-Equation Analysis of General-Input General-Service Processor Sharing System", :keyword2 99, :authors (26485 26546 25356), :session 113}, 517 {:keyword1 99, :keyword3 2, :abstract "There are many systems in which customers are scheduled to arrive at certain times and re-scheduled in case of disturbing events, such as delayed arrivals or capacity changes. Railway and aircraft sequencing are just two examples. Today, such schedules are often created by human experts who would like to better understand the impact of the disturbances on the system level: how far do delays propagate? How long does it take until the system is recovered from the disruptions?\r\n\r\nThe underlying problem can be formalized as a queueing system with pre-scheduled arrivals, but this problem is since long known to be notoriously difficult.\r\nWe present an original approach to a part of the problem that is based on elementary probability.\r\nMoreover, the queueing delays in our model are distributed between two waiting rooms. We quantify the propagated delay that is triggered by a late customer.\r\nThis propagation depends on the ratio of the usage of the waiting rooms. We then identify conditions under which waiting cost functions are convex.\r\n\r\nThis knowledge is useful to derive fuel-efficient strategies for aircraft sequencing.", :title "Delay Propagation in Re-Scheduled Queueing Systems", :keyword2 88, :authors (23312 24034), :session 175}, 518 {:keyword1 35, :keyword3 99, :abstract "I investigate the decision-making process of an owner of abandoned farmland that is currently restricted to agricultural use but will be available for non-agricultural use in the future. I find that a slight probability of land conversion greatly increases the land value and discourages the owner from cultivating the land. I also observe that a small gap in the anticipation of land conversion prevents the owner from selling or leasing the land to a more efficient farmer.", :title "Real Options Valuation of Abandoned Farmland", :keyword2 125, :authors (8187), :session 269}, 520 {:keyword1 126, :keyword3 0, :abstract "The talk is based on a joint paper with S. Aseev. We revisit the issue of necessary optimality conditions for infinite-horizon optimal control problems. We proved that the normal form maximum principle holds with an explicitly specified adjoint variable if an appropriate relation between the discount rate, the growth rate of the solution and the growth rate of the objective function is satisfied. The main novelty is that the result applies to general non-stationary systems and the optimal objective value needs not be finite (in which case the concept of overtaking optimality is employed). In two important particular cases it is shown that the current-value adjoint variable is characterized as the unique bounded solution of the adjoint equation. \r\n\r\nThe results are of particular interest for problems in economics, where the infinite horizon is typical and the issues of transversality and normality are delicate, especially for problems with unbounded solutions. \r\nA simple example of this type will be analyzed as an illustration.\r\n\r\n\r\n", :title "On the maximum principle for infinite-horizon optimal control problems with dominating discount", :keyword2 25, :authors (22710), :session 201}, 523 {:keyword1 92, :keyword3 0, :abstract "In this paper we consider a hybrid production system where it is possible to do manufacturing and remanufacturing. Two different hybrid systems PUSH and PULL, which are already defined in the literature, were compared depending on their inventory operating costs. We build a simulation model and run to compare these systems, having stochastic demand/return rate and manufacturing / remanufacturing lead time, within each other and also with traditional production system without remanufacturing. We considered variety of scenarios for each system based on different demand / return rate and manufacturing/remanufacturing lead time combinations.", :title "Performance analysis of hybrid manufacturing/ remanufacturing system according to inventory operating cost", :keyword2 97, :authors (19447 29329 29395 29333), :session 168}, 528 {:keyword1 88, :keyword3 0, :abstract "We consider a repair facility of one server and two independent arrival\r\nstreams of failed items; called base 1 and base 2. The arrival processes are\r\n independent Poisson processes with different rates, while the services\r\nare independent and exponentially distributed with equal rate.\r\nThe items are exchangeable in the sense that a failed item from base \r\n1 can satisfy a customer of base 2, and vice versa.\r\nThe items are admitted to one line but the customers wait and are marked\r\naccording to their sources.\r\nA backorder is created for each arrival. At a completion of service the item\r\nis delivered to the base which currently has the most backorders. In case of a\r\ntie, the item will be delivered to base 1 or base 2 with probability 0.5.\r\nSuch repair facilities occur as part of multi-echelon exchangeable item\r\n provisioning systems in which backorders are filled according to needs instead\r\n of FIFO or SIRO policies. Many organizations extensively use multi-echelon\r\n repairable-item systems to support advanced computer systems and sophisticated\r\n medical equipment.\r\n Our aim is to compute certain steady state performance measures of the\r\n system. Underlying these performance measures is the joint steady state \r\n distribution of the backorders.\r\n", :title "State Dependent Priorities for Service Systems with Exchangeable Items", :keyword2 0, :authors (29332), :session 114}, 530 {:keyword1 22, :keyword3 97, :abstract "This study covers both the pre-disaster and post-disaster phases of a disaster management problem. The pre-disaster decisions are the inventory decisions at the main depots for multiple items and the location decisions of the distribution centers. These decisions are made before observing the random data, which are jointly distributed demands and road capacities. After observing the randomness, at the second and later stages, the demands have to be satisfied using only the available inventories at the main depots and passing through the previously selected distribution centers. Mathematically, the first-stage problem is a mixed-integer linear optimization problem, whereas the problems at the later stages are simply linear programming problems. Assuming that the demands and road capacities are jointly and continuously distributed, the deterministic equivalent is obtained through the sample average approximation method. In addition to the risk-neutral multistage case, a risk-averse multistage reformulation using the conditional value-at-risk is obtained. Both the risk-neutral and risk-averse problems are solved through the stochastic dual dynamic programming (SDDP) under fairly general assumptions. Various implementation details related to SDDP will be provided during the talk.       ", :title "Multistage Stochastic Dynamic Programming Solution to Disaster Preparedness and Relief Distribution Problem ", :keyword2 85, :authors (29330 20053), :session 121}, 533 {:keyword1 17, :keyword3 18, :abstract "A Network DEA approach has been used to assess the efficiency of NBA teams and compared with a black-box (i.e. single-process) approach. Both approaches use a slack-based measure of efficiency (SBM) to evaluate the potential reduction of inputs consumed (team budget) and outputs produced (games won by the team). The study focuses on the distribution of the budget between first-team players and the rest of the payroll. The proposed Network DEA approach consists of six stages, which evaluate the performance of first-team and bench-team players, the offensive and defensive systems and the ability for transforming the points made by itself and by the opponent into wins. It has been applied to the 30 NBA teams for the regular season 2009-2010. The results show that Network DEA has more discriminating power and allows a deeper insight than the conventional DEA approach.", :title "Network DEA assessment of NBA teams efficiency", :keyword2 72, :authors (27742 29211 9590), :session 260}, 540 {:keyword1 101, :keyword3 100, :abstract "This paper is concerned with studying the effect of information on supply chain performance. We begin by studying wholesale price contracts between a supplier and retailer. A supplier produces a single product, and sells the product to a retailer at a unit wholesale price. The retailer then sells to stochastic demand, characterized by a distribution F, with known unit revenues and salvage values. The retailer faces a Newsvendor problem to maximize his expected profit. The supplier, knowing the retailer’s behavior, will choose a wholesale price to maximize his own profit. This exchange results is the well-known double marginalization effect, where the total supply chain profits are sub optimal. \r\n\r\nWe consider the above game where only one player, either the retailer or the supplier, has full knowledge of the demand distribution F, and the other only knows the mean and standard deviation of demand. We compare these situations to that where both the retailer and supplier have full information of the demand distribution F. We find that in certain situations the lack of information reduces the double marginalization effect and other times the double marginalization effect is amplified. This paper characterizes the conditions where the lack of distributional information either improves or deteriorates supply chain performance. \r\n\r\nWe also consider the behavior of buy-back and revenue-sharing contracts, which traditionally coordinate the supply chain. Under the incomplete information architectures described above, we show that, while the contracts still coordinate the supply chain, the individual players will have differing (inaccurate) beliefs about the supply chain performance. \r\n", :title "The Benefit/Detriment of Information in Coordinating Supply Chains", :keyword2 99, :authors (25170), :session 167}, 542 {:keyword1 106, :keyword3 78, :abstract "In this article, we present a routing and scheduling problem of a heterogeneous fleet of re-configurable ferries transporting cars, trucks, and passengers. The problem is formulated as a mixed integer program, and it is solved by a variation of a genetic algorithm that uses a general-purpose integer program solver as a subroutine to handle subproblems of a smaller size. This solution methodology achieved solutions providing average savings of $5,000 per week on real-world instances with four ferries and seven ports.\r\nOur ferry scheduling problem deals with finding routes and schedules for a fleet of ferries in order to serve transportation requests between a set of ports with the objective of minimizing ferry fixed and operational costs and maximizing customer satisfaction. It is a model of a scheduling problem of a company whose management wanted to re-evaluate their current schedules and consider possible improvements. Their goal was to use their resources (ferries and crews) efficiently and to reliably meet the existing demand for the transportation among the residents and tourists between the ports. Considered improvements of the ferry service include: decreasing the operational costs, reducing excess travel time for passengers (compared to the direct travel time), and reducing the passenger waiting time. We considered decreasing the operational costs without increasing excess travel time for passengers and the passenger waiting time.\r\n", :title "Routing and scheduling of a heterogeneous fleet of  re-configurable ferries: A model, a heuristic, and a case study ", :keyword2 96, :authors (10539 29337), :session 187}, 543 {:keyword1 95, :keyword3 35, :abstract "In this paper, we propose an exact solution method for dynamic route search under uncertainty. We can get easily dynamic information on roads through Intelligent Transport Systems (ITS) in recent years. Thereby, many heuristic methods are presented for dynamic route search with ITS, but there are few exact solution methods. It is difficult for the car navigation system apparatus in each car to solve an exact solution for route search inclemently. However, with using a server type car navigation system like the “Internavi LINC Premium Club” from HONDA, it becomes easier for us to get instantly exact solutions than previous.\r\n\r\nFirst, we formulate a dynamic route search problem under uncertainty as an optimal option exercise problem of compound options restricted on a road network. This compound option includes European and American type options which are used in finance. When we come into an intersection, we choose which way to go. This choice is an exercise of a European option. When an accident occurs ahead, we must reverse or revise our route. This revision of the route is an exercise of an American option. Exercises of these options are linked and restricted on the network architecture. We call this exact solution method “A Real Option Route Search (RORS),” which regards routes as real options. This method can be seen as an expansion of the ordinary real option to the direction of Euclidean Spaces.\r\n\r\nSecond, we conduct an empirical analysis on the Red Bus/Blue Bus type network. In this analysis, we prepare four methods of route search; traditional Dijkstra, Dijkstra considering uncertainty, RORS without U-turn and RORS with U-turn. Therefore, it is useful to utilise a RORS when uncertainty on the network is bigger and bottleneck is closer to a turning point.", :title "A real option route search", :keyword2 106, :authors (26181 26404), :session 207}, 547 {:keyword1 42, :keyword3 0, :abstract "In playing piano, it is important to use appropriate fingers to facilitate movements and transitions of fingers. In this paper, we address a problem of mapping piano music score into one of possible alternative fingering sequences.\r\nFirst, we present an efficient dynamic programming (DP) method for choosing an optimal fingering sequence. We introduce a layered acyclic digraph such that each layer of the digraph corresponds to a set of nodes representing the different possible finger chords at each time instance in a given piece. We find a shortest path from the first chord to the last chord of the piece, which gives one of the best sequences of finger chords.\r\nWhen we use the DP method, we need to determine cost of stretch for each chord?induced by positions of fingers and costs of transitions between pairs of successive chords. We propose a technique to estimate the DP cost functions based on an example of fingering offered by an experienced player. Our method is based on the inverse optimization technique for shortest path problem. We find a cost function such that a given example of finger chords becomes a shortest path in the digraph.\r\nOur experiments for several music excerpts yield a set of cost?functions which give fingering sequences with smooth transitions.\r\n", :title "Optimal Piano Fingering Based on Inverse Optimization", :keyword2 8, :authors (29338 13201), :session 208}, 550 {:keyword1 101, :keyword3 0, :abstract "We consider an integrated production and distribution scheduling problem and develop a mixed-integer programming formulation. The main specifics of this problem are, that not necessarily each customer has to be served and that the considered product has a limited lifespan.\r\n\r\nThere are customers with non-negligible traveling times between them and the manufacturer. Each customer requests a specific demand of a perishable product which he wants to receive in a specific time window. The manufacturer of this product has now to decide what customers to serve. The chosen orders have to be produced on a single machine, so another decision is when to produce which chosen order. As a third decision, the distribution of the chosen orders must be planned with a heterogeneous fleet of capacity-limited vehicles. All decisions shall be made simultaneously to draw as much profit as possible. The profit is the total revenue of the chosen orders minus the penalties of the not chosen orders and delivery costs.", :title "A MIP model for an integrated production and distribution scheduling problem", :keyword2 106, :authors (29339), :session 165}, 551 {:keyword1 42, :keyword3 0, :abstract "For a graph G=(V,E) and a vertex v of V, let T(v) be a trace at v, i.e. T(v) is an Eulerian  subgraph of G such that every walk W(v), starting at vertex v can be extended to an Eulerian tour in T(v). \r\nIn the talk we show, that every maximum edge-disjoint cycle packing Z* of G induces a maximum trace T(v) at v for every v in V. Moreover, if G is Eulerian and maximum traces at v are unique a maximum cycle packing of G can be obtained by the determination of edge-disjoint cycles packings of maximum traces T(v) in G.", :title "Packing Euler-graphs with traces", :keyword2 16, :authors (25677), :session 229}, 552 {:keyword1 106, :keyword3 0, :abstract "We address a problem motivated by the business requirements of a German long-haul freight transportation company operating in Europe. Legislation issued by the European Union on driving and rest periods has put increased pressure on the company to plan driver activities. Moreover, fuel cost has also become a critical factor as prices vary significantly across different countries in Europe. The integration of both issues – driver rest time scheduling and refueling policies – into the planning process has not been addressed in the literature so far although it is very important for any transportation company. To deal with this issue we present a sequential and a simultaneous planning approach. In the sequential approach, driver activities and stops for refueling are planned in three steps. In the first phase, time windows for customer locations are chosen with respect to driving hours and rest periods for the driver. In addition, enough slack time for vehicle refueling is considered. In the second phase, we determine the gas stations the driver is expected to choose as well as the amount of fuel he should purchase. In the third step, rest periods and breaks are rescheduled due to the additional time required by detours and refueling stops computed in step two. In the simultaneous approach, driver activities and time windows are planned along with refueling stops. Both approaches consider the minimization of fuel costs and lateness, giving the highest priority to punctuality. For test instances based on real-life data, the two approaches are evaluated in terms of solution quality, that means punctuality and fuel costs. The trade-off between solution quality and computing time is also considered.", :title "Vehicle refueling policies for long-haul freight transportation considering time windows and fuel costs", :keyword2 0, :authors (23455 1256 15127 15277), :session 187}, 553 {:keyword1 124, :keyword3 0, :abstract "In this paper, we propose a touch typing trainer system, such that characters that are mistyped are repeated more frequently. In a training session, our system shows words (called “true sequences”) and a user types sequences of characters (called “typed sequences”). Given a pair of true sequence and typed sequence, we found an alignment of the pair of sequences such that the number of mistyped characters is minimized by using an ordinary dynamic programming method for DNA alignment problem.\r\nWhen every pair has a unique optimal alignment, we estimate a probability to mistype for each character by maximum likelihood method under a standard binomial distribution model. In case that optimal alignment is not unique, we introduce a simple model that every optimal alignment has a mutual incidence. We obtain probabilities to mistype characters by maximum likelihood method under this model.\r\nLastly, our system chooses some words depending on the estimated mistyping probabilities. We formulate a problem of choosing words including characters that are mistyped as a variation of multi-armed bandit problem such that number of mistyped characters is a reward of an action to choose a word (true sequence). We introduce a simple strategy which is similar to UCB1 algorithm proposed by Auer, Cesa-Bianchi, and Fischer in 2002.\r\nWe show a performance of our system through computational experiences using simple binomial model for generating typed sequences.\r\n", :title "Touch Typing Trainer System", :keyword2 18, :authors (29341 13201), :session 241}, 556 {:keyword1 126, :keyword3 34, :abstract "In order to prevent or foresee financial crises, understanding the dynamics of the bubbles is crucial. We approach this issue by using geometry and topology to identify, predict and control size and the position of the bubbles. To model their progression we benefit from ellipsoidal calculus and homotopies. In addition, every bubble is dealt with as a system and thresholds are found between them. Finding these levels will be beneficial to give earlier signals. The bubbles will be monitored by thresholds. We firstly consider stock market crashes; therefore we validate the model by a large database from stock market.\r\n", :title "Understanding Dynamics of Financial Bubbles by Geometrical and  Topological Aspect ", :keyword2 93, :authors (19185 3524), :session 62}, 558 {:keyword1 19, :keyword3 0, :abstract "We study the effect of additional information on the quality of decisions.\r\nHence, we define the polar case of complete information about probabilities as our reference scenario. There, decision makers (DMs) can avail themselves of expected utility theory to evaluate the best alternative. Starting in the worst case – where DMs have no information at all about probabilities – we find a method of constantly increasing the information by limiting the ranges for the probabilities systematically. In our simulation–based study, we measure the effects of the constant increase in information by using different accuracy indices. We define these indices as the relative frequency of probabilities within stepwisely narrowing boundaries which lead to the same decision as with the probability in the reference scenario. Thus, they account for the\r\nquality of information. Combining input and output, we find a certain degree of decreasing returns to scale on information, or in other words, the costs of gathering additional information increase with the level of information.\r\nMoreover, we show that more available alternatives influence the decision\r\nprocess negatively.  Finally, we analyze the quality of decisions in processes where more states of nature prevail. We find that this degree of complexity in the decision process influences the quality of decision.", :title "Information Sets and Relations", :keyword2 97, :authors (29345 29347), :session 256}, 563 {:keyword1 7, :keyword3 65, :abstract "In [1], De Wolf and Smeers consider the optimal dimensioning of a gas transmission network. The pipe diameters where chosen to minimize the sum of the investment and operating costs. This model does not reflect any more the current situation. Today, the transportation and gas buying functions are separated. For example, on the Belgian gas network, the transport is devoted to Fluxys company and several actors are in charge of gas supplying. \r\n\r\nIn order to reflect this new situation, a modelisation of the compressors was introduced in the exploitation model of De Wolf and Smeers [2] by Bakouya and De Wolf [3]. In this new exploitation model, the transportation company determines the flows in the pipes to minimize the energy used in the compressors for the gas transport. \r\n\r\nThe present paper considers the optimal dimensioning model applied to the belgian gas transmission network. In [1], De Wolf and Smeers only consider the pipe diameters as investment variables. We also consider the maximal power of the compressors. We illustrates on the belgian gas network the fact that  this new model could balance any decrease in investment of pipelines with an increase of compressor power. \r\n\r\n[1] Optimal Dimensioning of Pipe Networks with Application to Gas Transmission Networks, D. De Wolf and Y. Smeers, Operations Research,Vol 44, No 4, July-August 1996, pp 596-608.\r\n[2] The Gas Transmission Problem Solved by an Extension of the Simplex Algorithm, D. De Wolf and Y. Smeers, Management Sciences, Vol. 46, No 11, November 2000, pp 1454-1465.\r\n[3] The gas transmission problem when the merchant and the transport functions are dis- connected, D. De Wolf, and B. Bakhouya, HEC Ecole de Gestion de l'ULG Working Paper 2007/01, January 2007. ", :title "Optimal dimensioning of gas transmission networks when the distribution and the transportation functions are separated.", :keyword2 14, :authors (29305), :session 76}, 568 {:keyword1 19, :keyword3 93, :abstract "Multi-period risk functionals assign a risk value to discrete-time stochastic processes. While convexity and monotonicity properties extend in a straightforward way from the single-period case, the role of information is more problematic in the multi-period situation. We define multi-period functionals in such a way that the development of available information over time (expressed as a filtration) enters explicitly the definition of the functional. This allows to define and study the property of information monotonicity, i.e. monotonicity w.r.t. increasing filtrations. It is well known that the requirement of time-consistency essentially leads to functionals, which are compositions of conditional mappings. We introduce the definition of information monotonicity as an additional requirement for multi-period functionals. For compositions of positive homogeneous risk/acceptability mappings a necessary and sufficient condition for information monotonicity is given. Within the class of distortion functionals only compositions of expectation or essential infima are information monotone. In addition we give a sufficient condition and examples for the rare case of compositions of nonhomogeneous mappings exhibiting information monotonicity.", :title "Are time consistent risk functionals (resp. acceptability functionals) information monotone?", :keyword2 85, :authors (18480 3122), :session 119}, 569 {:keyword1 85, :keyword3 67, :abstract "We define a multistage distance between discrete-time stochastic processes and demonstrate its properties. It is shown that this distance encodes not only the values, but also the information structure of the processes.\r\n\r\nIn particular, we study the distance between general discrete time processes and trees as well as the distance between two trees and derive a bound for the optimal values of the pertaining otpimization problems. \r\n\r\nBased on this technique, one may compare scenario generation techniques such as Monte Carlo, Quasi Monte Carlo and Probability Quantization. \r\n\r\nWe demonstrate the findings by various examples.    ", :title "Approximation quality for multistage stochastic programs", :keyword2 76, :authors (3122), :session 119}, 570 {:keyword1 59, :keyword3 0, :abstract "In this paper an environment is established for a quantitative analysis of separate and combined performance of local searchers and genetic algorithm. \r\nWell researched and controlled Euclidean Travelling Salesman Problem examines the impact of grafting a 2-opt based local searcher into the genetic algorithm, for solving the Travelling Salesman Problem with Euclidean distance. Genetic algorithms are known to be rather slow, while 2-opt search applied to the Travelling Salesman Problem quickly gives results that are far from optimal. \r\nWe propose a strategy to graft a 2-opt local searcher into a genetic algorithm, after recombination, to optimize each offspring’s genomes. Genetic algorithm provides new search areas, while 2-opt improves convergence.\r\nIn that controlled environment we compared two direct techniques, a genetic algorithm and a 2-opt algorithm with our grafted genetic algorithms. Exact solution from Concorde and lower bound on quality, greedy algorithm were added for better comparison. \r\nQuantitative results on test cases from TSPLIB show that grafted algorithms have new quality. Even when both components have serious drawbacks, their grafted combinations exhibits excellent behaviour.\r\nThis new method combines good qualities from both methods applied in such a way that it significantly outperforming each of them, compared to the quality of provided solutions.\r\nFurther calibration of this system will include measuring the optimal blend of two components for larger test cases. \r\n\r\n", :title "Quantitative Analysis of Separate and Combined Performance of  Local Searcher and Genetic Algorithm", :keyword2 8, :authors (29350 20940), :session 238}, 573 {:keyword1 98, :keyword3 0, :abstract "A key success factor of your OR-based solutions (i.e. applications in which Optimization plays a key role in making a difference to the organization it is used in), is the ability to put it into the hands of end-users. These end-users will use the solution to make better decisions; those could be strategic, tactical or operational such as network design, refinery planning, or workload scheduling. \r\nSuch OR-based solutions are more likely to be accepted if a workflow support system is provided that allows for easy publishing (by developers), easy usage (by end-users), and monitoring/managing (by IT). Another item that makes a solution more likely to be accepted, is that it should be easily changeable if business requires it.\r\nThe concept of content management system for websites, and the ability of using today’s powerful shared central resources (cloud, private data center etc.) has been the fundament for the development of PRO, the Publish and Remote Optimization framework for AIMMS-based applications. Through a simple web portal, end-users can start-up their OR-based solutions, while developers can use a web portal to upload and manage their published solutions (including user control, security, updates of solutions, etc.). In addition to the workflow support, PRO allows organizations to efficiently use their hard- and software and scale-up/down based upon user demand.\r\n", :title "Easy deployment of your OR-based solutions", :keyword2 0, :authors (19332), :session 241}, 580 {:keyword1 18, :keyword3 0, :abstract "Scenario analysis has become an important tool during decision making and problem analysis process. A key aspect in scenario analysis is the generation of a small set of representative scenarios that adequately represent the full spectrum of possible scenarios. Depending on the type of problem, this small set of representative scenarios can then be analysed by experts or e.g. by a time consuming computer simulation program. Various techniques for generation of the full spectrum of possible scenarios are available, like morphological analysis. However, these methods in general yield an enormous amount of scenarios, and do not further support the user in the selection of a small set of representative scenarios. Other methods, like design of computer experiment methods, do aim at the generation of a small set of representative scenarios, but they are only suitable for a specific type of scenarios.  In order to overcome these drawbacks we introduce a new general method for scenario generation that combines techniques from morphological analysis, design of experiments and combinatorial optimization and. The method starts with a morphological analysis. This yields a set of variables and their possible values defining the full spectrum of possible scenarios. Next, the method generates a user-defined number of scenarios satisfying a number of properties that reflect the representativeness of the set of scenarios. The user can specify the importance of each representativeness property.", :title "Scenario Generation: Combining Morphological Analysis and Design of Computer Experiments", :keyword2 8, :authors (25895 24972), :session 253}, 586 {:keyword1 45, :keyword3 0, :abstract "Healthcare operations management, which mainly aims both to control the increasing costs and to increase the accessibility level for healthcare services, is the discipline that integrates the aspects of management with OR techniques to determine the most efficient and optimal methods of supporting patient care delivery. The studies of OR on healthcare are not only for determining the methods for healthcare delivery, but also for clinical purposes or for simulating the systems to observe the long-term risks.\r\nApplication of OR to healthcare is accepted to have started in 1970s. First publications were mainly about health planning and administration. Later on, research areas on healthcare have widely spread from top management to the smallest operation. Healthcare operations management has become a popular research subject in many countries since 1990s: e.g. EURO working group ORAHS (Operational Research Applied to Health Services), the College of Healthcare Operations Management of POMS. Several articles were published, special journal issues were prepared, and conferences were held. Studies are being made in different areas of healthcare such as; resource allocation, scheduling, waiting-lists, patient flows, facility location, cost-effectiveness analysis, emergency services, and disease treatment investigations.\r\nEven though healthcare operations management has become very popular and lots of research studies have been made, a taxonomic review on the subject is still missing. Because of this necessity, this paper has been prepared to search articles about the healthcare operations management. The literature has been deeply reviewed and by classifying previous studies according to their preferences, taxonomy for healthcare operations management has been prepared.", :title "Healthcare operations management: A taxonomic review", :keyword2 0, :authors (29358 1177), :session 48}, 588 {:keyword1 91, :keyword3 97, :abstract "Accounting for individual choice decisions especially regarding buy-up nd  buy-down behaviour of customers in airline revenue management is both a complex stochstic and dynamic problem. Hence, dynamic optimization is able to provide an exact solution. In terms of capacity control in airline revenue management an application of the before mentioned method has proven to be rather inappropriate due to high computational and memory requirements. As a consequence, approximate methods are usually applied instead. Our aim is to provide an alternative approach based on the simulation of a flexible number of individuals with associated utility values and improved revenue performance. Thus, we are able to incorporate individual decision making behaviour regarding the choice of fare classes (alternatives). Utility values are obtained from random utility models (RUM) like the Multinomial Logit model (MNL) which is popular for its Independence from Irrelevant Alternatives (IIA) assumption resulting in constant substitution patterns. Anyhow, in situations where the choice set contains alternatives that share common unobserved attributes more flexible choice models like the Nested Logit model (NL) or Mixed Logit model (MMNL) are to be favored. These models exhibit flexible substitution patterns and, thus, are able to capture shifts in demand between alternatives that share common characteristics not observed by the modeler. In our analysis we take advantage of this characteristic to model buy-up and buy-down behaviour between fare classes. Consequently, by implementing simulation procedures in a mathematical model, we are finally able to provide a comparison of revenue development under both stochastically independent and dependent demand structure.", :title "Simulating Fare Class Choice Behaviour with Flexible Substitution Patterns in Airline Revenue Management", :keyword2 19, :authors (29346), :session 98}, 590 {:keyword1 13, :keyword3 53, :abstract "In this talk, we are interested in the development of new first-order methods for smooth convex optimization. It is well-known that the classical gradient method (GM) is not optimal for the class of smooth convex functions with Lipschitz-continuous gradient. The optimal methods for this class are the fast gradient methods (FGM) developed in various versions since 1983.\r\n\r\nHowever, we have proved in previous research that fast-gradient methods are more sensitive with respect to errors in the first-order information.\r\nContrarily to the simple gradient method, fast-gradient methods suffer from accumulation of errors. Moreover, we have shown that it is an intrinsic and unavoidable property of any optimal first-order method.\r\n\r\nIn this talk, we show that there is a clear link between the rate of convergence of a first-order method and the lowest possible rate of error accumulation that we can expect.\r\nMotivated by this result, we develop a whole family of first-order methods with intermediate rates of convergence and intermediate rates of error accumulation between the classical gradient and the fast gradient methods.\r\n\r\nSpecifically, we have developed a family of methods, interpolating between the dual gradient and the fast gradient methods.\r\nWe show how these new intermediate first-order methods can be used in order to accelerate the minimization of a smooth convex function when only inexact first-order information is available.", :title "Between Gradient and Fast Gradient Methods: a Family of Intermediate First-Order Methods.", :keyword2 10, :authors (25360 25666 25671), :session 61}, 591 {:keyword1 8, :keyword3 76, :abstract "The investment project scheduling problem is considered. The criterion is the net present value (NPV). Let N activities are given, whose processing requires only one kind of resources – finances. This is the storable kind of resources. The set of activities has a partial order. The amount of finances is given at every moment. Each activity is characterized by duration and cash-flow. The problem is to find a starting time for the activities, which will be maximize the net present value. \r\nThe problem with storable resources and criterion makespan is solvable in polynomial time. But the same problem with NPV criterion is strongly NP-hard. An exact algorithm for solving the investment project scheduling problem with the usage of credits, reinvestment of profit and the NPV criterion is proposed. The algorithm is based on the method of dynamic programming. And also we proved the following statement. \r\n\r\nTheorem. If the width of the partial order on the set of activities is bounded by a constant, then this problem is solvable in polynomial time.\r\n", :title "A dynamic programming algorithm for the  project scheduling problem with NPV criterion ", :keyword2 86, :authors (29303), :session 50}, 596 {:keyword1 40, :keyword3 127, :abstract "This article  characterises stable sets in  preordered sets.\r\nWe show that every stable subset of a preordered set is characterised as a fixed point of the mapping assigning  the set of all its maximal elements to each upper bounded  subset of the preordered set.\r\nThis result gives a  characterisation of  stable sets in  strategic  games with transitive preferences.\r\n", :title "Characterisation of Stable Sets in Game with Transitive Preferences", :keyword2 19, :authors (5988), :session 138}, 600 {:keyword1 54, :keyword3 0, :abstract "This presentation investigates scenarios, in which polluting or otherwise undesirable facilities have to be located with the objective to minimize the undesirable effects to the population, which is assumed to be located at given points. In the simplest case, related to the location set covering model for desirable facilities, we attempt to maximize the number of facilities that can be located so as to not cause undue harm to any portion of the population. The major flaw of this model is that undesirable effects tend to be additive, which is not the case in the location of desirable facilities. Ignoring this feature of the model results in undesirable “fringe” solutions. To overcome this deficiency, we introduce pollution decay functions, which—other than their additivity—behave similar to attraction functions that have been discussed in the literature for the location of desirable facilities. A number of different pollution functions are described and their properties examined. One solution approach to the undesirable location problem defines an acceptable level of pollution for each customer (these levels may vary, depending on who or what the “customers” are), and then maximizes the number of facilities that can be located, such that no customer receives a level of pollution that exceeds the prescribed largest acceptable amount. Another approach uses concepts similar to the well-known gradual covering models. Evidence of some preliminary computational experience is provided. ", :title "Covering Models for Undesirable Facilities", :keyword2 0, :authors (12245 1646), :session 177}, 603 {:keyword1 29, :keyword3 136, :abstract "Despite the uncertainty surrounding the design of a mechanism which is ultimately accepted by nations worldwide, the necessity to implement regulations to curb emissions of greenhouse gases on a global scale is consensual. The electricity sector plays a fundamental role in this puzzle and countries may soon have to revise their operating policy directives in order to make them compatible with additional constraints imposed by such regulations. In this work, we use optimal expansion planning to derive the marginal investment cost when imposing CO2 emission allowances quotas on a hydro-dominated power system. Benders' decomposition is used where the sub-problems are stochastic least-cost hydro-thermal scheduling problems, solved by stochastic dual dynamic programming methods.", :title "Optimal Expansion of CO2 Emission Constrained Hydro-Dominated Power Systems", :keyword2 85, :authors (29370 13458 29372), :session 82}, 605 {:keyword1 18, :keyword3 102, :abstract "In this study it is presented a linear mathematical model to evaluate and optimize the business activities of a dairy farm characterized by crop-livestock integration. In rural business, selecting agricultural crops and livestock activities are challenges to the decision makers during all the times. Nowadays, the concern about environmental aspects arises as an imminent factor into the economic analysis of production activities. In the specialized literature, it has not been found any mathematical model to optimize and to evaluate the dairy activity by taking into account the economic, social and environmental aspects. The proposed model aims at maximizing the profit of the whole dairy farm activities along a 60 month period. The model constraints are related to the number of animals in different categories (milking cows, dry cows, heifer etc.), land availability, animal feed demand, crop fertilization requirement, crop scheduling etc. Besides the traditional parameters which are taken into account in this kind of planning models, this study innovates by including the logistic costs (transportation of farm inputs and outputs), animal feeding and waste management, carbon emission/sequestration, water level consumption parameters. The model was implemented in GAMS syntax and solved by CPLEX. The model adjustments and its validation were performed in a high technology dairy farm in Brazil. The mathematical structure allows the model adaptation to several rural activities characterized by crop-livestock integration. The preliminary results show that the model may be used as a decision tool to evaluate the economic, social and environmental impacts in a dairy farm activity subject to external economic policies related to farm input/output prices.", :title "Mathematical model to optimize and assess a dairy farm characterized by crop-livestock integration: Consideration of economic, logistic, social and environmental aspects", :keyword2 125, :authors (28726 28706 29374), :session 254}, 606 {:keyword1 75, :keyword3 0, :abstract "Lean manufacturing is currently considered to be the most dominant manufacturing strategy globally.  It has transformed numerous firms in the manufacturing and non-manufacturing sectors into profitable enterprises. This empirical paper evaluated the current state of lean implementation in the Indian manufacturing sector. Lean is a multi-dimensional construct, and therefore, this paper assessed the degree of lean system implementation based on certain lean dimensions - focus on customer needs, pull system, set-up time reduction, total productive maintenance, supplier performance, statistical process control, and cross-departmental problem solving.  The performance metrics (productivity, first pass correct output, number of days in inventory, manufacturing lead time, and space requirement) were also examined.  A survey questionnaire was administered to manufacturing firms from various product segments. Seventy nine firms from various product segments responded to the survey. The study indicates that many Indian firms are at the advanced stages of lean implementation and have achieved superior operational performance. Analysis of variance indicates equal degree of lean system implementation across various product segments. Regression results suggest that there was significant positive relationship between lean implementation and firm’s overall or aggregate performance. The findings can be beneficial to those managers in India who are contemplating the idea of implementing lean manufacturing practices into their workplace to achieve better performance outcomes.", :title "A Study on the Assessment of Lean Implementation Success Factors in Indian Manufacturing Plants: An Empirical Investigation", :keyword2 0, :authors (29318), :session 225}, 607 {:keyword1 35, :keyword3 93, :abstract "In this paper we present an investment problem of the firm which is financed with convertible debt, taking into account managerial compensation in real options framework. We model a firm in which the managers act in their own interest to maximize the present value of the expected cash flows that they will take from the firm’s operations. We analyze the effects of separation of ownership and control on the firm’s convertible debt financing and investment decisions. Especially, we examine how managerial compensation affects investment and capital structures. In addition, we explore pay-performance sensitivity for firms issuing either straight debt or convertible debt and then investigate whether it is consistent with empirical evidences in Ortiz-Molina (2007) who argues the sensitivity decreases in leverage of straight debt, but is higher in firms issuing convertible debt.", :title "Convertible Debt Financing and Managerial Compensation", :keyword2 34, :authors (11980 28413), :session 267}, 608 {:keyword1 95, :keyword3 54, :abstract "In a market-driven e-grocery setting, it is a challenge to fulfill the consumer demand. A key strategy to achieve growth in many businesses is to offer value-added products that meet the needs and desires of consumers.  Yet, most e-groceries have not been able to elevate business from providing low value goods to fulfilling the consumer demand for value-added products. In this paper, we propose a business model for e-supermarkets to enable multi-product sourcing capacity through collaboration. The logistics aspect of our approach is to design and execute a network system where goods are acquired from vendors at multiple locations in the supply network and delivered to customers. Our specific goals are to: investigate the role of value-added product offer in creating critical mass and profit; develop a model for the mixed location-allocation and vehicle routing with pick-up and delivery problem; and propose a hybrid solution approach.\r\nIn this business model, the product range offered by the e-grocery includes the SKUs available in the grocery stores and the premium products which are available at a set of vendor locations. The location-routing problem combines two components: selection of vendors to supply premium products and routing of the vehicles serving the customers by picking up premium products from external vendors and consolidating them with grocery products. This problem yields a multiple pick-up and single delivery capacitated vehicle routing problem with time windows (VRPPDTW). We formulate this location-routing problem as a mixed integer programming model with an objective of minimizing total transportation costs. \r\nTo solve this problem, we developed a hybrid metaheuristic approach using Genetic Algorithm for the location-allocation part and a modified savings algorithm for the capacitated VRPPDTW. The proposed Genetic Algorithm guides the search for optimal pick-up location decisions, while for each generated solution in the genetic population, a corresponding VRPPDTW is solved using the savings algorithm.", :title "A Location-Routing Approach for Delivering Premium Goods in E-Grocery", :keyword2 106, :authors (20135 7649 29381), :session 186}, 613 {:keyword1 96, :keyword3 77, :abstract "This paper deals with a bus tour booked by Indian tourists. During the tour, the tourists visit specific locations of famous Bollywood films at various sites in Switzerland; moreover, the tour includes stops for lunch and for shopping. Each day, up to five busses operate the tour; however, two or more busses cannot stay at the same location simultaneously. Further operative constraints include time windows for activities and precedence relationships between activities. The planning problem consists in computing a feasible schedule for each bus such that the total waiting time (primary objective) and the total travel time (secondary objective) are minimized.\r\n\r\nIn this talk, we present a basic formulation of this problem as a mixed-integer linear program. We enhance this basic formulation by symmetry-breaking constraints, which reduce the search space without loss of generality. For the experimental analysis, we varied the number of busses and studied a set of problem-specific scenarios. We report on computational results obtained with the Gurobi 4.0 Solver. Our numerical results show that all relevant problem instances can be (approximately) solved using the basic formulation within reasonable CPU time, and that the symmetry-breaking constraints reduce that CPU time considerably.", :title "A scheduling application in the event-tourism industry: MILP model and experimental performance analysis", :keyword2 95, :authors (28457 125), :session 142}, 615 {:keyword1 57, :keyword3 106, :abstract "Currently, logistics service providers dealing with LTL (less than truckload) which offer transportation services for groupage freight are facing three main challenges: a huge increase in international transport volume, a growing environmental awareness by the customers, and the permanent pressure of strong competition in the transportation sector. Thus, these logistics service providers have to optimize their transportation networks on a regular basis in order to reach an efficient management of the corresponding resources vehicles, drivers, and terminals. \r\nIn this paper, we extend the classical hub location problem in several ways to satisfy the real world requirements of an international LTL logistics service provider. We allow direct transportation between origin-destination nodes as well as transportation via one or two hubs. Due to a multiple allocation approach, the best possible individual routing for each origin-destination pair may be chosen. Additionally, we consider capacities for possible hubs and different types of vehicles. Our objective function includes handling costs in the hubs and realistic transportation costs based on the actual number of vehicles needed on each arc of the network. \r\nWe present two different formulations, mixed-integer and multi-commodity flow, respectively, for the given problem and compare their performance by means of computational results for several test scenarios based on real life data which are solved by CPLEX. We conclude with possible enhancements to both formulations like time slices and buffering of goods.\r\n", :title "Optimization Approaches for a Network Design Problem of a LTL Logistics Service Provider", :keyword2 65, :authors (24074 23128 26657), :session 242}, 616 {:keyword1 94, :keyword3 96, :abstract "We consider simultaneously the scheduling problem and the maintenance tasks of a 2 level permutation Flow-Shop. This method allows the industrial decision-makers to find the trade-off between the objectives of production and maintenance. Our objective is to optimize at the same time three criterion. These criterion are the maximum completion time “Cmax”, the availability of flow-shop to find the time for preventive maintenance and the robustness of scheduling to take into account the possible machine breakdowns. For this, we present two approaches for scheduling the production jobs and preventive maintenance interventions. The first approach is to find the trade-off between Cmax and availability where the processing time integrate the possible machine breakdown. The second approach is the rescheduling approach. Several tests are proposed and the results are promising.", :title "Trade-off between CMAX and Availability of 2-level Flow-shop Under Corrective Maintenance", :keyword2 89, :authors (29382 16003), :session 147}, 617 {:keyword1 106, :keyword3 0, :abstract "The Truck and Trailer Routing Problem (TTRP) is an extension of the classical Vehicle Routing Problem (VRP), where ehicles are combinations of a truck and a trailer, yet due to road limitations, a subset of customers can only be served by the truck alone. Here a vehicle route starts and ends at a depot but the trailer can be detached at any customer on the route with the truck continuing serving customers on a truck sub-tour without the trailer before returning and deattaching the trailer.\r\n\r\nWe present a 2-phase heuristic for solving different variants of the TTRP. Our computational experiments show that we could improve the solution quality on benchmark problems for the TTRP variants that have been studied in literature and we could determine good reference solutions for new so far unstudied TTRP variants.\r\n", :title "A new approach for solving truck and trailer routing problems", :keyword2 59, :authors (29384 14755), :session 246}, 619 {:keyword1 106, :keyword3 59, :abstract "We present two metaheuristic approaches for solving a real-world vehicle\r\nrouting problem arising in the air cargo road feeder service business.\r\nThis problem, which we refer to as the Vehicle Routing Problem with\r\nMultiple use of Tractors and Trailers and EU-regulations (VRPMTT-EU),\r\ninvolves the following aspects: Transportation tasks from a given\r\ntimetable have to be combined to trips which can be operated by drivers\r\nrespecting the restrictive rules on driving times from EC Regulation No.\r\n561/2006. These trips, starting and ending at the hub, have to be\r\naggregated to multiple-trips which are operated by the same tractor. Also,\r\nto each trip a trailer has to be assigned which is compatible with all\r\ntasks in the trip. Tractors can perform multiple-trips with different\r\ntrailers during the planning period by exchanging trailers at the hub. The\r\nprimary objective of the VRPMTT-EU is to minimize the number of required\r\ntractors, i.e. the number of multiple-trips. We have found that the\r\ndecomposition of the problem into trip generation and trip aggregation\r\nyields the best results.\r\n", :title " Solving a real-world vehicle routing problem with multiple use of  tractors and trailers and EU-regulations for drivers arising in air  cargo road feeder services", :keyword2 95, :authors (14762 14755), :session 85}, 623 {:keyword1 35, :keyword3 25, :abstract "In this study, we empirically examined the relationships between Range to Standard Deviation Ratio (R/S Ratio) of a financial time series and the predictability of that time series based on past values of the series. Financial markets theories are based on the assumption that security prices are martingales, implying the expected value of security price is the price in the previous period. Therefore, security prices follow random walks and returns from financial securities are unpredictable. And technical analysis based trading rules are unlikely to give profitable results.\r\nHowever, many physical and biological systems display presence of long memory or trends in their time series. H. E. Hurst, a British hydrologist, analyzed water flow characteristics of River Nile. He developed a ratio by dividing high-low Range of the water flow by the Standard deviation of the data series and found that the ratio can be used to detect dependency of the future water flow on its past values. Similar to the study of natural phenomena, the ratio has found application in the study of price variations in financial markets. If the current price of a stock depends on its past prices then the dependency can be used to forecast future prices of the stock and profitable investment decisions can be taken. The larger the R/S ratio, the stronger is the dependence on the past values of the series and higher is the chance of technical trading rule giving profitable results. \r\nThe study analyzed R/S ratios of number of financial series involving stocks traded in stock markets in various periods and found out relationship between R/S ratio and performance of a technical trading rule.\r\n", :title "Forecasting Performance of Financial Time Series Based on Range to Standard Deviation Ratio ", :keyword2 37, :authors (29387), :session 267}, 627 {:keyword1 96, :keyword3 134, :abstract "We address the classical uniformly related machine scheduling problem, assuming that jobs may choose the machine on which they are processed. In this setting the price of anarchy measures by how much the performance of the system deteriorates due to the lack of central coordination. When jobs seek to minimize their own completion time, the utilitarian social choice function is to minimize the average job completion time. We analyze the price of anarchy for the natural coordination mechanism where jobs are sequenced shortest first per machine. We show upper and lower bounds on the price of anarchy is bounded from below by 1.58 and from above by 2.  This complements recent results on the price of anarchy for the more general unrelated machine scheduling problem by Cole et al. and Correa et al. Moreover, as Nash equilibria correspond one-to-one to SPT schedules, the same bounds hold for the SPT heuristic on uniformly related machines. Thereby, our work also fills a gap in the literature.", :title "Decentralized Scheduling on Related Machines", :keyword2 40, :authors (29289 1019), :session 51}, 629 {:keyword1 34, :keyword3 97, :abstract "We consider the problem of calculating tail loss probabilities and conditional expectations for the Bernoulli mixture model of credit risk. This is an important problem as all credit risk models proposed in literature can be represented as Bernoulli mixture models. Thus, we deviate from the efficient simulation of credit risk literature in that we propose an efficient simulation algorithm for this general Bernoulli mixture model in contrast to previous works that focus on specific credit risk models like CreditRisk+ or CreditMetrics model. The algorithm we propose is a combination of importance sampling based on cross-entropy and inner replications of the geometric shortcut. We evaluate the efficiency of our method considering three different examples: CreditRisk+ and two of the latent variable models, the Gaussian and the t-copula model. Numerical results suggest that the proposed general algorithm is more efficient or has approximately the same efficiency as the benchmark methods for these specific models.", :title "Efficient Simulations for a Bernoulli Mixture Model of Portfolio Credit Risk", :keyword2 93, :authors (19473), :session 216}, 632 {:keyword1 8, :keyword3 86, :abstract "\r\nWe consider three connected resource-constrained optimization problems:  1D bin packing (BPP),  resource-constrained project scheduling (PSP), and  2D strip packing without rotation (SPP). \r\nBPP and PSP are also known as \r\n 1D bar relaxation and  1D contiguous relaxation of SPP.\r\nIt is easy to see that SPP can be relaxed in two different ways down to a PSP:  horizontal and  vertical scheduling relaxation. \r\nIn turn, PSP itself can be relaxed down to BPP, again in two different ways,  horizontal and  vertical 1D relaxation. \r\nWe investigate the quality of these relaxations.", :title "Gaps between optimal values of some packing and scheduling problems", :keyword2 16, :authors (16923 11993), :session 148}, 633 {:keyword1 126, :keyword3 0, :abstract "Software can be distributed closed source (proprietary) or open source (developed collaboratively).  Previous papers have considered firms option to release a software under a closed or open source license as a simple once and for all time binary choice.  We generalize this to a two-stage optimal control model that allows for the possibility of keeping software proprietary for some optimally determined finite time period before making it open source. Both software development paradigms have their advantages.  While a firm might lose revenue from sales of a software, the open source software development process can have substantial impact on the quality of a software, its diffusion and, consequentially, the demand for a complementary product. \r\n\r\nWe will show that for high in-house R&D costs it is always optimal to make the software open source at some point (unless switching itself is too expensive), even if initial quality is high. On the other hand, we will see that when R&D is inexpensive, one would open the source code only for a low initial level of quality. For intermediate R&D costs, a firm might even be indifferent between opening the code immediately, at some optimally determined time and never. We will see that while high switching costs might prevent firms from adopting an open source business model, low switching costs mainly affect the timing of opening the source code.", :title "When to make software open source?", :keyword2 56, :authors (4860 39239 23372 10538 23254 23371), :session 197}, 634 {:keyword1 106, :keyword3 0, :abstract "Despite the growing official pressure to reduce green house gas emissions, there has only been limited research which seeks to reduce emissions as the primary objective of vehicle routing. At first, this contribution presents and analyzes some approaches from literature which introduce “green” formulations for the Vehicle Routing Problem (VRP). Then, a specific objective function referring to sustainability aspects within vehicle routing is proposed. It is assumed that the amount of CO2 emissions depends on the distances to be travelled and on the degree to which the used vehicles are loaded. The goal of minimizing the amount of CO2 emissions produced by a set of vehicles is contrasted with the goal of minimizing the total distance traveled by these vehicles. \r\nThis work includes a mathematical formulation of the problem and a small instance that illustrates the problem. CPLEX is used for solving typical problem instances and to generate routes which are optimal with respect to the objective functions of the above VRP approaches. Lastly, the trade-off between CO2 mini-mization and distance minimization is analyzed.", :title "Emissions Minimization Vehicle Routing Problem: an Approach Subjected to the Weight of Vehicles", :keyword2 78, :authors (23362), :session 85}, 636 {:keyword1 126, :keyword3 0, :abstract "In the present context social interaction means that prevalence influences incidence. To illustrate the propensity on the utility of committing an offense (e.g. of being corrupt) depends on the spreading of criminal behavior in a reference group (e.g. on the fact how 'clean' or 'dirty' the society is). Schelling (1978) pioneered the idea of frequency dependent equilibria in which individual incentives are a function of the aggregate level of corruption.\r\n\r\nIn the present paper we show how such endogenous feedback or social interactions may generate tipping points that separate multiple equilibria involving higher and lower levels of corruption. In particular, the interaction of micro-motives and macrobehavior create threshold behavior and path dependency. Essentially, we use optimal control techniques to explain great heterogeneity in corruption levels accross societies at a given point in time, but persistence over time of both lower and higher levels of corruption. Finally, we refer to several other economic decision processes exhibiting tipping behavior.", :title "Social Interactions and Tipping Points", :keyword2 0, :authors (4860 39239 23372 10538 23254 20910 23371), :session 197}, 638 {:keyword1 73, :keyword3 57, :abstract "Municipal authorities usually face the problem of distributing donated items and funds to needy/indigent residents. The problem has two components; the matching of donations and needs, and the distribution of items. A good matching of donations and needs is crucial for effectively meeting the necessities of the maximum amount of recipients. Optimizing the distribution schedule and routes is also critical for cost-effective utilization of public resources and also for timely satisfaction of the pressing needs of the indigent. In this study, we consider a real-life example of such a problem for a district. The problem is handled in two stages. We first formulate the matching problem as an assignment type model with utility maximization objective. We consider several attributes of donations and recipients for determining the utility of an assignment. The planning period is taken as a working day and there is a single depot of limited capacity for storing the donated items overnight. Previously donated items waiting at the depot or at the donors' are also considered for assignment, as well as daily donations. A fair assignment plan is tried to be achieved at this stage. In the second stage the daily schedule for the pick-up and delivery of items from the donors to the needy residents using a single vehicle is considered. The objective at this stage is to meet the demand of as many needy residents as possible at minimum cost. The priorities and criteria pertaining to the decisions of this stage differ from those of the first stage. The developed approach can be applied to other situations with similar structures.", :title "An Assignment-Based Approach for Distributing Donated Items to Indigent Residents", :keyword2 96, :authors (29389 19095 26811), :session 185}, 640 {:keyword1 80, :keyword3 53, :abstract "In this work we develop a randomized block-coordinate descent method for minimizing the sum of a smooth and a simple nonsmooth block-separable convex function and establish iteration complexity bounds. This extends recent results of Nesterov (Efficiency of coordinate descent methods on huge-scale optimization problems 2010), which cover the smooth case, to composite minimization, while improving the complexity and simplifying the analysis. In the smooth case we allow for arbitrary norms and probability vectors.\r\n\r\nUsing both synthetic and real data, we demonstrate numerically that the method is able to solve various optimization problems with a billion variables. Such problems can be found, for example, in Compressed Sensing (lasso), Statistics (group lasso), Machine Learning (L1-regularized logistic or L2 loss function) and Engineering (truss topology design).\r\n\r\nFor the L1-regularized least squares problem we implement a GPU-accelerated parallel version of our algorithm (CUDA) and observe speedups of up to two orders of magnitude when compared with an efficient serial code (C).\r\n\r\n", :title "Efficiency of Randomized Coordinate Descent Methods on Minimization Problems with a Composite Objective Function", :keyword2 13, :authors (29152 25495), :session 61}, 641 {:keyword1 54, :keyword3 8, :abstract "The classical p-median and weighted p-median problems are basic models for designing optimal structure of most public service systems as medical emergency system, fire-brigade deployment, public administration system design and many others. Application of these tools to design of real-world service system must comply with considerably big number of possible service center locations, which can take the value of several hundreds or thousands. Current exact approaches to the service system design are based on formulating a location-allocation model and solving it by a mathematical programming method. These approaches must face up to big increase of necessary computational time and can fail, when a large system must be designed. In this contribution we make use of the experimentally found fact that large instances of the covering problem are easy to solve by common optimization software. We study here an approximate approach to the p-median problem, which is based on a reformulation of the p-median problem to a case of the covering problem. This approach uses an approximation of a common distance between a service center location and a customer by some of pre-determined distances. The pre-determined distances are given by dividing points, which divide a range of possible distances. Deployment of these dividing points influences the accuracy of the approximation. To improve the covering approach to p-median problem, we have developed a sequential method of the dividing point deployment. An effectiveness of the method is demonstrated on numerical experiments, where the suggested sequential method is compared to the former static method. ", :title "A Sequential Zone Adjustment Method and Approximate Approach to Large p-Median Problems", :keyword2 106, :authors (29393 29390), :session 220}, 642 {:keyword1 14, :keyword3 0, :abstract "Kitahara and Mizuno (2010) get two upper bounds for the number of different basic feasible solutions generated by Dantzig's simplex method.  The size of the bounds highly depends on the ratio between the maximum and the minimum values of all the positive elements of basic feasible solutions.  We show that the ratio for a simple variant of Klee-Minty's LP is equal to the number of iterations by Dantzig's simplex method for solving it.  This implies that it is impossible to get a better upper bound than the ratio. \r\n", :title "Klee-Minty's LP and Dantzig's Simplex Method", :keyword2 78, :authors (29379 29392), :session 196}, 649 {:keyword1 78, :keyword3 85, :abstract "We consider linear programming with interval data. One of the most challenging problems in this topic is to determine or tight approximate the set of all optimal solutions over all perturbations within the given intervals. In general, the problem is intractable, but it becomes easier in some special cases, e.g. under the so called basis stability.\r\nWe will handle the problem in general. We propose an iterative method that finds a guaranteed enclosure for the set of optimal solutions. It is based on a linear approximation and sequential refinement. The method runs in polynomial time, so, naturally, convergence to the ideal set cannot be ensured.", :title "An interval linear programming contractor", :keyword2 94, :authors (12609), :session 196}, 650 {:keyword1 34, :keyword3 35, :abstract "Retail Banks usually apply OLS-based approaches for identifying\r\nthe replication portfolio which helps to manage their non-maturing\r\nsavings accounts. OLS-based client rate models used for the replication\r\nportfolios do not take into account neither the rigidity nor the\r\nasymmetry the banks follow when they adjust their client rates accordingly\r\nto the observed market rates dynamics. This is insofar surprising,\r\nas the asymmetric client rate adjustment forms the basis for pricing\r\nthe imbedded withdrawal options of the client rates. In this work we\r\ncontribute to the elimination of these inconsistencies: based on Swiss\r\nNational Bank (SNB) data we investigate models in error correction\r\nform, two threshold models complementing each other and a friction\r\nmodel for characterizing the dynamics of the client rate. In\r\naddition to the client rate models we introduce a volume model in autoregressive\r\nform that gives us an insight into the seasonality pattern of\r\nvolumes dynamics and that allows for forecasting the savings volumes\r\nwith respect to the markets rates. Finally, we apply a vector autoregressive\r\napproach for analyzing the behavior of the Swiss depositors\r\nwith respect to the macroeconomic factors Swiss Bond Index, Swiss\r\nPerformance Index, M1 and Consumer Price Index.", :title "Modeling client rates and volumes of the Swiss savings accounts", :keyword2 37, :authors (29385), :session 269}, 652 {:keyword1 8, :keyword3 95, :abstract "We introduce a new algorithm in the context of column generation to handle large scale optimization problems called two-stage column generation. \r\nIn two-stage column generation, variables of the so called compact and extensive formulations are generated simultaneously.  \r\nThe new algorithm is specifically conceived for tackling complex problems that cannot be efficiently solved by standard column generation and exploits the relationship between compact and extensive \r\nformulation.  \r\nRecently, different techniques have been explored to accelerate column generation. Namely, stabilization  dynamic constraint aggregation and variable elimination. All the mentioned techniques confirm that good dual information is crucial to enhance column generation schemes.  \r\nTwo-stage column generation makes use of the concept of extensive reduced cost. It is used to compute an estimate to the contribution of compact formulation variables to the master problem.  \r\nAn illustration based on the Resource Constrained Shortest Path Problem is solved with two-stage column generation when the pricing subproblem satisfies or not the integrality property.  \r\nWe provide extensive computational experiments on the Discrete Split \r\nDelivery Vehicle Routing Problem to validate our framework.  \r\nTwo-stage column generation reduces the number \r\nof generated columns and the computational time for complex instances.  \r\nFinally, we provide future research directions of the application of two-stage to complex combinatorial problems arising in port management.", :title "Two-stage column generation and applications", :keyword2 77, :authors (14144 19625 26236), :session 210}, 653 {:keyword1 8, :keyword3 0, :abstract "We consider a generalization of the unsplittable maximum two-commodity\r\nflow problem on undirected graphs where each commodity i can be split into a\r\nbounded number k_i of equally-sized chunks that can be routed on different paths. We show that in contrast to the single-commodity case this problem is NP-hard. We present a polynomial time 1/2-approximation algorithm for the case of uniform chunk size over both commodities and show that for even k_i and a mild cut condition it can be modified to yield an exact method. The uniform case can be used to derive a 1/4-approximation for the maximum concurrent (k1,k2 )-splittable flow without chunk size restrictions for special demand ratios.\r\n", :title "A polynomial time approximation algorithm for the two-commodity splittable flow problem ", :keyword2 10, :authors (24021 16928), :session 206}, 655 {:keyword1 67, :keyword3 13, :abstract "The Growth Optimal Portfolio (GOP), which provides the maximal achievable long-term growth rate within a given set of assets, is very appealing not only due to its performance potential but also to other attractive features. However, on a finite time horizon the GOP is exposed to significant risk. Therefore, it is natural to combine the approach with a protection strategy what results in the Growth Optimal Portfolio Insurance. There exist many solutions for this problem in continuous time. However, inclusion of the dynamic VaR and CVaR constraints leads to complicated continuous time models with internal discretization, which hinders an intuitive understanding.\r\nOur contribution to the solution of the Growth Optimal Insurance problem is twofold. Firstly, using the convex duality methods and relationship between options pricing and portfolio protection, we obtain an elegant and intuitive closed form solution for the optimal fraction of investment in the GOP. The solution also holds for the insurance of portfolios with constant rebalancing weights. Secondly, we show that the well-known CPPI rule not only gives an upper bound for the optimal fraction in discrete time, but also allows to handle dynamic risk measures such as VaR and CVaR. Based on this we develop a new protection strategy in discrete time as a mixture of the Growth Optimal Insurance in continuous time and the CPPI rule. \r\nSince proposed strategy is a mapping from the current portfolio value to the optimal investment proportion, we generalize this approach by introducing the class of empiric decision rules approximated by monotone cubic interpolation.\r\nSimulations clarify new strategies characteristics and their performance.\r\n", :title "Growth Optimal Portfolio Insurance in Continuous and Discrete Time", :keyword2 93, :authors (29247 14810), :session 217}, 656 {:keyword1 106, :keyword3 0, :abstract "In vehicle routing problems routes are compiled from a given portfolio of requests and it is assumed that the complete portfolio is known before the route compilation is initiated. The decision situation becomes more complicated if these assumptions are not valid anymore. In practical applications, the set of requests to be served is often only partially known and not all proposed requests can be considered during the route compilation because of limited capacity or unprofitability. Re-planning is applied if routes are already fixed but additional requests are proposed. Within this contribution, we investigate the situation of a freight carrier that consecutively receives a sequence of request proposals from different customers. This carrier has to decide reactively if it wants to fulfill a request proposal and how the existing routes are re-arranged in case that the request proposal has been accepted. We present a mathematical decision model for this dynamic decision problem and present initial results from computational simulation experiments.", :title "Integration of request acceptance and route compilation in dynamic vehicle routing", :keyword2 0, :authors (15277), :session 84}, 658 {:keyword1 92, :keyword3 97, :abstract "Recently literature has shown that sorting used goods before remanufacturing has massive impacts on reverse supply chains. This talk explores the influence of an uncertain quality grading process on the supply chain performance. Furthermore interdependencies between acquisition, grading and production disposition decisions are investigated.\r\n\r\nWe consider a situation where demand for used but remanufactured products must be fulfilled. After acquisition an optional inaccurate grading/test process with test costs can evaluate the product functions for each item and function. Based on this quality estimation a disposition decision is made whether the function has to be repaired or not. With some probability grading errors occur and the wrong disposition decision is made. Tested functions in a good condition will not be repaired whereas non-tested functions and functions in a bad condition must be repaired in any case. Repair causes fixed costs plus variable costs which depend on function quality. \r\n\r\nWrong disposition results in higher costs, so a trade-off between test costs, uncertain yield and limited capacity must be taken into account. Budget-constrained investments in testing equipment can help the (risk-averse) remanufacturer to reduce this uncertainty.\r\n\r\nDue to the highly uncertain structure and complexity of the model a simulation-based approach with different strategies is used to study the interaction and interdependencies of used product acquisition, quality grading and remanufacturing decisions.", :title "Acquisition, sorting and disposition of used goods for remanufacturing under uncertain quality grading", :keyword2 101, :authors (29397 9703), :session 168}, 659 {:keyword1 8, :keyword3 42, :abstract "The quadratic assignment problem (QAP) is one of the most important problems in the field of discrete optimization. The problem can be a mathematical model for a lot of real-world problems such as hospital and campus layout, backboard wiring problem, workshop designing and so on. Travel salesman problem, graph vertices enumeration problem and some others are special cases of the QAP. Since the QAP is NP-hard problem, both developing polynomial exact algorithms for special cases and building effective algorithms for more common ones are important. We consider the problem in terms of graphs, i.e. weighted graph represents a structure of connections between objects and network represents positions where objects should be placed in. The objective is to compute a permutation of the graph vertices on the network nodes so that a sum of the connections costs is minimized. We provide parallel dynamic programming algorithm for the QAP on non-weighted trees and decomposition algorithm for the QAP on networks. We analyze numerical results of solving the problem on different types of networks using these algorithms and consider how running time depends on a number of used threads. Memory growth rate analysis is provided. We also solve the problem using IBM ILOG CPLEX Optimization Studio toolkit and compare these results with ones obtained by mentioned algorithms.", :title "Some Algorithms for The Quadratic Assignment Problem on Networks", :keyword2 33, :authors (24983 23719), :session 204}, 661 {:keyword1 63, :keyword3 10, :abstract "In practice, one often faces several contradicting objectives for an optimization problem, like cost and duration. In Multicriteria Optimization the notion of Pareto optimality was introduced: A solution is called Pareto optimal if it is impossible to improve one objective without worsening another. However, the number of such solutions is often exponential. To identify a single Pareto optimal solution, one considers the weighted sum of all objectives to get a single-objective problem. This can lead to highly unbalanced solutions, though, even if perfectly balanced solutions exist. To overcome this problem, in the 70s Yu et al. proposed Compromise Solutions as an alternative.\r\nHere, the ideal point is defined as an imaginary solution that takes the optimal value in each objective. A Compromise Solution is a feasible solution that minimizes the distance to this ideal point with respect to some norm. We consider the standard vector norms as well as a parametrized combination of the Manhattan and the maximum norm. For the maximum norm, Compromise Solutions are equivalent to regret-robust solutions.\r\nCompromise Solutions have the advantage that typically there is only one of them, and they are always Pareto optimal (except for the maximum norm).\r\nWe show that for a fixed, polynomially sized norm parameter any Pareto optimal solution also is a Compromise Solution. Furthermore, an approximation scheme for Compromise Solutions enables us to approximate the Pareto set, by choosing different weights for the objectives. Compromise Solutions thus neatly fit into the popular concept of Pareto optimality.\r\nMoreover, if good balanced solutions exist, they can be obtained by computing a Compromise Solution. The degree of balancing can be influenced by the choice of the norm parameter.", :title "Compromise Solutions", :keyword2 8, :authors (29288 26508 17092), :session 202}, 663 {:keyword1 25, :keyword3 29, :abstract "The purpose of the paper is to investigate a regulated company’s investment choices if it faces a cost-based regulation and in addition to that, when growth opportunities exist. \r\n\t\r\nIn network industries like telecommunications or electricity, a regulated company’s investment decisions are affected by the actual regulatory instruments in place. It has been shown in previous research that the widely used cost-based remuneration can cause underinvestment from the regulator’s perspective. \r\n\t\r\nHowever, the existing literature does not cover all important aspects of such an investment decision. Especially in widely publicly discussed areas like investments in broadband technology or in smart grids, investment decisions are not static one-time decisions, but the companies will rather invest sequentially: Having gained experience with pilot projects, they will make subsequent investments in later periods. \r\n\t\r\nIt has not been investigated yet how the existing regulation affects investment incentives, if companies structure their investments as described. This paper will contribute to the existing literature by filling this gap. For the analysis, a theoretical model will be used which describes both the company’s and the regulator’s investment decisions. They will be modeled as discrete-time decisions and solved analytically. It is expected that the results will differ substantially from the one-time-investment reference case, since growth options are opened up by the initial investment choice. Different depreciation rules and their influence will be assessed. Furthermore, different product market structures will be analyzed, in particular a monopoly, oligopoly and perfect competition scenario.\r\n", :title "Analysis of Investment Incentives and the Influence of Growth Options in Regulated Industries", :keyword2 104, :authors (29400), :session 105}, 664 {:keyword1 59, :keyword3 7, :abstract "In the process industry it might be neccessary to simultaneously determine lotsizes and sequences for several production stages due to sequence dependent setups. In this article a new heuristic is proposed which is based on the principles of Variable Neighborhood Decomposition Search (VNDS) and Fix&Optimize. The idea is to combine decompositions for the Fix&Optimize heuristic with the Variable Neighborhood Search. Our procedure allows (in general) to solve MIP models for multi-level lot-sizing and scheduling problems as outlined above. In order to demonstrate the strength of our\r\nprocedure the GLSPMS model is chosen as a representative. This model is supposed to be one of the most realistic one, but no adequate solution procedure is known so far due to its complexity.", :title "Combining the principles of Variable Neighborhood Decomposition Search and Fix & Optimize heuristic to solve multi-level lot-sizing and scheduling problems", :keyword2 75, :authors (15324), :session 161}, 666 {:keyword1 85, :keyword3 97, :abstract "Many economic applications lead (from the mathematical point of view) to deterministic optimization problems depending on a probability measure. Since this measure is there often completely unknown, a solution has to be usually determined on the data basis. Many efforts has been paid to the investigation of the corresponding statistical estimates of an optimal value and optimal solutions. It was mostly done for \"classical\" problems\r\nand the \"underlying\" distribution with \"thin\" tails. In the talk we plan first to recall the main results based on a moment generating function, it means to the results that correspond to the \"underlying\" distribution with thin tails. However we focus mainly to the case of \"heavy\" tails, that just correspond to application in economy and finance. In particular, we try to introduce a relationship between consistency, convergence rate, empirical processes (corresponding to empirical estimates of the optimal\r\nvalue and the optimal solutions) and an existence of finite moments. To this end we employ stability results based on the Wasserstein metric corresponding to L_1 norm. Demonstration based on simulation technique will complete our investigation.\r\n", :title "Heavy Tails via Stochastic Optimization Problems", :keyword2 99, :authors (8650 29401), :session 118}, 669 {:keyword1 106, :keyword3 0, :abstract "Traffic congestion and environmental pollution in inner cities lead to a massive increase of interest in innovative non-polluting public transport. In this course, many cities established bike sharing systems in order to expand their local public transport. In most of the rack-bound bike sharing systems, it is possible to return a borrowed bike at an arbitrary station in the system which leads to imbalances in the spatial distribution of bikes. System operators must counteract these imbalances in order to ensure that a sufficient number of free bikes and free racks are available for satisfying customer demands. The most important countermeasure is relocation of free bikes by means of service vehicles at regular time intervals. However, operating service vehicles tends to be cost-intensive. Thus, the service vehicles must be routed efficiently in order to reduce transportation costs while satisfying customer demands. Customer demands in terms of bike requests and bike returns are considered as a stochastic influence that should be anticipated when making new routing decisions. \r\nThe resulting problem is a complex dynamic and stochastic vehicle routing problem with limited service vehicle capacities. In this contribution, we first illustrate the problem of dynamic bike relocation by means of real-world data from the rack-bound bike sharing system in the city of Vienna. We then model the problem as a Markov decision process and present a simulation approach for approximate solution of the problem.\r\n", :title "Dynamic bike relocation for rack-bound bike sharing systems", :keyword2 0, :authors (29348 13264 12952), :session 84}, 671 {:keyword1 76, :keyword3 93, :abstract "The usual optimization criteria examined in the literature on stochastic\r\ndynamic programming, such as a total discounted or mean (average) reward  \r\nstructures, may be quite insufficient to characterize the problem from \r\nthe point of a decision maker. To this end it may be preferable if not \r\nnecessary to select more sophisticated criteria that also reflect the \r\nvariability-risk features of the problem. Perhaps the best known approaches stem from the classical work of Markowitz on mean variance\r\nselection rules. On the other hand risky decisions can be also eliminated  when expectation of the stream of one stage rewards (or costs) is evaluated by an exponential utility function. Recall that exponential utility functions are separable and hence suitable for sequential decisions. This contribution is devoted to the risk-sensitive optimality\r\ncriteria in finite state Markov Decision Processes, i.e., when expectation \r\nof the stream of one-stage rewards (or costs) generated by a Markov chain,\r\nis evaluated by an exponential utility function, i.e. utility function \r\nwith constant risk sensitivity. Explicit formulae for the growth rates of \r\nthe expected utility as well as for mean value of the certainty equivalent \r\nalong with algorithmic procedures for finding maximal growth rate will be \r\ngiven, and necessary and sufficient optimality conditions will be discussed.\r\n\r\n", :title "Risk-Sensitive Average Optimality in Markov Decision Processes", :keyword2 99, :authors (10023), :session 115}, 673 {:keyword1 63, :keyword3 0, :abstract "In this paper we present a problem based on a manufacturing facility of an Austrian food producer where the packaging section is of our main interest. In a multi-product parallel machine environment with sequence-dependent setup times, decisions regarding lot sizing, lot sequencing and line and workforce assignments have to be made. Besides the objective of cost minimization in the respective planning horizon, the paper considers a second objective function that aims to balance workforce requirements within a planning period and, therefore, minimizes the amount of workforce idle time. Obtaining the optimal front of solutions for this type of bi-objective and NP-hard problem in reasonable time using classical optimization algorithms is extremely difficult. Therefore, this paper proposes a hybrid method based on a multi-objective evolutionary algorithm (MOEA) where the combinatorial part, including lot sequencing, line and workforce assignment, is separated from discrete optimization (lot sizing). \r\nOur MOEA is based on the NSGA-II and will be applied to handle the combinatorial part using a specific chromosome coding scheme and adapted operators. Thereafter, an integer linear programming solver will be used in each generation to decide about the lot sizes based on the genotype of each individual. The hybrid algorithm will be tested on generated instances of different size and will be compared to an epsilon constraint method using a diverse set of performance metrics for multi-objective optimization. \r\n\r\n", :title "A hybrid evolutionary algorithm for multi-objective simultaneous lot sizing, lot sequencing and workforce assignment on parallel machines", :keyword2 59, :authors (29406 2044), :session 159}, 675 {:keyword1 63, :keyword3 106, :abstract "Optimization of traffic network performance using dynamic traffic management (DTM) measures is a specific example of a network design problem. Decision variables are the DTM measures with specific settings or scenario’s. Objectives are network efficiency and various externalities of traffic, which are determined using a dynamic network assignment model. This results in a dynamic multi objective network design problem (DMONDP), which is solved as a bi-level optimization problem using the non-dominated sorting genetic algorithm II (NSGAII) and results in a Pareto optimal set. This set provides valuable information for the decision making process, e.g. trade offs between objectives, which would not have been available if the compensation principle would have been chosen (i.e. solving a single objective NDP with a weighted sum of all objectives). This optimization problem is NP-Hard and the evaluation of one solution is generally computationally expensive. Knowledge obtained by optimization of realistic cases can possibly be used to improve or accelerate the optimization procedure. However, the Pareto optimal set can become large, especially when the objectives are mainly opposed. As a consequence the Pareto optimal set may become difficult to analyze and to comprehend. In this case pruning and ranking to reduce the Pareto optimal set and to rank the solutions to assist the decision maker may become useful. These methods may influence the eventual decisions taken, so it is of importance to determine what method corresponds best with the underlying decision process and is in accordance with the qualities of the data used. In our research we assess different methods in a case study for a realistic network of the city Almelo in the Netherlands.", :title "Decision support by pruning and ranking the pareto optimal set", :keyword2 65, :authors (27449 28419 9109), :session 256}, 678 {:keyword1 106, :keyword3 0, :abstract "Container terminals are constantly seeking new ways to increase their transshipment and storage capacity to keep up with the growth in volume of containers to be handled. The stack is one of the areas in a container terminal that is highly affected. The design of the yard should be selected carefully to ensure an efficient interface with all other processes in the terminal and to make sure that turn-around times of both sea-going vessels and trucks is minimized. Yard design issues include selecting the equipment to handle containers, determining the layout of the yard, and defining the appropriate methods to sequence requests and assign them to cranes. We discuss two-crane technologies and focus on control issues. We present both a model and solution approach to schedule storages and retrievals in a stack with two automated stacking cranes working in a single block. Numerical results are shown to demonstrate the performance of the methods proposed.", :title "Sequencing New Types of Stacking Crane Configurations", :keyword2 33, :authors (9647 19846), :session 92}, 680 {:keyword1 67, :keyword3 126, :abstract "In recent years papers departing from standard discounting have received an increasing attention introducing non--constant time preferences. Some of these works have focused on the characterization of time consistent solutions overcoming the time inconsistency problem associated to the use of  standard optimal control techniques. In particular, Marín-Solano and Navas (2010) studied how time-inconsistent preferences modify the classical optimal consumption and portfolio Merton's model. On the other hand, related with this asset allocation framework, Josa-Fombellida and Rincón-Zapatero (2004) analyzed the optimal management of a defined benefit pension plan using the dynamic programming approach.\r\n\r\nIn this paper we depart from these previous works and explore how the introduction of time-inconsistent preferences for the promoter of the plan will affect the optimal decision rules in the context of a stochastic defined benefit plan being the objective of the sponsor to minimize the contribution rate risk and the solvency risk on a infinite planning horizon.\r\n\r\nReferences:\r\n\r\nJosa-Fombellida, R., Rincón-Zapatero, J.P., 2004. Optimal risk management in defined benefit stochastic pension funds. Insurance: Mathematics and Economics 34, 489-503.\r\n\r\nMarín-Solano, J., Navas, J., 2010. Consumption and portfolio rules for time-inconsistent investors. European Journal of Operational Research 201, 860-872.", :title "Time consistent optimal stochastic pension funding", :keyword2 99, :authors (23383 22949), :session 265}, 686 {:keyword1 106, :keyword3 0, :abstract "In public bus transport usually most trips of a timetable are serviced every day (in general more than 90%). Just a small amount of trips is irregular, i.e. is not serviced daily (e.g. extra trips to schools). But this small amount of irregular trips has a large impact when the corresponding vehicle and crew scheduling problems are solved at minimum costs by optimization tools: schedules produced for one day may completely differ from schedules for another day. As most companies prefer both cost efficient and similar schedules, we propose scheduling approaches that also consider similarity.\r\nIn this contribution we discuss two different approaches to increase the similarity in sequential and in partial integrated vehicle and crew scheduling: The first approach uses a common reference schedule. The scheduling problems of various days are solved separated from each other while the similarity is ensured by creating schedules with a small distance to the reference. The second approach tackles the scheduling problems of various days simultaneously while similarity is ensured with the help of regular patterns. In the corresponding MIP formulation patterns are included as variables. The models are solved with a column generation approach. In sequential planning we mainly increase the similarity in the vehicle scheduling stage while in partial integrated planning we focus on the crew scheduling stage to increase the similarity. Computational results show that the proposed approaches are suitable to build both cost efficient and similar schedules.", :title "Sequential and partial integrated vehicle and crew scheduling with various timetables - increasing the similarity of resource schedules in public transport", :keyword2 96, :authors (17597 23738 1194), :session 187}, 687 {:keyword1 91, :keyword3 0, :abstract "We investigate the value of coordinating static pricing and revenue management availability decisions under price-sensitive demand uncertainty. We first characterize a general class of stochastic, price-dependent demand models; these lead to several static pricing and revenue management models that can be solved efficiently and admit unique solutions with intuitive sensitivity properties. We then compare the performance of various hierarchical and coordinated models, shedding light on the value of coordinating price and availability decisions as well as of modeling demand uncertainty and resource substitution in pricing and revenue management. Our numerical insights, which are based on industry data, suggest that capturing price-sensitive demand uncertainty in a hierarchical revenue management process can yield significant revenue benefits and thereby achieve most of the potential of a fully coordinated process.", :title "Pricing and Revenue Management with Stochastic Demand ", :keyword2 2, :authors (29412 9392 2678), :session 101}, 690 {:keyword1 134, :keyword3 44, :abstract "Negotiations are often conducted in highly polarized environments, which are also uncertain and dynamic. However, the intense rivalry involved in these conflicts does not always prevent an agreement from being reached. A recently proposed static model sets out the conditions under which either an agreement is achieved or negotiations break down in this environment (Laengle and Loyola, Optim Lett, 2011, in press). Nevertheless, important aspects related to partial mutual knowledge of players in a dynamic context are not yet been studied. To fill this gap, we develop an extension of the static game to modelling highly polarized conflicts in an uncertain, asymmetric and dynamic environment. In this extension both parties bargain multiple negotiation rounds under uncertain threats that are materialised only if an agreement is not reached. If a negotiation breakdown occurs, each party learns about these threats from the outcome observed in the previous round. This paper presents the most important results, and a short discussion about possible applications. In particular, we provide the conditions that characterise different paths for negotiations held under polarized environments, which matches the observed evolution of many of these conflicts in the real world.", :title "Learning in Highly Polarized Conflicts", :keyword2 40, :authors (26217 29415), :session 139}, 691 {:keyword1 16, :keyword3 96, :abstract "In this study, we propose a general model for a sequential two-dimensional packing problem which may have direct applications in wireless telecommunications area. The dimensions correspond to time durations and frequencies used in wireless data transfer, analogous respectively to width and height. The shape of the packed items are restricted to rectangular blocks where the area of each represents the amount of data to be transferred from a base station to a fixed or mobile network service user station. These blocks are placed in identical rectangle bins called frames which characterize the resource capacity of the base station per unit time. Same amount of user demand can be represented by different width-height combinations, hence the shape of the rectangles depend on the objective of the problem, like minimum power consumption or maximum bandwidth usage. Most studies in the area aim to maximize the packing performance of a single frame employing strip packing techniques assuming same user demand levels per frame. However, satisfying service constraints as minimum transmission rate or maximum allowable delay is difficult in a dynamic environment. We consider a planning horizon composed of a sequence of frames for partially packing user demands. Thus allowing varying demand sizes for each user, we aim to solve multiple packing problems integrated with service level constraints. We also discuss some special cases of our model pertaining to other application areas such as scheduling of storage areas or purchasing payments.", :title "A Sequential Rectangular Packing Approach for a Resource Allocation Problem", :keyword2 104, :authors (19221 24799), :session 147}, 692 {:keyword1 86, :keyword3 78, :abstract "In this paper, we present lower bounds for a particular case of the Multi-Skill Project Scheduling Problem (MSPSP).\r\n\r\nThe main difference between our problem and the classical MSPSP is that we define a preemption by task, we have to find one person per task/skill and  the skills for  same task may have different durations. We also have a synchronization constraint which mean that skills of the same task must be started at the same time, but in case of preemption can be resumed independently.\r\n\r\nThis work is an enhancement of the lower bounds presented at ROADEF 2011. These lower bounds are an adaptation of the energetic reasoning and a linear model based on a discretization of the time horizon into successive intervals.\r\n\r\nThe main contributions consist in adding  time-window adjustments and a shaving procedure to the energetic lower bound. Moreover In order to strengthen the linear model we also add clique constraints.\r\n\r\nAdjusting a time-window for a non-preemptive task is done by computing the maximum workload that can be done by each necessary skill after processing all mandatory parts of all other tasks. This workload can be computed by solving a minimum cost  assignment problem. In this problem, the cost of  the ongoing/outgoing arcs, for each person who masters the skill is  greater than 0, and 0 otherwise. Thus, the searched workload is the difference between the availability of those persons on the considered interval and the  total work done by them in this assignment problem.\r\n\r\nThis workload is then compared to the minimum part that must be processed in the considered interval,     in case of starting the task at its release date  or ending  at its due date. Then, we right(left) shift release date (due date) if the work is less than the minimum part.\r\n\r\nThe clique constraints are essentially based on the disjunction relations between tasks; due to both precedence and resources constraints.\r\n\r\nWe have conducted a computational test on adapted instances from the PSPLIB benchmark.", :title "Lower Bounds for an industrial Multi-Skill Project Scheduling Problem (MSPSP)", :keyword2 96, :authors (29151 29420 11001 24802), :session 64}, 693 {:keyword1 106, :keyword3 74, :abstract "We propose a framework for the optimization of Stochastic Vehicle Routing Problems based on GPGPU and Monte Carlo Sampling. With our framework we make use of the computational capabilities of modern graphics cards. More in detail, solutions are approximately evaluated using Monte Carlo Sampling and this evaluation is parallelized on a sample level. That means the computational task that is performed in parallel is the evaluation of one solution on a single sample. This allows for a very efficient usage of graphics cards.\r\nAdditionally, we give experimental evidence for the efficiency of the proposed framework. For this purpose we adapt state-of-the-art metaheuristics for the Probabilistic Traveling Salesman Problem with Deadlines for usage in our framework. Note that those heuristics are already using Monte Carlo Sampling for the evaluation of solutions. Therefore only minor modifications were necessary to be able to use the framework. The new heuristics have been tested on common benchmark instances. For most of those instances the computational time could be reduced by an order of magnitude compared to former state-of-the-art heuristics, while solutions of competitive quality were obtained. Our results clearly reveal the potential of the proposed framework for Stochastic Vehicle Routing Problems.", :title "Solving Stochastic Vehicle Routing Problems using GPGPU", :keyword2 59, :authors (17336 518 22740), :session 247}, 695 {:keyword1 85, :keyword3 80, :abstract "The production planning problem aims to fulfill production and sourcing decisions so as to meet customer demand subject to production capacity, workforce availability and inventory restrictions and is inherently an optimization problem. The goal in production planning is to meet customer demand over a ?xed time horizon divided into planning periods by optimizing the trade-off between economic objectives such as production cost and customer satisfaction level . The major decisions are production and inventory levels for each product and the number of workforce in each planning period. In this paper we consider the management of small scale traditional business at North Sumatera Province which performs processing fish into several local seafood products. The inherent uncertainty of data (e.g. demand, fish availability), together with the sequential evolution of data over time leads the production planning problem to a nonlinear mixed-integer stochastic programming model. We use scenario generation based approach and feasible neighborhood search  for solving the model. The results which show the amount of each fish processed product and the number of workforce needed in each horizon planning are presented.", :title "A Nonlinear Mixed Integer Stochastic Programming Model for Solving  Fish Processed Production Planning Problem", :keyword2 75, :authors (25214), :session 121}, 697 {:keyword1 66, :keyword3 0, :abstract "A general classification scheme of necessary and sufficient criteria for the local error bound property will be presented. Several derivative-like objects from the primal as well as the dual space are used to characterize the error bound property of extended-real-valued functions.\r\n\r\nThe details can be found in\r\n\r\nM. Fabian, R. Henrion, A. Kruger, J. Outrata, Error bounds: necessary and sufficient conditions, Set-Valued and Variational Analysis, 18 (2010), no. 2, 121-149.", :title "Error bounds: necessary and sufficient conditions", :keyword2 108, :authors (9547), :session 55}, 698 {:keyword1 54, :keyword3 57, :abstract "In the (r|p)-centroid problem two players, leader and follower, open facilities to service clients. We assume that clients are on Euclidian plane and facilities can be opened in arbitrary points on the plane. Leader opens p facilities. Later on, follower opens r facilities. Each client patronizes the closest facility. Our goal is to find p facilities for the leader to maximize his market share. For this Stakelberg game we develop a new alternating heuristic, based on the exact approach for the follower problem. In each iteration of the heuristic we consider the solution of one player and calculate the best answer for the second player. At the final stage, the clients are clustered and an exact polynomial time algorithm for the (1|1)-centroid problem is applied to compute the most strong position for the leader facilities. Computational experiments show that this heuristic dominates the previous alternating heuristic of Bhadury, Eiselt, Jaramillo.\r\n", :title "New alternating heuristic for the (r|p)-centroid problem on plane", :keyword2 8, :authors (29418 4607 3190), :session 220}, 701 {:keyword1 41, :keyword3 127, :abstract "We present a new way to solve principal agent problems by polynomial programming techniques. We study the case where the agent's action is unknown and the space of outcomes is a finite set. All functions are assumed to be polynomials or rational functions. The resulting problem is a bilevel optimization problem with the principal's problem as the upper and the agent's problem as the lower level. The key idea is to find an exact reformulation of the agent's problem as a semidefinite optimization problem. Since this is a convex optimization problem, we then have necessary and sufficient global optimality conditions for the agent's problem. This reformulation can be done by using a classical result from real algebraic geometry linking positive polynomials and semidefinite matrices. We obtain a polynomial optimization problem which we then solve by the moment relaxation approach.", :title "Solving Principal Agent Problems by Polynomial Programming", :keyword2 40, :authors (29322 29300), :session 38}, 703 {:keyword1 17, :keyword3 0, :abstract "This paper addresses an application of DEA to media selection based on an empirical data.We present a simple non-parametric approach to an optimization problem in the stochastic frontier model with unknown functional form of the frontier based on DEA. Though much effort has been done on determining advertising-response curvbes to employ the parametric approach to media selection,there is little conclusive\r\nevidence so as to the shape of these curves. We had shown that for an optimization problem in stochastic frontier model with implicitly a Cobb-Douglas or \r\nnon Cobb-Douglas form, in either case an optimum solution to the data envelopment approximation model(DEAM) is sufficiently close to that of the original problem in either case by Monte Carlo simulation.\r\nIt is also shown that,in the problem with an implicitly non-Cobb-Douglas form DEAM outperforms the parametric approach in which it is required to specify the functional form. \r\nWe shall provide an application of DEAM to the problem of finding the “best practice” combination of media within each media type(TV, newspapers, magazines and radio) in which an advertising campaign is scheduled \r\nso as to maxmize some criterion (awareness value, knowledge level and so on) on the basis of advertising budget. We also provide the limitation of this method and areas for future research.", :title "Media Selection planning by data envelopment analysis approach", :keyword2 0, :authors (14775 26672), :session 259}, 708 {:keyword1 16, :keyword3 0, :abstract "An important task in physical distribution is the loading of goods (items) on carriers like pallets or containers for transportation. With appropriate planning and the use of optimization methods, the number of required loading carriers can be minimized resulting in savings regarding shipping space, charging time and costs. Moreover, the automation of the loading task reduces personal costs both for planning and for performing the actual packing.\r\n\r\nIn this contribution we concentrate on the constraints required from real world applications which are frequently neglected by three-dimensional packing algorithms. First of all we take into account the stability of every item in the packing. Stability depends on the area of support, which may consist of several, possibly unconnected areas of items at a lower level in the packing. Furthermore, we have to observe load bearing strength to avoid damaging loaded items. Finally, it must be possible to realize the packing by mechanical loading systems like robots or palletizers with limited spatial access possibilities. We develop a new theoretic approach for this last aspect which has hardly been treated in the literature before.\r\n\r\nTo solve the resulting optimization problem, a combination of a constructive heuristic and a permutation-based genetic algorithm is proposed. The constructive procedure calculates loading patterns consisting of spatial positions and orientations of all loaded items based on a given sequence of items. The item sequences are determined and altered by the genetic algorithm, aiming for a continuous improvement of the quality of the solution.\r\n\r\nThis project was conducted in cooperation with a German logistics company. Extensive tests on real-world data show highly favourable results.", :title "Solving a Three-Dimensional Packing Problem with Real-World Constraints", :keyword2 8, :authors (12695 16855), :session 172}, 710 {:keyword1 96, :keyword3 136, :abstract "Inland waterways form a natural network that is an existing, congestion free infrastructure with capacity for more traffic. The European commission promotes the transportation of goods by ship as it is a reliable, efficient and environmental friendly way of transport. The presence of locks, however, form a bottleneck for transportation over water. The lockmaster's problem studies the problem of finding an optimal strategy for operating a lock. In the lockmaster's problem we are given a lock, a set of ships coming from downstream, wanting to go upstream, and another set of ships coming from upstream, wanting to go downstream. We are given the arrival times of the ships and a constant lockage time; the goal is to minimize total waiting time (i.e., total flow time) of the ships. We show how this problem is related to batch scheduling problems with job compatibilities. A dynamic programming algorithm is proposed that solves the lockmaster's problem in polynomial time. Extensions of the problem considering weights, water usage, capacity, and a constant number of identical chambers are also shown to be solvable in polynomial time. Finally, we show that a problem where the number of chambers is part of the input is strongly NP-hard.", :title "The Lockmaster's Problem", :keyword2 106, :authors (6251 16156 23268), :session 141}, 711 {:keyword1 75, :keyword3 48, :abstract "This study proposes a mixed-integer linear programming model to solve the synchronized two-stage lot sizing and scheduling problem with setup times and costs. The main motivation behind this study is based on the need of improvement in the inventory control and management system of a supplier that serves to automotive industry.  The supplier considered in this study has synchronized two-stage production system which involves three parallel injection machines in the first stage and a single spray dying station in the second stage. In order to achieve synchronization of the production between these stages and improve the inventory levels, a mixed-integer linear programming model is proposed. The developed model is coded in GAMS and solved by using CPLEX 12.0 solver on a real life automotive supplier’s synchronized two-stage lot sizing and scheduling problem. By the help of developed model, synchronization between the parallel injection machines and the single spray dying station with minimum total cost is obtained. Optimal lot sizes for each stage and optimal schedules of these lot sizes are determined by the developed model as well. ", :title "Synchronized Two-Stage Lot Sizing and Scheduling Problem in Automotive Industry", :keyword2 96, :authors (2220 22992), :session 144}, 716 {:keyword1 7, :keyword3 80, :abstract "This talk investigates a multi product Newsvendor-problem with two limited capacity sources (speculative, reactive). Under uncertain demand the manufacturer has to decide the production strategies (speculative, reactive, dual or no production) and the produced quantities for each product. Until now only models governed by one limited capacity are known in literature. In these models the production scenarios are determined over boundaries for the single shadow price. The boundaries are given by scalar values under two limited capacity sources. Two interdependent shadow prices have to be determined for finding an optimal portfolio of production. Therefore the production strategies are no longer given by scalar boundaries. We get two-dimensional 'production fields' depending on both shadow prices. The 'production fields' in the shadow-price-space are transformed to a capacity depending space, that is more significant in finding the solution. The capacity-depending mapping, which is in fact a 'solution-map', shows a non-trivial effect: With decreasing level of one capacity, while the other one is kept constant, a back-and-forth switch between production strategies occurs. The origin of this effect can be found in the interaction of the two capacity sources. Due to the special structure of the problem variational inequalities (namely a Nonlinear Complementarity Problem or NCP) are used to solve the Multi product Newsvendor with multiple limited capacity sources.\r\n", :title "Multi product Newsvendor-problem, solution with NCP and a non-trivial effect", :keyword2 19, :authors (29114 9703), :session 256}, 717 {:keyword1 45, :keyword3 95, :abstract "The service sector in Europe expanded rapidly within the last 40 years.\r\nAlso the demand for home health care grew. But as the number of nurses\r\nand clients grow, it becomes more and more difficult to create staff\r\nrosters and daily tours fitting to all constraints given. Within this\r\npresentation we consider the nurse rostering problem of a specific\r\nhome health care service. The problem consists of two subproblems:\r\non the one hand, it has to be specified which nurse works on which days;\r\non the other hand, tours for the nurses have to be determined for each day.\r\nSince the planning periods for these subproblems are different, the planning\r\nis not done simultaneously.\r\n\r\nModels for staff rostering and tour generation are shown. While the first\r\nproblem can exactly be solved with integer linear programming, the second is\r\nsolved heuristically. We propose an insertion heuristic, mainly based upon\r\nthe insertion heuristic of Solomon, and an improvement heuristic.\r\nFinally, computational results for real-world data are presented.", :title "Staff rostering at a home health care service", :keyword2 121, :authors (28740 14742), :session 52}, 719 {:keyword1 18, :keyword3 0, :abstract "The fashion discounter we co-operate with supplies its branches by\r\npre-packaged bundles consisting of items of different size and number --\r\nso-called lot-types. Our goal is to find a \"good\" supply strategy on this basis.\r\nWe call this the lot-type design problem.\r\n\r\nWe developed different models for this problem, which differ in the treatment of exogenous influences.\r\nStarting with a binary deterministic formulation we developed an intermediate model to arrive at a stochastic mixed integer linear program, which include the effect of markdowns\r\nas a compensation for over-supply.\r\n\r\nEvaluation of the models based on historical data poses the question of how different\r\nstrategies are to be compared. From an economic point of view maximization of\r\nrevenue seems to be the most prominent goal. However, data samples showed that\r\nvariation of popularity among single items under certain conditions makes this approach unreliable.\r\n\r\nWe will present different models for the lot-type design problem with evaluation procedures and demonstrate results which came from a field study at our project partner. ", :title "Evaluation of supply strategies for a fashion discounter", :keyword2 85, :authors (29229 29433 23024 16606), :session 242}, 720 {:keyword1 72, :keyword3 105, :abstract "This paper considers the separation in 2-period double round robin tournaments with minimum breaks (2PMB). The separation is a lower bound on the number of slots between the two games with the same opponents. None of the known schemes provides 2PMB with separation of more than 0 slot. We present a new scheme to generate 2PMB with separation of 2 slots based on single round robin tournaments with minimum breaks and no break in the last 3 slots, which are shown to exist from 8 to 68 teams experimentally. Furthermore, we use a ``first-break, then-schedule'' approach to find the maximal separation in 2PMB, in which candidate home-away pattern sets are first enumerated, then a constraint programming model is called to find consistent schedules. We present the maximal separation for up to 12 teams.\r\n", :title "On the separation in 2-period double round robin tournaments with minimum breaks", :keyword2 96, :authors (29431 29392), :session 143}, 721 {:keyword1 106, :keyword3 59, :abstract "The fixed charge transportation problem (FCTP) is a well-known and difficult optimization problem with lots of applications in logistics. It consists in finding a minimum cost network flow from a set of suppliers to a set of customers. Beside costs proportional to quantities transported, transportation costs do, however, include a fixed charge. Iterated local search and record-to-record travel are both simple local search based meta-heuristics that, to our knowledge, not yet have been applied to the FCTP. In this paper, we apply both types of search strategies and combine them into a single heuristic search procedure for the FCTP. The hybrid approach results in a relatively efficient heuristic method, capable to improve the currently best known heuristics for the FCTP on some of the test problem instances usually considered in the literature.", :title "Iterated local search and record-to-record travel applied to the fixed charge transportation problem", :keyword2 8, :authors (29430 14847), :session 191}, 724 {:keyword1 95, :keyword3 8, :abstract "The generation of Blocking plans is a problem arising in railroad freight traffic. The moved volumes are too low on certain relations and must be consolidated with other relations. The Blocking plan consists of a routing plan for every commodity and a list of nodes where wagons have to be reclassified.\r\nThe problem is modelled as a MCFP with integer contraints because relations cannot be splitted.\r\n\r\nFormer formulations do not enforce the bundling of commodities on certain parts of their routes, but our model does. Difficult constraints as maximal travel time for the wagons are reformulated by a restriction on the number of allowed reclassifications per relation. Moreover the new reclassification restriction simplifies the objective function. A second problem, which reflects the difficulty of exact request forecasts, is tackled, too. It is possible to split the planning interval into several days with daily changing commodity sizes on every relation.\r\nDue to timetable necessities a solution, which is optimal over all forecasted requests, must be found.\r\n\r\nBecause of the large problem size a Column Generation approach is presented. The added reclassification constraints can be effectively reformulated as a property of the feasible paths. Those paths can be generated by a special graph algorithm during pricing in polynomial\r\ntime.", :title "Column Generation for Multi-Matrix Blocking Problems", :keyword2 106, :authors (29225 26657), :session 192}, 727 {:keyword1 91, :keyword3 97, :abstract "In revenue management literature, Littlewood’s 2-class model is the most popular model for solving the static single-resource order acceptance problem. The model assumes sequential arrivals, i.e. low-revenue demand arrives before high-revenue demand.  However, in reality this assumption is not always realistic, especially in a manufacturing context, where the demand fulfillment decisions are typically made on a rolling-horizon base. In this presentation, we relax the sequential-arrival assumption and analyze a 2-class mixed arrival model where the arrival processes of different customer classes are modeled as independent Poisson processes. We show how the booking limit for the lower class can be calculated analytically, based on a marginal analysis. We then compare both demand-arrival assumptions numerically. Our results show that the mixed-arrival model and the Littlewood model can generate very different booking limits. Through a statistical analysis we identify the problem parameters that drive these differences. The revenues of both classes and the capacity scarcity turn out to be significant factors.  We conclude the presentation by generalizing the mixed-arrival model to a multi-class situation. We develop a heuristic and compare its performance numerically to the widely used Expected Marginal Seat Revenue (EMSR) heuristic. ", :title "Booking Limits in a Mixed Arrival Revenue Management Model", :keyword2 99, :authors (29101 4229), :session 224}, 728 {:keyword1 100, :keyword3 0, :abstract "This paper presents an empirical study on strategic controlling in Viennese hospitals. The survey focused on hospitals for acute care and hospital compounds that own more than one hospital. We empircally investigate the current status of the implementation of strategic controlling and its underlying quantitative and qualitative methodologies used. Furthermore, differences in the importance of strategic controlling for hospitals dependent on different characteristics are analyzed.", :title "Strategic Controlling in Viennese Hospitals: A Statistical Analysis", :keyword2 45, :authors (2713 770 29437 29439 29440), :session 95}, 732 {:keyword1 8, :keyword3 0, :abstract "The theory of linear complementarity has its origin as a unifying framework for optimization problems such as linear, convex quadratic and\r\nbimatrix game problems. It is NP-complete to decide whether a\r\nlinear complementarity problem (LCP) has a solution. Therefore researches\r\nare seeking for instances on which popular solving methods run in polynomial time.\r\n\r\nThe study of LCPs and their solving methods has led to several\r\ncombinatorial abstractions. We are concerned with the abstraction in the\r\nsetting of oriented matroids. The theory of oriented matroids is a natural\r\nsetting which generalizes combinatorial properties of many geometric\r\nconfigurations such as point configurations and hyperplane arrangements. We\r\nbuild on Todd's approach which consists in combinatorially generalizing LCPs by formulating the complementary problem in oriented matroids (OMCP). \r\n\r\nWe define combinatorial analogues of hidden K-matrices in the context of\r\noriented matroids. We show that the combinatorial problem structures of\r\nhidden K-LCPs and linear programs where the feasible region builds a\r\ncombinatorial cube are the same. This means, any simple pivoting method is\r\nefficient for the hidden K-LCP if and only if it is efficient for linear\r\nprograms where the feasible region is a cube.\r\n\r\nLCPs with hidden K-matrices have a unique solution which is found in\r\npolynomial time, even though the only method known makes use of the ellipsoid method. We concentrate our study on simple principal pivoting strategies as solving methods. The randomized version of Murty's least-index pivoting rule is promising, and it is conjectured to run in strongly polynomial time. Experiments on LCPs with randomly generated hidden K-matrices indicate a runtime of O(n^2) pivoting steps in expectation.", :title "Simple Pivoting in Linear Complementarity", :keyword2 78, :authors (29429), :session 149}, 734 {:keyword1 94, :keyword3 101, :abstract "We address the design problem of manufacturing process flexibility under uncertain demands using Robust Optimization. The model involves discrete product-to-plant assignments and affine decision rules for the amounts of processed products. We illustrate how AIMMS is able to easily accommodate the formulation of the model under uncertainty and generate the robust counterpart automatically. We also show how the intuitive, effective modeling concepts in AIMMS allow for fast, flexible experiments and comparison of results based on various uncertainty sets.\r\n", :title "Robust k-flexible manufacturing using Robust Optimization features in AIMMS", :keyword2 61, :authors (10297 29443), :session 241}, 735 {:keyword1 7, :keyword3 0, :abstract "Maintenance is usually not undertaken for a whole resource at once. The components of a resource are rather maintained separately. Therefore maintenance planning has to consider the varying abrasion of each component induced by the ongoing production and schedule particular maintenance activities for each component. \r\nFor this purpose it is necessary to model the state of each component of a resource, which is modeled through a continuous abrasion function and considered in the decision process. The particular state of each component of a resource depends on the ongoing production and on the executed maintenance activities for the respective component. \r\nBy taking into consideration different maintenance concepts and the possibility of maintaining several components at once, adjustments of established models are presented. In these models, production and maintenance activities for several components of a resource are considered simultaneously.", :title "Simultaneous Production and Maintenance Planning of a Capacity-constrained Resource with Multiple Components", :keyword2 48, :authors (26159), :session 165}, 737 {:keyword1 54, :keyword3 0, :abstract "The \"multi-type\" or \"modular\" capacitated facility location problem (MCFLP) is a discrete location model that addresses non-convex piecewise linear production costs as, for instance, staircase cost functions. The literature basically distinguishes three different ways to formulate non-convex piecewise linear cost minimization problems: the convex combination model, the incremental model and the multiple choice model. All three models are generally equivalent, but in case of the MCFLP, the latter one allows to include additional variable upper bounds (implied bounds) that strengthen the LP relaxation. We show that the latter formulation, with these inequalities included, strictly dominates the other two ways of formulating the problem. We additionally investigate different strategies of including\r\nthese variable upper bounds within the model using a common MIP solver.", :title "Three formulations of the multi-type capacitated facility location problem", :keyword2 77, :authors (14847), :session 221}, 738 {:keyword1 40, :keyword3 0, :abstract "The analysis of factors influencing cooperation in dilemma situations is an important question in the study of human behavior. In our presentation we report on an experiment consisting of 2 parts: a questionnaire which aims to measure the participants social value orientation and an iterated prisoner's dilemma (IPD) game by which we can measure cooperative and defective behavior. The number of rounds in the IPD is not known to the players.\r\n\r\nWe analyse the players' behavior in the IPD in relation to their social value orientation. Our first results show: the behavior in the IPD is significantly depending on the social value orientation of the players. The socially oriented players realize far fewer opportunistic actions and support significantly more often cooperation than the selfish oriented players do.", :title "Social Values and Cooperation. Results from an Iterated Prisoner's Dilemma Experiment.", :keyword2 0, :authors (29438 281), :session 133}, 739 {:keyword1 42, :keyword3 80, :abstract "Network design problems are central to planning in many types of systems, such as telecommunication systems. Most network design research focuses on extracting from a network an optimal subnetwork that will satisfy various requirements. The most common looked for subnetworks are trees. The Minimum Spanning Tree problem is one of the best-known network optimization problems, in it one attempts to find a minimum cost tree network that connects all the nodes in a given network. Usually, only setup costs are incurred. There might be other constraints imposed on the design of trees such as the number of nodes in a subtree, the number of nodes in any path from the root node (hop-constrained), degree constraints on nodes (degree constrained), flow and capacity constraints on any arc or node, and type of services available on the arcs or nodes. We consider a new problem which is an extension of the Hop-constrained Minimum Spanning Tree problem (HMST), since in addition to the hop-constraints we also must satisfy node demands by finding the flow that is to be routed along each of the arcs. Furthermore, the costs to be minimized include a general nonlinear flow dependent cost as well as a setup cost. Nonlinear cost functions arise naturally as a consequence of taking into account economic considerations. For this problem we propose a hybrid metaheuristic that includes an Ant Colony Optimization algorithm to deal with the exploration, and a Local Search procedure to cope with the exploitation of the search space. In order to test the algorithm we have used problems that were previously solved by other authors using other population based heuristics and our algorithm was able to improve upon their results, both in terms of computing time and solution quality.", :title "An Ant Colony Optimization Approach for Minimum Spanning Tree Problems in Nonlinear Costs Network Flows", :keyword2 59, :authors (16320 23499 7032), :session 149}, 747 {:keyword1 8, :keyword3 10, :abstract "We extend our previous work on complexity indices for the travelling salesman problem, summarized in [1], using graph spectral techniques of data mining.\r\n\r\nLet $A$ be an (exact) algorithm for solving an NP-hard\r\ncombinatorial optimization problem $C$ and let $I$ be an instance\r\nof $C$ of dimension $n$. A complexity index  of $I$ for $C$ with\r\nrespect to $A$ is a real $r$, computable in polynomial time from\r\n$I$, by which we can predict (in a well defined statistical sense)\r\nthe execution time of $A$ for $I$.\r\n\r\nWe consider the symmetric travelling salesman problem with\r\ninstances complete weighted graphs $G$. Intuitively,\r\nthe hardness of an instance $G$ depends on the distribution of\r\nshort edges within $G$. Therefore we consider some short edge\r\nsubgraphs of $G$ (minimal spanning tree, critical connected\r\nsubgraph, and several others) as non-weighted graphs and several\r\ntheir invariants as potential complexity indices. Here spectral\r\ninvariants (e.g. spectral radius of the adjacency matrix) play an\r\nimportant role since. In particular, spectral clustering algorithms are used.\r\n\r\nThe results of computational experiments along these ideas will be\r\npresented.\r\n\r\nAlthough there are in the literature some empirical and theoretical considerations on complexity indices (e.g. locating phase transition, landscape analysis, analisis of hard instances, etc.) a good theory of such phenomena is still\r\nmissing.\r\n\r\n1. Cvetkovic D., Cangalovic M., Kovacevic-Vujcic V., Optimization and highly informative graph invariants, Two Topics in Mathematics, ed.\r\nB.Stankovic, Zbornik radova 10(18), Mat. Inst., Beograd 2004, 5-39\r\n\r\n\r\n", :title "Complexity indices for the travelling salesman problem and data mining", :keyword2 120, :authors (29446), :session 203}, 752 {:keyword1 106, :keyword3 0, :abstract "We combine a number of different waiting strategies with a greedy randomized adaptive search procedure (GRASP) for solving a stochastic and dynamic vehicle routing problem. The problem typically occurs in businesses providing after sales services. Previously unknown service requests arrive dynamically throughout the day and must be served according to specific service agreements. A premium request has to be served in the daytime, while service of standard requests may also be scheduled at a later point in time outside office hours. The vehicles leave the depot in the morning and have to return by the end of the drivers shift.\r\nTwo conflicting objectives have to be considered. First of all, service quality should be maximized and second, operational costs for service provision should be minimized, i.e., the routing must ensure consistency with service agreements while causing a minimal amount of distance travelled.\r\nWe first present and analyze a GRASP based approach for solving the problem. In order to achieve improved solutions, we then combine the myopic GRASP approach with a number of anticipatory waiting strategies. We apply the resulting set of approaches to a number of problem instances and show the impact of the increased degree of anticipation with respect to solution quality.\r\n", :title "Waiting Strategies for Dynamic Routing of After Sales Service Vehicles", :keyword2 0, :authors (17686 13264 12952), :session 84}, 754 {:keyword1 106, :keyword3 0, :abstract "In conventional vehicle routing problems, transfers of goods between two vehicles are prohibited. However, for some practical situations, release of this restriction will lead to better solutions of the transportation planning problems. Examples can be found in line-haul transportation, where two trucks from two depots of a lane change their trailers or swap-bodies somewhere in the middle and go back to their own depots. This transshipment problem can also be integrated into transportation planning problems on the operative level, where transshipments of goods among vehicles are planned simultaneously while vehicle routes are generated. However, in scenarios of collaborative transportation planning, this new possibility for cost reduction has not yet been studied thoroughly as an additional option for request reallocation among collaborating partners. In this contribution, the integrated transshipment planning and vehicle routing problem in the context of collaborative transportation planning is formally described and mathematically modeled. The potentials of cost reduction by taking advantage of transshipments are then illustrated based on some computational results. The possibilities and obstacles to integrate transshipments into collaborative transportation planning are then discussed for coalitions of freight carriers with different autonomy grades. Some interesting topics in this field to be studied are then derived for future research.", :title "Transshipment in Collaborative Transportation Planning", :keyword2 0, :authors (17524 15277), :session 246}, 755 {:keyword1 17, :keyword3 28, :abstract "Power generation out of renewable energies is accompanied with accelerated growth in the world with Germany as one of the pioneer markets - 7.400 MW of 18.800 MW global photovoltaic (PV) new capacities were installed here in 2010. The connection and distribution of power from wind, biomass and PV leads to massive reinforcement needs at distribution and transportation grid operator side to avoid impermissible load, voltage or frequency values. \r\nThe existing frameworks like revenue cap regulation give contradirectional incentives. Grid operators might be more profitable by avoiding investments and - if they are forced to invest - by not searching smart solutions but reinforce with additional assets - even though this might not be the best solution for the whole supply chain. For a single grid operator this behavior may seem to be rational, but it can lead to massive stability problems due to fluctuation out of renewable generation. \r\nWithin most regulatory frameworks efficiency analysis like Stochastic Frontier Analysis (SFA) and Data Envelopment Analysis (DEA) are used. These methods determine efficiency values for each grid operator with massive impact on prospective profits. In the current system, SFA and DEA even strengthen the effect of avoiding investments or prefer reinforcement due to misfeatured choice of input-/output parameters. In our research we aim to find further influencing factors for the profitability of investments and for strategic decisions of grid operators and create a model which shows sensitivities and the impact of efficiency analysis like DEA on profit values. A proposal for a better support of smart solutions in the grid to increase grid usage and renewable power generation is given.\r\n", :title "Regulation effects on innovations in distribution grids ", :keyword2 29, :authors (29450), :session 130}, 759 {:keyword1 34, :keyword3 0, :abstract "This paper explains how to derive expected returns on the basis of target prices from renowned analyst firms according to titles in the ATX, that are for the purpose to be implemented in an optimization routine in order to calculate risk-adjusted portfolios. The work focuses on the precise specification of the forecast returns, which can be deduced from these target prices. Based on the capital asset pricing model and the historical correlations functions \"equilibrium returns,\" can be derived, so that these are in line with the current market capitalizations of the corresponding firms. The combination of forecast returns with the returns based on historical data is done in a Bayesian approach under the Black-Litterman model. The calculated model portfolio takes into account both the current market for the target prices as well the historical correlations.As a further consequence the extent of transactions is quantified that is required by newly added target prices still to hold the portfolio structure at the optimum. The expectation is that with our approach a contrast to ad hoc or heuristic approaches can be formed, which provides in relation to a pure purchase, hold, or sell recommendation concrete numbers as to which securities are to be traded.By calculating the so-called Mahalanobis distance  it is also possible to determine how far the forecast returns are from the CAPM equilibrium returns and thus to the composition of the underlying index. This is not the mere finding of a return differential, but a statement based on probabilities. Thus, \"unrealistic\" predictions are tracked, which are occasionally to be look twice before they are implemented in a portfolio model.", :title "Practical usefulness of target prices in the equity allocation", :keyword2 35, :authors (29456 14020), :session 265}, 762 {:keyword1 96, :keyword3 10, :abstract "Due to high repetitivity, manual handling and presence of awkward postures, working on assembly lines is often connected with significant occupational health risks. Several tools are available for planners to reduce ergonomic risks (or risks to the health of workers), but among them assembly line re-balancing and job rotation are the only low-cost methods available in the medium and short run.\r\n\r\nIn our previous studies we showed that ergonomic risks remain in about half of cases even after application of assembly line re-balancing. Job rotation is an effective tool to reduce or even eliminate these remaining risks.\r\n\r\nAlthough the ergonomic job rotation model (EJR) was already referred to in the literature, the problem’s complexity remained unknown and available exact method were able to solve only small problem instances. In our work, we describe the complexity of different instances of EJR. After an examination of the state of the art of job rotation in the automobile industry, we introduce a relevant for practice instance of EJR and examine,\r\nwhether simple and handy rules of thumb may lead to near-optimal solutions.", :title "Ergonomic job rotation – Generating working schedules that minimize health risks", :keyword2 8, :authors (26784 15101), :session 147}, 764 {:keyword1 80, :keyword3 108, :abstract "It is well known that Karush-Kuhn-Tucker systems arising from optimization problems or variational inequalities can equivalently be reformulated as a possibly nonsmooth system of nonlinear equations.\r\n\r\nTo solve such a system a new iterative framework is applied. It is based on the solution of a linear program per step. Local superlinear convergence results are presented even in cases where nonisolated degenerate solutions occur.\r\n", :title "Application of a Successive Linear Programming Framework to Karush-Kuhn-Tucker Systems", :keyword2 14, :authors (10013 17041 29253), :session 57}, 765 {:keyword1 91, :keyword3 0, :abstract "The growing importance of information not included in the traditional annual accounts has urged legislation to improve capital market communication. Hereby, the enlargement of the scope of disclosure in the management report seems to be the most promising approach. This paper focuses on the question to what extent the latest amendments of legal provisions concerning management reporting changed the financial reporting behaviour of listed companies. Being part of a comprehensive study on European countries, the sample presented in the paper comprises Austrian companies listed on the Vienna Stock Exchange and German companies listed on the German Stock Exchange in 2004 and 2005 and due to timeliness 2009. The information published in the management reports of those companies is compared between all three calendar years as well as across both countries. The study follows the seven basic categories which have to be reported on by companies according to section 267 UGB and section 315 HGB. The results prove empirically that the companies observed the legal requirements in terms of both quantity and place of information provided, but were not extended voluntarily. They also indicate that the companies adjusted their information policies to the legal requirements. Hence, the financial reporting behaviour has already complied with reporting obligations on a high level. ", :title "Disclosure requirements in management reports - an empirical analysis ", :keyword2 55, :authors (29513 29521), :session 89}, 767 {:keyword1 28, :keyword3 81, :abstract "When optimizing the portfolios and assets of our parent companies, we have to “forecast” and to simulate future energy prices (“PFC= Price Forward Curve”) for the commodities electricity, gas, oil, coal and CO2.\r\nThe statistical models and methods we use depend on the task and the data available:\r\nFor short term optimization (up to one week) we make use of external forecasts for the hourly electricity spot prices. Their accuracy can be increased by making use of actual price development in the market and by obtaining dynamic relations between different exchanges and mid European markets.\r\nThe statistical bases of stochastic optimization are hourly PFC for electricity and daily or monthly PFC for primary energy. We use a standard approach for the hourly PFC, but we take the effect of the “market price of risk” of futures into account.\r\nFor deterministic optimization and the simulation of production and sales portfolios we have developed the hourly optimization price scenarios “HOPS”. By using characteristic spot price patterns, they are able to reproduce extremes (spikes and negative prices) and have better statistical properties than classical HPFC, i.e. realistic second moments. This makes a huge difference in optimization, as we are going to show in some examples. \r\nFor daily commodity PFC we have developed a new approach mainly based on traded futures. We apply quadratic optimization with linear constraints, thus minimizing the sum of quadratic differences between the daily function values. In other words, we search for a smooth interpolation curve with respect to mean restrictions. Implicitly, this optimization results in splines of even degree, while interpolation problems lead to odd degrees. We are going to show the proof and empirical examples.", :title "Energy Optimization and Stochastic Price Modeling: Bin Ovular Twins", :keyword2 37, :authors (28461 29523 29585), :session 127}, 768 {:keyword1 75, :keyword3 0, :abstract "We consider a multi-item spare part two-echelon inventory system in which the\r\ncentral warehouse operates under an (nQ,R) policy and the local warehouses\r\nimplement order-up-to S policy, each facing a compound Poisson demand. The\r\nobjective is to find the policy parameters minimizing expected system-wide inventory holding and fixed ordering costs subject to an aggregate mean response time constraint at each warehouse. In this paper, we propose four alternative approximations for the steady state performance of the system; and extend a heuristic and a lower bound proposed under Poisson demand assumption to the compound Poisson setting. In a computational study, we show that the performances of the heuristic, the lower bound and the approximations are quite satisfactory.\r\n", :title "Multi-item Two-echelon Spare Parts Inventory Control Problem with Batch Ordering in the Central Warehouse under Compound Poisson Demand", :keyword2 0, :authors (5030 634), :session 169}, 771 {:keyword1 96, :keyword3 0, :abstract "Due to the increasing importance of service quality and the fulfillment of due dates, production planning often addresses tardiness objectives more than the traditionally considered makespan objective. In this work, we consider the classical job shop scheduling problem with the objective to minimize the total weighted tardiness. The well-known disjunctive graph model can be extended by adding individual sink nodes for every job. The determination of the objective function value via the longest paths leads to a tree structure which includes all critical arcs. We denote it by\r\ncritical tree. The critical arcs form so called blocks which are used for the definition of local search neighbourhoods. We show how well-known neighbourhoods such as swap, shift and permutation operators are enlarged on the critical tree structure. Furthermore, we introduce new neighbourhoods by extending and supplementing operators from the literature. We also present a computational study by comparing all neighbourhoods in the local search. By accessing average improvement rates and further performance indicators we aim at identifying the most promising candidate operators for local search based metaheuristics.", :title "A Computational Study on Local Search Neighbourhoods for the Job-Shop Scheduling Problem with a Tardiness Objective", :keyword2 0, :authors (29163 14707), :session 145}, 772 {:keyword1 66, :keyword3 14, :abstract "In recent works of the authors [1,2] a nonsmooth Newton was developed in an abstract framework and applied to certain finite dimensional optimization problems with C^{1,1} data.\r\nWe will apply this method to disjunctive optimization problems. For this we reformulate stationary points of a disjunctive problem [3] as a zero of a suited nonsmooth function.\r\nWe will work out in detail the concrete Newton schemes from [1,2] for this application and discuss the (local) convergence properties of the Newton scheme.\r\n\r\nReferences\r\n[1] S. Buetikofer, Globalizing a nonsmooth Newton method via nonmonotone path search, Mathematical Methods of Operations Research 68 No. 2, (2008) 235 - 256\r\n[2] S. Buetikofer, D. Klatte, A nonsmooth Newton method with path search and its use in solving C^{1,1} programs and semi-infinite problems, SIOPT 20, (2010) 2381-2412\r\n[3] H.T. Jongen, J.J. Rückmann, O. Stein, Disjunctive Optimization: Critical Point Theory, JOTA 93 No.2, (1997) 321-336\r\n", :title "A nonsmooth Newton method for disjunctive optimization problems", :keyword2 80, :authors (21140 10871), :session 73}, 773 {:keyword1 96, :keyword3 0, :abstract "The Blocking Job Shop with Rail-Bound Transfer (BJS-RBT) considered here is an extension of the Job Shop scheduling problem characterized by the absence of buffers and the availability of a rail-bound transfer system. The BJS-RBT can be described as follows. The processing of the jobs takes place on a set of machines. Furthermore, a set of mobile devices, called here robots, constitute a transfer system allowing each job to be transferred from one machine to the next. The robots move on a straight rail along which the various machines are located. The robots cannot pass each other and must also maintain a minimal distance from each other. Moreover, each robot can handle at most one job at any time and can move at a speed up to a (robot-dependent) speed limit.\r\nAn important feature of the BJS-RBT is blocking. We assume that once a job has started and up to its completion, it is either on a machine or on a robot. In particular, after completing a processing operation, a job must wait on the machine – in effect blocking it – until it is picked up by a robot which transfers it to the next machine, and similarly, a job must wait on a robot until the robot can transfer the job to the next machine.\r\nIn the BJS-RBT, the starting time of each processing and transfer operation, but also the trajectory of each robot, i.e. the location of each robot at any time, have to be determined in order to minimize makespan.\r\nWe show how to project the solution space of the BJS-RBT problem onto the space of the operation starting times, allowing a reformulation as a scheduling problem in which operation starting times are the sole decision variables. A formulation in a disjunctive graph is given, which forms the framework for a local search heuristic for the BJS-RBT.\r\n", :title "The Blocking Job-Shop with Rail-Bound Transfer", :keyword2 42, :authors (19271 19607), :session 145}, 776 {:keyword1 48, :keyword3 96, :abstract "Assembly line balancing (ALBP) is a well-known decision problem which arises when assembly line production systems are designed and operated. A large variety of elaborate solution methods were developed and presented in the academic literature in the past 60 years. Nevertheless, computational experiments comparing the performance of solution procedures were mostly based on very limited data sets unsystematically collected from the literature and from some real-world cases. In particular, the precedence graphs used as the basis of former tests are limited in number and characteristics. Former performance analysis of ALBP solution methods indicate, that their relative computational efficiency depends on the structure of the underlying problem instance. The authors suggested that given characteristics of a particular assembly line it is possible to give a recommendation, which solution method is expected to be the most successful. However, due to lack of systematics and statistical evidence this valuable analysis remained largely inconclusive up to now.\r\nA main disadvantage in recent studies is the absence of a sufficient number of systematically created instances with very diverse structures under full control of the experiment's designer. For this, we propose a new instance generator for the simple assembly line balancing problem (SALBP) and present a generated collection of new challenging benchmark data sets.\r\nWe show results of a wide-ranged computational study on existing exact and heuristic solution methods. We perform a thorough computational analysis of dependency between their performance and different structure parameters of the underlying problem instances.", :title "A systematic study on the simple assembly line balancing problem", :keyword2 115, :authors (29458 26784 15101), :session 164}, 777 {:keyword1 101, :keyword3 0, :abstract "We consider a supply chain with a manufacturer selling a product through two competing retailers.  The manufacturer has private information about demand and decides whether to share it with the retailers before acquiring the information.  The manufacturer also offers a wholesale price for selling the product to the retailers.  Given the information sharing arrangements and the wholesale price, the retailers compete by choosing their effort levels and either retail prices or retail quantities.  A multi-stage game is formulated to analyze how the firms make information sharing, wholesale price and retail decisions.  We derive conditions under which the manufacturer shares information with one or both of the retailers, and show how these conditions depend on cost of effort, competition intensity and type of competition (price or quantity).  Numerical results will be presented to provide more insights.", :title "Sharing Manufacturer’s Information in a Supply Chain with Competing Retailers", :keyword2 40, :authors (6398), :session 167}, 781 {:keyword1 18, :keyword3 0, :abstract "The transformation towards an absolute buyer’s market is requesting from producing companies, to face shortening product life cycles and expanding product varieties. As a result, those companies have to increase their production excellence, which is significantly shaped during the planning phase. However, there are no objective evaluation methods, which guarantee a comprehensive consideration of waste during the planning horizon and therefore no effective decision support systems to realize an excellent production. The concept, which is primarily being developed for automated production lines, represents the basis for a holistic evaluation, considering waste, flexibility and variability. The method includes their interactions and reveals potential adjusting levers for an optimization. ", :title "OMNI LEAN – a quantitative method to evaluate waste for an objective decision support in production planning phases", :keyword2 133, :authors (29459 29466), :session 261}, 784 {:keyword1 14, :keyword3 57, :abstract "We characterize (Hoelder-) calmness for C1-systems of inequalities and for Karush-Kuhn-Tucker- points to optimization problems by the (local) speed of convergence of different methods which determine feasible points for the critical parameter. \r\nIn particular, we consider the behavior of well-known steepest descent methods and systems given by polynomials. Throughout, we are focused on verifiable conditions in terms of original data.", :title "Some characterizations of Hoelder-calm inequality systems", :keyword2 80, :authors (11954 13581), :session 55}, 786 {:keyword1 83, :keyword3 0, :abstract "Two adaptive solvers for semi-infinite programming with arbitrary index sets are presented. The first one is an extension of the adaptive convexification algorithm presented by C.A.Floudas and O.Stein. Following the main ideas of the original algorithm convex relaxations of the lower level problem are adaptively constructed and replaced by their Karush-Kuhn-Tucker conditions. Then the resulting mathematical programs with complementary constraints are solved. The second algorithm is an adaptive reduction algorithm which is an extension of the algorithm presented by P.I.Barton et al. Using unimodal relaxations of the lower level problem, which are in some kind isomorphic to the optimal centered forms of global optimization, the original problem is reduced to non-linear programming problems. Then the resulting programs are solved. Both approximations produce feasible iterates for the original SIP. The required box domains for both algorithms are generated adaptively during the iteration. \r\nConvergence of stationary points of the approximating problems to a stationary point of the original SIP within arbitrarily given tolerances is shown and a numerical example is given.", :title "Feasible solvers for semi-infinite programming with arbitrary index sets", :keyword2 0, :authors (25956), :session 73}, 787 {:keyword1 54, :keyword3 42, :abstract "Abstract: We study a model of strategic location choice where players are interpreted as firms who can choose a position in some product space. The basic assumption is that consumers' preferences are single-peaked on a (tree) graph. This is a substantial generalization of the standard assumption that consumers’ preferences are based on the graph distances (which is questionable if the graph does not represent a geographic space). By partially characterizing the Nash equilibria for two and more players, we observe that several results – but not all of them – extend from the standard framework to our much more general framework. Under various conditions, Nash equilibrium positions are minimally differentiated close to the median vertex of the weighted graph. ", :title "A Location Game under Generalized Single-Peaked Preferences", :keyword2 40, :authors (29472 29460 29480), :session 205}, 788 {:keyword1 8, :keyword3 0, :abstract "In the field of optimizing escape routes in buildings the task is to determine the routes from any room to the location of safety in case of a necessary evacuation. To guarantee the existence of sufficient escape routes buildings have to obey to regulations on the number of escape routes, the length of the routes, and in which parts routes must be pairwise disjoint. When designing a building and optimizing the arrangement of the rooms these regulations affect the complexity of the problem. We look at the problem of planning escape routes in the construction phase of a building from a graph theoretical point of view. Besides an introduction of the mixed integer linear program some theoretical und practical results will be shown. We also present an approach to solve the problem with a single source which is based on disjoint paths and demonstrate the difficulties occurring in case of more than one source.", :title "Planning escape routes in buildings", :keyword2 77, :authors (29462 13046), :session 213}, 789 {:keyword1 91, :keyword3 0, :abstract "In the literature on product line pricing, consumer choice is often modelled using the max-surplus choice rule. In terms of this concept, consumer preferences are represented by so-called reservation prices, which denote their willingness-to-pay. The deterministic decision rule is to choose the product that provides the highest positive surplus, which is defined as the difference of reservation price and product price. However, the distribution of the reservation prices often seems somewhat arbitrary. In this presentation, we demonstrate how reservation prices can be obtained using discrete choice analysis. This widely accepted theory is based on deep theoretical foundations and offers a big toolbox of proven models and estimation procedures. The results show that the two concepts are not as different as often perceived in the literature. A small example illustrates this approach, using data from a discrete choice model taken from the literature.", :title "Consumer Choice Modelling in Product Line Pricing: Reservation Prices and Discrete Choice Theory", :keyword2 0, :authors (17483 22994), :session 98}, 791 {:keyword1 28, :keyword3 0, :abstract "The need of additional storage systems in the energy system increases with higher shares of fluctuating power generation, especially from renewable energy sources. Storage power plants can (and must) help to balance the fluctuating electricity production. \r\nIn a first step, a short overview of relevant technologies (both large storage technologies, such as pump storage power plants, compressed air storage, and future distributed storage technologies, such as electric vehicles) is given. \r\nIn a second step, an optimization model is presented, which enables a techno-economic evaluation of selected storage technologies (compressed air and pumped storage). The market value is determined by the model based on the spot and reserve markets. It is investigated whether storage technologies are profitable or under what circumstances an economic operation is possible. Furthermore, the influence of stochastic programming (with electricity prices as stochastic parameter) versus a deterministic approach on the results will be presented. \r\n\r\n", :title "Evaluation of storage power plants in liberalized electricity markets", :keyword2 29, :authors (14876 29464 29465), :session 126}, 792 {:keyword1 57, :keyword3 86, :abstract "In cumulative scheduling, conflict analysis is one of the key ingredients\r\nto solve these problems efficiently. \r\nThereby, the computational complexity of explanation algorithms that explain infeasibilities or bound changes plays an important role. \r\nTheir role is even more substantial when we are faced with a backtracking system where explanations need to be constructed on the fly.\r\n\r\nIn this talk we present complexity results for computing minimum-size\r\nexplanations for the propagation algorithms time-tabling, edge-finding,\r\nand energetic reasoning. We show that it is possible to compute in polynomial time minimum-size explanations for bound changes which result from energetic reasoning and edge-finding.  In case of time-tabling, we prove that an important special case is already weakly NP-hard. \r\nIn the context of bound-widening, the problems all become NP-hard.\r\nTo this end, we establish a relation to unsplittable flow problems on the path. We evaluate different heuristic approaches and exact approaches to explain bound changes derived by these algorithms. \r\n\r\nUsing these minimum-size explanations pays off in total \r\ncompared to using faster but weaker explanation algorithms. \r\nOur computational results show that widened minimum-size explanations \r\ndrastically decrease the number of nodes in a branch-and-bound tree search \r\nand reduce the computation times by one-half on average. ", :title "Explanation Algorithms in Cumulative Scheduling", :keyword2 96, :authors (23876 14976), :session 148}, 793 {:keyword1 29, :keyword3 31, :abstract "This study deals with regulatory instruments, but focuses especially on the Emission Trade System (ETS) designed by the United Nations Framework Convention on Climate Change and introduced by the European Union in 2005. It is in our interest to forecast the effects of the ETS on different indicators with economic importance (e.g. emission abatement, power price, import dependency, supply security, efficiency increase) and its costs up to the year 2020. Therefore we use an optimization model, in which we consider the regulation framework, the market parameters and technical constraints for the German energy market as well as an endogenous price for emission allowances, running times of plants and capacity enlargements. After solving the model with linear programming in different scenarios we find, that the ETS has strong impacts on production decisions, but low interest rates offered by the market inventive program are more effective in long-term decisions like plant investments.", :title "Modeling impacts of the European Emission Trade System on the future energy sector", :keyword2 37, :authors (26412), :session 124}, 794 {:keyword1 96, :keyword3 77, :abstract "The National Swiss League Association of Ice Hockey (NLA) plans every year a fourfold round-robin tournament. In this tournament each of the 12 teams plays 4-times against all other teams. This gives 264 games that are partitioned into 44 rounds. Each round consists therefore of 6 games in which all team must play exactly once and each round is run on a particular day.\r\nFurthermore, the 12 teams are partitioned into 3 groups of 4 teams. Within the groups, each team has to play an additional 2-times against each other. That means they are an additional 36 inner-group games, partitioned into 6 derby-rounds. All 12 teams must play exactly once in a derby-round.\r\nIn total, they are 300 games partitioned into 50 rounds, executed in 50 different days. The goal is to generate a schedule of matches for the season in which the additional conditions hold:\r\n\r\n1. In the first 25 rounds each team must play 2 (respectively 3) games against each other in the other groups (respectively within the same group). \r\n2. Home and away games must alternate as much as possible.\r\n3. Each teams should have the same number of home-games on a Saturday and Sunday if possible. \r\n4. Some \"risk-games\" must be fixed in particular rounds (at a fixed date). \r\n5. At various dates certain stadiums are occupied by other events and no game can be run at this locations. \r\n\r\nWe shows a mixed integer approach to formulate the problem and solve it with standard MIP-solvers.\r\n", :title "Sport-Scheduling for the Swiss Ice Hockey League", :keyword2 8, :authors (22798), :session 143}, 795 {:keyword1 136, :keyword3 18, :abstract "Up to now, German municipal utilities paid little attention to costs and efficiency of the components in a water supply system. Due to discussions about liberalization of the water market the utilities are starting to think about saving costs. Therefore the optimization of water supply systems has gained more and more attention in recent years.  Here, the aim is to develop an application which optimizes the usage of water tanks. On the one hand locations of new tanks are identified, and on the other hand the size of existing tanks is optimized, subject to satisfying the demand and providing the necessary amount of fire water during all time periods. The optimal solution is found by a combination of optimization and simulation: After solving a coarse optimization model of the water supply system the solution is validated by a simulation tool which contains a finer model of the underlying system. If the solution is feasible the optimal solution has been found. Otherwise the optimization model is modified and solved again until an optimal solution is observed. One main difficulty is the consideration of the head loss equation in the optimization model. As this equation is non-convex and quadratic the optimization model becomes a non-convex MIQCP (Mixed Integer Quadratically Constrained Program). Different approaches to solve this MIQCP are discussed. ", :title "Planning the usage of water tanks in water supply systems by combination of optimization and simulation", :keyword2 81, :authors (27365 1141), :session 126}, 796 {:keyword1 93, :keyword3 13, :abstract "In portfolio management, Robust Conditional Value-at-Risk (Robust CVaR) has been proposed to deal with structured uncertainty in the estimation of the asset probability distribution. Meanwhile, regularization in portfolio optimization has been investigated as a way to construct portfolios that show satisfactory out-of-sample performance under estimation error. In this paper, we prove that optimal-Robust CVaR portfolios possess the regularization property. Based on expected utility theory concepts, we explicitly derive the regularization scheme that these portfolios follow and its connection with the scenario set properties.", :title "The Regularization Aspect of Optimal-Robust Conditional Value-at-Risk Portfolios", :keyword2 94, :authors (19615 6147 24762), :session 264}, 797 {:keyword1 92, :keyword3 101, :abstract "The quality of a returned product may vary greatly, depending on its previous usage. Since remanufacturing of products in good condition is more economically rewarding for the remanufacturer it seems logical to acquire used products of different quality levels for different prices. \r\n\r\nHowever, acquisition price differentiation (APD) requires that the products are graded before their actual acquisition. We observe two different approaches in current practice. The first one is a reverse logistics system with a centralized grading facility. Here the grading and afterwards the final acquisition price offer are done after shipping the used products to this specific facility. Then the customer can accept or decline the offer, which results either in the payment of the acquisition price or a shipment of the product back to the customer. The second setting is a decentralized system with several collection sites to which the customers can bring their used products. After a short grading procedure, they get a specific acquisition price offer for their products, which they can directly accept or decline.\r\n\r\nMotivated by these empirical observations, we analyze the impact of acquisition pricing on reverse logistics network design decisions. We show that APD can be a reason for decentralizing the reverse logistics network, if product quality is uncertain. We start our examination by comparing traditional price discrimination and quality-based APD. We derive an expression for the value of APD in a setting with discrete quality classes. Subsequently, we relate this value to the logistics costs of centralized and decentralized networks. This allows us to derive the optimal network structure, dependent on key problem parameters.\r\n\r\n\r\n", :title "The Value of Acquisition Price Differentiation in Reverse Logistics", :keyword2 65, :authors (26948 4229), :session 190}, 808 {:keyword1 95, :keyword3 0, :abstract "Empty container repositioning costs in the hinterland of seaports can be reduced if trucking companies allow the exchange of their empty containers with other cooperating companies. The purpose of this contribution is to quantify the emerging cost savings by comparing two scenarios. Both scenarios are situated in a local area and consider a seaport terminal and at least two inland depots constituting the number of trucking companies. Each company has its own customer base which is separated into two types of customers. While the first customer type receives goods by inbound containers, the second customer type ships goods by outbound containers. Additionally, there are empty inbound containers and empty outbound containers available in the local area. In the first scenario empty containers are exclusively used by their owners. Therefore, trucking companies solely have access to their own containers. In the second scenario empty containers are allowed to be interchanged among several owners. Companies share their information at which locations empty containers are stacked currently and therefore empty containers can be assigned to transportation tasks which seem to be most appropriate for cost reduction. Both scenarios lead to an integrated model considering empty container repositioning and vehicle routing simultaneously. Randomly generated test instances are employed and solved with the commercial tool CPLEX. The results show that container sharing among cooperating trucking companies leads to huge cost savings.", :title "Reduction of Empty Container Repositioning Costs by Container Sharing", :keyword2 78, :authors (26353 15277), :session 179}, 811 {:keyword1 8, :keyword3 0, :abstract "In this contribution we present and analyze algorithms for Interval-SAT (iSAT), an extension of the well-known satisfiability problem. iSAT is a special case of the so-called signed k-SAT problem, where one fixes a poset P and a set S of subsets of P, and one is given a formula consisting of a disjunction of m clauses, each of which is a conjunction of k literals.  Each literal states \"x is an element of s\", where s is an element of S, and x is one of n variables. A literal evaluates to true if x takes a values in s.\r\nFor iSAT we assume P to be a chain and S to be the set of intervals in P.\r\nInterest in this problem arises from various applications. In scheduling theory conflicting time windows of different jobs processed on one machine or the consecutiveness of certain jobs can be expressed. At the same time the molecular behavior of biological systems can be described by iSAT, where biological statements of the form \"if protein A reaches a certain threshold but does not exceed another, then it implies that protein B is in a certain activity window\" are encoded by interval clauses.\r\nIn general, iSAT is equally hard as classical SAT, hence NP-complete. However, 2-iSAT is polynomial-time solvable. We give a polynomial certificate of infeasible 2-iSAT instances in the spirit of the famous result of Aspvall, Plass, and Tarjan for 2-SAT.\r\nWe further study random algorithms for uniformly random 2- and 3-iSAT formulas. For 3-iSAT we prove that, if m/n is less than 2.3, an adaption of the well-known Unit-Clause algorithm enhanced by a backtracking subroutine succeeds with high probability to find an assignment of values to the variables satisfying the formula.", :title "Satisfiability and Intervals", :keyword2 42, :authors (29476 9796), :session 205}, 813 {:keyword1 10, :keyword3 42, :abstract "In the Laser Sharing Problem (LSP) a set of industrial arc\r\nwelding robots has to perform a series of welding seams. For this task they need\r\nto be connected to a laser source supplying them with the necessary energy.\r\nIn principle, a laser source can serve up to six\r\nrobots but only one at a time. Furthermore, when switching between two robots a\r\npositive delay must occur. Welding tasks of robots assigned to different\r\nlaser sources can be processed simultaneously, as long as no collision between\r\nthem are possible. Ensuring collision free tours can be done by \r\n additional resource types, namely, \"line-line\r\ncollisions\" and \"line-point collisions\". The first describes the situation where \r\ntwo moving robots may collide. In the other case a robot waiting for a\r\nneeded resource may be hit. Thus, a task may have several resource demands.\r\n\r\nIn this talk we will focus on the special case LSP-T where the robot tours are\r\nprescribed. In the absence of possible collisions LSP-T can be modelled as\r\n a special Job-Shop Problem, if only a single laser source is available to all\r\nrobots which has a zero switching time. Here, we have one driving machine per robot\r\n and one welding machine for the laser source. This situation is also known as\r\n \"one machine scheduling with chained min delay precedence constraints\".  \r\n\r\nWe will show that this special Job-Shop Problem is already NP-hard for three\r\nrobots. On the positive side, we present a polynomial algorithm for LSP-T with\r\ntwo robots. For an arbitrary but constant number of robots this can be solved in\r\npseudo-polynomial time. Together with an FPTAS this gives \r\na sharp boundary of the complexity status for a constant number of robots.", :title "A generalized Job-Shop Problem with more than one resource demand per task", :keyword2 96, :authors (16717 17055), :session 145}, 815 {:keyword1 63, :keyword3 76, :abstract "The discrete model of objects group servicing is considered. The objects are located in the vertices of an undirected simply-connected graph. The servicing is performed by a mobile-processor that starts its moving from the base graph vertex and then goes through all other vertices to serve every object. The servicing cannot be interrupted: the processor cannot start servicing another object until it completes the current one. The known parameters of the model are objects servicing durations, time of their readiness for servicing and the processor moving durations between objects. Each object is associated with its own penalty function which is monotone non-decreasing function of the service completion time. By servicing strategy we mean the sequence of indexes such that the object with the first index is served first, the object with the second index is served second and so on. The bi-criteria problem that we consider is in following: to construct servicing strategies in order to minimize the cumulative penalty function for all objects and to minimize total duration of processor movements. The problem is solved based on Pareto optimality principle. Total Pareto set of optimal strategies is constructed using the bi-criteria dynamic programming approach. The problem is proved to be NP-hard. Hence we used different heuristic methods such as Ant Colony, Tabu Search, Simulated Annealing, Genetic Algorithms and their combinations for large dimensions.\r\nOn practice the model describes the processes of diesel-oil supplies to the technological facilities that mine the gravel and gravel-sand mixture from the bottom of the rivers (Russian water transport).\r\n", :title "Bi-criteria optimization model and algorithms of servicing scheduling for a distributed objects group", :keyword2 59, :authors (28993), :session 202}, 817 {:keyword1 101, :keyword3 0, :abstract "A major issue in supply chain management is the coordination of individual firms’ decisions by appropriately designed contracts in order to avoid efficiency losses caused by misalignment of goals of independent supply chain actors. In cases where a supply chain is exposed to unreliable production processes which result in random production yields, this coordination problem has specific characteristics which are not well understood up to now. \r\nThe specific situation in a manufacturer-retailer supply chain with random production yields is such that both firms make interacting decisions (order quantity by the retailer and production quantity by the manufacturer) which generate risks that directly affect the success of both parties. If the production yield (output quantity) of the manufacturer is too small compared to the order quantity, the retailer suffers from insufficient delivery. If the yield is too large, the manufacturer suffers from overproduction that is not ordered by the retailer. \r\nIt is easy to show that in such a situation a simple wholesale price contract is not able to align the order and production decision so that the supply chain optimum can be achieved. It is not clear, however, how different types of contracts with different forms of risk sharing with or without penalty and reward mechanisms can help to coordinate the supply chain. The underlying study will contribute to gain insights into this research problem.\r\n", :title "Supply Chain Coordination by Risk Sharing Contracts in the Case of Random Yield", :keyword2 93, :authors (26317 2801), :session 167}, 818 {:keyword1 121, :keyword3 96, :abstract "Nurse rostering is not only of interest in huge hospitals but also in small healthcare institutions. This is because of the continuous coverage demands which are not easy to handle even with a small staff. We tackled a real-world nurse rostering problem for a small German healthcare institution. Based on MS Excel, we show a simple way to create a modeling file for the associated optimization problem in a user friendly and flexible way. The underlying mathematical programing approach comprises a range of typical and non-typical coverage and quality conditions. In addition to those conditions, we show how to deal with fairness aspects as well as with the need of robust re-planning in case of short-term absences.", :title "How to cope with rostering in small healthcare institutions", :keyword2 45, :authors (28739), :session 52}, 819 {:keyword1 40, :keyword3 55, :abstract "The currently presented experiment is one part of a greater study in which we examine the effects of (face-to-face) communication and the degree of principal´s control on agent's reporting behavior. However, in this talk we focus on the tradeoff between agent´s preferences for wealth and his/her preferences for honesty. Our objective is to find and examine the relation between honesty in managerial reporting and social preferences.\r\n\r\nIn particular, we conduct a laboratory experiment in which there are two parties: the supervisor or principal (upper manager) and the better informed subordinate or agent (lower manager). The agent has private perfect information and shall report it to the supervisor. Subordinate's compensation depends both on the reached production and the reported production. The parameters are set this way, that the subordinate gets the highest payoff by reporting the possibly lowest revenue, which means the highest level of misrepresentation.\r\n\r\nWe want to investigate how agent´s participation in the budgetary process influences his/her willingness to truthful communication of private information, in cases of financial incentives for misrepresentation.\r\n", :title "Honesty in Budgetary Reporting - an Experimental Study", :keyword2 19, :authors (26737), :session 134}, 821 {:keyword1 65, :keyword3 97, :abstract "The design of efficient production and distribution networks is a crucial driver of competitiveness in today’s customer oriented businesses. Most research on network design problems considers make-to-stock business environments where finished goods inventory is used to fulfill customer demand. Only few studies investigate make-to-order (MTO) businesses, where production and distribution processes are initiated by customer orders. A reason might be that the routing and processing of individual orders within a MTO network can hardly be captured by prevalent modeling techniques like mixed integer programming or queuing models. Although simulation provides a mean for tracing order fulfillment processes in a given network, it lacks the capability to optimize a network design. \r\n\r\nIn this talk, we present an approach for the design of MTO networks that combines optimization and simulation techniques. Variable Neighborhood Search heuristic is used to search for promising network designs with respect to (i) the suppliers, plants, and warehouses to take up in a network, (ii) the components that are provided at each facility, and (iii) the capacity level of each facility. A simulation component assesses these designs in terms of variable cost for processing orders and in terms of the achievable on-time delivery rate of orders. Here, production and distribution processes are simulated in detail with respect to load-dependent lead times at facilities, dynamic dispatching rules for order assignment, and rule based scheduling of production orders at facilities. Computational results for randomly generated test instances are presented, from which we derive insights regarding the interaction of strategic network design decisions and the operational performance of MTO networks.", :title "The Design of Make-To-Order Supply Networks by Means of Simulation-Optimization", :keyword2 101, :authors (14707 13086), :session 223}, 823 {:keyword1 96, :keyword3 97, :abstract "There exists a large body of literature where scheduling problems are discussed under the assumption that machines are always available. However, machine failures and maintenance activities can have a big impact on job completion times and delivery times. On the other hand the order of jobs constrains the placement of preventive maintenance activities. To regard this interaction, the integration of maintenance decisions in scheduling problems has to be considered. Several approaches are evolved in literature since the last decades but solutions for simple practical usage are still missing.\r\nIn this paper we study the problem to determine a production schedule for n jobs on a single machine which is subject to stochastic machine failure. To avoid long downtimes of the machine, preventive maintenance should be planned as well. Costs are assumed to occur through job tardiness when exceeding a due date and through performing preventive and corrective maintenance activities, where the latter take place after machine failure. Both maintenance activities are assumed to restore the machine to be \"`as good as new\"'. Furthermore it is assumed, that jobs interrupted by machine failure, have to be restarted after finishing corrective maintenance (non-resumable case). Thus the choice of the job order becomes more important. The aim of our study is to find a production and maintenance schedule minimizing the average costs. In the course of a simulation study, first simple decision methods for determining preventive maintenance insertion rules are developed and compared. Second the performances of different schedules are tested, resulting in a viable practical instruction, concerning job order and preventive maintenance decision.\r\n", :title "The Integrated Production Scheduling and Maintenance Problem with Stochastic Failures on a Single Machine", :keyword2 99, :authors (29394), :session 51}, 824 {:keyword1 101, :keyword3 0, :abstract "The increasing number of Free Trade Agreements (FTAs) strongly influences global production and sourcing strategies of multinational corporations. Based on the special local content requirements of the North American Free Trade Agreement (NAFTA) for automotive goods, a non-linear mixed integer problem is presented. Strategic decisions on supply parts and product flexibility provisions of the production sites are taken into account. The model integrates explicitly the legal options of the NAFTA automotive local content calculation. Furthermore, it considers the possibility to underachieve the local content requirements and to pay penalty duties for NAFTA cross-border deliveries instead. To determine the local content and possible duty payments, the plant fixed costs have to be allocated to the products in accordance with plant utilization. Due to the resulting non-linearity and the structure of the non-linear mixed integer programming model, a solution algorithm based on Benders Decomposition is presented. This approach leads to significant run-time improvements compared to piecewise linearization approaches. In a numerical study the impact of local content requirements on the strategic network design of an automotive manufacturer is highlighted.", :title "Benders Decomposition for a strategic network design problem under NAFTA local content requirements", :keyword2 0, :authors (29457 9112), :session 223}, 827 {:keyword1 88, :keyword3 97, :abstract "Issues such as traffic congestion in modern society are one of the key issues must be addressed. The study focused on the intersection of road traffic, numerically and theoretically analyzed traffic signal switching time to minimize congestion of cars at the objective intersection, i.e., minimize average waiting time of vehicles at this objective crossing.\r\nConcretely, we selected an intersection in downtown of Fukuoka (Japan) where congestion often occurs, and collected some data there in relation to existing traffic signal switching time, car arrivals etc. during rush hours. Then based on our proposed formulation on minimizing average waiting time of arrived cars at a crossing, we numerically calculated the optimal traffic signal switching time of the mentioned case via computer simulation. Finally, a theoretical expression is derived on the optimal traffic signal switching time to minimize average waiting time of cars at the objective intersection by supposing random or exponential distribution of car arrivals. Traffic signal control in a real road system in Japan usually places emphasis on guaranteeing a relatively smooth traffic flow of main roads. The study mentioned above offers some useful information to this design ideology and also, offers some flash idea for traffic signal control, and thus is considered to be meaningful from the viewpoint of urban traffic engineering.\r\n", :title "Studies on the optimal traffic signal switching time at an intersection", :keyword2 106, :authors (4928), :session 181}, 828 {:keyword1 8, :keyword3 0, :abstract "We present results on the geometry of maximal lattice-free polyhedra which are motivated by recent developments in cutting-plane theory. In particular, the class of integral lattice-free polyhedra which are maximal with respect to inclusion. This class of polyhedra is finite modulo affine transformations preserving the integer lattice.", :title "Some geometric aspects of cutting-plane theory", :keyword2 0, :authors (29477), :session 227}, 829 {:keyword1 63, :keyword3 59, :abstract "The objective of this paper is to optimize the daily operation of eight São Francisco´s hydroelectric power plants. The study considers eight power plants – Sobradinho, Luiz Gonzaga, Apolônio Sales, Paulo Afonso I, II, III, IV e Xingó – which belongs to the São Francisco Hydroelectric Company. \r\nBased on multi-objective optimization, the model maximizes the power plants´ efficiency in the same time that minimizes the number of startups and shut downs of the generating units. \r\nConsidering equal generating units, it determines the number of units to be dispatched and their load. \r\nThe scheduling problem of generation systems is usually divided in long, medium and short term planning periods. This works focus on the short term period, considering only the dispatch optimization model for the eight power plants system.  \r\nThe methodology proposed is divided in two steps: Step one attributes the load to be generated by each power plant in hour basis by linear programming techniques, and Step two determines the generating units to operate and their loads  for each power plant during this time interval employing genetic algorithms techniques. \r\nThe methodology was implemented on a case study with support of São Francisco Hydroelectric Company considering a daily planning horizon discretized in half hours.  \r\nThe implementation proved to be effective in terms of design and performance, enabling its use to optimize other hydroelectric power plants in cascading distribution. \r\nThis work involves dispatch optimization, linear and non-linear programming and genetic algorithms techniques.\r\n", :title "Multi-objective Optimization Model for São Francisco´s Hydroelectric Power Plants ", :keyword2 29, :authors (29249 27936 28237 1309), :session 126}, 835 {:keyword1 8, :keyword3 106, :abstract "The Sequential Ordering Problem (SOP) is an optimization problem used to model different real applications such as production planning, single vehicle routing problems with pick-up and delivery constraints and transportation problems in flexible manufacturing systems.\r\nAnt Colony System (ACS) is a well-known metaheuristic metaphor, and it has been successfully applied to many combinatorial optimization problems, among which the SOP.\r\nIn this work a well-known adaptation of the ACS method to the SOP is critically analyzed, with the aim of finding the drawbacks of the algorithm, and to overcome them. It was found that the main criticality of the ACS method was represented by the integration between the constructive phase and the local search phase. In particular, since the local search implemented was extremely effective and efficient in carrying out diversification, some intensification capabilities guaranteed by the constructive phase could be dropped. The new constructive phase we propose is faster, and only provides a form of diversification, while intensification is entirely left to the local search routine. Moreover, some mechanisms to minimize the number of calls to the local search have also been implemented: it is not convenient to run the local search over and over again on a same initial solution (as it was done in the original ACS). The new ACS algorithm we obtained is referred to as Enhanced Ant Colony System (EACS). \r\nComputational experiments show the effectiveness of the enhancements introduced: EACS clearly dominates ACS. Moreover, when compared with the state-of-the-art algorithms available in the literature, EACS is able to improve the best-known result for 32 of the 48 instances considered, while matching the best known result for the remaining 16.\r\n", :title "An Enhanced Ant Colony System for the Sequential Ordering Problem", :keyword2 59, :authors (7857 518 22740), :session 159}, 836 {:keyword1 57, :keyword3 94, :abstract "Wireless sensor networks are required when commanding actuators from remote or when establishing connections in places where the underlying network infrastructure is damaged. These sensor networks depend on small terminal devices which use antennae to communicate and small batteries as limited sources of power. To effectively use the limited power, the minimum power multicasting problem emerges, in which the goal is to minimize the total power consumption on terminals while still ensuring that the source terminal can transmit to the destination terminals.\r\n\r\nFor minimum power multicasting problem, we propose a three-stage approach which also considers that the transmission power required for a terminal to transmit to another, is subject to uncertainty. This uncertainty represents the unfriendly weather conditions which affect the transmission quality, and the errors in the estimations made by the engineers, while preparing the data for the optimization model.\r\n\r\nOur approach adds two polynomial time stages to a classical approach well-known in the literature and based on a mathematical programming formulation (stage one). Stages two and three are introduced to adjust the transmission power of nodes in such a way to achieve a better protection against uncertainty, without increasing the total power consumption.\r\n\r\nThe experimental results show that, our three-stage approach increases the robustness of the solutions obtained using the classical approach (stage one only).", :title "A Three-Stage Robust Optimization Approach for Minimum Power Multicasting Problem on Wireless Sensor Networks", :keyword2 42, :authors (24846 7857), :session 212}, 837 {:keyword1 106, :keyword3 121, :abstract "This paper addresses the rota scheduling problem (RSP) which aims to assign a set of working days, free days and reserve shifts to driver groups such that management considerations, labor laws and the preferences of drivers are considered. Currently, the reserve shifts in the RSP are evenly planned for all drivers (for example: a certain percentage is planned for reserve shifts) without considering more detailed information such as historical or weekday-depended sickness absence rates. The current practice in the case that the absence rate exceeds the available reserve personnel is that additional drivers are called manually on demand. This not only causes discontent for the drivers, but also creates a day-to-day managerial burden for the bus company.\r\nIn order to reduce the discrepancy between a planned roster and the actual one, a new stochastic optimization model for the RSP is formulated and is compared to the deterministic optimization model. The scenarios of the stochastic problem are created depending on historical and weekday-dependent absence rates. In addition to the present reserve optional attendance shifts are introduced. This offers better conditions for the reserve drivers as well as enables a specific reaction on the sickness absence rate of the day by using optional reserves.\r\n", :title "Deterministic and stochastic models for Rota scheduling in public bus transport", :keyword2 99, :authors (27073 23701 1141), :session 219}, 840 {:keyword1 63, :keyword3 106, :abstract "Vehicles using electric drive train, such as electric vehicles (EV) and Plug-in hybrid electric vehicles (PHEV), are emerging as promising solutions to reduce greenhouse gas emissions. Environmental performance of these alternatives must be analyzed clearly to formulate sustainable energy policies in the transportation sector. Environmental benefits of the EVs depend on source and location of the marginal electricity that is used to charge the vehicle batteries. Related studies about impacts of the EVs put emphasis solely on the cost of electricity. Therefore, resulting policy recommendations about charging hours, such as night time charging, lead to cost effective but CO2 intensive generation mixes. In this study a methodological approach that takes the bi-criteria nature of the problem into account to analyze emission impacts of the EVs is proposed. The first stage includes the development of a bi-criteria mixed-integer linear programming (MILP) electricity market optimization model to obtain efficient frontier of marginal electricity mixes that minimize generation costs and CO2 emissions under certain charging and scenarios. In the second step, charging patterns for the EVs are optimized by solving another bi-criteria MILP model that includes charging hours as decision variables instead of fixed charging scenarios. The approach is applied on real world data from Turkish electricity market and emissions of the EVs are compared to conventional vehicles. The results show that environmental performance of the EVs is sensitive to magnitude, time, and location of charging; hence governments should take regional specifications of the electricity market into account before deciding on policies regarding the EVs in order to get maximum benefit from this technology.", :title "A bi-criteria optimization model to analyze the impacts of electric vehicles on the electricity network", :keyword2 29, :authors (29481 230), :session 129}, 841 {:keyword1 7, :keyword3 0, :abstract "We consider a system consists of two competitive firms in a multi-period setting. Each firm serves two demand classes. Any unsatisfied demands of a firm in the current period may cause the loss of demands in the next period. The demand is substitutive. We show that the equilibrium capacity levels allocated by each firm to each demand class in each period are all of base stock type and are dependent on the expected values of the customers from different demand classes. Further, we derive some specific expressions for the equivalent unit stockout costs in traditional capacity/inventory models on the basis of the expected values of the consumers from different demand classes. And we show that those costs are all non-negative and non-decreasing over time.", :title "Capacity choice and allocation under stockout-based substitution", :keyword2 0, :authors (29416 29483 29482), :session 224}, 842 {:keyword1 23, :keyword3 101, :abstract "Workers in a bucket brigade production system perform unproductive travel when they walk to get more work from their colleagues. We introduce a new design of bucket brigades to reduce unproductive travel. Under the new design, each worker works on one side of an aisle when he proceeds in one direction and works on the other side when he proceeds in the reverse direction. We propose simple rules for workers to share work under the new design and find a sufficient condition for the system to self-balance. Numerical examples suggest that the improvement in throughput by the new design can be as large as 30%. Even with a 20% reduction in labor, the new design can still increase throughput by 7%.", :title "Cellular Bucket Brigades", :keyword2 75, :authors (16036), :session 225}, 847 {:keyword1 8, :keyword3 0, :abstract "In this paper, we discuss a method to hide an image into different images.\r\nThis problem is discussed in a field of visual secret sharing scheme.\r\nThere is a secret picture to be shared among n participants. The\r\npicture is divided into n transparencies (shares) such that if any m\r\ntransparencies are placed together, the picture becomes visible, but\r\nif fewer than m transparencies are placed together, nothing can be\r\nseen.\r\nIn the original visual secret sharing scheme, the shares given to\r\nparticipants are random dot images. We discuss a technique to share a\r\nsecret image such that each participant is able to see a given image\r\nin his transparency. Therefore, we start with n + 1 images where n\r\nimages are associated with the n participants and last one is the\r\nsecret image. We discuss to share the secret image into n images on\r\ntransparencies.\r\nWe report some computational experiences based on extended visual\r\nsecret sharing schemes and simple heuristic methods.", :title "Hiding an Image into Different Images", :keyword2 42, :authors (26300 13201), :session 208}, 848 {:keyword1 29, :keyword3 0, :abstract "Climate change impact simulations for the hydropower production at the plant in Löntsch, Switzerland have been carried out through the use of several climate models investigated in the context of the European project ENSEMBLE (2010). Variations in hydropower production capacity caused by climate change are of significant economical importance due to its dependency on water influx. Simulations of the future hydrological regime caused by greenhouse gas emissions were carried out with general circulation models (GCM) and the results were subsequently downscaled using regional climate models (RCM). The resulting temperature and precipitation estimates of the RCMs were downscaled by using an interpolation procedure. The local values for Löntsch were then used as input parameters for the hydrological modeling by using the deterministic Bernydro model developed at the University of Bern. The simulations were calibrated with the historical values of the net influx for the period of 1998-2001 and the forecast temperatures and precipitation were used to estimate the net influx for the period of 2021-2050. These results were then used in the Time-Steps-Energy 2010© software application for the simulations of the hydropower production planning in order to investigate the climate change effects on the future production capacity and turnover. Since the amount of water for the production of electricity can be scarce relative to the installed capacity of the plant, the modeling of the optimal dispatch strategy implies the determination of the revenue-maximizing decisions at each point in time in order to determine the right time for production typically when spot prices are expected to be high at peak-load during the day.", :title "Climate Change Impacts on Hydropower Production in Löntsch 2021-2050", :keyword2 37, :authors (29494 29495 29497 29498 29499 29500 29501 29502), :session 126}, 851 {:keyword1 34, :keyword3 85, :abstract "The objective of this paper is to propose a technique to generate scenario trees which excludes arbitrage opportunities by construction. In contrast, scenarios generated by methods such as moment matching or scenario reduction can only be checked for arbitrage ex-post, and trees which allow for arbitrage must be discarded. Our approach is embedded in the setting of arbitrage pricing theory (APT), and asset returns are assumed to be driven by (a small number) of orthogonal factors. We establish necessary conditions for the number of scenarios to be generated, and derive bounds for expected returns to exclude arbitrage at the outset. Apart from excluding arbitrage the approach has another attractive feature: scenario trees can be smaller than trees generated by moment matching with almost no loss in accuracy regarding the statistical properties of simulated returns.", :title "APT-Based Scenario Trees", :keyword2 35, :authors (26602 13094), :session 118}, 852 {:keyword1 96, :keyword3 0, :abstract "Two of the most common problems regarding the use of public transport are the loss of time waiting for buses to arrive at terminals and the lack of guidance in scheduling one’s route within urban cities, where complicated and interconnecting bus networks are used by millions of people every day. Judging by our own daily experience, the time commuters lose due to these two factors is significant.  An inappropriate allocation for this can lead to an increased waiting time for commuters as well as chaos and traffic on the roads.\r\n\r\nOur main objective is to help commuters minimise the time spent moving around a city and the frustration induced to them by the two factors mentioned above when using the public transportation system, thus making the later more efficient and user-friendly. \r\n\r\nIn this paper  we aim to address the above mentioned challenges. The software that we have developed takes in the various timings of  buses scheduled by the BMTC ( Bangalore Metropolitan Transport Corporation ) organization for travelling from one terminal to another and vice versa as well as the duration of travel. Based on these, optimal number of buses is allocated, considering constraints such as break time for the crew, travel duration in peak and non-peak hours, wear and tear of the buses, etc.  Implementation of the work is done using Java, making it portable. The front end is developed in Java whereas the back end in MS – ACCESS enabling us to store the provided data. They are linked using JDBC-ODBC Bridge.\r\n", :title "Bus allocation and its utilization between two terminals", :keyword2 105, :authors (29486 29487 29488 41043), :session 142}, 854 {:keyword1 106, :keyword3 77, :abstract "We study a rostering problem motivated by the ground operations of an international airline. Whilst air-crew scheduling has been intensively studied for decades, ground-crew scheduling has attracted less attention.\r\nThis paper investigates a ground-crew shift-rostering problem (SRP) --- the assignment of ground-crew to shifts over a planning horizon such that work rules are observed. A novelty in our approach is the use of prohibited shift sequences to represent work-rule constraints. We formulate the SRP as a mixed-integer-programming model, and propose a column-generation heuristic based on shift-assignment patterns. Computational performance on large problem instances is further improved by partitioning them into a number of smaller linked instances (blocks). Computational results on randomly-generated datasets show that the proposed approach is effective. Large problem instances of up to 6 months with 10 shifts are solved efficiently to near optimality.\r\n", :title "A column-generation approach to crew rostering using prohibited shift-sequences", :keyword2 2, :authors (3301 29503), :session 219}, 855 {:keyword1 96, :keyword3 0, :abstract "In several countries, including Denmark, home care is provided for certain citizens living at home. Home care offers cleaning, grocery shopping, helping with personal hygiene and medicine, helping citizens to get in and out of bed, etc. The home care scheduling problem is to generate working plans such that a high quality of service is maintained, the working hours of the employees are respected and the overall cost is kept as low as possible.\r\n\r\nQuality of service consists of the following. Regularity: visits at a citizen should be conducted at the same time and by the same small group of employees in order for the citizen to feel safe. Skill set requirements: certain tasks can only be performed by a subset of the employees due to skill requirements.\r\n\r\nAll time windows are soft, i.e., preferred visit times and employee working hours can be violated at a cost. The overall costs of a solution consists of a linear combination of employee transportation time, violation of time windows and regularity constraints.\r\n\r\nThe home care problem is NP-hard. It is often approached in two different ways in the literature: one way is to solve the daily planning problem, i.e., to generate plans for employees for a single day, which corresponds to a modified VRPTW. Another way is to solve a Periodic VRPTW, where visits can be performed on a limited combination of days and where the remaining regularity constraints are ignored.\r\n\r\nWe propose a branch-and-price algorithm for the full home care problem. The pricing problem generates a one-day plan for an employee, and the master problem merges the plans with respect to regularity constraints. The method is capable of generating plans with up to 80 visits during one week. This truly illustrates the complexity of the problem.", :title "Long-term home care scheduling", :keyword2 77, :authors (28424 24634), :session 52}, 856 {:keyword1 106, :keyword3 5, :abstract "Urban systems emerge and grow considerably in many countries today and in near future, and therefore also the necessity for efficient transport networks. This research is motivated by the need of methodologies for planning efficient, reliable and sustainable urban transport systems. Already existing approaches are summarized. The proposed optimization algorithm is capable of designing an entire urban road network. The network’s efficiency is measured with a computationally costly objective function (deterministic user equilibrium), including generalized costs of travel and an infrastructure budget constraint. The efficiency is maximized during the network design process. The optimization algorithm is initialized with a large set of candidate links describing a large search space. The algorithm complements strategies of an ant colony optimization (ACO) and a genetic algorithm (GA) to design the transport network. The learning ability is retained, which is prominent in an ACO. A recombination method, derived from the GA approach, focuses on transport network characteristics. The algorithm is detailed, and tested in several case studies, including real world examples, to design and evaluate road networks.\r\n\r\nThe algorithm is extended for network shape grammars because they have increasingly gained in importance in urban planning and simulations. Shape grammars describe in the form of rules how network elements of different types are added to each other. The results show that shape grammars can be incorporated in the algorithm and that they considerably influence the resulting networks, compared to networks excluding shape grammars. Potential applications in other fields of network construction are likely.\r\n", :title "An Integrated and Adaptive Ant Colony and Genetic Algorithm for Transport Network Design", :keyword2 65, :authors (29461 29508), :session 181}, 861 {:keyword1 105, :keyword3 72, :abstract "Sports scheduling has recently become a popular topic in the area of scheduling. We deals with home-away assignment problems arising in the field of tournament timetabling. The home-away assignment problems appear when we use a method called “schedule then break approach” for generating a round-robin tournament schedule. Given a timetable of a mirrored double round-robin tournament and distances of all the pairs of venues, home-away assignment problem determines a venue for each game and minimizes the total traveling distance. We consider a case that both the number of consecutive away games and that of consecutive home games are at most three.\r\nWe propose a randomized approximation algorithm yielding a feasible solution whose total traveling distance is less than or equal to (7/3+O(1/n))z where n is the number of teams, and z is the total traveling cost of an optimal assignment. To the best of our knowledge, our result is the first approximation algorithm with a constant approximation ratio, which is less than 3.\r\n", :title "Minimum Cost Home-Away Assignment of Double Round-robin Tournament", :keyword2 8, :authors (29492 13201), :session 143}, 862 {:keyword1 18, :keyword3 0, :abstract "Stochastic optimization algorithms are commonly used to support planning for decision making on liberalized energy markets with regard to uncertain prices and demand. In practice their results need to be validated and, if necessary, adapted in a manual process. In operational decision making the time available to make a decision is rather short. The solution times for the optimization as well as the time needed to manually process those results must be adapted to fit into the given time interval. This paper concentrates on approaches to reduce the time needed to analyze optimization results and generate a decision on how to utilize the given portfolio. The idea is to change the operational optimization model to obtain results which can be processed manually in the short time available.", :title "Operative Decision Support in Natural Gas Portfolio Management on Liberalized Markets", :keyword2 0, :authors (29378), :session 131}, 863 {:keyword1 91, :keyword3 0, :abstract "Revenue Management (RM) is concerned with demand management decisions, facing a relatively fixed capacity. RM models take a transactional perspective, focusing on short-term profit maximization. In contrast to RM, Customer Relationship Management (CRM) focuses on customer relationships and thus on a firm’s long-term profitability. Both concepts interact: Marketing research findings indicate that a company's short-term allocation decisions (i.e. RM) affect customer satisfaction and loyalty and thus customer relationships in the long run.\r\n\r\nOur research addresses this interaction. We develop a quantitative approach that combines both RM and the idea of long-term profitability arising from CRM. In a first step, we analyze a two-period model in which the firm faces stochastic demand of two customer classes and decides about the protection level for the higher customer class in each of the periods. The periods are linked through the influence of the firm’s decision in Period 1 on customer demand in Period 2. We investigate how the impact on future revenues changes the firm’s optimal decision in Period 1. We also compare the performance of the optimal policy with a myopic policy which ignores the interrelation between the periods. In this way, we seek to provide insight into the interplay between RM and CRM.\r\n", :title "Coordinating Short-term and Long-term Performance of Revenue Management", :keyword2 56, :authors (29467 4229), :session 96}, 864 {:keyword1 54, :keyword3 100, :abstract "We introduce a protection problem for capacitated median systems that minimizes precautionary investments in reducing the impact of component failures on service and supply systems, and the expected operational costs after disruption. We assume that some probabilities on disruption occurrence are available. Then, a two-stage stochastic program is presented where in the first stage the amount of investments for protective measures is decided and specific protective actions take place. The recourse problem minimizes the overall travelling distance given a particular disruption scenario and the protective measures implemented in the first stage.\r\nWe define some independent random variables indicating the rate of nominal capacity reduction at each time period due to disruption and also some random variables that relate independent capacity based random variables from different time periods. This allows us to model the recovery of facilities gradually over time where the time required to restore facilities to the normal state depends on the magnitude of the disruption, hence, is uncertain. We also view system disruption as an unexpected increase in the request for service to some facilities if this increased demand cannot be satisfied with the nominal capacity of the involved facilities. We consider independent customer demand based random variables.\r\n\r\nThe resultant problem stands as a large scale stochastic problem hardly solvable via exact stochastic solution approaches such as the L-shape method or column generation. We solve the problem via Stochastic Decomposition, a statistical based decomposition method. We provide a computational study of the problem for some variations of the classical method and give some estimates on the quality of the solutions obtained. \r\n", :title "Minimizing strategic investments and operational costs in median systems subject to uncertain disruption types", :keyword2 85, :authors (6513), :session 221}, 867 {:keyword1 25, :keyword3 0, :abstract "With a spatial general equilibrium model of housing and labor markets for the city of Zuerich which takes explicit account of the structure of roadways and equilibrium commuting times, we analyze changes in the structure of the transport network (e.g. adding new nodes to the model illustrating brown-field expansion) and changes in the capital stocks for housing and employment.  The modeling framework exploits the complementarity formulation of the Wardropian traffic equilibrium model proposed by Ferris, Meeraus and Rutherford (1998). A multi-commodity representation of the traffic network is compact and efficient, as it does not, in contrast to pure transportation network models, require implicit or explicit enumeration of all paths between origin-destination pairs in the network which can be cleanly integrated with a complementarity model of economic decisions.  Furthermore, in contrast to pure transport models prices and demand for transport, employment and housing are endogenized. The model has two interacting components: a model which describes the different transport modes, routes and traffic flow given where people live and work, and a sorting model which describes where people choose to live and work.  Households can choose between the public and private transport network based on a logit demand formulation.\r\n", :title "Roads, Housing Prices and Compensating Wage Differentials in Zurich", :keyword2 61, :authors (29511 29993), :session 79}, 868 {:keyword1 66, :keyword3 66, :abstract "The characterization of Karush-Kuhn-Tucker (KKT) points by means of the well-known Kojima $PC^1$-mapping was the key to many theoretical and computational results for Nonlinear Programs. We propose an approach how to generalize these concepts to a general class of optimization problems. The main idea is to replace the KKT conditions by an abstract and, hence, more general (``topological'') stationarity concept which is motivated by Morse Theory, and, which coincides with the KKT conditions for the case of an NLP. The characterization of the corresponding stationary points by $PC^1$-mappings makes it possible to develop nonsmooth Newton methods and, moreover, aspects of stability and genericity can be analyzed in a very convenient way. We apply our approach to the following optimization classes: Mathematical Programs with Complementarity Constraints (MPCCs), Mathematical Programs with Vanishing Constraints (MPVCs) and Disjunctive Optimization Problems. For these optimization problems the topological stationarity concepts are well known: C-stationarity for MPCCs, T-stationarity for MPVCs and stationarity for Disjunctive Optimization. We introduce $PC^1$-mappings which characterize the latter stationarity concepts. As a result we obtain new nonsmooth Newton methods (NNMs) for all problem classes. For MPCC and MPVC we show that the nondegeneracy (which is a generic property) of a respective stationary point implies the local convergence of the NNM at a superlinear/quadratic rate. For MPCCs we show, furthermore, that the strong stability of a C-stationary point (under LICQ) is sufficient for the local (quadratic) convergence of our newly introduced NNM. All results can be seen as generalizations of known results for NLPs.", :title "A Constructive Approach to Newton Methods in Nonsmooth Optimization", :keyword2 57, :authors (26361), :session 73}, 869 {:keyword1 101, :keyword3 0, :abstract "Working capital management has emerged as an important topic from the recent credit crisis: companies were forced to reduce their assets to minimize their financing cost and maintain fair credit ratings. Companies typically pulled three levers for working capital reduction: (i) shifting inventories to suppliers, (ii) reducing credit days from customers and (iii) extending credit days to suppliers. Most of these changes were based on the bargaining power in each respective customer-supplier relationship, i.e. more powerful parties shifted working capital to their less powerful counterparts. However, from an end-to-end supply chain perspective this practice is not necessarily optimal since it ignores the individual financing cost of the different supply chain partners. Supply chain finance (SCF) is an approach that allocates working capital considering these costs. In this paper, we analyze the potential of supply chain finance based on 27.462 customer-supplier relationships between 1990 and 2010. We leverage firm-level data to understand working capital allocations and financing cost of the individual companies. We analyze the potentials of supply chain finance and test different hypothesis, regarding the relationship between inventory and weighted-average cost of capital.", :title "Bargaining Power vs. Collaborative Effort: Empirical Analysis of Supply Chain Finance Potentials", :keyword2 35, :authors (29434 29575), :session 226}, 870 {:keyword1 75, :keyword3 7, :abstract "Procurement of commodities often faces highly volatile prices. In many practical settings therefore a combination of a (long-term) capacity reservation contract and (short-term) spot market purchasing is used. Sourcing from the spot market is beneficial in case of low prices or insufficient reserved capacity, and the capacity reservation contract is used to protect against high spot market prices. In our contribution, we analyze the combined sourcing decision under stochastic demand and random spot market price fluctuations. Initially, a long-term binding decision has to be made regarding the reservation capacity level. Subsequently, in each period it is decided which quantities to procure from each source. The decision on capacity reservation has to take into account the later capacity utilization of each source which itself depends on the procured long-term capacity. Thus, we face highly complex interdependencies between the decisions. Modeling the decision problem as a stochastic optimization problem and analyzing properties of optimal procurement strategies yields that the optimal decisions are made based upon a simple three-parameter policy with a fixed order-up-to level for ordering from the long-term supplier and price-dependent order-up-to levels for short-term spot market procurement. The third policy parameter is the capacity reservation level. However, it is very cumbersome to numerically calculate optimal values of all policy parameters. To this end, we propose a fairly simple heuristic procedure to determine all parameters based on the solution of appropriately adjusted newsvendor problems and on results from a related simplified base stock policy. Finally, it is shown that our heuristic performs very well for a wide range of problem instances.\r\n", :title "A Heuristic for Dual Sourcing with Capacity Reservation and Stochastic Spot Market Prices", :keyword2 99, :authors (17039 2801 2238), :session 224}, 873 {:keyword1 28, :keyword3 0, :abstract "In an electricity grid the Transmission System Operator (TSO) is responsible for maintaining the physical balance between supply and demand of energy. This balance is ensured with the utilization of reserve energy, that the TSO acquires in a periodic auction. Bids in a reserve energy auction are placed as a combination of a demand charge, that covers the provision of the energy for the entire auction period, and an energy charge, that is refunded according to the actual energy consumption.\r\nA power utility, participating in a reserve energy auction, is facing a challenge of revenue maximization. When formulating this goal as an optimization problem several issues have to be taken into account. The specific cost structure of the power plant providing the reserve energy has an immediate impact on the overall revenue and therefore has to be considered carefully. Furthermore the bids are placed under uncertainty of the outcome of the auction and the actual consumption during the requested auction period. \r\nWe are presenting an approach for supporting an energy trader in the preparation of bids to a reserve energy auction. The difficulties mentioned above are addressed and additional requirements on the resulting bids by the energy trader can be considered.\r\n", :title "Decision Support in Reserve Energy Auctions", :keyword2 61, :authors (29515), :session 82}, 874 {:keyword1 42, :keyword3 0, :abstract "For a graph G=(V,E) a maximum cycle packing is a collection of pairwise edge-disjoint cycles. The maximum cardinality of such a packing is denoted as the cycle packing number of G. \r\nIn general the determination of a maximum cycle packing and the cycle packing number, respectively, is NP-hard.\r\nIn this lecture we consider the family of generalized Petersen graphs. We establish lower and upper bounds on the cycle packing number by using structural arguments for such graphs.\r\n", :title "Bounds on the cycle packing number for generalized Petersen graphs", :keyword2 16, :authors (29424), :session 229}, 875 {:keyword1 40, :keyword3 0, :abstract "An efficient points scoring system is often considered central to encouraging competition in a sport. It is also related to the viewership and spectator numbers crucial to any sport’s commercial success and long-term viability. As the market values of many sports have been on a sharp rise in the last couple of decades, so have numerous attempts to alter their scoring systems to maintain the public interest and ensure profitability. In particular, some studies have been carried out to assess the competitive impact of a shift from a 2-1-0 to a 3-1-0 system in soccer. They evidence that it has actually entailed adverse competitive effects and further aggravated the imbalance contrary to the declared intention. A vivid example of numerous changes in the points scoring system can be found in a popular motorcar racing competition Formula 1. Challenged by legislative changes in the advertising regulation and falling public interest, it was forced to look for new global sponsors as well as circuits in the emerging markets of Asia and the Middle East. Another attempt to reinvent the competition is related to two transitions in the scoring system in the last twenty years. From its inception in 1950, various rules have existed with respect to the number of races that counted towards the world championship, team (constructor) points, and points for the fastest lap. Eventually, the system settled on awarding points to the top six finishers (10-6-4-3-2-1) in 1991, only to be altered to eight scoring places (10-8-6-5-4-3-2-1) in 2003 and to ten places (25-18-15-12-10-8-6-4-2-1) in 2010. This paper analyzes the three points scoring systems of the last twenty seasons in Formula 1 (1991-2010) from a game theoretic perspective to verify if these changes have indeed improved competition.", :title "Points scoring systems in Formula 1: A game theoretic perspective", :keyword2 0, :authors (16808), :session 139}, 876 {:keyword1 77, :keyword3 0, :abstract "Dantzig-Wolfe Reformulation (DWR) is a widely used tool to solve Mixed Integer Programs (MIPs). It is mostly implemented ad-hoc and currently not yet seen as a general tool to solve arbitrary Mixed Integer Programs (MIPs); it is usually tailored to a given problem. We present a fully automated DWR algorithm which is able to perform DWR on arbitrary MIPs without explicitly available structural information and show that it performs well on a subset of instances of both the MIPLIB 2003 and the MIPLIB 2010. We explain how decompositions for arbitrary MIPs can be obtained by partitioning a hypergraph associated with the constraint\r\nmatrix of the problem. Further, we introduce new scores to rate decompositions in order to predict its quality before calculating the dual bound of the DWR. These scores can be computed easily for arbitrary DWR decompositions and are based on clues obtained from their visualization. From our experiments we deduce that visually appealing decompositions lead to better dual bounds. We discuss the conclusions drawn from this rather simple approach. With our approach, we enable also users not willing to implement a full Branch-and-Price framework benefit from the advantages of DWR. Furthermore, we elaborate both on extensions of the detection process as well as on implementational improvements of this integrated algorithm.", :title "Automatic Dantzig-Wolfe Decomposition", :keyword2 57, :authors (29178 30014 25257 14969 7400 30724), :session 210}, 878 {:keyword1 75, :keyword3 109, :abstract "Retailers strive for high product availability at low operational cost in a complex stochastic environment. The product availability has increased with the introduction of Automated Store Ordering (ASO) systems. These systems assist replenishment decisions, based on forecasting and inventory control models. To increase the efficiency of the operations, retailers have to focus now on transportation and handling processes. Aspects such as weekly demand patterns and in-store replenishment processes due to limited shelf space have a profound effect on the workload in the supply chain from retail DC to the stores. We derived fast approximations for the expected (backroom) inventory, the expected number of order lines and other relevant measures for each product in the store under given ASO parameters. With these approximations, we can optimize transportation and handling processes by changing the ASO parameters in a multi-product setting. We illustrate our approach in a case study involving a periodic delivery scheduling problem at a Dutch retailer.", :title "Optimizing transportation and handling costs by setting parameters for a replenishment system in a retail supply chain", :keyword2 101, :authors (3329 3330), :session 169}, 883 {:keyword1 94, :keyword3 0, :abstract "Energy supply routes to a given region are subject to random events, resulting in partial or total closure of a route (corridor). For instance: a pipeline may be subject to technical problems that reduce its capacity. Or, oil supply by tanker may be reduced for political reasons or because of equipment mishaps at the point of origin, or again by a conscious decision by the supplier in order to obtain economic benefits.\r\nThe purpose of this article is to formulate a simplified version the above issue that addresses mainly long term uncertainties. The formulation is done via a version of the TIAM-WORLD Integrated Model, modified to implement the approach of Robust Optimization for improving the security of supply to the European Energy system.\r\nThe first numerical results are interesting. They show that Robust Optimization leads to combine several actions in order to handle uncertainty: It decreases imports selectively, builds extra corridor (again in selective manner) and tends to equalize the market shares of the various corridors. ", :title "Energy Security: A Robust Programming Approach and Application to European Energy Supply via TIAM", :keyword2 29, :authors (29443 32762 2841), :session 125}, 886 {:keyword1 28, :keyword3 0, :abstract "A few years back, the Stadtwerke Kassel  shopped for an optimization based tool to support their tactical and strategic planning. Rather than purchasing one of the tools available on the market, they decided to commission the development of such a tool from scratch to get the closest match of their situation in an optimization model. A team of engineers, economists, modelers and software specialist with significant participation from the Stadtwerke build a prototype model within a few weeks. Rather than moving this prototype into a slick application, the rough but flexible prototype was used in production and part of the saved resources were spend on training the users. Since then the model has been used successfully and gets continuously updated to reflect changes in the way the Stadtwerke Kassel operate.", :title "A Planning Tool for a Municipal Utility Company", :keyword2 61, :authors (10542 29518), :session 77}, 887 {:keyword1 31, :keyword3 25, :abstract "In this research the embedded energy of products and services will be assessed for the Austrian economy using input output analysis. \r\nThe main driver for the production of goods and services is the demand for products of consumers. For the majority of production processes some kind of commercial energy input is needed. So we can conclude that consumption is also the main driver for energy needs. In other words, by consuming goods and services one also consumes (embedded) energy. Theoretically the whole demand for energy can be traced back to the demand for goods and services.\r\nHowever, most statistics relate energy demands to different industry sectors. Energy use from a private consumption perspective is only provided for direct energy services like electricity, heat or petrol. Here we will shed light on total energy use, which includes direct and embedded energy from a private consumption perspective. The embedded energy of products is derived from economic data linked with energy statistics using Input-Output analysis. Recently this method has been used to assess the carbon footprint of economies. Instead of linking the technology matrices with CO2 intensities we integrate energy demand of industries using a two region approach. For an aggregate of 57 product groups the embedded energy is assessed distinguishing between 20 energy carriers.\r\nSuch a perspective allows to estimate price effects of energy carriers on final goods and may help to establish environmentally orientated taxes or carbon allowance regimes. Data like that can also provide consumers with information on their total personal energy use which is a precondition for adjusting to sustainable consumption patterns.\r\n \r\n", :title "Assessing Embedded Energy with Input-Output Analysis - Results for the Austrian Economy", :keyword2 29, :authors (29514), :session 128}, 888 {:keyword1 13, :keyword3 0, :abstract "We show that the Hedge algorithm, a method that is widely used in Machine Learning, can be interpreted as a particular subgradient algorithm for minimizing a well-chosen convex function, namely as a Mirror Descent scheme. Using this reformulation, we establish three modificitations and extensions of the Hedge algorithm that are better or at least as good as the standard method with respect to worst-case guarantees. Numerical experiments show that the modified and extended methods that we suggest in this talk perform consistently better than the standard Hedge algorithm.\r\nRecently, Arora and Kale have introduced a more generalized Hedge algorithm, where the decision variables are symmetric matrices instead of vectors. We conclude this talk by outlining the computational challenges we face when we stick to the more general matrix setting.", :title "Reconstruction and extensions of the Hedge algorithm in the context of subgradient methods", :keyword2 124, :authors (19677 19615), :session 60}, 890 {:keyword1 106, :keyword3 74, :abstract "Since many companies concentrate on their core business fields today, non-core activities are often outsourced to external suppliers. Logistics services are one of the most outsourced activities. In order to reduce the transactional costs, a freight tariff agreement between the outsourcing company and logistics service providers is signed. Freights are then calculated based on such agreement for the performed transportation services depending on their quantities and distances. Due to economies of scale, it is beneficial for the outsourcing company to bundle their transportation tasks before releasing them to their logistics service provider. This problem is called Freight Consolidation Problem. In this contribution, we first present a mixed integer linear programming model for this problem. As a solution approach for large-scale problems, we developed a simulated annealing algorithm, which recursively divides the neighborhood into different branches and searches them simultaneously in a parallel fashion. To evaluate the performance of the proposed algorithm, test instances with different attributes are generated. Solutions found by the algorithm are compared with the optimal ones obtained by a commercial solver for small instances. For larger instances we compared the solutions with those obtained by a tabu search heuristic developed by the authors previously. The results show that the proposed simulated annealing algorithm is effective and can provide reasonable solutions within an acceptable computational time.", :title "A new simulated annealing algorithm for the freight consolidation problem", :keyword2 59, :authors (29454 29527 17524 15277), :session 85}, 891 {:keyword1 8, :keyword3 54, :abstract "In this talk, we consider the classical 1-median problem in the d-dimensional space with the Chebyshev-norm.  Given n points with positive weights, find a point that minimizes the sum of the weighted distances to the given points.\r\nFor a long time this problem was only well understood in two dimensions. In this special case the  Chebyshev-norm and the Manhattan-norm are closely related and an algorithm for the 1-median problem with the Manhattan-norm is known.\r\nWe focus on higher dimensions and  state the first combinatorial algorithm and an optimality criterion for this location problem.\r\n\r\nFurthermore, we discuss the corresponding inverse problem where\r\na location of the facility is already given and the task is to modify\r\nthe weights of the clients  at minimum cost such that the given facility is\r\noptimal with respect to the modified instance.\r\n\r\nIn turns out that this problem can be transformed to the following parametric flow problem.  Let G be a directed graph with a source and an even number of sinks where the sinks are paired in groups of two sinks each. Moreover, we have some capacities on the edges of the graph.\r\nFinally, we call a flow f in G perfect if two sinks that form a pair have the same excess with respect to f. The  task is to find a maximum perfect\r\nflow.\r\n\r\nFinally, we discuss a combinatorial algorithm for this maximum perfect flow problem which gives us a method for solving the inverse 1-median problem with the Chebyshev-norm.", :title "A Parametric Flow Problem and its Application in Location Theory", :keyword2 42, :authors (23827), :session 206}, 892 {:keyword1 93, :keyword3 34, :abstract "This study considers portfolio selection problems in which risk is\r\nmeasured using Value-at-Risk (VaR), the most popular measure of \r\nrisk in financial industry.  Because VaR is generally a\r\nnonconvex and nonsmooth function, conventional optimization\r\nmethods fail to solve portfolio optimization models with VaR included. \r\nThis has been considered an open problem since the 1990's. \r\n\r\nThe study employs the scenario simulation method in evaluating VaR, \r\nand proves that VaR estimated with this method is a continuous \r\npiecewise linear function.  And then, we propose a method to solve \r\nVaR minimization models by using LP techiques. The proposed method can yield a good local minimum, or even a global optimum although it \r\nhas no theoretical guarantee. Because the proposed method uses only \r\nLP techniques, common LP solution software can be employed to solve \r\nVaR minimization models of practical sizes in a short period of time.\r\n\r\nTo illustrate the performance of the proposed method, we use it to\r\nsolve a VaR minimization model with 30 equities and 1000 scenarios.\r\nWe also compare the precision and computing time with another method. \r\nThe results show that both methods can yield the optimal solution, but \r\n the proposed method is much faster.\r\n\r\n", :title "Solving VaR Minimization Models with LP Techniques", :keyword2 67, :authors (29455 29551 29536 29553), :session 217}, 893 {:keyword1 88, :keyword3 0, :abstract "In the analysis of steady-state queues it is assumed that the system parameters are static. However, in reality queueing systems are often characterized by a dynamic behavior. Thus the arrival and processing rates can be time-dependent and the number of servers can vary over time. Therefore, when considering production or service systems, it is often very important to analyze the time-dependent development of the performance measures to gain reliable information about the system.\r\n\r\nThis work focuses on giving deeper insights in the dynamic behavior of queueing systems. Thereby the main focus lies on the effects that arise when considering time-dependent arrival rates, for example the end-of-day behavior of a queue, when the arrival rate abruptly decreases to zero.\r\n\r\nDifferent approaches for the derivation of the time-dependent waiting time in an M/M/c-queue are discussed to evaluate the end-of-day performance. Furthermore the reliability of the common used fluid approach, the stationary independent period-by-period approach (SIPP), and the stationary backlog carryover approach (SBC) is shown in a simulation study.\r\n", :title "Analyzing the dynamic behavior of queueing systems", :keyword2 0, :authors (29469 10255), :session 163}, 895 {:keyword1 8, :keyword3 42, :abstract "We present a framework for approximating the metric TSP based on a\r\nnovel use of matchings.  For the TSP on graphic metrics (graph-TSP),\r\nthe approach yields a 1.461-approximation algorithm with respect to\r\nthe Held-Karp lower bound. For graph-TSP restricted to a class of\r\ngraphs that contains degree three bounded and claw-free graphs, we\r\nshow that the integrality gap of the Held-Karp relaxation matches the\r\nconjectured ratio 4/3. The framework allows for generalizations in a\r\nnatural way and also leads to a 1.586-approximation algorithm for the\r\ntraveling salesman path problem on graphic metrics where the start and\r\nend vertices are prespecified.\r\n\r\n\r\nOur framework is based on earlier works by Frederickson & Ja'ja' and\r\nMonma, Munson & Pulleyblank, who related the cost of an optimal tour\r\nto the size of a minimum 2-vertex-connected subgraph. In retrospect,\r\nthe main novelty of our approach compared to theirs and others is the\r\nuse of matchings. Traditionally, matchings have been used to add edges\r\nto make a given graph Eulerian whereas our framework offers a\r\nstructured way to specify a set of edges that safely may be removed\r\nleading to a decreased cost.  We then present a way to find such a set of\r\nremovable edges by using network circulations and obtain the main\r\ningredient of our algorithmic results.\r\n\r\nThese results are submitted for printed proceedings elsewhere and is\r\nthus not amenable to be published in the post-conference proceedings.\r\n", :title "Approximating Graphic TSP by Matchings", :keyword2 10, :authors (29526 29130), :session 203}, 896 {:keyword1 126, :keyword3 0, :abstract "Many industrialized countries face fertility rates below the replacement level, combined with mortality decline, especially in older ages. Consequently, the populations of these countries have started to age. \r\nOne important indicator of age structures is the dependency ratio which is the ratio of the nonworking-age population to the working-age population. A low dependency ratio indicates that there are proportionally more adults of working age that can support the young and old.\r\nIn this paper we find the age-specific immigration pattern that minimizes the dependency ratio in a stationary population through immigration.\r\nWe consider two different scenarios. First, we fix the total number of people who immigrate to the country. Alternatively, we prescribe the total size of the receiving country's population. For both cases we set up optimal control models and make use of Pontryagin’s maximum principle. We show that the optimal immigration profile in both setups is of bang-bang type switching from one age-specific limit for immigration to the other. \r\nFor the first scenario we prove that additional to younger ages the optimal immigration profile also equals the age-specific upper bound for immigration for ages on every interval arbitrarily small and containing the upper age limit. \r\nThe optimal solution of the second model formulation equals the upper bound for immigration on at the most two separate intervals to the left of the retirement age and is on the lower bound elsewhere. \r\nFor either case we provide numerical results for the optimal immigration profile and for the resulting age-structure of the population, as well as for the dependency ratio. \r\n", :title "Minimizing the Dependency Ratio in a Population with Below-Replacement Fertility through Immigration", :keyword2 14, :authors (29259 39239 30019), :session 198}, 897 {:keyword1 8, :keyword3 42, :abstract "Vehicle rotation planning for long distance passenger railways is a fundamental problem in rail transport. It deals with the allocation of vehicles to trips in a cyclic weekly schedule. Its result is an assignment of each trip to a follow-on trip which will be serviced by the same vehicle.\r\n\r\nTo take so-called regularity, which is an important requirement, into account, vehicle rotation planning can be modeled as a hyperassignment problem. This is a generalization of the assignment problem to directed hypergraphs we proposed.\r\n\r\nWe proved that the hyperassignment problem is NP-hard for the practically relevant cases and that the canonical integer linear programming (ILP) formulation results in large integrality gaps and arbitrarily high basis matrix determinants. \r\n\r\nOur main contribution so far is an extended ILP formulation, which provably implies important classes of inequalities, e. g.,\r\nall clique inequalities. Clique inequalities are of great importance, because as calculations with practical data, which we will present, show they highly reduce the LP-IP gap. The extended formulation can be solved by\r\ncolumn generation. We proposed fast combinatorial algorithms for the pricing subproblem.", :title "Minimum Cost Hyperassignments with Applications to ICE/IC Rotation Planning", :keyword2 121, :authors (29520 14923), :session 209}, 898 {:keyword1 75, :keyword3 0, :abstract "We consider single item, single echelon, spare parts networks that consist of one central warehouse, multiple local warehouses and multiple customers. The inventories are controlled by base stock policies. Customers have service contracts that specify the maximum response time in\r\ncase of a demand for a spare part. Demand can be fulfilled from every local warehouse with stock at hand and from the central warehouse using an expensive emergency shipment. If a part request cannot be fulfilled within contract time, a high penalty cost is incurred. \r\nOur objective is to minimize the sum of average annual delivery cost and average annual penalty cost.\r\nWe propose a new allocation policy that belongs to the class of rollout algorithms. Our rollout algorithm uses a simple static allocation rule as base policy. We approximate the differential cost vector associated with the base policy by estimating the transient network flow for arbitrary\r\nactual stock level vectors.\r\nIn numerical experiments we compare our proposed allocation rule with the optimum allocation rule and the static allocation rule. Results show that our dynamic allocation rule has a small optimality gap and leads to cost reductions of more than 10% for a wide range of problem instances.", :title "Real-time demand allocation in spare parts networks via rollout algorithms", :keyword2 126, :authors (17501 4229 2052 3589 12769), :session 224}, 901 {:keyword1 18, :keyword3 0, :abstract "This paper introduces a method to dynamically schedule a Speed Dating event in order to minimize the maximum waiting time of participants.\r\n\tSpeed Dating events aim to allow men and women to meet each other over a series of short dates, lasting 5 to 7 minutes. Each woman is assigned to a unique table during the whole event. At the end of each date, men move on to the next date. At the end of the event, participants submit to organizers a list of who they would like to provide their contact information to. If there is a match, contact information is forwarded to both parties.\r\n\tWhen it comes to reality, this ideal organization could not apply anymore: some participants already know each other and do not want to meet again. Moreover, the number of men and women may not be equal, which means that participants may have to wait. Besides, lateness and call off make the problem dynamic. Because of this complexity, simple rotations are not effective if we want to minimize the waiting time of participants.  It means that participants have to be lead by organizers either to their next meeting or to the waiting place. In order to make the transition step as smooth as possible, organizers reduce the possible moves of men by allowing only simple moves, following a move policy.\r\n\tWe propose a method based on constraint programming in order to solve this problem. First results, performed on real data, show that our tool simplifies the scheduling task and reduces the maximum waiting time of participants. Besides, we compare various move policies so that organizers could knowingly choose which move policy is better. First conclusions show that the constraint programming model easily reaches a good solution, but requires quite a high computational time to conclude about optimality.", :title "Scheduling of a Speed Dating event", :keyword2 23, :authors (29504 22893 4910), :session 51}, 907 {:keyword1 19, :keyword3 42, :abstract "Many recent applications in areas like bioinformatics, image recognition, network analysis and web content mining rely on graphs to capture and model information. The increasing popularity of graphs as fundamental data structures is due to their inherent flexibility in modeling not only information and concepts, but also their structure. This has led to the development of new research avenues that focus on how to efficiently store, search and query graphs.\r\n\r\nFor the end-user, graphs are nonetheless complex entities whose analysis is cognitively challenging. The practical usage of graphs as data structures calls for the development of recommendation and decision support systems that build upon a measure of adequacy or usefulness of graphs. To this purpose, we first introduce and define the concept of “graph utility”. As the direct specification of utility functions is itself a difficult problem, we explore the problem of learning utility functions for graphs on the basis of user preferences that are extracted from pairwise graph comparisons.\r\n", :title "Learning utility functions from preference relations on graphs", :keyword2 124, :authors (29158), :session 256}, 908 {:keyword1 91, :keyword3 0, :abstract "Based on EU legal standards, reporting requirements on corporate governance have considerably increased in scope over the last few years. These legal standards have been adopted into national law by the EU member states. Furthermore, national Corporate Governance codes add to concrete reporting requirements, for example the Austrian Code of Corporate Governance (OeCGK) or the German Code of Corporate Governance (DCGK). Both provide principles of remuneration systems of the management board and specify the content of the Corporate Governance Report concerning the remuneration system.\r\nThe remuneration shall contain fixed and variable components. The variable remuneration components are of considerable importance for such designs of management board compensation systems. Regularly, the calculation of the variable components is linked to the corporate management target systems, and thus in many cases is based upon internal management control systems. Consequently, compensation systems represent close interaction between external and internal accounting. This interaction will be analysed, with special focus on the development of the structure of the compensation of the management board (fixed/variable components; bases for variable components). The analysis is based on recent annual reports of selected publicly traded companies.\r\nAs a result, the following questions will be answered: In how far are management control systems of importance for external reporting on management compensation? Are there effects of requirements concerning external reporting on compensation systems, and thus consequently on management control systems that serve as bases? \r\n", :title "Management control systems and reporting requirements of remuneration systems for the management board", :keyword2 55, :authors (29398 29530), :session 89}, 910 {:keyword1 100, :keyword3 0, :abstract "This paper treats the strategic behaviour of medical universities / faculties in Germany, Austria, and Swiss. Especially, it concentrates on the planning, performance measurement systems, the policy instruments and in particular the possible use of the Balanced Scorecard. Due to legal requirements in Austria, intellectual capital reports were added to possible strategic management tools whereas the differentiation between Balanced Scorecard and intellectual capital report in regard to their concepts and their future relevance was stressed. \r\n\r\nFirst, existing Balanced Scorecards from the literature and practice have been studied to reveal possible applications for medical universities / faculties. Second, a full sample survey including all German, Austrian, and Swiss medical universities / faculties was conducted in December 2010. The response rate was 40%. The questionnaire included sections on planning, strategy and implementation, indicators, and general statistics. \r\n", :title "Balanced Scorecard  – A strategic tool for medical universities and faculties?", :keyword2 0, :authors (29436), :session 95}, 911 {:keyword1 59, :keyword3 0, :abstract "In vehicle routing problems where the ratio of driving time to service\r\ntime is low, increasing distribution efficiency may require adding\r\nmultiple deliverymen per vehicle. These additional workers shorten the\r\nservice time allowing to construct routes that would otherwise violate\r\nrestrictions of working hours. The approach of permitting additional\r\nworkers is of particular importance in the presence of service time\r\nwindows as reduced service times may enable the combination of nearby\r\nnodes with overlapping time windows.\r\n\r\nBuilding on prior work of Pureza et al. (2011) we implement an ACO\r\nalgorithm for the VRPTW with multiple deliverymen (VRPTWMD) to\r\ninvestigate the effect of assigning different numbers of workers when\r\nbuilding the solution. This is critical as the solution quality of ACO\r\nheuristics is highly dependent on the quality of the solution\r\nconstruction mechanism. The TS and ACO algorithms for the VRPTWMD\r\nproposed in Pureza et al. (2011) were based on different adaptions of\r\nSolomon's I1 heuristic. This leads to difficulties in making specific\r\nstatements about the performance implications of the algorithms'\r\ncomponents.\r\n\r\nThus, the aim of this research is to systematically evaluate the\r\nbenefits of different strategies with regard to service workers when\r\nconstructing the solution. The results are tested against instances\r\ngenerated from a set of classic examples and compared in terms of\r\ncomputation time and solution quality.", :title "ACO for the VRPTW with Multiple Deliverymen", :keyword2 0, :authors (29525 9703), :session 85}, 913 {:keyword1 106, :keyword3 0, :abstract "A classical problem in transportation is a combined format problem involving several types of transportation such as truck and train that operate on both flexible and fixed schedules. This is the intermodal transportation problem: a problem closely related to Less-Than-Load transportation where consolidation points are required in the transportation network with the side constraint that multiple types of equipment may be operated within the network.\r\nWe consider an intermodal transportation problem that also incorporates the problem of equipment selection. This problem is inspired by the requirements of a leading European construction group currently delivering a product from a handful of factories via a trucking network to several destinations. The company is considering opportunities to expand the network to an intermodal transportation network by adding rail and/or barge links as well as buying the necessary equipment. \r\nWe model this network design problem as a capacitated multi-commodity network flow problem, with flow variables creating a distribution schedule from factories to destinations such that demands at the destinations are satisfied. Flow variables are binary, ensuring that flow cannot be split. The resulting model is large scale due to the time step; has weak bounds due to the flow bundling constraints; and also contains SOS1 constraints. To address these issues, we propose a reduction preprocessing approach and a branch-and-cut step to improve the bounds. We exploit the structure created by the time step and SOS1 constraints to generate a Benders decomposition approach that elicits a 2-stage stochastic programming solution.", :title "Models and Algorithms for Intermodal Transportation and Equipment Selection", :keyword2 0, :authors (22160 24616), :session 191}, 917 {:keyword1 122, :keyword3 0, :abstract "The competitive environment of manufacturing companies is characterized by rising innovation dynamics, shorter product life cycles as well as diverse customer requirements. To keep up with its competitors, companies are forced to expand their product portfolio which leads to increasing product variety. Besides positive effects such as an increase in turnover or the acquisition of new customers, the diversity of product variants leads to considerable changes in cost structures. Benefits and costs of product variants have to be balanced out to ensure company's competitiveness. The purpose of our research is to examine an ANP based framework to evaluate the performance of different product variants in terms of benefits and costs. This evaluation supports strategic decision making on condition of reducing product diversity. The framework, developed for small/medium manufacturing enterprises, was examined in an industrial case study in a German metal processing company by using the Super Decisions software. ", :title "Benefit-cost evaluation of product variants using Analytic Network Process", :keyword2 0, :authors (24131 29535 24295), :session 261}, 920 {:keyword1 48, :keyword3 0, :abstract "Checking the feasibility of gas transportation orders between entries and exits in a\r\ngas network is a recurring task in gas transportation companies. The issue is to\r\nfind an operation plan for the active elements of the network (valves, control\r\nvalves, compressors) meeting operational constraints and adhering to the physics of\r\ngas flow. For the stationary case, we present a heuristic for making these\r\noperational decisions. A key component of the heuristic is  to eliminate flow\r\nvariables from the nonlinear system of flow conservation and pressure drop\r\nconstraints. The method employs standard solvers in its NLP parts and allows to\r\ncheck feasibility in real-world meshed gas networks.", :title "A heuristic method to check feasibility in real-world gas transportation networks", :keyword2 0, :authors (24343 9512), :session 76}, 922 {:keyword1 61, :keyword3 0, :abstract "Motivated by examples from different industries, including portfolio and airline optimization, this talk discusses step-by-step the design choices for optimization applications: after the initial choice among different types of modeling systems and architectural issues, we shortly review possibilities for problem decomposition and concurrent solving with hints at their ease of implementation. We further comment on the role of visualization of input data and intermediate results during development, and user interaction with the application, including during the solving process. ", :title "Optimization application with XPRESS-Mosel using distributed computing", :keyword2 0, :authors (10087), :session 77}, 923 {:keyword1 76, :keyword3 0, :abstract "We present an Approximate Dynamic Programming method for Stochastic Linear Control Problems with piecewise linear and convex cost structure. The method is based on parametric dynamic programming using convex piecewise linear approximations of the differential cost function in approximate relative value iteration steps. The obtained differential cost approximation not only defines a policy that performs well in practice, it also yields valid lower bounds for the optimal infinite horizon average cost per stage. These lower bounds can be used to judge the quality of the greedy policy corresponding to the approximated differential cost function or any heuristic policy for a particular problem. We prove that the sequence of lower bounds resulting from the approximate relative value iteration steps is monotonously increasing. \r\n\r\nWe apply the developed technique to inventory management problems with multiple suppliers and stochastic demands and lead times. These problems could be solved using exact dynamic programming methods, but this is computationally too expensive for most realistic settings. For scenarios that can be solved to optimality by dynamic programming, our approach typically finds an optimal solution, as well. For bigger scenarios, where the optimal solution is unknown, the policies resulting from the developed approximation method performed very well, and were better than all state-of-the-art heuristics we considered. Using the computed lower bound of the optimal average costs, an upper bound of the optimality gap can be given.", :title "Approximate Parametric Dynamic Programming applied to Inventory Management", :keyword2 101, :authors (29534 17127 17063 24762 12769), :session 169}, 928 {:keyword1 96, :keyword3 59, :abstract "We consider an integrated sequencing and scheduling problem arising at filling lines in dairy industry. Even when a processing sequence is decided, still a scheduling problem has to be solved for the sequence. This incorporates typical side constraints as they occur also in other sequencing problems in practice. We propose a framework for general sequencing and scheduling problems which has already been successfully used for the planning of coil coating lines in steel industry: A genetic algorithm is utilized for the sequencing, incorporating a problem specific algorithm for the fixed-sequence scheduling. In this talk, we investigate how this approach performs for filling lines.  Based on insights into structural properties of the problem, we propose different scheduling algorithms. In cooperation with Sachsenmilch GmbH, the algorithm was implemented for their bottleneck filling line, and evaluated in an extensive computational study. For the real data from production, our algorithm computes almost optimal solutions. However, as a surprising result, our simple  greedy algorithms outperform the more elaborate ones in many aspects.", :title "Sequencing and Scheduling for Filling Lines in Dairy Production", :keyword2 8, :authors (17125 29468 20420), :session 163}, 929 {:keyword1 85, :keyword3 108, :abstract "We formulate  two-stage stochastic programming models for shape optimization of elastic bodies subject to random forces. Here the shape itself takes the role of the nonanticipative first-stage decision, and the second-stage optimization problem is given by the weak formulation of the elasticity partial differential equation. Exploiting analogies from finite-dimensional stochastic programming we discuss risk neutral and risk averse models. We present solution methods and report some computational results.", :title "Shape Optimization under Uncertainty  from Stochastic Programming Perspective", :keyword2 93, :authors (9512), :session 117}, 930 {:keyword1 86, :keyword3 0, :abstract "We consider the stochastic resource-constrained project scheduling problem (SRCPSP) where the duration of activities are stochastic and the expected makespan is minimized. We propose an estimation of distribution algorithm (EDA) for the SRCPSP. EDA employs a probability model in order to generate activity lists which are then mapped into a schedule with a resource-based scheduling policy. Based on well-known test instances from the literature we investigate on the performance of EDA compared to other heuristics which have been proposed for the SRCPSP. Furthermore, we present insight on the impact of different problem parameters on the performance.", :title "Stochastic Resource-constrained Project Scheduling - A New Solution Approach and Experimental Insight", :keyword2 99, :authors (29540 829), :session 50}, 931 {:keyword1 95, :keyword3 0, :abstract "Modern mobility is more and more focused on multi-modal routes. City dwellers tend to use several transport modes for their daily trips, not only public transport but also bike-sharing systems such as Vélib' in Paris. These modes have their own advantages and drawbacks, this is why multi-objective path-finding algorithms are relevant tools to plan routes in average and large cities. Our application is based on geospatial data: road network (for pedestrians and cyclists), underground and bus schedules. First, we will present a graph model aggregating this data. We also propose a set of objectives to represent the needs of travelers, such as distance, safety (while cycling), and number of transport changes. To compute multi-objective routes, we use an a priori approach, known as Best Compromise A* or BCA*, introduced by Futtersack and Perny. This is a label-correcting algorithm, which principle is similar to the mono-objective A* algorithm. BCA* relies on heavy pre-processing, to compute the lower bound from every node to the destination and an ideal solution, by computing mono-objective paths from the destination from the source. This pre-processing guides the algorithm straight to the solution. We will see how to adapt BCA* pre-processing to the multi-modal context. In particular, the lower bound computation cannot be used as-is from a node to the destination, since the time to reach the destination is not known in advance. A naive approach for lower bound would be ignoring transport schedules, thus we assume there is no transfer time. Better estimates can be obtained by computing the minimum time to change between different transport routes. We will present other techniques to get more efficient lower bounds, and measure the influence of lower bounds.", :title "Best compromise approach for multi-modal multi-objective route planning.", :keyword2 42, :authors (24726 29361 24802), :session 207}, 935 {:keyword1 80, :keyword3 0, :abstract "The problem of solving a system of equations, possibly subject to convex\r\nconstraints, appears in several applications. For example,\r\nKarush-Kuhn-Tucker conditions are frequently written in this way.\r\n\r\nA new iterative framework is presented whose subproblems are linear programs.\r\nLocal superlinear convergence results of the framework are derived under\r\nan error bound condition. This enables the application to problems with\r\nnonisolated solutions. Moreover, new conditions are presented to study the\r\nlocal convergence of the framework for nonsmooth equations as well.", :title "A New Successive Linear Programming Framework for Constrained Smooth and Nonsmooth Equations", :keyword2 14, :authors (10013 17041 29253), :session 57}, 937 {:keyword1 2, :keyword3 0, :abstract "Operating an airport efficiently is nowadays unimaginable without sophisticated resources management systems that optimally utilize the limited resources at reasonable costs. \r\nBesides scheduling infrastructure and equipment, personnel staffing is a major domain here.\r\nWe consider the problem of finding an appropriated number of open check-in counters over the week. The problem has to take into account the flight plan, the arrival patterns of passengers and a given service level (max. waiting time of a passenger before being served). The goal is to generate a schedule for the check-in counters that uses as few as possible check-in counters per time. \r\nCheck-in counter schedules are typically highly irregular. Passengers arrive at the airport some time ahead of take off. That forerun depends on service class (business vs. tourists), day (week vs. weekend), or destination (long haul vs. domestic flights). Train connections can imply passenger waves arriving e.g. every 20 minutes, etc. Flight operations, on the other hand, typically conglomerate at some peak times (morning and evening). All in all, the number of passengers and thus the time and personnel needed to serve these passengers is highly volatile. In order to reduce costs it is thus desirable to smooth the demand by making use of the allowed service level.\r\nWe present a network flow formulation for this problem and discuss additional constraints relevant for real-world scenarios. We show how to solve the model and present numerical results on real-world data. \r\nThe model is part of the Inform GroundStar suite that successful is in use on more than 200 airports world-wide. GroundStar is an integrated resources management system to optimize all planning and control processes in aircraft handling at airports.\r\n", :title "Check-In Counter Planning via a Network Flow Approach", :keyword2 42, :authors (29388), :session 77}, 939 {:keyword1 54, :keyword3 33, :abstract "This paper evaluates the locations of flow-capturing facilities on a railway network from multiple objectives. The flow-capturing location problem (FCLP), originally proposed by Hodgson, aims to locate a given number of facilities on a network in order to maximize   flows which contain at least one facility along their pre-planned routes. Various studies have been made to extend the original FCLP. So far, most models of FCLP and their applications assume a situation to capture traffic flow on a road network. The flow-capturing framework is also applicable to capturing flows travelling along railway network and thus, developing a model to incorporate characteristics of railway flows is important. Also, most FCLP models assume a single objective and evaluation of the locations of flow-capturing facilities from multiple points of view have not been sufficiently addressed so far. We generate several solutions which perform well in terms of the original FCLP objective and evaluate these solutions from various other objectives. As one important characteristic for railway flows is that facilities located at the origin station, the destination station and transfer stations are more easily accessible than facilities located at stations passed by. The amount of flows having a facility at these stations is an important measure we employ to evaluate a given solution. We apply the model to the analysis of locations of flow capturing facilities on the railway network of Keio Railway Company using census data conducted in 2000 for commuter traffic in Tokyo Metropolitan area.", :title "Evaluating locations of flow-capturing facilities on a railway network from multiple objectives", :keyword2 106, :authors (6938 20142), :session 221}, 942 {:keyword1 106, :keyword3 8, :abstract "In global logistics operations, strategic and tactic planning aims at laying the groundwork for cost-efficient day-to-day operation by deciding on transport modes, routes, and delivery frequencies between facilities in the network. Large shipments usually yield lower per-unit shipping cost, while high delivery frequencies reduce capital commitment and storage cost. This crucial tradeoff encourages the consolidation of shipments, which may take place spatially by combining goods at hub locations, and temporally by accumulating goods over time for shipping.\r\n\r\nWe propose a transportation model for strategic and tactic logistics planning taking into account spatial and temporal consolidation effects, while being able to represent tariff schemes commonly used in practice. For this model, we present a broad set of heuristics combining well-known combinatorial concepts such as network flows, shortest paths, network design, and packing. To evaluate the quality of these approaches we present a computational study on a set of large-scale real-world instances provided by our industrial cooperation partner 4flow. Our results also comprise lower bounds obtained from using mixed integer programming techniques.\r\n\r\nThe model and the obtained results are part of the MultiTrans project, a cooperation between the COGA group at TU Berlin and 4flow AG, a market leader in logistics and supply chain management consulting.", :title "A Fixed-Charge Flow Model for Strategic Logistics Planning with Delivery Frequencies", :keyword2 42, :authors (26508 26518 17134 14976), :session 191}, 943 {:keyword1 63, :keyword3 14, :abstract "The trade-off concept in multiple criteria decision making (MCDM) refers to ratios between changes of different outcomes when moving through the set of efficient (e.g. Pareto optimal) outcomes. Decision making techniques usually operate two types of trade-off information: objective trade-offs describe inherent properties of the problem's efficient outcome set, while subjective trade-offs represent decision maker's (DM's) judgment to the relative importance of criteria. We propose an approach to handle preferences based on local trade-offs, to be applied in interactive MCDM methods for continuous problems. Our approach utilizes trade-offs of both types to form a complete learning cycle: the DM is informed about trade-offs for a given efficient outcome (DM learning) and in its turn, presents partial information about preferences in terms of subjective trade-offs (computer learning). The scheme of handling preferences concerns one iteration of the interactive decision making process:\r\nIn the beginning, an efficient outcome is given. The DM is informed about all local partial trade-offs at the outcome, for any criterion which can be improved. If the DM does not find any changes reasonable, the procedure stops. Otherwise, the DM selects a criterion to be improved and, after analyzing objective trade-off information related to this improvement, presents his/her own preferences in terms of acceptable trade-off ratios.\r\nThen the direction of outcome changes is searched in the efficient outcome set such that the local directional trade-offs are proportional to ones presented by the DM. The projection of this direction to the efficient outcome set (a curve in the outcome space) is presented to the DM for interactive exploration and choosing the next efficient outcome.\r\n", :title "An approach to handling preferences based on local trade-off information in interactive MCDM methods", :keyword2 79, :authors (6600 29550), :session 254}, 944 {:keyword1 74, :keyword3 0, :abstract "Mixed integer programs (MIP) are typically solved with a branch-and-bound approach. Tree search algorithms are natural candidates for parallelization. The question, however, how to design communication efficiently with respect to the specific requirements of MIP, is an active field of research. In this paper, we present a so-called Ubiquity Generator (UG) framework which enables sequential MIP solvers to be run in parallel from the outside of the solver. This approach works for both, distributed memory systems, using MPI, and shared memory systems, using a multithreaded parallelization.\r\n\r\nAs a test engine, we use SCIP, a state-of-the-art non-commercial MIP solver. Currently, SCIP does not employ parallelization. Using the UG framework, we implemented FiberSCIP, a multithreaded environment for SCIP, and ParaSCIP, an MPI-process parallel SCIP. In this presentation, we focus on FiberSCIP.  The main advantage of shared memory is that bigger data transfers can be handled more efficiently, thereby allowing more communications between parallel solvers.\r\n\r\nUsing FiberSCIP, the effect of transferring local cuts, conflict constraints, and branching history information, will be studied.  Computational experiments will be conducted on the MIPLIB2010 benchmark test set. The UG framework is designed for a large-scale parallelization of MIP solvers. ParaSCIP has been tested on up to 7,000 cores. The computational results shall give us an insight how to weigh of the impact of transferred information versus the communication overhead in large-scale parallelization.", :title "Computational experiments with FiberSCIP - a multithreaded MIP Solver", :keyword2 77, :authors (29543 16880 23876 29546 29547), :session 227}, 946 {:keyword1 106, :keyword3 8, :abstract "Systems of rail-mounted vehicles play a key role in many logistics\r\napplications, and the efficiency of their operation frequently has a\r\nsignificant impact on the overall performance of the surrounding\r\nproduction environment. In theory, assigning transport requests to\r\nthe vehicles of such systems and scheduling their execution amounts\r\nto finding k tours on a common line, where tours may never cross\r\neach other in time - dynamic collision constraints need to be\r\nrespected. The goal is to minimize the makespan for a given set of\r\ntransport requests.\r\n\r\nWe establish a model capturing the core challenges in transport\r\nplanning problems of this type and relate it to other models in\r\nliterature.  \r\n\r\nBeside proving NP-hardness for a basic version of the\r\nproblem and some significant insight about its structure,\r\nan important part of the talk is dedicated \r\nto devising various fast heuristic algorithms suitable for practice.\r\nWe present computational results regarding the performance of the algorithms\r\n\r\nproposed for several classes of problem instances.", :title "1D vehicle scheduling with conflicts", :keyword2 96, :authors (29468 17134), :session 209}, 948 {:keyword1 41, :keyword3 0, :abstract "We consider polynomials in an arbitrary number of variables which frequently occur in all kinds of optimization problems. Polynomials are used in economic models, in financial mathematics as well as for empiric description of complex systems. Even though the properties of polynomials are well understood, it can be hard to find the minimizer of an polynomial of high order. A common problem is to determine bounds for the range of polynomials. These bounds can be used for optimization (e.g. as relaxation of a direct search method) or they can help to identify regions of the feasible set where the function values satisfy certain conditions (e.g. function value above or below a certain level). For those problems we introduce two approaches which generate lower and upper bounds of multivariate polynomials over an n-dimensional box. These strategies differ in accuracy and complexity of calculation. The first method is based on the estimation of the contribution of the polynomial's summands, while the second one uses an expansion into Bernstein polynomials to obtain a convex envelope which yields the desired bounds. Two hyperplanes which enclose the polynomial's graph can be derived from the convex envelope. They increase the quality of the bounds. The mentioned approaches work both for univariate and multivariate polynomials and are enhanced to rational polynomials. We apply the methods to an academic example from literature as well as to an real-world problem which occurs in the development process of vehicle transmissions. In this example, a system of equations with inherent parameters is transformed into a polynomial and the obtained description is optimized with the help of lower and upper bounds.", :title "Range Approximation of Multivariate Rational Polynomials used in Global Optimization", :keyword2 80, :authors (16918), :session 195}, 950 {:keyword1 106, :keyword3 8, :abstract "Recent innovations of SBB (Swiss Federal Railways) are pointing towards an adaptive, centralized control of trains in their network. The goals are energy savings and improved capacity usage. As part of this project we design a framework for dispatching trains inside a main station area. The framework is based on dynamic model predictive control, i.e. trains predicted to enter the area inside a given time horizon are dispatched. The time horizon is iteratively moved forward with a frequency of one minute, thereby dispatching trains for a whole day. In each computation step a new assignment problem has to be solved: To each train a so called blocking stairway based on a variety of alternative track routes, station platforms, speed profiles and arrival or departure times has to be assigned. The objective is to minimize a weighted sum of locally measured delays and the number of broken connections.\r\nThe resulting model can be formulated as a binary linear program and is solved using standard commercial solvers. We report results for the busy main station area Berne in Switzerland using recorded data of train trips over a typical SBB business day.", :title "Algorithms for adaptive train disposition in main stations", :keyword2 105, :authors (19264 17127), :session 245}, 953 {:keyword1 80, :keyword3 0, :abstract "Bilevel programming problems arise when one optimization problem,\r\nthe upper problem, is constrained by another optimization problem,\r\nthe lower problem. In this paper we present an algorithm for\r\nsolving the mixed-integer bilevel programming problem with one\r\nparameter in the right hand side of the constraints in the lower\r\nlevel problem.The upper level variables are continuous, and lower\r\nlevel variables are discrete. This algorithm is based on\r\nreformulating the mixed-integer lower problem as continuous via\r\nits vertex polyheral convex hull representation and approximation\r\nthe optimal value function of the lower problem.", :title "Global solution of mixed-integer bilevel programming problem", :keyword2 0, :authors (28833), :session 71}, 955 {:keyword1 91, :keyword3 0, :abstract "Airlines face the problem of allocating seat capacity of multiple scheduled flights serving a single origin-destination market when customers may place seat requests for either a specific flight or a predefined set of two or more flights. While booking requests arrive according to some stochastic process until the end of the reservations horizon, the decisions to accept (or to reject) and to assign an accepted request to a final resource are made simultaneously. To our knowledge, existing literature about optimal controls for the revenue management problem with flexible products is restricted to models with a single flexible product and two constituting resources. In this work, a generalized stochastic dynamic programming formulation with multiple flexible products and resources is presented. Our model belongs to the class of static capacity control models. Due to the state space dimension the computation of optimal controls by value function evaluation is prohibited. Hence, we analyze the structure of an optimal booking policy for the multi-resource problem. First we show that our model contains special cases exhibiting well-known structural properties. For general instances, however, structural properties are not obvious. Therefore, we next identify a formal relation between the opportunity cost of reducing capacity and capacity-dependent bid prices. This relation helps to identify the general structure of an optimal booking policy and is further used to characterize other controls such as optimal protection levels or booking limits.", :title "Optimal seat capacity control for flexible products with multiple resources", :keyword2 76, :authors (29366 4161), :session 101}, 957 {:keyword1 106, :keyword3 77, :abstract "Nowadays, transport logistics is faced with several changes and challenges: a growing (international) freight traffic, a trend to smaller shipments and a greater (geographical) distribution of the customers, as well as an existing competition between the different modes of transport. This competitive environment is enforced by the liberalization of the railway. The design of transport networks has a great influence on the quality, efficiency, and costs of the network. In order to achieve advantages of this situation, the current network of wagonload traffic has to be optimized. \r\n\r\nIn wagonload traffic, flows of single wagons or small wagon groups with different origins and destinations are consolidated on their route through the network. The network is build up by several formations yards, which differ, e.g., in their size function, technical equipment and shunting process. Each wagon is routed through several formation yards and therefore uses several of trains.  Hence, the consolidation of wagons leads to lower transportation costs, but increases costs due to establishing and operating formation yards. \r\n\r\nWe present a specific hub location problem, which covers the main characteristics of wagonload traffic. For each potential hub node (formation yard) we consider a set of multiple capacity levels. We limit the total incoming flow at hubs. Besides, we consider the choice of different vehicle types of different capacity to build up a stepwise cost structure for transportation. The number of hubs and vehicles is not given a priori but is determined implicitly by the optimization process. We also limit the number of trains on each arc. The hub location problem is solved with CPLEX. The computational results for several test data sets are presented. \r\n", :title "An Integer Programming Approach to the Network Design Problem of Wagonload Traffic", :keyword2 65, :authors (23128 26657), :session 270}, 959 {:keyword1 96, :keyword3 2, :abstract "Shift scheduling and tour scheduling, as sub-problems of the workforce planning process, consist mainly of allocating individual staff members to suitable shifts and day-offs in order to meet service demand. In airport industry, check-in services for different airlines are provided by ground-handling companies. As the flight schedules are known for each airline, the staff requirements for any particular point of time are also known, which means the demand for this problem can be considered as deterministic.\r\n\r\nHowever, this process becomes more complex if, in order to satisfy the demand, a specific number of employees with particular skills or qualifications is required, i.e. workforce is not homogeneous. That is the case for check-in counters at airports due to the fact that airlines operate with different check-in computer system, and specifies the staff and qualification levels for each of the flights on their schedule. Furthermore, it is possible for an employee to operate a different check-in system on each period throughout his or her shift, i.e. qualifications are non-exclusive.\r\n\r\nTo this extend, we propose a MILP model based on the reduced set-covering formulation for the tour scheduling problem. Our approach considers individual employees with a set of non-exclusive qualifications to be assigned to shifts as to meet demand for each skill in each period of the planning horizon. Using real-world demand scenarios from a ground-handler at a German airport, we present first computational results.", :title "Heterogeneous workforce scheduling for check-in counters at airports", :keyword2 121, :authors (29524 10255), :session 140}, 963 {:keyword1 106, :keyword3 18, :abstract "Over the last decades, the growth and importance of cargo transportation in international trade has opened up new challenges for efficient operations at intermodal terminals. With the rail freight market reaching new heights, an efficient handling of the train loading distinguishes intermodal terminals and fulfils the goals of its stakeholders. \r\nThe train loading optimisation problem is generally treated as either an operative or an online problem, with the former being suggested in the literature and the latter being solved manually in practice. This talk aims at uniting both of these worlds. \r\nThe novel approach in the software solution for intermodal terminals SyncroTESS resides in a decision support tool with a mathematical programming model at its core. It bridges both mentioned planning levels, while introducing an additional tactical planning level which makes it applicable in practice.  \r\nThe decision support tool of SyncroTESS for train loading at intermodal terminals and the coverage of its model will be presented. Moreover, experiences gathered from its current use at two terminals in Germany will be profiled. This will include a glimpse at the graphical interface which displays mathematically optimised solutions to the train loading dispatcher.\r\n", :title "Train loading optimisation: Bridging the gap between research and practice", :keyword2 57, :authors (14688), :session 242}, 964 {:keyword1 93, :keyword3 0, :abstract "Testing calibration quality by means of backtesting is an integral part in the validation of credit rating systems. Against this background this paper provides a comprehensive overview of existing testing procedures for whole rating systems. Currently employed methods lack the ability to consistently apply an assumed dependence structure in the calibration, application and validation. We provide a general framework for testing rating systems under any assumed dependence structure. Using this framework, we develop two novel tests, one relying on the squared Mahalanobis distance and one based on the Sterne test. Performing a scenario analysis using rating data of Moody's, we are able to demonstrate that our new procedures allow for a more accurate analysis of rating systems than existing procedures.", :title "Consistent Testing of Calibration Quality in the Presence of Default Dependence", :keyword2 0, :authors (29556 29549 29555), :session 215}, 965 {:keyword1 6, :keyword3 0, :abstract "One of the key functions of financial markets is generating prices and price discovery processes through trading of different assets. These roles are linked to the concept of price efficiency and liquidity which are the key determinants of market quality. This study focuses on the effect of opening call auctions on market quality. The objective is to find out which market structure is the best for the opening period and whether a spillover-effect of an opening call auction on the subsequent continuous trading exists. We apply the experimental approach for analyzing these questions. Our examination extends the existing market microstructure literature in two aspects. First, we do not only investigate the market quality of call auctions at the market opening but also analyze the effect of an opening call auction on the subsequent continuous trading phase during a trading period. Second, we analyze two different kinds of call auctions: a transparent design with an open order book and a non-transparent version where no order information is available during the order entry phase.\r\nWe find that an opening call auction significantly increases the informational efficiency of opening prices in comparison to the continuous double auction alone. Regarding the effect of an opening call auction on the subsequent continuous trading phase, we discover a positive spillover-effect in terms of higher informational efficiency and liquidity compared to the single trading venue without an opening call auction.\r\n", :title "The effect of different market opening structures on market quality - experimental evidence", :keyword2 35, :authors (23103 23119 281 29559), :session 218}, 967 {:keyword1 75, :keyword3 0, :abstract "The concept of production leveling (or Heijunka), which is part of the Toyota Production System, aims at reducing the variance of upstream material requirements. It consists in fixing a cyclic schedule which is composed of small (e.g. one piece) batches. The allocation of the products to the batches is fixed in such a way that, for any product, the intervals between consecutive batches are as even as possible and the allocated capacity is sufficient for at least the average demand. Various algorithms for determining such schedules are proposed in literature.\r\nWhen using Heijunka control, however, the fluctuation of the external demand has to be compensated by end product inventory and/or the fill time (the time from demand arrival until fulfillment), depending on the available production capacity. The inventory is usually controlled by Kanban loops. But precise statements on the necessary number of Kanbans to guarantee a certain  fill time are missing in literature.\r\nWe consider a multi-item production line with a given Heijunka schedule and Poisson demand. We derive approximative analytic relationships between fill time, inventory and capacity for the following cases:\r\n\r\n1. No inventory: The fill time of a product is a function of the total capacity of the production line and the capacity allocated to that product. This function can be used for optimizing the capacity allocation.\r\n\r\n2. Inventory with Kanban control: The fill time depends now also on the number of Kanbans.\r\n\r\n3. Lost sales in case of positive fill time: The fill rate is a function of the capacity and the number of Kanbans.\r\n\r\nThe new analytic approximations have been verified by simulation, which showed a very good congruence. \r\n", :title "Fill Time, Inventory and Capacity in a Multi-Item Production Line under Heijunka Control", :keyword2 99, :authors (29442 5524), :session 170}, 969 {:keyword1 25, :keyword3 0, :abstract "This paper presents examples of stochastic overlapping generation (OLG)  models with infinite-dimensional indeterminacy. Our study departs from the  deterministic OLG model considered by Kehoe and Levine (1990), in which the  indeterminacy is one-dimension and the fundamentals (shocks and wealth  distribution) as well as the shadow value of investment in financial assets (m) are sufficient for households to correctly predict asset prices. We  construct a stochastic variation of their model and verify the existence of  indeterminacy by computing all Markov equilibrium. Numerical simulations  suggest that the uncertainty introduces indeterminacy with infinite  dimension. The fundamentals accompanied by m will not pin down the prices  due to the existence of numerous selections of transition and policy functions from the equilibrium set. Each selection correspondences a sequential competitive equilibrium that may present quite different volatile movements in asset price. It is possible to construct a continuum of recursive equilibrium. However our numerical simulations suggest that it is problematic to look at recursive equilibrium in which the volatility of asset price is solely determined by the fundamentals.", :title "Numerical Simulation of the Overlapping Generations Models with Indeterminacy", :keyword2 134, :authors (29558), :session 139}, 970 {:keyword1 98, :keyword3 77, :abstract "OpenSolver is an open source Excel add-in developed at the University of Auckland that allows linear and integer programming models to be solved using the powerful COIN-OR CBC solver. OpenSolver is compatible with existing Solver models, but avoids the size restrictions built into the free Solver. OpenSolver includes new model visualisation tools and provides an alternative more intuitive approach to setting up an optimisation model, features that make OpenSolver more appealing to both students and OR practitioners. OpenSolver also provides useful tools for advanced users including output of the underlying LP equations, command line interaction with the CBC optimiser, and the ability to quickly re-solve models after changes to constraint right hand sides. OpenSolver is available for free download at http://opensolver.org", :title "OpenSolver - An Open Source COIN-OR Solver for Excel", :keyword2 78, :authors (4275), :session 241}, 972 {:keyword1 102, :keyword3 97, :abstract "Transportation accounts for 20 -30 % of CO2 emissions in developed countries, and transportation induced emissions are rapidly increasing in developing countries. Therefore, regulatory measures are being introduced worldwide in order to reduce emissions of the transportation sector. California has a leading position with regard to emission reduction requirements. Here, automobile manufacturers must not only reduce greenhouse gas emissions of their vehicle fleet (GHG regulations), but also sell increasing shares of zero emission vehicles (ZEV regulations). Manufacturers have to pay high penalties in case of non-compliance.\r\nAgainst this background, California's regulatory measures are analyzed with regard to compliance strategies of automotive manufacturers. This is done using a dynamic simulation model, in which future development of powertrain technologies, vehicle types offered, accompanying infrastructure coverage and market diffusion based on customer behavior are incorporated. Application of the model to the regulations of California shows that feedback between GHG and ZEV regulations necessitate the development of joint compliance strategies. Recommendations are derived concerning California’s regulations as well as appropriate manufacturers’ compliance strategies.\r\n", :title "Regulatory impact assessment in the automotive industry – case study California", :keyword2 103, :authors (2650 14924 17364 2651), :session 105}, 976 {:keyword1 19, :keyword3 127, :abstract "Following the law concerning the appropriateness of management board remuneration (“Gesetz zur Angemessenheit der Vorstandvergütung” (VorstAG)), German stock corporations are obliged to implement a deductible on the D&O insurance policies for their managers. The main argument for a mandatory deductible is the necessity to motivate managers to prevent damages, which might otherwise harm stakeholders. In the literature, the following questions are controversially discussed: Should a deductible be part of a D&O policy? Can such a deductible effectively influence the behavior of the managers? Should the corporation or the management board members themselves pay the premium?\r\n\r\nIn this paper, we address these questions. With the help of a simple agency model we show that D&O insurances can generally be beneficial to the stockholders. However, a deductible does not always lead to further improvements. Moreover, an insurance provided by the corporation turns out to be superior to a private insurance of the managers. As a result, a mandatory deductible for D&O insurances cannot be supported, since the favorability depends too much on the specifics of agency relationships.\r\n", :title "The deductible on the D&O insurance - an agency theoretic analysis", :keyword2 93, :authors (29542 29560), :session 94}, 977 {:keyword1 25, :keyword3 0, :abstract "In this paper we examine existence and Pareto-efficiency of equilibria in a dynamic stochastic exchange economy with collateral constraints. We assume that agents can write any state contingent contract but that the only enforcement mechanism in the economy is the possible seizure of collateral associated with the financial contracts. If there is ’enough’ collateral competitive equilibrium is Pareto-efficient, while a shortage of collateral can lead to constrained inefficient allocations. In order to examine the quantitative question how much collateral is needed to support the efficient allocation, we examine an infinite horizon economy. We show that equilibria in this economy can often be characterized by a finite number of equations and that therefore the analysis becomes extremely tractable.\r\nFor the simple case of an economy with no aggregate uncertainty and iid idiosyn- cratic shocks, we give a simple condition on fundamentals that ensures Pareto efficiency. We also consider the calibration from Heaton and Lucas (1996) and argue that there inefficiencies only arise if one assumes unrealistically low levels of collateral.", :title "Dynamic General Equilibrium with Complete Markets and Collateral", :keyword2 134, :authors (28031), :session 138}, 979 {:keyword1 44, :keyword3 0, :abstract "This paper presents an approach to applying PROMETHEE for group decision making to support strategic decision making for the implementation of service-based business concepts. Such strategic decisions are not only dependent on profit but also on other economical and ecological criteria, i. e. gain or loss of know-how and chances as well as risks concerning cooperation. Therefore, the application of a multi criteria decision support methodology is necessary. To chose a concept which is successful in the market this methodology should include both, the provider’s and the customer’s perspective. \r\nIt has already been proven that PROMETHEE is a suitable method for supporting pro-viders in their decision process of choosing an appropriate concept out of various feas-ible service-based business concepts. In order to increase the acceptance by the cus-tomer of the chosen alternative of those business concepts, his demands should be fulfilled as well. To be able to use PROMETHEE for this issue the methodology now was developed further to include both parties of the decision making process. This ap-proach focuses on the applicability for practitioners. In contrast to the application of PROMETHEE by a single decision maker, the weighting process includes the share of the vote of the different decision makers – as already shown in other approaches - as well as contrary targets of the decision makers for the defined set of criteria.\r\n", :title "Dealing with conflicting targets by using group decision making within PROMETHEE", :keyword2 100, :authors (28479 24622), :session 251}, 983 {:keyword1 77, :keyword3 0, :abstract "We consider nonlinear integer optimization problems. In order to solve such a problem, we use the fact, that continuous nonlinear optimization-problems are often easier to solve than their integer counterparts. Assume that we can solve a continuous nonlinear problem in polynomial time and we know that an optimal integer point can be found by just rounding (up or down) the components of an optimal solution of the continuous problem, \r\nthen we can (in fixed dimension) also solve the IP in polynomial time.\r\nTo check whether we get an optimal solution to the IP by rounding a continuous solution (we call this the rounding property) we use a geometric approach: we investigate the geometric shape of the level sets. E.g. if the level sets are balls around the continuous solution the problem has the rounding property.\r\nWe extend this by identifying geometric properties of the level sets that also lead to the rounding property: First, the rounding property is still true, if we don't take the standard Euclidean-norm-ball, but an arbitrary p-norm-ball. Second, we will show that the rounding property holds if the level set is included between two p-norm-balls if the difference of their radii is small enough. For our third generalization we investigate rectangular-distance-star-shaped sets and show that the rounding property also holds in this case.\r\nWe will present examples for functions that have one of the above properties and apply our approach on problems from location theory.\r\nFurthermore, we will discuss a sharper property which makes sure that we can round the continuous optimum to the closest integer point. If it holds we can solve the integer version of a continuous optimization problem in the same time as the continuous problem (in any dimension).", :title "A level set approach for integer nonlinear optimization", :keyword2 80, :authors (29561 1601), :session 204}, 985 {:keyword1 75, :keyword3 96, :abstract "We propose a greedy randomized adaptive search procedure (GRASP) metaheuristic for the problem of scheduling slabs at continuous casters. Slab production is the central process in integrated steel mills, the most common configuration used in industry. The determination of a sequence to produce slabs requires solving a combined lot sizing and scheduling problem, which can be formulated as MIP (see Wichmann et al., 2011). This MIP is unique in terms of four specific requirements which comprise flexible job specifications, continuously adjustable in-situ control parameters, material supply in batches and different types of machine setups. To solve the MIP, we propose a two-stage GRASP metaheuristic. In the first stage, solutions are generated using a randomized construction method. In the second stage, the generated solutions are improved in a local search phase. The most special feature of the approach is the handling of the problems’ characteristics during both solution phases. We analyze the performance of the approach in a numerical case study with numerous data sets generated from real world data. To evaluate the performance, we present a firm lower bound on the objective function value. As a result, for problems of real world size solutions with an average gap to the lower bound with less than 20% can be obtained within reasonable computing time.", :title "An efficient GRASP heuristic for the slab scheduling problem", :keyword2 59, :authors (17130 26841 2651), :session 53}, 987 {:keyword1 25, :keyword3 0, :abstract "This paper reproduces the slope of the uncovered interest rate parity (UIP) regression for six different country pairs within one standard deviation under rational expectations. \r\n\r\nWhile standard theory predicts a slope of one, the empirically observed slope of the regression of currency returns on the interest rate differential between two countries is negative for most country pairs. This empirical fact that, on average, investors require higher returns on bonds denominated in a currency expected to appreciate, poses a strong challenge for economic models. In this paper, we propose a potential explanation within an infinite horizon dynamic stochastic general equilibrium model with incomplete markets. Heterogenous investors experience varying risk aversion as a result of habit formation. \r\n\r\nThe underlying mechanism of the model relies on varying international diversification in the investors' portfolio choice decision. In response to their changing habit levels, investors' hedging desire varies over time, leading to adjustments in interest rates. The habit-induced investment decisions are negatively correlated with exchange rate movements. This leads to a negative correlation between interest rates and expected exchange rates, as implied by a negative UIP slope.\r\n\r\nDepending on the magnitude of habits, the model is capable of reproducing positive as well as negative UIP slopes, as seen empirically in the data.", :title "Time-Varying International Diversification and the Forward Premium", :keyword2 34, :authors (29562), :session 38}, 988 {:keyword1 8, :keyword3 0, :abstract "The Train Marshalling Problem consists of rearranging an incoming\r\ntrain in a marshalling yard in such a way that cars with the same\r\ndestinations appear consecutively in the final train and the number of\r\nneeded sorting tracks is minimized. Besides an initial roll-in\r\noperation, just one pull-out operation is allowed for all cars\r\non the same sorting track. Such a constraint especially makes sense\r\nin the European railway network, where coupling cars has to be done\r\nmanually and is therefore very time consuming. This problem is\r\nknown to be NP-hard to solve. We study the Train Marshalling\r\nProblem both from an offline and online optimization point of\r\nview. For the offline version we provide tight new lower bounds on the\r\noptimum solution obtained by partitioning an associated interval\r\ngraph.  We provide an experimental evaluation of our lower bound and\r\nalgorithm which shows the practical tightness of the bound. To study\r\nthe effect of uncertainty and interuptions in the schedule we look\r\nat the corresponding online version of the problem. Here the cars arrive \r\none by one and must be placed irrevocably on a track.  We prove a \r\nlower bound of 2 on the competitiveness of any deterministic online \r\nalgorithm and show that this bound can be achieved by a natural algorithm.", :title "The Train Marshalling Problem - Online Algorithms and Bounds", :keyword2 106, :authors (29246 19477 29565), :session 209}, 994 {:keyword1 77, :keyword3 95, :abstract "This paper presents the first full-fledged branch-and-price (bap) algorithm for the capacitated arc-routing problem (CARP).  Prior exact solution techniques either rely on cutting planes or the transformation of the CARP into a node-routing problem.  The drawbacks are either models with inherent symmetry, dense underlying networks, or a formulation where edge flows in a potential solution do not allow the reconstruction of unique CARP tours.  The proposed algorithm circumvents all these drawbacks by taking the beneficial ingredients from existing CARP methods and combining them in a new way.  The first step is the solution of the one-index formulation of the CARP in order to produce strong cuts and an excellent lower bound.  It is known that this bound is typically stronger than relaxations of a pure set-partitioning CARP model.  Such a set-partitioning master program results from a Dantzig-Wolfe decomposition.  In the second phase, the master program is initialized with the strong cuts, CARP tours are iteratively generated by a pricing procedure, and branching is required to produce integer solutions.  This is a cut-first bap-second algorithm and its main function is, in fact, the splitting of edge flows into unique CARP tours.\r\n", :title "Cut-First Branch-and-Price-Second for the Capacitated Arc-Routing Problem", :keyword2 106, :authors (4161 29566), :session 182}, 1001 {:keyword1 13, :keyword3 0, :abstract "Continuity of convex functions is an important issue in the theory of convex analysis, in particular, as a regularity condition for strong duality results. In the case of set-valued functions several notions of continuity exist. We will compare them and state a Fenchel-Rockafellar type duality theorem with a regularity condition based on the weakest continuity notion.", :title "Continuity of convex set-valued functions", :keyword2 0, :authors (6948 19982), :session 78}, 1002 {:keyword1 94, :keyword3 13, :abstract "Given a backbone network for telecommunication with uncertain demand between any pair of nodes the task is to find capacities for the links in the network so that all demand can be routed through the network with high probability. Our model is based on a multicommodity flow formulation for routing the demand between any two nodes with chance constraints coupling flow and capacity values on each link. If demand can be approximated reasonably by a multivariate normal distribution a standard approach is to reformulate the chance constraints as second order cone constraints. In practice, demand is given via past traffic matrices that typically exhibit rather strong fluctuations. The purpose of this study is to investigate wether this second order cone approach is helpful in spite of the rather bad match between data and required distribution properties. Underlying testinstances are based on data from the US research and education network ABILENE.", :title "Experiments on robust network capacity design in telecommunication based on a second order cone model for chance constraints", :keyword2 104, :authors (29545 17006), :session 211}, 1003 {:keyword1 105, :keyword3 74, :abstract "The train timetabling problem (TTP) is to find conflict free time\r\nslots for predefined train routes in a given railway network. \r\nMotivated by project with Deutsche Bahn we model\r\nthis aperiodic problem in a classical way using a time-discretized\r\nnetwork for each train and employ Lagrangian relaxation of\r\nthe coupling constraints, which ensure track and station capacities. \r\nIn the TTP trains influence each other if and only if\r\nthey use the same parts of the infrastructure at near time steps,\r\ni.e., a single constraint couples only a small number of trains. While\r\nclassical subgradient optimization methods optimize over the whole\r\nspace of dual variables, we propose an asynchronous parallel bundle\r\nmethod that detects automatically interdependencies between trains and\r\nselects appropriate subspaces of dual variables that correspond to\r\nconstraints in highly important areas of the network. Several such\r\nsubspaces can be selected at the same time and optimized over. Most\r\nparallel algorithms in the literature require an a priori\r\nseparation of the whole space in subspaces or some global\r\nsynchronization step which is evaluated from time to time to ensure\r\nglobal convergence. In contrast, our algorithm selects the subspaces\r\ndynamically during execution and optimizes over them in a fully\r\nparallel and asynchronous way without any global synchronization step.\r\nWe provide first promising computational experiments on some\r\ntest-instances of the TTP.", :title "A Parallel Bundle Method for Asynchronous Subspace Optimization in Lagrangian Relaxation and its Application to Train Timetabling Problems", :keyword2 13, :authors (16988 17006), :session 92}, 1004 {:keyword1 106, :keyword3 8, :abstract "Operating freight trains in a dense rail network is an enormous challenge for railway transport companies. In fact, they have to handle a highly complex optimization problem involving a tremendous number of eligible train routes and departure times, sparse capacities of the infrastructure and important conflicting objectives: minimizing the total travel distance for rolling stock as well as the individual due dates for freight delivery.\r\n\r\nIn this talk, we will outline first results from an ongoing project with Deutsche Bahn. Customers of the Deutsche Bahn request rail car transport of a large amount of freight from origins to destinations throughout Germany. Here, we focus on freight train composition, i.e. on routing rail cars from origin to destination and assigning them accordingly to a sequence of pre-scheduled freight trains. The resulting challenge consists in finding a feasible assignment, including the complete ordering of the rail cars within the freight trains, which minimizes the total number of the time-consuming shunting operations in the rail yards.\r\n\r\nWe will compare our NP-hard model to other models known in the literature and we will discuss new Integer Programming formulations. Some heuristical solution methods as well as preliminary computational experience for practical data will be presented. We conclude the talk with some remarks on future research.", :title "Optimal freight train composition with reduced shunting operations", :keyword2 95, :authors (13837 15375), :session 92}, 1007 {:keyword1 17, :keyword3 0, :abstract "We want to discuss the regulatory impact of environmental standards on the eco-efficiency of firms. Due to the exogeneity of inputs, desirable and undesirable outputs in DEA, it is not possible to introduce environmental constraints on these parameters directly. Therefore, we implement the environmental standard in a bounded-variable way, which allows for constraints on the efficiency frontier. The regulatory impact of the environmental standard on a particular firm (the industry) is determined by the comparison of its eco-efficiency scores (average eco-efficiencies) before and after fictive introduction of the standard. Therefore, a SBM framework, accounting for possible slacks, is more advantageous for our purpose. Two possible models for measuring eco-efficiency are considered: a SBM version of Model B from Luptacik and Korhonen (2004) and the Undesirable Output Model from Cooper et al. (2007). These models constitute the starting point for our methodological implementation. We distinguish between weak and strong disposability of undesirable outputs and develop according models. Weak disposability itself is an extension to common SBM eco-efficiency models. Our proposed model framework has a huge flexibility. The regulator can choose between 2 general SBM model frameworks, 3 types of environmental standards and 2 weak disposability versions, so the model can be adopted to a wide range of industries. Moreover, assessing the regulatory impact of environmental standards in advance can provide support for the environmental policy makers in choosing appropriate instruments and adjusting the intensity of regulation.\r\n\r\n", :title "Regulatory Impact of Environmental Standards on the Eco-Efficiency of Firms", :keyword2 0, :authors (29570 29475 29576 26084), :session 105}, 1008 {:keyword1 8, :keyword3 0, :abstract "In the quadratic traveling salesman problem the costs are associated with any three nodes traversed \r\nin succession in a tour and the task is to find a tour of minimal total cost. In the symmetric case,\r\ncosts do not depend on the direction of traversal. The problem is \r\nmotivated by an application in biology but also includes the angular-metric traveling \r\nsalesman problem used in robotics and the traveling salesman problem with reload costs arising in\r\nthe planning of telecommunication and transport networks.\r\nWe study the polyhedral structure of a linearized integer programming formulation and present several\r\nfacets of the corresponding polyhedron. These include some related to facets of the boolean quadric \r\npolytope, a new class of polynomial time separable facet defining inequalities forbidding conflicting\r\nconfigurations of edges, and strengthened subtour elimination constraints that can be derived from a \r\ngeneric strengthening approach lifting valid inequalities of the traveling salesman problem. For these \r\nextended subtour elimination constraints, \r\nfinding a maximally violated inequality is NP-complete. Finally, we present some computational results\r\nto illustrate the importance of the new inequalities.", :title "The Symmetric Quadratic Traveling Salesman Problem", :keyword2 77, :authors (26471 17006), :session 204}, 1009 {:keyword1 106, :keyword3 0, :abstract "The dial-a-ride problem (DARP) is a pickup and delivery problem for personal transportation. We consider a variant of the DARP where the total travel costs are to be minimized subject to pairing, precedence, capacity, time-window and ride-time constraints. Adapting standard column-generation techniques for VRP variants to this problem is not straightforward: For pricing out new routes, existing labeling algorithms are not able to check both time-window and ride-time constraints. Hence, Ropke and Cordeau ignore ride-time constraints in their pricing problem, enforcing them through cuts in the master problem. We present a new approach that integrates the ride-time constraints into the pricing problem of a column-generation algorithm.", :title "A new approach to handling ride-time constraints in column generation for the dial-a-ride problem", :keyword2 95, :authors (29571), :session 189}, 1010 {:keyword1 17, :keyword3 0, :abstract "This study analyses how different regulatory regimes affect the efficiency of electricity distribution companies. We begin our analysis with Norway, a pioneering country that switched from cost-based to incentive regulation accompanied by a significant improvement of productivity (Edvardsen et al. (2006)) and even developed further changes in the incentive regulation regime. We want to extend the research for Norway by assessing the effects on efficiency of a change from a pure revenue cap to a more hybrid form of revenue cap. More related research can be found in Jamasb et al. (2008) who measured productivity and efficiency of gas transmission companies under different regulatory regimes, with the result that benchmark-based regulation has rather been successful when taking productivity and convergence as performance indicators into account.\r\nIn order to evaluate the effects of changes in the regulatory system, the efficiencies of distribution companies between two different points in time have to be compared. As the possible change of the efficiency frontier due to changes in the production technology must not be neglected, we use the Malmquist Index, which accounts for the change in the production technology. Herein, the efficiency development for each firm is split into two parts, the catch-up, which accounts for the individual efficiency development of the firm and the frontier shift, measuring the industry wide efficiency development. The product of both effects is the Malmquist Index, which represents the overall efficiency development.\r\nOur first findings show that different regulatory regimes matter with regard to efficiency. ", :title "Assessing the effects of different regulatory regimes on european electricity distribution efficency", :keyword2 0, :authors (29570 29475 29576), :session 105}, 1011 {:keyword1 57, :keyword3 78, :abstract "Column generation is a successful technique to solve well-structured\r\nlarge-scale linear programs (LPs). Typically, these LPs arise as\r\nlinear relaxations from combinatorial optimization problems (vehicle\r\nrouting, crew scheduling, coloring, packing, etc.). As such, these LPs\r\nare often extremely degenerate, and degeneracy is known to be a major\r\nperformance issue in column generation.\r\n\r\nBased on recent advances in increasing the performance of the\r\nsimplex method for degenerate LPs, we propose to exploit degeneracy of\r\nthe master problems that arise in column generation. The idea is to\r\ntemporarily ignore/fix the degenerate basic variables, thus\r\nconsiderably reducing the size of a basis matrix and to speed up the\r\nre-optimization of the master problem. This implies to temporarily\r\nkeep the degenerate basic variables at their bounds and the column\r\ngeneration subproblems must respect this. As a consequence, every\r\niteration in the master problem leads to a strict improvement of the\r\nobjective function value.  The method can be seen as a value based\r\ndecomposition (instead of a structure based decomposition which is\r\ntypical for column generation), and this decomposition is dynamically\r\nupdated when necessary. The approach is guaranteed to solve the master\r\nLPs to optimality.\r\n\r\n", :title "Improved  Column Generation for Highly Degenerate Master Problems", :keyword2 53, :authors (3046 29579 14969), :session 210}, 1013 {:keyword1 23, :keyword3 94, :abstract "In highly dynamic scheduling, change events occur long before the scheduling horizon is reached. The scheduler is driven by change. The complexity of these problems cannot be described in terms of NP-hardness, as no exact optimal solution exists for a dynamic problem. Nevertheless, search space explosions are common. In addition, search time is very limited, since the environment requires immediate solutions. Each problem solving approach will therefore employ heuristics in some sense. The heuristics may be in the algorithm (e.g., metaheuristics), in narrowing down the search space, or in enhancing the fitness functions (e.g., by preferring robust schedules).\r\nEvolutionary algorithms (EA) are often applied metaheuristics, both in static and dynamic environments. They have innate robust tendencies, being able to adapt to changing environments. However, we argue they are of limited use in highly dynamic problems. As revised schedules preferably stay close to the original, there is no need for broad sampled neighbourhoods such as provided by EAs. Furthermore, schedules in dynamic environments have a great internal coherence, which an EA is prone to break. Lastly, in such problems, the time to perform EA computations simply is not there. The optimisation approach needed in such environments often involves load balancing, which can be performed by exchanging tasks between machines or queues. Therefore, more straightforward element-swapping heuristics such as k-opt search, will prove more valuable.\r\nElevator dispatching was used as a case study in this research. It is a typical example of a highly dynamic scheduling problem. Experiments using real world passenger data show that EAs are outperformed by k-opt search, even when search time was unlimited. ", :title "Straightforward heuristics vs. evolutionary algorithms in dynamic scheduling", :keyword2 59, :authors (29573), :session 75}, 1015 {:keyword1 25, :keyword3 0, :abstract "We compute the welfare consequences of social security in a calibrated life cycle economy featuring aggregate as well as idiosyncratic risk. We take a portfolio choice perspective on social security. Hence, social security is an implicit asset that partially substitutes for missing insurance markets and which provides diversification of risks of an individual's life-time income. We look at a 'marginal' introduction of a social security system and decompose the total welfare effects into (i) a direct positive effect through partial insurance against various sources of risk, (ii) an indirect positive effect through portfolio diversification, and (iii) the negative effect of the crowding out of capital. Our preliminary results show that social security leads to long-run welfare losses in the order of magnitude of 1.2 percent of life-time consumption. These losses are exaggerated because the current version of our quantitative model does only produce an equity premium of 2.2 percent and social security in our model does not provide partial insurance against idiosyncratic wage income risk.", :title "On the Welfare Effects of Social Security in a Model with Aggregate and Idiosyncratic Risk", :keyword2 76, :authors (29569 29578), :session 134}, 1016 {:keyword1 8, :keyword3 101, :abstract "We study a production planning problem known as the discrete lot-sizing and scheduling problem with sequence-dependent changeover costs. The problem consists in defining the size as well as the schedule of the lots to be processed on a single production resource so as to minimize both the production and the inventory holding costs. We consider here the case where the amount of changeover costs to be incurred before starting the production of a lot depends on the production sequence.\r\n\r\nWe propose a new way of obtaining strong lower bounds for this difficult optimization problem. This is achieved by formulating the problem as a quadratic integer program (QIP) and by developping a solution approach to compute a semidefinite relaxation of the obtained QIP. \r\n\r\nTwo alternative formulations are considered for the QIP:\r\n(1) an \"aggregate\" formulation where binary decision variables are related to the assignment of products to production periods.\r\n(2) an \"extended\" formulation of the problem where binary decision variables are related to the assignment of demand units to production periods.\r\n\r\nIn both cases, an algorithm based on a semidefinite relaxation of the obtained quadratic integer program is developped, providing a lower bound of the cost of an optimal production plan.\r\n\r\nComputational experiments carried out on a series of small instances are then presented. In particular, we compare the lower bounds obtained by semidefinite relation with the ones obtained by known tight continuous relaxations of the problem. \r\nThe results show that, for certain classes of instances, a significant improvement of the lower bound quality can be obtained by using a semidefinite relaxation of the \"extended\" formulation.\r\n\r\n", :title "Tight lower bounds by semidefinite relaxation for the discrete lot sizing and scheduling problem with sequence-dependent changeover costs", :keyword2 82, :authors (29574 5582), :session 161}, 1017 {:keyword1 25, :keyword3 0, :abstract "A pure characteristics model (PCM) is a class of discrete-choice random-coefficients \r\ndemand models in which there is no idiosyncratic logit error term in a consumer’s utility. \r\nThe absence of the logit error term leads to a nonsmooth formulation of the predicted \r\nmarket share equations. As a result, inverting the market share equations for the unobserved product characteristics and estimating the model becomes computationally infeasible \r\nusing nested-type algorithms. We formulate the GMM estimation of a pure characteristics \r\nmodel as a mathematical programs with equilibrium constraints (MPEC), where the equilibrium \r\nconstraints characterize consumers’ decisions. We also present the formulation of the \r\nPCM model with supply-side equations and discuss the computational challenges in estimating these models with the MPEC approach.", :title "An MPEC Approach for Estimating Pure Characteristic Models", :keyword2 57, :authors (29577), :session 38}, 1018 {:keyword1 97, :keyword3 93, :abstract "In this work we apply the theory of bivariate Markov chains to bootstrap continuous valued processes (in the discrete time). To this purpose we solve a minimization problem to partition the support of a continuous process into a finite number of states. We start from an inflated segmentation of the support and obtain a coarser representation. The resulting partition identifies levels in the support such that the process modifies significantly its dynamics (i.e. its expected value, or its variance, etc.). A distance indicator is used as objective function to favor the clustering of the states having similar transition probabilities. A multiplicity boundary is also introduced to prevent that the bootstrapped series are not diversified enough.\r\nThe problem of the exploding number of alternative partitions in the solution space (which grows with the initial number of states) is approached through an application of the Tabu Search algorithm.\r\nOur method serves also to assess the order k of the process. It turns out that the search of the relevant states contributes to identify also the relevant time lags. The formation of few large groups at some time lags, as opposed to the formation of several small clusters in other time lags, is taken as evidence against the relevance of the former and in favor of the latter.\r\nThe method is applied to bootstrap bivariate series of prices and traded volumes observed in the German and Spanish electricity markets. The analysis of the results confirms the good consistency properties of the method proposed.", :title "A Markov chain method to bootstrap multivariate continuous processes", :keyword2 29, :authors (3654 7142 2991 12473), :session 122}, 1020 {:keyword1 78, :keyword3 0, :abstract "It is well known that Linear Programming (LP) is a polynomial time solvable problem. On the other hand, despite many efforts, the existence of a strong polynomial time algorithm for solving LP remains an open question. Fujishige et al. (2009) proposed an algorithmic approach which is motivated as an alternative attempt on resolving this issue.\r\n\r\nTheoretically, general LP over polyhedra can be reduced to LP over zonotopes which then may easily be solved in a greedy fashion. The overall resulting Newton-type methods iteratively converges to the optimum of the original general LP in a finite number of steps - even for real-number input with exact arithmetic computations. \r\n\r\nWe will present some theoretical as well as some computational results using a high precision implementation of the method including the GNU multiple precision arithmetic library.", :title "Some results on the LP-Newton method", :keyword2 10, :authors (14773), :session 196}, 1022 {:keyword1 95, :keyword3 42, :abstract "The Capacitated Arc Routing Problem (CARP) is a well known vehicle routing problem. The aim of the CARP is to find a set of vehicle tours in a graph such that each arc of a specified subset of arcs of \r\nthe graph is serviced by exactly one vehicle, the load assigned to a vehicle does not exceed its capacity and the total distance traveled is minimized. A promising exact approach to the CARP\r\nis to model it as a set partitioning problem in which every variable corresponds to a feasible vehicle tour and solve it via branch-and-price. The column generating subproblem in this model is\r\nthen to find feasible vehicle tours. Usually this is done by solving an elementary ressource constrained shortest path problem either by dynamic programming or by a mixed integer program.\r\nThe idea of the two-stage column generation approach is now to mimic the well known heuristic Cluster-First-Route-Second principle in an exact column generation approach for the above subproblem.\r\nTo solve the subproblem of finding feasible vehicle tours we therefore use a level-2-masterproblem and a level-3-subproblem to generate new columns for the level-2-masterproblem. The level-2-masterproblem is to select a subgraph of the original graph and find a feasible vehicle tour on this subgraph with \r\nnegative reduced cost using the dual variables from the set partitioning masterproblem. In the level-3-subproblem those subgraphs have to be generated. It is not obvious at first glance how these\r\nsubgraphs should look like and how they are computed. As we want to find feasible tours on those subgraphs they have to contain the depot and they should be connected (or strongly connected in the\r\ndirected case). In this talk we present our work in progress on the two-stage model and its subproblems.", :title "A Two-Stage Column Generation Approach to the Capacitated Arc Routing Problem", :keyword2 106, :authors (29344 14969), :session 210}, 1023 {:keyword1 136, :keyword3 0, :abstract "A common task of deterministic optimization of water network operations is to determine pump, valve, water storage and source flow schedules in order to minimize the network operation costs, such as energy consumption costs.\r\nWhile common approaches available in literature and as software packages use deterministic water demand predictions as a base, the focus of this paper considers uncertainties in the water demands prediction.\r\nTo avoid running dry due to increased or unexpected water demands, the current practice of water utilities is to operate their systems with artificially high water storage level bounds to maintain constantly high water levels in their reservoirs. But in the case of unexpected volatile demand realizations, the water levels can violate the bounds up to running dry.\t\r\n  \r\nIn this paper we present a methodology, which targets on lowering the minimum water storage level bounds without increasing the risk of running out of water. This is done by modeling uncertainties in water demand and applying stochastic programming techniques. Controlling the water storage levels allows the decrease of the artificial high bounds.\r\nReducing water storage levels implies a reduction of pumping costs, as pumps do not have to work against these high heads.\r\nFinally we demonstrate the fundamental concepts at an academic example of convenient size.\r\n", :title "Optimization of water network operation under uncertainties ", :keyword2 85, :authors (29137 8732 25496 29584), :session 120}, 1025 {:keyword1 96, :keyword3 42, :abstract "The static aircraft landing problem asks for a schedule of aircraft landings on one or more runways, minimizing the costs of delayed landings while assuring that the necessary separation time between two landings is kept. The general case, in which separation time and delay costs depend on the particular aircraft, is an NP-hard optimization problem which can be solved exactly only for small instances.\r\n\r\nBy assuming, (1.) that each aircraft belongs to one of a limited number of aircraft classes, and (2.) that the minimum separation time as well as the cost for delayed landings depend only on these aircraft classes, polynomial time solution algorithms could be developed. The assumption of a limited number of aircraft classes is realistic, since in practice aircraft are also divided into three to five classes in order to determine the minimum separation time between two landings.\r\n\r\nIn this case, the problem can be solved with a dynamic programming approach based upon a representation as shortest-path problem in acyclic directed graphs. While the graphs are of polynomial size, numerical tests show that their actual size is still huge, causing unacceptably long computation times. Therefore we develop a heuristic solution method exploiting the graph structure. In a numerical study we compare its runtime and solution quality to the exact results of the MIP formulation.", :title "A dynamic programming approach to the aircraft landing problem with aircraft classes", :keyword2 2, :authors (29046 10255 5838), :session 53}, 1028 {:keyword1 89, :keyword3 97, :abstract "A condition-based release of preventive maintenance jobs is analysed for a production/maintenance-system where maintenance is performed by a separate department. It is assumed, that the conditions of the machines deteriorate as a function of multiple production parameters. The task of maintenance is to keep up a predefined operational availability. In this context the problem of determining the optimal machine condition that triggers the release of a preventive maintenance job arises. Due to the division of labour between the two departments additional problem-specific characteristics are: (1)A purposive information exchange protocol is required to diminish the information asymmetry. (2)The waiting time between triggering the release and carrying out a maintenance job is determined by different stochastic processes. (3)During waiting time production can be continued, whereby a modified choice of the production parameter setting is possible. In order to solve this problem a specific continuous condition monitoring and a suitable information exchange protocol is developed. On this basis the factors determining the waiting time are operationalised, the economic effects of choosing the triggering condition are presented and alternative stochastic approaches to calculate the triggering condition are formulated. Finally, based on simulations an analysis of solution quality and computational effort is carried out to draw conclusions about suitable application areas of the approaches. Thereby, relevant characteristics of the production/maintenance-system and the maintenance task are varied systematically. The results of this research support the decision makers at the situation-dependent choice of a suitable approach for determining the triggering condition.\r\n", :title "Condition-based Maintenance Policy for decentralised Production/Maintenance-Control", :keyword2 85, :authors (29065 26613), :session 164}, 1029 {:keyword1 77, :keyword3 73, :abstract "Every student in North Rhine-Westphalia, Germany, studying to become a teacher, has to do a semester of practical courses at a school. In order to assign students to schools and satisfy thereby as many requests of the students, without exceeding capacity limitations of the schools, the problem is modeled as a discrete, assignment-like optimization problem and solved to optimality. \r\nThereby every student can select a priority list of five schools, where he wants to do his internship. To avoid arbitrary assignments in the case that a student can not be assigned to one of its priority choices, every student additionally selects a location, where the school for the internship should be close by. Thus, we obtain a composite objective function, maximize the number of satisfied requests and if none of the requests of a student can be fulfilled minimize the distance of the assigned school to the selected location. \r\nSince students study two major subjects, a school has to provide capacity in both of them to be a candidate for a feasible assignment. At the schools there are two different kinds of capacity constraints, first, in each subject there is only a limited number of open positions and second, the total number of students is limited. \r\nParticularly, the capacity constraint for both subjects of a student yield a different kind of assignment problem, which can be represented by a multi-commodity flow network.  Different model formulations, some theoretical results and first computational results are presented.", :title "Assigning Students to Schools for an Internship", :keyword2 8, :authors (9695 14792 1560), :session 214}, 1030 {:keyword1 103, :keyword3 25, :abstract "In this work an economic model of the EU dairy industry has been studied using the system dynamics methodology. The EU dairy industry is characterized by a rapidly changing policy and trading environment. In response to these changes it is expected that complexity and dynamics in this industry will rise. In contrast to existing models (for example the FAPRI model) which are based on partial equilibrium the system dynamics model explicitly focuses on the use of feedback loops and dynamic cause effect chains. The model captures the interdependencies of the major elements among the supply chain of the dairy market. With the model the impact of these elements on the milk price has been studied. Further different EU dairy policies (like the abolition of the EU quota system) have been analyzed and evaluated. The results give hints about which policies are meaningful and achieve the original goals (for example income stability for the farmers) determined by the policy setters and how optimal dairy polices could look like in such a dynamic environment.", :title "A system dynamics model for the EU dairy industry", :keyword2 125, :authors (26596 15381), :session 128}, 1031 {:keyword1 28, :keyword3 93, :abstract "We consider a generation capacity evaluation process where complications arise for the evaluation of the marginal value of plants because of the penetration of intermittent sources. We apply sampling methods both in a static and multistage environments in order to assess the distribution of the cash flow of generation units.\r\n \r\nWe start from standard generation capacity expansion models. Designed as optimization problems for the regulated monopoly industry, they can be interpreted in terms  of equilibrium in a competitive environment. The property remains valid in a risky world assuming  that all agents in the economy are risk-neutral.\r\n \r\nInvestment and operations levels at the optimum of the standard stochastic capacity expansion models are equilibrium quantities in different states of the world. The dual variables of the model play a crucial role as they represent prices and margins in these states of the world.  We show that the Lagrange multipliers associated to the nonanticipativity constraints are the profit margins of the different technologies. We give a procedure for estimating the distribution of these profit margins (which allows one to compute accurately statistics of these distributions).  We illustrate our findings on a simple example which is meant to represent a market subject to three types of uncertainty, namely wind penetration, demand growth and the gas price.  We explore the changes in the generation mix and show that uncertainty about wind penetration exacerbates the need of capital requirement (measured by a CVaR) of an investment. \r\n", :title "Estimation of the distribution of the marginal value of power plants in generation capacity expansion models", :keyword2 85, :authors (29581 8470 3662), :session 120}, 1033 {:keyword1 14, :keyword3 41, :abstract "We propose a method to construct a polynomial approximation for a density function of a Borel measure given a finite number of moments of this measure. We show the polynomial whose moments  coincide with the moments of the desired density function is the minimizer of the L2 norm of the difference between the density function and the vector space of polynomials. In our method we guarantee the polynomial approximation to be a density function itself by additionally enforcing it to be nonnegative. Replacing nonnegativity by sum of squares constraints results in a tractable semidefinite program. It can be understood as an inverse problem for the generalized problem of moments with polynomial data. The approximation accuracy and the size of the problem are determined by the degree of the polynomial approximation, the number of moment equality constraints taken into account and the order of the sum of squares relaxation. Almost uniform convergence of the polynomial density functions to the desired, unknown density for increasing degree of the polynomial can be shown.\r\nImportant areas of application encompass the reconstruction of geometric objects in one or several dimensions, finding smooth approximations for solutions of nonlinear ordinary and partial differential equations, and retrieving trajectories of nonlinear optimal control problems. The superior performance of our method in terms of pointwise approximation accuracy and computation time compared to maximum entropy estimation is demonstrated in numerical experiments for some of these applications.", :title "Reconstruction of density functions by L2 norm minimization and semidefinite programming", :keyword2 82, :authors (19122 13695 29582), :session 200}, 1034 {:keyword1 106, :keyword3 63, :abstract "The Dial-a-Ride Problem (DARP) belongs to the general class of Vehicle Routing Problems with Pickup and Delivery (VRPPD). It consists in scheduling a set of transportation requests on a heterogeneous fleet of vehicles. Each request consists in a number of persons, a specified pickup location, a destination location and desired departure and arrival time windows.  We investigate a new and general model for the transportation of persons, it involves three objective functions that have to be optimized in order to measure the potential efficiency of the DARP solution on different aspects. In practice, the transportation requests of the DARP are usually booked in advance, so in this paper we consider the static version of the problem. More precisely we consider a novel model aimed to be closer to real-life situations since we consider not only the reduction of the transportation costs, which only reflects the transportation operator desires, but also criteria related to the quality of service provided to the users and the ecological impact of vehicle routings. The later is too of high importance, mainly for societal and environmental reasons. \r\n In this paper we focus on the problem of optimal timing in each route, which consists in finding the optimal dates of start service at each location knowing the routes. To solve this problem we present an O(nlog(n)) optimal algorithm  which can be applied to any convex piecewise linear objective function.", :title "Optimal timing computation for quality service in a Dial a Ride Problem", :keyword2 95, :authors (29428 29606 382), :session 189}, 1041 {:keyword1 54, :keyword3 42, :abstract "We analyze a classical sequential location problem on networks, the (r,p)-centroid problem under a binary choice rule. Differing from the majority of previous publications, we consider networks with both, vertex and edge demand. This is motivated by the fact that, in an urban context, demand is typically continuously dispersed over the streets of the city. The corresponding follower problem is known to be NP-hard even on networks with edge demand only. We prove that this remains true for the (r,p)-centroid problem. On tree networks, however, an efficient algorithm to determine a (1,p)-centroid can be derived, once we restrict the location sites to the vertex set of the underlying network (discrete problem class). Bilevel programming models are presented for the discrete (r,p)-centroid problem with vertex and edge demand on general networks. Computational results based on these models indicate, that heuristics will need to approximate the follower’s response to a given set of leader’s locations. An upper bound on the follower’s market share has previously been introduced for the case of vertex demand only. We show that this bound can be adapted to the case of vertex and edge demand.", :title "(r,p)-centroid problems on networks with vertex and edge demand", :keyword2 40, :authors (29563), :session 220}, 1042 {:keyword1 103, :keyword3 102, :abstract "Due to the worldwide ongoing growing population and especially the economic growth of Germany, the energy demand is rising. The countrywide energy economy is still mainly based upon fossil fuels and therefore CO2 emmissions are further increasing. In the case of Germany eepecially the very high energy import dependency of fossil fuels from abroad requires corresponding actions. Germany, as a member of the European Union, holds a leading position in strenghtening the efforts for the 2020 energy transisiton plan. \r\nSystem Dynamics has the potential to idetentify some important factors of the energy transition until 2020 and furthermore can support the path of the European Union’s strategy „Energy 2020 - A strategy for competitive, sustainable and secure energy.” Therefore System Dynamics modelling can be regarded as a powerful modelling tool for creating shared understanding and managing both-complexity and uncertainty.\r\n", :title "Germany‘s 2020 energy transition plan supported by System Dynamics", :keyword2 29, :authors (26937 20972 4796), :session 128}, 1043 {:keyword1 101, :keyword3 94, :abstract "It is well known, that the pharmaceutical industry is struggling with increasing cost and length of R&D projects. Earnings of a drug drop drastically after patent expiration. Thus, the industry spends much effort on reducing Time-to-Market. In the literature, no attention is given to supply chain planning before and during the market entry of the drug after the drug has been approved. \r\n\r\nProduction of the active pharmaceutical ingredient [API] is characterized by long change-over times due to cleaning requirements. Production planning is long term, multiple batches of each drug are produced in succession and each drug is only produced few times annually. Assuming fixed intermediate availability of API, supply network planning consists of finding inventory levels and production volumes for downstream stages to cope with the highly fluctuating demand of new markets.\r\n\r\nUnique for the pharmaceutical industry, reimbursement negotiations have to be carried out before a drug can be marketed. These negotiations both necessitate time phasing market entries and introduce a series of uncertainties e.g. varying allowed price and awarded subsidy. Also if the label is not approved for marketing, all packaged products have to be scrapped.\r\n\r\nWe have developed an MILP supply network planning model, which sets time phased market entries and finds inventory levels and production volumes to balance fluctuating demand with fixed periodic production of the API. Our model is recourse-based and considers demand uncertainty and the risk of a forced label change and includes solution robustness. While considering limited shelf life of the drug, the supply of packaging material and outsourcing, the objective of our model is to reduce supply chain cost including lost peak sales from delayed market entry.", :title "Supply Network Planning for Market Entry of New Products in the Pharmaceutical Industry", :keyword2 75, :authors (29351 909), :session 165}, 1046 {:keyword1 95, :keyword3 8, :abstract "Routing problems occur in wide variety of situations. Different problems have some similarities but differ in subtle ways due to differences in the processes, the needs of operators, the needs of the customers, the legislation, in the dependencies to other operations, and other context-dependent factors.\r\n\r\nDue to this heterogeneity, we do not yet fully know how to make routing software cost-effectively. More specifically, we do not know how to manage the complexity of addressing the relevant aspects in logistic planning and solving the variety of different problem types. This inhibits the application of the latest results in OR to practice.\r\n\r\nThe heterogeneity of routing problem introduces variation. In the last decade, we have witnessed an emergence of systematic approach into managing variation within set of related software systems. This talk presents application of these advances from software engineering into the domain of routing: we suggest the construction of a higher-level (meta-) model of routing problems and the application of a software product line approach.\r\n\r\nThe proposed approach results in a flexible product line for constructing a family of route optimization systems. This talk introduces the product line approach, examines the structure of the system and the properties of the metamodel, and analyzes initial results. The model is shown to be compatible with the state of the art solution methods and its expressiveness is demonstrated by benchmarks and real-life cases.\r\n\r\nWe argue that the usage of software product line approach decreases the effort needed in adapting optimization systems to different variants and solution methods and that implementation of routing systems benefits from recent advances in variability management in software engineering.", :title "Producing Routing Systems Flexibly Using a VRP Metamodel and a Software Product Line", :keyword2 61, :authors (15898), :session 242}, 1049 {:keyword1 105, :keyword3 106, :abstract "Today already many European railway networks run almost at their capacity limit. With the increasing demand for reliable and frequent services as well as limited infrastructure, timetabling for dense networks, as for example in Switzerland, becomes more and more complex.\r\nIn the last decades different algorithmic approaches for solving timetabling problems were developed. Yet the size, computational complexity and the lack of transparent interfaces for planners hinder the roll out to practice. We propose to cope with the inherent complexity by applying geography-based decomposition methods to solve large instances of periodic event scheduling problems (PESP) encompassing the core part of the Switzerland's passenger train timetable.\r\nWe will present ideas to find good cuts to split a periodic event graph in several subgraphs for which we then can solve corresponding MIPs independently. Mathematical decomposition methods were combined with additional information on the infrastructure and service intention. Furthermore several ideas to connect feasible solutions of the decomposed subproblem in order to reach global feasible or even optimal solutions will be discussed.\r\n", :title "Decomposition methods for periodic railway timetabling problems", :keyword2 133, :authors (24125 17127), :session 192}, 1050 {:keyword1 65, :keyword3 77, :abstract "Innovative bandwidth-requiring services lead telecommunication operators to the renewal of their fixed copper access networks, with the introduction of optical fibers.\r\nWhile designing a telecommunication Passive Optical Network, we have to deal with a lot of specific constraints which turn the classical network design problem into a difficult to solve non convex one.\r\nThe core of the problem is a mixed integer linear program which has been well studied, and which can be efficiently solved using branch and bound approaches. \r\nHowever, additional constraints arise from deployment considerations (such as deploying cables instead of individual fibers),  Quality of Services considerations (such as the control of the optical power budget) or regulatory ones. \r\nThe resulting problem is a mixed integer, non linear, program, that proves intractable on real-life instances. With the aim of designing a deployable network, we separate the problem into several sub problems and solve them independently. We describe some solutions and compare them. \r\nNumerical results, based on real-life instances, are given before concluding with the presentation of several sub problems that we wish to solve more efficiently.\r\n", :title "Real life constraints in designing passive optical network architecture", :keyword2 104, :authors (26799 29587 29586 19832), :session 104}, 1056 {:keyword1 88, :keyword3 99, :abstract "We  assess appointment scheduling for outpatients in a hospital. A physician sees K patients during a fixed-length session.  Each patient has been given an appointment time during this session in advance. The aim of our evaluation approach is to obtain accurate predictions at a very low computational cost for the waiting times of the patients and the idle time of the physician. To this end, we investigate a modified Lindley recursion in a discrete-time framework.  We assume general, possibly distinct, distributions for the patient's consultation times, which allows for accounting for multiple treatment types. In addition the model at hand supports patient unpunctuality as well as patient no-shows. The moments of waiting and idle times are obtained and the computational complexity of the algorithm is discussed.", :title "Efficient evaluation of out-patient scheduling with unpunctuality", :keyword2 45, :authors (7336 14874), :session 52}, 1057 {:keyword1 54, :keyword3 8, :abstract "To design public service systems, as for example, distribution systems, emergency medical system, or to decide on positions of marshaling yards throughout the railway network, various types of location and allocation models can be used. In general, this problem can be seen as an example of resource allocation problem, with a central planner. Although the costs for system construction and its operation are typically shared by everybody, not all citizens are enjoying the same access to the service. When it is possible to estimate the satisfaction level of citizens by a utility function, various fairness schemes can be used to compare corresponding allocation strategies.\r\nThis paper focuses on utilitarian solution, obtained when maximizing the sum of all utilities and proportionally fair solution, taking into account proportional changes in individual utilities. As an archetypical example of optimization problem, we are examining the p-median problem, which is solved by the primary-dual based procedure. We use realistic large-scale data describing the road network and spatial distribution of population. By comparing the resulting solutions, for selected range of parameters, we evaluate how costly it is to consider fairness criteria in the service system design. As the proportional fairness scheme does not guarantee the existence of dominant optimal solution for integer problems, we evaluate the close neighborhood of obtained solutions. Based on these analyses we draw conclusion on the price of proportionally fair solutions and we assess their stability.", :title "Proportionally Fairer Service Systems Design", :keyword2 106, :authors (29548 29390 29160), :session 186}, 1058 {:keyword1 101, :keyword3 0, :abstract "In focal supply chains, the original equipment manufacturer (OEM) bears responsibility for the success of the product development, but his influence is often limited. In current practice, product development processes are distributed over various companies. Hence, the components of the final product are not developed centrally at the OEM, but at a variety of specialized suppliers. For this reason, the success of the product development process depends on the specifications of each component of the product and thus on the development effort of the suppliers.\r\n\r\nTo coordinate such product development processes, contracts are used. These contracts include specifications of the components the suppliers develop, the price and potentially penalties.\r\n\r\nIf inappropriate contracts are used in these collaborations, inefficiencies can occur. Reasons can be found in existing uncertainties with regard to the development results and differing objectives of the legally and economically independent companies.\r\n\r\nAgainst this background, we develop a mathematical model for the analysis of decentralized product development processes in focal supply chains. Based on this model, the coordination ability of different kinds of contracts can be analyzed. We applied the model to two different contract types, a fixed-price and an incentive contract. The analysis showed that fixed-price contracts lead to inefficiencies, while incentive contracts can reduce inefficiencies. Based on this approach companies can be supported in forming contracts for decentralized product development processes in focal supply chains.", :title "Coordination of product development processes in focal supply chains with uncertain development results", :keyword2 0, :authors (15178 26841 2651), :session 167}, 1059 {:keyword1 12, :keyword3 0, :abstract "The motif discovery problem consists of uncovering exceptional patterns (called motifs) in sets of sequences. It arises in molecular biology when searching for yet unknown functional sites in DNA sequences. We present a motif discovery algorithm that (1) is exact, that means it returns a motif with optimal score, (2) can use the statistical significance with respect to complex background models as a scoring function, (3) takes into account the effects of self-overlaps of motif instances, and (4) is efficient enough to be useful in large-scale applications. To derive this algorithm, a compound Poisson approximation to the exact p-value (that is, the statistical significance) is used and a branch-and-bound scheme is introduced. To this end, bounds for the p-value of motifs known only partially are developed. Finally, we report on the algorithm's performance in comparison to other algorithms and on applications to non-coding parts of the genome of Mycobacterium tuberculosis, a human pathogen causing tuberculosis. An Open Source implementation of the algorithm is publicly available (http://mosdi.googlecode.com).\r\n", :title "Discovering sequence motifs with optimal statistical significance using a branch-and-bound approach", :keyword2 0, :authors (28964 28982), :session 67}, 1060 {:keyword1 54, :keyword3 8, :abstract "When a public service system is designed, there are two different views on how to evaluate the resulting quality of the system structure. The utilitarian approach, preferring solutions, which maximize the system utility and the fair approach, which takes into account individual users and their rights to have an equal access to provided services. Although, there is no general agreement on what is fair, various basic fairness schemes can be used to decide on the resulting allocation of resources. In this paper we compare the utilitarian approach with generalized max-min fair allocation applied to the p-center problem.\r\nThe main contribution of this paper is the new method able to find the generalized max-min fair allocation for p-center problem in reasonable time. This method is based on the sequential approach, where the size of the problem is gradually reduced. At each iteration, we identify the set of users whose utility cannot be further improved. Centers, corresponding to this set, are added the final set of located centers. Each step requires to solve p-median problem, using the primary-dual algorithm. Effectiveness of the method is demonstrated by numerical experiments, using the large-scale topological data.", :title "Sequential Approach to Large Instances of Generalized p-center Problem", :keyword2 106, :authors (29548 29390 29160), :session 220}, 1062 {:keyword1 95, :keyword3 59, :abstract "In this study, we described a problem of routing a fleet of unmanned combat aerial vehicles (UCAV) to multiple targets toward a common goal. UCAV fleet routing problem with split deliveries (UFRPSD) consists of finding UCAV routes to destroy all predetermined targets completely such that; each UCAV route starts and ends at the base; each target can be attacked by one or more UCAVs and needs a certain number of total ammunition to be completely destroyed. The objective is to find routes with minimum total distance covered. A mixed integer linear programming formulation is developed for the problem. Moreover, an ant colony optimization (ACO) metaheuristic approach is proposed for solution. Ability to accomplish target demolition by more than one UCAV makes the proposed problem similar to the vehicle routing problem with split deliveries (SDVRP). Therefore computational experiments were executed in two parts for original and modified benchmark instance sets of the SDVRPs. Firstly, the performance of proposed ACO algorithm is tested on instances found in the SDVRP literature. The results for SDVRP instances were found promising and interesting. Secondly, original SDVRP instances are converted to UFRPSD instances by adding range limits to the vehicles. UCAV fleet routing problem has not been modeled by handling the payload capacity, fuel capacity and splitting properties simultaneously before. Limited number of studies found in this area lack in describing a standardized model and giving comparable results for the researchers.  In this manner, main contributions of this work are proposing a new generic UFRPSD problem and declaring comparable results that may attract the notice of many researchers and can be further studied with various exact and metaheuristic approaches.", :title "UCAV Fleet Routing Problem with Split Deliveries", :keyword2 60, :authors (29479 29618 42208), :session 247}, 1063 {:keyword1 40, :keyword3 40, :abstract "Social values are nowadays an important issue not only in psychology. Recently there is an increasing interest in the measurement of such values  in (experimental) economics. In our study we focus on the Ring Measure of Social Values (Liebrand 1984, Liebrand & McClintock 1988) and its use in laboratory experiments. \r\n\r\nThe Ring Measure of Social Values is an instrument in which test persons run a lottery. They decide between different allocations of resources (money) for themselves and for others. \r\nIn our study we want to find out the influence of financial incentives on subjects' decisions. \r\n\r\nWe designed an experiment that consists of two treatments: In the first one subjects decide in a hypothetical situation with no direct consequences on the payoffs. In the second treatment the decisions in the Ring Measure influence the payoff of the player and his/her partner.\r\n\r\nWe analyse the behavior of players in an iterated prisoners dilemma game in relation to the measured social preferences and compare the results of the two treatments.\r\nWe check the validity of the construct of social values.\r\n\r\n", :title "Measuring Social Values - the Role of Financial Incentives", :keyword2 19, :authors (29438 26737 281), :session 134}, 1064 {:keyword1 75, :keyword3 0, :abstract "In order to match capacity with highly volatile demand, original equipment manufacturers in the automotive industry apply advances in production technology to increase plant flexibility. For example, multi-model assembly lines are introduced, to generate the capability to assemble different car models on a single assembly line. Combining multiple flexible plants results in a flexible production network, where car models can be re-allocated between plants over time to optimally use available capacity. Since such re-allocations nowadays are feasible in the mid-term, the model-plant allocation decision in flexible production networks is no longer an onetime long-term decision. The planning problem moves from the strategic level to the tactical level and current strategic decision support models do not address the planning situation adequately. Decision support in the form of mathematical planning models accounting for the increased flexibility and characteristics of the mid-term planning situation is required. Two different modeling approaches will be considered in this work and compared for their applicability to the planning situation. An approach based on a one time index model formulation and an approach based on a two time index formulation. To illustrate their benefits and computational limits, quantitative results will be presented.", :title "Mid-term model-plant allocation for flexible production networks in the automotive industry", :keyword2 0, :authors (15390 9272 2651), :session 222}, 1066 {:keyword1 42, :keyword3 106, :abstract "The Steiner connectivity problem has the same significance for line\r\nplanning in public transport as the Steiner tree problem for\r\ntelecommunication network design. It consists in finding a minimum\r\ncost set of simple paths to connect a subset of nodes in an\r\nundirected graph and is, therefore, a generalization of the Steiner\r\ntree problem. We propose an extended directed cut formulation\r\nfor the problem which is, in comparison to the canonical undirected\r\ncut formulation, provably strong, implying, e.g., a class of facet\r\ndefining Steiner partition inequalities. Since a direct application\r\nof this formulation is computationally intractable for large\r\ninstances, we develop a partial projection method to produce\r\na strong relaxation in the space of canonical variables that\r\napproximates the extended formulation. We also investigate the\r\nseparation of Steiner partition inequalities and give computational\r\nevidence that these inequalities essentially close the gap between\r\nundirected and extended directed cut formulation.  Using these\r\ntechniques, large Steiner connectivity problems can be solved\r\nefficiently.", :title "The Steiner Connectivity Problem", :keyword2 57, :authors (15059 17083 14923), :session 209}, 1067 {:keyword1 95, :keyword3 42, :abstract "One of the most successful recent approaches for solving single source - single destination problems in graphs and in particular in digital road maps is the Contraction Hierarchies (CH) algorithm, originally published by [Geisberger et al (2008)]. It is particularly popular in the OpenStreetMap project (OSM).\r\n\r\nThe algorithm consists of two phases: Firstly, a total order on the nodes in the graph is calculated. Secondly for queries, a bidirectional Dijkstra-search is performed on the hierarchy implied hereby. Both search trees meet at the highest ranked node of the optimal path. Only those edges are used that lead to higher ranked nodes, thus strongly bounding the search space. Query performance is strongly determined by the way the hierarchy is built. Further, it is equally important to quickly find a bridging node between the two search trees, as this yields an upper bound for the rest of the search.\r\n\r\nRelying on Dijkstra’s algorithm, CH makes no use of the geometric information contained within digital road maps. We propose a modification of the original query algorithm, by making use of a bi-directional A* search in order to find a bridging node more quickly. Once such a node is found, we re-sort the A* search trees in a Dijkstra fashion and switch to original bi-directional Dijkstra-search.\r\n\r\nFor this paper we have developed a Java implementation of our approach running on digital maps from OSM. We present benchmark results that show a query speed-up by an order of magnitude compared to CH.\r\n\r\n[Geisberger et al (2008)] Geisberger R, Sanders P, Schultes D, Delling D, (2008) Contraction hierarchies: Faster and simpler hierarchical routing in road networks. Proc. of the 7th Workshop on Experimental Algorithms (WEA’08).", :title "Contraction hierarchies with A* for digital road maps", :keyword2 106, :authors (14705 14704 14803), :session 207}, 1070 {:keyword1 106, :keyword3 59, :abstract "In the dial-a-ride problem with split requests and profits (DARPSRP), each request is associated with a revenue and the objective is to maximize the total profit, that is, the total revenue minus the total (routing) costs. Users place transportation requests in advance of the planning. For each request a pickup and a delivery location are specified. Both locations are associated with time windows. A vehicle fleet of fixed size is used to serve these requests. Each vehicle has a given capacity and each route may not exceed a given route duration limit. Transportation requests involving several persons may be split if it is beneficial to do so. Problems of this type are encountered by taxi companies providing pooled transportation services in rural areas. We formulate the DARPSRP in terms of a mixed integer program and we propose several families of valid inequalities. Different problem properties are discussed and small problem instances are solved with CPLEX. For the solution of larger instances a variable neighborhood search (VNS) algorithm is developed. The shaking phase of the proposed VNS relies on three classes of neighborhoods that relocate sets of requests to different routes. Request selection is incorporated into two of them and request splitting is performed during request insertion. A local search heuristic is employed after each shaking step. It allows for request rejoining in the case where the locally optimized positioning of two request parts suggests this to be beneficial. The decision whether to move to a newly generated solution or not follows a simulated annealing type acceptance scheme. We propose a set of benchmark instances and we investigate the impact of different revenue schemes and of request splitting.", :title " The dial-a-ride problem with split requests and profits", :keyword2 95, :authors (20539 17649 9944), :session 189}, 1074 {:keyword1 12, :keyword3 8, :abstract "In modern biomedicine, gene expression profiling has become a well-established tool for disease classification and subtyping. However, cellular functions cannot be understood on an isolated level, but need to be studied in the context of cellular networks. Of particular interest is the identfication of novel functional modules in protein interaction networks by means of detecting differentially expressed network regions under different conditions. This requires on the one hand an adequate scoring of the nodes in the network to be identified and on the other hand the availability of an effective algorithm to find maximally scoring network regions.\r\n\r\nWe present the first exact solution for this problem, which is based on a sound statistical score definition and an unusual connection to the well-known prize-collecting Steiner tree problem, which also appears in network design. Despite the complexity of the underlying combinatorial problem, our method typically computes provably optimal subnetworks in large networks in a few minutes. We have applied our algorithm to data from a well-established lymph cancer study involving 194 patients suffering from two different lymphoma subtypes. Our algorithm discovers biologically meaningful dysregulated modules, which include and extend modules that are well-known for the pathogenesis of the two tumor subtypes.", :title "Prize-collecting Steiner trees in biological networks", :keyword2 42, :authors (11835), :session 65}, 1075 {:keyword1 77, :keyword3 75, :abstract "The steel mill slab design problem from the CSPLib is a bin packing problem that is motivated by an application of the steel industry and that has been widely studied in the constraint programming community. Recently, several people proposed new models and methods to solve this problem. A steel mill slab library was created which contains 380 instances. A closely related bin packing problem called multiple knapsack problem with color constraints, originated from the same industrial problem, were discussed in the integer programming community. In particular, for this problem an integer program based on a column-generation approach has been given by Forrest et al. (INFORMS Journal on Computing, 18 (2006), pp. 129–134). The aim of this paper is to bring these different studies together. Moreover, we adopt the model of Forrest et al. for the steel mill slab problem. Using a state of the art integer programming solver, this model is capable to solve all instances of the steel mill slab library, mostly in less than one second, to optimality. We improved, thereby, the solution value of 76 instances.", :title "Solving Steel Mill Slab Problems with Branch and Price", :keyword2 48, :authors (29588 23876 14771), :session 240}, 1077 {:keyword1 35, :keyword3 19, :abstract "As theoretical and empirical approaches suffer some shortcomings if it comes to analyzing insiders' behaviour, we conducted an adequate experiment. The experimental design incorporates traders with perfect information of the fundamental value of the tradeable asset. These insiders compete with regular uninformed participants on different market structures, in particular on a transparent and on an intransparent call market as well as on a continuous double auction. The results shed first light on a couple of interesting issues, including whether and how insiders try to stay undetected, how their profits are accumulated and what market structure is more advantageous for insiders.\r\n", :title "An experimental study examining insider trading with respect to different market structures", :keyword2 40, :authors (23103 23119 281 14545 29559), :session 133}, 1078 {:keyword1 18, :keyword3 97, :abstract "Public transport is thought an important contribution towards increased environmental friendliness. On the other hand, the bus and tram fleet contributes substantially to pollution. Managers thus need to decide about changes in the transportation network like fleet changes, timetables or attracting more passengers. In this paper, we design a decision support system (DSS) based on data a typical transportation company already has or could easily collect. \r\n\r\nIn our test case of a mid-sized German city, we did paper and field research on key data such as   distances and driving times between stations, length of passenger stops, obstructions and utilization per route and time segment. A semi-official Handbook of Emission Factors in Traffic was used to provide emission factors by street type and transportation mode.\r\n\r\nThe model calculates different emission types on each of the route sections depending on several factors. Changes of route characteristics (e.g. low speed zones), of fleet and fuel composition may be simulated.\r\nThe user interface allows displaying the whole transportation network on a GIS system, color marking route sections by amount of emission or emission per passenger. Public transport companies can integrate this information in their investment decisions. \r\n", :title "A decision support system for changes in public transportation networks to meet CO2-efficiency requirements", :keyword2 31, :authors (8450 29117 15857), :session 131}, 1079 {:keyword1 75, :keyword3 99, :abstract "Using inventory pooling, enterprises become able to reduce their local stockpiles and to improve their service by sharing goods between different stocking locations. In the literature, many different models for various situations have been developed. In this presentation, we analyze a model for emergency transshipments between three identical retail outlets with negligible transshipment lead times as introduced by Tagaras (1999). We extend the analysis onto generally distributed demand. Numerical studies show the influence of different probability distributions on several performance measures e. g. the echelon holding costs and the service levels.", :title "Analysis of emergency transshipments under general demand distributions", :keyword2 101, :authors (29593 6751 29595 29596), :session 223}, 1080 {:keyword1 77, :keyword3 0, :abstract "Mixed-integer linear programming (MIP) is a powerful tool for solving combinatorial optimization problems. Primal heuristics are an important component of state-of-the-art codes for MIPs to find feasible solutions early during the search. Most MIP primal heuristics presented in the recent literature solve sequences of linear programs or even smaller sub-MIPs to construct high-quality feasible solutions. In this paper, we will concentrate on primal heuristics that only employ computationally inexpensive procedures such as rounding and logical deductions (propagation). Rounding and propagation heuristics are particularly valuable for the construction of first feasible solutions already during root node processing.\r\n\r\nRounding heuristics try to round the fractional values of a linear programming relaxation such that the rounded integral vector stays feasible for the constraints. This can typically be performed in linear time. Propagation heuristics expand a small auxiliary branch and bound tree to find feasible solutions. Domain propagation techniques rather than linear programming relaxations are used to guide the search.\r\n\r\nWe discuss eight different approaches, some known from the literature and some new ones. All approaches have been implemented in the branch-and-cut framework SCIP. Computational results assess the impact of the heuristics to the ability to find feasible solutions and to solve MIP problems to optimality.\r\n", :title "Rounding and Propagation Heuristics for Mixed Integer Programming", :keyword2 57, :authors (16880 12336 29594), :session 228}, 1081 {:keyword1 18, :keyword3 106, :abstract "Under consideration of a worldwide growth of transportation demands the network operations of forwarding companies handling less-than-truckload (LTL) items, the performance is significantly influenced by each node within the network. Although real-time information of handling processes like routing vehicles, special yard operations and gate assignments is increasingly available, most companies do not generate benefits of it. In this approach known and specially developed scheduling heuristics are developed based on limited resources for cargo handling, various weights and sizes of goods, uncertain and varying truck arrival times and different linehaul departure times. We apply and compare several strategies to schedule incoming trucks, buffer areas and handling equipment like forklift trucks. \r\nThis project, funded by the BMWi (Federal Ministry of Economics and Technology) in Germany, has two main objectives. On the one hand, the tour planning in the short distance region of the forwarding agency, and on the other hand, the yard management and door assignment of trucks is optimized to improve the intra-terminal goods handling. The common goal of this project is to combine the two optimization approaches to achieve additional benefits. In the following we show the main results of the optimized terminal and yard operations based on real input data of two LTL terminals.\r\nThe developed six algorithms allow the implementation into a real-time system, but positive results require the data input of the tour planning. Even static evaluations allow valuable performance estimations of the terminal operation. Performed computational tests with real data of two different terminals demonstrate the potential of this decision supporting system for yard management.", :title "Scheduling strategies for logistics terminals and yards", :keyword2 96, :authors (26516 26657), :session 186}, 1082 {:keyword1 93, :keyword3 25, :abstract "The Amplitude Model (TAM) emerges as a complement to the models Hurwicz and Laplace, to assist in decision making under uncertainty, when one of this pair of models could not decide because it had a tie between the best alternatives or when each favored a different alternative when having other evidence.\r\n\r\nThe novelty of this model is that besides being based on the expected value it makes use of data dispersion throughout the range or amplitude thereof. TAM creation gave rise to problems under uncertainty, almost naturally, for problems under risk, Model Amplitude for Risk and Uncertainty (MARU), which follows the same philosophy of using the amplitude as penalty.\r\n\r\nBoth models, TAM and MARU use a multiplicative factor B to handle the influence of amplitude on the decision-making. This factor B, which should be in a range between 0 and 1, is up to the decision maker, which could create some kind of bias in some situations. This paper is dedicated to demonstrate what should be the range of B and hence arises the objective of it: Establish the range in which it must operate the B factor of The Amplitude Model and Model Amplitude for Risk and Uncertainty.\r\n\r\nTo demonstrate the use of B will present a series of problems with which they operate will be further TAM and MARU.\r\n\r\nKeys works: Decision making, Uncertainty, Risk, Factor B, The Amplitude Model (TAM).\r\n\r\n\r\n\r\n", :title "Stabilization of the B factor in the Amplitude Model and the Model of Amplitude for Risk and Uncertainty", :keyword2 19, :authors (10380 10390 29599), :session 258}, 1083 {:keyword1 94, :keyword3 0, :abstract "An essential task in railway optimization is train classification: according to a classification schedule incoming trains are split up into their single cars and are reassembled to form new outgoing trains. Often such a prepared sorting schedule becomes infeasible when the incoming trains are subject to delay and arrive in an unexpected order. Classification methods applied today deal with this issue by completely disregarding the input order of cars, which presents robustness against any amount of disturbance but also wastes the potential contained in an a priory knowledge of the input.\r\n\r\nWe introduce a new method that provides a feasible sorting schedule for the expected input and allows to flexibly insert additional sorting steps if the schedule has become infeasible after revealing the disturbed input. By excluding disruptions that almost never occur from our consideration, we obtain a classification process that is quicker than the current railway practice but still provides robustness against realistic delays. In fact, our algorithm allows a trade-off of fast classification and high degrees of robustness depending on the respective need. We further explore this flexibility in experiments on real-world traffic data underlining that our algorithm improves on the methods currently applied in practice. \r\n", :title "Recoverable Robust Train Classification", :keyword2 106, :authors (29317 17092), :session 245}, 1084 {:keyword1 121, :keyword3 47, :abstract "The talk presents a general approach for flexible days off scheduling. The main objective is to minimize the total workforce that is scheduled over a planning horizon of several days to cover time varying worker requirements. When performing the scheduling the minimum and maximum number of consecutive days on as well as consecutive days off is limited. Furthermore, the total assignment of working days, i.e. days on, in the planning horizon is limited by some maximum value. \r\n\r\nTo solve the problem we develop a branch & price algorithm. The master problem is stated as a set covering type formulation. To find promising schedules we use three different subproblem representations. The first subproblem is based on implicit modeling techniques whereas the second uses a resource constraint shortest path formulation. Both formulations are solved using state of the art optimization software, which is in our case CPLEX. Eventually, the third subproblem formulation exploits the underlying network flow structure. We introduce a dynamic programming formulation and solve it applying a labeling algorithm. We implement a branching scheme based on master problem variables and show how the constraint region of the subproblems must be changed to find optimal schedules. In our computational experiments we show the benefits of flexible days on and days off scheduling using real data.", :title "Flexible days off scheduling: A general approach", :keyword2 96, :authors (15060 29609), :session 140}, 1085 {:keyword1 86, :keyword3 0, :abstract "We examine a workforce assignment problem arising in the multi-project environment of a company. For a given set of workers and for a given set of projects, we want to find one team of workers for each project that is able to satisfy the project workload during each period of project execution. The projects require certain skills offered by workers who master different subsets of skills at various levels. Workers may be assigned to more than one project, but their working time is limited in each period. The aim is to minimize average team size, i.e. to minimize the total number of assignments of workers to projects in order to improve team performance and to alleviate project workflow. \r\n\r\nWe outline two mixed integer linear programming (MIP) formulations of the NP-hard optimization problem and introduce four heuristic approaches to this problem. The first MIP formulation is related to a generalized assignment model, whereas the second formulation is based on a network flow model. The first two heuristic approaches are derived from the DROP and the ADD procedure, respectively, known from warehouse location problems. They provide good quality solutions, but require relatively high computational effort. A third heuristic approach is a simple stochastic construction heuristic while the fourth approach exploits matchings on a bipartite graph to construct a solution. \r\n\r\nA numerical study for the two MIP formulations revealed the superiority of the network flow model when small-scale instances are solved by the commercial solver CPLEX. Additionally, we will present preliminary computational results for the heuristic approaches on large-scale instances.\r\n", :title "On a multi-project staffing problem with heterogeneously skilled workers", :keyword2 77, :authors (17325 5965), :session 64}, 1086 {:keyword1 106, :keyword3 0, :abstract "Vehicle routing problems (VRPs) are meaningful problems in real-life distribution management. Most of the algorithms for VRPs reported in the literature are used to solve one specific VRP. Normally, different variants ask for different parameter settings or even different approaches. In real-world situations on the vendor side as well as on the customer side, today’s economic conditions induce merging companies to larger units therefore vehicle fleets have to be able to service customers and routes with different tasks. Accordingly, a key issue is to design methods that are generic, although genericity should not be achieved at the expense of solution quality.\r\nWe develop a unified framework for solving seven different VRPs with fixed fleet size beginning with the capacitated VRP through the VRPs with time windows and the open VRPs up to the time-dependent VRPs. Further we consider two different types of time windows: soft and hard time windows. Consequently we have to deal with two different objective functions.\r\nAll problem variants are solved with a generic method, a modified variable neighborhood search algorithm while using a default parameter configuration. For realization the problems have to be transformed to a standardized VRP. A computational study, in which the different variants of VRPs are considered, is performed on standard benchmark instances from the literature. The outcomes of the tests are promising and they show that generality does not come at the expense of solution quality. The realized prototype for a generic framework can provide a good basis for a further extension in terms of integration of more sophisticated tuning algorithms and state of the art statistical methods to evaluate the performance of the designed solution procedure.\r\n", :title "Solving Vehicle Routing Problems with a Unified Variable Neighborhood Search Framework", :keyword2 59, :authors (23775 19001 2769 10538), :session 247}, 1087 {:keyword1 29, :keyword3 0, :abstract "The classic energy supply chain is changing. The demand for renewable energy generation and an improved energy efficiency leads to emerging technologies in production, consumption and storage. In general, this leads to a more decentralized energy supply chain. This switch to a decentralized grid also has its implications on the transmission and distribution grid.\r\n\r\nThe management and control of the energy supply chain are changing accordingly. Due to the large amount of different appliances and the varying flexibility in control for these appliances the control of such a smart grid needs new approaches. At the University of Twente a three step methodology to control the energy supply chain has been developed. In this method, predictions on local device level, a planning based on these predictions, and real-time control methods to deal with deviations from the predicted values are used.\r\n\r\nIn this talk we shortly sketch the three step methodology and we propose an energy flow model for the energy supply chain. This model consists of four types of devices (nodes) and energy flows between them. Each energy flow is linked to an energy pool, which requires conservation of energy. Each device type has its specific characteristics to model the different kinds of appliances in the smart grid. The model is very general, allows all types of energy to be used and easily models conversion between different energy types. It forms the base for developing solution approaches for the different steps of the three step methodology.", :title "A general model for the energy flows in the energy supply chain", :keyword2 0, :authors (26519 8513), :session 129}, 1091 {:keyword1 8, :keyword3 0, :abstract "The classical inverse shortest path problem is to find an optimal\r\nmetric such that some prespecified paths become shortest paths. In\r\nthis talk we consider a feasibility variant of this problem where some\r\narcs are prohibited to be in a shortest path to some destinations.\r\nThis problem is central in bilevel programs with shortest path\r\nproblems at the lower level, e.g. some Stackelberg network pricing\r\nproblems and the design of OSPF networks.\r\n\r\nThe Farkas system of the node-arc formulation of the inverse shortest\r\npath feasibility problem is closely related to the multicommodity flow\r\nproblem. However, it has some important characteristics: (1) flow may\r\nbe negative on some arcs for some commodities, (2) all arc capacities\r\nare zero, (3) all flows are circulating, and (4) all capacity\r\nconstraints are 'essentially binding'. It is straightforward to\r\ntranslate this problem into a standard multicommodity flow problem,\r\nbut because of (4) the resulting instances belongs to hardest possible\r\ninstances of the multicommodity flow problem even for small problems.\r\n\r\nOur modelling is based on fundamental cycle bases, i.e., we use\r\nvariables that corresponds to circulations. By choosing the trees that\r\ninduce the fundamental cycle bases appropriately we can handle (2),\r\nthe negativity issue, implicitly. This results in a compact model\r\nwhere only capacity constraints remain.\r\n\r\nWe investigate some theoretical properties of the original problem via\r\nour new formulation. In particular, we show that there is a solution\r\nwhere all capacity constraints are binding. We also report on\r\nnumerical experiments that verify that the cycle basis formulation is\r\noften significantly easier to solve by commercial LP-solvers than the\r\noriginal formulation(s).\r\n", :title "Inverse shortest path problems via Fundamental Cycle Bases", :keyword2 0, :authors (25545 2190), :session 212}, 1093 {:keyword1 108, :keyword3 14, :abstract "Mountain pass theorems for scalar-valued functions are important tools\r\nin critical point theory. In the present talk we extend a mountain pass theorem to smooth vector-valued functions f acting between finite-dimensional spaces. Under suitable geometric condition we prove the existence of a critical point of f and we localize this point as a solution of a minmax problem. The considered minmax problem consists of an inner vector maximization problem and of an outer set-valued minimization problem. To deal with the outer set-valued problem we use the solution concept introduced by Kuroiwa. The talk is based on the joint work with Elena Molho and Enrico Miglierina.", :title "A mountain pass theorem for vector-valued functions", :keyword2 79, :authors (48141), :session 194}, 1095 {:keyword1 97, :keyword3 40, :abstract "It is an open question how cooperation develops if participants are not informed about the continuation probabilities, but can form expectations from prior experience. How does the shadow of the future interact with the shadow of the past? Are there easy rules which are capable to explain observed behavior?\r\nThe experimental design by Hennig-Schmidt/Leopold-Wildburger (2010) helps to study this situation. \r\nObservations indicate that easy stochastic rules with Markov structure might apply successfully.\r\n\r\nIn the simulation study we raise the question whether the experimentally observed time pattern of cooperation can be reconstructed with a simple Markov model of individual behavior. The model parameters are inferred from the experimental data. The resulting Markov model is used to simulate experimental outcomes. Our Markov model with symmetry assumptions might be a reasonable description of transition probabilities for successive states of cooperation. Surprising, the model is extremely simple, and no attempt to model end behavior has been made so far. Our Markov model explains run behavior reasonably well.\r\n\r\n", :title "A Markov Model of Behavior in an Iterated Prisoner's Dilemma Game", :keyword2 19, :authors (9096 26937 281), :session 133}, 1098 {:keyword1 67, :keyword3 0, :abstract "An introduction as well as recent advances on Benson's algorithm are presented. This algorithm can be used to solve real world problems. Examples from finance are given. Recent improvements of the algorithm include the case of arbitrary polyhedral ordering cones. We formulate the problem to compute the set of super-hedging prices in incomplete markets with transactions costs as a sequence of linear vector optimization problems and solve it with the new variants of Benson's algorithm.", :title "On algorithms for linear vector optimization problems and applications in finance", :keyword2 63, :authors (19168 29603), :session 78}, 1100 {:keyword1 8, :keyword3 42, :abstract "In many transportation systems, the shipment quantities are subject to minimum lot sizes in addition to regular capacity constraints. This means that either the quantity must be zero, or it must be between the two bounds. In this work, we consider a directed graph, where a minimum lot size and a flow capacity are defined for each arc, and study the problem of maximizing the flow from a given source to a given terminal. We prove that this problem is strongly NP-hard. In a recent paper, we have suggested a heuristic method that gradually augments the set of flow-carrying (open) arcs. Checking feasibility of intermediate solutions in this heuristic is accomplished by solving regular maximum flow problems in an extended network. In the current work, we consider enhancing the performance of the application. We start by profiling a serial implementation of the heuristic algorithm and identifying the most expensive computational kernels. Then, we study two different levels of parallelism: parallelism among the computational kernels and parallelism within each kernel itself. Moreover, since the heuristic algorithm involves solving a series of regular maximum flow problems that each has an initial feasible flow, we test the possibility, performance, and parallelizability of different known max-flow methods. We finally report the achieved speedup of the new implementation when executed on a 2 x 6 AMD Opteron processor.", :title "Parallel algorithms for the maximum flow problem with minimum lot sizes", :keyword2 74, :authors (29602 15948 29604 29605), :session 206}, 1101 {:keyword1 96, :keyword3 0, :abstract "We discuss a real-world scheduling problem arising when servicing railcars. In regular time intervals railcars have to be checked and serviced, which requires some sequential maintenance steps depending on the degree of wear.\r\n\r\nMaintenance is carried out in a service hall with several parallel rail tracks and a dead end at each track at the opposite side of the gate. At each track some machines perform the same maintenance step. As a consequence, each railcar has to visit several tracks in a predefined and specific order to finish its service.\r\n\r\nInterruptions of maintenance steps are not allowed. Hence, no railcar can pass another railcar being currently serviced on the same track and has to wait until that service is done. We shortly refer to this complicating fact as blockages. The resulting problem is described as a particular flexible job shop model with identical machines at each stage including these blockages.\r\n\r\nIn particular, we shortly develop a suitable mixed integer linear programming model enhanced by some cuts, lower bounds and a heuristical method and we present an exact solution method in detail. The exact solution method is based on a Branch&Bound-Algorithm using specific lower bounds that are generated by longest paths and are determined without relaxations. Furthermore, we show that these lower bounds are sufficient to characterize feasible solutions of the above problem and we describe the structure of these solutions.\r\n\r\nFinally, we discuss computational results for several data sets and different branching rules.", :title "Flexible Job Shop Scheduling with Blockages and an Application in Railcar Maintenance", :keyword2 8, :authors (26387 13837 15375), :session 144}, 1102 {:keyword1 101, :keyword3 76, :abstract "In supply chain management, optimization of inventory policies is prominent for the improvement of the performance of a supply chain modeled as a multi-echelon inventory system. In the literature, two approaches are used in the optimization of inventory systems: stochastic-service approach (SSA) and guaranteed-service approach (GSA). In this paper, periodic-review, serial inventory systems with Poisson external demand and fixed order costs at each stock are considered and the GSA approach is used to design their optimal inventory policies. Because of the existence of fixed order costs, echelon (R, nQ) policies are used to control the inventory replenishment of each stock in the system. It is assumed that the demand is bounded and that there is a guaranteed service time between every stage and its customers under the GSA framework. We derive an analytical expression of the total system cost function, which is neither convex nor concave. Based on this, the problem of finding optimal echelon inventory policies for the system can be decomposed into two independent sub-problems, a batch size decision problem and a reorder point decision problem. For the first sub-problem, we find a bound for the optimal batch size at each stage of the system, and then develop an efficient dynamic programming approach to solve it. For the second sub-problem, we find a lower bound of its cost function by linear approximation and develop an efficient branch and bound algorithm for obtaining an optimal solution of the problem. The computational study on randomly generated instances demonstrates that the algorithms are able to obtain optimal inventory policies quickly. ", :title "Optimal (R, nQ) Policies for Serial Inventory Systems with Guaranteed Service Approach ", :keyword2 48, :authors (29241 19703), :session 169}, 1103 {:keyword1 54, :keyword3 0, :abstract "In the future, biomass will play an important role as energy carrier. Currently, different biomass-based processes for the production of electric energy and solid, liquid or gaseous fuels are investigated and realized in pilot plants. Decision support, in particular strategic supply chain design, is required for the future implementation of large scale plants and value chain networks, which consist of several plants for biomass preparation, chemical conversion and separation steps. This must especially address the multi-layer structure of the value chains, simultaneously determine number, capacities and locations of production steps under consideration of mass and energy flows of the underlying technical processes. Taking into account economies of scale arising with increasing plant capacities the problem becomes non-convex. As data on production costs is scarcely available costs can be estimated on the basis of investments.\r\nIn this contribution, different modeling approaches are compared for the multi-layer location problem of a biofuel production value chain using wood and straw residues and applying crushing, drying, pyrolysis, gasification, gas cleaning and conditioning and Fischer-Tropsch synthesis. So far, no solution approach has been established in literature for large, non-convex multi-layer location and capacity planning problems. As a result, piecewise linear approximation of the non-convex cost functions is applied. Utilization of special-ordered sets of type 2 (SOS2) is compared to common mixed-integer approaches, both using CPLEX 12. The computational limits regarding the model size are demonstrated by means of a case study for a specific region.\r\n", :title "Comparison of different modeling approaches of the multi-layer location problem for bio-energy applications", :keyword2 100, :authors (23469 8713 2675), :session 128}, 1104 {:keyword1 106, :keyword3 0, :abstract "This paper considers a decision problem as it arises in a rail-road ransshipment yard when unloading a bundle of trains. The loading units, e.g. containers, arriving on trains and occasionally arriving on trucks have to be placed on storage lanes of limited capacity. Loading units are placed and removed keeping stacking and crane rail moves small. We present two NP-hard models and three heuristics for solving the problem. One of these heuristics is currently applied at the yard. The algorithms are then tested using real life data.", :title "Positioning of loading units in a transshipment yard storage area", :keyword2 86, :authors (12453), :session 140}, 1106 {:keyword1 6, :keyword3 77, :abstract "Based on the benefits of acquiring complementary goods in auctions of new power plants in the Brazilian context, this paper aims to evaluate a combinatorial auction format in order to ensure greater competition in this process. Thus, the investors are able to effectuate bids on packages of ventures. Therefore, it was used a binary integer programming model (set-packing) in order to implement the computational problem of solving the auction through an optimization tool. Although the set-packing problems are considered NP-hard, it was converged in a satisfactory computational time, so this methodology was feasible to the Brazilian electric energy market.\r\n\r\n", :title "Combinatorial auction - an application in the Brazilian electric energy market", :keyword2 28, :authors (27936 28216 1309), :session 137}, 1110 {:keyword1 101, :keyword3 100, :abstract "Optimal purchase decisions and strategies are to be figured out and implemented in order to support enterprises to persist in the increased competition on global markets. Complex economic interdependencies, uncertainty of future demands and different kinds of discounts complicate an optimal selection of suppliers and allocation of orders. The short term decision for a certain product with lowest price can be optimal, but in another situation may induce losses when volume discount margins are missed. Deterministic mathematical programming models are suitable to handle complex situations and support optimal supplier selection and order allocation under certainty. But usually, unpredictable demand modifications occur during a contract period and a predetermined solution loses optimality or even feasibility. Therefore, a sustained interest in a robust solution of quantitative purchase models exists and decision-support systems should provide solutions which can be used even if product needs change. Enterprises take a great interest in dealing with flexibility and robustness. Quantitative models based on the analysis of purchase situations, handling stochastic demands and different volume discounts are presented which provide the basis for further developments according to different robustness concepts. Numerical examples and some computational results are reported which demonstrate the influence and effects of volume discount implications and features on optimal purchase solutions. An evaluation of several robustness approaches and their consequences on the quality of recommended solutions compares the resulting benefits. ", :title "Robustness in purchase models with discount consideration", :keyword2 94, :authors (26288 10057), :session 225}, 1111 {:keyword1 106, :keyword3 77, :abstract "We present a model that optimizes the toll controlling on German motorways. Since 2005 a distance based toll for freight vehicles is introduced. The paying of the toll has to be enforced, which is partly done by mobile control teams. Our goal is to guarantee a network-wide control that is proportional to regional and time-dependent traffic distributions. Since each team can only control local sections, an anonymous planning of the tours and a subsequent duty and roster planning is not possible. \r\nTherefore, we set up a model for an integrated tour and duty roster planning for the mobile teams. The first subproblem, the tour planning, could be seen as a vehicle routing problem with profits under additional constraints like minimum control requirements and tour length restrictions. We formulated this problem as a multi-commodity flow problem in a time-expanded graph. \r\nAlso for the rostering problem we used a multi-commodity flow formulation. In the related graph the nodes correspond to duties and the arcs model feasible sequences on the duties. Hence each feasible duty roster corresponds to a path in this rostering graph. Both problems were formulated by an Integer Program and extended by coupling constraints to an integrated formulation. \r\nWe will present computational results for this model on some practical instances from a control area of East-Germany. The results show that we could consider all important legal rules for the duties and achieve a problem size that is tractable for state-of-the-art solvers to solve the instances near to optimality.", :title "An IP approach for an optimized toll enforcement", :keyword2 73, :authors (23714 20679 14923), :session 190}, 1113 {:keyword1 78, :keyword3 75, :abstract "This paper presents an optimization approach for the integrated planning of production and one-stage outbound distribution to transshipment points on an aggregate level for a plant of an automotive vehicle manufacturer. The motivation is twofold. First, the potential economic benefits through higher transport utilization and lower finished goods inventory carrying cost as observed in other industry sectors shall be realized in the automotive industry. Second, the bundling of larger numbers of orders with the same destination shall enable an increased use of rail transports instead of road transports and contribute to a greener supply chain.\r\n\r\nThe contribution of this paper lies in the consideration of characteristics from mixed-model assembly lines in the integrated optimization of production and outbound distribution. Using industry data from a German vehicle manufacturer, customer orders are allocated to daily order buckets for one plant in a multi-modal one-stage distribution network while constraints from both production and distribution are respected. The problem is formulated as an extension of the multi-resource general assignment problem (MRGAP) and solved with CPLEX. We compare the results of the integrated approach to the results of the traditional approach where production and distribution are optimized separately and discuss the quality of the solution as well as the solution method. The integrated approach results in lower costs and a larger share of rail transports; transport utilization does not differ significantly. The model presented can serve as a basis for a logistics decision support system for integrated production and outbound distribution planning in the automotive industry.\r\n", :title "Integrated Production and Outbound Distribution Planning in the Automotive Industry", :keyword2 106, :authors (29220 26398 29612), :session 222}, 1114 {:keyword1 66, :keyword3 57, :abstract "Generalized differentiation concepts have proven to be useful tools for the derivation of optimality conditions for many types of non-smooth optimization problems in finite dimensional spaces. Though there exists a large body of theory concerning generalized differentiation in Banach space settings, there is a general lack of concrete results pertaining to settings of interest to many problems in PDE-constrained optimization and MPECs in function spaces.\r\n\r\nWe discuss some of the difficulties of directly applying certain results from the given theory.  Afterwards, we take a specific example derived from the theory of mathematical elasticity and demonstrate how to explicitly calculate the involved derivatives. These results are then used to derive so-called strong stationarity conditions for an associated bi-level programming problem.", :title "Generalized Differentiation of Solution Mappings in Function Spaces with Applications to Bi-level Programming", :keyword2 126, :authors (19086), :session 200}, 1115 {:keyword1 40, :keyword3 39, :abstract "The analysis of any process frequently involves the identification of the different causes which intervene in it and the quantification of their relative importance. The study of mortality in road traffic accidents or the performance of health care delivery services are examples of areas in which this kind of analysis is done. \r\n\r\nTo determine the exact incidence of each cause is a significant issue, so that priority assessments become crucial for implementing precise actions to diminish mortality in traffic accidents or improve health care delivery services. However, the data available on the performance of these systems is frequently incomplete, contains uncertainties, or involves high complexity. In this fuzzy context, in which assume assuming independence of the causes, we propose some measures to evaluate the importance of each cause.\r\n", :title "Evaluation of the incidence of causes in systems with incomplete data", :keyword2 45, :authors (11762 19612), :session 136}, 1116 {:keyword1 40, :keyword3 0, :abstract "China’s civil aviation industry has observed many challenges since its initial deregulation and economic reforms in 1978, which saw the beginnings of a transformation from a fully state-owned entity to a rent-seeking corporation. The major challenges that came with the deregulation are a lax market entry, a sudden surge in new carriers and the intense price wars that result in major losses for the entire industry in 1998. A reform was sought and in late 2002, mergers and consolidation efforts had led to 3 major dominant carriers: Air China Limited (AC), China Eastern Airlines (CEA), and China Southern Airlines (CSA). AC and CEA have an equal number of announced acquisition deals, which stood at twenty two; out of which 8 and 4 deals were concluded to date, respectively.  We investigated the sales, expenses, revenue and profit data of the 2 airlines, and based on a 2-player noncooperative game model; we analyze the strategic efficacy of their decisions to merge based on equilibrium changes. The results indicate that although both players are better-off not acquiring in terms of profit/sales ratio, this is deemed to be a weakly dominant strategy. As such, a stable solution is for both to continuously see their acquisitions through although the increased in profit/sales ratio is lower for its post-acquisition strategy. This implies that liberalization of the civil aviation industry in China through merger and acquisition activities offsets the drawbacks of its initial deregulation policies.     ", :title "A Game Theoretic Model for China's Aviation Sector", :keyword2 106, :authors (29610 28935 29615 29616), :session 138}, 1120 {:keyword1 101, :keyword3 0, :abstract "Volatility of sales during the year has been a popular topic for many years and can often be related to well known effects like the bullwhip effect, demand seasonality or sales timing. However, volatility of inventories has often been disregarded and is also important since higher inventory volatility requires companies to extend warehouses and keep higher safety stock to buffer against stock-outs.  We use quarterly firm-level inventory data for US public companies to analyze the volatility of inventories. Based on a comprehensive literature review and economic theory hypotheses on the drivers of inventory volatility and its financial impacts are developed. In a next step, a large sample of US manufacturing companies from COMPUSTAT is analyzed to test the hypotheses. Different statistical methodologies are used to gain the required insights. The objective of this paper is threefold: First, a performance measure for inventory volatility is derived that is used to identify the level of volatility in companies and industries over time. Second, the determinants of inventory volatility are identified and linked to different drivers. Third, the financial impact of volatile inventories to the company is investigated. \r\n", :title "Does it swing? An Empirical Analysis of Inventory Volatility in Supply Chains", :keyword2 0, :authors (29614 29434), :session 170}, 1121 {:keyword1 19, :keyword3 23, :abstract "The authors present a new approach to determine optimal strategies for so called antagonistic positional games. As example special markov decision processes are considered. A new algorithm is characterized. Furthermore some applications within the area of complex processes (energy systems) are discussed.", :title "Optimal Strategies within  Antagonistic Positional Games in Markov Decision Processes", :keyword2 40, :authors (9694 4796), :session 133}, 1122 {:keyword1 29, :keyword3 0, :abstract "Decision-making processes concerning the selection between different alternatives need support by analytical methods that are able to adequately capture the complexity of reality. Well-developed paradigms, such as modern portfolio theory introduced by Harry M. Markowitz in 1952, are often based on probability theory and widely used for both financial as well as real assets. However, a number of empirical studies have shown that Markowitz’s approach captures reality only partially. In this paper, we propose fuzzy theory as an alternative to the classical, probabilistic approach. In contrast to probability theory, the possibility distribution function, which corresponds to the probability distribution function, is defined by a so-called membership function describing the degree of affiliation of fuzzy variables. Thus, the aim of this paper is to investigate the usefulness of a fuzzy portfolio selection model, where investor's aspiration levels of a portfolio's return and risk are regarded and expressed by membership functions. We define portfolio risk as a downside risk measure and introduce a fuzzy semi-mean absolute deviation (FSMAD) portfolio selection model. We apply our model to the selection of mixes of power generation assets (plants) and compare the results with those obtained from applying the classical Markowitz model. We conclude from our analysis the following: (1) using a downside risk measure causes the efficient frontier to shift with respect to the scale of risk, (2) the application of membership functions for investor's aspiration levels regarding portfolio’s return and risk reduces the set of efficient portfolios. Both conclusions could have a significantly influence on the decision-making processes of energy providers.", :title "On the Use of Fuzzy Theory for Optimizing Portfolios of Power Generation Assets", :keyword2 0, :authors (59838 21108), :session 130}, 1123 {:keyword1 106, :keyword3 77, :abstract "We consider the crane scheduling problem in European road-rail terminals. In\r\nsuch terminals up to three rail mounted gantry cranes (RMGs) lift load units\r\n(containers, swap bodies and trailers) between trains, trucks and storage\r\nareas. Each transportation job needs to be assigned to a crane and for each\r\ncrane a sequence of the assigned jobs has to be calculated. The objective is to\r\nreduce the total length of empty crane moves, setup costs for cranes and\r\nwaiting times for high-priority jobs. Hard constraints are job release dates,\r\nnon crossing constraints for the cranes and travel time constraints for the\r\ncranes. Besides the objective a main difference to most crane planning problems\r\nin maritime terminals is that cranes have to move load units by crane movements\r\nalongside the rails. For maritime cranes often only loaded trolley movement is\r\nconsidered.\r\n\r\nWe present a MIP formulation of the problem and heuristic approaches which are\r\nbased on list scheduling and local search with tabu search and simulated\r\nannealing. One scheduler is based on the assumption that each crane has a fixed\r\nworking area and the working areas partially overlap. So crane interference\r\nonly have to be avoided within the overlapping areas and for some jobs only\r\none crane is left for handling the job. Other jobs have to be split and handled\r\nby two cranes consecutively.\r\nAnother scheduler implementation restricts the crane working areas only due\r\nto physical restrictions caused by other cranes. So nearly all jobs can be\r\nhandled by every crane.\r\nWe compare the solution quality and the runtimes of the two schedulers. For\r\nsmall size instances the scheduler solutions are also compared with solutions\r\noptained by solving the MIP model.\r\n", :title "Crane scheduling in road-rail terminals", :keyword2 96, :authors (16987 14742), :session 141}, 1124 {:keyword1 65, :keyword3 104, :abstract "The roll-out of fiber-optic access networks is currently a major issue in telecommunications. As the deployment of such fiber-to-the-home (FTTH) or fiber-to-the-building (FTTB) networks is a highly complex task and connected with huge investment costs, optimization is invaluable for network planning. We present mathematical models that are used for FTTx network planning and results of these models applied to realistic test-cases from telecommunication companies.\r\n\r\nThe main approach uses an integer programming formulation to plan a cost-optimal FTTx network. The integer program models the connection of customer locations to central offices, while respecting a number of restrictions imposed by properties of the used technology\r\nas well as planning parameters set by the carrier. It meets specifications such as targeted coverage rates for various types of customers, limited numbers of customers connected to specific locations, but also cable sizes, closure capacities, and available ports. Additionally, it is possible to include existing infrastructure into the optimization problem.\r\n\r\nSince the lion's share of the costs involved with FTTx roll-out originates from trenching, an important subproblem is the optimization of the network topology. This can be modelled to some extent by a generalized Steiner tree formulation, which takes not only edge costs into account, but also includes opening costs for central offices, as well as some capacity conditions. Although a few important restrictions that occur in practise have to be left aside in this formulation, it nevertheless provides lower bounds on trenching costs that can give valuable information to asses the quality of solutions in this respect.\r\n", :title "Models for FTTX network planning", :keyword2 77, :authors (25050 12185 12231), :session 211}, 1125 {:keyword1 93, :keyword3 40, :abstract "Empirical studies on risk reporting of German companies reveal that most firms do not disclose quantitative risk information although it may increase the firm’s market price. A reason for this behavior may be that the reporting firm must disclose additional detailed information as prescribed in DRS 5, which in turn may induce a competing firm to enter the market. We analyze a situation in which an incumbent firm, endowed with private information about a risk factor in its market, can credibly disclose quantitative risk information to the market and thus also to its opponents. Favorable information increases the market price of the firm but it may also induce the opponent to enter the market, which imposes a proprietary cost on the firm. We show that there exist partial-disclosure equilibria with two distinct nondisclosure intervals. If the firm does not disclose, the opponent will not enter the market. We conclude that one reason for the empirical observed unusual quantitative risk disclosure is the fact that firms are required to explain the underlying assumptions and models used to measure the risk, which can lead to important competitive disadvantages.", :title "Incentives for risk reporting with potential market entrants", :keyword2 19, :authors (29541 29560), :session 94}, 1126 {:keyword1 92, :keyword3 37, :abstract "Strategic capacity planning, which has to set up and to adapt capacity of a Closed-Loop Supply Chain in a longer time horizon, has been analysed in only a few papers. The analysis of these approaches shows, that capacity for processing returned goods and manufacturing capacity for final products are planned independently, and information about returning goods is assumed to be available. Therefore, a model for planning manufacturing capacity and returns processing capacity simultaneously, that contains a return quantity forecast with update function, is developed. It consists of three parts: 1) The forecasting model considers the relation between customer-directed flows and reverse flows of goods with an autoregressive distributed lag model. A problem-specific formulation and the application prerequisites of corresponding statistical estimation methods are explained. 2) The goods flow model considers relevant transformation processes and their capacity demand by modelling flows of goods with different qualities as an aggregated dynamic linear technology. Thereby, customer-directed flows and reverse flows of goods are coupled by the forecasting model. 3) The capacity adjustment model comprises the effects of expanding and contracting the capacity which is provided by investments in machines, that may have different flexibility. Additionally, the delay between an investment decision and the realised capacity adaption is taken into account. In sum a linear mixed-integer programming model arises which supports strategic capacity planning with a rolling planning horizon. In order to point out suitability and functionality of the proposed approach, the model is solved with a standard solver for a set of example scenarios.", :title "Strategic Capacity Planning in Closed-Loop Supply Chains", :keyword2 7, :authors (26613 29519), :session 168}, 1131 {:keyword1 63, :keyword3 45, :abstract "This paper introduces a new metaheuristic called MultiObjective Simulated Annealing with Random Trajectory Search that we call (MOSARTS). This technique incorporates memory concepts to simulated annealing in order to transform the algorithm into a multiobjective method. These elements represent the long term and short term memories of the algorithm and are advocated to decide in which direction should the search continue in each iteration. The algorithm was tested in a multiobjective simulation optimization strategy for an operating room scheduling problem. The approach uses discrete event simulation to capture the resources randomness involved in the patient flow process and interacts with the metaheuristic that searches for better schedules. In order to evaluate the performance of the proposed algorithm, a set of experiments was conducted using MOSARTS and MOSA (Multiobjetive Simulated Annealing).  Both algorithms were compared solving a set of problems considering different number of patients and operating rooms. Pareto frontiers for each experiment were constructed from the set of nondominated solutions obtain by both algorithms. The results showed that MOSARTS generates significantly betters Pareto frontiers that the simulated annealing approach. Also the results showed that the proposed scheduling approach improves the hospital performance in comparison to the current method.", :title "Multiobjective Simulation Optimization for Operating Room Scheduling Problems", :keyword2 59, :authors (24375 8475), :session 160}, 1132 {:keyword1 12, :keyword3 99, :abstract "Recent experimental and computational work confirms that CpGs can be\r\nunmethylated inside coding exons, thereby showing that codons may be\r\nsubjected to both genomic and epigenomic constraint. It is therefore\r\nof interest to identify {\\em coding} CpG islands (CCGIs) that are\r\nregions inside exons enriched for CpGs. The difficulty in identifying\r\nsuch islands is that coding exons exhibit sequence biases determined \r\nby codon usage and constraint that must be taken into account.\r\n\r\nWe present a method for finding CCGIs that showcases a novel approach\r\nwe have developed for identifying regions of interest that are significant (with respect\r\nto a Markov chain) for the counts of any pattern. Our method begins\r\nwith the exact computation of tail probabilities for the number of CpGs in all\r\nregions contained in coding exons, and then applies a greedy algorithm\r\nfor selecting islands from among the regions. We show that the greedy\r\nalgorithm provably optimizes a biologically motivated criterion for\r\nselecting islands while controlling the false discovery rate.\r\n\r\nThe statistical criterion we apply to evaluating islands greatly\r\nreduces the number of false positives in existing annotations, and our\r\napproach to defining islands reveals significant numbers of\r\nundiscovered CCGIs in coding exons. Many of these appear to be\r\nexamples of functional epigenetic overloading in coding exons.", :title "Determining coding CpG islands by identifying regions significant for pattern statistics on  Markov chains", :keyword2 8, :authors (29611), :session 67}, 1136 {:keyword1 65, :keyword3 0, :abstract "In the years before the economic crisis in 2008, rail freight traffic in Germany attained a significant growth. The expansion of the available rail network capacities to cope with the increasing demand always dragged behind this development. The short term drop in demand due to the economic crisis offers the opportunity to make up for this deficit in order to prepare the railway network for the demand growth forecasted for the upcoming years. Recent studies predict annual growth rates of 5% within the next 15 years which would result in a freight traffic more than twice as high as nowadays. This requires extensive investments in the construction of new tracks and the expansion of existing ones.\r\n\r\nIn this talk we present a mixed integer model to support the decision process at Deutsche Bahn AG, the largest European railway company, on how to optimally invest their annual budget in the infrastructure. We modeled the problem as a network design problem with a nested routing problem. We consider a long-term planning horizon, where expensive measures can be stretched over several years. The routing has to be in compliance with the track capacities that can be extended by these measures.\r\nAs the routing in our model is fractional, we can solve it as a multicommodity flow subproblem in our Benders Decomposition approach. It is compared with a Lagrangian Relaxation approach as well as a Branch-And-Bound approach. We give computational results on real-life instances under different demand scenarios, which extrapolate from the current demands assuming different growth rates.", :title "A comparison of decomposition approaches for the railway network expansion problem", :keyword2 0, :authors (59498 13046 19514), :session 270}, 1139 {:keyword1 102, :keyword3 71, :abstract "The squat lobster fishery in Chile dates back to the 70s and started under a free access system, heavy fishing pressures and other factors made necessary a series of management measure that included a total allowable catch quota. Previous models proposed to determine an annual quota did not take into account some reproductive biological aspects and the specific period of total prohibition of fishing during each year of the long-term planning horizon. In this contribution, we present a new age-structure nonlinear optimization model based on a three-month period, that allow us to consider the effect of different options in the total prohibition of fishing period. We also present the results obtained in the use of this methodology, conclusions and possible extensions of the present research.", :title "Managing the squat lobster fishery in the north of Chile using a nonlinear optimization model for a total allowable catch quota", :keyword2 125, :authors (2866 8451 32003), :session 261}, 1140 {:keyword1 63, :keyword3 67, :abstract "Kyoto Protocol is an international agreement, which was signed in 1997 and intent to reduce human interventions on climate change. The agreement brought the perspective of a carbon credits market and also provides the use of control mechanisms, so developed countries and economies in transition can comply with quantified reduction on GHG emissions. The present paper aims to examine the feasibility on using carbon credits from CDM (Clean Development Mechanisms) projects that are related to biofuels production and to biofuels final use in Brazil. To achieve this objective, the authors have developed a multiobjective model. The main purpose of this model is to demonstrate favorable and competitive conditions related to the use of energy from biomass, as an alternative to the use of energy from fossil fuels. Having estimated the project baseline, the incremental payoff obtained from the sale of CER (Certified Emission Reductions) might be accounted using the multiobjective model. Optimization models for carbon credits contracts can help on mitigating the risks for investor, since marketing decisions are directed by the price of negotiated credit. Therefore, it might contribute for control mechanisms efficiency and, also, for reducing GHG emissions. The model developed in the present paper incorporates criteria for a sustainable development on the energy sector and it assists developing countries on mitigating global warming as well as it encourages the production and use of renewable energy.", :title "Feasibility on using carbon credits: A multi-objective model", :keyword2 102, :authors (28210 28209 1309), :session 129}, 1146 {:keyword1 96, :keyword3 0, :abstract "The Kiel Canal connects the North and Baltic seas and is ranked among the world's three major canals. In terms of number of passages, it is the busiest artificial waterway in the world. Due to the different water levels at both ends the canal is bounded by lock systems. Hence, the bidirectional ship traffic passing the canal must enter and leave it through one of the lock chambers. Besides the bounded capacities of these chambers also the canal itself is too small for unrestricted traffic. \r\n\r\nIn order to cope with the ever increasing traffic demand in the future, measurements, e.g. an enlargement of the canal and the locks, will be taken. The goal is to simulate the ship traffic within the canal at the one hand together with the lock system at the other hand, such that the effect of distinct measurements can be estimated. For this, we need models and algorithms covering as many real world details as possible.\r\n\r\nThis talk is about the realization of the lockage planning for the Kiel Canal and how this is coupled with the planning of the ship traffic within the canal. The lock system of each boundary consists of four lock chambers that in principle can be operated independently. Planning independent lock chambers was considered by Verstichel and Vanden Berghe. However, this is inappropriate for the Kiel Canal. Further difficulties arise since there are interdependencies between the movement of the ships entering and leaving distinct lock chambers. Hence, the previous algorithmic ideas must be extended to respect all feasibility constraints.", :title " Lock scheduling at the Kiel Canal", :keyword2 106, :authors (26629 29628), :session 172}, 1148 {:keyword1 106, :keyword3 96, :abstract "The demand for access to certain line segments of the Norwegian railroad infrastructure is very unevenly distributed. At certain times of the day demand by far outweighs the available capacity while, simultaneously, other parts of the network are underutilized. Consequently the network is not used to its full potential.\r\n \r\nTo obtain access to the infrastructure the train operating companies (TOC) submit route requests to the infrastructure manager who uses prioritization rules to decide which route requests will be approved or denied. The fees associated with using the infrastructure are the same during the entire day and in all parts of the network. Consequently, there is little or no incentive for the TOC’s to avoid bottlenecks when submitting their requests.\r\n \r\nCharging fees or granting subsidies that depend on the time of day, the specific line segment or the type of rolling stock provides incentives to move demand from peak hours to non-peak hours. Ideally tariffs or subsidies should be used so that trains with different characteristics, such as speed and acceleration, are sequenced in such a way that the utilization of the infrastructure is improved. We look into how bi-level programming can be combined with service network design to determine socio-economical optimal tariffs over the day for the different line segments of the infrastructure.", :title "Improving railway infrastructure utilization through pricing mechanisms", :keyword2 134, :authors (29627 9116 2188), :session 192}, 1157 {:keyword1 91, :keyword3 0, :abstract "In the field of customer relationship management, the customer lifetime value — often defined as the present value of all future profits generated from a customer — is a vastly investigated metric which serves as an important decision-making criterion. The incorporation of the expected customer lifetime value into revenue management systems is therefore identified as an existent challenge in the relevant literature — however, there are hardly any revenue management methodologies that comprise such a long-term perspective. Even though a service provider’s current pricing and availability decisions may affect the customers’ purchase behaviour in future periods, yet these implications are ignored. The up-to-date optimisation approaches in capacity control are almost exclusively transaction-based, i.e. solely short-term attainable revenue is maximised. This presentation provides insights in how to value customer relationships in a revenue management context and depicts problems which arise in this case. Moreover, we investigate the impact on the control policy of a deterministic linear program when both product-related revenue and the beforehand developed customer lifetime value measures are considered.", :title "On the Integration of Customer Lifetime Value into Revenue Management", :keyword2 0, :authors (29191), :session 96}, 1160 {:keyword1 2, :keyword3 41, :abstract "When aircraft sharing the same airspace are \"too close\" to each other according to their predicted trajectories, i.e. their horizontal and vertical distances are less than two given separation distances, they are said to be potentially in conflict. The problem of detecting and solving these conflicts is evidently crucial in Air Traffic Management to guarantee air traffic safety, specially taking into account the increasing air traffic density. Risks of collision should be avoided minimizing the impact of the separation maneuvers on the flight efficiency. To this aim, various models and solution strategies have been proposed for the corresponding optimization problem. Recent advances in mixed-integer programming open new perspective for the modelization and efficient solution of deconfliction problems. We focus on mixed-integer nonlinear programming (MINLP) models based on speed regulation, where conflicts are avoided allowing aircraft to only accelerate or decelerate, keeping their trajectory unchanged. When a large number of conflicts occurs, a deterministic global optimization approach for the MINLP problem is usually highly time and memory demanding. We propose a heuristic procedure where the problem is decomposed and it is locally solved by a deterministic solver. Computational results are discussed.", :title "Aircraft deconfliction: a heuristic based on local exact solutions", :keyword2 57, :authors (22409), :session 175}, 1162 {:keyword1 12, :keyword3 0, :abstract "New technologies have brought about disruptive change in the volume of DNA sequencing by halving the cost roughly every 9 months. We will discuss the effect this has primarily on applications in Biology and Medicine but also touch briefly on implications in other fields. To serve this increasingly wide range of applications DNA sequencing technologies will diversify into high vs. low volume, mobile vs. stationary, high quality vs. low quality, short vs. long sequence length to name but a few parameter ranges. This future diversity calls for efficient and effective and in some cases well controlled frameworks, protocols and algorithms to harness the full potential of this technology. ", :title "Future Developments in DNA Sequencing", :keyword2 45, :authors (29463), :session 67}, 1165 {:keyword1 8, :keyword3 0, :abstract "In the area of optimization of public transportation there are several methods for modelling and solving vehicle and driver scheduling problems. In this talk we consider the combined vehicle and driver scheduling problem, one of the main daily scheduling tasks of transportation companies. Public transportation usually consists of bus or other vehicle lines, which connect some stations. From our point of view only the beginning and end stations of the lines are interesting. The lines and the daily trips of the lines are usually given by a timetable. In practice it is given in advance, based on the travel demands and logistic decisions. The timetable gives explicitly the departure and arrival time of the trips for each line. It is also well-known, that we can form several series of trips, which can be executed continuously by a vehicle. If we can cover all the trips with such chains, then we get a set of feasible schedules. Another task is to assign drivers to these theoretical schedules. This should be done in such a way, that all the natural requirements given by transportation companies be satisfied.\r\nWe designed a sequential heuristic method for solving the combined (vehicle and driver scheduling) problem. Our model is based on a modification of the vehicle schedules to satisfy driver requirements. We introduced a driver friendly approach of the optimization of the scheduling, which is closer to the practice used by public transportation companies. We give test results for this, comparing to theoretical bounds based only on the timetable of trips and some driver-requirements. In our opinion this new theoretical lower bound can be applied in other approaches. We show illustrative example for the method in the scheduling of the bus trips of Szeged city, Hungary.", :title "Driver scheduling based on \"driver-friendly\" vehicle schedules", :keyword2 106, :authors (20939 29636 29632 25774 20930 29635), :session 219}, 1166 {:keyword1 75, :keyword3 18, :abstract "Motivated by an industrial application, we consider the proportional lot-sizing and scheduling problem with backorders as well as sequence-dependent setup times and costs. The real-world application reveals that the bill of materials has a significant impact on the setup structure. As a consequence, the setup times increase dramatically if the setup state is changed in between two product groups. A further extension is the consideration of the raw material availability.\r\nDue to its computational complexity, we solve the problem heuristically. A transformation into a traveling salesman problem with soft time windows serves as the basis for the design of a tabu search algorithm. It features a multi-stage approach that successively evaluates different neighborhoods. In particular, the important setup structure is exploited by a dedicated neighborhood operation. The effectiveness of our algorithm is evaluated in a computational study. Applying our procedure to real-world instances from an automotive supplier, we reveal a significant optimization potential. Moreover, a novel instance generation scheme is proposed.", :title "A Tabu Search Approach for the Sequence-dependent Proportional Lot-sizing and Scheduling Problem with Backorders and Raw Material Availability Checks", :keyword2 48, :authors (29630 14800 29640), :session 161}, 1171 {:keyword1 76, :keyword3 104, :abstract "We formulate a discrete time Markov decision process for a resource assignment problem for multi-skilled resources with a hierarchical skill structure to minimize the average penalty and waiting costs for jobs with different waiting costs and uncertain service times. In contrast to most queuing models, our application leads to service times that are known before the job is actually served but only after it is accepted and assigned to a server. We formulate the corresponding Markov decision process, which is intractable for problems of realistic size due to the curse of dimensionality. Using a linear approximation of the bias function, we develop a simple linear program that yields a lower bound for the minimum average costs. We suggest how the solutions we obtain from the linear program can be used in a simple heuristic and illustrate its performance in numerical examples.", :title "An approximate dynamic programming model for resource assignment of hierarchical multi-skill jobs in the telecommunications industry", :keyword2 88, :authors (25676 29641 829), :session 121}, 1172 {:keyword1 8, :keyword3 10, :abstract "Optimization under uncertainty has attracted vast attention in the last decades. The two main paradigms in the field are Stochastic Optimization and Robust Optimization. The former normally involves optimizing the expected value of the solution, hence it is meaningful in applications where the optimization needs to be performed many times. In the case that uncertainty affects the underlying structure of the problem, namely when different scenarios correspond to different feasible sets, stochastic optimization is often not applicable, since we are rarely interested in solutions which are 'feasible in expectation'. Robust optimization is often a suitable alternative in the presence of uncertainty in the underlying structure.\r\n\r\nIn this work we present a model for dealing with structural failures in combinatorial optimization. We motivate the model and present some results on robust counterparts of some classical combinatorial optimization problems.", :title "Structural Robustness in Combinatorial Optimization", :keyword2 94, :authors (29580 17063), :session 212}, 1173 {:keyword1 75, :keyword3 78, :abstract "The hierarchical production planning is a widely utilized methodology for real world capacitated production planning systems with the aim of establishing different levels of decision-making of the planning issues on the time horizon considered. This paper presents a hierarchical approach proposed to FER CREACIONES Ltd., a company that produces reusable shopping bags in Chile and Perú, to determine the optimal allocation of resources at tactical level as well as over the most immediate planning horizon to meet customer demands for the next weeks. Starting from an aggregated production planning model, the aggregated decisions are disaggregated into refined decisions in two levels, using a couple of nonlinear optimization models that imposes appropriate constraints to keep coherence of the plan on the production system. The main features and extensions of the particular hierarchical solution approach are presented.", :title "A hierarchical approach for a production planning system", :keyword2 101, :authors (29642 8451), :session 166}, 1174 {:keyword1 93, :keyword3 19, :abstract "Some properties and comparative-static results are derived for a simple model of decision under uncertainty, in which a representative risk-averse agent maximizes the expected utility of a random wealth. The wealth is postulated in a fairly general form, especially in what concerns to the effect of the decision variable, so that other decision models from different contexts under uncertainty can be considered as particular cases. In this proposed general framework, we give a new method to yield easily both properties of the optimal solution and comparative-static effects. For instance, we can compare the optimal solution with the corresponding solution in absence of uncertainty, and can also consider a proportional wealth tax and study the effect of a variation in its rate. Our method is analytic, and makes use of a technical result scarcely used in the literature. Finally, we illustrate the usefulness of this general setting by translating the results to some models from the theory of the firm under uncertainty. Concretely, we consider a recent model with two sources of uncertainty (production and price) due to Dalal and Alghalith, and a two-end model of our own. In both cases we are able to give new properties and results.  ", :title "A New Analytic Method to Study some Decision Models under Uncertainty: Applications to the Theory of the Firm ", :keyword2 99, :authors (25752 25797 29445), :session 258}, 1176 {:keyword1 101, :keyword3 53, :abstract "The Hunter Valley Coal Chain (HVCC) constitutes mining companies, rail operators, rail track owners and terminal operators, together forming the world's largest coal export facility. In 2008, the throughput of the HVCC was about 92 million tonnes, or more than 10 per cent of the world's total trade in coal for that year. The coal export operation generates around $15 billion in annual export income for Australia. As demand has increased significantly in recent years and is expected to increase further in the future, efficient supply chain management is crucial. Our industry partner, the Hunter Valley Coal Chain Coordinator Limited (HVCCC) was founded to enable integrated planning and coordination of the interests of all involved parties, so as to improve the efficiency of the system as a whole. We present a problem motivated by the annual maintenance planning process for the HVCC. By carefully aligning necessary maintenance on different infrastructure parts capacity losses can be reduced significantly. In the talk we describe how this can be modeled as a dynamic network flow problem, the network arcs corresponding to load points, railway track sections, terminal machines etc., and their capacities varying over time depending on scheduled maintenance. We compare a mixed integer programming approach with local search heuristics, and present computational results on random and real world instances.    ", :title "Mixed integer programming based maintenance scheduling for the Hunter Valley Coal Chain", :keyword2 96, :authors (28236 27792 23580 28655), :session 164}, 1179 {:keyword1 75, :keyword3 53, :abstract "We provide a production planning framework for variant rich customized products (such as automobiles or computers), by calculating entirely constructible configuration sets for future customer demands in a novel manner. Most of the established approaches analyze configurations out of historical order banks for estimating the appropriate set of future demands. In the current environment of rapidly changing designs and highly customized products, historical demands cannot easily be extrapolated to capture future market demand and may not even retain future product document restrictions. Especially for new products where no order history is available, we need methods to calculate constructible product configurations that satisfy sales and production requirements simultaneously.\r\n\r\nOn the other hand, even though past product configurations may not remain valid for future product designs, they may contain interesting information about correlation between attributes of a product reflecting customer buying behavior. This information should also be reflected by the configuration set that we generate. \r\n\r\nWe present a method that transforms logic propositions related to product technology into algebraic constraints. To this, we add sales and production constraints together with attribute association constraints (derived from past order history). Sales constraints could be in the form of take rates of key modules or attributes and these would anyway need to be forecasted accurately for capacity planning, vendor negotiations and some marketing decisions. \r\n\r\nThe order set generation problem is formulated as a large scale 0-1 optimization model. We propose column generation and other techniques to solve this large scale optimization model.\r\n", :title "Calculation of constructible set of valid configurations for product variety management", :keyword2 101, :authors (24063 28300 29648 29647), :session 226}, 1183 {:keyword1 35, :keyword3 0, :abstract "This paper introduces a valuation method of Credit Default Swaps (CDS) with correlated jumps of the firm's asset value by applying the structural model.  Credit risk of firms is an important factor in evaluating CDS premium.  Furthermore, it is important to incorporate the dependent structure between firms into the valuation model in order to measure the credit risk of the firms.  For example, in case that firms belong in the same industry, the simultaneous default probability could increase.  By considering these situations, it is capable of estimating their accurate default probabilities and default correlation.\r\n\r\nIn previous study; Lipton and Sepp(2009), the asset value dynamics of the reference entity and protection seller are given by geometric jump diffusion processes.  However, it is unable to calculate the default correlation correctly due to the assumption that a jump between the firms occur independently.  Without taking account of right default correlation, people may misunderstand evaluating default probabilities in such the situation that firms defaulted at the same time like the financial crisis in 2008.  Therefore, in this study, we illustrate default correlation with separating the jump term of stochastic processes into a firm-specific jump term and a simultaneous jump term.\r\n\r\nAdditionally, this paper evaluates the theoretical CDS premium to demonstrate the validity of this model by using the recent market data with Monte Carlo simulation.  We compare the results calculated by our model and the prior models with the market CDS rate and show how precisely we can calculate the CDS price.  As a result of sensibility analysis, we found that the volatility of jump amplitude has a strong impact on the CDS premium.", :title "A Valuation Method of Credit Default Swaps with Correlated Jumps of the Firm's Asset Value", :keyword2 34, :authors (29649 26181 26404), :session 216}, 1184 {:keyword1 40, :keyword3 0, :abstract "This research models a bidding behavior for a target company considering the bidding contest among competitive companies. Bidding contests is assumed TOB between two companies. Before their biddings, they need to conduct due diligence to evaluate an exact value of the target company. In the previous study; Smit et al. (2005), periods of the due diligence are determined as constant exogenously. In actual situations, bidding companies can choose their own periods of due diligence to maximize their expected profits from the bidding contest. There are one advantage and two disadvantages when the periods of due diligence are extended. They can obtain more accurate information about the target company when the period of due diligence becomes longer. On the other hand, the cost of the due diligence is higher. Additionally, longer periods of due diligence lead to the higher discount factor.\r\n\r\nTherefore, this research proposes an endogenous method determining the periods of due diligence considering tradeoffs between the advantage and the disadvantages. We model two competitive companies' behaviors as an option game by fixing bidding order of the companies. In this game, conducts of due diligence and bidding are captured as option exercises. Equilibrium strategies are derived by solving its optimal conditions backward numerically.\r\n\r\nFinally, we conduct a sensitive analysis to reveal nature of equilibrium strategies. As a result of this analysis, it was found that a first bidder's period of due diligence is longer than a second bidder's one. Furthermore, when a bidding price of the first bidder is higher, the second bidder's period of due diligence as an optimal reactive strategy is longer.\r\n", :title "A Determination of Optimal Periods of Due Diligence under a Bidding Contest", :keyword2 134, :authors (29651 26181 26404), :session 137}, 1186 {:keyword1 120, :keyword3 106, :abstract "When clustering objects in real, geographic  space, the presence of  obstacles such as rivers, highways or access restricted territory poses a significant problem, as travel distances and proximities can no longer be reliably measured through Euclidian distances (“as the crow flies”) or other popular metrices.  Algorithms to overcome this problem have been proposed, but are typically tested only on artificial data or at best a single and algorithm specific real life set. \r\n\r\nThis paper commences by analyzing three of the most popular proposals (AUTOCLUST+, DBCluC and DBRS+) from a ‘code walk through’ perspective. The distance measures employed and the often rough-and-ready approach to measuring the real travel distances is identified as a major shortcoming. Distances produced can be totally unrealistic under certain constellations. We propose improvements and proceed to test original and improved versions on a real life data set of substantial size. \r\n\r\nThe issue is to form delivery regions for a daily newspaper within an urban area, where rivers and highways form a complicated topological structure. This case serves to identify a new set of shortcomings and suggests ideas for improvement.", :title "Evaluation of well-know Spatial Clustering Algorithms with Obstacles", :keyword2 54, :authors (29117 15857), :session 177}, 1189 {:keyword1 77, :keyword3 18, :abstract "It is important to consider the fingering for playing the piano naturally. The fingering problem for the piano score is to specify the natural and reasonable fingering automatically.\r\nThere are some previous works; for example, the fingering for a score with at most 10 notes by solving the Dynamic Programming, the fingering for a score with a few notes by the Genetic Algorithm, and the fingering based on the Hidden Markov model. All of them are applied to the right-hand single passage.\r\nThe model in this research is the 0-1 Integer Programming based on several fingering rules. The IP models are for the right and left hand single passage, the 3rd and 6th sequence, and the chord sequence, respectively. \r\nConsidering the fingering, there are several rules to be mentioned in common. However, in fact, each different types of note sequence should be treated on the basis of different fingering rules. That required the several types of IP-model. \r\nThere is no best solution for every pianist. So, in the model, some costs are designed to be capable of reflecting the different personalities.\r\nIn this research, it is reported that what kind of rule is better or not for each type of sequence.\r\nIt is not difficult to get the optimal solution to solve the problem based on several settings, but it is difficult to evaluate the solution. A way to do is to show each value of cost of the solution, respectively.", :title " A mathematical approach for the piano fingering", :keyword2 57, :authors (6325), :session 208}, 1192 {:keyword1 57, :keyword3 48, :abstract "Keskinoglu is one of the largest integrated Poultry producers in Turkey. Keskinoglu produces 10 million Hy-line egg lying chicks annually through computer controlled production system with fully automated vaccination. The company breeds over 40 million broiler chicks for meat production. Keskinoglu is capable of processing up to 250,000 pullets per day through fully automated systems and integrated packaging. This paper deals with a production planning problem Keskinoglu faces. The problem is optimal disassembly and assignment of pullets to demand for poultry products. The challenges in modeling this problem comes from the facts that demand items are produced by disassembling (cutting up) pullets and that some of the demand has weight specification. The first challenge is the interdependency between demand items. Based on the way each pullet is disassembled, different products are obtained simultaneously. To satisfy certain demand, other products that may not be demanded have to be produced alongside. The second challenge is that weight of the pullet determines the weight of the products (heavier the pullet, heavier the product will be). To satisfy demand with weight specification, a pullet of the appropriate weight must be disassembled. If, upon disassembly, the product is heavier than the specified weight, trimming has to be done, resulting in loss (remnant). Therefore, the disassembly plan has to be such that remnant is minimized. The main purpose is to be able to determine how each of the daily available pullets will be disassembled to satisfy the daily demand while minimizing remnant and excess products produced. We present a nonlinear mixed integer programming model to solve this problem. Results of experiments using real data from Keskinoglu Company are provided.", :title "Disassembly Planning and Application in Keskinoglu Poultry", :keyword2 75, :authors (3578 26811), :session 243}, 1195 {:keyword1 56, :keyword3 0, :abstract "In this paper, we propose an application of the structured C-Logit model for the cross-category analysis. \r\nThe cross-category analysis helps brand managers to choose the optimal degree of localization of branding and marketing communications.\r\nOnce we can apply the C-Logit model for cross-category analysis, in introducing new products into existing product lines, retailers can analyze how new products introductions have influences on the other products. Then it is possible for retailers to analyze influences by new products introductions quantitatively, retailers are considered to be able to make an adjustment for volume of inventories. The C-Logit model is established for route choice in traffic planning. So, we first apply the C-Logit model for brand choice model.\r\nTherefore, the purpose of this study is to construct a model for the cross-category analysis to forecast new products influences. In conventional cross-category models (such as Russell and Petersen, 2000), the term of cross effects (effects between categories) in utility function is constant, and we cannot use this in more than two categories. So, in this study, we make it possible to improve this by applying the C-Logit model. Thanks to this application, the term of cross effects in utility function is expressed by variables, and we can use this in more than two categories.\r\nFinally, we conduct an empirical analysis with scanner panel data of actual product categories (butter and margarine). We show that the model predicts cross-category choices better than conventional ones. If the proposed cross-category analysis were conducted with a number of categories, it would be possible for retailers to assort product lines effectively in terms of the strength of cross-category relationships.", :title "A Cross-Category Analysis: An application of the structured C-Logit Model", :keyword2 0, :authors (29349 26181 29808 26404), :session 257}, 1199 {:keyword1 45, :keyword3 94, :abstract "Due to changes in health care systems, hospitals are under pressure to substantially reduce their costs. Increasing demand for medical treatment leads to high utilization of resources. Additionally, a special focus is required on the interests of several stakeholders, mainly patients, staff, and hospital management. A basic modeling framework considers limited capacity of resources to make suitable appointments for all patients. The conflicting goals overtime, waiting time and utilization represent the different interests of the groups involved. \r\n\r\nWe calculate individually optimal solutions under uncertainty and then use a fuzzy sets approach to determine a robust compromise. A further extension indicates the benefit of including uncertainty and vagueness of components like available capacity or duration of treatment. A scenario-based optimization model is proposed to allocate treatments over a given time period. The model provides a sufficient amount of capacity for worst case situations in a medium-term perspective. This approach anticipates various aspects of uncertainty and multiple criteria to calculate a robust solution. The evaluation of the model shows the balanced allocation of resources as well as good levels of goal attainment can be realized. The quality of the compromise solution is compared to solutions under perfect information for all possible scenarios. Relative distances to those ideal optimal solutions are calculated to visualize levels of achievement. We evaluate the impact of different membership functions on the obtained results and provide a simulation study to demonstrate the quality of the robust compromise.", :title "Robust capacity allocation for medical treatment units", :keyword2 63, :authors (17358 10057), :session 88}, 1200 {:keyword1 77, :keyword3 133, :abstract "Engineers are very interested in finding the optimal topology of trusses (structures of bars and nodes under an external force), especially if they have discrete bar areas. The Truss Topology Design Problem is also interesting from a mathematical point of view. The standard model for minimizing the compliance is non-convex and non-linear. \r\nThere are different ways to convexify the model yielding a linear, a quadratic or a semidefinite problem. Furthermore we look at trusses with additional active components, which we want to position in the truss. Finally we want to optimize under uncertainty. Therefore we look at the multiple load case with different scenarios.\r\nOne way to convexify and linearize the model yields a very big mixed-integer program (MIP) on which standard-software needs days for solving even small instances. Changing the objective of the problem to a quadratic function gives some speedup. Another convexification can be achieved with a semidefinite program (SDP), which can be solved for continuous bar areas using interior-point-solvers. \r\nOur aim is to model trusses with discrete bar areas and additional active components. Both are modeled via binary variables. The active bars can add additional forces to the truss and are therefore able to counter external forces. They need to be positioned in the truss. Additionally we want to analyze trusses under multiple loads, which means there are several scenarios and different loads in every scenario and we want to find one optimal truss for all the scenarios.\r\nBoth extensions enlarge the MIP as well as the SDP. Moreover the binary variables in the SDP require the combination of a branch-and-bound-framework together with a SDP-solver. We compare the different models and present first computational results.", :title "Optimal positioning of active components in trusses under multiple loads", :keyword2 82, :authors (19441 29261 19424), :session 213}, 1202 {:keyword1 42, :keyword3 0, :abstract "We focus on the problem of partitioning the vertices of a directed, arc- and vertex-weighted graph into clusters, i.e. disjoint sets. Clusters are to be determined such that the sum of the vertex weights within one cluster satisfies an upper bound and the sum of the arc weights within the clusters is maximized. Compared to traditional graph partitioning problems, we additionally enforce that the graph partitions into a directed, acyclic graph with clusters as vertices. This problem is known as the Acyclic Partitioning Problem and has been proven to be NP-hard. Real life applications include a train scheduling problem that arises at rail-rail transshipment yards and VLSI (Very Large Scale Integration) design. We propose two (mixed) integer programming formulations for the problem and suggest an exact solution approach based on a thorough problem analysis and a branch and bound framework. To show the efficiency of our algorithm, we end with a computational study.", :title "A Branch and Bound Algorithm for the Acyclic Partitioning Problem", :keyword2 0, :authors (23511), :session 228}, 1203 {:keyword1 75, :keyword3 0, :abstract "Inventory management and pricing decisions based on quantitative models both in industrial practice and academic works often rely on minimizing expected cost or maximizing expected revenues or profits, which refers to the concept of risk-neutrality of the decision maker. Although many useful insights in operational problems can be obtained by such an approach, it is well understood that incorporating attitudes toward risk is an important lever for building new theories in other fields such as economics and finance. The level of risk associated with an investment might be as important as the expected gain from the investment. Hence, it is necessary to find appropriate measures of risk and the appropriate objectives related to or including these risk measures for inventory control & pricing problems. \r\n\r\nAfter the axiomatic foundation of coherent risk measures the application of risk measures to inventory models such as Conditional Value-at-risk (CVaR) or  convex combinations of mean and CVaR became popular. However, the different risk measures are special cases of the general class of spectral risk measures.\r\n  \r\nIn our work we apply spectral risk measures to the inventory control & pricing problem and derive optimal policies as well as structural properties. By doing so we are able to unify the results obtained so far in the literature under the common concept of spectral risk measures for the case of zero and non-zero shortage penalty cost.  In particular, we show convexity results and structural properties for the inventory control and under some assumptions also for the joint inventory & pricing problem. A numerical analysis of the problem concludes the talk. ", :title "Single Period Inventory Control & Pricing with Spectral Measures of Risk ", :keyword2 93, :authors (29657 29658), :session 170}, 1204 {:keyword1 61, :keyword3 0, :abstract "In this talk, different approaches towards modeling optimization problems using the statistical programming language R will be presented. Real-world examples from the application areas Finance and Energy will be shown.", :title "Optimization Modeling using R", :keyword2 18, :authors (2685), :session 79}, 1205 {:keyword1 54, :keyword3 73, :abstract "Recently in Japan and various countries, doctor-helicopter system has been received much attention to upgrade the existing ground ambulance system. Doctor-helicopters are deployed at medical centers and can send medical doctors or specially-trained medical staffs near an accident site with much faster speed than ground ambulance. One of the notable characteristics of the system is that helicopters cannot always land at emergency scene. This requires specially designated location where a helicopter and land and depart. This paper presents an optimization model for determining the locations of helipads for designing effective doctor-helicopter system. As for the operation of the system, the following are assumed. The ground ambulance arrived at the scene of the accident examines the condition of a patient. When the patient is judged to be in critical condition but it requires long time to transport the patient to an appropriate hospital, the ambulance requests the dispatch of a doctor-helicopter. Then, the ambulance and the helicopter meet at a helipad and the patient receives first medical care, and the patient can be transported to the base hospital of the helicopter (U-turn flights) or to an appropriate other hospital (J-turn flights). In this operation, we assume two types of helipads. The first type works as a meeting point for helicopter dispatched from its base hospital and ambulance carrying the patient, while the second type works as a landing point at a large medical hospital. The model seeks to optimize the locations of both types of helipads so as to maximize the average survival rate for all demands. The model is formulated as an integer programming problem and applies to the location problem using actual population and geographical data of an area of Japan.", :title "Optimization of helipad locations for helicopter emergency medical systems focusing on \"J-turn'' flights", :keyword2 45, :authors (6938 20142), :session 221}, 1206 {:keyword1 2, :keyword3 18, :abstract "As the underlying models of customer behavior and competition are extended and the mathematical methods applied are continuously improved, revenue management systems grow more sophisticated and therefore complex.  This has an effect both on technical performance as well as on the requirements regarding the task of revenue management analysts.  \r\nAnalyzing the causality of results, designing well-planned influences of the automated system and accounting for the consequences of these influences requires an informed understanding of the mechanisms involved in state of the art revenue management.  Major challenges are posed for example by considering the outcome of effects in a network based system with multiple points of sale or by analyzing the correctness of forecasts based on correlated demand.\r\nIn this presentation, we illustrate the aspects of complexity that are added to new revenue management systems.  Based on this, we present the risks that evolve with regard to robustness, performance evaluation and collateral damage imposed by misunderstandings and badly understood system adjustments.  We introduce indicators to measure the effect of these factors with regard to the economic outcome of revenue management.  \r\nAs a consequence, we offer alternative approaches to setting up sophisticated revenue management systems.  Such systems need to incorporate both complex mathematical methods and a robust user interface, allowing for the adjustment of automated systems with regard to changing markets.\r\n", :title "Accommodating Complexity in Revenue Management", :keyword2 91, :authors (29660 19297 29659), :session 99}, 1207 {:keyword1 54, :keyword3 82, :abstract "In this talk we consider the problem of minimizing the ordered median function of finitely many rational functions over compact semi-algebraic sets. Then, we present a hierarchy of SDP relaxations that approximates, up to any degree of accuracy, the optimal value of those problems. We apply this very general framework to a broad family of continuous location problems showing that some difficult problems (convex and non-convex) that up to date could only  be solved on the plane and with Euclidean distance, can be reasonably solved with different l_p-norms and in any finite dimension. We illustrate this methodology with some preliminary computational results. ", :title "A semidefinite programming approach for location problems", :keyword2 41, :authors (5876 9356 30015), :session 177}, 1208 {:keyword1 29, :keyword3 85, :abstract "This paper investigates the effects of wind penetration on market coupling operation. Market coupling separates the control of the energy and the transmission markets. The former market is controlled by Power Exchanges (PXs), while the latest is managed by Transmission System Operators (TSOs). The limit of this market organization is that PXs operate with a simplified representation of the transmission grid. As a consequence, the power flows determined on the energy market may not be compatible with the physical characteristic of the network. When this happens, TSOs intervene and re-organize flows in order to restore grid feasibility. These operations, that take the name of counter-trading, are more complex when the intermittence of wind energy production is considered.   \r\nIn this paper, we develop simple stochastic models in order to monitor the impacts of wind energy penetration on the counter-trading costs. We take as reference a simplified representation of the Central Western European electricity market including France, Germany, Belgium and the Netherlands where market coupling now applies. We expect that an increase of wind capacity availability as required by the new 20-20-20 targets of the European Emission Trading Scheme will lead to an increase of counter-trading costs. ", :title "A stochastic version of market coupling with wind penetration", :keyword2 134, :authors (20825 12583 3662), :session 125}, 1209 {:keyword1 2, :keyword3 40, :abstract "Alliances are a major topic in the recent context of trends in the airline sector. Codesharing allows airlines to share common flights and is one of the most important practices in the field of airline alliances – this triggers an inquiry with regard to mechanisms of availability control and revenue sharing as applied in codesharing alliances. \r\nAlliance partners are confronted with three major decisions: what common products to offer, how to decide on availability controls, and how to split commonly earned revenues. In return, they are able to enlarge their network and to offer new products. \r\nThe core of this presentation is an investigation of how these decisions are related and how one decision will influence the outcome of another. As each decision requires the exchange of information between partners, this is the main focus of the investigation. \r\nA game theoretic approach is used to explore under which circumstances the incentive for transmitting faulty information to its partner is given, so that cheating leads to a benefit. We expect that especially the selection of the correct revenue sharing method has a large impact on the behavior of the actors and therefore analyze the effect of this aspect with special care.\r\n", :title "Considering Airline Alliances: A Game Theoretic Approach", :keyword2 91, :authors (29662 19297), :session 98}, 1210 {:keyword1 34, :keyword3 93, :abstract "The elephant in the room around CDS, CMBS, CMBX, and CDO pricing is the recovery rate. Practically, whilst recovery swaps exist they are not liquid. The problem is especially acute when upfront payments, or quoted prices, contradict previous recovery rate assumptions, e.g. pre-crisis, 40% for equities, or up to 80% (or more) for some CMBS. Although recoveries will decrease as rating drop, ratings are not always in sync with market movements. Theoretical developments have run ahead of market reality for calibration. Whilst CDS and CDO reduced-form models exist for stochastic hazard rates and stochastic recovery rates actual calibration is problematic. In this presentation we take a step backwards and consider a dynamic calibration of traditional static CDS models to market data. We start from the usual daily model recalibration and propose a heuristic for market-consistent calibration of static data, specifically the recovery rate within static hazard rate models. It will be argued that these heuristics can be extended and generalized in different ways within stochastic models. For example, the market-implied recovery rate that is now an output can be the input for a stochastic recovery rate model. This is joint work with Chris Kenyon and Manuela Spangler.", :title "Reassessing recovery rates: Floating recoveries", :keyword2 35, :authors (8981), :session 215}, 1212 {:keyword1 63, :keyword3 35, :abstract "This paper presents a multi-objective portfolio model with the expected return as a performance measure and the expected worst-case return as a risk measure. The problems are formulated as a bi-objective linear program. One of the problem objectives is to allocate the wealth on different securities to optimize the portfolio return. The portfolio approach has allowed the two popular in financial engineering percentile measures of risk, value-at-risk (VaR) and conditional value-at-risk (CVaR) to be applied. The decision maker can assess the value of portfolio return and the risk level, and can decide how to invest in a real life situation comparing with ideal (optimal) portfolio solutions. The concave efficient frontiers illustrate the trade-off between the conditional value-at-risk and the expected return of the portfolio. Numerical examples based on historical daily input data from the Warsaw Stock Exchange are presented and selected computational results are provided. The computational experiments show that the proposed solution approach provides the decision maker with a simple tool for evaluating the relationship between the expected and the worst-case portfolio return.", :title "Multi-criteria portfolio optimization  with downside risk measure", :keyword2 57, :authors (11260), :session 265}, 1213 {:keyword1 91, :keyword3 0, :abstract "The use of revenue management methods is still an upcoming topic in the liner shipping industry, while in similar logistics industries, revenue management methods are already well established. In the literature, only a few publications on the topic of revenue management in the liner shipping industry can be found. Most of the models which have been suggested for the liner shipping industry so far consider only one service and one ship cycle on this service. However, the liner shipping industry relies on a network structure and demand can differ between ship cycles, because of long cycle times. Moreover, there is more than one ship deployed on most of the services. Hence, it is important to consider the possibility of transshipments between services and of different demand situations at different times. Based on these findings, a new quantitative slot allocation model is developed which takes into account the network structure of liner shipping with the possibility of transshipments and the existence of different ship cycles on the services. As restrictions, the model includes the maximum capacity of the ships and the requirement to fulfill the forecasted demand for loaded and empty containers. Based on forecasted demand, the model creates booking limits for each possible path in the network, considering each possible segment, i.e. container types, paths and service segments. In contrast to the existing models, this approach leads to a more realistic representation of the situation in liner shipping, as it incorporates the network structure with multiple services and changing demand over time. This facilitates the application to real-world planning situations. A simulation study is carried out for different demand scenarios, which leads to promising results.", :title "A revenue management slot allocation model for liner shipping networks", :keyword2 0, :authors (26490 20937), :session 99}, 1215 {:keyword1 7, :keyword3 87, :abstract "Automotive manufacturing is performed in four main stages in three departments. In the first two stages, metal forming and welding operations are carried out in the body shop; whereas, in the other two stages, painting and assembly operations are done in the paint and final assembly departments.  Due to the nature of painting operations, paint defect rates could be as high as 30- 35 % depending on vehicle color, with an overall average of 10 %. One tool that can be used to control the paint defects is an attributes control chart set up in the paint department. The objective in setting up an attributes chart is to detect the shift in proportion of defective produced as soon as possible. An upward shift in defect rate reduces the paint department capacity because, if the control chart detects such a shift, the painting operations are halted and causes for the shift are investigated. In this study, we jointly determine; 1) the optimal number of vehicle types produced, and 2) the attribute chart design parameters, namely, the control limits and number of vehicles sampled. Joint determination of these parameters and production quantities are important, since inspection of number of vehicles sampled and looking for the causes for out of control situations disrupts painting operations. Therefore, if the effects of such out of control situations are not considered on the number of vehicles produced, customer demand may not be fulfilled on time. In order to determine the chart parameters and production quantities optimally, we formulate the problem as a two-stage stochastic programming problem, and solve it by using sample approximation algorithm (SAA). We also provide managerial insights on the problem by performing a numerical study. ", :title "Integration of control chart design and production decisions in automotive manufacturing", :keyword2 99, :authors (20767 24367), :session 222}, 1217 {:keyword1 65, :keyword3 77, :abstract "We consider the design of a passive optical telecommunication access network, where clients have to be connected to an intermediate level of distribution points (DPs) and further on to some central offices (COs) in a tree-like fashion. Each client demands a given number of fiber connections to its CO. Passive optical splitters installed at the DPs allow k connections to share a single common fiber between the DP and the CO. We consider fixed charge costs for the use of an edge of the underlying street network, of a DP, and of a CO and variable costs for installing fibers along the street edges and for installing splitters at the DPs. \r\n\r\nWe present a Lagrangian solution approach that decomposes the overall problem into two combined capacitated facility location and network design problems - one for the distribution network connecting the clients to the DPs and one for the feeder network connecting the DPs to the COs. Both subproblems are solved using MILP techniques. We report computational results for realistic instances and compare the efficiency of the Lagrangian approach to the solution of an integrated MILP model. ", :title "A Lagrangian solution approach for the two-level FTTX network design problem", :keyword2 104, :authors (13058 22042 29359), :session 211}, 1218 {:keyword1 75, :keyword3 133, :abstract "Today while the end-of-life products are collected and reprocessed so as to maximize the recovery of the inherent economic and ecologic value, one of the main operations performed is disassembly. Disassembly lines are one of the settings on which collected products can be disassembled in large quantities. In a paced disassembly line, each work station is allotted a fixed amount of time to perform the assigned tasks, which is called the cycle time. In this study, we consider a disassembly line with stochastic task times and seek a feasible assignment of tasks to an ordered sequence of such that disassembly precedence relations are satisfied and expected profit is maximized. As the work content of workstations are now random variables, there is a probability that some of the assigned tasks may not be completed during the cycle time. When such incompletions occur, two plausible remedial actions are stopping the line and performing offline disassembly. In case of incompletions, a hybrid disassembly line allows stopping the line for some tasks and for the remaining tasks offline disassembly is performed for the incomplete task and its successors. We, first present a structured way of calculating the incompletion costs for both remedies to obtain the expected profit for a given hybrid line. Then, a method that solves the stochastic disassembly line balancing problem given cycle time is proposed for the hybrid line and the results of our computational analysis are discussed. ", :title "Balancing hybrid disassembly lines with stochastic task times", :keyword2 99, :authors (29554 19750 634), :session 164}, 1220 {:keyword1 25, :keyword3 0, :abstract "The paper is oriented to the presentation of a microeconomic model apparatus for a support of the protection of the competitive environment in Slovakia. In connection with the transformation of the Slovak economy to a market model it was necessary to deal within a relatively short period of time with a series of urgent and important tasks that were connected with new principles of market forces operation. The existence of the market structure of imperfect competition is naturally linked to overt and covert effects affecting the implementation of the economic competition conditions. An observation of the competitive conditions is regulated institutionally in advanced world countries and in European Union countries too, and this systemic element of the economic development is ascribed a great importance. The paper describes ways of utilizing model approaches and economic-mathematical methods, computing technology, when evaluating the present state and the development of the competitive environment in industries. The advanced economies with historical experience and the existence of the economy under the market conditions are of course aware of the risks of negative impacts of a high degree of concentration on the competitive environment quality. In Slovakia the realization of tasks related to the protection of the economic competition is carried out by the Antimonopoly Office of the Slovak Republic. In the paper, there are also presented the basic concepts of methods of measuring concentration in industries. Specifically the methods of quantification of the degree of concentration and indicators of absolute and relative concentration are explained. The special attention is paid to the explanation of the extreme cases of the degree of concentration in the industries.", :title "Utilizing of microeconomic models in evaluating of competitive environment in Slovakia", :keyword2 48, :authors (12763 12604), :session 105}, 1221 {:keyword1 38, :keyword3 0, :abstract "Swiss forestry sector is characterised by a complex structure encompassing a large variety of activities and firms. There are presently some 2600 forestry firms in Switzerland, about three quarters of them in public hands. This paper is an empirical analysis of the productive efficiency of public forestry firms in Switzerland. The period under study extends from 1998 to 2006. We use original unpublished data provided by the Swiss Forestry Association and covering some 700 firms. \r\n\r\nBy comparing various forestry firms among themselves (benchmarking), one can identify the most efficient units and their distinctive features. We inquire whether public subsidies exert any significant impact on the efficiency of these firms. In order to determine the productive efficiency of forestry firms, a nonparametric method (DEA) is applied. Panel unit root tests and panel cointegration technique are employed to establish the long run relationship between efficiency and selected variables.", :title "Relation between the Efficiency of Public Forestry Firms and Subsidies: The Swiss Case", :keyword2 17, :authors (23155 23153), :session 259}, 1222 {:keyword1 34, :keyword3 57, :abstract "In the situation of financial crisis, where the stiff competition in financial market turns out to be the norm, where mergers and acquisitions or insolvencies of financial institutions take place, the majority of banks are reformed in order to become more efficient and more flexible in the new economic environment. During the last decade the wide use of ICT has changed the traditional branch distribution channel by introducing the web delivery channel, which forced banks to set up all the necessary decision support system to re-engineer their business process in order to provide their customers with services such as: electronic payments, e-statements of personal accounts, e-services for International trade, etc and competitive products with privileged interest rates for both deposits and lending accounts. It is obvious that the number and the location of branches as well as the variety of offered services, is an emerging issue for a bank’s management team. Banks have to satisfy customers’ needs through traditional and web channels, and in the same time have to rethink about the regional range of each branch in order to avoid overlapping. Based on previous work, where we had proposed an algorithm for reconfiguring branch network according to the dictates of the market, the internal bank resources and the strategic policy constraints, we have determined the optimum number of branches that should operate in a specified geographical area. In this study we are seeking to define the “location coordinates” for each branch in the area under examination. The goal of this paper is to develop an algorithm for optimizing a branch network by determining the location of branches, the diversity of products and the variety of offered services.", :title "Branch location and service optimization of a bank network", :keyword2 18, :authors (19731 13972), :session 269}, 1225 {:keyword1 75, :keyword3 88, :abstract "We study a stochastic production-inventory system where several products\r\nshare a single resource and product substitution decisions are taken to\r\nimprove customer service. We first characterize the optimal policy and\r\nshow that resource allocation, stocking and substitution decisions\r\ndynamically change with the net inventory levels. For systems with\r\nrelatively small number of items it is possible to determine the optimal\r\npolicy through stochastic dynamic programming. However, as the number of\r\nitems increase, dynamic programming becomes an inefficient method. We aim\r\nto construct heuristic policies that perform close to optimal policy for\r\nmulti-item settings. Our heuristics improve upon priority- and longest\r\nqueue-based resource allocation and substitution rules. We present the\r\nconditions under which the heuristics perform well.\r\nWe conduct a computational study to address several research questions. We\r\nfirst assess the benefit of product substitution given that resource\r\nallocation and scheduling is already done optimally. Dynamic policies take\r\nreal-time information on net inventory levels into account, but are based\r\non impractical implementation rules. We assess the benefit of real-time\r\ninformation on net inventory by comparing dynamic scheduling and\r\nsubstitution policies with static policies. Results show that the benefit\r\nof dynamic product substitution is limited in the presence of dynamic\r\nresource allocation, while dynamic resource allocation is essential for\r\nachieving low cost.", :title "Managing Production Scheduling and Product Substitution for a Multi-item Make-to-Stock Queue", :keyword2 76, :authors (29598 15424 1857), :session 163}, 1227 {:keyword1 41, :keyword3 57, :abstract "We present a branch and bound type global optimization method based on a systematic use of  concave and convex support functions. Method starts with concave support functions for obtaining lower bounds as an approximate solutions of auxiliary concave programing problems. During the branching process partitions elements are getting smaller in diameter and this property give us a possibility to substiute gradually concave support functions with convex support functions and solve auxiliary convex programming problems. In total such approach accelerates convergence near optimal solutions. Numerical testing results are given.", :title "Global minimization of twice continuously differentiable function over a polytope", :keyword2 14, :authors (48465 29671), :session 195}, 1230 {:keyword1 28, :keyword3 78, :abstract "With increasing amounts of power generation from intermittent sources like wind and solar, capacity planning has not only to account for the expected load variations but also for the stochastics of volatile power feed-in. Moreover investments in power generation are no longer centrally planned in deregulated power markets but rather decided on competitive grounds by individual power companies. This poses particular challenges when it comes to evaluating future electricity markets in large-scale systems like the European transmission system. Within this article an approach is presented which allows assessing electricity market development in the presence of stochastic power feed-in and endogenous investments of power plants and renewable energies. This model uses typical days and hours as well as recombining trees to represent both load and feed-in fluctuations until 2050. \r\nFive scenarios are presented covering 30 European countries and simultaneously optimizing generation investments and dispatch as well as utilization of transmission lines. These scenarios focus on different aspects of the triangle of energy policy targets, consisting of security of supply, sustainability and economic efficiency. The first two scenarios give high priority to environmental protection and renewable energies but differ in the impact of government driven expansion of wind, solar and biomass on the integration of renewable energies. In an alternative scenario, the focus is on preserving competitiveness without compromising environmental protection. A fourth scenario focuses on security of supply in connection with strong economic growth. Finally, a scenario is investigated where conflicting interests and competing objectives lead to an energy policy without any clear priorities.", :title "Integration of Fluctuating Renewable Energy in Europe", :keyword2 99, :authors (29663 14845), :session 125}, 1233 {:keyword1 6, :keyword3 0, :abstract "This contribution investigates a bid generation and evaluation problem (BGEP) faced by a freight carrier in a combinatorial procurement auction for transport requests. Combinatorial auctions allow bidders to submit bundle bids. A bundle bid is an all-or-nothing bid on any subset of the tendered transport requests, i.e., a carrier either wins all requests composed in a bundle bid or none. With this feature, carriers are able to express their valuations for synergies for different combinations of transport requests.\r\n\r\nAlthough only a few approaches of the BGEP are considered in the literature, two distinct streams can be identified: central and decentral approaches. Central approaches assume that carriers submit a cost function and the auctioneer calculates the relevant request combinations and bid prices himself. In decentral approaches, a carrier explicitly calculates bundle bids. Central approaches require the carrier to reveal sensitive information while decentral approaches are computationally challenging, as each element of the power set of the tendered requests is a potential bundle bid and can require the solution of some kind of vehicle routing problem.\r\n\r\nWe propose a formulation of a BGEP which combines the task of request bundling with route planning based on the traveling salesman problem. The decentral approach avoids the necessity to share private information of the carrier with the auctioneer . We assume carriers are bidding honestly and therefore do not integrate game theoretic considerations. To solve the proposed BGEP, we develop an exact algorithm and a heuristic algorithm. We furthermore propose and perform a computational experiment to evaluate algorithms for BGEP problems.\r\n", :title "Generation and Evaluation of Bundle Bids for a Combinatorial Transport Auction", :keyword2 106, :authors (11448 15277), :session 190}, 1234 {:keyword1 16, :keyword3 53, :abstract "When the cutting stock problem (CSP) is viewed as continuous process, the trim loss can be lowered by returning some leftovers back to stock and reusing them in subsequent orders. Two sorts of leftovers exist. If they are shorter than an arbitrarily set length M, they are treated as a trim loss. Leftovers longer than M are allowed to be returned to stock. Following this definition, the main objective of the optimization is not only to minimize the trim loss of a specific order, but the overall loss of subsequent orders. The objective of the proposed optimization method is to adjust each specific cutting plan in order to generate more leftovers longer than M. The method is tested by solving a practical example. ", :title "Continuous cutting stock optimization", :keyword2 14, :authors (29666 18342 29674), :session 195}, 1235 {:keyword1 78, :keyword3 0, :abstract "In a vector space over a linearly ordered (possibly skew) field, we consider a linear program with an infinite number of constraints. Only finitely many of them are allowed to be non-zero at a point of the space and a certain constraint qualification must hold. The objective function attains values in another linearly ordered vector space over the field. We present the respective variant of Farkas' Lemma first. We give a generalization of Gale's Theorem of the alternative next. And we formulate the Duality Theorem as well. Finally, we consider possible applications of this theory to other problems of infinite linear programming, whose solution is known, aiming to establish a new approach to solving some of those problems.", :title "A Duality Theorem for Infinite Linear Programming: A Purely Linear-Algebraic Approach", :keyword2 83, :authors (18744), :session 196}, 1237 {:keyword1 96, :keyword3 48, :abstract "The main goal of just-in-time production planing is reduction of the in-process inventory level. This goal may be achieved by appropriate scheduling where items are completed as close to their further processing (or shipment) dates as possible. In some situations where it is too costly to define and control due dates for individual items the model proposed in Toyota may be applied that requires the actual product rate of particular products to be monitored. The problem is formulated as follows, given is a number of products and the required number of items of each product to be produced over a given time period. Processing time of an item of any product is one time unit. Product rate is the proportion of items of a given product to the total number of items over all products completed up to a given time unit. An ideal product rate may be seen as a product rate calculated at the end of the schedule. Some deviation from this ideal may be observed in each time unit. The objective is to construct schedules with minimum (total or maximum) deviation from an ideal product rate. This approach called minimization of the Product Rate Variation is considered in the literature in the context of one machine systems. Practical situations justify considering also parallel machine systems with the objective to minimize the Product Rate Variation. We show that in multi machine environment product rate may be defined in two ways: as time related product rate or volume related product rate. The volume related product rate is defined as in the single machine case. The time related product rate is the average number of items of a product that should be completed in a single time unit. Observe that since items have unit processing times this distinction is not relevant in a single machine system. We discuss both the definitions in the context of two most popular objectives: minimization of total and maximum deviation from ideal product rate. We show that some algorithms developed for the single machine case can be generalized to solve the parallel-machine scheduling problem.", :title "Product rate variation on parallel machines", :keyword2 13, :authors (17949), :session 50}, 1240 {:keyword1 34, :keyword3 0, :abstract "Variable banking products like traditional savings deposits or certain types of mortgages have no contractual maturity and an adjustable client rate, therefore their future cash flows are uncertain. In order to assess the various kinds of risk inherent in these positions, usually a replicating portfolio of traded instruments is constructed that transforms the uncertain cash flows into apparently certain ones. Clearly the construction of this portfolio has a significant impact for the potential risk and return. A stochastic optimization model is proposed for this task. Results based on real data are compared to traditional approaches.", :title "Optimization of variable banking products", :keyword2 99, :authors (29673), :session 267}, 1242 {:keyword1 14, :keyword3 0, :abstract "We describe and analyze an application of the p-regularity theory to nonregular (irregular, degenerate) nonlinear optimization problems. The p-regularity theory, also known as the p-factor-analysis of nonlinear mappings, has been developing successfully for the last twenty years. The p-factor-approach is based on the construction of a p-factor-operator, which allows us to describe and analyze nonlinear problems in the degenerate case. First, we illustrate how to use the p-factor-approach to solve degenerate optimization problems with equality constraints, in which the Lagrange multiplier associated with the objective function might be equal to zero. We then present necessary and sufficient optimality conditions for degenerate optimization problem with equality and inequality constraints. The p-factor approach is also used for solving mathematical programs with equilibrium constraints and construcing the p-factor method for solving degenerate optimization problems. We give new p-order stability conditions for sensitivity analysis of nonregular optimization problems.", :title "P-regular nonlinear optimization", :keyword2 80, :authors (29169), :session 194}, 1244 {:keyword1 23, :keyword3 0, :abstract "Network problems coupled to partial and differential equations offer a broad application area. For instance, think of traffic flow networks, gas pipelines and supply chains. Basically, the focus is on the mathematical modelling as well as on techniques for simulation and optimization purposes. \r\nIn fact, in various cases those models can be related to mixed-integer programming models. To ensure feasibility and to reduce the computational effort of large-scale instances, there is evidently need for suitable algorithms.  ", :title "Time-continuous network problems ", :keyword2 57, :authors (29675), :session 104}, 1247 {:keyword1 75, :keyword3 94, :abstract "Quantitative methods are used for the planning and analysis of product configuration decisions and support the design of a differentiating product line, e.g. by implementing integrated product service systems. Origin is the description of customer-relevant features and the estimation of customers’ willingness to pay and costs for product design, manufacturing and supply. By applying optimization the design of a profit maximizing product program is motivated.\r\nRisks of product supply, which occur due to changes in customer requirements, can be reduced by quantitative methods that increase flexibility. An optimal product configuration for the current period has therefore to be enhanced by a dynamic perspective. Based on the analysis of multi-period product life cycles the performance of a product program is determined by successful innovations, modifications and eliminations. Cost-effective products over several periods are composed by the possible usage of modular architectures for product line design. The variation of additional components promotes product modifications, and thus flexibility. The uncertain and dynamic view of a strategy for cost-efficient product configuration has been considered hardly ever.\r\nThis paper demonstrates how the selection of modules within a multi-period product life cycle perspective is optimized by means of mathematical models. To take into account uncertain demand and customer requirements, robust modules are identified so that future adjustments are optimally anticipated. A risk analysis of the impact of uncertain customer requirements and the cost structure of product lines increases transparency of the specific business risk.\r\n", :title "Optimization of product modularization in light of product life cycles", :keyword2 93, :authors (15182 10057), :session 226}, 1249 {:keyword1 75, :keyword3 97, :abstract "Locating systems are used, if production lead times of mass customized products exceed customers’ expectations for delivery times. To serve these customers, a certain share of production has to be build to stock (BTS) in anticipation of future demand. If incoming customer orders can be matched with these products, customers virtually receive products which are built to their order (BTO), yet with significantly reduced lead times. The identification of suitable BTS products is referred to as locating. Here we present a capacity control which supports the locating of mass customized BTS products to serve individual customer requests. Possible assignments are evaluated based on opportunity costs. Towards this end, price thresholds are computed for each BTS product. These thresholds incorporate information on future demand. We propose simulation optimization to solve the trade-off between the selectivity and the accuracy of the capacity control. Results from a numerical example illustrate potential benefits. The approach has relevance for companies using combined BTO/BTS production in its ability to improve the profitability of order fulfillment.", :title "Capacity control for the locating of mass customized products", :keyword2 91, :authors (26841 2651), :session 99}, 1250 {:keyword1 47, :keyword3 0, :abstract "Employability marks an essential pre-condition to stay successfully within the representative life scheme of an occupational biography. But a permanently rising part of population will shipwreck toward that representative kind of an enduring integration. These failures are caused by economic structure but as well by insufficient competences for individual decision making in the context of labor markets and life schemes of people themselves. \r\nSo far our paper refers to one of the most fundamental problems of modern human resource management: how to decode and how to manage the complexity of modern biographical constructions toward the needs of a modern society which is fundamentally based on economic and technological dynamics. Fitted by some empirical projects concerning unemployed young academics our method – Biographical Factors Tableau (BFT) combined with System Dynamics modeling and simulations – has become reliable to create better diagnostic perspectives, efficient ways of prognosis and fostering personal curricula even within classical (socio-)pedagogical processes which seemed – historically qualified as deeply hermeneutical and structured by situational, individualized field interventions – to be resistant all over the time toward methods of quantification and systematic measurement. \r\nSome empirical case studies underline that a highly quantified controlling of typical biographical indicators and individualized concepts of action by BFT allows positioning as well as navigating of workless careers including differentiated evaluation. We want to provide evidence that “employability” as a referred personal attitude follows to some extend diagnostic master plans as we got to know ever from medical services or preventing maintenance-engineering. \r\n", :title "Re-Building Biographical Employability - A New Methodological Approach of Workforce Related Fostering ", :keyword2 103, :authors (26410 20972), :session 253}, 1252 {:keyword1 29, :keyword3 97, :abstract "The rising share of renewable energies in today's power grids poses challenges to electricity providers and distributors. Renewable energies, like, e.g., solar power and wind, are not as reliable as conventional energy sources. The literature introduces several concepts of how renewable energy sources can be load-balanced on the producer side. However, the consumer side also offers load-balancing potential.\r\n\r\nSmart devices are able to react to changing price signals. A rational behavior for a smart device is to run when electricity rates are low. Possible devices include washing machines, dryers, refrigerators, warm water boilers, and heat pumps. Prototypes of these devices are just starting to appear. For a field experiment with 500 households we simulate adequate device behavior. The simulation leads to a mapping from price signal to load change. We then train a neural network to output an appropriate price signal for a desired load change. Our results show that even with strong consumer-friendly constraints on acceptable price changes the resulting load change is significant. We currently implement the results with a leading energy services provider.", :title "Price-Induced Load-Balancing at Consumer Households for Smart Devices", :keyword2 124, :authors (19080 26402 19100), :session 124}, 1253 {:keyword1 18, :keyword3 124, :abstract "Advanced neural network architectures like, e.g., Historically Consistent Neural Networks (HCNN) offer a host of information. HCNN produce distributions of multi step, multi asset forecasts. Exploiting the entire informational content of these forecasts is difficult for users because of the sheer amount of numbers. To alleviate this problem often some kind of aggregation, e.g., the ensemble mean is used. With a prototypical visualization environment we show that this might lead to loss of important information.\r\n\r\nIt is common to simply plot every possible path. However, this approach does not scale well. It becomes unwieldy when the ensemble includes several hundred members. We use heat map style visualization to grasp distributional features and are able to visually extract forecast features. Heatmap style visualization shows clearly when ensembles split into different paths. This can make the forecast mean a bad representative of these multi modal forecast distributions. Our approach also allows to visualize forecast uncertainty. The results indicate that forecast uncertainty does not necessarily increase significantly for future time steps.", :title "Visualizing Forecasts of Neural Network Ensembles", :keyword2 37, :authors (19080 26402 19100), :session 107}, 1254 {:keyword1 120, :keyword3 56, :abstract "Customer attrition represents a major problem in several industries. The paper elaborates on a methodology for a timely identification of likely churners by means of predictive modeling. The use of forecasting techniques to support decision making is well established in the marketing sciences. However, churns models are routinely devised by traditional modeling paradigms that stipulate the use of a single – possibly pre-selected – model. To improve upon this practice, we explore the potential of a recently developed machine learning approach termed Ensemble Selection. Ensemble Selection consists of two stages: First, a library of individual forecasting models is derived by standard techniques and these are pooled in a second stage by means of greedy heuristics. A set of hypotheses concerning the superiority of Ensemble Selection over traditional marketing support models is developed and tested within an empirical study using several large real-world churn datasets. The results provide strong evidence for the efficacy of ensemble selection and suggest that it outperforms several benchmark techniques. ", :title "Novel Approaches for Marketing Prediction: An Evaluation of Ensemble Selection for Forecasting Customer Churn", :keyword2 37, :authors (9422), :session 109}, 1255 {:keyword1 35, :keyword3 3, :abstract "The portfolio selection involves obtaining optimal proportions of the assets for constructing a portfolio that respects investor-preferences. In general, the existing portfolio selection models consider only financial criteria for asset allocation. In our view, portfolio selection models can be substantially improved by considering the issue of suitability in portfolio selection. Suitability is a behavioral concept that refers to the propriety of the match between investor-preferences and portfolio-characteristics. Financial experts and investment companies use various techniques to profile investors and then recommend a suitable asset allocation from which an optimal portfolio is constructed. In this paper, we propose a framework for portfolio selection by measuring asset quality on both the financial and the suitability criteria. We use a fuzzy multiple criteria decision making method to obtain comprehensive financial quality scores of the assets based upon investor-ratings on the financial criteria used. Analytical hierarchy process technique is used to model the suitability considerations of the assets and a comprehensive suitability performance score of each asset is calculated. Hybrid optimization models based upon the financial quality scores and suitability performance scores are proposed for optimal asset allocation. Numerical illustrations are presented to justify the use of the proposed methodology for asset allocation.", :title "An integrated fuzzy decision making approach for suitable and optimal portfolio construction", :keyword2 39, :authors (29681 29683), :session 268}, 1256 {:keyword1 77, :keyword3 106, :abstract "We consider the following freight train routing problem.\r\nGiven is a transportation network with fixed routes for passenger\r\ntrains and a set of freight train requests, each defined by an origin and\r\ndestination station pair. The objective is to calculate a route for\r\neach freight train such that a sum of expected delays and running times\r\nis minimal. Previous research concentrated on microscopic\r\ntrain routings for junctions or major stations. Only recently\r\napproaches were developed to tackle larger corridors or even networks.\r\nWe also investigate the routing problem from a strategic perspective,\r\ncalculating the routes in a macroscopic transportation network. In this approach, complex structures are aggregated into smaller elements. Furthermore the departure and arrival times of freight trains are approximated.\r\nWe propose two mixed integer programming models for the freight train routing problem, compare them, and present\r\ncomputational results.", :title "The Freigth Train Routing Problem ", :keyword2 95, :authors (26325 14923 16315 14771), :session 92}, 1257 {:keyword1 48, :keyword3 133, :abstract "In the car sequencing problem the cars are scheduled along an assembly line in order to install one or more options.  Cars should be sequenced in such a way that the capacity of none of the stations is exceeded. The sequence that is determined according to capacity, demand and cycle time constraints is called the scheduled sequence. This sequence has vital importance to smooth workload at the stations and avoid order delays. Scheduled sequence can be altered due to defects occur cars in paint shop and these defects cause the shuffling of the scheduled sequence. Therefore, the vehicles should be resequenced according to the predetermined scheduled sequence. The objective of resequencing is to increase the scheduled sequence achievement ratio (SSAR), which is defined as the ratio of cars that enters to the assembly line in the order of the scheduled sequence. To increase SSAR, automobile manufacturers locate a buffer stock area between paint shop and assembly line for resequencing of cars before entering to the assembly line. In this buffer area, defective cars are replaced with non-defectives and position of the cars is changed to increase SSAR. The problem is to determine number of cars (in each model and color) in stock area to maximize SSAR. In this study we developed a two stage stochastic mixed integer programming model to maximize SSAR. In the first stage, the scheduled sequence and number of types and colors of cars in the buffer are decided and in the second stage whether a car in a given position is defective is observed. The two-stage program is solved by Sample Average Approximation (SAA) method and insights on effects of defect rates, stock quantities, composition of model and color type combination on SSAR are discussed. \r\n\r\n\r\n", :title "Maximization of Scheduled Sequence Achievement Ratio in Automobile Manufacturing", :keyword2 78, :authors (29682 20767), :session 240}, 1262 {:keyword1 65, :keyword3 80, :abstract "The topic of this talk is topology planning  of large-scale, real-world gas distribution networks. We are given a set of nominations which each define a balanced allocation of source and sink flows. The goal is to decide which combination of given network extensions such as pipelines, or compressors should be added to the gas network such that every nomination is feasible which means that the specified amount of gas can be transported.\r\n\r\n\r\nThe gas transportation network is modeled by a directed graph. Each arc corresponds to a pipeline or to an active element such as compressors or control valves. In addition to flow conservation a pressure value must be assigned to each node and the gas flow on a pipe is induced by the pressure difference of the endnodes of the arc. This relation is described by a nonlinear function.\r\n\r\n\r\nTo solve large-scale topology extension instances, we present a framework which computes a global optimal solution for this problem. We formulate a nonlinear mixed-integer model in which discrete decisions correspond to active elements. In the beginning of the solution process every nonlinearity is substituted by linear outer approximations. At the time when all integer variables are fixed, we replace the approximations by their corresponding exact formulas. The resulting local problem is convex and thus can be solved to global optimality. This interconnection of a mixed-integer linear program and a nonlinear program is implemented using the solvers SCIP and IPOPT. We will present computational results on real-world instances with hundreds of nodes and about 3000 arcs. The data are provided by Open Grid Europe GmbH (OGE), a subsidiary company of E.ON Ruhrgas AG.", :title "Mathematical Optimization for Capacity Planning of Gas Distribution Networks", :keyword2 53, :authors (25350 14736 16315 23745 26282), :session 76}, 1266 {:keyword1 8, :keyword3 0, :abstract "In many applications, we are faced with optimization problems of fixed combinatorial structure and only the values of the parameters vary. Our task is to derive algorithms that quickly deliver new solutions to changing parameters. This is particularly important for realtime devices.\r\n\r\nAn example occurs in the design of display controllers for OLED devices: A given image must be decomposed into non-negative rank-1-matrices that add up to the original image. This problem must be solved repeatedly on the fly for varying content. However, the combinatorial structure of the problem remains the same. For example, a task in one commercially used addressing schemes can be modeled as a transshipment problem on a fixed graph with bounded bandwidth, whereas the demands and the capacities depend on the image. There is a linear time algorithm of Hagerup et al, but it relies on integer programming in fixed dimension which is not an option on a driver chip in a mobile phone. We present a general technique to design custom-made dynamic programming algorithms that fit the needs for being implemented in hardware.\r\n\r\nOur method is based on Fourier-Motzkin-Elimination. This may come to some surprise as FME is not thought to solve LPs efficiently. The key point is that we use FME only in the design process of the algorithm, where we consider the input parameters as variables. We perform the elimination on the original variables and we treat the input parameters symbolically. However, this does not work out of the box. We present techniques and software to eliminate redundant constraints and to lift the considered polyhedron, i.e. to derive extended formulations, to avoid an explosion of number of inequalities. We firmly believe that our general method can be applied to many other problems.", :title "A technique to solve combinatorial optimization problems in real-time devices ", :keyword2 0, :authors (29680), :session 214}, 1268 {:keyword1 28, :keyword3 14, :abstract "Electricity prices are the vital input of short-term planning in a competitive electricity market. Turkey's electricity market is going to be changed from a centralized approach to a competitive market model. Fluctuations in the electricity consumption show that there are three periods, day, peak, and night, for demand. The fluctuations in a day cause fluctuations in the electricity prices, which is a planning problem from suppliers' point of view. Therefore, this study proposes a customized modeling approach to predict next-day's electricity price in each period with minimum error. Proposed approach is based on robust and continuous optimization techniques, which ensures achieving the optimum electricity price to minimize error in periodic price prediction. On the other hand, next-day electricity prices are commonly forecasted by using time series models in the literature. Thus an error comparison between dynamic regression model, which is a common time series model, and the approach proposed here is to be presented.", :title "Electricity Price Modeling for Turkey", :keyword2 94, :authors (14543 20092 20485 3524), :session 62}, 1269 {:keyword1 85, :keyword3 98, :abstract "In this computational study we compare different solution methods on a reasonably wide test set (31 problems, each solved repeatedly with expanding scenario sets). \r\n\r\nFirst we consider direct solution of the deterministic equivalent LP problems by simplex and interior-point methods (using general-purpose solvers). \r\nThen we try Benders-type decomposition methods: \r\nthe L-shaped method of Van Slyke and Wets, \r\nthe Regularized Decomposition method of Ruszczynski, \r\nthe box-constrained trust-region method of Linderoth and Wright, \r\nand a level-regularised decomposition method. \r\n(The latter method applies the Level Method of Lemarechal et al.) \r\n\r\nWe conclude that decomposition methods have much better scale-up properties than direct methods. Regularisation further improves performance. \r\nMoreover we find that aggregated models scale better than multicut ones. \r\n", :title "A comparison of solution methods for two-stage stochastic linear programming problems", :keyword2 13, :authors (29687 29688 13952 3775), :session 119}, 1270 {:keyword1 56, :keyword3 125, :abstract " In Japan, the production of vegetables has fallen from the latter half of the 1980's because of decreasing of agriculture workers. On the other hand, the amount of   imported vegetable has increased, because the price of imported vegetables is cheap and the stable supply of them is possible. However, in recent years, the consumers have become increasingly aware of problem related to safety of food like chemical levels in imported vegetables, therefore, needs of domestic vegetable have risen. This study analyzed purchasing behaviors of domestic vegetables and imported vegetables through two questionnaire surveys and interviews survey of housewives who live in Tokyo area at super-market. Four main analyses were undertaken. First, the consumer consciousness concerning the purchase of the vegetables has been extracted by the factorial analysis. Second, consumer purchasing behaviors were classified into two types based on factor scores of factorial analysis by cluster analysis. Third, the author compared two types and the consumer consciousness that influence purchasing Japanese domestic vegetables was analyzed by structural equation modeling analysis (SEM). And last, factors affecting consumers’ decision–making in purchasing vegetables were ascertained whether they are based on the consumer consciousness which influence the purchasing Japanese domestic vegetables by the survey at a store. From this survey, brand switching behavior model with price acceptability was built. This model is available for price setting at supermarket.", :title "Decision Making Process Model with Price Acceptability in Japanese Vegetables", :keyword2 19, :authors (29686), :session 257}, 1272 {:keyword1 77, :keyword3 8, :abstract "Routing a pipe through a power plant is a difficult task as one has many possibilities. The problem combines discrete aspects and a nonlinear physical model, which can be formulated as a truss. In the past time the wide field of truss design with linear elasticity has been discussed from a mostly nonlinear point of view. Models for the problem can either be written as quadratic problems/ second-order-cone problems or with the use of semidefinite problems. On the other hand, some research has been done modeling the problem with discrete variables. This approach linearizes some constraints in the quadratic problem so one gets a mixed-integer program.\r\nWe investigate how adding path constraints change the properties of the problem. This was not done before and yields some difficulties for solving the model. Also the self-weight of the bars is considered.\r\nIn our application a rough outline of the admissible region and a start and end point are given. The task is find a practical solution for an engineer to start with. In addition to the self-weight of the pipe we are also asked to place pipe hangers that provide support for the pipe. Several sorts of hangers need to be considered and are modeled into the MIP-framework.\r\nSome numerical results are presented.", :title "How to route a pipe", :keyword2 133, :authors (19441 29261 19424), :session 213}, 1274 {:keyword1 94, :keyword3 14, :abstract "The goal of robust optimization is to find solutions which are applicable even if uncertainties within the parameters of the problem are involved. However, classic robust optimization often is too conservative such that the resulting solutions are much worse than a non-robust solution to the problem. This is a reason for the development of less conservative robust models. In this paper we extend the concept of light robustness originally developed in Fischetti and Monacci (2009). \r\nIts idea is to carefully relax the constraints and hence the robustness of the solution as much as it is needed in order to satisfy a certain quality standard.\r\n\r\nWe analyze this concept and discuss its relation to other well-known robustness concepts such as strict robustness (see Ben-Tal, Ghaoui, Nemirovski (2010)), or the approach of Bertsimas and Sim (2004). We show that the light robust counterpart is computationally tractable in case of polyhedral or ellipsoidal uncertainty sets. In robust optimization it has to be accepted that the nominal quality of a solution decreases with an increasing level of robustness.\r\nWe discuss this trade-off and show that non-dominated solutions with\r\nrespect to nominal quality and robustness can be calculated by the light robust approach.\r\n", :title "The concept of light robustness", :keyword2 89, :authors (1601), :session 194}, 1275 {:keyword1 35, :keyword3 34, :abstract "Since Jegadeesh and Titman (1993) [JT] introduced an abnormal return generating, decile portfolio based trading strategy, that buys stocks with the highest past returns (top decile) and sells those with the lowest (bottom decile), a vast number of subsequent papers discussed possible explanations for this effect referred to as momentum. Besides a risk based reasoning, behavioral models emerged which claim momentum to be a consequence of irrational behavior of market participants.\r\nIn contrast, we pursue a mere statistical approach that is motivated by JT’s decomposition of momentum profits. Although we primarily focus on providing theoretical insights into (statistical) sources of momentum profits, our work is deeply substantiated by empirical evidence from various stock markets as well. By the means of Monte Carlo simulation, we replicate properties of real market data, helping us to extract necessary conditions for significant momentum profits. Essentially, we find these factors to be the first and second moment of individual stock return time series. Thus, a considerable amount of trading profits stems from the distribution of mean and variances of stock returns. More precisely, the particular appearance of any stock market’s mu-sigma-plot alone indicates, whether momentum effects can be pronounced in this market or not. Additionally, we find the mean-variance ratio of stock returns to play an important role in understanding the momentum puzzle. Introducing higher moments or unequal covariance does not change our results significantly.\r\nWe further show, that in absence of notably autocorrelated stock returns or stock reactions to a \"common factor\" [JT], momentum must necessarily show up and hence is at least less puzzling than pointed out by existing literature.", :title "Statistical sources of momentum trading profits", :keyword2 97, :authors (29669 14545), :session 218}, 1276 {:keyword1 35, :keyword3 93, :abstract "We extend a well known risk measure that measures the impact of uncertainty resulting from mis-specification of derivative models by using an optimization-based approach that uses distributions based on non-parametric specification. This allows for incorporation of a much wider class of distributions that results in more revealing measures. Our risk measure can be formulated as a semi-definite optimization problem and can be efficiently solved.\r\n", :title "Market Price-Based Convex Risk Measures: A Distribution-Free Optimization Approach ", :keyword2 82, :authors (2573 30065), :session 264}, 1278 {:keyword1 86, :keyword3 0, :abstract "We consider the stochastic resource-constrained multi-project scheduling problem (SRCMPSP) where a number of projects with stochastic activity durations have to be scheduled such that the expected sum of the project makespans is minimized. In an experimental investigation we first generate a novel set of instances for the SRCMPSP subject to a well-defined test design with different problem parameters. We then perform a computational study employing a genetic algorithm with two different scheduling policy classes (resource- and activity-based) and study the performance of the latter with respect to the mean and the variance of the objective function. ", :title "Experimental investigation of scheduling approaches for the stochastic resource-constrained multi-project scheduling problem", :keyword2 99, :authors (29667 829), :session 50}, 1283 {:keyword1 22, :keyword3 71, :abstract "Humanitarian logistics is a widely recognized area. Most of the OR-oriented publications in this area deal with problems occurring in the preparation or in the immediate response phase of the disaster relief-lifecycle. Only little literature addresses the recovery phase or long-term relief operations. Characteristic for this phase is, for instance, the tight financial situation. Hence, it is important to consider costs as an optimisation criterion in this phase. Moreover, climate change has caused an increasing number of extreme weather events in the recent past. These weather influences often lead to further disastrous events following the initial natural disaster, and hence result in an increasing number of uncertainties in the recovery phase of a relief operation.\r\n\r\nVarious humanitarian logistics planning problems arise in such “overlapping disaster settings” as described above. For instance, transportation and inventory planning have to be adjusted to the new situation and even locations sometimes have to be replanned if facilities have been destroyed or the affected area has increased. Meanwhile, the ongoing relief operations have to proceed.\r\n\r\nIn this work, a transshipment model to relocate inventory in an overlapping disaster situation is presented. The mixed integer programming model considers two objectives: First, the minimisation of unsatisfied demand and second, the minimisation of logistics costs. The former is included using a penalty cost approach with periodically increasing costs for unsatisfied demand. It is shown that the overall unsatisfied demand for relief items can be reduced considerably without a significant increase of operational costs using the proposed model for transportation planning in overlapping disaster situations.", :title "A transshipment model for relief item redistribution in overlapping disaster situations", :keyword2 106, :authors (26489 20937 26607), :session 185}, 1285 {:keyword1 85, :keyword3 99, :abstract "Coherent risk measures play an important role in building and solving optimization models for decision problems under uncertainty.\r\nA prominent example is the single-period risk measure Conditional-Value-at-Risk (CVaR), which is widely used in applications due to its favorable properties.\r\nEspecially, in single-period mean-risk optimization problems\r\ninvolving scenarios, CVaR-based models allow for equivalent linear programming formulations.\r\nAn appropriate time-consistent generalization for multiple periods is to apply CVaR-like measures recursively over the time periods. \r\nThis type of risk measurement attracted interest in recent years (e.g. as nested Average VaR (nAVaR), dynamically consistent Tail VaR (DTVaR), Conditional Risk Mappings).\r\nWe consider the case of risk measurement for stochastic value processes. The risk-adjusted value is calculated recursively over the\r\ntime steps, taking the current intermediate value in a minimization into account. Risk measurement for a single random variable at the time horizon is a special case in this setting, corresponding to simplifications concerning the intermediate values. \r\nWe consider a finite setting in time and states on a scenario tree and discuss different problem formulations with recursive \r\nmulti-period risk measurement and compare this approach with the single-period model with CVaR spanning over the whole time horizon.\r\nWe discuss the integration of this concept into multi-period mean-risk optimization problems.\r\nAs an application, we consider risk-adjusted value processes in power generation optimization.\r\n", :title "Multiperiod stochastic optimization problems with time-consistent risk constraints and an application to power generation scheduling", :keyword2 93, :authors (29367 29692), :session 127}, 1286 {:keyword1 35, :keyword3 97, :abstract "According to IAS 36 an entity has to recognise an impairment if the recoverable amount of an asset is lower than the carrying amount.  The recoverable amount as value in use is the sum of the discounted net cash inflows of a detailed planning period and a terminal value. Thus, the recoverable amount and of course the impairment of the asset are the results of forecasts be based on best estimates. IAS 36 gives some guidelines in forecasting the cash flows and in choosing the discount rate.\r\n\r\nUsually only a combination of assets generates cash flows. The smallest possible set of assets that generates future cash flows is a cash generating unit. Furthermore, there are assets or combinations of assets that are needed by two or more cash generating units. IAS 36 argues that the carrying amount value of these combinations of assets can be divided on a reasonable and consistent basis among the related cash generating units and offers several rule-of-thumb suggestions for such an assignment. Even more, if an entity assumes that a consistent allocation is impossible, a new cash generating unit on a higher aggregated level has to be defined that combines all considered assets and sets of assets. A similar structure is given for goodwill that once was calculated as a residuum from purchase price allocation.\r\n\r\nThe problem is how to choose a mechanism for allocating the carrying amount of joint assets. The decision has consequences for the amount of impairment for years. As the cash flows generated by the cash generating units are forecasts, we are faced with the stochastic nature of the consequences. We will discuss several approaches for the allocation decision, objective functions, and present an optimization approach that incorporates Monte Carlo simulation technique.\r\n", :title "Optimizing Impairment of Assets", :keyword2 94, :authors (13364), :session 94}, 1290 {:keyword1 85, :keyword3 35, :abstract "This paper deals with portfolio efficiency testing with respect to second-order stochastic dominance criterion. These tests classify a given portfolio as efficient or inefficient and give some additional information for possible improvements. Unfortunately, these tests are very sensitive to underlying discrete probability distribution of returns. Therefore, this paper focuses on applying robustness approaches and techniques to these tests. The robust formulations of the SSD portfolio efficiency tests are presented. Firstly, the effect of changes in scenarios is addressed. Secondly, the possible changes in probabilities of the scenarios are incorporated. Finally, the contamination techniques and stress testing approach is applied. In a numerical study, the results of all these considered robust tests are compared.        ", :title "Robustness in SSD portfolio efficiency testing", :keyword2 19, :authors (12024), :session 118}, 1292 {:keyword1 91, :keyword3 63, :abstract "Cloud Computing is a promising approach for IT users as it allows for the accommodation of their highly fluctuating demand for IT resources at reasonable costs. In so-called Clouds, resources such as CPU, memory, storage and bandwidth are bundled into single services which are then offered to Cloud users. The efficient utilization of these limited capacity resources is a crucial success factor for Cloud service providers who face uncertain, temporally distributed demand for service classes of different worthiness. Hence, revenue management is applied to control the acceptance or denial of booking requests in order to maximize revenues. Whereas an acceptance can have a positive influence on customer loyalty, a denial can put the customer loyalty at risk. These changes in customer loyalty will have an impact on the amount of future business and cross selling. In order to maximize long-term profits Cloud service providers should establish loyalty with prospective customers with low actual but high future contributions and reference customers with low own but high induced contributions. Therefore, the traditional optimization problem of only maximizing transaction-based revenues is enhanced by also considering the loyalty affecting capacity availability decisions of the Cloud service provider which in turn will influence future revenues. Furthermore, a simulation in MATLAB with an extended bid-price control method is performed in order to test the efficiency of the proposed model.", :title "Customer Loyalty-Based Revenue Management in Cloud Computing", :keyword2 56, :authors (29444), :session 96}, 1296 {:keyword1 101, :keyword3 78, :abstract "Today's decision making problems are discrete, multi-criteria and involve multiple decision maker (DM).Organizations use the GDM techniques because of the problem's complexity. One of the key questions in this type of problems is how the preferences of the DMs can be modeled. DMs are able to provide only incomplete information, because of time pressure, lack of knowledge, and their limited expertise related to the problem domain. In these types of situations the DSS should allow modeling of the incomplete preference information. \r\nIn this study we developed an interactive procedure which uses incomplete information preference information. Main theme underlying the method is every group member wants to compare their partial information with other group members. This procedure reflects the incomplete information as linear range because it can count easily from partial utility information. Range type makes the incomplete information effective and efficient to demonstrate the group members. In addition to this, range type utility information makes easy to compare every group members’ utility information with group’s information and collecting the each group member’s utility information within group’s utility information. To obtain group utility, preference aggregation method is used. Interactive procedure helps to make a consensus of group.  The method uses the criterion of realism (Hurwicz) and for this it uses the infinity of knowledge. \r\nWe used this method for the evaluation of the performance of organization companies as the service suppliers of a pharmaceutical company.\r\n", :title "The evaluation of supplier performance with multi-criteria group decision making method based on partial information", :keyword2 44, :authors (26093 29699), :session 252}, 1299 {:keyword1 6, :keyword3 0, :abstract "Laboratory experiments on combinatorial auctions with human subjects have been conducted by several research groups to compare performance measures of various auction formats and rules. The experimental studies have mostly focused on analyzing aggregate performance outcomes and emergent behaviors rather than individual bidders’ behaviors. The purpose of this research is to computationally replicate previous experimental outcomes based on the characteristics of individual bidders’ behaviors. Especially, as a format of combinatorial auction, Hierarchical Package Bidding (HPB) has been suggested and used for spectrum auctions by the FCC in the U.S. because of its simplicity in implementation. In this research, using the data from the laboratory experiments (openly available at http://wireless.fcc.gov/auctions), on which the FCC based its decision to use the HPB in 2008, bidding behaviors of each bidder as an agent are modeled in terms of the behavioral variables such as degrees of irrationality and risk-attitude in comparison to straightforward bidding behavior. Then the experimental auction outcomes are replicated by employing Agent-based Social Simulation method so that computational experiments can be performed further on with various auction design rules and different sets of agent populations. The preliminary results indicate that the proposed modeling and simulation approaches are promising and worthy of further research. By the time of the OR 2011 in Zurich, the models will be refined and therefore able to provide more accurate results.", :title "Agent-based Modeling and Simulations for Replicating Experimental Outcomes in Combinatorial Auctions", :keyword2 97, :authors (29320), :session 134}, 1302 {:keyword1 17, :keyword3 100, :abstract "A peculiarity of the relative optimisation non-parametric (NP) – neural network (NN) forecasting models is their dimensionality, namely the number of input-output bundles used for the training phase of the NN with respect to the number of input variables incorporated. Trout et al. (1995), as well as Pendhakar and Rodger (2003), argue that the input-output bundle size should be more than ten times the number of input variables. As a result, a significant number of hybrid (NP-NN) applications for optimisation forecasting are abandoned. To be more precise, by assuming that every bundle stands for an operational unit, it is not uncommon that only a few units operate in a sector, hence, the NP-NN models are disqualified. \r\n\r\nWe tackle this problem by developing a random data generation method to create virtual operational units respecting the production process of the parent – actual units. The data generation process involves an interval estimation to determine the range where the input and output parameters of the units’ production process take values. These intervals are formed by the probability density function that rules the input-output data of the sector.  \r\n\r\nThe scope of the present study, besides the solution development on the dimensionality problem of the NP-NN models, is the introduction of a forecasting technique to determine the optimum input-output levels between two consecutive time instances, t and t+1. The optimum output or input levels uncovered by the proposed model are a result of the comparative efficiency assessment process of the sample operational units.\r\n\r\nThe new model applies a hybrid three-stage analysis based on Data Envelopment Analysis, random data generation process and Artificial Neural Networks.\r\n", :title "Dimensionality Free Short-Term Comparative Optimisation Forecasting Model", :keyword2 32, :authors (29709 29707 29701), :session 109}, 1303 {:keyword1 8, :keyword3 86, :abstract "We consider the following problem of course scheduling and assignment to students. Students express their preferences for each course from several sets of proposed courses, and each student has to take a certain number of courses from each set. A minimal number of students is required to open a course, and a maximal number of students is specified for each course. The courses have to be scheduled on a limited number of periods, so that any two courses may take place simultaneously only if they have no students in common. This problem can be seen as a generalization of the Student Project Allocation problem. The problem consists therefore in determining which courses to open, specifying the schedule of these opened courses and assigning students to courses, so that their preferences are maximized. Our model is an Integer Programming problem. We solve it by means of an iterative process with a common available solver.", :title "Course assignment problem with expressed preferences in a timetable", :keyword2 77, :authors (18125 29706), :session 142}, 1305 {:keyword1 86, :keyword3 96, :abstract "We consider project scheduling problems subject to general temporal constraints where the utilization of a set of renewable resources has to be smoothed over a prescribed planning horizon. In particular, we consider the classical resource leveling problem, where the variation of resource utilization during the project execution is to be minimized and the so-called overload problem, where cost are incurred, if a given threshold for the resource utilization is exceeded. For both problems, we present new mixed-integer linear model formulations and domain-reducing preprocessing techniques. In order to strengthen the models, lower and upper bounds for the resource requirements at some point in time as well as effective cutting planes are outlined. We use CPLEX 12.1 to solve new medium-scale instances as well as instances of the well-known test set devised by Kolisch et al. (1999). In a comprehensive experimental performance analysis, the solutions of the resulting branch-and-cut procedure are compared to a tree-based branch-and-bound method with a sophisticated constructive lower bound (best exact method known from the literature). Our new procedure usually outperforms the state-of-the-art tree-based algorithm. Instances with up to 50 activities and tight project deadlines are solved to optimality for the first time.", :title "Mixed-integer linear programming models for resource leveling problems", :keyword2 77, :authors (9524 5965 14828), :session 64}, 1307 {:keyword1 12, :keyword3 0, :abstract "Peptide sequencing from mass spectrometry data is a key step in proteome research. Especially de novo sequencing, the identification of a peptide from its spectrum alone, is still a challenge even for state-of-the-art algorithmic approaches.\r\nWe developed a fast and flexible algorithm named ANTILOPE which is based on mathematical programming. \r\nIt builds on the widely used spectrum graph model and can be combined with a variety of scoring schemes.\r\nIn the graph theoretical formulation the problem corresponds to the longest antisymmetric path problem in a directed acyclic graph. \r\nOther algorithms like PepNovo or NovoHMM can solve this problem only for the special case where conflicting node-pairs are non-interleaving.\r\nTherefore these algorithms are limited to a certain set of ion-types when constructing the spectrum graph.\r\nANTILOPE combines Lagrangian relaxation for solving an integer linear programming formulation with an adaptation of Yen’s k-shortest paths algorithm to compute suboptimal solutions.\r\nThis approach shows a significant improvement in running time compared to mixed integer optimization and performs at the same speed like other state-of-the-art de novo sequencing tools like PepNovo or NovoHMM.\r\nANTILOPE implements a generic probabilistic scoring scheme that can be trained automatically for a dataset of annotated spectra and is independent of the mass spectrometer type.\r\nEvaluations on benchmark data show that ANTILOPE is competitive to the popular state-of-the-art programs in terms of run time and accuracy.\r\nFurthermore, it offers increased flexibility in the number of considered ion types.\r\nANTILOPE will be freely available as part of the open source proteomics library OpenMS.", :title "Antilope - a Lagrangian relaxation approach to the de novo peptide sequencing problem", :keyword2 77, :authors (29626 11835 29713), :session 65}, 1308 {:keyword1 75, :keyword3 124, :abstract "Dramatic savings may be achieved by the coordination of replenishment orders for item groups in multi-item inventory systems. In this study, we consider a fully substitutable group of product inventory system in which customer demand may be satisfied by delivering a combination of products in the group. The problem motivation comes from ATMs: A customer requesting a certain amount from an ATM accepts any combination of banknotes that totals to the amount she requested. However, her satisfaction would not be the same for all deliverable combinations. Our objective is to determine customer order fulfillment policy that minimizes average cost per unit time. We assume that customer gives different utility values for each combination and that utility function is known. We consider a continuous-review can order policy (S,c,s) with Compound Poisson demand with lost sales and assume that replenishment lead times are random variables. We model the system as a Markov Decision Process, and determine order fulfillment and replenishment policies by using approximate dynamic programming. Because of infamous curse of dimensionality, we develop a function approximation algorithm by using neural one-layer neural network that iteratively fits a function to state values and finds an approximately optimal can order and order fulfillment policy. The performance of this policy is compared with those of some heuristic policies. ", :title "Order fulfillment and replenishment policies in substitutable item inventory systems ", :keyword2 76, :authors (29710 20170), :session 122}, 1309 {:keyword1 85, :keyword3 0, :abstract "In this paper we present an expansion planning model for electricity systems. The model was developed to analyze long term investment strategies in an electricity system. In particular the model is developed to  study how a large share of renewable energy generation best can be included in an existing electricity system.  The decisions are divided into long term strategic investment decisions and short term operational decisions. This is in order to address the effects of short term uncertainty, for example variation in wind and other renewable generation, on investments. The model is a combined infrastructure and operational decision model including both generation and the physical transmission network (DC Load Flow approach).  Both are subject to uncertain factors such as availability of renewable generation, fuel prices and growth in demand. The uncertainty is modeled using a scenario tree, were nodes are divided into strategic and operational nodes, and the resulting problem turns into a large scale multi-stage stochastic MIP solved using a branch and fix algorithm.", :title "A multi-stage stochastic programming approach to power system expansion planning", :keyword2 29, :authors (29711), :session 103}, 1310 {:keyword1 45, :keyword3 0, :abstract "A major factor in the increase in the cost of any health care system is related to the strategic behavior of the system participants based on incentives embedded in the system.Health care systems with multiple decision makers often have conflicting objectives leading to additional costs in the system.  The U.S. health care system has the highest expenditures as a percentage of GDP, standing at 17.3% of U.S. GDP in 2009. While most engineering efforts to reduce costs have focused on normative models  of components of the delivery system,  this paper considers the effects of incentives such as contracts, education / information, and limited contracting to reduce the cost for a health care system with insurers, providers and patients. We focus on the issue of promoting preventive care and analyze the incentive structures needed to reduce the overall cost for the system.\r\n", :title "Engineering Incentives for Health Care Systems", :keyword2 0, :authors (24653 29714 29715 29716), :session 81}, 1311 {:keyword1 100, :keyword3 0, :abstract "A simple extension of the standard scenario technique can show how a system strikes back. Thus, under certain circumstances a system analyst can foresee what must be done to achieve specific goals in a system. The standard scenario technique uses an impact matrix model to assess the importance of impact factors for the future development. The importance is assessed based on the strength of the mutual impacts between the factors. In the standard approach two impacts on a factor enhance the importance of that factor even if one of these impacts tends to increase and the other tends to decrease the factor. In the new approach such impacts cancel themselves out and thus the new approach called indirect system feedback analysis reveals a much more realistic development of the system. The presentation shows (a) the plausibility of the indirect system feedback analysis, (b) the additional requirement s for the definition of the impact factors and the impacts, and (c) prototypic results for two case studies. When analyzing the production chain of maize and investigating the coexistence of genetically modified plants and non-genetically modified plants the indirect feedback analysis shows that the extent and costs of measures to avoid commingling strongly increase. When analyzing regional touristic development the indirect feedback analysis shows that the touristic value added can at most be increased by the power of the regional touristic organization. ", :title "Systems strike back – but how?", :keyword2 19, :authors (29693), :session 253}, 1312 {:keyword1 75, :keyword3 0, :abstract "We present a new model formulation for a multi-product lotsizing problem with product returns and remanufacturing options subject to a capacity constraint. The given external demand of the products has to be satisfied by remanufactured or newly produced goods. The objective is to determine a feasible production plan which minimizes holding and setup costs. As a model formulation based on the well-known CLSP leads to poor bounds of the LP relaxation we defined valid inequalities to tighten the LP relaxation. Furthermore, we describe a MIP-based solution approach to solve this lotsizing problem. A numerical study shows the performance of this solution approach.", :title "Multi-product capacitated lotsizing in Closed-Loop Supply Chains", :keyword2 92, :authors (13866), :session 161}, 1314 {:keyword1 33, :keyword3 7, :abstract "We consider a two-echelon supply chain problem, where the demand of a set of retailers is satisfied from a set of suppliers and shipped through a set of capacitated cross-docks which are to be established. The objective is to determine the number and location of cross-docks, the assignment of retailers to suppliers via cross-docking so that the total cost of pipeline and retailers' inventory, transportation, and facility location is minimized. We formulate the problem as a non-linear mixed integer programming.We first derive several structural results for special cases of the problem. We also demonstrate that the \"Capacitated Plant Fixed-Charge Transport Location Problem\" is a special case of our problem. To solve the general problem, we show that it can be written as a cutting stock problem and develop a column generation algorithm to solve it. We investigate the efficiency of the proposed algorithm numerically. We then\r\nextend the problem by allowing dierent truck capacities as decision variables.", :title "Designing Production-Inventory-Transportation Systems with Capacitated Cross-Docks", :keyword2 8, :authors (5465 20857), :session 223}, 1315 {:keyword1 8, :keyword3 59, :abstract "The floorplanning problem consists in finding the optimal positions for a given set of departments of fixed area within a facility such that the sum of distances between pairs of department that have a positive connection cost is minimized. This is a NP-hard combinatorial optimization problem. This paper applies the Electromagnetism-like Meta-Heuristic method with some local search to the floorpalnning problem. We provide results from several test problems that demonstrate the robustness of this approach across different problems and parameter setting.", :title "Solving Floorplanning Problem by  Electromagnetic Meta-Heuristic Method", :keyword2 54, :authors (29691 14137), :session 238}, 1316 {:keyword1 25, :keyword3 88, :abstract "Production management strives to optimize the overall cost of in-line inspection and the value of throughput gained in return. This study is based on semiconductors manufacturing, but can applied in any production line embedded with inspections. The line consists of consecutive deteriorating machines, each inspected via the items it produces. Each inspection result triggers the respective machine's repair, if needed. Fixed and variable inspection cost includes elements, such as: depreciation, maintenance, operations, manpower, materials, facilities, and overhead. The gain of inspection is quantified via the reduction in throughput loss, achieved due to improved machine processing. The impacts of inspection capacity and inspection policy on cost and throughput loss are investigated using analytical and simulation models, based on queueing and Markov chains. Conclusions illustrate that:\r\n(a)\tUnder a given inspection capacity, throughput loss decreases to a minimum and then increases with average inspection rate. This is since growing inspection rate increases the yield until a maximum, but further increase in rate causes longer inspection sojourn time and consequently longer response time to repair a machine, and thus reduces the yield.\r\n(b)\tIncreased inspection capacity generates higher cost, but also reduces throughput loss. Modeling the inspection capacity cost and the line throughput gain enables to determine the optimized combination of both.\r\nThus, the inspection policy and inspection capacity are used to optimize the overall cost and throughput gain of in-line inspection. The associated inspection tool utilization and various inspection policies are also investigated and results are compared.\r\n", :title "Optimizing the Cost and Throughput Gain of In-line Inspection in a Production Line", :keyword2 87, :authors (22274 10323), :session 164}, 1318 {:keyword1 45, :keyword3 96, :abstract "We consider the problem of planning the flow of elective patients in a hospital. For each patient the Diagnosis-related group (DRG) and the clinical pathway are given. The DRG and the length of stay determine the revenue the hospital will receive for a patient. The clinical pathway of a patient defines the clinical procedures to be performed and precedence relations between them. Resources such as diagnostic devices, the operating theater, and beds which are required by the procedures within the clinical pathways are limited. This problem is closely related to admission planning but instead of deciding on the number of patients for fixed schedules we decide for a fixed number of patients on the schedule (patient flow) of each patient. To this end we model the problem as a resource-constrained multi-project scheduling problem (RCMPSP) with minimum and maximum time lags. We propose a zero-one programming formulation with the objective to maximize the DRG-based contribution margin taking into account limited resources.  In a computational study where we employ data from a midsize hospital we can show that solving the zero-one programming formulation with standard optimization software can be done fast enough for practical applications. Furthermore, we show that the solutions obtained with our approach considerably improve the solutions currently employed in the hospital.", :title "Managing the flow of elective patients within hospitals", :keyword2 57, :authors (29539 829), :session 88}, 1320 {:keyword1 126, :keyword3 14, :abstract "The use of integrated aqueduct systems (vertical systems with several interconnections between the network infrastructures) is quite common in the provision of drinking water. In fact, it enables the system to handle crisis in the provision of the service caused, for example, by pollution emergencies or peaks in day demand curves. In Italy, the Law n. 36/1994 established a net separation between water resource planning, assigned to local water authorities (ATOs) and the operation of water utilities. The ATO assigns a concession contract to a private provider that has the right to produce, operate and manage water utilities for a certain period of time (usually 30 years). The tariffs, set by the ATO according to the Government Decree n. 1/8/1996, can be revised after a period lasting three years. Within these periods some technical data can be considered as fixed, such as the volume of water produced and the operating costs. Therefore the provider’s profit can be considered as constant over a single year though it varies on a yearly basis. That’s why a deterministic approach can be properly adopted over a three-year period.\r\nWe formulate and solve a multi period optimal control model in order to determine the optimal abstraction policy  for a provider of water services who has invested in the interconnection of two different sources (e.g. groundwater vs river abstraction) and wants to maximise his profit and to minimise the environmental costs related to the abstraction. The interconnection of water abstraction plants gives the provider the option to strategically decide the optimal mix of different water sources to be used in suppling water to a local community. Our aim is to show that this operational flexibility is economically relevant if optimally exercised.", :title "Multi period optimal mix in the interconnection of drinking water sources", :keyword2 136, :authors (16165 10666), :session 197}, 1325 {:keyword1 44, :keyword3 18, :abstract "By aggregating, unifying and extending several existent evaluation models, a holistic and universal framework for the assessment of group decision-making methods and systems is introduced and justified. It focuses on the following general points of view: ability to direct the decision-making process, communication, fairness, efficiency and cognitive complexity of analysis, problem abstraction, learning, and methodological foundations. It consists of twenty-eight criteria and almost hundred sub-criteria which are defined and structured in such a way that quantitative measurability and objectivity are maximized. The long-term goal of the framework is to provide a standardized means for the unbiased analysis and comparison of a wide range of heterogeneous methods and systems that support group MCDA.\r\n\r\nTwo applications of the framework are also presented. Firstly, an interactive multi-agent aggregation/disaggregation dichotomic sorting procedure is evaluated with a simulation experiment and a case study. Several factors are considered: ability to reach a compromise, autonomous guidance and conflict resolution, convergence of opinions, and robustness of the derived solution.\r\n\r\nSecondly, some widely used and state-of-the-art multi-criteria methods for group decision-making – ELECTRE TRI for groups, ELECTRE-GD, group PROMETHEE, group AHP, etc. – are analysed and compared with regard to their information complexity and the cognitive load that is imposed on the decision-makers. Five evaluation criteria are applied: total number of preferential parameters, quantity of inputs required for the first iteration of the decision-making process, average number of manual adjustments in each subsequent iteration, amount of data to be observed, and complexity of data types.", :title "A universal framework for the assessment of group MCDA methods and systems – with its applications to convergence and cognitive complexity", :keyword2 19, :authors (29689), :session 251}, 1329 {:keyword1 28, :keyword3 77, :abstract "The integration of renewable energy sources is one of the key challenges for the transition of the energy supply chain towards a low carbon society. Due to the intermittency of wind and solar power additional storage and flexibility is needed for their integration into the electricity system. In a so called smart grid generation plants and consumers are connected via data network and therefore new flexibility options like demand side management, virtual power plants or electric vehicles can come into force.\r\n\r\nThe Öko-Institut developed within the E-Energy research project eTelligence the energy system model PowerFlex to quantify the environmental and economic effects of the smart grid concept. Based on a reference scenario without new flexibility options, the effects in the German electricity system from 2010 to 2030 are quantified for different smart grid development paths.\r\n\r\nThe PowerFlex model is a mixed-integer linear optimisation model implemented in GAMS to determine the optimal dispatch of power plants and flexibility and storage options. The supply of wind and solar power as well as the demand of electricity and balancing power is preset. About 250 thermal power plants with individual efficiency ratio and ramp rates for three operational status (start-up/shut-down, partial load, full load) are taken into account. The dispatch of plants and flexibility options is calculated day ahead on hourly base. The power of the thermal plants within the first time step of a new optimisation period depends on the power of the last time step of the previous period.\r\n\r\nAs a result the curtailed amount of wind and solar power as well as the total costs and CO2-emissions of electricity generation is determined.\r\n", :title "Integration of renewable energy sources into the electricity system with new storage and flexibility options", :keyword2 29, :authors (29544 29720), :session 125}, 1330 {:keyword1 14, :keyword3 59, :abstract "A large class of state-of-art continuous gradient-free optimization methods use the multivariate normal distribution as a means to iteratively sample the underlying search space. Important examples include Simulated Annealing over continuous domains, the Cross-Entropy method, and variable-metric algorithms such as Covariance Matrix Adaptation schemes. In operations research and control, these heuristics are applied whenever only zeroth-order information about the objective function is available and convexity of the objective function cannot be assumed. Due to the fact that the multivariate normal distribution is defined on the complete Euclidian domain, the natural question arises how optimization methods that use this distribution for search can be applied in the presence of explicit equality or inequality constraints. In this contribution we propose to combine the aforementioned optimization methods with an efficient Gibbs sampler for the truncated normal distribution. This synthesis provides a generic way for constrained continuous gradient-free optimization because the optimizer is guaranteed to only operate on the feasible domain. No problem- or domain-specific constraint-handling techniques (such as penalty or barrier methods) have thus to be developed for the given optimization task. The proposed sampler works for normal distributions with arbitrary mean and covariance structure for any number of linear inequality or convex quadratic constraints. Using the Gibbs sampling methodology, the computational complexity of generating constrained samples is poly(n). As a proof of concept we couple the sampler with gradient-free variable-metric methods and show its efficacy and efficiency on selected test problems from mathematical programming and operations research.", :title "Continuous gradient-free optimization over polyhedral and convex quadratically constrained domains based on Gibbs sampling", :keyword2 133, :authors (29284), :session 195}, 1331 {:keyword1 94, :keyword3 65, :abstract "Quality of service (QoS) and quality of experience (QoE) of contemporary mobile communication networks are crucial, complex and correlated. QoS describes network performance while QoE depicts perceptual quality at the user side. A set of key performance indicators (KPIs) describes in details QoS and QoE. Our research is focused specially on mobile speech and video telephony services that are widely provided by commercial UMTS mobile networks. A key point of cellular network planning and optimization is building voice and video quality prediction models. The scope of our paper is to predict quality of mobile services using regression estimates inspired by the paradigm of robust optimization. Prediction models have been developed using measurements data collected from live-world UMTS multimedia networks via drive-test measurement campaign.", :title "Robust Optimization in Non-Linear Regression for Speech and Video Quality Prediction in Mobile Multimedia Networks", :keyword2 87, :authors (29721 29727 29932 24762), :session 104}, 1332 {:keyword1 124, :keyword3 37, :abstract "Time series in the financial sector may include annual, weekly and daily periodicals as well as non-periodical events. The energy price and consumed volume time series; the time series of consumer sales volume could be the examples. The generalized linear autoregressive models are used to forecast these time series. The samples of the main time-period of the time series correspond to the features of the forecasting models.\r\nTo boost the quality of the forecast, two problems must be solved. First, we must select a set of features, which forms the model of optimal quality. Second, we must split the time series on the periodical and eventual segments and assign a model of optimal quality of each type of segments. To solve these problems, we estimate the distribution of the model parameters using coherent Bayesian inference.\r\nThe optimal model for a given time-segment has the most probable value of maximum evidence, which is estimated under conditions of the stepwise regression: the features are added and deleted from the active feature set towards the evidence maximizing. The splitting procedure includes analysis of the model parameters distributions. Consider two forecasting models that are defined on their non-intersecting consequent time-segments. These models are different if the Kullback-Leibler distance between the distributions of their parameters is statistically significant. In this case the time-segment split is fixed; otherwise we consider the models equal and join the time-segments. The proposed approach brings the most precise time-segment splitting than the dynamic time warping procedure and causes increase of the forecasting quality.\r\nAs an illustration we discuss the automatic detection of seasonal sales and promotions of consumer goods.", :title "Multilevel models in time series forecasting", :keyword2 120, :authors (19525), :session 108}, 1335 {:keyword1 25, :keyword3 0, :abstract "Economic theory lead naturally to nonlinear models that are difficult to empirically test using real-world data.  Since a unique feature of economics is the sophistication of its theoretical models, and since data is more readily available than ever before, this is an awkward situation for the field.\r\n\r\nIn this paper, we propose a method for confronting nonlinear models with the data.  Agents in economic theory solve optimization problems, which lead to first-order conditions that depend functionally on exogenous state variables.  Thus the endogenous variables (which are chosen by the agents) are determined by nonlinear functions which are only available implicitly as the solutions to equations.\r\n\r\nWe show that if you solve the implicit equations by using the Galerkin method that we can treat the model as a linear regression problem with \"structural\" constraints derived from the Galerkin conditions.  We demonstrate the efficacy of this procedure by fitting the Lucas (1978) model of consumption-based asset pricing, and show that we can find reasonable estimates of agent risk aversion.", :title "Fitting Economic Models with Structural Constraints", :keyword2 0, :authors (29724), :session 138}, 1337 {:keyword1 28, :keyword3 0, :abstract "A number of European studies consider the necessary power plant investment to reach the targets of the EU climate control targets.  Often they ignore the fact that power plant investment is made by independent companies. Independent power producers only build new generation facilities if they can cover their longterm costs.\r\nWe consider a multi-step approach to model  the continuous changes of the European power system by investment and dismantling  decisions of independent power producers.  In a first step we solve a mixed-integer program to obtain investment decisions that cover the hourly demand for electricity and ancillary services in coupled European power markets. After that we use an iterative procedure to evaluate the longterm cost recovery of the investment decisions. In case that the investment decisions are not profitable we utilize further mixed-integer optimization programs to modify the preliminary power system development in a systematic way (delay or revision of investment decisions, dismantling of existing power plants).  The result is a power system development where all power plants generate positive cash flows.\r\n", :title "Power plant investment in coupled markets with high share of renewable generation", :keyword2 100, :authors (29726 29728), :session 82}, 1338 {:keyword1 106, :keyword3 0, :abstract "Finding good solutions for dynamic vehicle routing problems often is non-trivial. Models allowing for optimal solutions exist, but typically entail prohibitive computational costs. As an alternative approximate solutions are derived either by means of pure heuristics or by approximate dynamic programming. Approximate dynamic programming approaches rely on approximation of state values as given by Bellman’s optimality equations. Both type and solution quality of an approach is determined significantly by its approximation architecture.\r\nIn this contribution, we present different approximation architectures and compare their performance on different instances of a dynamic vehicle routing problem. The problem originates from a less-than-truckload shipping context. It involves a service vehicle that must be routed in the course of a given time horizon. Customer requests occur randomly over time and must be either accepted or rejected as soon as becoming known. The overall goal consists in serving as many customer requests as possible before returning to the depot at the end of the time horizon.\r\nFor a number of instances of this problem, we identify the most suitable approximation architecture with respect to computational burden and solution quality.\r\n", :title "Approximation Architectures for Dynamic Routing of a Service Vehicle", :keyword2 0, :authors (13264 12952), :session 84}, 1339 {:keyword1 94, :keyword3 0, :abstract "We develop tractable semidefinite programming-based approximations for distributionally robust individual and joint chance constraints, assuming that only the first- and second-order moments as well as the support of the uncertain parameters are given. It is known that robust chance constraints can be conservatively approximated by Worst-Case Conditional Value-at-Risk constraints. We first prove that this approximation is exact for robust individual chance constraints with concave or (not necessarily concave) quadratic constraint functions. By using the theory of moment problems we then obtain a conservative approximation for joint chance constraints. This approximation affords intuitive dual interpretations and is provably tighter than two popular benchmark approximations. The tightness depends on a set of scaling parameters, which can be tuned via a sequential convex optimization algorithm. We show that the approximation becomes in fact exact when the scaling parameters are chosen optimally. We evaluate our joint chance constraint approximation in the context of a dynamic water reservoir control problem.\r\n", :title "Distributionally Robust Joint Chance Constraints with Second-Order Moment Information", :keyword2 0, :authors (3240 23133 20200), :session 117}, 1340 {:keyword1 34, :keyword3 17, :abstract "Considering the active portfolio management framework, the tenet that advocates in favor of the managers' skills in order to outperform the market is still under debate. This study attempts to responds to an incessant intent of achieving conclusions from the manager decision-making and, ultimately, its implications for the portfolio efficiency. We apply non-parametric techniques for measuring mutual fund’s performance and we conveniently extend the methodology in order to isolate the manager's influence on the degree of efficiency reached. Results shed light both on investors and practitioners' concerns because differences among managers do actually arise. This work provides a guide for evaluating managers’ forecasting ability and how they perform covering ex ante investors' expectations.", :title "Does active management add value? New evidence from Spanish mutual funds", :keyword2 93, :authors (26496 25958 25959), :session 266}, 1343 {:keyword1 106, :keyword3 95, :abstract "In Turkey, a major portion of the inner city public transportation is carried out by municipalities. The decisions taken by the municipalities regarding public transporation include strategical (intermodal transportation network design, determining the fleet size), tactical (allocation of vehicles to counties,constructing the routes) and operational decisions (pick-ups and deliveries, maintenance). Since the municipalities have to provide transportation service to every resident, and at a low price, they are often left struggling with negative balance and operational inefficiencies. Due to low price policy, the revenues could only be increased through increased demand fulfilment. This implies operating under low costs and improving the service level is essential for survivability. \r\n\r\nWe conduct a study to analyze the inefficiencies in the public transportation in Ankara. Due to large-scale of the problem, we focus on a single county in Ankara. We first identify the problems that lead to inefficiencies. Analysis of hourly transportation demand and supply reveal that there exist inefficiencies due to fleet allocation, routing and dispatch frequency of the vehicles. This leads to unsatisfied customers, especially in the peak hours. We provide decision support to the decision makers at the tactical level. Considering the daily and hourly transportation needs of the users, we determine routes and dispatch frequencies through a mathematical model. Alternative solutions are developed, and compared under performance measures such as; unmet demand, transport duration, or cost. Finally, the effect of factors such as fleet size, increase in fares and/or fuel prices, developing residential areas, on the robustness of the decisions are analyzed.\r\n", :title "Decision support for inner city public transportation system", :keyword2 73, :authors (15424 634 29736 29743), :session 181}, 1344 {:keyword1 101, :keyword3 126, :abstract "We investigate a supply chain with a single supplier and a single manufacturer. The manufacturer knows the demand for the final product which is produced from a component ordered from the supplier just in time — i.e., the manufacturer holds no component inventory. The costs of the manufacturer consist of quadratic inventory holding costs, quadratic production cost, and linear purchasing cost. It is assumed that the market price of the final product is known as well, hence the sales of the manufacturer are known in advance. The goal of the manufacturer is to maximize her cumulated profits. The costs of the supplier are the quadratic manufacturing and inventory holding costs; his goal is to maximize the revenues minus the relevant costs. In this paper we will not examine the bargaining process that determines the adequate price and quantity. The situation is modeled as a differential game. The decision variables of the supplier are the sales price and the production quantity, while the manufacturer chooses a production plan that minimizes her costs, so maximizing the cumulated profits. The basic problem is a Holt-Modigliani-Muth-Simon (HMMS) problem extended with linear purchasing costs. We will examine two cases: the decentralized Nash-solution and a centralized Pareto-solution to optimize the behavior of the players of the game. Authors: Imre Dobos, Barbara Gobsch, Nadezda Pakhomova, Grigory Pishchulov, Knut Richter.\r\n\r\n", :title "Channel coordination in a HMMS-type supply chain with profit sharing contract", :keyword2 75, :authors (29732), :session 167}, 1345 {:keyword1 75, :keyword3 7, :abstract "Aggregate Production Planning (APP) models cover the mid-term planning level, and de-termine a cost-optimal trade-off between overtime capacity and (seasonal) inventories for the master production schedule. However, APP models have two major drawbacks due to their assumptions. First, APP models can only handle lead times that are multiples of the time bucket length. Second, they apply an implicit capacity discount to accommodate for the capacity loss due to setups and breakdowns at the shop floor level.\r\nIn this paper, we introduce an aggregate stochastic queuing (ASQ) model for each time pe-riod of the APP model to anticipate average lead time offset and capacity loss due to setups and breakdowns. The APP and ASQ model are integrated into a hierarchical framework, and are solved in an iterative approach. The approximate capacity situation at the shop floor level is thus reflected more accurately in the master production schedule. A case-oriented example is used to highlight the benefits of this approach.", :title "Improving Deterministic Aggregate Production Planning with an Integrated Stochastic Queuing Model", :keyword2 99, :authors (23451 29734 1131 29740 27254), :session 166}, 1347 {:keyword1 91, :keyword3 76, :abstract "Markdown policies for product groups having a significant crossprice elasticity among each other should be jointly determined, which makes finding optimal policies for products computationally intractable as the number of products increases. We first formulate the problem as an MDP and use approximate dynamic programming approach to solve it. Since the state space is multidimensional and very large, it is required to perform too many iterations to learn the state values. Therefore, we use function approximation using neural networks to determine the approximately optimal markdown policies and provide insights on the behavior of markdown policy when 1) cross-price elasticity between products are constant, i.e. independent of product price levels 2) cross-price elasticity between products depend on product price levels. We also investigate how the behavior of markdown policies in each case are affected by the time sensitivity of product demand. We also provide insights on which product should be marked down and effect of markdown on percentage gains of each product known as diversion ratio.", :title "Analysis of cross-price effects on markdown policies", :keyword2 99, :authors (20767 24562), :session 101}, 1348 {:keyword1 94, :keyword3 95, :abstract "In public transportation, given a passenger's traveling request, the goal of the timetable information problem is to find a 'good' route from the passenger's origin to his destination.\r\nThis is often done taking the travel time or the number of transfers as an objective. \r\nHowever,  in case of delays, changing connections on such a route may be missed and thus lead to a much longer travel time. \r\nIn this paper we investigate the question how to give timetable information that is robust against delays. \r\n\r\nThe classic notion of strict robustness leads to the problem of identifying those changing connections which will never break subject to the specified set of delay scenarios.\r\nWe show that this is in general a strongly NP-hard problem.\r\nHowever, a subset of these robust changing activities can be determined by dynamic programming in polynomial time. Based on this subset, it is possible to find strictly robust paths for the passengers, that is routes that will always be realizable for all under the assumptions made on the delay scenarios.  \r\n\r\nAs the concept of strict robustness may lead to routes with quite long travel times, we furthermore apply the less conservative concept of light robustness to the timetable information problem, where a certain nominal quality of the solution is required while maximizing its robustness.\r\n\r\nBased on the schedule of high-speed trains within Germany of 2011, we explore the trade-off between the level of guaranteed robustness and the increase in travel time. Strict robustness turns out to be a fairly conservative concept, while light robustness is quite promising: \r\na modest level of guarantees is achievable at a reasonable price for the majority of passengers.", :title "Finding passenger routes that are robust against delays", :keyword2 106, :authors (19182 29733 29735 29738 1601), :session 245}, 1349 {:keyword1 8, :keyword3 133, :abstract "e consider the problem of punching purlins on a multi-stamp machine. The machine produces purlins  with  holes of prespecified diameters at prespecified positions. The length of a purlin together with  the position and the size of its holes determine a purlin type.  A typical order consists of many pieces  of several purlin types. The punching machine  has a punching block with  several pairs of  punching arms, one of them being the reference punching arm (RPA). The punching arms   can be equipped with different punching stamps. The punching arms can slide along the symmetry axes of the punching block while fulfilling certain position constraints. The stamps and the position of the punching arms specify the machine configuration. The configuration has to be fixed prior to processing an order and remains unchanged until the order is finished. The  input material  comes in  rolls of  metal sheet  and  is  rolled out forwards, whereas the punching block can only move up and down. The punching block moves down towards the  punching bed at the moment it should punch some hole(s). The simultaneous punching of holes is called a punching step.  The position of the RPA at a punching step determines the so called punching position.\r\n\r\nThe goal is to determine a machine configuration and a punching plan such that the order is fulfilled and the output of the machine is maximized.  The later is proportional to the spacing  between two consecutive punching positions. There is also a  lower bound on the minimum  spacing which can be reached at all. Given a  machine configuration, the problem of determining an optimal punching plan can be formulated as an IP. We develop a local search heuristic to solve this  problem and report on satisfactory numerical results on real life instances.", :title "Modelling and optimizing the punching of purlins on a multi-stamp machine", :keyword2 48, :authors (28646 29737 23827 149 29741), :session 214}, 1353 {:keyword1 18, :keyword3 86, :abstract "If objective decision making within dynamically changing multi criteria scenarios is needed, merely methods addressing the outstanding visual cognition of man may help. \r\nHow to get faster towards good processes? That’s one of the basic questions in those highly complex situations, and one answer is playBoard, an intuitive tool for developing new and navigating through processes on a virtual board.\r\nDrowning in information, and thirsting for knowledge! This describes a usual situation for a decision maker, confronted with various conflicting monitoring, controlling and optimizing variants, and here knowCube may assist, a user-friendly tool for finding balanced solutions by using graphical means, applicable by non-experts, too.\r\nBoth tools are combined in a web portal, and evaluated in real-life applications.", :title "Online Decision Support for the Management of Multi Criteria Dynamic Processes", :keyword2 52, :authors (2283), :session 252}, 1354 {:keyword1 88, :keyword3 97, :abstract "Queuing problems address a wide gamut of applications which have been extensively tackled and discussed in various disciplines. However, most research on this subject has been mainly aimed at the optimization of performance measures and the equilibrium analysis of a queuing system.  The decision making process of customers of the facility and the impact of their individual choice on queue formation have been rarely studied. We incorporate decision rules based on adaptive behaviour of customers. We deviate from most of the literature in that we model dynamic queuing systems with deterministic and endogenous arrivals. We apply a one-dimensional cellular automata in order to model the research problem. We use this model to explain how customers interact in a multichannel service facility and study their collective behaviour. We describe a self organizing queuing system with local interaction and locally rational customers who based on adaptive expectations of sojourn time decide which facility to use. Customers update their expectations based on their own experience and that of their local neighbours. We also introduce uncertainty into the process of formation of agents’ expectations. Simulations of the model illustrated that risk-neutral customers base their decision on the expected sojourn time, while risk-averse customers estimate an upper bound for the different sojourn times. When customers have an intermediate degree of risk aversion, the system exhibits a longer transient period and, after this transient period, the system converges more slowly to an almost-stable average sojourn time. Systems where customers are either close to risk-neutral or strongly risk-averse perform better than those who have an intermediate level of risk aversion.", :title "Decision Making Analysis in a Queuing System Where Customers Choose a Facility Based on their Experience and Considering Uncertainty", :keyword2 127, :authors (28504 28333 29044 28505), :session 258}, 1355 {:keyword1 93, :keyword3 35, :abstract "We introduce a framework for robustifying convex, version independent risk and deviation measures with respect to ambiguity in the distribution of the\r\nasset returns. The robustified risk measure is defined as the worst case risk, where the worst case is taken over the so called ambiguity set. The ambiguity set is modeled as a Kantorovich ball around a reference measure which represents the investors beliefs about the asset returns. We demonstrate how to solve the resulting infinite dimensional optimization problem and obtain closed form solution for the robustified risk measures. The resulting robustified risk measures are again convex, version independent risk measures which are computationally of the same complexity as their non-robust counterparts. We conclude with several examples and a numerical study.", :title "Robust Convex Measures of Risk", :keyword2 94, :authors (9082 3122 25997), :session 217}, 1357 {:keyword1 101, :keyword3 57, :abstract "In this paper models for the integrated production and distribution planning problem in a two-level industrial supply chain are discussed. Five planning methods are compared. The monolithic method solves a single model describing the entire optimization problem, i.e. simultaneously determines both the production and distribution plans. Four other methods decompose the overall problem into two subproblems: production and distribution planning, and solve them sequentially. The decomposition methods differ on the sequence of subproblems and on the kind of instruction passed from the upper to the bottom planning level. All methods are implemented by means of mixed integer programming models.\r\n\r\nPresented computational tests are based on data sets from component suppliers for the automobile industry cooperating with clients according to the Vendor Managed Inventory (VMI) approach. Presented results confirm that the right choice of the planning method is very important for overall cost of the supply chain and show that appropriate choice of the decomposition method depends on utilization of the production system and on the relationship between production and distribution operational costs.", :title "Vertical Decomposition of Integrated Production and Distribution Planning Models", :keyword2 75, :authors (18856), :session 165}, 1361 {:keyword1 89, :keyword3 99, :abstract "Based on regulatory requirements in electricity markets, power grid operators try to balance costs and quality of supply. The continuity of supply, one main aspect of the quality of supply, is influenced by the restoration time after incidents in the power grid, which in turn depends on the availability of (human) resources performing the restoration work. We present a component-based model for redundant power grids with endogenous restoration times. The assignment of the available resources to the failed components is optimized in a Markov decision process that minimizes the average expected power not supplied over an infinite time horizon. Based on the aggregation of unlikely states, an approximate model is formulated that yields an upper bound on the base model. The effects of a limited availability of resources on the continuity of supply can be quantified by the model. The observed effects, however, are rather marginal and the results mainly confirm the high reliability of redundant power grids.", :title "A Markov decision model for resource-constrained incident management in power grids", :keyword2 76, :authors (17127 23746 17063), :session 103}, 1363 {:keyword1 40, :keyword3 0, :abstract "We consider a two-dimensional model of spatial competition where firms are competing to sell a product to customers in a given market. The market is represented by the unit square and customers are continuously distributed throughout the market according to a density function which is strictly positive. Each firm seeks to maximise its market share by choosing an optimal location in the market. Downsian competition between the firms is modelled as a non-cooperative game with the unit square as the common strategy set. We determine the existence and the value of the Nash equilibrium strategies of the firms as well as necessary and sufficient conditions regarding customer distribution.\r\n", :title "Nash equilibria in a two-dimensional Downsian competition", :keyword2 134, :authors (25341 29747), :session 139}, 1364 {:keyword1 48, :keyword3 77, :abstract "We present a new solution method for the Steel Hot Rolling Problem, which, in the steel production process, is a follow-up problem of the Steel Mill Slab Design Problem (CSPLib Problem 38). The Hot Rolling Problem consists of scheduling a maximum weight subset of steel slabs to be rolled in the hot rolling plant.\r\n\r\nSlabs have to be grouped into programs that obey certain length and slab type quality restrictions. Furthermore, due to the technical process, the sequence of slabs in programs have to fulfill dimension restrictions, i.e., not every slab can succeed every other and the feasibility of a position for a slab depends on the proceeding slabs. If profitable, dummy slabs can be inserted allowing to include more profitable ones which otherwise were not feasible in the current sequence.\r\n\r\nWe model the problem as a large scale weighted bin packing problem, which can be tackled by column generation. In order to do so we used the framework SCIP to realize a Branch and Price approach. We show that pricing variables is equivalent to the resource constrained shortest path problem. A main advantage of this approach is that is very flexible and general. It enables planners to adapt for varying technical requirements in different rolling plants.\r\n\r\nWe present theoretical complexity results and preliminary computational results on simplified instances based on real world data for one specific rolling plant.", :title "Steel hot rolling: A column generation approach", :keyword2 96, :authors (29421 19477 19462 14771), :session 144}, 1365 {:keyword1 106, :keyword3 88, :abstract "Recently, Electric vehicles (EVs) have attracted attention for the future transportation systems of clean-energy society for decades.  However, as defects of EVs, low running distance per charge and long recharging time are pointed out.  To overcome these problems, A venture-backed company ``Better Place'' has proposed a business model of ``battery switch stations'' where batteries of EVs can be replaced. This business model proposes to “replace” the batteries instead of “recharging”.  Obviously, replacing batteries is much faster than recharging them, so EVs can use a battery switch station like a typical refuel station. Better Place has already launched some test markets in several countries.  As described, the infrastructure of “battery switch stations” is enough practical idea to support EVs.  From these point of view, in this study, we focus on the battery switch station as a infrastructure to support EVs, and evaluate how to manage battery stock in stations. Particularly, formulating the battery’s stochastic process in multiple stations using queueing network theory, we discuss the theoretical relationship how the number of safety battery stock depends on the arrival rate of EVs and the charging time of batteries.  As first mathematical model, the loss probability and the safety stock of batteries in each station are calculated.  From the model, we clarified that the number of safety battery stock increases approximately in proportion to the recharging time of battery.  Next, the relationship of multiple stations is considered using queueing network theory.  In the analyses, a central recharging terminal and the several type of battery are also incorporated, and a optimal management of battery recharging for sustainable systems is proposed.", :title "An Optimal Management of Battery Switch Stations for Electric Vehicles Based on Queueing Network Theory", :keyword2 29, :authors (9690), :session 181}, 1367 {:keyword1 75, :keyword3 10, :abstract "A Multi-Feeder Mailroom is a machine for high-speed insertion of advertising inserts into folders. It consists of a single production line on which several insert feeders operate independently.\r\n\r\nThe input to a Mailroom Production Planning problem is given by a set of advertising inserts and by a collection of insert bundles, which are subsets of inserts to be fitted together (e.g. into a folder or a newspaper). Each bundle has a demand (number of copies) and a corresponding production time. In order to produce a bundle all of its inserts have to be loaded on the feeders.\r\n\r\nThere are less feeders than inserts, and different bundles use different  inserts. Therefore, the inserts loaded on the feeders will change during the production.  Loading an insert on a feeder requires a set-up time, during which the feeder cannot be used.  If a loading cannot be performed during the idle time of the corresponding feeder then a machine stop has to be triggered, which delays the production and incurs operational  costs.\r\n\r\nThe Mailroom Production Planning problem consists in deciding the order of  production for the bundles and, for each bundle, the allocation of its inserts to the feeders. The main goal is to minimize the number of machine stops, which is equivalent to minimize the production make-span.  Other (conflicting) objectives that can be considered are the minimization of the number of insert loadings (ideally, one per insert), and the minimization of the number of feeders on which each insert is loaded (ideally, one per insert).  We describe the complexity of the problem under different scenarios, and propose possible solution approaches. Some application-oriented extensions, including production deadlines, load balancing, and inhomogeneous feeders, are also discussed.", :title "Mailroom production planning", :keyword2 96, :authors (29746), :session 144}, 1368 {:keyword1 57, :keyword3 0, :abstract "Let P be a rational polyhedron, and let P_I be the mixed integer hull of P.\r\nWe characterize whenever a valid inequality for P_I, or the disjunctive cuts for P corresponding to a lattice-free polyhedron, can be obtained with a finite number of disjunctive cuts corresponding to an arbitrary family of lattice-free polyhedra containing the splits.\r\nIn the special case where we consider only split cuts, we held a characterization of the lattice-free polyhedra whose corresponding disjunctive cuts have finite split rank.", :title "On the rank of disjunctive cuts", :keyword2 77, :authors (29748), :session 227}, 1370 {:keyword1 12, :keyword3 0, :abstract "Sequence alignment has paved the way for many important applications in bioinformatics. Unlike sequence data, which can be represented as a string over some finite alphabet, interactions are captured in a network. In order to elucidate functionally significant interactions, it is imperative to have a way to identify similarity among networks.\r\n\r\nIn this work, we consider the problem of pairwise global network alignment: given two graphs and a scoring function that reflects similarities among the nodes and edges in the graphs, we are asked to identify a maximally-scoring alignment from nodes in the one network to nodes in the other. We show that this problem is NP-hard. From the reduction also an inapproximability result follows: no constant-factor approximation exists unless P=NP. \r\n\r\nRemarkably, the problem is intimately related to the quadratic assignment problem (QAP). Inspired by previous work on the QAP, we present two integer linear program formulations. By exploiting a property of the scoring function, we are able to show that in our setting the LP relaxations of the two formulations achieve the same bound. We approximate the bounds using Lagrangian relaxation. In addition to the default subgradient optimization method for computing the Lagrangian dual, we devise and employ for each of the two formulations a dual descent scheme. A nice property of these schemes is that they result in monotonically decreasing bounds. We combine the dual descent schemes with subgradient optimization to efficiently compute upper bounds on problem instances involving protein interaction networks of five distinct species: rat, mouse, human, fruit fly and nematode. A simple heuristic is employed to compute actual feasible solutions, which for most instances leads to a very small gap.", :title "Lagrangian relaxation applied to global network alignment", :keyword2 8, :authors (28738 11835), :session 65}, 1371 {:keyword1 92, :keyword3 31, :abstract "In the paper an extended joint economic lot size problem is studied which incorporates the return flow of repairable (remanufacturable) used products. The supply chain under consideration consists of a single supplier and a single buyer. The buyer orders a single product from the buyer, uses it for her own needs, and collects the remanufacturable items after use. The ordered items are shipped from the supplier to the buyer in the lot-for-lot fashion by a transport vehicle which also returns the collected used items from the buyer to the supplier for remanufacturing and subsequent service of the buyer’s demand in the next order cycle. To satisfy the total demand, the supplier manufactures new items or remanufactures used ones received from the buyer. For the given demand, productivity, collection rate, disposal cost, setup cost, order cost, holding cost for serviceable and nonserviceable products at the supplier as well as the buyer, the lot size (order size) of the supplier (buyer) has to be determined which minimizes the total cost.\r\n\r\nThe ecological problem of the model is how to construct an incentive scheme (quantity discount contract) which motivates the participants of the supply chain to save natural resources with reuse of items from the consumption process. The reuse of used items can contribute to the sustainable production with lower energy consumption and save resources.", :title "Remanufacturing of used products in a closed-loop supply chain with quantity discount", :keyword2 101, :authors (20832 29732 29752 44490 14722), :session 168}, 1374 {:keyword1 96, :keyword3 2, :abstract "We present a model where we integrate  schedule design, fleet assignment and demand models to maximize the profit of an airline. The objective of the study is to identify the challenges behind the integration of demand modeling into the optimization model and develop methodologies to overcome these challenges.\r\n\r\nThe study is in the context of a collaborative work  between EPFL and EPFL Middle East. A new air transportation concept, Clip-Air, is  developed at EPFL which is a modular innovative aircraft with detachable load units that increase the flexibility. The decoupling of the load (capsules) and carrying units (wings) is believed to improve the airline operations. Clip-Air, being a flexible transportation concept, brings more interest into the integration of supply and demand models. Therefore models are adapted to the Clip-Air case and comparative analysis is done between standard aircrafts and Clip-Air to quantify the potential advantages.\r\n\r\nConsidered supply model is an integrated schedule design and fleet assignment model. Integrated demand model is specified as a logit model where utility of the itineraries are explained by fare, departure time and number of stops which are shown to have explanatory power in the literature. Fare class segmentation is considered in the optimization model as different fare classes have different sensitivities suggested by the demand model. Furthermore we include supply and recapture effects in order to better represent the demand where recapture ratios are based on a logit model similar to the demand model.\r\n\r\nThe resulting model is a mixed integer nonlinear problem and as a first step to deal with the high complexity of the problem, we present a heuristic method based on Lagrangian relaxation and sub-gradient optimization. ", :title "Integrated schedule planning with supply-demand interactions for a new generation of aircrafts", :keyword2 106, :authors (26849 19625 26236), :session 141}, 1376 {:keyword1 96, :keyword3 59, :abstract "Most of the literature on scheduling does not take into account maintenance tasks when optimizing production scheduling. In recent years, decision makers give a great importance to the maintenance function, given its substantial contribution to business productivity. In this paper, we propose an integrated bi objective model to deal with the joint production scheduling and maintenance planning problem. The performance criteria considered for production and maintenance are, respectively, the total tardiness and the unavailability of the production system. The non dominated solution sets of the integrated model are based on a Hybrid Particle Swarm Optimization (HPSO) algorithm. The proposed algorithm is compared, according to several metrics, with a well-known evolutionary multi-objective algorithm, namely SPEA 2 and it shows interesting results.", :title "Hybrid particle swarm optimization to simultaneously minimize total tardiness and unavailability system in parallel machine scheduling", :keyword2 89, :authors (29751 16003), :session 163}, 1377 {:keyword1 136, :keyword3 80, :abstract "An elementary mathematical optimisation problem arising in the\r\noperative planning of water supply networks is the minimisation of\r\noperational costs over a short-term planning horizon in order to\r\nsatisfy reliable customer demands.\r\nWe present a detailed mixed-integer nonlinear programming model\r\ninvolving nonconvex side constraints and objective function.\r\n\r\nWhereas, due to the difficulty of solving these problems directly,\r\nmost approaches in the literature focus on approximations or\r\nrelaxations, we discuss general-purpose as well as problem-specific\r\nalgorithmic techniques aiming at solving these complex mathematical\r\nprograms to global optimality.\r\n\r\nOur algorithmic approach is based on safe linear outer approximation\r\nof the nonlinearities to obtain valid dual bounds.  Branching on both\r\ninteger and continuous variables and domain propagation help to\r\ncontinuously tighten the outer approximation.  We demonstrate the\r\ngreat impact of aggressive bound tightening techniques (feasibility-\r\nand optimality-based) on the running time.  We describe an intuitive rolling horizon heuristic which creates fully\r\nfeasible solutions employing a global MINLP solver for solving the\r\nresulting subproblems.\r\n\r\nOur computational experiments on real-world instances provided by our\r\nindustry partner are based on extensions of the constraint integer\r\nprogramming framework SCIP.\r\n\r\n", :title "Operative Planning of Water Supply Networks by Nonconvex MINLP", :keyword2 77, :authors (19147 29756 29755 9536), :session 213}, 1378 {:keyword1 35, :keyword3 0, :abstract "The aim of this paper is to present a general pricing formula for defaultable claims. The formula is obtained as an extension of the one proposed in the paper by Coculescu and Nikeghbali (2011, to appear in Mathematical Finance). Using the technique of the progressive enlargement of a filtration originally introduced by Elliott, Jeanblanc and Yor (2000), it is possible to find expressions of the price of a defaultable claim in a subfiltration, that represents the information flow of the non-defaultable claims in the market. In this filtration, the default time is modeled as a random time that is not a stopping time. In this setting, the Az\\'ema supermartingale associated with the default time is the main object to study. Some simplifying assumption are usually made in the literature in order to compute the prices, typically the Az/'ema supermartingale  is continuous decreasing.  In Coculescu and Nikeghbali (2011) the last property  has been relaxed, leading to a simple formula that holds under a suitable change of measure. The aim in the present paper is to go a step further and give the formula for the most general case, where no assumption an the Az/'ema supermartingale is needed.", :title "A general formula for pricing defaultable claime", :keyword2 0, :authors (29754), :session 216}, 1379 {:keyword1 120, :keyword3 104, :abstract "Understanding and forecasting technology evolution become more critical for successful technology management. To effectively forecast the direction of technology evolution, it is necessary to examine the changes of technology over time. However, many of previous studies lack this perspective. In this paper, we suggest a new forecasting approach based on both patent citation network analysis and association rule utilizing time segmented patent data. The proposed approach is then applied to telecommunication area, where its technology has been continuously interacted and evolved. From the results obtained using patent data from USPTO, we found the important technology with high centrality over multiple periods. In addition, associated technologies with this important technology were identified. Empirically observed patterns explain that the telecommunication technology has been evolving toward the pictorial communication, secured & jamming communication, multiplex communication, controlling signal & computer related technology, and its transferring system technology from digital data recognition & processing technology, multiplex & switch related technology. Most recent period shows an interesting trend that the telecommunication technology is now heading back to the advanced transferring system technology, which is not the application domain, but the infrastructure domain. It is expected that these findings can help to prepare for the R&D policies for telecommunication industry.", :title "Patent network analysis and association rules applied to forecast the evolution in telecommunication technology ", :keyword2 37, :authors (29758 1888), :session 109}, 1380 {:keyword1 16, :keyword3 59, :abstract "The cutting and packing problems are considered classics problems in the operations research, due to its big spectrum of application in the industry and its highly mathematical and computational complexity for the academy. In this study we present the k-staged two-dimensional guillotineable single knapsack problem of rectangular items, with and without associated weights to the items, with and without items rotations of 90° and with guillotine cuts. We develop an appropriate encoding of the problem to work on it by a metaheuristic hybrid algorithm of variable neighborhood search and simulated annealing. To check the efficiency of the presented methodology, case of studies were taken from specialized literature, where it could be analyzed and compared the presented solution method with the state-of-the-art of the problems, we obtained results of excellent quality and never reported in the literature.", :title "k-staged two-dimensional guillotineable single knapsack problem", :keyword2 8, :authors (29772 29757), :session 177}, 1381 {:keyword1 61, :keyword3 57, :abstract "MPL has been distributed with a standard GUI interface for development and the object-oriented OptiMax Component library for deployment for many years now. With the advent of scripting language frameworks such as Python, that are becoming increasingly popular, there are now new opportunities for integrating optimization into real-world applications. With \"MPL for Python\" and \"MPL for .Net\" we are introducing a new scripting and component library interfaces for MPL, that takes full advantage of the many powerful features of Python, CSharp, and VB.Net.", :title "MPL for Python and MPL for .Net - Introducing New Scripting and Library Interfaces for the MPL Modeling Language", :keyword2 98, :authors (3843), :session 90}, 1382 {:keyword1 61, :keyword3 98, :abstract "TBD", :title "Optimization Modeling in Practice", :keyword2 57, :authors (11248 3843), :session 90}, 1384 {:keyword1 88, :keyword3 134, :abstract "When a service firm faces more than one type of customers, e.g., high-end consumers and lower-end consumers, how does the firm make effective decisions to maximize its revenue? If the firm has the flexibility to offer the customers with multiple attributes for its service, e.g., price and quality, then information economics methods such as adverse selection can often be used to design a menu of contracts; and the contracts make the customers reveal their private information and segment the different types of customers to maximize its objective function.  It may happen, however, that in some applications the firm can make decision only on one attribute, such as sales price, and neither can it offer different pricing for different customers. How does the service firm make decision using information on customer types in that case? In this article, we consider a service system that faces two classes of demands, and the firm determines its optimal selling price to maximize its expected revenue. Since each class of customers reacts to firm's pricing decision in making joining decisions, the resulting problem is a Stackelberg game. We model the problem by a queuing system with Poisson arrival processes of customers and arbitrary service time distributions. We show that the optimal pricing decision can vary a lot, and it depends on the range of system parameters. We find the optimal price for each and every range of the system parameters, and compare the optimal prices in the different parameter regions.\r\n\r\nSpecifically, we address this problem by considering a queueing system with two classes of customers that have different service values and different sensitivities to delays. We find that, depending on the customer characteristics, we may be in any one of the following cases: dominating high class customers, dominating low class customers, and non-dominating customers. In the dominating high class customers case, the high class customers always have more incentive to enter the service system regardless of the price of the service; in the dominating low class customers case, the low class customers always have more incentive to enter the service system regardless of the price of the service; and in the third case, either one may be more willing to enter the service system depending on the charging price. For each case, we first find the customer equilibrium, and then use the customer equilibrium to compute the optimal price for the firm. Therefore, the optimization problem we consider is a Stackelberg game. Furthermore, in contrast to the research literature on revenue-maximizing pricing and social optimal pricing, in this paper we are mainly concerned with the effect of market structure on the revenue-maximizing pricing. Optimal solution is obtained for this problem that yield insights on optimal pricing strategies of a firm when it faces multiple classes of customers. \r\n\r\nThis is a joint work with Whenhui Zhou. \r\n", :title "Optimal pricing decision of a service firm when facing two classes of customers", :keyword2 99, :authors (22715), :session 115}, 1387 {:keyword1 8, :keyword3 57, :abstract "We investigate the use of Gomory cuts to improve the bounds of a column generation formulation for the Capacitated Arc Routing problem (CARP). This formulation has non-elementary routes as columns. We show how to modify the pricing subproblem to cope with the addition of cuts in the master problem. In particular, we show that this can be done efficiently by a suitable modification of the dynamic programming algorithm, opposing to when this is done when columns are elementary routes. We compare the bounds obtained with the one based on elementary routes. The experiment shows that this less agressive approach allows going further.", :title "Improving Lower Bounds for the CARP with Gomory Cuts", :keyword2 76, :authors (24413 29760 29761), :session 182}, 1392 {:keyword1 7, :keyword3 76, :abstract "This paper deals with the simultaneous acquisition of capacity and material in a situation with uncertain demand, with non-zero lead-times for the supply of both material and capacity. Although there is a lot of literature on the time-phased acquisition of capacity and material, most of this literature focuses on one of the two decisions. By using a dynamic programming formulation, we describe the optimal balance between using safety stocks and contingent workforce for various lead-time situations. We compare the cost ingredients of the optimal strategy with the standard inventory approach that neglects capacity restrictions in the decision. The experimental study shows that co-ordination of both decisions in the optimal strategy leads to cost reductions of around 10 percents. We also derive characteristics of the optimal strategy that we expect to provide a thorough basis for operational decision making.", :title "Integrated capacity and inventory decisions in a simple production system", :keyword2 75, :authors (19523 19530), :session 171}, 1397 {:keyword1 77, :keyword3 8, :abstract "Fueling logistics play a meaningful role in the railroad industry, since trains are mostly powered by diesel locomotives worldwide. The goal of the Locomotive Refueling Problem (LRP), First presented in the 2010 INFORMS Railway Application Section (RAS) Competition, is to define the locations where a locomotive should refuel along its pre-defined route. The goal of our talk is to demonstrate how the Constraint Integer Programming framework SCIP solver can be used to efficiently model and solve the LRP instance of the competition. Finally, we discuss how to enhance the standard solution approach by adding primal heuristics for the LRP. ", :title "A Constraint Integer Programming Approach for the Locomotive Refueling Problem", :keyword2 106, :authors (23876 29399 14771), :session 270}, 1402 {:keyword1 127, :keyword3 39, :abstract "Due to the increase in access of malicious data over the internet resources, intrusions Detection Systems (IDSs) have become the necessary component of the computer and information security framework. Although the field of IDSs is still developing, they are not able to detect all types of intrusions.\r\nNew intelligent Intrusion Detection Systems (IDSs) which are based on sophisticated algo-rithms rather than current signature-base detections are in demand. This work discuss about the ways of implementing a swarm intelligence approach to data clustering to detect intrusions. Mo-bile agent technology is used to initially collecting data properties. These data are evaluated by the combining of the artificial Immune recognition system and the artificial fuzzy ants clustering sys-tems. Our approach allows us to recognize not only known attacks but also to detect suspicious ac-tivity that may be the result on knowledge Discovery and Data Mining (KDDCup 1999) dataset compared to a standard learning schema that use the full dataset.", :title " Intrusion detection based on swarm intelligence using mobile agent ", :keyword2 12, :authors (22533 22515 9736), :session 238}, 1406 {:keyword1 95, :keyword3 63, :abstract "Airborne systems – including manned and unmanned vehicles -  are a significant component in sea surveillance. Currently, each vehicle in use is controlled manually by several operators in a high uncertain and fast changing environment. Quick responses are needed when new suspect boats appear, surveillance time must be extended, or weather conditions change. It is the aim of the project to introduce autonomy and reliability into the management system by developing a decision support system for operators.\r\n\r\nThe presentation will focus on the modelling of a routing problem that is subject to a substantial set of operational parameters including weather conditions, safety aspects, and unknown service times. Two routing aspects will be presented: (i) the routing of a set of unmanned aerial vehicles over a number of suspect target points and (ii) the persistent coverage of a geographical area. The presentation will show how to model the specifics of aerial vehicles routing problems and which solving algorithms are of potential interest for the two different routing aspects (i) and (ii) for a scenario in the Mediterranean sea.\r\n", :title "Toward a decision support system for aerial vehicles routing problems", :keyword2 18, :authors (25559 15482 36610), :session 255}, 1408 {:keyword1 106, :keyword3 121, :abstract "The share of crew-related costs is substantial in railways and the fixed crew salaries constitute a significant portion of crew-related costs. Therefore, the number of crew members under long-term contracts is an important decision. Tactical planning is concerned with determining the required crew capacity of a crew region to operate the train schedule under the responsibility of the region. The crew capacity planning problem determines the minimum number of crew members required to cover all duties in a region while each crew member is to be associated with a feasible schedule of duties. This problem can be formulated as a pure set covering problem where a feasible crew schedule corresponds to a column in the formulation. In this study, we consider finding the minimum number of crew members associated with a set of feasible crew schedules that can be connected to other schedules from one period to the other. To formulate this version of the problem, the set covering problem is enriched with additional constraints that represent the connectivity relationship among the schedules. Existence of such constraints (i.e. rows of the formulation) depends on the existence of columns in the formulation. In this respect, a traditional column generation algorithm would not suffice to solve this problem. In order to solve this problem, we develop a column-and-row generation algorithm that simultaneously generates feasible crew schedules and associated connectivity constraints. The pricing subproblem of the column-and-row generation algorithm is formulated as a shortest path problem over a space-time network that represents the crew capacity planning problem. We present the computational study on a real-life data set acquired from Turkish State Railways.", :title "A Column-and-Row Generation Algorithm for a Crew Planning Problem in Railways", :keyword2 7, :authors (25014 14274), :session 219}, 1409 {:keyword1 94, :keyword3 0, :abstract "Markov decision processes (MDPs) are powerful tools for decision making in uncertain dynamic environments. However, the solutions of MDPs are of limited practical use due to their sensitivity to distributional model parameters, which are typically unknown and have to be estimated by the decision maker. To counter the detrimental effects of estimation errors, we consider robust MDPs that offer probabilistic guarantees in view of the unknown parameters. To this end, we assume that an observation history of the MDP is available. Based on this history, we derive a confidence region that contains the unknown parameters with a pre-specified probability 1?beta. Afterwards, we determine a policy that attains the highest worst-case performance over this confidence region. By construction, this policy achieves or exceeds its worst-case performance with a confidence of at least 1?beta. Our method involves the solution of tractable conic programs of moderate size.", :title "Robust Markov Decision Processes", :keyword2 0, :authors (46693), :session 115}, 1411 {:keyword1 73, :keyword3 44, :abstract "In November 2010 an election for a special Constitutional Assembly was held in Iceland when 25 persons were elected. The purpose of the Constitutional Assembly is to review the Constitution of the Republic of Iceland. The assembly was supposed to meet on 15 February 2011 and work for 2-4 months.\r\n\r\nThree people challenged the legality of the elections and on 25th January 2011 the Supreme Court ruled that the elections were illegal and not valid. On 24th March 2011 the Icelandic Althingi approved a parliamentary resolution stating that an advisory Constitutional Council should be appointed by Althingi to review the constitution and the members of council should be the same that were elected in the elections of the Constitutional Assembly.\r\n\r\nThe first meeting of the Constitutional was 6th April 2011. They shall deliver the Council’s propositions to Althingi by the end of June but may ask for an extension of one month.\r\n\r\nThe paper will focus on the decision making of the Constitutional Council, both decisions about the content of the constitution and decisions about the process. Decisions about the content will mainly be discussed in relations to Problem Structuring Methods and Multi Criteria Decision Making. The group of 25 people started to discuss decisions about the process soon after the election in November 2010, and many decisions are made informally before they are formally made. Furthermore, the wish of the council to give the “nation” possibility to influence the decisions about the content of a new constitution will be discussed.\r\n\r\nThe research is based on official information, including information in the media, and on discussions with many individuals, among them some of the members of the Constitutional Assembly.", :title "The Constitutional Council in Iceland", :keyword2 115, :authors (2983), :session 252}, 1413 {:keyword1 12, :keyword3 0, :abstract "We will give a short overview of the rapid progress in DNA sequencing over the last 3 or 4 years. Within a week, a single sequencing machine in a small lab can now generate more sequence data than the Human Genome Project produced in 13 years. The sheer volume and particular properties of next-generation sequence data have created a whole new set of theoretical and computational challenges for computer scientists, not only changing the requirements for long-standing tasks such as alignment and assembly but also yielding a need for novel algorithms employing advanced methods from stringology or graph theory to support new applications that have now become feasible. \r\nWe will highlight some of these challenges and present specific problem settings.", :title "Computational challenges in next-generation sequencing", :keyword2 0, :authors (29023), :session 67}, 1414 {:keyword1 14, :keyword3 0, :abstract "In this paper, we develop a lifecycle framework in which a dynastic\r\ndecision-maker chooses optimal paths for consumption/savings, mortality\r\nand fertility within a closed economy with production and an\r\nage-structured population. Individuals period utility depends on\r\nconsumption and fertility. Mortality can be reduced by the purchase of\r\nhealth care. By using age-structured optimal control theory we derive and interpret the optimality conditions for the three life-cycle choices and characterise analytically and numerically the optimal life-cycle trajectories. We also develop the value of life and the value of progeny for a production economy and show how they interact in determining demographic, i.e. fertility- and mortality-related, choices. We characterise the allocation under stable population growth and provide an impossibility result regarding interior rates of optimal population growth.\r\n", :title "On optimal fertility and mortality in economies with age-structured population", :keyword2 0, :authors (19666 19669), :session 198}, 1415 {:keyword1 61, :keyword3 0, :abstract "This presentation describes planned and ongoing projects to extend and enhance the AMPL modeling language and system, with the aim of helping modelers to get optimization projects running sooner and more successfully.  Following an introductory survey using a scheduling optimization example, projects are organized according to the primary aspects of AMPL that they will affect.  Extensions to AMPL's core language will be designed to allow for more natural description of discrete models, through the introduction of logical and other non-arithmetic operators.  New solver interfaces will automate sophisticated conversions from human analysts' formulations to the problem types that solvers recognize, providing enhanced access to nontraditional solvers in areas such as conic programming, global optimization, and hybrid constraint-integer programming.  New interfaces to the AMPL system will facilitate \"optimization as a service\" and encourage business deployment.", :title "New and Forthcoming Developments in the AMPL Modeling Language and System", :keyword2 0, :authors (3753), :session 90}, 1416 {:keyword1 28, :keyword3 96, :abstract "Plug-in hybrid electric vehicles and fully electric vehicles can potentially lower the fossil fuel dependency of the personal transportation sector. Plug-in vehicles are typically connected to the local low-voltage electricity grid to recharge their internal battery. If these vehicles are used for commuting, the driving can be more or less synchronized in time and the charging power can be relatively high compared to other household loads. Thus, if the charging is not managed, a large adoption of plug-in vehicles is likely to have a negative impact on the distribution grid. Because commuter vehicles are parked most of the time during the day the time of charging is flexible. This flexibility can be managed and utilized to, for example, offer balancing power capacity and to minimize the impact on the grid.\r\n\r\nWe focus on the a centralized approach of directly controlling the plug-in vehicle charging behavior. A charging service provider computes charging schedules for each vehicle to ensure sufficiently charged energy. This service provider is separate from other power system players such as the electricity retailer and the distribution system operator. A framework of including the charging service provider, the retailer, and the distribution system operator in the charging management is proposed. The retailer is responsible for the electricity market level interactions and the distribution system operator is involved to solve local grid congestion. The goal is to avoid unnecessary end user involvement and to automate the charging management as much as possible. The proposed methods are tested and evaluated in a simulated environment based on the power grid on the Danish island of Bornholm.", :title "Optimization of electric vehicle charging schedules avoiding local distribution grid congestion", :keyword2 97, :authors (29782 29783), :session 103}, 1418 {:keyword1 97, :keyword3 0, :abstract "This paper analyzes the effectiveness of knowledge transfer between\r\nresearch and development (R&D) and intra-firm production units.\r\nSpecifically, it analyzes the advantages and disadvantages of a special\r\ntype of production network, the lead factory concept. The lead factory\r\nacts as an intermediary and serves as the central knowledge hub of the\r\nnetwork, i.e., it transfers knowledge between R&D and the production\r\nplants. So far, researchers merely focused on the description of different\r\nplant roles and the differences to each other, but the literature has\r\nneglected to explain the reasons why such a special plant should be\r\ncreated. It is unclear if the lead factory concept positively influences\r\nthe company¹s aim of achieving a competitive advantage. Moreover, it\r\nremains to be analyzed if and under what contingencies the lead factory\r\nconcept produces concrete advantages over a network without a lead\r\nfactory. Our paper tries to fill this gap in the literature by analyzing\r\nthe impact of the lead factory concept. Based on a NK simulation model, we\r\nhighlight relevant factors that determine the relative advantages and\r\ndisadvantages of the lead factory concept in comparison to a traditional\r\nproduction network. The traditional network mirrors those networks not\r\nhaving implemented special strategic plant roles. Second, we derive the\r\nfactors that influence the overall efficiency of a production network.\r\nThird, we extend the literature on NK models by implementing search costs\r\ninto the simulation model. Fourth, we are the first to apply the NK\r\nframework to explicitly model the production process of a firm.", :title "Knowledge Transfer within Production Networks: An NK-Model Approach", :keyword2 75, :authors (29785 29786 29787 29788), :session 104}, 1420 {:keyword1 59, :keyword3 0, :abstract "In this work we design a multi-objective evolutionary algorithm to optimize electric/electronic (E/E-) architectures, which is a challenging problem in the automotive industry. In such an E/E-architecture, a number of functions such as ABS and ESP are given. Each function consists of a number of components (sensors, actors, and software) and signals transmitted between these components. To create an E/E-architecture, these components have to be clustered into an arbitrary number of assembly units. Each assembly unit must be assigned to a mounting space and equipped with a suitable intelligent semiconductor and power supply. Additionally, assembly units need to be assigned to buses, and have to be wired accordingly. The considered objectives are cost, function complexity, and function linkage.\r\n\r\nAs the search space of possible E/E-architectures is huge, the evolutionary algorithm must be designed carefully. The number of design variables should be reduced as much as possible, while still keeping all interesting solutions reachable. We present a representation for E/E-architectures, including suitable variation operators that have a direct, controllable effect on the E/E-architectures. Furthermore, we present heuristics for single-objective subproblems e.g. the bus topology design. The core of the representation is a tree which codes the hierarchical clustering of components to assembly units and assembly units to buses. This tree representation is a general framework to tackle hierarchical clustering problems and can be extended to an arbitrary number of hierarchy levels. Beside the optimization of E/E-architectures itself, this work, especially the hierarchical clustering, may be helpful to support the design of evolutionary algorithms for similar problems.", :title "Evolutionary Exploration of E/E-Architectures in Automotive Design", :keyword2 0, :authors (29474 29924 29965), :session 160}, 1422 {:keyword1 35, :keyword3 0, :abstract "This is a joint work with Ying Hu and Adrien Richou -- Univ Rennes.\r\nWe prove that a BSDE with subquadratic driver and with terminal value that is exponentially integrable has a unique solution of class D.  A similar result was proved by the same authors for terminal values that were slightly better behaved. \r\n\r\n", :title "A uniqueness result for solutions of BSDE with quadratic driver and unbounded terminal value", :keyword2 0, :authors (29834), :session 215}, 1423 {:keyword1 35, :keyword3 0, :abstract "We show a new approach to solving the Zakai equation of\r\nfiltering when an affine process is observed. We are led to a scheme\r\nconverging towards the conditional distribution with deterministic\r\nerror bounds.\r\n", :title "Filtering of affine processes", :keyword2 0, :authors (29835), :session 218}, 1424 {:keyword1 99, :keyword3 0, :abstract "Modern probability theory, whose foundation is based on the axioms set forth by Kolmogorov, is  currently the major tool for performance analysis  in stochastic systems. While it offers insights in understanding such systems, probability theory is really not a  computationally tractable theory. Correspondingly, some of its major areas of application remain unsolved when the underlying systems become multidimensional: Queueing networks, network information theory, pricing multi-dimensional financial contracts, auction design in multi-item, multi-bidder auctions among others.\r\n\r\nWe propose a new approach to analyze stochastic systems based on robust optimization. The key idea is to replace the Kolmogorov axioms as primitives of probability theory, with some   of the asymptotic  implications of probability theory: the central limit theorem and law of large numbers and to define appropriate robust optimization problems to perform performance analysis. In this way, the performance analysis questions become highly structured optimization problems (linear, conic, mixed integer) for which there exist efficient, practical algorithms that are capable of solving truly large scale systems.\r\n\r\nWe demonstrate that  the proposed approach achieves a computationally tractable methods for  (a) analyzing multiclass queueing networks, (b)  characterizing the capacity region of network information theory and associated coding and decoding methods generalizing the work of Shannon, (c) pricing multi-dimensional  financial contracts generalizing the work of Black, Scholes and Merton, (d)  designing multi-item, multi-bidder auctions generalizing the work of Myerson.\r\n\r\nThis is joint work with my doctoral student  at MIT Chaitanya Bandi.", :title "A computationally tractable theory of performance analysis in stochastic systems", :keyword2 0, :authors (3025), :session 123}, 1425 {:keyword1 76, :keyword3 0, :abstract "Life is a very large dynamic programming problem. The standard approach to analyzing real problems is to formulate highly stylized and unreliable simplifications, and use analytical tools or primitive numerical methods.\r\n\r\nThis is no longer necessary with the computational tools that are now available. We are developing DPSOL, a flexible and robust set of computational tools for discrete-time dynamic programming based on modern computational methods. We use multivariate approximation methods to represent value functions. Standard approximation methods, such as least squares curve fitting, often lead to numerically unstable iterations. We stabilize value function iteration by using shape-preserving approximation methods. We also use Hermite interpolation to improve the quality of the approximation with only minor extra cost. We use efficient multivariate quadrature methods to compute expectations, and modern optimization methods to solve the Bellman equations. We combine these ideas to develop a nonlinear programming approach to dynamic programming. We have developed parallel versions to exploit distributed computing systems.\r\n\r\nThis is illustrated with applications such as (a) portfolio choice with six stocks, one bond, and transaction costs, (b) life-cycle decisions over consumption, investment, labor supply, and education choices, (c) a dynamic stochastic generalization of DICE, a well-known model used in climate change studies.\r\n\r\nMore generally, we lay out a conceptual framework for thinking about numerical solutions of dynamic programming problems and incorporating past and future advances in algorithms and hardware.\r\n\r\nThis is joint work with Yongyang Cai, a postdoctoral student at the Hoover Institution.", :title "Numerically Efficient and Stable Algorithms for Solving Large Dynamic Programming Problems in Economics, Finance, and Climate Change Models", :keyword2 0, :authors (), :session 152}, 1426 {:keyword1 19, :keyword3 0, :abstract "For the last  decade, there has been increasing recognition of the importance of advanced analytics and optimization methods  to public and private organizations.  This is being driven by increased global competition as well as an accelerated pace of business.   It coincides with the emergence of new hardware and software paradigms as well as the capability to integrate advanced analytic methods in our planning and operational activities.\r\n\r\nHere are some of the main issues:\r\n\r\n1. How do we deal with unprecedented amounts of data in our decision making?\r\n2. How can we effectively incorporate  risk measurement and management in our decision making?\r\n3. How do we enable the transition from strategic planning systems to real-time operational systems?\r\n4. What optimization and analytics opportunities are being created by the rapid growth of social networks?\r\n\r\nFrom 2005 to 2009, as part of IBM’s Global Business Services, I led an organization with the mission of developing and delivering these capabilities to clients in all sectors. This has subsequently become a major part of IBM’s consulting business.  Since 2010 I have been a member of the faculty at The United States Military Academy, West Point and have discovered that top-of-mind issues in the military are very similar.\r\n\r\nI will discuss challenges and issues encountered, as well as examples of successful projects dealing with these topics.  These include steel mill scheduling, optimizing call center profitability and dealing with uncertainty related to government policy decisions.   I will also discuss obstacles that remain to be overcome.", :title "Optimizing Twenty-First Century Decision Making", :keyword2 0, :authors (), :session 153}, 1427 {:keyword1 127, :keyword3 0, :abstract "Many cyber-technical visions convincingly suggest that network-centric technology will provide unprecedented levels of capability and efficiency to support the operation and management of modern society’s most vital functions—ranging from delivery of economic goods and services, business processes, global financial markets, education, health care, military operations and national defense, and other government services.  A fundamental challenge is to understand and manage the growing complexity of these systems.\r\nIn this talk, I will revisit the notion of “organized complexity” and suggest that it is fundamental to what we define as essential in these network systems.  I argue that complexity arises in highly evolved technological (and biological) systems primarily to provide mechanisms to create robustness.  This view of complexity in highly organized systems is fundamentally different from the dominant perspective in the field of network science, which downplays function, constraints, and tradeoffs, and tends to minimize the role of design.", :title "Robustness, Design, and Complexity and their Implications for Network-Centric Infrastructures", :keyword2 0, :authors (23582), :session 234}, 1428 {:keyword1 127, :keyword3 0, :abstract "This talk addresses a key, controversial issue in the health OR literature, namely the apparent failure of OR modelling in general and simulation in particular to become embedded and widely implemented as practical management tools within healthcare organizations. There is a massive academic literature in this field, but the vast majority of published papers are either purely theoretical or report individual one-off success stories. The evidence suggests that simulation has failed to become part of the regular “management toolkit” in the healthcare sector, in contrast with its success in manufacturing and service industries, and the military and defence sectors. The reasons for this remain unclear. The research presented here is a case study to evaluate the adoption (or otherwise) of one particular simulation modelling tool, Scenario Generator, which was developed by the SIMUL8 Corporation in a collaborative partnership with the UK’s National Health Service Institute for Innovation and Improvement.  The software was offered free of charge for one year to any UK healthcare organisation that wished to try it.  The deal also included two full days of face-to-face hands-on training plus unlimited telephone support. Our study involved semi-structured interviews with employees of 28 organisations who had all been engaged in some way with the initiative.  In addition to interviewing active users, we also talked to people who had tried the software but had given up, and people who had decided not to use it. The latter two groups provided some particularly useful insights. In this talk we present a brief summary of barriers and facilitators to the successful use of the Scenario Generator software itself, but the main aim is to focus more broadly on...", :title "Overcoming the barriers: Getting simulation used in healthcare", :keyword2 0, :authors (9100), :session 158}, 1429 {:keyword1 127, :keyword3 0, :abstract "Understanding cause-effect relationships between variables is of great interest in many fields of science. An ambitious but highly desirable goal is to infer causal effects from observational data obtained by observing a system of interest without subjecting it to interventions, thereby circumventing severe experimental constraints or exhibiting much lower costs. This is particularly relevant for many important questions in molecular biology. \r\n\r\nWe discuss recent progress that has been achieved over the last few years in statistical graphical modeling and optimization for causal inference, particularly in high-dimensional, sparse settings with thousands of variables but based on only a few dozens of observations. We highlight exciting possibilities, fundamental limitations of any modeling approach, and we discuss two successful experimental validations in the context of molecular biology for yeast (Saccharomyces cerevisiae) and the model plant Arabidopsis thaliana.", :title "Statistics and Optimization for Causal Inference in Large-Scale Biological Systems", :keyword2 0, :authors (29861), :session 230}, 1430 {:keyword1 127, :keyword3 0, :abstract "This lecture will start with an overview of the supply chain in Nestlé, from the purchasing of raw and packing materials to the final delivery point at our customers. Then we will focus on some applications where simple decision support and optimization tools have proven very helpful over the years. Such applications include : building of an efficient pallet or container load, simulation of picking activities in a warehouse, identification of optimal warehouse locations, calculation of safety stocks, search for an optimum product portfolio.", :title "Decision Support Models in Supply Chain at Nestle", :keyword2 0, :authors (9103), :session 231}, 1431 {:keyword1 127, :keyword3 0, :abstract "The current discussion around the 2011 Earthquake in Japan, and the 2007-09 Financial Crisis have once more brought rare, but extreme events to the forefront of the public debate. In this talk I will review some of the methodology underlying modern Extreme Value Theory (EVT), show where EVT has practical value, warn for areas where its applicability is dubious and discuss where more research is needed.\r\n\r\n\r\nThe talk is very much based on scientific papers to be found on my website www.math.ethz.ch/~embrechts, and in particular in the textbooks:\r\n[1] G. Balkema and P. Embrechts (2007). High Risk Scenarios and Extremes: A Geometric Approach. European Mathematical Society, Zurich.\r\n[2] P. Embrechts, C. Klueppelberg and T. Mikosch (1997). Modelling Extremal Events for Insurance and Finance. Springer, Berlin.\r\n[3] A.J. McNeil, R. Frey and P. Embrechts (2005). Quantitative Risk Management: Concepts, Techniques, Tools. Princeton University Press, Princeton, NJ.", :title "The modelling of rare events: From methodology to practice and back", :keyword2 0, :authors (29862), :session 154}, 1432 {:keyword1 127, :keyword3 0, :abstract "Price differentiation in the airline industry leads to significant revenue opportunities realized by efficiently controlling bookings for the various price products. We give an overview of common practices in revenue management from single flight control to network optimization and dynamic pricing. We discuss the critical role of distribution technology advancements from the traditional travel agent to Internet distribution.", :title "Developments in Booking Control Optimization by Airline Revenue Management", :keyword2 0, :authors (29863), :session 155}, 1433 {:keyword1 127, :keyword3 0, :abstract "Scientists and engineers are increasingly turning from the simulation of complex processes to the optimization and design of complex systems. Many important design problems involve not only continuous variables with nonlinear relationships but also discrete decisions, giving rise?to mixed-integer nonlinear programming problems (MINLPs). MINLPs combine the combinatorial complexity of the discrete decisions with the numerical challenges of the nonlinear functions.??\r\n\r\nWe present a new package for solving mixed-integer nonlinear optimization problems, called MINOTAUR. The MINOTAUR toolkit is designed to provide a flexible and efficient framework for solving MINLPs. The code s developed in a modular way to enable developers and users to efficiently combine the knowledge of problem structure with algorithmic insights. We will survey recent developments in MINLP and present the underlying algorithmic ideas of MINOTAUR. Our talk will focus on the integration of nonlinear solvers into the MINOTAUR's branch-and-cut framework, and highlight challenges and opportunities for nonlinear optimization.", :title "MINOTAUR: Solving Mixed-Integer and Nonlinear Optimization Problems", :keyword2 0, :authors (13402), :session 232}, 1434 {:keyword1 127, :keyword3 0, :abstract "Co-Authors: Joshua Elliott, Ian Foster, Margaret Loudermilk:\r\nCIM-EARTH is a framework for specifying and solving computable general equilibrium models.  In this talk, I will give an overview of the state of the framework and then discuss a case study using this framework on the international trade implications of carbon policies and border tax adjustments.  Carbon contents for the border tax adjustments are computed endogenous to the model by applying a carbon conservation principle.  Results are presented using matrices of bilateral carbon flows to analyze the amount of leakage resulting from the policies studied.  I will also provide some insights into the sensitivities of the outcomes to uncertain parameters based on the results from a large-scale computational study.", :title "CIM-EARTH: Overview and Case Study", :keyword2 0, :authors (3846), :session 235}, 1435 {:keyword1 127, :keyword3 0, :abstract "In this talk, we present the recent results on\r\nthe complexity bounds for methods of Convex Optimization \r\nbased only on computation of the function values or directional derivatives.\r\n\r\nFirst, we analyze the behavior of the random coordinate descent method and\r\nshow that for some problem classes it can be more efficient than the usual\r\ngradient scheme. In the second part of the talk we discuss pure random\r\nsearch strategies based on normally distributed random Gaussian vectors.\r\nSuch methods usually need at most $n$ times more iterations than the\r\nstandard gradient methods, where $n$ is the dimension of the space of\r\nvariables. This conclusion is true both for nonsmooth and smooth problems.\r\nFor the later class, we develop also an accelerated scheme with the expected rate of convergence of order $n$ square over $k$ square, where $k$ is the iteration counter. For Stochastic Optimization, we propose a zero-order scheme and justify its expected rate of convergence of order $n$ over square root of $k$. We give also some bounds for the rate of convergence of the random gradient-free methods to stationary points of nonconvex functions, both for smooth and nonsmooth cases. Our theoretical results are supported by preliminary computational experiments.", :title "Random Methods in Convex Minimization", :keyword2 0, :authors (25671), :session 156}, 1436 {:keyword1 127, :keyword3 0, :abstract "For several decades, Pontryagin’s maximum principle has been applied to solve optimal control problems in engineering, economics, or management. Early Operations Research applications of optimal control include problems such as production planning, inventory control, maintenance, marketing, or pollution control. Since the mid-nineties, optimal control models of illicit drug consumption have contributed successfully to a better understanding of drug epidemics and their control via an optimal mix of instruments such as prevention, treatment, or law enforcement. This talk explains why and how tools of dynamic optimization are used to address pressing questions arising in drug policy. Moreover, methodological advances in optimal control theory that have been triggered by solving these problems will be highlighted (e.g., multiple equilibria & thresholds, age-structured control systems, numerical analysis).", :title "Operations Research, Drugs, and Optimal Control", :keyword2 0, :authors (4861), :session 236}, 1437 {:keyword1 127, :keyword3 0, :abstract "We give a broad overview of a set of studies on electronic negotiation processes. Our approach combines an analysis of the substantive issues of negotiations, in particular offers, and the communication and relationship aspects. At both levels, we focus on the negotiation process, its influence factors, and the resulting outcomes of negotiations. we show how context factors, like negotiator's preferences, support systems used or characteristics of the negotiation problem influence both quantitative and qualitative aspects of the negotiation process, like concession levels or the structure of communication acts. These process characteristics in turn can be demonstrated  to impact outcomes. By various examples of such quantitative and qualitative studies, we show how an integration of different aspects can lead to a comprehensive understanding of negotiation processes.", :title "Analyzing e-negotiations from a quantitative and qualitative perspective", :keyword2 0, :authors (454), :session 157}, 1438 {:keyword1 127, :keyword3 0, :abstract "The field of metaheuristics has traditionally been very receptive to proposals about how to structure algorithms in order to effectively solve optimization problems. Innovation of solution approaches has always been one of the traits of the field, and design paradigms have succeeded as inspiration for algorithm designers: inspiration from nature, improvements of local search, logics and probability, etc.\r\n\r\nIn this presentation we aim to show how both metaheuristics and mathematical programming (MP) can leverage on one another. This especially relates to the term Matheuristics, which describes works that are along these lines, e.g., exploiting MP techniques in (meta)heuristic frameworks or on granting to MP approaches the cross-problem robustness and constrained CPU-time effectiveness which may characterize metaheuristics. This follows a trend in hybridization, which appeared in several forms in the last years: metaheuristics are being hybridized with artificial intelligence, with constraint programming, with statistics, not to mention among themselves. However, the combination of metaheuristics and MP has a set-apart condition. Including MP techniques for a metaheuristic designer does not mean looking for contributions, which could possibly derive from another research area, it means looking inside one’s own cultural baggage, it means using in a different way something one has already had experience with.\r\n\r\nExamples and applications of matheuristics in various problem domains are surveyed, including logistics as well as telecommunications.", :title "Matheuristics: Hybridizing Metaheuristics and Mathematical Programming", :keyword2 0, :authors (5931), :session 233}, 1439 {:keyword1 127, :keyword3 0, :abstract "From a practical perspective, mixed integer optimization represents a very powerful modeling paradigm. Its modeling power, however, comes with a price. The presence of both integer and continuous variables results in an increase in complexity over the pure integer case with respect to geometric, algebraic, combinatorial and algorithmic properties. Specifically, the theory of cutting planes for mixed integer linear optimization has not yet been at a similar level of development as in the pure integer case. The goal of this talk is to discuss four research directions that are expected to contribute to the development of this field of optimization. In particular, we examine a new geometric approach based on lattice point free polyhedra and use it for developing a cutting plane theory for mixed integer sets. We expect that these novel developments will shed some light on the additional complexity that goes along with mixing discrete and continuous variables.", :title "A Cutting Plane Theory for Mixed Integer Optimization", :keyword2 0, :authors (2950), :session 237}, 1440 {:keyword1 29, :keyword3 0, :abstract "Our society has a great dependence on electricity. It is therefore essential that the energy market is operated efficiently and reliably. The Midwest Independent Transmission System Operator (ISO) used Operations Research to ensure reliable operation and equal access to high-voltage power lines in 13 U.S. states and the Canadian province of Manitoba, while minimizing the cost of electricity for their 40 million end customers.\r\n\r\nIn this presentation, we will demonstrate how the Midwest ISO was able to realize between $2 and $3 billion in cumulative savings between 2007 and 2010. In recognition of this achievement he Midwest ISO, together with Paragon Decision Technology (the developers of AIMMS) and Alstom Grid, was awarded the prestigious Franz Edelman Award at the recent INFORMS conference on business Analytics and Operations Research held in April.\r\n\r\nOur presentation starts with an introduction to the design of the electricity market, both from a technical perspective as well as financial perspective and includes an overview of the different energy related products. This will be followed by an explanation of the optimization models that are solved as part of the grid operations, and the challenges related to model size and the tight performance requirements. We will then conclude the presentation with future challenges for the operations of the electric grid.", :title "OR in the Energy Market – Winning the Franz Edelman Award 2011", :keyword2 48, :authors (29864), :session 82}, 1443 {:keyword1 127, :keyword3 0, :abstract "We study theoretical aspects of the Gomory-Chvátal closure of polyhedra. A Gomory-Chvátal cutting plane for a polyhedron P is derived from any rational inequality that is valid for P by shifting the boundary of the associated half-space towards the polyhedron until it intersects an integer point. The Gomory-Chvátal closure of P is the intersection of all half-spaces defined by its Gomory-Chvátal cuts.\r\nAs our main result, we answer a question raised by Schrijver (1980) and show that the Gomory-Chvátal closure of a non-rational polytope is a rational polytope. Schrijver had established the polyhedrality of the Gomory-Chvátal closure for rational polyhedra. In essence, his proof relies on the fact that the set of integer points in a rational polyhedral cone is generated by a finite subset of these points. This is not true for non-rational polyhedral cones. We develop a completely different proof technique to show that the Gomory-Chvátal closure of a non-rational polytope can be described by a finite set of Gomory-Chvátal cuts. Our proof is geometrically motivated and makes use of classic results from polyhedral theory and the geometry of numbers.", :title "The Gomory-Chvátal Closure: Complexity, Polyhedrality and Extensions", :keyword2 0, :authors (29922), :session 150}, 1444 {:keyword1 127, :keyword3 0, :abstract "Our work deals with the cost allocation problem, which arises when several participants share the costs of building or using a common infrastructure. We attempt to answer the question: What is a fair cost allocation among participants? By combining cooperative game theory and state-of-the-art algorithms from linear and integer programming, our work not only defines fair cost allocations but also calculates them numerically for large real-world applications. \r\nFirst, in the theoretical part, we present and discuss several game-theoretical concepts. These concepts consider not only different aspects of fairness but also practical requirements, which, to the best of our knowledge, have not been considered in previous research. In addition, this part also investigates the computational complexity by calculating allocations based on the game-theoretical concepts. If the cost function is submodular, then one can find them in oracle-polynomial time. However, the problem is NP-hard in general. The biggest challenge is that there is exponential number of possible coalitions. To tackle this issue, we construct a constraint generation approach as well as primal and dual heuristics for its separation problem. \r\nIn the second part, we consider several applications based on the framework in the first part, one of which is the ticket pricing problem of the Dutch IC railway network. The current distance tariff results in a situation that some passengers in the central region of the country pay over 25% more than the costs they incur, and these excess payments subsidize operations elsewhere. In this case, it is obvious that the cost allocation is unfair. Using our method, we suggest new ticket prices which can reflect costs better and reduce the overpayments to less than 1.68%.", :title "Algorithmic Cost Allocation Games: Theory and Applications", :keyword2 0, :authors (16972), :session 150}, 1445 {:keyword1 127, :keyword3 0, :abstract "Recent developments in information and communication technologies have facilitated the practical application of dynamic vehicle routing systems. So far, most of the available dynamic vehicle routing approaches deal with urban area environments. In our contribution, however, the focus is set to wide area dynamic freight transportation covering the entire European continent. Due to its dynamic planning component, the occasional transportation mode (tramp transportation) – independent of predefined line networks – is considered.\r\nWe develop and evaluate two new dynamic planning approaches and incorporate all important real-life restrictions, such as regulations on driving hours (EC 561), working hours and traffic bans. Extensive numerical tests are carried out with a five-week real life data set from an international freight forwarding company. The results indicate that significant improvements, especially in terms of empty kilometers and service quality, can be achieved.", :title "Dynamic Fleet Management for International Truck Transportation - focusing on Occasional Transportation Tasks", :keyword2 0, :authors (15164), :session 239}, 1446 {:keyword1 127, :keyword3 0, :abstract "In the hydro-thermal scheduling problem, one is interested in determining the optimal operating policy for the use of hydro and thermal resources. In this thesis, the classical stochastic dual dynamic programming algorithm commonly used to solve this problem has been extended in various ways by (1) a scenario tree framework to capture stochastic electricity demand and fuel prices (2) modeling of CO2 emission allowances, and (3) trading of CO2 emission allowances in a deregulated market.", :title "A Unified State-space and Scenario Tree Framework for Multi-stage Stochastic Optimization", :keyword2 0, :authors (29370), :session 150}, 1447 {:keyword1 127, :keyword3 0, :abstract "A stochastic programming extension to the traditional Data Envelopment Analysis model (SDEA) is developed when input/output parameters are random variables described by discrete probability distributions. The SDEA framework yields a robust performance metrics for the underlying firms by controlling for outlier data and randomness in data. Using accounting data, the resulting relative financial strength (RFS) indicator is highly predictive of stock performance of public firms. In contrast, the traditional DEA model is shown to over-estimate the actual firm efficiencies. The SDEA model is used to develop lower and upper estimates on performance. Computations using firms covering all major sectors of the U.S. stock market are performed with quarterly financial data. The RFS metric is used to devise portfolios that yield superior financial performance relative to using sector-based ETF portfolios.", :title "Stochastic Programming DEA Model of Fundamental Analysis of Public Firms for Portfolio Selection", :keyword2 0, :authors (23224), :session 118}, 1449 {:keyword1 127, :keyword3 0, :abstract "Optimization under uncertainty has always been part of the field mathematical optimization. In fact, George B. Dantzig, published a paper with the title \"Linear Programming under Uncertainty\" in 1955. Since then, a lot of research has been done and several modeling approaches and decomposition algorithms for stochastic programming problems have been developed. However, the practical use of stochastic programming in business and industry has by far not reached the popularity of classes such as LPs, MIPs, or NLPs. We want to address this issue by first discussing stochastic programming methods and applications. Afterwards we analyze several algebraic modeling languages in regard to their support of these methods. The focus of this talk then lies in the application of methods and modeling systems to real world problems. In specific, we apply a decomposition method, the Stochastic Dual Dynamic Programming algorithm, to a sophisticated model, motivated by hydropower planning, using GAMS. We show difficulties in the practical use of the analyzed programming systems and present properties of the implemented algorithm, using the latest programming features of GAMS. Finally we compare the performance of the GAMS implementation to a Concert approach.", :title "Practical Stochastic Programming using Algebraic Modeling Systems", :keyword2 0, :authors (26501), :session 271}, 1450 {:keyword1 127, :keyword3 0, :abstract "The goal of this thesis is to identify special cases of (unrestricted) nonlinear integer optimization problems that can be solved by rounding (up or down) the components of the solution vector of its continuous relaxation. To this end we consider the level sets of the objective function: one can rewrite the optimization problem to minimize a given function over all integer points as finding the minimal level such that the corresponding level set still contains an integer point.\r\nThe problem is easy to solve if the level sets are balls around the optimal solution of the continuous relaxation of the original problem: The first integer point to be reached by growing the level sets and hence an optimal solution for the original integer problem will be the one with the smallest Euclidean distance from the relaxed solution. \r\nFollowing this motivation in addition to balls we want to identify other geometrical forms guaranteeing that the first integer point to be reached will be a \"neighbour\" of the relaxed solution, i.e. it can be found by rounding up or down the components. \r\nKnowing this, all we have to do to solve the original integer problem after having solved its continuous relaxation is to test the points we get by rounding up or down the components of the relaxed solution. \r\nThis allows us to solve the integer problem in polynomial time if the continuous relaxation is solvable in polynomial time and if the dimension is fixed.", :title "When is rounding allowed?  A level set approach to integer nonlinear optimization.", :keyword2 0, :authors (29561), :session 271}, 1451 {:keyword1 127, :keyword3 0, :abstract "Many practical decision and planning problems in operations research can be modeled as mixed integer programs (MIPs) with a special structure; this structure can be exploited in branch-and-price algorithms which are based on the Dantzig-Wolfe decomposition. Primal heuristics are a very important aspect of MIP solving: In practice, the decision maker is often satisfied with a \"good\" solution to her problem; besides, such solutions can help accelerate the solving process. We developed and tested heuristics specially tailored for branch-and-price that exploit the fact that two different formulations of the MIP are available via the Dantzig-Wolfe decomposition. We implemented our heuristics in the branch-and-price solver GCG which is based on the renowned SCIP framework. Although not so much improving the solution time, solutions could be found and the number of solving nodes could be reduced on almost all of the problems on which the heuristics were tested; in particular, they were successful on some instances where GCG previously failed. As today's branch-and-price algorithms are almost always tailored to the application and thus \"reserved to experts\", a more generally accessible solver is much needed. Our work contributes first steps towards this goal by providing primal heuristics for branch-and-price.", :title "Primal Heuristics for Branch-and-Price Algorithms", :keyword2 0, :authors (29257), :session 271}, 1452 {:keyword1 13, :keyword3 0, :abstract "Model predictive control (MPC) requires the solution of a constrained finite horizon optimal control problem in a receding horizon fashion. Consequently, the solution to this optimization problem has to be obtained within one sampling period of the control loop. But guaranteeing deterministic termination of an iterative solution method is a challenging problem in general. This talk focuses on certifying the fast gradient method for both input-only constrained and input/state constrained linear quadratic MPC. We establish links between problem data and convergence speed and emphasize the practicability of the certification results by several examples and real-world applications.", :title "Certification of the fast gradient method in model predictive control", :keyword2 126, :authors (28832), :session 61}, 1453 {:keyword1 127, :keyword3 0, :abstract "The Austrian health care system is characterised by a high density of health care facilities. In 2010, a total of 266 hospitals were available for inpatient care. Total annual health care expenditure amounts to approximately EUR 30.3 billion, which is 11 % of the gross domestic product. The major funders of the Austrian health care system include the social health insurance funds and the Federal Government. In 2009, a majority of the expenditure on hospitals was borne by these two parties. In order to ensure an efficient allocation of resources, the Federal Ministry of Health established a reporting system for hospitals in 2010 with the aim of supporting decision-making processes on the federal and provincial level and particularly providing reliable data for effective decisions in connection with the ongoing health care reform debate. The reporting system consists of five components which give an overview of the structure and the maturity of the hospitals’ assets and capital, the composition of equity, revenues, receipts and expenditures and the origin and composition of allowances. The aim of the paper is to describe the individual components of the reporting system in detail and to outline their informative value and their decision usefulness. Based on this description, the paper identifies items which are of major importance for the hospitals’ capital and cost structure and proposes possible decision-useful management ratios.", :title "The Austrian Health Care System – Introduction of a New Reporting System for Hospitals", :keyword2 0, :authors (29971 29972), :session 95}, 1454 {:keyword1 127, :keyword3 0, :abstract "Due to economic pressure industries, when planning, tend to focus on optimizing the expected profit or the yield. The consequence of highly optimized solutions is an increased sensitivity to uncertainty. This generates additional \"operational\" costs, incurred by possible modifications of the original plan to be performed when reality does not reflect what was expected in the planning phase. The modern research trend focuses on \"robustness\" of solutions instead of yield or profit. Although robust solutions have a lower expected profit, they are less sensitive to noisy data and hence generate less operational costs. In this talk, we focus on the robustness of airline schedules. We compare different existing methods for \"robust scheduling\" on simulated data in order to analyze their performance. In particular, we analyze the consequences of erroneous prediction models on the performance of robust solutions. Simulations are based on the public data of the ROADEF Challenge 2009 (http://challenge.roadef.org/2009).", :title "Combining Robustness and Recovery for Airline Schedules", :keyword2 0, :authors (29977), :session 239}, 1455 {:keyword1 37, :keyword3 35, :abstract "Physical dynamical systems are modeled in a causal manner, but market behavior is caised by human interaction. Thus, it includes an aspect of rational behavior, i.e. utility optimization. The adjoint equations of an optimal control problem have naturally a retro-causal formulation. The realization of a causal-retro-causal approach with recurrent neural networks allows a significant improvement of the modeling of market prices. We exemplifiy our model on the forecasting of commodity prices.", :title "Causal-Retro-Causal Neural Networks for Market Price Forecasting", :keyword2 23, :authors (14817 14818), :session 107}, 1458 {:keyword1 37, :keyword3 23, :abstract "The main goal is to translate the wind forecasts into power. We predict the wind park power for the next seven days ahead on hourly time buckets. For this task we refer to so-called deep neural networks. A deep neural network is a feedforward neural network consisting of several hidden layers for the processing of the input information. The input is fed to all intermediate (hidden) layers in order to avoid the loss of input information. Each hidden layer is connected to a separate output layer, which independently provides forecasts for the targets. Learning is not only applied to the last output layer, but to all intermediate layers.\r\n", :title "Modeling the Energy Supply of Wind Parks with Deep Neural Networks", :keyword2 29, :authors (14817 14818), :session 109}}, :users {125 {:firstname "Norbert", :lastname "Trautmann", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (142 163 266)}, 139 {:firstname "Laureano Fernando", :lastname "Escudero", :department "Estadística e  Investigación Operativa", :institution "Universidad Rey Juan Carlos", :country "Spain", :sessions (118 175 117)}, 149 {:firstname "Bettina", :lastname "Klinz", :department "Institut für Optimierung und Diskrete Mathematik", :institution "TU Graz", :country "Austria", :sessions (214)}, 152 {:firstname "Antonio", :lastname "Alonso-Ayuso", :department "", :institution "Rey Juan Carlos University", :country "Spain", :sessions (175)}, 220 {:firstname "Diptesh", :lastname "Ghosh", :department "Production and Quantitative Methods", :institution "Indian Institute of Management, Ahmedabad", :country "India", :sessions (238 206)}, 230 {:firstname "Metin", :lastname "Turkay", :department "Department of Industrial Engineering", :institution "Koc University", :country "Turkey", :sessions (129)}, 281 {:firstname "Ulrike", :lastname "Leopold-Wildburger", :department "Statistics and Operations Research", :institution "Karl-Franzens-University", :country "Austria", :sessions (133 48 134 157 218)}, 382 {:firstname "T'kindt", :lastname "Vincent", :department "", :institution "Ecole d'Ingénieurs en Informatique pour l'Industrie", :country "France", :sessions (202 189)}, 454 {:firstname "Rudolf", :lastname "Vetschera", :department "Dept. of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (157 130)}, 518 {:firstname "Luca Maria", :lastname "Gambardella", :department "Istituto Dalle Molle di Studi sull'Intelligenza Artificiale", :institution "IDSIA", :country "Switzerland", :sessions (159 160 247 233)}, 634 {:firstname "Z. Pelin", :lastname "Bayindir", :department "Department of Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (169 181 164)}, 770 {:firstname "Marion", :lastname "Rauner", :department "Faculty of Business, Economics, and Statistics", :institution "University of Vienna", :country "Austria", :sessions (48 95 158)}, 773 {:firstname "Thomas", :lastname "Sigl", :department "Decision Support Systems", :institution "Fraunhofer Institute for Integrated Circuits", :country "Germany", :sessions (187)}, 829 {:firstname "Rainer", :lastname "Kolisch", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (88 50 121)}, 909 {:firstname "Martin", :lastname "Grunow", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (165)}, 930 {:firstname "Christoph", :lastname "Schwindt", :department "Institute of Management and Economics", :institution "Clausthal University of Technology", :country "Germany", :sessions (64)}, 1019 {:firstname "Marc", :lastname "Uetz", :department "Applied Mathematics ", :institution "University of Twente ", :country "Netherlands", :sessions (51)}, 1131 {:firstname "Heinrich", :lastname "Kuhn", :department "Operations Management", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (166)}, 1141 {:firstname "Leena", :lastname "Suhl", :department "Dept. Business Information Systems", :institution "University of Paderborn", :country "Germany", :sessions (219 126 150 239)}, 1177 {:firstname "Y. Ilker", :lastname "Topcu", :department "Industrial Engineering", :institution "Istanbul Technical University", :country "Turkey", :sessions (48)}, 1194 {:firstname "Natalia", :lastname "Kliewer", :department "Information Systems", :institution "Freie Universitaet Berlin", :country "Germany", :sessions (187)}, 1256 {:firstname "Teresa", :lastname "Melo", :department "Business School", :institution "Saarland University of Applied Sciences", :country "Germany", :sessions (187 81 191)}, 1309 {:firstname "Paulo", :lastname "Correia", :department "Energy Department", :institution "Unicamp", :country "Brazil", :sessions (126 129 137)}, 1327 {:firstname "Tadeusz", :lastname "Sawik", :department "Operations Research & Information Technology", :institution "AGH University of Science & Technology", :country "Poland", :sessions (147)}, 1459 {:firstname "Claudio", :lastname "Gentile", :department "", :institution "IASI-CNR", :country "Italy", :sessions (229)}, 1527 {:firstname "María", :lastname "Merino", :department "Applied Mathematics, Statistics and Operations Research", :institution "University of the Basque Country", :country "Spain", :sessions (117)}, 1560 {:firstname "Kathrin", :lastname "Klamroth", :department "Department of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (214)}, 1601 {:firstname "Anita", :lastname "Schöbel", :department "TU Kaiserslautern", :institution "Fachbereich Mathematik", :country "Germany", :sessions (194 245 195 204)}, 1646 {:firstname "Vladimir", :lastname "Marianov", :department "Electrical Engineering", :institution "Pontificia Universidad Catolica de Chile", :country "Chile", :sessions (177)}, 1857 {:firstname "Yasemin", :lastname "Serin", :department "INDUSTRIAL ENGINEERING", :institution "MIDDLE EAST TECHNICAL UNIVERSITY", :country "Turkey", :sessions (163)}, 1888 {:firstname "So Young", :lastname "Sohn", :department "Industrial Engineering", :institution "Yonsei university", :country "Korea, Republic of", :sessions (109)}, 2044 {:firstname "Hubert", :lastname "Missbauer", :department "Information Systems, Production and Logistics Management", :institution "University of Innsbruck", :country "Austria", :sessions (159)}, 2052 {:firstname "Geert-Jan", :lastname "van Houtum", :department "Fac. of Technology Management", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (224)}, 2127 {:firstname "Michalis", :lastname "Doumpos", :department "School of Production Engineering and Management", :institution "Technical University of Crete", :country "Greece", :sessions (267)}, 2128 {:firstname "Constantin", :lastname "Zopounidis", :department "Dept. of Production Engineering and Management", :institution "Technical University of Crete", :country "Greece", :sessions (109)}, 2168 {:firstname "Reinaldo", :lastname "Morabito", :department "Dept. of Production Engineering", :institution "Federal University of São Carlos", :country "Brazil", :sessions (243)}, 2188 {:firstname "Teodor Gabriel", :lastname "Crainic", :department "Management and Technology", :institution "Univ. du Québec à Montréal", :country "Canada", :sessions (192)}, 2190 {:firstname "Kaj", :lastname "Holmberg", :department "Department of Mathematics", :institution "Linköping University", :country "Sweden", :sessions (212)}, 2220 {:firstname "Rifat Gürcan", :lastname "Özdemir", :department "Industrial Engineering Department", :institution "Istanbul Kültür University", :country "Turkey", :sessions (144)}, 2238 {:firstname "Peter", :lastname "Kelle", :department "ISDS", :institution "Louisiana State University", :country "United States", :sessions (224)}, 2266 {:firstname "Takashi", :lastname "Shibata", :department "Graduate School of Management", :institution "Tokyo Metropolitan University", :country "Japan", :sessions (266)}, 2283 {:firstname "Hans L.", :lastname "Trinkaus", :department "Systemanalyse, Prognose und Regelung", :institution "Fraunhofer ITWM", :country "Germany", :sessions (252)}, 2474 {:firstname "Robert", :lastname "Manger", :department "Faculty of Science, Department of Mathematics", :institution "University of Zagreb", :country "Croatia", :sessions (75)}, 2573 {:firstname "Roy", :lastname "Kwon", :department "Mechanical and Industrial Engineering", :institution "University of Toronto", :country "Canada", :sessions (264)}, 2650 {:firstname "Grit", :lastname "Walther", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (105 103)}, 2651 {:firstname "Thomas", :lastname "Spengler", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (105 222 99 167 53)}, 2675 {:firstname "Frank", :lastname "Schultmann", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (128)}, 2678 {:firstname "Ioana", :lastname "Popescu", :department "Decision Sciences", :institution "INSEAD", :country "Singapore", :sessions (101)}, 2685 {:firstname "Ronald", :lastname "Hochreiter", :department "Finance, Accounting and Statistics", :institution "WU Vienna University of Economics and Business", :country "Austria", :sessions (79)}, 2690 {:firstname "Celia", :lastname "Glass", :department "Cass Business School", :institution "City University", :country "United Kingdom", :sessions (112)}, 2713 {:firstname "Michaela", :lastname "Schaffhauser-Linzatti", :department "Business Administration", :institution "University of Vienna", :country "Austria", :sessions (95)}, 2769 {:firstname "Karl", :lastname "Doerner", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (247 185)}, 2801 {:firstname "Karl", :lastname "Inderfurth", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University of Magdeburg", :country "Germany", :sessions (224 167)}, 2841 {:firstname "Richard", :lastname "Loulou", :department "", :institution "GERAD", :country "Canada", :sessions (125)}, 2866 {:firstname "Cristian", :lastname "Canales", :department "", :institution "Instituto de Fomento Pesquero", :country "Chile", :sessions (261)}, 2950 {:firstname "Robert", :lastname "Weismantel", :department "Department of Mathematics", :institution "ETH Zurich", :country "Germany", :sessions (237)}, 2983 {:firstname "Snjolfur", :lastname "Olafsson", :department "Faculty of Economics and Business Administration", :institution "University of Iceland", :country "Iceland", :sessions (251 252)}, 2991 {:firstname "Paolo", :lastname "Falbo", :department "Department of Economics and Management", :institution "University of Brescia", :country "Italy", :sessions (122)}, 3025 {:firstname "Dimitris", :lastname "Bertsimas", :department "Sloan School of Management, MIT", :institution "Massachusetts Institute of Technology", :country "United States", :sessions (123)}, 3046 {:firstname "Jacques", :lastname "Desrosiers", :department "", :institution "GERAD", :country "Canada", :sessions (210)}, 3051 {:firstname "Rajesh", :lastname "Piplani", :department "Systems and Engineering Mgmt", :institution "Nanyang Technological University", :country "Singapore", :sessions (171)}, 3122 {:firstname "Georg", :lastname "Pflug", :department "Department of Statistics and Decision Support Systems", :institution "University of Vienna", :country "Austria", :sessions (217 119)}, 3190 {:firstname "Yury", :lastname "Kochetov", :department "Information Technology", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (220)}, 3240 {:firstname "Daniel", :lastname "Kuhn", :department "", :institution "EPFL", :country "Switzerland", :sessions (117)}, 3301 {:firstname "Janny", :lastname "Leung", :department "Systems Engineering & Engineering Management Dept.", :institution "The Chinese University of Hong Kong", :country "Hong Kong", :sessions (219)}, 3329 {:firstname "Rob", :lastname "Broekmeulen", :department "OPAC", :institution "TU Eindhoven", :country "Netherlands", :sessions (169)}, 3330 {:firstname "Karel", :lastname "van Donselaar", :department "OPC", :institution "TU Eindhoven", :country "Netherlands", :sessions (169)}, 3524 {:firstname "Gerhard-Wilhelm", :lastname "Weber", :department "Faculty of Engineering Management, Chair of Marketing and Economic Engineering", :institution "Poznan University of Technology", :country "Poland", :sessions (62)}, 3542 {:firstname "Walter", :lastname "Gutjahr", :department "Department of Statistics and Operations Research", :institution "University of Vienna", :country "Austria", :sessions (75)}, 3578 {:firstname "Mahmut Ali", :lastname "Gokce", :department "Industrial Engineering", :institution "Yaşar University", :country "Turkey", :sessions (243)}, 3589 {:firstname "Jo", :lastname "van Nunen", :department "Department Decision and Information Sciences", :institution "RSM Erasmus University", :country "Netherlands", :sessions (224)}, 3654 {:firstname "Cristian", :lastname "Pelizzari", :department "Department of Economics and Management", :institution "University of Brescia", :country "Italy", :sessions (122)}, 3662 {:firstname "Yves", :lastname "Smeers", :department "CORE", :institution "Universite catholique de Louvain", :country "Belgium", :sessions (125 120)}, 3676 {:firstname "Karl", :lastname "Frauendorfer", :department "", :institution "University of St. Gallen", :country "Switzerland", :sessions (151)}, 3753 {:firstname "Robert", :lastname "Fourer", :department "", :institution "AMPL Optimization Inc.", :country "United States", :sessions (90)}, 3775 {:firstname "Gautam", :lastname "Mitra", :department "CARISMA", :institution "Brunel University", :country "United Kingdom", :sessions (119)}, 3791 {:firstname "Nico", :lastname "Dellaert", :department "Technology Management", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (171)}, 3843 {:firstname "Bjarni", :lastname "Kristjansson", :department "", :institution "Maximal Software", :country "Iceland", :sessions (90)}, 3846 {:firstname "Todd", :lastname "Munson", :department "Mathematics and Computer Science Division", :institution "Argonne National Laboratory", :country "United States", :sessions (235)}, 4099 {:firstname "Paolo", :lastname "Ventura", :department "", :institution "IASI-CNR", :country "Italy", :sessions (229)}, 4161 {:firstname "Stefan", :lastname "Irnich", :department "Chair of Logistics Management, Gutenberg School of Management and Economics", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (101 182)}, 4229 {:firstname "Moritz", :lastname "Fleischmann", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (96 224 190)}, 4275 {:firstname "Andrew J", :lastname "Mason", :department "Dept Engineering Science", :institution "University of Auckland", :country "New Zealand", :sessions (241)}, 4357 {:firstname "Christian", :lastname "Stummer", :department "Department of Business Administration and Economics", :institution "Bielefeld University", :country "Germany", :sessions (130)}, 4607 {:firstname "Emilio", :lastname "CARRIZOSA", :department "", :institution "IMUS - Instituto de Matemáticas de la Universidad de Sevilla", :country "Spain", :sessions (220)}, 4796 {:firstname "Stefan Wolfgang", :lastname "Pickl", :department "Department of Computer Science", :institution "UBw München COMTESSA", :country "Germany", :sessions (133 128 235)}, 4860 {:firstname "Jonathan", :lastname "Caulkins", :department "H. John Heinz III School of Public Policy & Management", :institution "Carnegie Mellon University", :country "United States", :sessions (197)}, 4861 {:firstname "Gernot", :lastname "Tragler", :department "OR and Control Systems", :institution "Vienna University of Technology", :country "Austria", :sessions (236)}, 4910 {:firstname "Christelle", :lastname "GUERET", :department "Automatique - Productique", :institution "Ecole des Mines de Nantes", :country "France", :sessions (51)}, 4928 {:firstname "Mingzhe", :lastname "Li", :department "Faculty of Economics", :institution "Fukuoka University", :country "Japan", :sessions (181)}, 5030 {:firstname "Engin", :lastname "Topan", :department "Department of Industrial Engineering and Innovation Sciences", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (169)}, 5078 {:firstname "Stefan", :lastname "Nickel", :department "Institute for Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (240 155)}, 5086 {:firstname "Fotios", :lastname "Pasiouras", :department "Dept. of Production Engineering and Management ", :institution "Technical University of Crete", :country "Greece", :sessions (109)}, 5236 {:firstname "Adam", :lastname "Janiak", :department "Institute of Computer Engineering, Control and Robotics", :institution "Wroc&#322;aw University of Technology", :country "Poland", :sessions (146)}, 5465 {:firstname "Oded", :lastname "Berman", :department "Rotman School of Management", :institution "University of Toronto", :country "Canada", :sessions (223)}, 5524 {:firstname "Bernhard", :lastname "Fleischmann", :department "Production&SCM", :institution "Universität Augsburg", :country "Germany", :sessions (170)}, 5582 {:firstname "Abdel", :lastname "Lisser", :department "LRI", :institution "University Paris Sud", :country "France", :sessions (161)}, 5590 {:firstname "Eva", :lastname "Vallada", :department "Estadística e Investigación Operativa Aplicadas y Calidad", :institution "Universidad Politécnica de Valencia", :country "Spain", :sessions (53)}, 5838 {:firstname "Dirk", :lastname "Briskorn", :department "", :institution "University of Wuppertal", :country "Germany", :sessions (53 140)}, 5876 {:firstname "Justo", :lastname "Puerto", :department "Estadistica e I.O.", :institution "Universidad de Sevilla", :country "Spain", :sessions (177)}, 5931 {:firstname "Stefan", :lastname "Voss", :department "Wirtschaftsinformatik/Information Systems", :institution "University of Hamburg", :country "Germany", :sessions (233)}, 5965 {:firstname "Jürgen", :lastname "Zimmermann", :department "Operations Research", :institution "TU Clausthal", :country "Germany", :sessions (64)}, 5988 {:firstname "Takashi", :lastname "Matsuhisa", :department "BUSAIKU BUHI Foundation for Scientific Research", :institution "Mathematical Research Institute", :country "Japan", :sessions (138)}, 6147 {:firstname "Hans-Jakob", :lastname "Lüthi", :department "D-MATH", :institution "ETHZ", :country "Switzerland", :sessions (28 123 264 230)}, 6251 {:firstname "Frits", :lastname "Spieksma", :department "Mathematics and Computer Science", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (143 141)}, 6281 {:firstname "Sergei", :lastname "Chubanov", :department "", :institution "University of Siegen", :country "Germany", :sessions (229)}, 6325 {:firstname "Keisuke", :lastname "Hotta", :department "Faculty of Business Administration", :institution "Bunkyo University", :country "Japan", :sessions (208)}, 6398 {:firstname "Albert", :lastname "Ha", :department "Information Systems, Business Statistics and Operations Management", :institution "Hong Kong University of Science and Technology", :country "Hong Kong", :sessions (167)}, 6404 {:firstname "Andreas", :lastname "Bortfeldt", :department "Dept. of Management Science", :institution "University of Magdeburgagen", :country "Germany", :sessions (179)}, 6513 {:firstname "Atsuo", :lastname "Suzuki", :department "Dept. of Systems and Mathematical Sciences", :institution "Nanzan University", :country "Japan", :sessions (221)}, 6600 {:firstname "Jussi", :lastname "Hakanen", :department "Dept. of Mathematical Information Technology", :institution "University of Jyvaskyla", :country "Finland", :sessions (254)}, 6751 {:firstname "Michael", :lastname "Manitz", :department "Technology and Operations Management, Chair of Production and Supply Chain Management", :institution "University of Duisburg/Essen", :country "Germany", :sessions (223)}, 6938 {:firstname "Takehiro", :lastname "Furuta", :department "", :institution "Nara University of Education", :country "Japan", :sessions (221)}, 6948 {:firstname "Frank", :lastname "Heyde", :department "Institute of Mathematics and Scientific Computing", :institution "University of Graz", :country "Austria", :sessions (78)}, 7032 {:firstname "Fernando A. C. C.", :lastname "Fontes", :department "Systec-ISR, Dept. of Electrical and Computer Engineering, Faculdade de Engenharia", :institution "Universidade do Porto", :country "Portugal", :sessions (149)}, 7142 {:firstname "Roy", :lastname "Cerqueti", :department "Department of Economics and Law", :institution "University of Macerata", :country "Italy", :sessions (122)}, 7336 {:firstname "Dieter", :lastname "Fiems", :department "", :institution "Ghent University", :country "Belgium", :sessions (52 122)}, 7400 {:firstname "Enrico", :lastname "Malaguti", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (210)}, 7405 {:firstname "Margit", :lastname "Sommersguter-Reichmann", :department "Department of Finance", :institution "University of Graz", :country "Austria", :sessions (48 81)}, 7649 {:firstname "Burcin", :lastname "Bozkaya", :department "Sabanci School of Management", :institution "Sabanci University", :country "Turkey", :sessions (186)}, 7687 {:firstname "Stephan", :lastname "Dempe", :department "Mathematics and Computer Sciences", :institution "Technische Universitaet Freiberg", :country "Germany", :sessions (41 55 156 71 236)}, 7857 {:firstname "Roberto", :lastname "Montemanni", :department "Department of Sciences and Methods for Engineering", :institution "University of Modena and Reggio Emilia", :country "Italy", :sessions (159 212)}, 8187 {:firstname "Michi", :lastname "Nishihara", :department "Graduate School of Economics", :institution "Osaka University", :country "Japan", :sessions (269 266)}, 8334 {:firstname "Klaus", :lastname "Schittkowski", :department "Dept. of Computer Science", :institution "University of Bayreuth", :country "Germany", :sessions (60)}, 8450 {:firstname "Kathrin", :lastname "Kirchner", :department "Cooperative Studies", :institution "Berlin School of Economics and Law", :country "Germany", :sessions (131)}, 8451 {:firstname "Victor M.", :lastname "Albornoz", :department "Departamento de Industrias", :institution "Universidad Tecnica Federico Santa Maria", :country "Chile", :sessions (261 166)}, 8470 {:firstname "Alexander", :lastname "Shapiro", :department "Industrial and Systems Engineering", :institution "Georgia Institute of Technology", :country "United States", :sessions (120)}, 8475 {:firstname "Oscar", :lastname "Cornejo", :department "Ingeniería Industrial", :institution "Facultad de Ingenieria-Universidad Católica de Concepción", :country "Chile", :sessions (160)}, 8513 {:firstname "Johann", :lastname "Hurink", :department "Department of Applied Mathematics", :institution "University of Twente", :country "Netherlands", :sessions (129)}, 8650 {:firstname "Vlasta", :lastname "Kaňková", :department "Econometrics", :institution "Institute of Information Theory and Automation of  ASCR", :country "Czech Republic", :sessions (118)}, 8713 {:firstname "Magnus", :lastname "Fröhling", :department "Faculty of Economics", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (128)}, 8732 {:firstname "Guido", :lastname "Sand", :department "Corporate Research Germany", :institution "ABB AG", :country "Germany", :sessions (120)}, 8981 {:firstname "Ralf", :lastname "Werner", :department "Institut für Mathematik", :institution "Universität Augsburg", :country "Germany", :sessions (215)}, 9066 {:firstname "Krzysztof", :lastname "Fleszar", :department "Olayan School of Business", :institution "American University of Beirut", :country "Lebanon", :sessions (166)}, 9082 {:firstname "David", :lastname "Wozabal", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (217 108)}, 9096 {:firstname "Thomas", :lastname "Burkhardt", :department "Campus Koblenz, IfM", :institution "Universitaet Koblenz-Landau", :country "Germany", :sessions (133)}, 9100 {:firstname "Sally", :lastname "Brailsford", :department "Southampton Business School", :institution "University of Southampton", :country "United Kingdom", :sessions (158)}, 9103 {:firstname "Daniel", :lastname "Costa", :department "", :institution "??", :country "Italy", :sessions (239 231)}, 9109 {:firstname "Eric", :lastname "van Berkum", :department "Civil Engineering", :institution "University of Twente", :country "Netherlands", :sessions (256)}, 9112 {:firstname "Stefan", :lastname "Minner", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (223)}, 9116 {:firstname "Adrian", :lastname "Werner", :department "Industry", :institution "SINTEF AS", :country "Norway", :sessions (192)}, 9171 {:firstname "Markus", :lastname "Günther", :department "Department of Business Administration and Economics", :institution "Bielefeld University", :country "Germany", :sessions (130)}, 9212 {:firstname "Pierre", :lastname "Kunsch", :department "BUTO", :institution "Vrije Universiteit Brussel", :country "Belgium", :sessions (255)}, 9272 {:firstname "Achim", :lastname "Koberstein", :department "Information and Operations Management", :institution "European University Viadrina Frankfurt (Oder)", :country "Germany", :sessions (222)}, 9356 {:firstname "Víctor", :lastname "Blanco", :department "Quant. Methods for Economics & Business", :institution "Universidad de Granada", :country "Spain", :sessions (177)}, 9392 {:firstname "Ayse", :lastname "Kocabiyikoglu", :department "Department of Business Administration", :institution "Bilkent University", :country "Turkey", :sessions (101)}, 9422 {:firstname "Stefan", :lastname "Lessmann", :department "School of Business and Economics", :institution "Humboldt-University of Berlin", :country "Germany", :sessions (109 107)}, 9512 {:firstname "Rüdiger", :lastname "Schultz", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (117 76)}, 9524 {:firstname "Julia", :lastname "Rieck", :department "Operations Research Group", :institution "University of Hildesheim", :country "Germany", :sessions (187 64)}, 9536 {:firstname "Stefan", :lastname "Vigerske", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (213)}, 9537 {:firstname "Andreas", :lastname "Eichhorn", :department "Portfolio Management", :institution "VERBUND Trading GmbH", :country "Austria", :sessions (126)}, 9547 {:firstname "Alexander", :lastname "Kruger", :department "Faculty of Science and Technology", :institution "Federation University Australia", :country "Australia", :sessions (55)}, 9583 {:firstname "Dries", :lastname "Goossens", :department "Business Informatics and Operations Management", :institution "Ghent University", :country "Belgium", :sessions (143)}, 9590 {:firstname "Sebastián", :lastname "Lozano", :department "Dept. of Industrial Management", :institution "University of Seville", :country "Spain", :sessions (107 260)}, 9647 {:firstname "Iris F.A.", :lastname "Vis", :department "Faculty of Economics and Business, Dep. of Operations", :institution "University of Groningen", :country "Netherlands", :sessions (92)}, 9684 {:firstname "Francisco", :lastname "Saldanha-da-Gama", :department "Department of Statistics and Operations Research / CMAF-CIO, Faculty of Science", :institution "University of Lisbon", :country "Portugal", :sessions (191)}, 9690 {:firstname "Yudai", :lastname "Honma", :department "Institute of Industrial Science", :institution "The University of Tokyo", :country "Japan", :sessions (181)}, 9694 {:firstname "Dmitrii", :lastname "Lozovanu", :department "Institute of Mathematics and Computer Science", :institution "Academy of Sciences of Moldova", :country "Moldova, Republic of", :sessions (133)}, 9695 {:firstname "Michael", :lastname "Stiglmayr", :department "School of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (214)}, 9703 {:firstname "Marc", :lastname "Reimann", :department "Lehrstuhl für Produktion und Logistiks Management", :institution "Universität Graz", :country "Austria", :sessions (85 256 168 226)}, 9736 {:firstname "Rachid", :lastname "Chelouah", :department "95011", :institution "EISTI ", :country "France", :sessions (238)}, 9796 {:firstname "Dirk O.", :lastname "Theis", :department "", :institution "University of Heidelberg", :country "Germany", :sessions (205)}, 9827 {:firstname "Keith", :lastname "Hipel", :department "Systems Design Engineering", :institution "University of Waterloo", :country "Canada", :sessions (252)}, 9874 {:firstname "Wilhelm", :lastname "Rödder", :department "Operations Research", :institution "University of Hagen", :country "Germany", :sessions (259 260)}, 9925 {:firstname "Elisabetta", :lastname "Allevi", :department "Department of Economics and Management", :institution "University of Brescia", :country "Italy", :sessions (124)}, 9944 {:firstname "Jorge", :lastname "Pinho de Sousa", :department "", :institution "Faculdade de Engenharia da Universidade do Porto / INESC Porto", :country "Portugal", :sessions (189)}, 10013 {:firstname "Francisco", :lastname "Facchinei", :department "", :institution "La Sapienza Università di Roma", :country "Italy", :sessions (57)}, 10023 {:firstname "Karel", :lastname "Sladky", :department "Department of Econometrics", :institution "Institute of Information Theory and Automation, Academy of Sciences of the Czech Republic", :country "Czech Republic", :sessions (115)}, 10057 {:firstname "Brigitte", :lastname "Werners", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (272 88 225 226)}, 10087 {:firstname "Oliver", :lastname "Bastert", :department "", :institution "FICO", :country "Germany", :sessions (77)}, 10115 {:firstname "Florian", :lastname "Frommlet", :department "Medical Statistics", :institution "Medical University Vienna", :country "Austria", :sessions (66 65 67)}, 10171 {:firstname "Alejandro", :lastname "Balbás", :department "Business Administration", :institution "University Carlos III of Madrid", :country "Spain", :sessions (264)}, 10255 {:firstname "Raik", :lastname "Stolletz", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (163 53 140)}, 10297 {:firstname "Ovidiu", :lastname "Listes", :department "", :institution "AIMMS", :country "Netherlands", :sessions (241)}, 10323 {:firstname "Gad", :lastname "Rabinowitz", :department "Department of Industrial Engineering and Management", :institution "Ben Gurion University of the Negev", :country "Israel", :sessions (164)}, 10380 {:firstname "José G.", :lastname "Hernández R.", :department "Gestión de la tecnología", :institution "Universidad Metropolitana", :country "Venezuela, Bolivarian Republic of", :sessions (258)}, 10386 {:firstname "Krunoslav", :lastname "Puljic", :department "Faculty of Economics & Business", :institution "University of Zagreb", :country "Croatia", :sessions (75)}, 10390 {:firstname "María J.", :lastname "García G.", :department "Gerencia General", :institution "Minimax Consultores, C.A.", :country "Venezuela, Bolivarian Republic of", :sessions (258)}, 10538 {:firstname "Richard", :lastname "Hartl", :department "Business Admin", :institution "University of Vienna", :country "Austria", :sessions (197 246 247 201)}, 10539 {:firstname "Snezana", :lastname "Mitrovic Minic", :department "", :institution "Simon Fraser University", :country "Canada", :sessions (187)}, 10542 {:firstname "Michael", :lastname "Bussieck", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (77 79 82)}, 10666 {:firstname "Chiara", :lastname "D'Alpaos", :department "Department of Civil  Architectural and Environmental Engineering", :institution "University of Padova", :country "Italy", :sessions (197)}, 10811 {:firstname "Cristinca", :lastname "Fulga", :department "Department of Applied Mathematics", :institution "The Bucharest University of Economic Studies", :country "Romania", :sessions (268)}, 10871 {:firstname "Diethard", :lastname "Klatte", :department "IBW", :institution "Universität Zürich", :country "Switzerland", :sessions (29 41 56 73 200 153)}, 10957 {:firstname "Pakize", :lastname "Taylan", :department "Mathematics", :institution "Dicle University", :country "Turkey", :sessions (62)}, 11001 {:firstname "Ameur", :lastname "Soukhal", :department "University of Tours", :institution "Computer Science Laboratory", :country "France", :sessions (202 64)}, 11248 {:firstname "Sandip", :lastname "Pindoria", :department "", :institution "Maximal Software Ltd", :country "United Kingdom", :sessions (90)}, 11260 {:firstname "Bartosz", :lastname "Sawik", :department "Department of Applied Computer Science", :institution "AGH University of Science & Technology", :country "Poland", :sessions (265)}, 11448 {:firstname "Tobias", :lastname "Buer", :department "Logistics, Tourism and Service Management", :institution "GUtech", :country "Oman", :sessions (190)}, 11599 {:firstname "Vladimir", :lastname "Zubov", :department "Mechanics of continuum media", :institution "Institution of Russian Academy of Sciences Dorodnicyn Computing Centre of RAS", :country "Russian Federation", :sessions (201)}, 11762 {:firstname "Josep", :lastname "Freixas", :department "Matemàtiques", :institution "Universitat Politècnica de Catalunya", :country "Spain", :sessions (136)}, 11799 {:firstname "David", :lastname "Pisinger", :department "DTU Management", :institution "Technical University of Denmark", :country "Denmark", :sessions (175)}, 11835 {:firstname "Gunnar", :lastname "Klau", :department "Life Sciences group", :institution "Centrum Wiskunde & Informatica (CWI)", :country "Netherlands", :sessions (68 69 65 67)}, 11884 {:firstname "Guillermo", :lastname "Owen", :department "", :institution "Naval Postgraduate School", :country "United States", :sessions (136)}, 11954 {:firstname "Bernd", :lastname "Kummer", :department "Mathematik", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (55 200)}, 11980 {:firstname "Kyoko", :lastname "Yagi", :department "Graduate School of Social Sciences", :institution "Tokyo Metropolitan University", :country "Japan", :sessions (267)}, 11993 {:firstname "Gleb", :lastname "Belov", :department "Numerical Mathematics", :institution "TU Dresden", :country "Germany", :sessions (148)}, 12024 {:firstname "Milos", :lastname "Kopa", :department "Department of Probability and Mathematical Statistics", :institution "Charles University in Prague, Faculty of Mathematics and Physics", :country "Czech Republic", :sessions (118)}, 12185 {:firstname "Sebastian", :lastname "Orlowski", :department "Optimization", :institution "atesio GmbH", :country "Germany", :sessions (211)}, 12231 {:firstname "Roland", :lastname "Wessäly", :department "", :institution "atesio GmbH", :country "Germany", :sessions (211)}, 12245 {:firstname "H.A.", :lastname "Eiselt", :department "", :institution "University of New Brunswick", :country "Canada", :sessions (177)}, 12336 {:firstname "Tobias", :lastname "Achterberg", :department "", :institution "Gurobi", :country "Germany", :sessions (228)}, 12346 {:firstname "Christoforos", :lastname "Charalambous", :department "", :institution "Frederick University", :country "Cyprus", :sessions (166)}, 12428 {:firstname "Ulrich", :lastname "Dorndorf", :department "", :institution "INFORM GmbH", :country "Germany", :sessions (203)}, 12453 {:firstname "Florian", :lastname "Jaehn", :department "Management Science and Operations Research", :institution "Helmut-Schmidt-University - University of the Federal Armed Forces Hamburg", :country "Germany", :sessions (140)}, 12473 {:firstname "Gianfranco", :lastname "Guastaroba", :department "Department of Economics and Management", :institution "University of Brescia", :country "Italy", :sessions (122)}, 12515 {:firstname "Petr", :lastname "Mariel", :department "Department of Applied Economics III", :institution "University of the Basque Country", :country "Spain", :sessions (131)}, 12583 {:firstname "Giorgia", :lastname "Oggioni", :department "Department of Economics and Management", :institution "University of Brescia, Italy", :country "Italy", :sessions (124 125)}, 12604 {:firstname "Michal", :lastname "Fendek", :department "Department of Operations Research and Econometrics", :institution "University of Economics in Bratislava", :country "Slovakia", :sessions (105)}, 12609 {:firstname "Milan", :lastname "Hladik", :department "Department of Applied Mathematics", :institution "Charles University, Faculty  of  Mathematics  and  Physics", :country "Czech Republic", :sessions (196)}, 12646 {:firstname "Marko", :lastname "Bohanec", :department "Department of Knowledge Technologies", :institution "Jožef Stefan Institute", :country "Slovenia", :sessions (254 255)}, 12659 {:firstname "Theodorus S.H. ", :lastname "Driessen", :department "Department of Applied Mathematics ", :institution "University of Twente", :country "Netherlands", :sessions (136)}, 12662 {:firstname "Roger", :lastname "Knight", :department "Operational Research", :institution "Cass Business School", :country "United Kingdom", :sessions (112)}, 12695 {:firstname "Ulrich", :lastname "Pferschy", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (146 172)}, 12763 {:firstname "Eleonora", :lastname "Fendekova", :department "Department of Business Economics", :institution "University of Economics in Bratislava", :country "Slovakia", :sessions (105)}, 12769 {:firstname "Eleni", :lastname "Pratsini", :department "", :institution "IBM Zurich Research Lab", :country "Switzerland", :sessions (169 224 231)}, 12952 {:firstname "Dirk Christian", :lastname "Mattfeld", :department "Business Information Systems", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (84)}, 13046 {:firstname "Alexander", :lastname "Martin", :department "Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (213 237 270)}, 13058 {:firstname "Andreas", :lastname "Bley", :department "Mathematics", :institution "Uni Kassel", :country "Germany", :sessions (211)}, 13086 {:firstname "Frank", :lastname "Meisel", :department "", :institution "Christian-Albrechts-University", :country "Germany", :sessions (223 186)}, 13094 {:firstname "Michael", :lastname "Hanke", :department "Institute for Financial Services", :institution "University of Liechtenstein", :country "Liechtenstein", :sessions (118)}, 13201 {:firstname "Tomomi", :lastname "Matsui", :department "Department of Social Engineering", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (143 241 208)}, 13264 {:firstname "Stephan", :lastname "Meisel", :department "Carl-Friedrich Gauss Department", :institution "University of Braunschweig", :country "Germany", :sessions (84)}, 13270 {:firstname "Nihat", :lastname "Kasap", :department "", :institution "Sabanci University", :country "Turkey", :sessions (121)}, 13364 {:firstname "Matthias", :lastname "Amen", :department "Chair for Quantitative Accounting & Financial Reporting", :institution "Bielefeld University", :country "Germany", :sessions (155 94)}, 13402 {:firstname "Sven", :lastname "Leyffer", :department "", :institution "Argonne National Lab", :country "United States", :sessions (232 60)}, 13458 {:firstname "Mario", :lastname "Veiga Pereira", :department "", :institution "PSR", :country "Brazil", :sessions (82)}, 13581 {:firstname "Jan", :lastname "Heerda", :department "Mathematik", :institution "Humboldt-Universitaet Berlin", :country "Germany", :sessions (55)}, 13695 {:firstname "Didier", :lastname "Henrion", :department "LAAS-CNRS", :institution "University of Toulouse", :country "France", :sessions (200)}, 13837 {:firstname "Uwe T.", :lastname "Zimmermann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (92 144 270)}, 13866 {:firstname "Florian", :lastname "Sahling", :department "Chair of Production Management", :institution "University of Kaiserslautern", :country "Germany", :sessions (161)}, 13952 {:firstname "FRANCIS", :lastname "ELLISON", :department "", :institution "BRUNEL UNIVERSITY", :country "United Kingdom", :sessions (119)}, 13972 {:firstname "Vassilis", :lastname "Angelis", :department "Business Administration", :institution "University of the Aegean", :country "Greece", :sessions (269)}, 14005 {:firstname "sujinda", :lastname "Chemsripong", :department "Faculty of Management and Information Science", :institution "Naresuan University ", :country "Thailand", :sessions (81)}, 14020 {:firstname "Mex", :lastname "Glawischnig", :department "Finance", :institution "KF Uni Graz", :country "Austria", :sessions (48 265)}, 14133 {:firstname "Enrico", :lastname "Miglierina", :department "Dipartimento di Discipline Matematiche, Finanza Matematica ed Econometria", :institution "Universita Cattolica del Sacro Cuore", :country "Italy", :sessions (78)}, 14137 {:firstname "Eric", :lastname "Taillard", :department "", :institution "HEIG-Vd", :country "Switzerland", :sessions (238)}, 14144 {:firstname "Ilaria", :lastname "Vacca", :department "Transport and Mobility Laboratory (Transp-OR)", :institution "École polytechnique fédérale de Lausanne (EPFL)", :country "Switzerland", :sessions (210)}, 14274 {:firstname "Guvenc", :lastname "Sahin", :department "Faculty of Engineering and Natural Sciences, Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (219)}, 14543 {:firstname "Miray Hanim", :lastname "Yildirim", :department "Institute of Applied Mathematics", :institution "Middle East Technical University", :country "Turkey", :sessions (62)}, 14545 {:firstname "Roland", :lastname "Mestel", :department "Banking and Finance", :institution "University of Graz", :country "Austria", :sessions (133 218)}, 14554 {:firstname "Savvas", :lastname "Pericleous", :department "", :institution "Frederick University", :country "Cyprus", :sessions (166)}, 14573 {:firstname "Ulrich", :lastname "Thonemann", :department "Supply Chain Management", :institution "Universtiy of Cologne", :country "Germany", :sessions (224)}, 14587 {:firstname "Pradyumn Kumar", :lastname "Shukla", :department "", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (57)}, 14588 {:firstname "Knut", :lastname "Haase", :department "Institut f. Verkehrswirtschaft, Lehrstuhl BWL, insb. Verkehr", :institution "Universität Hamburg", :country "Germany", :sessions (192)}, 14675 {:firstname "Franz", :lastname "Rothlauf", :department "Lehrstuhl für Wirtschaftsinformatik und BWL", :institution "Universität Mainz", :country "Germany", :sessions (159)}, 14688 {:firstname "Rafael", :lastname "Velásquez", :department "Logistics Optimisation", :institution "INFORM - Institut für Operations Research und Management", :country "Germany", :sessions (242)}, 14704 {:firstname "Felix", :lastname "Hahne", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (207)}, 14705 {:firstname "Curt", :lastname "Nowak", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (207)}, 14707 {:firstname "Christian", :lastname "Bierwirth", :department "", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (223 145 186)}, 14722 {:firstname "Knut", :lastname "Richter", :department "Faculty of Economics", :institution "St. Petersburg State university", :country "Russian Federation", :sessions (168)}, 14736 {:firstname "Benjamin", :lastname "Hiller", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (76)}, 14742 {:firstname "Sigrid", :lastname "Knust", :department "Institute of Computer Science", :institution "University of Osnabrück", :country "Germany", :sessions (52 141 53)}, 14755 {:firstname "Ulrich", :lastname "Derigs", :department "Information Systems and Operations Research", :institution "University of Cologne", :country "Germany", :sessions (85 246)}, 14762 {:firstname "Ulrich", :lastname "Vogel", :department "Department of Information Systems and Operations Research", :institution "University of Cologne", :country "Germany", :sessions (85)}, 14771 {:firstname "Thomas", :lastname "Schlechte", :department " ", :institution "LBW Optimization GmbH", :country "Germany", :sessions (240 92 144 270)}, 14773 {:firstname "Dennis", :lastname "Egbers", :department "Institut für Mathematische Optimierung", :institution "Technische Universität Braunschweig  ", :country "Germany", :sessions (196)}, 14775 {:firstname "Katsuaki", :lastname "Tanaka", :department "Faculty of Business Administration", :institution "Setsunan University", :country "Japan", :sessions (259)}, 14792 {:firstname "Simon", :lastname "Goertz", :department "Faculty of Economics", :institution "University of Wuppertal", :country "Germany", :sessions (214)}, 14800 {:firstname "Stefan", :lastname "Bock", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (161 53)}, 14803 {:firstname "Klaus ", :lastname "Ambrosi", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "Universität Hildesheim", :country "Germany", :sessions (207)}, 14810 {:firstname "Ursula", :lastname "Walther", :department "FB 1", :institution "Berlin School of Economics and Law", :country "Germany", :sessions (217 218)}, 14817 {:firstname "Ralph", :lastname "Grothmann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (109 107)}, 14818 {:firstname "Hans Georg", :lastname "Zimmermann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (109 107)}, 14828 {:firstname "Thorsten", :lastname "Gather", :department "Operations Research Group", :institution "Clausthal Institute of Technology", :country "Germany", :sessions (64)}, 14845 {:firstname "Christoph", :lastname "Weber", :department "", :institution "Universität Essen", :country "Germany", :sessions (125)}, 14847 {:firstname "Andreas", :lastname "Klose", :department "Department of Mathematics", :institution "Aarhus University", :country "Denmark", :sessions (221 191)}, 14874 {:firstname "Stijn", :lastname "De Vuyst", :department "Telecommunications and Information Processing", :institution "Ghent University", :country "Belgium", :sessions (52)}, 14876 {:firstname "Dominik", :lastname "Möst", :department "Chair of Energy Economics", :institution "Technische Universität Dresden", :country "Germany", :sessions (126)}, 14898 {:firstname "Lutz", :lastname "Westermann", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (79)}, 14923 {:firstname "Ralf", :lastname "Borndörfer", :department "Optimization", :institution "Zuse-Institute Berlin", :country "Germany", :sessions (209 190 92)}, 14924 {:firstname "Jörg", :lastname "Wansart", :department "", :institution "Institute for Production and Logistics Management", :country "Germany", :sessions (105)}, 14969 {:firstname "Marco", :lastname "Lübbecke", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (210)}, 14973 {:firstname "Michael", :lastname "Drexl", :department "", :institution ".", :country "Germany", :sessions (187)}, 14976 {:firstname "Jens", :lastname "Schulz", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (191 148)}, 15051 {:firstname "Eugenio", :lastname "Mijangos", :department "Applied Mathematics and Statistics and Operations Research", :institution "UPV/EHU", :country "Spain", :sessions (117)}, 15059 {:firstname "Marika", :lastname "Neumann", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (209)}, 15060 {:firstname "Jens", :lastname "Brunner", :department "Chair of Health Care Operations/Health Information Management", :institution "Faculty of Business and Economics, University of Augsburg", :country "Germany", :sessions (140)}, 15094 {:firstname "Refik", :lastname "Gullu", :department "Industrial Engineering Department", :institution "Bogazici University", :country "Turkey", :sessions (168)}, 15101 {:firstname "Armin", :lastname "Scholl", :department "Chair of Management Science and Decision Analysis", :institution "FSU Jena", :country "Germany", :sessions (164 147)}, 15118 {:firstname "Hans-Otto", :lastname "Guenther", :department "Industrial Engineering", :institution "Pusan National University", :country "Korea, Republic of", :sessions (162)}, 15127 {:firstname "Thomas", :lastname "Bousonville", :department "Business and Administration", :institution "Hochschule für Technik und Wirtschaft des Saarlandes", :country "Germany", :sessions (187)}, 15164 {:firstname "Steffen", :lastname "Schorpp", :department "Production&Logistics", :institution "Universität Augsburg", :country "Germany", :sessions (239)}, 15178 {:firstname "Kerstin", :lastname "Schmidt", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (167)}, 15182 {:firstname "Urs", :lastname "Pietschmann", :department "Faculty of Management and Economics", :institution "Ruhr-University Bochum", :country "Germany", :sessions (226)}, 15215 {:firstname "Nahit", :lastname "Serarslan", :department "", :institution "Technical University of Istanbul", :country "Turkey", :sessions (121)}, 15277 {:firstname "Herbert", :lastname "Kopfer", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (187 85 246 84 190 179)}, 15324 {:firstname "Florian", :lastname "Seeanner", :department "Rechts- und Wirtschaftswissenschaften", :institution "Fachgebiet Produktion & Supply Chain Management", :country "Germany", :sessions (161)}, 15375 {:firstname "Ronny", :lastname "Hansmann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (92 144)}, 15381 {:firstname "Andreas", :lastname "Thümmel", :department "FB MN", :institution "Hochschule Darmstadt", :country "Germany", :sessions (128)}, 15390 {:firstname "Kai", :lastname "Wittek", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (222)}, 15424 {:firstname "Secil", :lastname "Savasaneril", :department "Department of Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (163 181)}, 15482 {:firstname "Alessio", :lastname "Ishizaka", :department "Portsmouth Business School", :institution "University of Portsmouth", :country "United Kingdom", :sessions (255)}, 15649 {:firstname "Lea M.", :lastname "Wakolbinger", :department "Department of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (130)}, 15688 {:firstname "Elmar", :lastname "Kiesling", :department "Department of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (130)}, 15802 {:firstname "Verena", :lastname "Schmid", :department "Supply Chain Management", :institution "Europa-Universität Viadrina", :country "Germany", :sessions (246)}, 15857 {:firstname "Johannes", :lastname "Ruhland", :department "University of Jena", :institution "Faculty of Business and Economics", :country "Germany", :sessions (177 131)}, 15898 {:firstname "Tuukka", :lastname "Puranen", :department "Department of Mathematical Information Technology", :institution "University of Jyväskylä", :country "Finland", :sessions (242)}, 15948 {:firstname "Dag", :lastname "Haugland", :department "Department of Informatics", :institution "University of Bergen", :country "Norway", :sessions (206)}, 16003 {:firstname "Farouk", :lastname "Yalaoui", :department "Institut Charles Delaunay, ICD LOSI", :institution "University of Technology of Troyes", :country "France", :sessions (163 147)}, 16036 {:firstname "Yun Fong", :lastname "Lim", :department "Lee Kong Chian School of Business", :institution "Singapore Management University", :country "Singapore", :sessions (225)}, 16156 {:firstname "Sofie", :lastname "Coene", :department "ORSTAT", :institution "KULeuven", :country "Belgium", :sessions (141)}, 16165 {:firstname "Alessandra", :lastname "Buratto", :department "Department of Mathematics", :institution "University of Padova", :country "Italy", :sessions (197)}, 16315 {:firstname "Armin", :lastname "Fügenschuh", :department "MINT", :institution "Brandenburg Technical University", :country "Germany", :sessions (76 92 270)}, 16320 {:firstname "Marta S. R. ", :lastname "Monteiro", :department "Faculdade de Economia and LIAAD-INESC Porto L.A.", :institution "Universidade do Porto", :country "Portugal", :sessions (149)}, 16606 {:firstname "Jörg", :lastname "Rambau", :department "Fakultät für Mathematik, Physik und Informatik", :institution "LS Wirtschaftsmathematik", :country "Germany", :sessions (242)}, 16639 {:firstname "Sven", :lastname "Müller", :department "Transport Business Economics", :institution "Karlsruhe University of Applied Sciences", :country "Germany", :sessions (192)}, 16717 {:firstname "Cornelius", :lastname "Schwarz", :department "Chair of Business Mathematics", :institution "University of Bayreuth", :country "Germany", :sessions (145)}, 16808 {:firstname "Krystsina", :lastname "Bakhrankova", :department "Applied economics", :institution "SINTEF - Technology and society", :country "Norway", :sessions (139)}, 16855 {:firstname "Gerald", :lastname "Hubmann", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (172)}, 16870 {:firstname "Katja", :lastname "Schimmelpfeng", :department "Lehrstuhl für Beschaffung und Produktion", :institution "Universität Hohenheim", :country "Germany", :sessions (271)}, 16880 {:firstname "Timo", :lastname "Berthold", :department "", :institution "Fair Isaac Germany GmbH", :country "Germany", :sessions (227 228)}, 16918 {:firstname "Martin", :lastname "Stöcker", :department "Fakultät Mathematik, Professur Wirtschaftsmathematik", :institution "Technische Universität Chemnitz", :country "Germany", :sessions (195)}, 16923 {:firstname "Guntram", :lastname "Scheithauer", :department "Mathematik", :institution "Technische Universität Dresden", :country "Germany", :sessions (148)}, 16928 {:firstname "Utz-Uwe", :lastname "Haus", :department "", :institution "Cray EMEA Research Lab", :country "Switzerland", :sessions (206 212)}, 16972 {:firstname "Nam Dung", :lastname "Hoang", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (150)}, 16975 {:firstname "Holger", :lastname "Flier", :department "Institute of Theoretical Computer Science", :institution "ETH Zürich", :country "Switzerland", :sessions (245)}, 16987 {:firstname "Florian", :lastname "Bruns", :department "Institute of Computer Science", :institution "University of Osnabrück", :country "Germany", :sessions (141)}, 16988 {:firstname "Frank", :lastname "Fischer", :department "Mathematics and Natural Sciences", :institution "University of Kassel", :country "Germany", :sessions (92)}, 17006 {:firstname "Christoph", :lastname "Helmberg", :department "Fakultät für Mathematik", :institution "Technische Universität Chemnitz", :country "Germany", :sessions (211 204 92)}, 17023 {:firstname "Philipp", :lastname "Baumann", :department "Department of Industrial Engineering and Operations Research", :institution "University of California, Berkeley", :country "United States", :sessions (163 266)}, 17039 {:firstname "Rainer", :lastname "Kleber", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University of Magdeburg", :country "Germany", :sessions (224)}, 17041 {:firstname "Andreas", :lastname "Fischer", :department "Department of Mathematics", :institution "Technische Universität Dresden", :country "Germany", :sessions (57)}, 17055 {:firstname "Joachim", :lastname "Schauer", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (145)}, 17063 {:firstname "Rico", :lastname "Zenklusen", :department "Department of Mathematics", :institution "ETH Zurich", :country "Switzerland", :sessions (169 103 212)}, 17083 {:firstname "Marc", :lastname "Pfetsch", :department "Discrete Optimization", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (209)}, 17092 {:firstname "Christina", :lastname "Büsing", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (202 245)}, 17125 {:firstname "Wiebke ", :lastname "Höhn", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (163)}, 17127 {:firstname "Marco", :lastname "Laumanns", :department "", :institution "Bestmile SA", :country "Switzerland", :sessions (10 30 19 104 169 103 192 245 234)}, 17130 {:firstname "Matthias Gerhard", :lastname "Wichmann", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (53)}, 17134 {:firstname "Felix G.", :lastname "König", :department "", :institution "TomTom International B.V.", :country "Germany", :sessions (209 191)}, 17325 {:firstname "Matthias", :lastname "Walter", :department "Institut für Wirtschaftswissenschaft", :institution "Technische Universität Clausthal", :country "Germany", :sessions (64)}, 17331 {:firstname "Christian", :lastname "Rathjen", :department "", :institution "Dassault Systèmes", :country "Germany", :sessions (53)}, 17336 {:firstname "Roberto", :lastname "Montemanni", :department "(IDSIA)", :institution "Istituto Dalle Molle di Studi sull'Intelligenza Artificiale", :country "Switzerland", :sessions (247)}, 17358 {:firstname "Sebastian", :lastname "Rachuba", :department "Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (88)}, 17364 {:firstname "Karsten", :lastname "Kieckhäfer", :department "Chair of Business Administration, esp. Resource Management", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (105)}, 17483 {:firstname "Stefan", :lastname "Mayer", :department "Department of Analytics & Optimization", :institution "University of Augsburg", :country "Germany", :sessions (98)}, 17501 {:firstname "Harold", :lastname "Tiemessen", :department "Mathematical and Computational Sciences", :institution "IBM Research", :country "Switzerland", :sessions (224)}, 17524 {:firstname "Xin", :lastname "Wang", :department "Business Studies & Economics, University of Bremen", :institution "Chair of Logistics", :country "Germany", :sessions (85 246)}, 17597 {:firstname "Boris", :lastname "Amberg", :department "Information Process Engineering", :institution "FZI Research Center for Information Technology", :country "Germany", :sessions (187)}, 17621 {:firstname "Josef", :lastname "Kallrath", :department "GMC/MS - B 9", :institution "BASF SE", :country "Germany", :sessions (79)}, 17649 {:firstname "Bernardo", :lastname "Almada-Lobo", :department "", :institution "INESC-TEC, Faculty of Engineering of Porto University", :country "Portugal", :sessions (162 189)}, 17686 {:firstname "Uli", :lastname "Suppa", :department "Institut für Wirtschaftsinformatik", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (84)}, 17949 {:firstname "Joanna", :lastname "Józefowska", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (50)}, 18006 {:firstname "Winfried", :lastname "Steiner", :department "Marketing", :institution "Clausthal University of Technology, Institute of Management and Economics", :country "Germany", :sessions (257)}, 18125 {:firstname "Sacha", :lastname "Varone", :department "Economie d'Entreprise", :institution "Haute Ecole de Gestion de Genève", :country "Switzerland", :sessions (142)}, 18342 {:firstname "Miro", :lastname "Gradisar", :department "", :institution "Univ. of Ljubljana, Faculty for economy", :country "Slovenia", :sessions (195)}, 18480 {:firstname "Raimund", :lastname "Kovacevic", :department "DB04 J03", :institution "Institut für Stochastik und Wirtschaftsmathematik, ORCOS", :country "Austria", :sessions (119)}, 18584 {:firstname "Andrey", :lastname "Albu", :department "Applied optimization problems", :institution "Institution of Russian Academy of Sciences Dorodnicyn Computing Centre of RAS", :country "Russian Federation", :sessions (201)}, 18644 {:firstname "Megha", :lastname "Sharma", :department "Operations Management", :institution "Indian Institute of Management Calcutta", :country "India", :sessions (206)}, 18744 {:firstname "David", :lastname "Bartl", :department "Department of Informatics and Mathematics", :institution "Silesian University in Opava / School of Business Administration in Karviná", :country "Czech Republic", :sessions (196)}, 18856 {:firstname "Waldemar", :lastname "Kaczmarczyk", :department "Department of Operations Research", :institution "AGH University of Science and Technology", :country "Poland", :sessions (165)}, 18887 {:firstname "Duan", :lastname "Li", :department "Associate Provost (Strategic Planning), Chair Professor of Operations Research and Acting Dean School of Data Science", :institution "City University of Hong Kong", :country "Hong Kong", :sessions (204)}, 19001 {:firstname "Fabien", :lastname "Tricoire", :department "Institute for Production and Logistics Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (247)}, 19047 {:firstname "Matúš", :lastname "Mihalák", :department "Dept. of Data Science and Knowledge Engineering", :institution "Maastricht University", :country "Netherlands", :sessions (245)}, 19076 {:firstname "Jens", :lastname "Poppenborg", :department "Institute of Applied Stochastics and Operations Research", :institution "Clausthal University of Technology", :country "Germany", :sessions (53)}, 19080 {:firstname "Hans-Jörg", :lastname "von Mettenheim", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (124 109 107)}, 19086 {:firstname "Thomas", :lastname "Surowiec", :department "Department of Mathematics", :institution "Humboldt University of Berlin", :country "Germany", :sessions (200)}, 19095 {:firstname "Deniz", :lastname "Türsel Eliiyi", :department "Industrial Engineering", :institution "Yasar University", :country "Turkey", :sessions (145 185)}, 19100 {:firstname "Michael H.", :lastname "Breitner", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (124 107)}, 19122 {:firstname "Martin", :lastname "Mevissen", :department "", :institution "IBM Research - Ireland", :country "Ireland", :sessions (200)}, 19147 {:firstname "Ambros", :lastname "Gleixner", :department "Department of Mathematical Optimization", :institution "Zuse Institute Berlin (ZIB)", :country "Germany", :sessions (213)}, 19168 {:firstname "Andreas", :lastname "Löhne", :department "Institut für Mathematik", :institution "FSU Jena", :country "Germany", :sessions (78)}, 19182 {:firstname "Marie", :lastname "Schmidt", :department "Rotterdam School of Management", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (245)}, 19185 {:firstname "Efsun", :lastname "Kürüm", :department "Department of Banking and Finance", :institution "Near East University", :country "Cyprus", :sessions (62)}, 19221 {:firstname "Uğur", :lastname "Eliiyi", :department "Computer Science", :institution "Dokuz Eylül University", :country "Turkey", :sessions (147)}, 19264 {:firstname "Martin", :lastname "Fuchsberger", :department "D-Math, Insitute for Operations Research", :institution "ETH Zurich", :country "Switzerland", :sessions (245)}, 19271 {:firstname "Reinhard", :lastname "Bürgy", :department "Dept of Informatics", :institution "University of Fribourg", :country "Switzerland", :sessions (145)}, 19297 {:firstname "Catherine", :lastname "Cleophas", :department "Service Analytics", :institution "CAU Kiel University", :country "Germany", :sessions (98 99)}, 19332 {:firstname "Guido", :lastname "Diepen", :department "", :institution "AIMMS", :country "Netherlands", :sessions (241)}, 19359 {:firstname "Hasan Huseyin", :lastname "TURAN", :department "", :institution "University of Yalova", :country "Turkey", :sessions (121)}, 19424 {:firstname "Sonja", :lastname "Friedrich", :department "Fachbereich Mathematik", :institution "TU Darmstadt", :country "Germany", :sessions (213)}, 19441 {:firstname "Lars", :lastname "Schewe", :department "Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (213)}, 19447 {:firstname "Özalp", :lastname "Vayvay", :department "Chairman of Engineering Management Department", :institution "Marmara University Institute of Pure and Applied Sciences", :country "Turkey", :sessions (168)}, 19462 {:firstname "Sleman", :lastname "Saliba", :department "Power Generation", :institution "ABB AG", :country "Germany", :sessions (144)}, 19473 {:firstname "Halis", :lastname "Sak", :department "Department of Mathematical Sciences", :institution "Xi'an Jiaotong-Liverpool University", :country "China", :sessions (216)}, 19477 {:firstname "Sven", :lastname "Krumke", :department "Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (209 144)}, 19514 {:firstname "Sebastian", :lastname "Pokutta", :department "Department of Mathematics", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (270)}, 19523 {:firstname "Nico", :lastname "Dellaert", :department "IE&IS", :institution "Technische Universiteit Eindhoven", :country "Netherlands", :sessions (171)}, 19525 {:firstname "Vadim", :lastname "Strijov", :department "", :institution "Russian Academy of Sciences, FRC Computer Science and Control", :country "Russian Federation", :sessions (254 108)}, 19530 {:firstname "Jully", :lastname "Jeunet", :department "Université Paris-Dauphine", :institution "CNRS, Lamsade", :country "France", :sessions (171)}, 19582 {:firstname "Kaspar", :lastname "Schüpbach", :department "Institute for Operations Research", :institution "ETH Zurich", :country "Switzerland", :sessions (182)}, 19607 {:firstname "Heinz", :lastname "Gröflin", :department "Dept of Informatics", :institution "University of Fribourg", :country "Switzerland", :sessions (145)}, 19612 {:firstname "Montserrat", :lastname "Pons", :department "Mathemàtiques", :institution "Universitat Politècnica de Catalunya", :country "Spain", :sessions (136)}, 19615 {:firstname "Michel", :lastname "Baes", :department "IFOR", :institution "ETH", :country "Switzerland", :sessions (63 264 61 60)}, 19625 {:firstname "Matteo", :lastname "Salani", :department "", :institution "IDSIA - USI/SUPSI", :country "Switzerland", :sessions (210 141)}, 19666 {:firstname "Stefan", :lastname "Wrzaczek", :department "Vienna Institute of Demography", :institution "Wittgenstein Centre", :country "Austria", :sessions (198)}, 19669 {:firstname "Michael", :lastname "Kuhn", :department "", :institution "Vienna Institute of Demography", :country "Austria", :sessions (198)}, 19677 {:firstname "Michael", :lastname "Bürgisser", :department "", :institution "IFOR, ETH Zurich", :country "Switzerland", :sessions (61 60)}, 19703 {:firstname "Haoxun", :lastname "Chen", :department "Institut Charles Delaunay and UMR CNRS STMR 6279", :institution "Université de Technologie de Troyes", :country "France", :sessions (169)}, 19731 {:firstname "Maria", :lastname "Mavri", :department "Business Administration", :institution "University of the Aegean", :country "Greece", :sessions (269)}, 19750 {:firstname "F. Tevhide", :lastname "Altekin", :department "Sabanci School of Management", :institution "Sabanci University", :country "Turkey", :sessions (164)}, 19832 {:firstname "Matthieu", :lastname "Chardy", :department "CORE/M2V", :institution "Orange Labs", :country "France", :sessions (104)}, 19846 {:firstname "Hector", :lastname "Carlo", :department "Industrial Engineering", :institution "University of Puerto Rico-Mayaguez", :country "Puerto Rico", :sessions (92)}, 19982 {:firstname "Carola", :lastname "Schrage", :department "", :institution "", :country "Germany", :sessions (78)}, 20053 {:firstname "Nihan", :lastname "Karaca", :department "Industrial Engineering", :institution "Istanbul Kultur University", :country "Turkey", :sessions (121)}, 20092 {:firstname "Özlem", :lastname "Türker Bayrak", :department "Industrial Engineering Department", :institution "Çankaya University", :country "Turkey", :sessions (62)}, 20135 {:firstname "Seda", :lastname "Yanık", :department "Industrial Engineering", :institution "Istanbul Technical University", :country "Turkey", :sessions (186)}, 20142 {:firstname "Ken-ichi", :lastname "Tanaka", :department "", :institution "The University of Electro-Communications", :country "Japan", :sessions (221)}, 20170 {:firstname "Ufuk", :lastname "Kula", :department "Industrial Engineering", :institution "Sakarya University", :country "Turkey", :sessions (122)}, 20200 {:firstname "Berc", :lastname "Rustem", :department "Department of Computing", :institution "Imperial College", :country "United Kingdom", :sessions (117)}, 20382 {:firstname "Somnath", :lastname "Mukhopadhyay", :department "Marketing and Management", :institution "The University of Texas at El Paso", :country "United States", :sessions (88)}, 20420 {:firstname "Rolf", :lastname "Möhring", :department "", :institution "Beijing Institute for Scientific and Engineering Computing", :country "China", :sessions (163 190)}, 20485 {:firstname "Ayse", :lastname "Özmen", :department "Mathematics and Statistics", :institution "University of Calgary", :country "Canada", :sessions (62)}, 20539 {:firstname "Sophie", :lastname "Parragh", :department "Institute of Production and Logistics Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (189)}, 20607 {:firstname "Vladimir", :lastname "Shikhman", :department "", :institution "TU Chemnitz", :country "Germany", :sessions (73 200)}, 20679 {:firstname "Guillaume", :lastname "Sagnol", :department "Optimization", :institution "ZIB", :country "Germany", :sessions (190)}, 20767 {:firstname "Ufuk", :lastname "Kula", :department "Industrial Engineering", :institution "Sakarya University", :country "Turkey", :sessions (222 101 240)}, 20821 {:firstname "Abbas", :lastname "Seifi", :department "Head of Industrial Engineering and Productivity Research Center", :institution "Amirkabir University of Technology", :country "Iran, Islamic Republic of", :sessions (247)}, 20825 {:firstname "Frederic", :lastname "Murphy", :department "Fox School of Business and Management", :institution "Temple University", :country "United States", :sessions (125)}, 20832 {:firstname "Grigory", :lastname "Pishchulov", :department "", :institution "University of Manchester; St. Petersburg State University", :country "United Kingdom", :sessions (168)}, 20857 {:firstname "Hossein", :lastname "Abouee-Mehrizi ", :department "", :institution "University of Toronto", :country "Canada", :sessions (223)}, 20910 {:firstname "Andreas", :lastname "Novak", :department "Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (197)}, 20930 {:firstname "Miklos", :lastname "Kresz", :department "Department of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (219)}, 20937 {:firstname "Kathrin", :lastname "Fischer", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology (TUHH)", :country "Germany", :sessions (185 99)}, 20939 {:firstname "József", :lastname "Békési", :department "Department of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (219)}, 20940 {:firstname "Andrej", :lastname "Brodnik", :department "", :institution "University of Primorska, PINT", :country "Slovenia", :sessions (238)}, 20972 {:firstname "Bo", :lastname "Hu", :department "Department of Management", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (253 128)}, 21108 {:firstname "Reinhard", :lastname "Madlener", :department "School of Business and Economics / E.ON Energy Research Center", :institution "RWTH Aachen University", :country "Germany", :sessions (130)}, 21117 {:firstname "Peter", :lastname "Scholz", :department "Banking & Finance", :institution "Hamburg School of Business Administration", :country "Germany", :sessions (218)}, 21140 {:firstname "Stephan", :lastname "Buetikofer", :department "Institute of Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (73)}, 21172 {:firstname "Alain B.", :lastname "Zemkoho", :department "School of Mathematics", :institution "University of Birmingham", :country "United Kingdom", :sessions (55 196 71)}, 21636 {:firstname "Jason", :lastname "Atkin", :department "School of Computer Science", :institution "University of Nottingham", :country "United Kingdom", :sessions (148)}, 22042 {:firstname "Ivana", :lastname "Ljubic", :department "IDS", :institution "ESSEC Business School of Paris", :country "France", :sessions (211)}, 22048 {:firstname "Werner", :lastname "Hürlimann", :department "", :institution "FRSGlobal Switzerland", :country "Switzerland", :sessions (268)}, 22119 {:firstname "Torben", :lastname "Barth", :department "", :institution "DTU Management / Fraport AG", :country "Germany", :sessions (175)}, 22160 {:firstname "Jakob", :lastname "Puchinger", :department "LGI", :institution "CentraleSupélec, IRT-SystemX", :country "France", :sessions (191)}, 22274 {:firstname "Israel", :lastname "Tirkel", :department "Industrial Engineering & Management", :institution "Ben-Gurion University", :country "Israel", :sessions (164)}, 22326 {:firstname "Azar", :lastname "Karimov", :department "Financial Mathematics", :institution "Institute of Applied Mathematics, Middle East Technical University", :country "Turkey", :sessions (62)}, 22409 {:firstname "Sonia", :lastname "Cafieri", :department "", :institution "ENAC - Ecole Nationale d'Aviation Civile", :country "France", :sessions (175)}, 22442 {:firstname "Fatma", :lastname "Yerlikaya Özkurt", :department "Industrial Engineering", :institution "Atılım University", :country "Turkey", :sessions (62)}, 22499 {:firstname "Gloria", :lastname "Perez", :department "Applied Mathematics and Statistics and Operational Research", :institution "Universidad del País Vasco", :country "Spain", :sessions (118 117)}, 22515 {:firstname "Khaled", :lastname "Sellami", :department "LMA Laboratory", :institution "Bejaia University", :country "Algeria", :sessions (238)}, 22533 {:firstname "Lynda", :lastname "Sellami", :department "Sciences de Gestion", :institution "Université de Bejaia", :country "Algeria", :sessions (238)}, 22710 {:firstname "Vladimir", :lastname "Veliov", :department "Institute of Statistics and Mathematical Methods in Economics", :institution "Vienna University of Technology", :country "Austria", :sessions (201)}, 22715 {:firstname "Xiuli", :lastname "Chao", :department "IOE", :institution "University of Michigan", :country "United States", :sessions (115)}, 22740 {:firstname "Dennis", :lastname "Weyland", :department "", :institution "IDSIA", :country "Switzerland", :sessions (159 247)}, 22798 {:firstname "Tony", :lastname "Hürlimann", :department "Departement of Informatics", :institution "University of Fribourg", :country "Switzerland", :sessions (143)}, 22799 {:firstname "Anna", :lastname "Galluccio", :department "", :institution "IASI-CNR", :country "Italy", :sessions (229)}, 22855 {:firstname "Stefan", :lastname "Ravizza", :department "School of Computer Science", :institution "University of Nottingham", :country "United Kingdom", :sessions (148)}, 22874 {:firstname "Vladimir", :lastname "Beresnev", :department "Operation Research", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (205)}, 22875 {:firstname "Diana", :lastname "Roman", :department "Mathematics", :institution "Brunel University", :country "United Kingdom", :sessions (264)}, 22893 {:firstname "Odile", :lastname "Bellenguez-Morineau", :department "Automatique et Productique", :institution "Ecole des Mines de Nantes", :country "France", :sessions (51)}, 22897 {:firstname "Bettina", :lastname "Berning", :department "Decision Support Systems", :institution "Fraunhofer SCS", :country "Germany", :sessions (187)}, 22949 {:firstname "Ricardo", :lastname "Josa-Fombellida", :department "Estadística e Investigación Operativa and IMUVA", :institution "Universidad de Valladolid", :country "Spain", :sessions (265)}, 22964 {:firstname "Francesc", :lastname "Carreras", :department "Applied Mathematics II", :institution "Technical University of Catalonia", :country "Spain", :sessions (136)}, 22992 {:firstname "Fadime", :lastname "Üney-Yüksektepe", :department "Industrial Engineering Department", :institution "İstanbul Kültür University", :country "Turkey", :sessions (144)}, 22994 {:firstname "Jochen", :lastname "Gönsch", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (102 98)}, 23024 {:firstname "Sascha", :lastname "Kurz", :department "Mathematics, Physics and Computer Science", :institution "University of Bayreuth", :country "Germany", :sessions (242)}, 23038 {:firstname "Yue", :lastname "Wu", :department "School of Management", :institution "University of Southampton", :country "United Kingdom", :sessions (162)}, 23051 {:firstname "María Araceli", :lastname "Garín", :department "Applied Economy III", :institution "UPV/EHU", :country "Spain", :sessions (118 117)}, 23103 {:firstname "Philipp", :lastname "Hornung", :department "", :institution "", :country "Austria", :sessions (133 218)}, 23114 {:firstname "Pedro", :lastname "Amorim", :department "Industrial Engineering and Management", :institution "Faculty of Engineering of University of Porto", :country "Portugal", :sessions (162)}, 23119 {:firstname "Gernot", :lastname "Hinterleitner", :department "", :institution "", :country "Austria", :sessions (133 218)}, 23128 {:firstname "Julia", :lastname "Sender", :department "Institute of Transport Logistics", :institution "TU Dortmund", :country "Germany", :sessions (242 270)}, 23133 {:firstname "Steve", :lastname "Zymler", :department "Computing", :institution "Imperial College London", :country "United Kingdom", :sessions (117)}, 23153 {:firstname "Bernur", :lastname "Acikgoz", :department "Institute of Research in Economics", :institution "University of Neuchatel", :country "Switzerland", :sessions (259)}, 23155 {:firstname "Alexander", :lastname "Mack", :department "Engineering and Information Technology", :institution "Bern University of Applied Sciences", :country "Switzerland", :sessions (259)}, 23224 {:firstname "Chanaka", :lastname "Edirisinghe", :department "Lally School of Management", :institution "Rensselaer Polytechnic Institute", :country "United States", :sessions (118)}, 23254 {:firstname "Peter M.", :lastname "Kort", :department "", :institution "University of Tilburg", :country "Netherlands", :sessions (197 201)}, 23268 {:firstname "Greet", :lastname "Vanden Berghe", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (141)}, 23312 {:firstname "Claus", :lastname "Gwiggner", :department "Operations Research", :institution "University of Hamburg", :country "Germany", :sessions (175)}, 23362 {:firstname "Heiko ", :lastname "Kopfer", :department "Engineering", :institution "Institut für Konstruktion - MVP", :country "Germany", :sessions (85)}, 23371 {:firstname "Andrea", :lastname "Seidl", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (197)}, 23372 {:firstname "Dieter", :lastname "Grass", :department "", :institution "Vienna University of Technology", :country "Austria", :sessions (197)}, 23383 {:firstname "Jorge", :lastname "Navas", :department "Dpt. de Matematica economica, financera i actuarial", :institution "Universitat de Barcelona", :country "Spain", :sessions (265)}, 23438 {:firstname "Gerhard", :lastname "Reichmann", :department "Department of Information Science and Information Systems", :institution "University of Graz", :country "Austria", :sessions (81)}, 23440 {:firstname "Adolf", :lastname "Stepan", :department "", :institution "Technical University Vienna", :country "Austria", :sessions (48)}, 23451 {:firstname "Gerd J.", :lastname "Hahn", :department "", :institution "German Graduate School of Management and Law", :country "Germany", :sessions (166)}, 23455 {:firstname "Alexandra", :lastname "Hartmann", :department "Business School", :institution "University of Applied Sciences, Saarland", :country "Germany", :sessions (187)}, 23461 {:firstname "Narcisa", :lastname "Apreutesei", :department "Department of Mathematics", :institution "Technical University ", :country "Romania", :sessions (198)}, 23469 {:firstname "Frank", :lastname "Schwaderer", :department "Institute for Industrial Production (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (128)}, 23499 {:firstname "Dalila", :lastname "Fontes", :department "", :institution "LIAAD, INESC TEC, Faculdade de Economia do Porto, Universidade do Porto", :country "Portugal", :sessions (149)}, 23511 {:firstname "Jenny", :lastname "Nossack", :department "Institute of Information Systems", :institution "University of Siegen", :country "Germany", :sessions (228)}, 23580 {:firstname "Hamish", :lastname "Waterer", :department "School of Mathematical and Physical Sciences", :institution "University of Newcastle", :country "Australia", :sessions (164)}, 23582 {:firstname "David", :lastname "Alderson", :department "Operations Research Dept.", :institution "Naval Postgraduate School", :country "United States", :sessions (234)}, 23701 {:firstname "Marc", :lastname "Naumann", :department "Decision Support & Operations Research Lab", :institution "University of Paderborn", :country "Germany", :sessions (219)}, 23706 {:firstname "Evelina ", :lastname "Trutnevyte", :department "Institute for Environmental Decisions (IED), Natural and Social Science Interface (NSSI)", :institution "ETH Zurich", :country "Switzerland", :sessions (251 254)}, 23714 {:firstname "Elmar", :lastname "Swarat", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (190)}, 23719 {:firstname "Gennady", :lastname "Zabudsky", :department "Laboratory of Discrete Optimization", :institution "Omsk Branch of Sobolev Institute of Mathematics Siberian Branch of Russian Academy of Sciences", :country "Russian Federation", :sessions (204)}, 23724 {:firstname "Rossana", :lastname "Riccardi", :department "Economics and Management", :institution "University of Brescia", :country "Italy", :sessions (124)}, 23738 {:firstname "Bastian", :lastname "Amberg", :department "Department of Information Systems", :institution "Freie Universitaet Berlin", :country "Germany", :sessions (187)}, 23745 {:firstname "Thomas", :lastname "Lehmann", :department "Optimization", :institution "Konrad-Zuse-Zentrum", :country "Germany", :sessions (76 60)}, 23746 {:firstname "Michael", :lastname "Guarisco", :department "", :institution "n.a.", :country "Switzerland", :sessions (103)}, 23775 {:firstname "Stefanie", :lastname "Kritzinger", :department "Department of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (247)}, 23789 {:firstname "Isabel", :lastname "Correia", :department "Departamento de Matemática- CMA", :institution "FCT-Universidade Nova de Lisboa", :country "Portugal", :sessions (191)}, 23827 {:firstname "Johannes", :lastname "Hatzl", :department "Department of Optimization and Discrete Mathematics", :institution "Graz University of Technology", :country "Austria", :sessions (206 214)}, 23875 {:firstname "Frank", :lastname "Schneider", :department "", :institution "INFORM -GmbH", :country "Germany", :sessions (203)}, 23876 {:firstname "Stefan", :lastname "Heinz", :department "", :institution "Xpress Optimization, FICO", :country "Germany", :sessions (240 227 270 148)}, 23883 {:firstname "Necati", :lastname "Aras", :department "Industrial Engineering", :institution "Bogazici University", :country "Turkey", :sessions (168)}, 23890 {:firstname "ÖZLEM", :lastname "ŞENVAR", :department "Industrial Engineering Department", :institution "Marmara University Faculty of Engineering", :country "Turkey", :sessions (222)}, 23909 {:firstname "Oliver", :lastname "Exler", :department "Department of Computer Science", :institution "University of Bayreuth", :country "Germany", :sessions (60)}, 24021 {:firstname "Elke", :lastname "Eisenschmidt", :department "Deptartment of Mathematical Optimization", :institution "Otto-von-Guericke Universität", :country "Germany", :sessions (206)}, 24034 {:firstname "Sakae", :lastname "Nagaoka", :department "Air Traffic Management", :institution "Electronic Navigation Research Institute", :country "Japan", :sessions (175)}, 24063 {:firstname "Tilak Raj", :lastname "Singh", :department "MFTBC, IT-Big Data and Analytics", :institution "Daimler Trucks Asia- Japan", :country "Japan", :sessions (226)}, 24074 {:firstname "Jens", :lastname "Baudach", :department "Institute of Transport Logistics", :institution "TU Dortmund University", :country "Germany", :sessions (242)}, 24091 {:firstname "Michael", :lastname "Stauffacher", :department "Institute for Environmental Decisions (IED) Natural and Social Science Interface (NSSI)", :institution "ETH Zurich", :country "Switzerland", :sessions (251)}, 24093 {:firstname "Roland W. ", :lastname "Scholz", :department "Institute for Environmental Decisions (IED), Natural and Social Science Interface (NSSI)", :institution "ETH Zurich", :country "Switzerland", :sessions (251 258)}, 24105 {:firstname "Sumanta", :lastname "Basu", :department "Operations Management", :institution "Indian Institute of Management Calcutta", :country "India", :sessions (238)}, 24125 {:firstname "Sabrina", :lastname "Wiedersheim", :department "D-Math", :institution "ETH Zurich", :country "Switzerland", :sessions (192)}, 24129 {:firstname "Filipa", :lastname "Duarte Carvalho", :department "Matematica", :institution "ISEG/UTL; CIO", :country "Portugal", :sessions (228)}, 24131 {:firstname "Judith", :lastname "Huelle", :department "Chair of Management Accounting and Control", :institution "University of Goettingen", :country "Germany", :sessions (261)}, 24132 {:firstname "Maria Teresa", :lastname "Almeida", :department "Matematica", :institution "ISEG/UTL; CIO", :country "Portugal", :sessions (228)}, 24295 {:firstname "Tobias", :lastname "Klatt", :department "Department of Economic Studies", :institution "Göttingen University", :country "Germany", :sessions (261)}, 24343 {:firstname "Claudia", :lastname "Gotzes", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (76)}, 24367 {:firstname "Tülin", :lastname "Aktin", :department "Industrial Engineering Department", :institution "Istanbul Kültür University", :country "Turkey", :sessions (222)}, 24375 {:firstname "Felipe", :lastname "Baesler", :department "Industrial Engineering", :institution "Universidad del Desarrollo", :country "Chile", :sessions (160)}, 24413 {:firstname "Marcus", :lastname "Poggi", :department "Informatica", :institution "PUC-Rio", :country "Brazil", :sessions (182)}, 24562 {:firstname "Ozlem", :lastname "Cosgun", :department "Industrial Engineering", :institution "Fatih University", :country "Turkey", :sessions (101)}, 24616 {:firstname "Christina", :lastname "Burt", :department "Mathematics and Statistics", :institution "University of Melbourne", :country "Australia", :sessions (191)}, 24622 {:firstname "Jutta", :lastname "Geldermann", :department "Chair of Business Administration and Production Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (251 261)}, 24634 {:firstname "Thomas Sejr", :lastname "Jensen", :department "Department of Mathematics and Computer Science", :institution "University of Southern Denmark", :country "Denmark", :sessions (52)}, 24653 {:firstname "Abhijit", :lastname "Deshmukh", :department "School of Industrial Engineering", :institution "Purdue University", :country "United States", :sessions (81)}, 24726 {:firstname "Gaël", :lastname "Sauvanet", :department "", :institution "Laboratoire d'Informatique de l'Université de Tours", :country "France", :sessions (207)}, 24762 {:firstname "Apostolos", :lastname "Fertis", :department "IFOR, D-MATH", :institution "ETH Zürich", :country "Switzerland", :sessions (104 264 169)}, 24799 {:firstname "Efendi", :lastname "Nasibov", :department "Department of Computer Science", :institution "Dokuz Eylül University", :country "Turkey", :sessions (147)}, 24802 {:firstname "Emmanuel", :lastname "Néron", :department "", :institution "Laboratoire d'Informatique de l'Université de Tours", :country "France", :sessions (64 207)}, 24823 {:firstname "Helmut", :lastname "Niessner", :department "", :institution "Simplan Optimizations e.U.", :country "Austria", :sessions (48)}, 24840 {:firstname "Vladimir", :lastname "Soloviev", :department "Department of Applied Mathematics", :institution "Institute for Humanities and Information Technology, Moscow, Russia", :country "Russian Federation", :sessions (135)}, 24846 {:firstname "Nihat Engin", :lastname "Toklu", :department "", :institution "Istituto Dalle Molle di Studi sull'Intelligenza artificiale (IDSIA)", :country "Switzerland", :sessions (212)}, 24969 {:firstname "Yousef", :lastname "Ghiami", :department "Information, Logistics and Innovation", :institution "VU University Amsterdam", :country "Netherlands", :sessions (162)}, 24972 {:firstname "Ana Isabel", :lastname "Barros", :department "Defence, Security and Safety", :institution "TNO", :country "Netherlands", :sessions (253)}, 24983 {:firstname "Artem", :lastname "Lagzdin", :department "Laboratory of Discrete Optimization", :institution "Omsk Branch of Sobolev Institute of Mathematics Siberian Branch of Russian Academy of Sciences", :country "Russian Federation", :sessions (204)}, 25014 {:firstname "A. Cetin", :lastname "Suyabatmaz", :department "Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (219)}, 25019 {:firstname "Jian", :lastname "Cui", :department "", :institution "TU Darmstadt", :country "Germany", :sessions (120)}, 25050 {:firstname "Axel", :lastname "Werner", :department "Optimization", :institution "Zuse Institut Berlin (ZIB)", :country "Germany", :sessions (211)}, 25065 {:firstname "Zeynep", :lastname "Sargut", :department "Industrial Systems Engineering", :institution "Izmir University of Economics", :country "Turkey", :sessions (146)}, 25170 {:firstname "Michael", :lastname "Wagner", :department "", :institution "Saint Mary's College of California", :country "United States", :sessions (167)}, 25214 {:firstname "Herman", :lastname "Mawengkang", :department "Mathematics", :institution "The University of Sumatera Utara", :country "Indonesia", :sessions (121)}, 25257 {:firstname "Fabio", :lastname "Furini", :department "LAMSADE", :institution "Paris Dauphine", :country "France", :sessions (210)}, 25341 {:firstname "Mark", :lastname "Van Lokeren", :department "", :institution "Vrije Universiteit Brussel", :country "Belgium", :sessions (139)}, 25350 {:firstname "Jesco", :lastname "Humpola", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (76)}, 25356 {:firstname "Yoshitaka", :lastname "Takahashi", :department "Faculty of Commerce", :institution "Waseda University", :country "Japan", :sessions (113 114)}, 25360 {:firstname "Olivier", :lastname "Devolder", :department "CORE", :institution "Université catholique de Louvain (UCL)", :country "Belgium", :sessions (61)}, 25361 {:firstname "Adriano", :lastname "Solis", :department "Management Science Area, School of Administrative Studies", :institution "York University", :country "Canada", :sessions (88)}, 25363 {:firstname "Andreas", :lastname "Frey", :department "Faculty of Business Management and Social Sciences", :institution "University of Applied Sciences Osnabrueck", :country "Germany", :sessions (114)}, 25364 {:firstname "Yoshiaki", :lastname "Shikata", :department "Faculty of Informatics for Arts", :institution "Shobi University", :country "Japan", :sessions (113 114)}, 25442 {:firstname "Elmar", :lastname "Reucher", :department "Quantitative Methoden und Wirtschaftsmathematik", :institution "FernUniversität in Hagen", :country "Germany", :sessions (259)}, 25495 {:firstname "Peter", :lastname "Richtarik", :department "", :institution "University of Edinburgh", :country "United Kingdom", :sessions (61)}, 25496 {:firstname "Frederik", :lastname "Blank", :department "", :institution "ABB Corporate Research", :country "Germany", :sessions (120)}, 25545 {:firstname "Mikael", :lastname "Call", :department "Department of Mathematics", :institution "Linköping University", :country "Sweden", :sessions (212)}, 25559 {:firstname "Jana", :lastname "Ries", :department "Portsmouth Business School", :institution "University of Portsmouth", :country "United Kingdom", :sessions (255)}, 25666 {:firstname "François", :lastname "Glineur", :department "CORE", :institution "Université catholique de Louvain (UCL)", :country "Belgium", :sessions (61)}, 25671 {:firstname "Yurii", :lastname "Nesterov", :department "CORE", :institution "Université catholique de Louvain (UCL)", :country "Belgium", :sessions (156 61)}, 25676 {:firstname "Christiane", :lastname "Barz", :department "Institute of Business Administration", :institution "University of Zurich", :country "Switzerland", :sessions (121)}, 25677 {:firstname "Peter", :lastname "Recht", :department "OR und Wirtschaftsinformatik", :institution "TU Dortmund", :country "Germany", :sessions (229)}, 25731 {:firstname "Rien", :lastname "van de Ven", :department "", :institution "Netherlands Defence Academy", :country "Netherlands", :sessions (172)}, 25752 {:firstname "Alberto A.", :lastname "Álvarez-López", :department "Quantitative Applied Economics II", :institution "UNED (Spanish National University of Distance Education)", :country "Spain", :sessions (258)}, 25774 {:firstname "Balazs", :lastname "David", :department "Department of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (219)}, 25797 {:firstname "Inmaculada", :lastname "Rodríguez-Puerta", :department "Department of Economics, Quantitative Methods and Economic History", :institution "Pablo de Olavide University", :country "Spain", :sessions (258)}, 25893 {:firstname "Jack", :lastname "Vermeulen", :department "Behavioural and Societal Sciences", :institution "TNO", :country "Netherlands", :sessions (172)}, 25895 {:firstname "Axel", :lastname "Bloemen", :department "", :institution "TNO - Defense, Security and Safety", :country "Netherlands", :sessions (253)}, 25956 {:firstname "Paul", :lastname "Steuermann", :department "Institute of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (73)}, 25958 {:firstname "Juan Carlos", :lastname "Matallin-Saez", :department "Finance and Accounting", :institution "Universitat Jaume I", :country "Spain", :sessions (266)}, 25959 {:firstname "Emili", :lastname "Tortosa-Ausina", :department "", :institution "Universitat Jaume I", :country "Spain", :sessions (266)}, 25997 {:firstname "Alois", :lastname "Pichler", :department "", :institution "NTNU", :country "Austria", :sessions (217)}, 26045 {:firstname "Juri", :lastname "Hinz", :department "Logistics", :institution "Zurich Universtity of Applied Sciences", :country "Switzerland", :sessions (115)}, 26084 {:firstname "Mikulas", :lastname "Luptacik", :department "Economics", :institution "University of Economics and Business", :country "Austria", :sessions (105)}, 26093 {:firstname "Halil", :lastname "ŞEN", :department "", :institution "Sakarya University", :country "Turkey", :sessions (252)}, 26158 {:firstname "Katherina", :lastname "Brink", :department "Business Adminstration & Economics", :institution "Bielefeld University", :country "Germany", :sessions (95)}, 26159 {:firstname "Anja", :lastname "Wolter", :department "Institut für Produktionswirtschaft", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (165)}, 26181 {:firstname "Kei", :lastname "Takahashi", :department "Center for Mathematics and Data Science", :institution "Gunma University", :country "Japan", :sessions (257 137 207 216)}, 26217 {:firstname "Sigifredo", :lastname "Laengle", :department "Department of Management Control", :institution "University of Chile", :country "Chile", :sessions (139)}, 26236 {:firstname "Michel", :lastname "Bierlaire", :department "ENAC INTER TRANSP-OR", :institution "École Polytechnique Fédérale de Lausanne (EPFL)", :country "Switzerland", :sessions (210 141)}, 26282 {:firstname "Jacint", :lastname "Szabo", :department "Business Optimization", :institution "IBM Research Lab, Zurich", :country "Switzerland", :sessions (76)}, 26286 {:firstname "Friedhelm", :lastname "Kulmann", :department "Quantitative Methoden und Wirtschaftsmathematik", :institution "FernUniversität in Hagen", :country "Germany", :sessions (208)}, 26288 {:firstname "Kathrin", :lastname "Armborst", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (225)}, 26300 {:firstname "Yuko", :lastname "Moriyama", :department "Department of Information and System Engineering", :institution "Chuo University", :country "Japan", :sessions (208)}, 26311 {:firstname "Dominic", :lastname "Brenner", :department "Quantitative Methoden und Wirtschaftsmathematik", :institution "FernUniversität in Hagen", :country "Germany", :sessions (208)}, 26317 {:firstname "Josephine", :lastname "Clemens", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University Magdeburg", :country "Germany", :sessions (167)}, 26325 {:firstname "Torsten", :lastname "Klug", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (92)}, 26353 {:firstname "Sebastian", :lastname "Sterzik", :department "Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (179)}, 26361 {:firstname "Dominik", :lastname "Dorsch", :department "Dept. Mathematics", :institution "RWTH Aachen University", :country "Germany", :sessions (73)}, 26387 {:firstname "Thomas", :lastname "Rieger", :department "Institute for Mathematical Optimization ", :institution "Technical University Braunschweig", :country "Germany", :sessions (144)}, 26398 {:firstname "Bernd", :lastname "Hellingrath", :department "Chair for Information Systems and Supply Chain Management", :institution "University of Münster", :country "Germany", :sessions (222)}, 26402 {:firstname "Cornelius", :lastname "Köpp", :department "", :institution "edicos Group", :country "Germany", :sessions (124 107)}, 26404 {:firstname "Takahiro", :lastname "Ohno", :department "Dept. of Ind. & Manage. Systems Eng.", :institution "Waseda University", :country "Japan", :sessions (257 137 207 216)}, 26410 {:firstname "Hans-Rolf", :lastname "Vetter", :department "", :institution "UniBw München", :country "Germany", :sessions (253)}, 26412 {:firstname "Carola", :lastname "Hammer", :department "Lehrstuhl für BWL - Controlling", :institution "Technische Universität München", :country "Germany", :sessions (124)}, 26471 {:firstname "Anja", :lastname "Fischer", :department "", :institution "TU Dortmund", :country "Germany", :sessions (204)}, 26485 {:firstname "Kentaro", :lastname "Hoshi", :department "Media Network Center", :institution "Waseda University", :country "Japan", :sessions (113)}, 26489 {:firstname "Beate", :lastname "Rottkemper", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology", :country "Germany", :sessions (185)}, 26490 {:firstname "Sebastian", :lastname "Zurheide", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology (TUHH)", :country "Germany", :sessions (99)}, 26496 {:firstname "Amparo", :lastname "Soler-Dominguez", :department "", :institution "Universitat Jaume I", :country "Spain", :sessions (266)}, 26501 {:firstname "Timo", :lastname "Lohmann", :department "", :institution "TU Braunschweig", :country "Germany", :sessions (271)}, 26508 {:firstname "Jannik", :lastname "Matuschke", :department "TUM School of Management, Lehrstuhl für Operations Research", :institution "Technische Universität München", :country "Germany", :sessions (202 191)}, 26516 {:firstname "Christian", :lastname "Tesch", :department "", :institution "Institute of Transport Logistics - TU Dortmund University", :country "Germany", :sessions (186)}, 26518 {:firstname "Tobias", :lastname "Harks", :department "Institut für Mathematik", :institution "Universität Augsburg", :country "Germany", :sessions (191 190)}, 26519 {:firstname "Maurice", :lastname "Bosman", :department "", :institution "University of Twente", :country "Netherlands", :sessions (129)}, 26546 {:firstname "Naohisa", :lastname "Komatsu", :department "Faculty of Science and Engineering", :institution "Waseda University", :country "Japan", :sessions (113)}, 26596 {:firstname "Dennis", :lastname "Bergmann", :department "", :institution "Hochschule Darmstadt", :country "Germany", :sessions (128)}, 26602 {:firstname "Alex", :lastname "Weissensteiner", :department "", :institution "Free University of Bolzano", :country "Italy", :sessions (118)}, 26607 {:firstname "Alexander", :lastname "Blecken", :department "Business Computing, esp. CIM", :institution "University of Paderborn", :country "Germany", :sessions (185)}, 26613 {:firstname "Ralf", :lastname "Gössinger", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (164 168)}, 26629 {:firstname "Elisabeth", :lastname "Lübbecke", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (172)}, 26657 {:firstname "Uwe", :lastname "Clausen", :department "Director", :institution "Fraunhofer-Institute for Materialflow and Logistics (IML)", :country "Germany", :sessions (192 242 270 186)}, 26665 {:firstname "Marc", :lastname "Wiedmer", :department "", :institution "IFOR ETH Zurich", :country "Switzerland", :sessions (18 10 26 9 19 17 6 32 31 27)}, 26672 {:firstname "Yoshinori", :lastname "Matano", :department "Account Management Division", :institution "AD DENTSU OSAKA INC.", :country "Japan", :sessions (259)}, 26737 {:firstname "Arleta", :lastname "Rasmußen", :department "Institute of Statistics and Opoerations Research", :institution "University of Graz", :country "Austria", :sessions (134)}, 26750 {:firstname "Dirk", :lastname "Hartmann", :department "Corporate Technology", :institution "Siemens AG", :country "Germany", :sessions (207)}, 26752 {:firstname "Gerta", :lastname "Köster", :department "Computer Science and Mathematics", :institution "University of Applied Sciences - Munich", :country "Germany", :sessions (90 207)}, 26768 {:firstname "Ozlem", :lastname "Defterli", :department "Department of Mathematics and Computer Science", :institution "Cankaya University, Ankara, Turkey & Saginaw Valley State University, College of Science, Engineering and Technology, MI, USA (currently as PostDoc)", :country "United States", :sessions (62)}, 26784 {:firstname "Alena", :lastname "Otto", :department "Management Science", :institution "Friedrich-Schiller University Jena", :country "Germany", :sessions (164 147)}, 26799 {:firstname "Stanislas", :lastname "Francfort", :department "CORE/M2V", :institution "Orange Labs", :country "France", :sessions (104)}, 26811 {:firstname "Burak", :lastname "Gokgur", :department "Industrial Systems Engineering", :institution "Izmir University of Economics", :country "Turkey", :sessions (185 243)}, 26841 {:firstname "Thomas", :lastname "Volling", :department "Chair of Production and Operations Management", :institution "TU Berlin", :country "Germany", :sessions (101 99 167 53)}, 26849 {:firstname "Bilge", :lastname "Atasoy", :department "Transport and Mobility Laboratory", :institution "École Polytechnique Fédérale de Lausanne (EPFL)", :country "Switzerland", :sessions (141)}, 26854 {:firstname "Arkadi", :lastname "Nemirovski", :department "Industrial and Systems Engineering", :institution "Georgia Institute of Technology", :country "United States", :sessions (61)}, 26937 {:firstname "Armin", :lastname "Leopold", :department "Department for Computer Science", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (133 128)}, 26948 {:firstname "Stefan", :lastname "Hahler", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (190)}, 26950 {:firstname "Max", :lastname "Klimm", :department "Wirtschaftswissenschaftliche Fakultät", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (190)}, 27073 {:firstname "Lin", :lastname "Xie", :department "Wirtschaftsinformatik", :institution "Leuphana Universität Lüneburg", :country "Germany", :sessions (219)}, 27212 {:firstname "Marc", :lastname "Wiedmer", :department "", :institution "ETH", :country "Switzerland", :sessions (25 15)}, 27254 {:firstname "Nico", :lastname "Vandaele", :department "Operations Management Dept.", :institution "Katholieke Universiteit Leuven", :country "Belgium", :sessions (166)}, 27365 {:firstname "Corinna", :lastname "Hallmann", :department "DS&OR Lab", :institution "Paderborn University", :country "Germany", :sessions (126)}, 27436 {:firstname "Petr", :lastname "Ekel", :department "Graduate Program in Electrical Engineering", :institution "Pontifical Catholic University of Minas Gerais", :country "Brazil", :sessions (202)}, 27449 {:firstname "Ties", :lastname "Brands", :department "Centre for Transport Studies", :institution "University of Twente", :country "Netherlands", :sessions (256)}, 27647 {:firstname "Andrew", :lastname "Clark", :department "Investment & Advisory", :institution "Thomson Reuters", :country "United States", :sessions (266)}, 27696 {:firstname "Prem Kumar", :lastname "Viswanathan", :department "TRANSP-OR, ENAC", :institution "Ecole Polytechnique Federal de Lausanne", :country "Switzerland", :sessions (141)}, 27700 {:firstname "Wataru", :lastname "Katagiri", :department "", :institution "Faculty of Informatics for Arts, Shobi University", :country "Japan", :sessions (113)}, 27701 {:firstname "Saurabh", :lastname "Chandra", :department "Operations Management and Quantitative Techniques", :institution "Indian Institute of Management Indore", :country "India", :sessions (172)}, 27742 {:firstname "Placido", :lastname "Moreno", :department "Engineering School", :institution "University of Seville", :country "Spain", :sessions (260)}, 27792 {:firstname "Natashia", :lastname "Boland", :department "H. Milton Stewart School of Industrial and Systems Engineering", :institution "Georgia Institute of Technology", :country "United States", :sessions (164)}, 27877 {:firstname " Amir ", :lastname "Mahmood", :department "", :institution "Faculty of Business & Law, ", :country "Australia", :sessions (81)}, 27936 {:firstname "Debora", :lastname "Yamazaki Lacorte", :department "Energy Department", :institution "UNICAMP", :country "Brazil", :sessions (126 137)}, 28011 {:firstname "Erich Walter", :lastname "Farkas", :department "Banking and Finance", :institution "University of Zurich", :country "Switzerland", :sessions (154)}, 28031 {:firstname "Felix", :lastname "Kubler", :department "Banking and Finance", :institution "University of Zurich", :country "Switzerland", :sessions (138)}, 28091 {:firstname "Lyudmila", :lastname "Egorova", :department "", :institution "National Research University Higher School of Economics", :country "Russian Federation", :sessions (268)}, 28092 {:firstname "Rajiv", :lastname "Srivastava", :department "Operations Management", :institution "Indian Institute of Management Lucknow", :country "India", :sessions (172)}, 28209 {:firstname "Natália", :lastname "Addas Porto", :department "Energy Department", :institution "University of Campinas", :country "Brazil", :sessions (129)}, 28210 {:firstname "Bruna", :lastname "de Barros Correia", :department "Energy Department", :institution "State University of Campinas", :country "Brazil", :sessions (129)}, 28216 {:firstname "Elisa Bastos", :lastname "Silva", :department "Energy Department", :institution "Unicamp - State University of Campinas", :country "Brazil", :sessions (137)}, 28236 {:firstname "Thomas", :lastname "Kalinowski", :department "", :institution "University of New England", :country "Australia", :sessions (164)}, 28237 {:firstname "Jéssica", :lastname "Pillon Torralba Fernandes", :department "Energy Department", :institution "UNICAMP", :country "Brazil", :sessions (126)}, 28288 {:firstname "John", :lastname "Carlsson", :department "Industrial and Systems Engineering", :institution "University of Southern California", :country "United States", :sessions (221)}, 28300 {:firstname "Narayan", :lastname "Rangaraj", :department "Industrial Engineering and Operations Research", :institution "Indian Institute of Technology Bombay", :country "India", :sessions (226)}, 28333 {:firstname "Karthik", :lastname "Sankaranarayanan", :department "Faculty of Business and Information Technology", :institution "University of Ontario", :country "Canada", :sessions (258)}, 28413 {:firstname "Ryuta", :lastname "Takashima", :department "Faculty of Social Science", :institution "Chiba Institute of Technology", :country "Japan", :sessions (267)}, 28419 {:firstname "Luc", :lastname "Wismans", :department "Centre for Transport Studies", :institution "University of Twente", :country "Netherlands", :sessions (256)}, 28424 {:firstname "Mette", :lastname "Gamst", :department "", :institution "(DORS)", :country "Denmark", :sessions (52)}, 28457 {:firstname "Gianluca", :lastname "Brandinu", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (142)}, 28461 {:firstname "Gerold", :lastname "Petritsch", :department "Research", :institution "e & t Energie Handels GmbH", :country "Austria", :sessions (127)}, 28479 {:firstname "Ute", :lastname "Weissfloch", :department "", :institution "Fraunhofer ISI", :country "Germany", :sessions (251)}, 28504 {:firstname "Carlos", :lastname "Delgado", :department "HEC", :institution "University of Lausanne", :country "Switzerland", :sessions (258)}, 28505 {:firstname "Erik", :lastname "Larsen", :department "Department of Management", :institution "Aarhus University", :country "Denmark", :sessions (258)}, 28600 {:firstname "Ulrich", :lastname "Weidmann", :department "Institute for Transport Planning and Systems", :institution "ETH Zurich", :country "Switzerland", :sessions (245)}, 28646 {:firstname "Eranda", :lastname "Cela", :department "Department of Discrete Mathematics", :institution "TU Graz", :country "Austria", :sessions (214)}, 28655 {:firstname "Lanbo", :lastname "Zheng", :department "Math and Physics", :institution "University of Newcastle", :country "Australia", :sessions (164)}, 28706 {:firstname "Cleber", :lastname "Rocco", :department "Faculdade de Ciências Aplicadas (FCA)", :institution "University of Campinas (UNICAMP)", :country "Brazil", :sessions (254 243)}, 28726 {:firstname "Augusto", :lastname "Gameiro", :department "Department of Animal Nutrition and Production", :institution "University of Sao Paulo", :country "Brazil", :sessions (254)}, 28738 {:firstname "Mohammed", :lastname "El-Kebir", :department "", :institution "CWI", :country "Netherlands", :sessions (65)}, 28739 {:firstname "Michael", :lastname "Krause", :department "", :institution "Clausthal University of Technology", :country "Germany", :sessions (52)}, 28740 {:firstname "Mareike", :lastname "Paul", :department "", :institution "University of Osnabrück", :country "Germany", :sessions (52)}, 28749 {:firstname "Dariusz", :lastname "Zagrodny", :department "Mathematics", :institution "Cardinal Stefan Wyszynski University", :country "Poland", :sessions (194)}, 28756 {:firstname "Eric ", :lastname "Ebermann", :department "Institute of Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (240)}, 28773 {:firstname "Kyriaki ", :lastname "Kosmidou", :department "Dept. of Economics", :institution "Aristotle University of Thessaloniki ", :country "Greece", :sessions (267)}, 28782 {:firstname "Wladyslaw", :lastname "Janiak", :department "Faculty of Computer Science and Management", :institution "Wroclaw University of Technology", :country "Poland", :sessions (146)}, 28801 {:firstname "Ziming", :lastname "Zhu", :department "Department of Management Science and Engineering", :institution "Tsinghua University", :country "China", :sessions (115)}, 28823 {:firstname "R.", :lastname "Hildenbrandt", :department "Inst. Mathematik", :institution "TU Ilmenau", :country "Germany", :sessions (240)}, 28832 {:firstname "Stefan", :lastname "Richter", :department "", :institution "ETH Zurich", :country "Switzerland", :sessions (61)}, 28833 {:firstname "zhaohui", :lastname "xu", :department "Fakultät für Mathematik", :institution "Technische Universität Chemnitz ", :country "Germany", :sessions (71)}, 28859 {:firstname "Biljana", :lastname "Mileva-Boshkoska", :department "Department of Knowledge Technologies", :institution "Jozef Stefan Institute", :country "Slovenia", :sessions (254)}, 28935 {:firstname "Mark", :lastname "Goh", :department "School of Management, UNISA", :institution "University of South Australia", :country "Australia", :sessions (138)}, 28944 {:firstname "Reiner", :lastname "Wolff", :department "Department of Quantitative Economics", :institution "University of Fribourg", :country "Switzerland", :sessions (136)}, 28947 {:firstname "Frida", :lastname "Harrysson", :department "Information systems", :institution "Swedish Defence Research Agency (FOI)", :country "Sweden", :sessions (253)}, 28964 {:firstname "Sven", :lastname "Rahmann", :department "Computer Science 11", :institution "TU Dortmund", :country "Germany", :sessions (65 67)}, 28978 {:firstname "Sebastian", :lastname "Böcker", :department "Maths and Computer Science", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (65)}, 28982 {:firstname "Tobias", :lastname "Marschall", :department "", :institution "CWI Amsterdam", :country "Netherlands", :sessions (65 67)}, 28986 {:firstname "Chris", :lastname "Schwiegelshohn", :department "Computer Science", :institution "TU Dortmund", :country "Germany", :sessions (65)}, 28990 {:firstname "Madhu", :lastname "Jain", :department "Department of Mathematics", :institution "IIT Roorkee", :country "India", :sessions (112)}, 28992 {:firstname "G.C.", :lastname "Sharma", :department "School of Mathematical Sciences", :institution "IBS, Agra", :country "India", :sessions (112)}, 28993 {:firstname "Nadezhda", :lastname "Dunichkina", :department "", :institution "Volga State Academy of Water Transport", :country "Russian Federation", :sessions (202)}, 28996 {:firstname "Susanne", :lastname "Franke", :department "", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (71)}, 29021 {:firstname "Eline", :lastname "De Cuypere", :department "TELIN", :institution "University Ghent", :country "Belgium", :sessions (122)}, 29023 {:firstname "Markus", :lastname "Bauer", :department "Computational Biology Group", :institution "Illumina Cambridge", :country "United Kingdom", :sessions (67)}, 29034 {:firstname "Markus", :lastname "Bohlin", :department "", :institution "SICS Swedish ICT", :country "Sweden", :sessions (245)}, 29036 {:firstname "Illya", :lastname "Kokshenev", :department "Graduate Program in Electrical Engineering", :institution "Pontifical Catholic University of Minas Gerais", :country "Brazil", :sessions (202)}, 29038 {:firstname "Henrique", :lastname "Schuffner", :department "Graduate Program in Electrical Engineering", :institution "Pontifical Catholic University of Minas Gerais", :country "Brazil", :sessions (202)}, 29039 {:firstname "F. Javier", :lastname "Martin-Campo", :department "Estadistica e Investigacion Operativa II", :institution "Universidad Complutense de Madrid", :country "Spain", :sessions (175)}, 29040 {:firstname "Friederike", :lastname "Paetz", :department "", :institution "Marketing, Clausthal University of Technology, Institute of Management and Economics", :country "Germany", :sessions (257)}, 29044 {:firstname "Ann", :lastname "van Ackere", :department "HEC", :institution "University of Lausanne", :country "Switzerland", :sessions (112 258)}, 29045 {:firstname "Whester Jubert", :lastname "Araujo", :department "Administration of the Integrated Center of Distribution Maintenance", :institution "CEMIG Distribution S.A.", :country "Brazil", :sessions (202)}, 29046 {:firstname "Alexander", :lastname "Lieder", :department "Chair of production management", :institution "University of Mannheim", :country "Germany", :sessions (53)}, 29050 {:firstname "Fulya", :lastname "Gokalp", :department "Statistics", :institution "Yildiz Technical University", :country "Turkey", :sessions (81)}, 29055 {:firstname "Li", :lastname "Jian", :department "College of Engineering, Nanjing Agricultural University", :institution "", :country "China", :sessions (247)}, 29065 {:firstname "Michael", :lastname "Kaluzny", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (164)}, 29079 {:firstname "Michihiro", :lastname "Amagasa", :department "Management Information", :institution "Hokkai Gakuen University", :country "Japan", :sessions (108)}, 29083 {:firstname "Bizhan", :lastname "Jamshidnezhad", :department "", :institution "The University of Melbourne", :country "Australia", :sessions (122)}, 29084 {:firstname "Lucas", :lastname "Silva", :department "Program in Electrical Engineering", :institution "Pontifical Catholic University of Minas Gerais", :country "Brazil", :sessions (202)}, 29088 {:firstname "Umesh", :lastname "Gupta", :department "Demartment of Mathematics", :institution "Indian Institute of Technology Kharagpur", :country "India", :sessions (113)}, 29091 {:firstname "Ivo", :lastname "Neidlein", :department "", :institution "SSI Schäfer Noell GmbH", :country "Germany", :sessions (77)}, 29095 {:firstname "Vladimir", :lastname "Shlyk", :department "Mathematics and Mechanics", :institution "Belarusian State Unuversity; Unuversity of Civil Protection", :country "Belarus", :sessions (227)}, 29101 {:firstname "Yao", :lastname "Yang", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (224)}, 29102 {:firstname "Florian", :lastname "Forster", :department "Dept. of Information Systems", :institution "University of Hagen", :country "Germany", :sessions (179)}, 29104 {:firstname "Alan", :lastname "Smith", :department "Mechanical Engineering", :institution "The University of Melbourne", :country "Australia", :sessions (122)}, 29106 {:firstname "Hiroaki", :lastname "Morimoto", :department "Department of Mathematics", :institution "Ehime University", :country "Japan", :sessions (198)}, 29108 {:firstname "Vassiliki", :lastname "Balla", :department "Production Engineering and Management Department", :institution "Technical University of Crete", :country "Greece", :sessions (109)}, 29114 {:firstname "Benjamin", :lastname "Gotthardt", :department "Department of Mathematics and Scientific Computing", :institution "Uni Graz", :country "Austria", :sessions (256)}, 29117 {:firstname "Stephan", :lastname "Tiesler", :department "University of Jena", :institution "Faculty of Business and Economics", :country "Germany", :sessions (177 131)}, 29119 {:firstname "Larraitz", :lastname "Aranburu", :department "Economía Aplicada III", :institution "UPV/EHU", :country "Spain", :sessions (118)}, 29130 {:firstname "Ola", :lastname "Svensson", :department "Department of Theoretical Computer Science", :institution "KTH Royal Institute of Technology", :country "Sweden", :sessions (203)}, 29137 {:firstname "Ralf", :lastname "Lenz", :department "Fachbereich Mathematik", :institution "FU Berlin, ", :country "Germany", :sessions (120)}, 29138 {:firstname "Anuradha", :lastname "Banerjee", :department "Mathematics", :institution "Indian Institute of Technology", :country "India", :sessions (113)}, 29150 {:firstname "Juergen", :lastname "Meyerhoff", :department "Institut für Landschaftsarchitektur und Umweltplanung", :institution "TU Berlin", :country "Germany", :sessions (131)}, 29151 {:firstname "Cheikh", :lastname "Dhib", :department "", :institution "Laboratoire d'informatique de l'université de Tours", :country "France", :sessions (64)}, 29152 {:firstname "Martin", :lastname "Takac", :department "", :institution "Lehigh University", :country "United States", :sessions (61)}, 29153 {:firstname "Maren", :lastname "Martens", :department "Optimization & Consulting", :institution "Axxom Software AG", :country "Germany", :sessions (182)}, 29157 {:firstname "David", :lastname "Hoyos", :department "Department of Applied Economics III", :institution "University of the Basque Country", :country "Spain", :sessions (131)}, 29158 {:firstname "Geraldine", :lastname "Bous", :department "Business Intelligence Practice", :institution "SAP Research Sophia Antipolis", :country "France", :sessions (256)}, 29159 {:firstname "Mª Reyes", :lastname "Gómez-Medina", :department "", :institution "Escuela Superior de Ingenieros", :country "Spain", :sessions (107)}, 29160 {:firstname "Lubos", :lastname "Buzna", :department "Department of Mathematical Methods and Operations Reserach", :institution "University of Zilina", :country "Slovakia", :sessions (220 186)}, 29163 {:firstname "Jens", :lastname "Kuhpfahl", :department "School of Economics and Business, Chair of Production and Logistics", :institution "MLU Halle-Wittenberg", :country "Germany", :sessions (145)}, 29169 {:firstname "Alexey", :lastname "Tretyakov", :department "Faculty of Science", :institution "Siedlce University, System Research Institute, PAS, Warsaw, Poland, Dorodnitsyn Computing Center FRS CSC RAS, Vavilova 40, Moscow 119991, Russia", :country "Poland", :sessions (194)}, 29171 {:firstname "tang", :lastname "xin", :department "", :institution "Laboratoire Informatique, Université François-Rabelais de Tours", :country "France", :sessions (202)}, 29178 {:firstname "Martin", :lastname "Bergner", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (210)}, 29181 {:firstname "Natasa", :lastname "Peric", :department "", :institution "Master Student at University of Vienna, Austria", :country "Austria", :sessions (48)}, 29182 {:firstname "Teresa", :lastname "Herdlicka", :department "", :institution "Master Student at University of Vienna", :country "Austria", :sessions (48)}, 29183 {:firstname "Michael", :lastname "Seitz", :department "Computer Science and Mathematics", :institution "University of Applied Sciences - Munich", :country "Germany", :sessions (207)}, 29186 {:firstname "Mohammed", :lastname "Chahim", :department "Econometrics and Operations Research", :institution "Tilburg University", :country "Netherlands", :sessions (201)}, 29191 {:firstname "Johannes", :lastname "Kolb", :department "", :institution "University of Augsburg", :country "Germany", :sessions (96)}, 29194 {:firstname "ÖZALP", :lastname "VAYVAY", :department "Industrial Engineering Department", :institution "Marmara University Faculty of Engineering", :country "Turkey", :sessions (222)}, 29195 {:firstname "Niklaus", :lastname "Lehmann", :department "Agricultural and Food Sciences", :institution "ETH Zurich", :country "Switzerland", :sessions (160)}, 29197 {:firstname "Svenja", :lastname "Lagershausen", :department "Department of Supply Chain Management and Production", :institution "University of Cologne", :country "Germany", :sessions (114)}, 29203 {:firstname "Tjark", :lastname "Vredeveld", :department "Dept of Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (51)}, 29211 {:firstname "Jose L.", :lastname "Salmeron", :department "School of Engineering", :institution "University Pablo de Olavide", :country "Spain", :sessions (107 260)}, 29216 {:firstname "Christian", :lastname "Hillbrand", :department "Technische Logistik", :institution "V-Research", :country "Austria", :sessions (242)}, 29217 {:firstname "Dorota Slawa", :lastname "Mankowska", :department "", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (186)}, 29219 {:firstname "Nurcan", :lastname "Demirok Donmez", :department "Industrial Engineering", :institution "Istanbul Kultur University", :country "Turkey", :sessions (168)}, 29220 {:firstname "Felix", :lastname "Zesch", :department "", :institution "4flow AG", :country "Germany", :sessions (222)}, 29221 {:firstname "Durga Prasad", :lastname "Modekurti", :department "Operations Management", :institution "Institute of Rural Management,Anand", :country "India", :sessions (136)}, 29224 {:firstname "Felix", :lastname "Wex", :department "Chair for Information Systems Research", :institution "Albert-Ludwigs-Universität Freiburg", :country "Germany", :sessions (185)}, 29225 {:firstname "Robert", :lastname "Voll", :department "Institute of Transport Logistics", :institution "TU Dortmund University", :country "Germany", :sessions (192)}, 29226 {:firstname "Guido", :lastname "Schryen", :department "", :institution "Universität Regensburg", :country "Germany", :sessions (185)}, 29227 {:firstname "Dirk", :lastname "Neumann", :department "Chair for Information Systems Research", :institution "Albert-Ludwigs-Universität Freiburg", :country "Germany", :sessions (185)}, 29229 {:firstname "Miriam", :lastname "Kießling", :department "", :institution "Universität Bayreuth", :country "Germany", :sessions (242)}, 29233 {:firstname "elham", :lastname "farhash", :department "Transportation system", :institution "Transportation Research Institute", :country "Iran, Islamic Republic of", :sessions (246)}, 29239 {:firstname "You-Jin", :lastname "Park", :department "School of Business Administration", :institution "College of Business and Economics, Chung-Ang University", :country "Korea, Republic of", :sessions (243)}, 29241 {:firstname "Peng", :lastname "Li", :department "Recherche Opérationnelle Statistique Simulation", :institution "Université de Technologie de Troyes", :country "France", :sessions (169)}, 29244 {:firstname "Miriam", :lastname "Padberg", :department "OR and Business Informatics", :institution "TU Dortmund", :country "Germany", :sessions (238)}, 29246 {:firstname "Florian", :lastname "Dahms", :department "Operations Research", :institution "RWTH Aachen", :country "Germany", :sessions (209)}, 29247 {:firstname "Sergey", :lastname "Sosnovskiy", :department "", :institution "Frankfurt School of Finance and Management", :country "Germany", :sessions (217)}, 29248 {:firstname "Tobias", :lastname "Paetz", :department "Operations Management Group", :institution "Clausthal University of Technology", :country "Germany", :sessions (64)}, 29249 {:firstname "Regiane Silva de", :lastname "Barros", :department "Energy Department", :institution "Unicamp", :country "Brazil", :sessions (126)}, 29251 {:firstname "Maryam", :lastname "SteadieSeifi", :department "IE&IS", :institution "Technische Universiteit Eindhoven", :country "Netherlands", :sessions (247)}, 29253 {:firstname "Markus", :lastname "Herrich", :department "", :institution "Technische Universität Dresden", :country "Germany", :sessions (57)}, 29255 {:firstname "Liyuan", :lastname "Zhang", :department "Graduate School of Systems and Information Engeering ", :institution "University of Tsukuba", :country "Japan", :sessions (149)}, 29256 {:firstname "Noriyoshi", :lastname "Sukegawa", :department "Graduate School of Decision Science and Technology", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (149)}, 29257 {:firstname "Christian", :lastname "Puchert", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (271)}, 29258 {:firstname "Pınar", :lastname "Aker", :department "Technology and Innovation Funding Programs Directorate (TEYDEB)", :institution "The Scientific and Technological Research Council of Turkey (TUBITAK)", :country "Turkey", :sessions (259)}, 29259 {:firstname "Christa", :lastname "Simon", :department "Vienna Institute of Demography", :institution "Austrian Academy of Sciences", :country "Austria", :sessions (198)}, 29260 {:firstname "Yoshitsugu", :lastname "Yamamoto", :department "Graduate School of Systems and Information Engineering", :institution "University of Tsukuba", :country "Japan", :sessions (149)}, 29261 {:firstname "Jakob", :lastname "Schelbert", :department "Department of Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (213)}, 29263 {:firstname "Arne", :lastname "Mensendiek", :department "Business Administration and Economics", :institution "Bielefeld University", :country "Germany", :sessions (146)}, 29264 {:firstname "Anna-Laura", :lastname "Wickström", :department "", :institution "Universität Zürich", :country "Switzerland", :sessions (55)}, 29274 {:firstname "Didier", :lastname "Aussel", :department "Lab.PROMES UPR 8521", :institution "University of Perpignan", :country "France", :sessions (57)}, 29276 {:firstname "Vural", :lastname "Aksakalli", :department "Mathematical and Geospatial Sciences", :institution "RMIT University", :country "Australia", :sessions (215)}, 29277 {:firstname "Alan", :lastname "Reiner", :department "AMDD", :institution "JHU Applied Physics Lab", :country "United States", :sessions (215)}, 29278 {:firstname "Frank", :lastname "Pfeuffer", :department "Institut für Mathematische Optimierung", :institution "Otto-von-Guericke Universität Magdeburg", :country "Germany", :sessions (212)}, 29282 {:firstname "Marco", :lastname "Rocco", :department "", :institution "University of Bergamo", :country "Italy", :sessions (124)}, 29284 {:firstname "Christian L.", :lastname "Müller", :department "Computer Science", :institution "Institute of Theoretical Computer Science and Swiss Institute of Bioinformatics", :country "Switzerland", :sessions (195)}, 29287 {:firstname "Rok", :lastname "Orel", :department "Research", :institution "Xlab", :country "Slovenia", :sessions (255)}, 29288 {:firstname "Kai-Simon", :lastname "Goetzmann", :department "", :institution "PSI Transcom GmbH", :country "Germany", :sessions (202)}, 29289 {:firstname "Ruben", :lastname "Hoeksma", :department "", :institution "Universität Bremen", :country "Germany", :sessions (51)}, 29291 {:firstname "Robert", :lastname "Finger", :department "Agricultural and Food Sciences", :institution "ETH Zürich", :country "Switzerland", :sessions (160)}, 29292 {:firstname "Michael", :lastname "Serejenkov", :department "", :institution "Fernuniversität in Hagen", :country "Germany", :sessions (260)}, 29294 {:firstname "Martin", :lastname "Bauch", :department "Mathematics and Computer Science", :institution "Ernst Moritz Arndt University Greifswald", :country "Germany", :sessions (142)}, 29295 {:firstname "Stefan", :lastname "Funke", :department "Institut für Formale Methoden der Informatik", :institution "University of Stuttgart", :country "Germany", :sessions (142)}, 29296 {:firstname "Andreas", :lastname "Dellnitz", :department "", :institution "Chair of Operations Research, FernUniversität in Hagen", :country "Germany", :sessions (259)}, 29300 {:firstname "Karl", :lastname "Schmedders", :department "Business", :institution "University of Zurich", :country "Switzerland", :sessions (152 232 38)}, 29302 {:firstname "JEAN-PAUL", :lastname "ARNAOUT", :department "Industrial & Mechanical Engineering", :institution "Lebanese American University", :country "Lebanon", :sessions (159)}, 29303 {:firstname "Evgeniya", :lastname "Martynova", :department "", :institution "Omsk State University", :country "Russian Federation", :sessions (50)}, 29305 {:firstname "Daniel", :lastname "De Wolf", :department "TVES & CORE -UCL", :institution "Université du Littoral", :country "France", :sessions (76)}, 29310 {:firstname "Beatriz", :lastname "Balbas", :department "Finance and Economic Analysis", :institution "University of Castilla-La Mancha", :country "Spain", :sessions (265)}, 29315 {:firstname "Mikhail", :lastname "Kuznetsov", :department "", :institution "Moscow Institute of Physics and Technology", :country "Russian Federation", :sessions (254)}, 29317 {:firstname "Jens", :lastname "Maue", :department "", :institution "ETH Zurich", :country "Switzerland", :sessions (245)}, 29318 {:firstname "Manimay", :lastname "Ghosh", :department "Operations Management", :institution "Institute of Management Technology", :country "India", :sessions (225)}, 29320 {:firstname "Whan-Seon", :lastname "Kim", :department "School of Business", :institution "Myongji University", :country "Korea, Republic of", :sessions (134)}, 29322 {:firstname "Philipp", :lastname "Renner", :department "Economics", :institution "University of Zurich", :country "Switzerland", :sessions (38)}, 29325 {:firstname "S", :lastname "Viswanathan", :department "", :institution "NTU", :country "Singapore", :sessions (171)}, 29326 {:firstname "Sugoutam", :lastname "Ghosh", :department "Industrial Engineering", :institution "Antalya International University", :country "Turkey", :sessions (171)}, 29329 {:firstname "Adnan", :lastname "Çorum", :department "Industrial Engineering", :institution "Bahçeşehir University", :country "Turkey", :sessions (168)}, 29330 {:firstname "Ebru", :lastname "Angun", :department "Industrial Engineering", :institution "Galatasaray University", :country "Turkey", :sessions (121)}, 29332 {:firstname "RACHEL", :lastname "RAVID", :department "Industrial Engineering and Management", :institution "Ort Braude College", :country "Israel", :sessions (114)}, 29333 {:firstname "Cihan ", :lastname "Evecen", :department "Industrial Engineering", :institution "Bahçeşehir University", :country "Turkey", :sessions (168)}, 29337 {:firstname "Abraham", :lastname "Punnen", :department "", :institution "Simon Fraser University", :country "Canada", :sessions (187)}, 29338 {:firstname "Masako", :lastname "Wakamatsu", :department "Department of Information and System Engineering", :institution "Chuo University", :country "Japan", :sessions (208)}, 29339 {:firstname "Rolf", :lastname "Wendt", :department "Operations Research and Business Informatics", :institution "TU Dortmund", :country "Germany", :sessions (165)}, 29341 {:firstname "Isao", :lastname "Aruga", :department "Department of Information and System Engineering", :institution "Chuo University", :country "Japan", :sessions (241)}, 29344 {:firstname "Sarah", :lastname "Kirchner", :department "Operations Research", :institution "RWTH Aachen", :country "Germany", :sessions (210)}, 29345 {:firstname "Magdalena", :lastname "Six", :department "Faculty of Business, Economics and Statistics", :institution "University of Vienna", :country "Austria", :sessions (256)}, 29346 {:firstname "Frauke", :lastname "Seidel", :department "Institut für Verkehrswirtschaft", :institution "Universität Hamburg", :country "Germany", :sessions (98)}, 29347 {:firstname "Christoph", :lastname "Graf", :department "Faculty of Business, Economics and Statistics", :institution "University of Vienna", :country "Austria", :sessions (256)}, 29348 {:firstname "Viola", :lastname "Ricker", :department "Business Information Systems", :institution "University of Braunschweig", :country "Germany", :sessions (84)}, 29349 {:firstname "Takuya", :lastname "Adachi", :department "Business Design & Management", :institution "Graduate School of WASEDA UNIVERSITY", :country "Japan", :sessions (257)}, 29350 {:firstname "Milan", :lastname "Djordjevic", :department "College of Engineering and Technology", :institution "American University of the Middle East", :country "Kazakhstan", :sessions (238)}, 29351 {:firstname "Klaus Reinholdt Nyhuus", :lastname "Hansen", :department "Section for Supply Chain Management and Production", :institution "TU Munich", :country "Germany", :sessions (165)}, 29358 {:firstname "Serhat", :lastname "Tüzün", :department "Industrial Engineering", :institution "Yildiz Technical University", :country "Turkey", :sessions (48)}, 29359 {:firstname "Olaf", :lastname "Maurer", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (211)}, 29361 {:firstname "Emmanuel", :lastname "DEWAELE", :department "", :institution "Université de Tours, Laboratoire d'informatique", :country "France", :sessions (207)}, 29366 {:firstname "David", :lastname "Sayah", :department "Logistics and Supply Chain Optimization", :institution "FZI Research Center for Information Technology", :country "Germany", :sessions (101)}, 29367 {:firstname "Martin", :lastname "Densing", :department "Energy Economics", :institution "PSI", :country "Switzerland", :sessions (127)}, 29370 {:firstname "Steffen", :lastname "Rebennack", :department "Economics and Business", :institution "Colorado School of Mines", :country "United States", :sessions (150 82)}, 29372 {:firstname "Bruno", :lastname "Flach", :department "", :institution "IBM Research, Brazil", :country "Brazil", :sessions (82)}, 29374 {:firstname "Jose Vicente", :lastname "Caixeta-Filho", :department "Department of Economics, Administration and Sociology", :institution "University of Sao Paulo", :country "Brazil", :sessions (254)}, 29378 {:firstname "Bastian", :lastname "Meier", :department "Portfolio Optimisation", :institution "VNG Verbundnetz Gas AG", :country "Germany", :sessions (131)}, 29379 {:firstname "Tomonari ", :lastname "Kitahara", :department "", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (196)}, 29381 {:firstname "Ronan Jouan ", :lastname "de Kervenoael", :department "", :institution "Sabanci University", :country "Turkey", :sessions (186)}, 29382 {:firstname "faicel", :lastname "hnaien", :department "LOSI", :institution "University of Technology of Troyes", :country "France", :sessions (147)}, 29384 {:firstname "Markus", :lastname "Pullmann", :department "", :institution "University of Cologne", :country "Germany", :sessions (246)}, 29385 {:firstname "Florentina", :lastname "Paraschiv", :department "NTNU Business School", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (269)}, 29387 {:firstname "Subrata", :lastname "Mitra", :department "Faculty", :institution "Institute of Management Technology, Nagpur", :country "India", :sessions (267)}, 29388 {:firstname "Torsten", :lastname "Fahle", :department "Airport Systems Division", :institution "Inform GmbH", :country "Germany", :sessions (77)}, 29389 {:firstname "Aybike", :lastname "Özdemirel", :department "Industrial Systems Engineering", :institution "Izmir University of Economics", :country "Turkey", :sessions (185)}, 29390 {:firstname "Jaroslav", :lastname "Janacek", :department "Mathematical Methods and Operations Research", :institution "University of Zilina", :country "Slovakia", :sessions (220 186)}, 29392 {:firstname "Shinji", :lastname "Mizuno", :department "Industrial Engineering and Management", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (143 196)}, 29393 {:firstname "Marek", :lastname "Kvet", :department "", :institution "University of Zilina", :country "Slovakia", :sessions (220)}, 29394 {:firstname "Wiebke", :lastname "von Hoyningen-Huene", :department "Supply Chain Management", :institution "Christian-Albrechts-Universität zu Kiel", :country "Germany", :sessions (51)}, 29395 {:firstname "Erkan", :lastname "Bayraktar", :department "", :institution "Bahçeşehir University", :country "Turkey", :sessions (168)}, 29397 {:firstname "Gernot", :lastname "Lechner", :department "Institute of System Sciences, Innovation and Sustainability Research", :institution "University of Graz", :country "Austria", :sessions (168)}, 29398 {:firstname "Karina", :lastname "Sopp", :department "", :institution "University of Vienna", :country "Austria", :sessions (89)}, 29399 {:firstname "Andre Augusto", :lastname "Cire", :department "Department of Management", :institution "University of Toronto Scarborough", :country "Canada", :sessions (270)}, 29400 {:firstname "Sabine", :lastname "Pallas", :department "", :institution "TU München", :country "Germany", :sessions (105)}, 29401 {:firstname "Michal", :lastname "Houda", :department "Econometrics", :institution "Institute of  Information Theory and Automation of the ASCR", :country "Czech Republic", :sessions (118)}, 29406 {:firstname "Stefan", :lastname "Holzmann", :department "Information Systems, Production and Logistics Management", :institution "University of Innsbruck", :country "Austria", :sessions (159)}, 29412 {:firstname "Catalina", :lastname "Stefanescu-Cuntze", :department "", :institution "ESMT ", :country "Germany", :sessions (101)}, 29415 {:firstname "Gino", :lastname "Loyola", :department "Department of Management Control", :institution "University of Chile", :country "Chile", :sessions (139)}, 29416 {:firstname "Taofeng", :lastname "Ye", :department "School of Economics and Management", :institution "Southeast University", :country "China", :sessions (224)}, 29418 {:firstname "Ivan", :lastname "Davydov", :department "Theoretical Cybernetics", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (220)}, 29420 {:firstname "Anis", :lastname "Kooli", :department "", :institution "Ecole Supérieure des Sciences Economiques et Commerciales de Tunis", :country "Tunisia", :sessions (64)}, 29421 {:firstname "Matthias", :lastname "Altenhoefer", :department "", :institution "Mathematics, University of Kaiserslautern", :country "Germany", :sessions (144)}, 29424 {:firstname "Eva-Maria", :lastname "Sprengel", :department "Operations Research", :institution "Technische Universität Dortmund", :country "Germany", :sessions (229)}, 29428 {:firstname "AHMED", :lastname "ATAHRAN", :department "Informatique", :institution "Université François Rabelais", :country "France", :sessions (189)}, 29429 {:firstname "Lorenz", :lastname "Klaus", :department "D-MATH", :institution "IFOR, ETH Zurich", :country "Switzerland", :sessions (149)}, 29430 {:firstname "Jeanne", :lastname "Andersen", :department "Department of Economics and Business", :institution "Aarhus University", :country "Denmark", :sessions (191)}, 29431 {:firstname "Lishun", :lastname "Zeng", :department "Industrial Engineering and Management", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (143)}, 29433 {:firstname "Tobias", :lastname "Kreisel", :department "Lehrstuhl für Wirtschafstmathematik", :institution "Universität Bayreuth", :country "Germany", :sessions (242)}, 29434 {:firstname "Kai", :lastname "Hoberg", :department "Seminar for Supply Chain Management and Management Science", :institution "University of Cologne", :country "Germany", :sessions (226 170)}, 29436 {:firstname "Markus", :lastname "Künzel", :department "Internal Audit", :institution "Medical University of Vienna", :country "Austria", :sessions (95)}, 29437 {:firstname "Sabine", :lastname "Blaschke", :department "", :institution "University of Vienna", :country "Austria", :sessions (95)}, 29438 {:firstname "Jürgen", :lastname "Fleiß", :department "Department of Statistics and Operations Research", :institution "University of Graz", :country "Austria", :sessions (133 134)}, 29439 {:firstname "Nadine", :lastname "Eder", :department "", :institution "Master Student at University of Vienna", :country "Austria", :sessions (95)}, 29440 {:firstname "Manuela", :lastname "Kolesnik", :department "", :institution "Master Student of University Vienna", :country "Austria", :sessions (95)}, 29442 {:firstname "Andreas", :lastname "Tegel", :department "", :institution "Robert Bosch GmbH", :country "Germany", :sessions (170)}, 29443 {:firstname "Frédéric", :lastname "Babonneau", :department "", :institution "Ordecsys and EPFL", :country "Switzerland", :sessions (125 241)}, 29444 {:firstname "Michael", :lastname "Mohaupt", :department "", :institution "Dresden University of Technology", :country "Germany", :sessions (96)}, 29445 {:firstname "Mónica", :lastname "Buendía", :department "Deparment of Economics", :institution "ESERP", :country "Spain", :sessions (258)}, 29446 {:firstname "Dragos", :lastname "Cvetkovic", :department "", :institution "Mathematical institute SANU", :country "Serbia", :sessions (203)}, 29450 {:firstname "Stefan", :lastname "Nykamp", :department "", :institution "University Twente, NL / RWE Deutschland, Bad Bentheim", :country "Germany", :sessions (130)}, 29454 {:firstname "Erk", :lastname "Struwe", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (85)}, 29455 {:firstname "Chunhui", :lastname "Xu", :department "Risk Science in Finance and Management", :institution "Chiba Institute of Technology", :country "Japan", :sessions (217)}, 29456 {:firstname "Michael", :lastname "Murg", :department "", :institution "KF Uni Graz", :country "Austria", :sessions (265)}, 29457 {:firstname "Katharina", :lastname "Mariel", :department "", :institution "Daimler AG/ University of Vienna", :country "Germany", :sessions (223)}, 29458 {:firstname "Christian", :lastname "Otto", :department "", :institution "DB Schenker Rail Deutschland AG", :country "Germany", :sessions (164)}, 29459 {:firstname "Kerstin", :lastname "Herrmann", :department "", :institution "Daimler AG", :country "Germany", :sessions (261)}, 29460 {:firstname "Berno", :lastname "Buechel", :department "", :institution "Saarland University", :country "Germany", :sessions (205)}, 29461 {:firstname "Basil", :lastname "Vitins", :department "Civil, Environmental and Geomatic Engineering", :institution "ETH Zurich", :country "Switzerland", :sessions (181)}, 29462 {:firstname "Stefan", :lastname "Schmieder", :department "Mathematics", :institution "Faculty of Science", :country "Germany", :sessions (213)}, 29463 {:firstname "Dirk", :lastname "Evers", :department "Computational Biology", :institution "Illumina", :country "United Kingdom", :sessions (67)}, 29464 {:firstname "Friedrich", :lastname "Kunz", :department "Chair of Energy Economics", :institution "TU Dresden", :country "Germany", :sessions (126)}, 29465 {:firstname "Alexander", :lastname "von Selasinsky", :department "", :institution "TU Dresden", :country "Germany", :sessions (126)}, 29466 {:firstname "Frank", :lastname "Bertagnolli", :department "", :institution "Daimler AG", :country "Germany", :sessions (261)}, 29467 {:firstname "Volker", :lastname "Ruff", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (96)}, 29468 {:firstname "Torsten", :lastname "Gellert", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (163 209)}, 29469 {:firstname "Gregor", :lastname "Selinka", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (163)}, 29472 {:firstname "Nils", :lastname "Röhl", :department "", :institution "Paderborn University", :country "Germany", :sessions (205)}, 29474 {:firstname "Ralph", :lastname "Moritz", :department "", :institution "Robert Bosch GmbH", :country "Germany", :sessions (160)}, 29475 {:firstname "Francisca", :lastname "Bauer", :department "", :institution "WU", :country "Austria", :sessions (105)}, 29476 {:firstname "Kathrin", :lastname "Ballerstein", :department "", :institution "IFOR, ETH Zurich", :country "Switzerland", :sessions (205)}, 29477 {:firstname "Gennadiy", :lastname "Averkov", :department "Faculty of Mathematics", :institution "University of Magdeburg", :country "Germany", :sessions (227)}, 29479 {:firstname "Sezgin", :lastname "Kilic", :department "Industrial Engineering", :institution "Turkish Air Force Academy", :country "Turkey", :sessions (247)}, 29480 {:firstname "Jan-Philip", :lastname "gamp", :department "", :institution "Institute of Mathematical Economics, Bielefeld University", :country "Germany", :sessions (205)}, 29481 {:firstname "Bora", :lastname "Kabatepe", :department "Industrial Engineering ", :institution "Koç University", :country "Turkey", :sessions (129)}, 29482 {:firstname "Qingli", :lastname "Da", :department "School of Economics and Management", :institution "Southeast University", :country "China", :sessions (247 224)}, 29483 {:firstname "Fei", :lastname "Chen", :department "School of Economics and Management", :institution "Southeast University", :country "China", :sessions (224)}, 29486 {:firstname "Dnyanesh", :lastname "Patil", :department "Computer Science", :institution "PES Institute of Technology", :country "India", :sessions (142)}, 29487 {:firstname "Jessica", :lastname "Patel", :department "Computer Science", :institution "PES Institute of Technology", :country "India", :sessions (142)}, 29488 {:firstname "Meghna", :lastname "Suvarna", :department "Computer Science", :institution "PES Institute of Technology", :country "India", :sessions (142)}, 29492 {:firstname "Takashi", :lastname "Masuko", :department "Department of Information and System Engineering", :institution "Chuo University", :country "Japan", :sessions (143)}, 29494 {:firstname "Eivind", :lastname "Helland", :department "Handel und Vertrieb", :institution "Axpo AG", :country "Switzerland", :sessions (126)}, 29495 {:firstname "Pascal", :lastname "Hänggi", :department "Geographisches Institut, Oeschger-Zentrum für Klimaforschung", :institution "Universität Bern", :country "Switzerland", :sessions (126)}, 29497 {:firstname "Eduard", :lastname "Zuur", :department "", :institution "Time-steps AG", :country "Switzerland", :sessions (126)}, 29498 {:firstname "Thomas", :lastname "Bosshard", :department "Institut für Atmosphäre und Klima", :institution "ETH Zürich", :country "Switzerland", :sessions (126)}, 29499 {:firstname "Daniel", :lastname "Rietmann", :department "Hydroenergie", :institution "Axpo AG", :country "Switzerland", :sessions (126)}, 29500 {:firstname "Bruno", :lastname "Schädler", :department "Geographisches Institut, Oeschger-Zentrum für Klimaforschung", :institution "Universität Bern", :country "Switzerland", :sessions (126)}, 29501 {:firstname "Robert", :lastname "Schneider", :department "Handel und Vertrieb", :institution "Axpo AG", :country "Switzerland", :sessions (126)}, 29502 {:firstname "Rolf", :lastname "Weingartner", :department "Geographisches Institut, Oeschger-Zentrum für Klimaforschung", :institution "Universität Bern", :country "Switzerland", :sessions (126)}, 29503 {:firstname "David S.W.", :lastname "Lai", :department "", :institution "The Chinese Univesrity of Hong Kong", :country "Hong Kong", :sessions (219)}, 29504 {:firstname "Tanguy", :lastname "Lapegue", :department "Automatique Productique", :institution "Ecole des Mines de Nantes", :country "France", :sessions (51)}, 29508 {:firstname "Kay", :lastname "Axhausen", :department "", :institution "ETH Zurich", :country "Switzerland", :sessions (181)}, 29511 {:firstname "Thomas", :lastname "Rutherford", :department "", :institution "ETH Zürich", :country "Switzerland", :sessions (124 125 79 235)}, 29513 {:firstname "Alexander", :lastname "Redlein", :department "IFM", :institution "TU Wien", :country "Austria", :sessions (89)}, 29514 {:firstname "Michael", :lastname "Hartner", :department "", :institution "TU Vienna", :country "Austria", :sessions (128)}, 29515 {:firstname "Stefan", :lastname "Janson", :department "Energiemarkt Methoden & Modelle", :institution "EnBW Trading GmbH", :country "Germany", :sessions (82)}, 29518 {:firstname "Christian", :lastname "Jungbluth", :department "", :institution "BET Büro für Energiewirtschaft und technische Planung GmbH", :country "Germany", :sessions (77)}, 29519 {:firstname "Sandra", :lastname "Hallek", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (168)}, 29520 {:firstname "Olga", :lastname "Heismann", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (209)}, 29521 {:firstname "Rik", :lastname "Meijer", :department "IFM", :institution "TU Wien", :country "Austria", :sessions (89)}, 29523 {:firstname "Julien", :lastname "Chabas", :department "", :institution "Vienna University of Technology", :country "Austria", :sessions (130 127)}, 29524 {:firstname "Emilio", :lastname "Zamorano de Acha", :department "Chair of Production Management", :institution "Univerisity of Mannheim", :country "Germany", :sessions (140)}, 29525 {:firstname "Gerald", :lastname "Senarclens de Grancy", :department "Institute of Production and Operations Management", :institution "University of Graz", :country "Austria", :sessions (85)}, 29526 {:firstname "Tobias", :lastname "Mömke", :department "School of Computer Science and Communication", :institution "KTH Royal Institute of Technology", :country "Sweden", :sessions (203)}, 29527 {:firstname "Christopher", :lastname "Sander", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (85)}, 29530 {:firstname "Josef", :lastname "Baumüller", :department "", :institution "University of Vienna", :country "Austria", :sessions (89)}, 29534 {:firstname "Stefan", :lastname "Woerner", :department "", :institution "IBM Research", :country "Switzerland", :sessions (169)}, 29535 {:firstname "Klaus", :lastname "Moeller", :department "Chair for Controlling / Performance Management", :institution "University of St. Gallen", :country "Switzerland", :sessions (261)}, 29536 {:firstname "Yanli", :lastname "Huo", :department "Financial Engineering", :institution "China Jiliang University", :country "China", :sessions (217)}, 29539 {:firstname "Daniel", :lastname "Gartner", :department "TUM School of Management", :institution "Technische Universitaet München", :country "Germany", :sessions (88)}, 29540 {:firstname "Chen", :lastname "Fang", :department "Department of Automation", :institution "Tsinghua University", :country "China", :sessions (50)}, 29541 {:firstname "Nicole", :lastname "Kusemitsch", :department "Lehrstuhl für Unternehmensrechnung/Accounting", :institution "Otto-von-Guericke Universität Magdeburg", :country "Germany", :sessions (94)}, 29542 {:firstname "Danny", :lastname "Behrendt", :department "Economics and Management", :institution "Otto-von-Guericke-University Magdeburg", :country "Germany", :sessions (94)}, 29543 {:firstname "Yuji", :lastname "Shinano", :department "Optimization", :institution "Zuse Institue Berlin", :country "Germany", :sessions (227)}, 29544 {:firstname "Matthias", :lastname "Koch", :department "Energy & Climate", :institution "Öko-Institut", :country "Germany", :sessions (125)}, 29545 {:firstname "Peter", :lastname "Hoffmann", :department "", :institution "Fakultät für Mathematik, Technische Universität Chemnitz", :country "Germany", :sessions (211)}, 29546 {:firstname "Thorsten", :lastname "Koch", :department "Mathematical Optimization", :institution "ZIB / TU Berlin", :country "Germany", :sessions (227)}, 29547 {:firstname "Michael", :lastname "Winkler", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (227)}, 29548 {:firstname "Michal", :lastname "Kohani", :department "Mathematical Methods and Operations Research", :institution "University of Zilina", :country "Slovakia", :sessions (220 186)}, 29549 {:firstname "Florian", :lastname "Resch", :department "", :institution "Oesterreichische Nationalbank", :country "Austria", :sessions (215)}, 29550 {:firstname "Dmitry", :lastname "Podkopaev", :department "Dept. of Mathematical Information Technology", :institution "University of Jyväskylä", :country "Finland", :sessions (254)}, 29551 {:firstname "Xiaolin", :lastname "Huang", :department "Department of Automation", :institution "Tsinghua University", :country "China", :sessions (217)}, 29553 {:firstname "Shuning", :lastname "Wang", :department "Department of Automation", :institution "Tsinghua University", :country "China", :sessions (217)}, 29554 {:firstname "Volkan", :lastname "Gümüşkaya", :department "Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (164)}, 29555 {:firstname "Manuel", :lastname "Lingo", :department "", :institution "Oesterreichische Nationalbank", :country "Austria", :sessions (215)}, 29556 {:firstname "Wolfgang", :lastname "Aussenegg", :department "Finance and Corporate Control", :institution "Vienna University of Technology", :country "Austria", :sessions (215)}, 29558 {:firstname "Zhigang", :lastname "Feng", :department "Banking and Finance", :institution "Universiy of Zurich", :country "Switzerland", :sessions (139)}, 29559 {:firstname "Stefan", :lastname "Palan", :department "Institute of Banking & Finance", :institution "Karl-Franzens-University Graz", :country "Austria", :sessions (133 218)}, 29560 {:firstname "Anne", :lastname "Chwolka", :department "", :institution "OvGU", :country "Germany", :sessions (94)}, 29561 {:firstname "Ruth", :lastname "Hübner", :department "Institut für Numerische und Angewandte Mathematik", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (271 204)}, 29562 {:firstname "Benjamin", :lastname "Jonen", :department "IBF", :institution "u of zurich", :country "Switzerland", :sessions (38)}, 29563 {:firstname "Dominik", :lastname "Kress", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (220)}, 29565 {:firstname "Katharina", :lastname "Beygang", :department "Department of Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (209)}, 29566 {:firstname "Claudia", :lastname "Schlebusch", :department "Chair of Logistics Management, Gutenberg School of Management and Economics", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (182)}, 29569 {:firstname "Daniel", :lastname "Harenberg", :department "Economics Department", :institution "University of Mannheim", :country "Germany", :sessions (134)}, 29570 {:firstname "Christoph", :lastname "Bremberger", :department "Research Institute for Regulatory Economics", :institution "WU Vienna", :country "Austria", :sessions (105)}, 29571 {:firstname "Timo", :lastname "Gschwind", :department "", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (189)}, 29573 {:firstname "Jeroen", :lastname "de Jong", :department "", :institution "PA Consulting", :country "Netherlands", :sessions (75)}, 29574 {:firstname "Céline", :lastname "Gicquel", :department "Laboratoire de Recherche en Informatique", :institution "Université Paris Sud", :country "France", :sessions (161)}, 29575 {:firstname "Margarita", :lastname "Protopappa-Sieke", :department "", :institution "EBS University", :country "Germany", :sessions (226)}, 29576 {:firstname "Stephan", :lastname "Schmitt", :department "", :institution "WU Vienna, Institute of Regulatory Economics", :country "Austria", :sessions (105)}, 29577 {:firstname "Che-Lin", :lastname "Su", :department "Booth School of Business", :institution "University of Chicago", :country "United States", :sessions (38)}, 29578 {:firstname "Alexander", :lastname "Ludwig", :department "Center for Macroeconomic Research", :institution "University of Cologne", :country "Germany", :sessions (134)}, 29579 {:firstname "Jean-Bertrand", :lastname "Gauthier", :department "", :institution "GERAD & HEC Montreal", :country "Canada", :sessions (210)}, 29580 {:firstname "David", :lastname "Adjiashvili", :department "D-MATH", :institution "IFOR, ETH Zurich", :country "Switzerland", :sessions (212)}, 29581 {:firstname "Gauthier", :lastname "de Maere d'Aertrycke", :department "CORE", :institution "Université catholique de Louvain", :country "Belgium", :sessions (120)}, 29582 {:firstname "Jean Bernard", :lastname "Lasserre", :department "", :institution "LAAS - CNRS", :country "France", :sessions (200)}, 29584 {:firstname "Martin", :lastname "Weiser", :department "Numerical Analysis and Modelling", :institution "Zuse Institute Berlin", :country "Germany", :sessions (120)}, 29585 {:firstname "Katharina", :lastname "Vedovelli", :department "Research", :institution "e&t", :country "Austria", :sessions (127)}, 29586 {:firstname "Frederic", :lastname "Moulis", :department "", :institution "SARL Frederic Moulis", :country "France", :sessions (104)}, 29587 {:firstname "Cedric", :lastname "Hervet", :department "CORE/M2V", :institution "Orange Labs", :country "France", :sessions (104)}, 29588 {:firstname "Rüdiger", :lastname "Stephan", :department "", :institution "Technische Universität Berlin", :country "Germany", :sessions (240)}, 29593 {:firstname "Ralf", :lastname "Heim", :department "Technology and Operations Management", :institution "University of Duisburg/Essen", :country "Germany", :sessions (223)}, 29594 {:firstname "Gregor", :lastname "Hendel", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (228)}, 29595 {:firstname "Andreas", :lastname "Serin", :department "Technology and Operations Management", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (223)}, 29596 {:firstname "Christian", :lastname "Wothke", :department "Technology and Operations Management", :institution "University of Duisburg/Essen", :country "Germany", :sessions (223)}, 29598 {:firstname "Nursen", :lastname "Tore", :department "Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (163)}, 29599 {:firstname "Gilberto J.", :lastname "Hernández G.", :department "Gerencia de Investigación", :institution "Minimax consultores", :country "Venezuela, Bolivarian Republic of", :sessions (258)}, 29602 {:firstname "Mujahed", :lastname "Eleyat", :department "", :institution "Miriam AS", :country "Norway", :sessions (206)}, 29603 {:firstname "Birgit", :lastname "Rudloff", :department "", :institution "Princeton University", :country "United States", :sessions (78)}, 29604 {:firstname "Magnus", :lastname "Lie Hetland", :department "", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (206)}, 29605 {:firstname "Lasse", :lastname "Natvig", :department "", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (206)}, 29606 {:firstname "Christophe", :lastname "Lenté", :department "Polytech'Tours/Dep Informatique", :institution "LI de l'Université François Rabelais", :country "France", :sessions (189)}, 29609 {:firstname "Jan Mathias", :lastname "Köhler", :department "Statistics", :institution "LMU Munich", :country "Germany", :sessions (140)}, 29610 {:firstname "Joshua", :lastname "Ignatius", :department "School of Mathematical Sciences", :institution "Universiti Sains Malaysia", :country "Malaysia", :sessions (138)}, 29611 {:firstname "Alexander", :lastname "Schoenhuth", :department "", :institution "Centrum Wiskunde & Informatica", :country "Netherlands", :sessions (67)}, 29612 {:firstname "Dominik", :lastname "Pfeiffer", :department "Chair for Information Systems and Supply Chain Management", :institution "University of Münster", :country "Germany", :sessions (222)}, 29614 {:firstname "Sebastian", :lastname "Steinker", :department "Supply Chain and Operations Strategy", :institution "Kühne Logistics University", :country "Germany", :sessions (170)}, 29615 {:firstname "Lalitha", :lastname "Dhamotharan", :department "Nottingham University Business School Malaysia", :institution "University of Nottingham", :country "Malaysia", :sessions (138)}, 29616 {:firstname "Tian Siang", :lastname "Tan", :department "School of Mathematical Sciences", :institution "Universiti Sains Malaysia", :country "Malaysia", :sessions (138)}, 29618 {:firstname "Tuncay", :lastname "SARI", :department "Industrial Engineering", :institution "Turkish Air Force Academy", :country "Turkey", :sessions (247)}, 29626 {:firstname "Sandro", :lastname "Andreotti", :department "Institut für Informatik", :institution "Freie Universität Berlin", :country "Germany", :sessions (65)}, 29627 {:firstname "Arnt-Gunnar", :lastname "Lium", :department "Applied Economics", :institution "SINTEF", :country "Norway", :sessions (192)}, 29628 {:firstname "Martin", :lastname "Luy", :department "", :institution "TU Berlin", :country "Germany", :sessions (172)}, 29630 {:firstname "Rudolf", :lastname "Bauer", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (161)}, 29632 {:firstname "János", :lastname "Balogh", :department "Juhász Gyula Faculty of Education, Department of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (219)}, 29635 {:firstname "Attila", :lastname "Tóth", :department "Juhász Gyula Faculty of Education, Department of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (219)}, 29636 {:firstname "Viktor", :lastname "Árgilán", :department "Juhász Gyula Faculty of Education, Department  of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (219)}, 29640 {:firstname "Paul", :lastname "Göpfert", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (161)}, 29641 {:firstname "Bernhard", :lastname "Schwarz", :department "Technische Dienstleistungen und Operations Management", :institution "TU München", :country "Germany", :sessions (121)}, 29642 {:firstname "VIRNA", :lastname "ORTIZ-ARAYA", :department "CIENCIAS BASICAS", :institution "UNIVERSIDAD DEL BIO-BIO", :country "Chile", :sessions (166)}, 29647 {:firstname "Christian", :lastname "Schlange", :department "GR/PPQ", :institution "Daimler AG ", :country "Germany", :sessions (226)}, 29648 {:firstname "Andreas", :lastname "Schuette", :department "Prognose und Optimierungsmethoden (GR/PPQ)", :institution "Daimler AG ", :country "Germany", :sessions (226)}, 29649 {:firstname "Tomoya ", :lastname "Horiuchi", :department "Business Design and Management", :institution "Graduate School of Waseda University", :country "Japan", :sessions (216)}, 29651 {:firstname "Tatsuya", :lastname "Terada", :department "Business Design and Management", :institution "Graduate School of Waseda University", :country "Japan", :sessions (137)}, 29657 {:firstname "Johannes", :lastname "Fichtinger", :department "School of Management", :institution "Cranfield University", :country "United Kingdom", :sessions (170)}, 29658 {:firstname "Emel", :lastname "Arikan", :department "Department of Information Systems and Operations", :institution "Vienna University of Economics and Business", :country "Austria", :sessions (170)}, 29659 {:firstname "Philipp", :lastname "Bartke", :department "Wirtschaftsinformatik", :institution "Freie Universität Berlin", :country "Germany", :sessions (99)}, 29660 {:firstname "Benedikt", :lastname "Zimmermann", :department "Wirtschaftsinformatik", :institution "Freie Universität Berlin", :country "Germany", :sessions (99)}, 29662 {:firstname "Daniel", :lastname "Kadatz", :department "Wirtschaftsinformatik", :institution "Freie Universität Berlin", :country "Germany", :sessions (98)}, 29663 {:firstname "Stephan", :lastname "Spiecker", :department "", :institution "University of Duisburg-Essen", :country "Germany", :sessions (125)}, 29666 {:firstname "Mihael", :lastname "Cesar", :department "Business computing", :institution "Faculty of Economics, University of Ljubljana", :country "Slovenia", :sessions (195)}, 29667 {:firstname "Thomas", :lastname "Fliedner", :department "TUM School of Management", :institution "Technische Universitaet Muenchen", :country "Germany", :sessions (50)}, 29669 {:firstname "Alexander", :lastname "Brauneis", :department "Finance & Accounting", :institution "University of Klagenfurt", :country "Austria", :sessions (218)}, 29671 {:firstname "Mokryi", :lastname "Igor", :department "Applied Mathematics", :institution "Institute of Energy System, Siberian Branch of Russian Academy of Sciences", :country "Russian Federation", :sessions (195)}, 29673 {:firstname "Michael", :lastname "Schürle", :department "Institute for Operations Research and Computational Finance", :institution "University of St. Gallen", :country "Switzerland", :sessions (267)}, 29674 {:firstname "Luka", :lastname "Tomat", :department "Academic Unit for Business Informatics and Logistics", :institution "Faculty of Economics, University of Ljubljana", :country "Slovenia", :sessions (195)}, 29675 {:firstname "Simone", :lastname "Göttlich", :department "School of Business Informatics and Mathematics", :institution "University of Mannheim", :country "Germany", :sessions (104)}, 29680 {:firstname "Andreas", :lastname "Karrenbauer", :department "", :institution "Max Planck Institute for Informatics", :country "Germany", :sessions (214)}, 29681 {:firstname "Pankaj", :lastname "Gupta", :department "Operational Research", :institution "University of Delhi", :country "India", :sessions (268)}, 29682 {:firstname "Elif Elcin", :lastname "Gunay", :department "Industrial Engineering", :institution "Sakarya University", :country "Turkey", :sessions (240)}, 29683 {:firstname "Mukesh", :lastname "Mehlawat", :department "Operational Research", :institution "Apeejay School of Management", :country "India", :sessions (268)}, 29686 {:firstname "Yumi", :lastname "Asahi", :department "Department of engineering, Management of business", :institution "Shizuoka University", :country "Japan", :sessions (257)}, 29687 {:firstname "Csaba", :lastname "Fabian", :department "Dept. of Informatics", :institution "John von Neumann University", :country "Hungary", :sessions (119)}, 29688 {:firstname "Victor", :lastname "Zverovich", :department "CARISMA: The Centre for the Analysis of Risk and Optimisation Modelling Applications, School of Information Systems, Computing and Mathematics", :institution "Brunel University", :country "United Kingdom", :sessions (119)}, 29689 {:firstname "Andrej", :lastname "Bregar", :department "", :institution "Informatika", :country "Slovenia", :sessions (251)}, 29691 {:firstname "Hassan", :lastname "Taheri", :department "Mathematical Science", :institution "Khayyam University of Mashhad", :country "Iran, Islamic Republic of", :sessions (238)}, 29692 {:firstname "Janos", :lastname "Mayer", :department "Department of Business Administration", :institution "University of Zurich", :country "Switzerland", :sessions (127)}, 29693 {:firstname "Olaf", :lastname "Tietje", :department "", :institution "FHO-Hochschule Rapperswil", :country "Switzerland", :sessions (253)}, 29699 {:firstname "Murat", :lastname "Ayanoglu", :department "", :institution "Faculty of Economics and Administrative Sciences", :country "Turkey", :sessions (252)}, 29701 {:firstname "Panagiotis", :lastname "Zervopoulos", :department "Faculty of Economics and Management", :institution "Open University of Cyprus", :country "Cyprus", :sessions (109)}, 29706 {:firstname "David", :lastname "Schindl", :department "Business Administration", :institution "Geneva School of Business Administration", :country "Switzerland", :sessions (142)}, 29707 {:firstname "Markos", :lastname "Anastasopoulos", :department "School of Electrical and Computer Engineering", :institution "National Technical University of Athens", :country "Greece", :sessions (109)}, 29709 {:firstname "Miltiades", :lastname "Filippou", :department "", :institution "Institut EURECOM", :country "France", :sessions (109)}, 29710 {:firstname "Beyazıt", :lastname "Ocaktan", :department "Industrial Engineering", :institution "Sakarya University", :country "Turkey", :sessions (122)}, 29711 {:firstname "Morten Bremnes", :lastname "Nielsen", :department "Industrial Economics and Technology Management ", :institution "NTNU", :country "Norway", :sessions (103)}, 29713 {:firstname "Knut", :lastname "Reinert", :department "Mathematics and Computer Science", :institution "FU Berlin", :country "Germany", :sessions (65)}, 29714 {:firstname "Brandon", :lastname "Pope", :department "Industrial Engineering", :institution "Purdue University", :country "United States", :sessions (81)}, 29715 {:firstname "Andrew", :lastname "Johnson", :department "Department of Industrial & Systems Engineering", :institution "Texas A&M University", :country "United States", :sessions (81)}, 29716 {:firstname "James", :lastname "Rohack", :department "2401 South 31st Street", :institution "Scott and White Health Care", :country "United States", :sessions (81)}, 29720 {:firstname "Dierk", :lastname "Bauknecht", :department "", :institution "Öko-Institut", :country "Germany", :sessions (125)}, 29721 {:firstname "Charalampos", :lastname "Pitas", :department "School of Electrical and Computer Engineering, National Technical University of Athens", :institution "Mobile Radiocommunications Laboratory", :country "Greece", :sessions (104)}, 29724 {:firstname "Walter", :lastname "Pohl", :department "Quantitative Business Administration", :institution "University of Zurich", :country "Switzerland", :sessions (138)}, 29725 {:firstname "Olga", :lastname "Proncheva", :department "", :institution "Moscow Institute of Physics and Technology (MIPT)", :country "Russian Federation", :sessions (137)}, 29726 {:firstname "Nicole", :lastname "Gröwe-Kuska", :department "", :institution "Vattenfall Europe AG", :country "Germany", :sessions (82)}, 29727 {:firstname "Athanasios", :lastname "Panagopoulos", :department "School of Electrical & Computer Engineering,National Technical University of Athens", :institution "Mobile Radiocommunications Laboratory", :country "Greece", :sessions (104)}, 29728 {:firstname "Felix", :lastname "Färber", :department "", :institution "Vattenfall Europe AG", :country "Germany", :sessions (82)}, 29732 {:firstname "Imre", :lastname "Dobos", :department "Economics", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (167 168)}, 29733 {:firstname "Marc", :lastname "Goerigk", :department "Network and Data Science Management", :institution "University of Siegen", :country "Germany", :sessions (245)}, 29734 {:firstname "Chris", :lastname "Kaiser", :department "Operations Management", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (166)}, 29735 {:firstname "Martin", :lastname "Knoth", :department "", :institution "Martin-Luther Universitaet Halle-Wittenberg", :country "Germany", :sessions (245)}, 29736 {:firstname "Ugur", :lastname "Cetin", :department "", :institution "Middle Eact Technical University", :country "Turkey", :sessions (181)}, 29737 {:firstname "Elisabeth", :lastname "Gassner", :department "Fixed Income / Financial Engineering,  Group Treasury", :institution "Raiffeisen Landesbank Steiermark", :country "Austria", :sessions (214)}, 29738 {:firstname "Matthias", :lastname "Müller-Hannemann", :department "Computer Science", :institution "Martin-Luther Universität Halle-Wittenberg", :country "Germany", :sessions (245)}, 29740 {:firstname "Lien", :lastname "Perdu", :department "Operations Management", :institution "Katholieke Universiteit Leuven", :country "Belgium", :sessions (166)}, 29741 {:firstname "Jan", :lastname "Pöschko", :department "Department of Optimization and Discrete Mathematics", :institution "Graz University of Technology", :country "Austria", :sessions (214)}, 29743 {:firstname "Nurbanu", :lastname "Ince", :department "Department of Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (181)}, 29746 {:firstname "Sandro", :lastname "Bosio", :department "IFOR", :institution "ETH Zurich", :country "Switzerland", :sessions (144)}, 29747 {:firstname "Philippe", :lastname "Cara", :department "of Mathematics", :institution "Vrije Universiteit Brussel", :country "Belgium", :sessions (139)}, 29748 {:firstname "Alberto", :lastname "Del Pia", :department "Mathematics", :institution "IFOR, ETH Zurich", :country "Switzerland", :sessions (227)}, 29751 {:firstname "Ali", :lastname "Berrichi", :department "LIMOSE, Computer Science department", :institution "University M'hamed Bougara of Boumerdes", :country "Algeria", :sessions (163)}, 29752 {:firstname "Barbara", :lastname "Gobsch", :department "", :institution "European University Viadrina", :country "Germany", :sessions (168)}, 29754 {:firstname "Delia", :lastname "Coculescu", :department "Department of Banking and Finance", :institution "University of Zurich", :country "Switzerland", :sessions (216)}, 29755 {:firstname "Wei", :lastname "Huang", :department "Optimization", :institution "Zuse-Institute Berlin", :country "Germany", :sessions (213)}, 29756 {:firstname "Harald", :lastname "Held", :department "", :institution "Siemens", :country "Germany", :sessions (213)}, 29757 {:firstname "David", :lastname "Álvarez-Martínez", :department "Industrial Engineering", :institution "Universidad de Los Andes", :country "Colombia", :sessions (177)}, 29758 {:firstname "Wonsang", :lastname "Lee", :department "Digital Media Services", :institution "Yonsei University Library", :country "Korea, Republic of", :sessions (109)}, 29760 {:firstname "Rafael", :lastname "Martinelli", :department "Industrial Engineering", :institution "Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio)", :country "Brazil", :sessions (182)}, 29761 {:firstname "Diego", :lastname "Pecin", :department "Informatica", :institution "PUC-Rio", :country "Brazil", :sessions (182)}, 29772 {:firstname "Luis Miguel", :lastname "Escobar Falcón", :department "Maestría en Ing. Eléctrica", :institution "Universidad Tecnológica de Pereira", :country "Colombia", :sessions (177)}, 29782 {:firstname "Olle", :lastname "Sundstroem", :department "", :institution "IBM Research - Zurich", :country "Switzerland", :sessions (103)}, 29783 {:firstname "Carl", :lastname "Binding", :department "Computer Sciences", :institution "IBM Research - Zurich", :country "Switzerland", :sessions (103)}, 29785 {:firstname "Markus", :lastname "Lang", :department "", :institution "University of Zurich", :country "Switzerland", :sessions (104)}, 29786 {:firstname "Patricia", :lastname "Deflorin", :department "Departement of Business Administration", :institution "University of Zurich", :country "Switzerland", :sessions (104)}, 29787 {:firstname "Helmut", :lastname "Dietl", :department "", :institution "University of Zurich", :country "Switzerland", :sessions (104)}, 29788 {:firstname "Eric", :lastname "Lucas", :department "", :institution "University of Zurich", :country "Switzerland", :sessions (104)}, 29808 {:firstname "Hiroto", :lastname "Suzuki", :department "Research Institute for Science and Engineering", :institution "Waseda University", :country "Japan", :sessions (257)}, 29834 {:firstname "Freddy", :lastname "Delbaen", :department "", :institution "ETH Zurich", :country "Switzerland", :sessions (215)}, 29835 {:firstname "Josef ", :lastname "Teichmann", :department "D-MATH", :institution "ETH Zurich", :country "Switzerland", :sessions (218)}, 29836 {:firstname "Johan", :lastname "Schubert", :department "Information Systems", :institution "Swedish Defence Research Agency", :country "Sweden", :sessions (253)}, 29837 {:firstname "Farshad", :lastname "Moradi", :department "", :institution "Swedish Defence Research Agency", :country "Sweden", :sessions (253)}, 29861 {:firstname "Peter", :lastname "Buehlmann", :department "Department of Mathematics", :institution "ETH Zurich", :country "Switzerland", :sessions (230)}, 29862 {:firstname "Paul", :lastname "Embrechts", :department "Department of Mathematics", :institution "ETH Zurich", :country "Switzerland", :sessions (154)}, 29863 {:firstname "Karl", :lastname "Isler", :department "", :institution "Swiss International Air Lines", :country "Switzerland", :sessions (155)}, 29864 {:firstname "Peter", :lastname "Nieuwesteeg", :department "", :institution "Paragon Decision Technology B.V.", :country "Netherlands", :sessions (82)}, 29871 {:firstname "Huang", :lastname "Zuqing", :department "", :institution "China Jiliang University", :country "China", :sessions (247)}, 29922 {:firstname "Juliane", :lastname "Dunkel", :department "", :institution "Massachusetts Institute of Technology", :country "United States", :sessions (150)}, 29924 {:firstname "Tamara", :lastname "Ulrich", :department "Computer Engineering and Networks Laboratory", :institution "ETH Zurich", :country "Switzerland", :sessions (160)}, 29932 {:firstname "Philip", :lastname "Constantinou", :department "School of Electrical & Computer Engineering,National Technical University of Athens", :institution "Mobile Radiocommunications Laboratory", :country "Greece", :sessions (104)}, 29965 {:firstname "Lothar", :lastname "Thiele", :department "Computer Engineering and Networks Laboratory", :institution "ETH Zurich", :country "Switzerland", :sessions (160)}, 29971 {:firstname "Magdalena", :lastname "Kuntner", :department "Institute for Financial Accounting and Auditing", :institution "Vienna University of Economics and Business", :country "Austria", :sessions (95)}, 29972 {:firstname "Barbara", :lastname "Schallmeiner", :department "Institute for Financial Accounting and Auditing", :institution "Vienna University of Economics and Business", :country "Austria", :sessions (95)}, 29977 {:firstname "Niklaus", :lastname "Eggenberg", :department "", :institution "APM Technologies SA", :country "Switzerland", :sessions (239)}, 29993 {:firstname "Renger", :lastname "van Nieuwkoop", :department "Management, Technology and Economics", :institution "ETH Zuerich", :country "Switzerland", :sessions (79)}, 30001 {:firstname "Tommy", :lastname "Klein", :department "", :institution "Research Station Agroscope Reckenholz-Tänikon ART", :country "Switzerland", :sessions (160)}, 30014 {:firstname "Alberto", :lastname "Caprara", :department "DEIS", :institution "Universita di Bologna", :country "Italy", :sessions (210)}, 30015 {:firstname "Safae", :lastname "EL Haj Ben Ali", :department "ESTADISTICA E.I.O.", :institution "Universidad de Sevilla", :country "Spain", :sessions (177)}, 30019 {:firstname "Anton", :lastname "Belyakov", :department "Mathematical Methods in Economics", :institution "Vienna University of Technology", :country "Austria", :sessions (198)}, 30065 {:firstname "Jonathan", :lastname "Li", :department "Mechanical and Industrial Engineering", :institution "University of Toronto", :country "Canada", :sessions (264)}, 30074 {:firstname "Chrysovalantis", :lastname "Gaganis", :department "Department of Economics", :institution "University of Crete", :country "Greece", :sessions (109)}, 30724 {:firstname "Emiliano", :lastname "Traversi", :department "", :institution "Fakultät für Mathematik, Technische Universität Dortmund", :country "Germany", :sessions (210)}, 30896 {:firstname "Babak", :lastname "Farhang Moghaddam", :department "", :institution "Institute for Management and Planning Studies", :country "Iran, Islamic Republic of", :sessions (246)}, 31871 {:firstname "Amir Afshin", :lastname "Fatahi", :department "Industrial Engineering", :institution "Islamic Azad University, Parand Branch", :country "Iran, Islamic Republic of", :sessions (246)}, 32003 {:firstname "Nuxia", :lastname "Espinoza", :department "", :institution "CRIDESAT", :country "Chile", :sessions (261)}, 32762 {:firstname "aaa", :lastname "bbb", :department "", :institution "XXXX", :country "Spain", :sessions (125)}, 35072 {:firstname "Busra", :lastname "Temocin", :department "", :institution "Middle East Technical University ", :country "Turkey", :sessions (62)}, 36610 {:firstname "Patrick", :lastname "Beullens", :department "School of Mathematics, School of Management", :institution "University of Southampton", :country "United Kingdom", :sessions (255)}, 38976 {:firstname "Fuad", :lastname "Aleskerov", :department "Mathematics", :institution "NRU HSE", :country "Russian Federation", :sessions (268)}, 39239 {:firstname "Gustav", :lastname "Feichtinger", :department "Institute of Statistics and Mathematical Methods in Economics", :institution "Vienna University of Technology", :country "Austria", :sessions (41 197 198)}, 40725 {:firstname "Lyudmila", :lastname "Kuzmina", :department "Theoretical mechanics", :institution "Kazan National Research Technical University - Kazan Aviation Institute - National Research University", :country "Russian Federation", :sessions (201)}, 41043 {:firstname "Guruprasad", :lastname "Nagaraj", :department "Computer Science", :institution "CMR Institute of Technology", :country "India", :sessions (142)}, 42208 {:firstname "Volkan", :lastname "Çakır", :department "Industrial Engineering", :institution "Istanbul Arel University", :country "Turkey", :sessions (247)}, 44490 {:firstname "Nadezda", :lastname "Pakhomova", :department "Economic Faculty", :institution "St. Petersburg State University", :country "Russian Federation", :sessions (168)}, 46693 {:firstname "Wolfram", :lastname "Wiesemann", :department "", :institution "Imperial College London", :country "United Kingdom", :sessions (115)}, 48141 {:firstname "Ewa", :lastname "Bednarczuk", :department "Modelling and Optimization of Dynamical Systems", :institution "Systems Research Institute of the PAS", :country "Poland", :sessions (194)}, 48465 {:firstname "Oleg", :lastname "Khamisov", :department "", :institution "Energy System Institute", :country "Russian Federation", :sessions (195)}, 50532 {:firstname "Alwin", :lastname "Haensel", :department "", :institution "Haensel AMS", :country "Germany", :sessions (101)}, 51317 {:firstname "Esra", :lastname "Karasakal", :department "Industrial Engineering Department", :institution "Middle East Technical University", :country "Turkey", :sessions (259)}, 59498 {:firstname "Andreas", :lastname "Bärmann", :department "", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (270)}, 59838 {:firstname "Barbara", :lastname "Glensk", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (130)}}}