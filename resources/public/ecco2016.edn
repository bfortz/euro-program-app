{:timeslots {1 {:schedule "Thursday, 9:00 - 9:30", :day "T", :time "A", :sessions (41)}, 2 {:schedule "Thursday, 9:30 - 10:30", :day "T", :time "B", :sessions (3)}, 4 {:schedule "Thursday, 11:00 - 12:40", :day "T", :time "C", :sessions (12 13 14 15)}, 5 {:schedule "Thursday, 14:30 - 16:10", :day "T", :time "D", :sessions (16 17 18 19)}, 6 {:schedule "Thursday, 16:40 - 17:55", :day "T", :time "E", :sessions (20 21 22 23)}, 7 {:schedule "Friday, 9:00 - 10:00", :day "F", :time "A", :sessions (2)}, 8 {:schedule "Friday, 10:00 - 10:50", :day "F", :time "B", :sessions (24 25 26 27)}, 9 {:schedule "Friday, 11:20 - 13:00", :day "F", :time "C", :sessions (28 29 30 31)}, 10 {:schedule "Friday, 14:30 - 15:30", :day "F", :time "D", :sessions (4)}, 11 {:schedule "Saturday, 9:00 - 10:00", :day "S", :time "A", :sessions (5)}, 12 {:schedule "Saturday, 10:00 - 10:50", :day "S", :time "B", :sessions (32 33 34 35)}, 13 {:schedule "Saturday, 11:20 - 13:00", :day "S", :time "C", :sessions (37 38 39 40)}, 14 {:schedule "Saturday, 13:00 - 13:10", :day "S", :time "D", :sessions (42)}}, :streams {1 {:name "Contributed", :order 1, :sessions (12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 37 38 39 40)}, 2 {:name "Invited Talks", :order 2, :sessions (3 2 4 5)}, 3 {:name "Opening / Closing", :order 1, :sessions (41 42)}}, :sessions {2 {:name "Invited AF", :stream 2, :chairs (4503), :specialroom "Room 1", :timeslot 7, :papers (228), :track 1}, 3 {:name "Invited DP", :stream 2, :chairs (1252), :timeslot 2, :papers (230), :track 1}, 4 {:name "Invited LL", :stream 2, :chairs (5390), :timeslot 10, :papers (219), :track 1}, 5 {:name "Invited AB", :stream 2, :chairs (4503), :timeslot 11, :papers (267), :track 1}, 12 {:name "Graph Theory I", :stream 1, :chairs (51577), :timeslot 4, :papers (119 260 200 197), :track 1}, 13 {:name "Game Theory I", :stream 1, :chairs (50732), :timeslot 4, :papers (72 75 237 88), :track 2}, 14 {:name "Energy and scheduling", :stream 1, :chairs (51132), :timeslot 4, :papers (70 184 190 130), :track 3}, 15 {:name "Routing and logistics", :stream 1, :chairs (51930), :timeslot 4, :papers (16 194 261 235), :track 4}, 16 {:name "Combinatorial Algorithms I", :stream 1, :chairs (11277), :timeslot 5, :papers (160 224 163 90), :track 1}, 17 {:name "Integer Programming I", :stream 1, :chairs (16992), :specialroom "Room 2", :timeslot 5, :papers (186 246 125 180), :track 2}, 18 {:name "Scheduling algorithms", :stream 1, :chairs (22043), :timeslot 5, :papers (42 56 229), :track 3}, 19 {:name "Routing and location", :stream 1, :chairs (35631), :timeslot 5, :papers (166 181 118 174), :track 4}, 20 {:name "Combinatorial Algorithms II", :stream 1, :chairs (51635), :timeslot 6, :papers (158 91 256), :track 1}, 21 {:name "Computational biology", :stream 1, :chairs (50858), :timeslot 6, :papers (154 165 175), :track 2}, 22 {:name "Scheduling in manufacturing systems", :stream 1, :chairs (9037), :timeslot 6, :papers (204 215 233), :track 3}, 23 {:name "Vehicle routing", :stream 1, :chairs (50930), :timeslot 6, :papers (39 47 97), :track 4}, 24 {:name "Graph Theory II", :stream 1, :chairs (51707), :timeslot 8, :papers (53 232), :track 1}, 25 {:name "Game Theory II", :stream 1, :chairs (2509), :timeslot 8, :papers (192 155), :track 2}, 26 {:name "Embedded scheduling problems", :stream 1, :chairs (51093), :timeslot 8, :papers (234 136), :track 3}, 27 {:name "Supply chains I", :stream 1, :chairs (48951), :timeslot 8, :papers (52 120), :track 4}, 28 {:name "Optimization in Networks", :stream 1, :chairs (16077), :timeslot 9, :papers (211 262 113 17), :track 1}, 29 {:name "Integer Programming II", :stream 1, :chairs (5994), :timeslot 9, :papers (86 266 101), :track 2}, 30 {:name "Project scheduling", :stream 1, :chairs (10217), :timeslot 9, :papers (268 137 33 100), :track 3}, 31 {:name "Supply chains II", :stream 1, :chairs (11482), :timeslot 9, :papers (115 122 117 264), :track 4}, 32 {:name "Exact methods  ", :stream 1, :chairs (50992), :timeslot 12, :papers (116 104), :track 1}, 33 {:name "Optimization algorithms", :stream 1, :chairs (35317), :timeslot 12, :papers (150 161), :track 2}, 34 {:name "Optimization at airports", :stream 1, :chairs (24329), :timeslot 12, :papers (108 177), :track 3}, 35 {:name "Algorithms and computational design", :stream 1, :chairs (52000), :timeslot 12, :papers (61 245), :track 4}, 37 {:name "Combinatorial Algorithms III", :stream 1, :chairs (51698), :timeslot 13, :papers (225 248 218), :track 1}, 38 {:name "Integer Programming III", :stream 1, :chairs (10785), :timeslot 13, :papers (250 251 131), :track 2}, 39 {:name "Supply chains III", :stream 1, :chairs (47432), :timeslot 13, :papers (258 238 146 74), :track 3}, 40 {:name "Manufacturing applications", :stream 1, :chairs (50699), :timeslot 13, :papers (173 183 80 73), :track 4}, 41 {:name "Opening session", :stream 3, :chairs (1252 4503), :timeslot 1, :papers nil, :track 1}, 42 {:name "Closing session", :stream 3, :chairs (1252 4503), :timeslot 14, :papers nil, :track 1}}, :rooms {1 {:room "Room 1"}, 2 {:room "Room 2"}, 3 {:room "Room 3"}, 4 {:room "Room 4"}}, :keywords {11 {:name "Integer programming", :sessions (13 15 16 17 28 29 30 32 34 37 38 39)}, 12 {:name "Mixed integer programming", :sessions (13 14 15 17 19 20 22 26 29 30 31 4 39)}, 13 {:name "Global optimization", :sessions (33)}, 14 {:name "Stochastic integer programming", :sessions (19 40)}, 16 {:name "Heuristics and meta-heuristics", :sessions (13 14 15 18 20 26 27 28 29 30 33 34 39 40)}, 17 {:name "Graph theory and networks", :sessions (12 16 20 2 24 25 28 32 37)}, 18 {:name "Cutting and packing", :sessions (17 40)}, 19 {:name "Routing, location and capacity planning", :sessions (3 15 19 23 27 28 29 5 39 40)}, 20 {:name "Scheduling", :sessions (13 14 18 19 22 26 30 34 39)}, 21 {:name "Multiobjective programming", :sessions (15 23 26)}, 22 {:name "Computational biology, bioinformatics and medicine", :sessions (21 5)}, 23 {:name "Game theory", :sessions (13 25)}, 24 {:name "Data mining", :sessions (20)}, 26 {:name "Logistics and supply chain management", :sessions (3 17 18 19 23 27 31 39 40)}, 27 {:name "Manufacturing", :sessions (14 22 28 31 40)}, 29 {:name "Energy production and distribution", :sessions (39)}, 30 {:name "Telecommunications", :sessions (28)}, 32 {:name "Financial sector", :sessions (39)}, 36 {:name "Exact algorithms for combinatorial optimization problems", :sessions (3 12 17 18 19 20 21 23 2 24 28 32 38)}, 38 {:name "Machine learning", :sessions (31)}, 39 {:name "Algorithm Engineering", :sessions (15 22)}, 40 {:name "Algorithm and Computational Design", :sessions (16 17 24 30 4 35 37)}, 41 {:name "Algorithms", :sessions (12 13 16 17 19 20 21 25 29 30 31 33 35 37 38)}, 42 {:name "Semidefinite Optimization", :sessions (28 32)}, 43 {:name "Combinatorial Optimization", :sessions (12 13 15 16 17 20 21 22 23 24 25 27 28 29 30 31 4 33 34 35 37 38 39 40)}}, :papers {16 {:keyword1 16, :keyword3 19, :abstract "The combination of the general scheduling problem with the traditional vehicle routing problem gives rise to the Workforce Scheduling and Routing Problem (WSRP) that arises in practical applications. Given a number of service technicians with different skills and tasks at different locations with time windows and skill requirements, the WSRP consists of finding the assignment and ordering of technicians to tasks such that they only attend to tasks that they are skilled to perform, within the respective time windows, and that the total cost of the routing is minimised. This paper describes an iterated local search algorithm for solving the WSRP. The performance of the proposed algorithm is evaluated against an off-the-shelf optimizer and an existing adaptive large neighbourhood search algorithm on benchmark instances. The results indicate that the proposed algorithm can produce high-quality solutions in reasonable computational times. ", :title "Iterated local search for the workforce scheduling and routing problem ", :keyword2 43, :authors (50340 4 2435), :session 15}, 17 {:keyword1 43, :keyword3 36, :abstract "We consider the problem of finding an optimum schedule for restoring a transportation network destroyed or damaged as a result of an extreme event (disaster). The extreme event destroyed connectivity between vertices which needs to be restored as soon as possible. For each pair of vertices, a due date for restoring the connectivity of the pair is given. The restoration speed, defined by available resources, is constant. Any part of the network is accessible for restoration at any time. It is required to find an optimal schedule of restoration activities that minimizes the maximum lateness of vertex pairs. We discuss complexity of the problem and its structural properties, a mixed-integer linear programming formulation, lower bounds on the optimal objective value, and present a branch-and-bound exact algorithm and results of computational experiments.", :title "Pairwise Connection Restoration Problems in Networks", :keyword2 17, :authors (16077 48039), :session 28}, 33 {:keyword1 16, :keyword3 40, :abstract "Derivative-based numerical methods are usually insufficient for solving difficult computational optimization problems. Therefore, most of the researchers devoted their research efforts towards developing metaheuristic algorithms for solving complex/difficult computational optimization problems. Researchers are usually tried to imitate some natural phenomenon for metaheuristic algorithm development.  Although many effective metaheuristic algorithms were evolved for problem solving, very few of them truthfully realize dynamic characteristics of the phenomenon they try to imitate. We believe that an agent based modeling/design environment will be more useful and natural way for a better realization of the inspired phenomenon. It is possible to model various behaviors (like; entering and leaving of agents, group forming etc), purposeful inter-agent communications for goal seeking etc easily by making use of the power of agent based system modeling and algorithm development. Based on this motivation, Stochastic Diffusion Search Algorithm (SDS) is modeled/realized in a multi agent environment for modeling and solving Resource Constrained Scheduling Problem (RCPS) first time in the literature. JACK Autonomous Software and Eclipse Java Platform are employed for modeling and evolving the simulation models and experiments. In order to examine the performance and behavior of the proposed model, several tests are carried out on different data sets which are known as J30, J60, J90, J120 in the related literature. Moreover, different local search mechanisms and lox-crossover mechanism are also incorporated into the SDS algorithm for performance improvement. The preliminary results obtained from our experiments are shown that the proposed agent based model can produce efficient solutions.", :title "Realization of Stochastic Diffusion Search Algorithm in a Multi-Agent Modeling Environment for Resource Constrained Project Scheduling Problem", :keyword2 43, :authors (50490 36036), :session 30}, 39 {:keyword1 19, :keyword3 26, :abstract "   In contrast to the main works on Fuzzy Vehicle Routing Problem (FVRP) in this work both poles of expert data - uncertainty (possibility measure of the vehicle movement on the routes) and imprecision (fuzzy traveling times on the routes) are condensed in models’ parameters by the Choquet integral. Obviously, the use of such aggregations with both information poles in FVRP models would make them more reliable. Our aim was to create possibilistic but non-probabilistic environment for developing of the subjective criterion - the feasibility of vehicle moving on closed routes in the extreme conditions.\r\nAn intelligent-interactive algorithm of generation of possibility levels of the vehicle movement on the closed routes is constructed. Using Choquet Integral the possibilistic expectation of total fuzzy travel time on the closed routes is constructed. If we consider a classical capacitated VRP with one depot but for extreme environment the bi-criteria partitioning problem on all possible closed routes can be constructed. This problem considers the partitioning of closed routes, which satisfies two criteria: the possibilistic expectation of total fuzzy travel time is minimal and feasibility of vehicle movement on these routes of partitioning is maximal.\r\n   Our approach for the solving of the constructed bi-criteria partitioning problem belongs to a two-phase approach strategy by classification of the Gilbert Laporte. At first phase: so called “promising” routes are constructed. In practice, building all admissible routes is impossible because of their large number in real problems. Therefore we are considering only a limited number of promising routes based on heuristic approaches. We make this selection using the specially created algorithm based of so called “constructive” approach. A construction of promising routes is performed by the analysis of individual customers' demand values, their geographical locations and defined limits on the maximum route length and load capacity of the vehicles. Second phase: We solve the bi-criteria type partitioning problem for the selected promising closed routes when the number of selected rational closed routes is much less than the real large number of admissible routes. The -constraint method is used for the numerical solution of this problem for promising routes. For the scaling minimal partitioning problem with the -constraints we created generalized parallel exact algorithm based on D. Knuth’s Dancing Links technique DLX. The illustrated practical examples show the usability of the new approach in VRP for difficult situations on the roads. \r\n   In our future works we will develop our new approach for more complex models like VRP with time windows and others.", :title "Bi-criteria Fuzzy Vehicle Routing Problem for Extreme Conditions on the Roads", :keyword2 21, :authors (35266 50930), :session 23}, 42 {:keyword1 20, :keyword3 0, :abstract "Container shipping plays important role in the contemporary logistics. Port container terminals have key importance in global trade as transshipment points where modes of transportation change. Due to growing competitiveness between ports a port authority must take into account significant factors attracting maritime traffic. One of them is vessel turnaround time.\r\nVessel turnaround time is determined by the allocation and sequencing of ships and cranes at the berths. Hence, Quay Crane Assignment Problem (QCAP), Quay Crane Scheduling Problem (QCSP), and Berth Allocation Problem (BAP) were considered in the literature. \r\nIn this presentation we consider Berth Allocation Problem. BAP is usually solved before QCAP, QCSP because ships are most valuable and least flexible element of the harbor logistics. Consequently, assigning vessels to berths in the port is one of the most critical actions undertaken by the port manager. BAP is defined by a set of ships and berths. A ship is determined by its arrival time, length, unloading and loading time, importance. A berth is characterized by its length. The optimality criteria are mean weighted flow time and mean weighted stretch. BAP can be solved to optimality only for small instances and very short time horizons. Long time horizons are more typical when estimating limits of port throughput. We introduce a bunch of heuristics, including greedy and fast metaheuristics, which can be used for solving big instances of BAP emerging when time horizon of months and years come into consideration. Performance of the heuristics is analyzed with respect to quality of solutions and runtime. ", :title "Heuristics for solving the Berth Allocation Problem", :keyword2 26, :authors (50204 806 39366 19524 36740), :session 18}, 47 {:keyword1 19, :keyword3 21, :abstract "Set partitioning problem (SPP) belongs to the widely spread class of discrete optimization and is well known for number of applications. In particular, we can note one of the methods of solving vehicle routing problems (VRP) by solving minimum partitioning problem. Set partitioning problem algorithms have been successfully applied to airline crew scheduling problems too.\r\nIn reality, most of decision making problems are multicriteria by nature, the optimal solution is evaluated by several criteria. Multicriteria optimization problems are harder to solve compared to scalar optimization problems and requires specific methods and approaches.\r\nOur approach for solving VRP has two phases. At the first phase we build set of admissible routes based on some heuristic considerations. At the second phase from generated admissible routes we choose the optimal ones by solving set partitioning problem.\r\nWe present the task of solving bicriteria set partitioning problem using ε-constraint method. The algorithm is constructed which allows us to find Pareto optimal (efficient) solutions. For solving partitioning problem, the modified version of D.Knuth’s Dancing Links algorithm is used.\r\nThe research and test results has shown that bicriteria set partitioning problem can be successfully used for creating decision support systems with practical applications.\r\n", :title "Bicriteria Partitioning Problem: Application to VRP", :keyword2 43, :authors (50597 50930), :session 23}, 52 {:keyword1 43, :keyword3 26, :abstract "In the advancement of sensor technology, it is expected that each machine (or asset) would be connected with other machines in near future. To perform task efficiently, machines need to work together (share information) and one machine needs to perform more than one task at a time if capacity permits. This paper proposes a novel mathematical modelling for connected movable or static machine allocation to various tasks request where each task has earliest start-time and latest completion time. The complexity of the mathematical model is analyzed and the model tightening approached is proposed to solve the problem faster using branch and cut algorithms. This problem can be mapped as a dial-a-ride problem but the existing dial-a-ride problem does not consider the aspects of IoT (i.e., machine to machine communication and task hopping between two machines). Based on the dial-a-ride scenario, the data is simulated for testing the proposed model. The solution quality and execution time of the proposed mathematical model are compared with the existing mathematical model (i.e., vehicle routing model (Santos et al. 2015)) for dial-a-ride problem. The analysis suggests that the proposed model generates solution faster than existing model and it can be implemented in real-life scenario.\r\n\r\nReferences:\r\n1.\tSantos, D. O., & Xavier, E. C. (2015). Taxi and ride sharing: a dynamic dial-a-ride problem with money as an incentive. Expert Systems with Applications, 42(19), 6728-6737.\r\n", :title "A mathematical model for dynamic asset and task allocation in IoT ecosystem", :keyword2 19, :authors (50616), :session 27}, 53 {:keyword1 43, :keyword3 17, :abstract "In 1958, Ryser solved the problem of finding a degree-specified simple bipartite graph G=(S,T;E) in which the matching number is as large as possible. In this talk we present an extension of Ryser's result by finding a degree-bounded simple bipartite graph in which the matching number is as large as possible and the total number of edges also falls between given bounds. Formally, we consider the following problem. Let S and T be disjoint sets and f and g be lower and upper bound functions on the union of S and T. Moreover, let MIN and MAX be non-negative integers. Our aim is to find a simple bipartite graph G=(S,T;E) with maximum matching number such that the degrees fall between the upper and lower bounds and |E| falls between MIN and MAX. We describe a direct algorithmic solution to compute such a graph. \r\n\r\nThere are well-known algorithms and techniques that can be applied for matching problems in bipartite graphs. A characteristic feature of these methods is that the the weighted (or minimum cost) versions of the applications are typically also tractable. The minimum cost version of the above problem had not been settled for a long time, but recently Pálvölgyi proved that this min-cost version is in fact NP-complete. Therefore earlier approaches -like using network flows- to attack the maximum term rank problem are not applicable. The sharp borderline between the problem of finding a degree-specified simple bipartite graph and the problem of finding a degree-specified simple bipartite graph with matching number at least k is best clarified by the fact that -though both problems are in P- the natural extension of the first problem, when a degree-specified subgraph of an initial bipartite graph is to be found, is still in P, while the analogous extension of the second problem, when a degree-specified subgraph with matching number at least k of an initial bipartite graph is to be found, is already NP-complete.\r\n\r\nOur algorithm resolves this problem and provides a new tool that proved to be widely applicable when a degree-bounded simple bipartite graph satisfying certain matching constraints is needed.", :title "Degree-bounded simple bipartite graphs with maximum matching number", :keyword2 36, :authors (38451 50624), :session 24}, 56 {:keyword1 26, :keyword3 16, :abstract "We consider the problem of scheduling two identical rail mounted gantry cranes (twin cranes) working within a single storage area (block) at a seaport. The cranes, referred to as seaside crane and landside crane, cannot pass each other. We focus on peak times, where the minimization of dwell times of vessels at the berth is typically the major objective of port authorities. Earlier studies have shown that allowing the cranes to cooperate, i.e. allowing the seaside crane to drop inbound containers at intermediate positions where the landside crane takes over and delivers the containers to their target slots, is beneficial, at least when there are no containers that are already stored in the block at the beginning of the planning horizon and that have to be delivered to the landside handover point by the landside crane within given time windows. In this paper, we analyze if this remains true when these latter jobs are present. This might have a critical impact because these tasks are performed close to the landside whereas supporting the seaside crane is performed rather close to the seaside. We present complexity results and some general insights into the aforementioned problem. Furthermore, we introduce lower bounds and we develop heuristic procedures that apply these bounds. The performance of the algorithms is evaluated in computational tests.", :title "Scheduling cooperative gantry cranes with seaside and landside jobs", :keyword2 20, :authors (29563 12453), :session 18}, 61 {:keyword1 40, :keyword3 43, :abstract "The International Organization for Standardization defines a cloud service broker (CSB) as a “cloud service partner that negotiates relationships between cloud service customers and cloud service providers”. A cloud service partner is further explained as a “party which is engaged in support of, or auxiliary to, activities of either the cloud service provider or the cloud service customer or both”. The second type of partner described in the standard is the cloud auditor. In other words, cloud brokering encompasses a wide range of activities. Essentially, it includes all intermediaries that stand between a cloud service provider (CSP) and a cloud service customer (CSC). The negotiation of relationships is most often understood as a proposition of contract that’s satisfying for both customers and providers. Sustainable broker business models must create added value to ensure that CSCs have real interest in using broker services.\r\n\r\nMotivations for using broker services vary. First, using these services might be more advantageous from an economical viewpoint: CSBs might offer better conditions to customers than CSPs. On the other hand, CSBs might create new channel and marketing opportunities for CSPs, resulting in a growth of sales.\r\n\r\nThe external position of CSBs might also result in the creation of new products based on existing CSP offers. Brokers don’t have to be bound by loyalty to a single company. As a result, they can select the most suitable combination of services for their clients. Moreover, their independence allows them to introduce redundancy by simultaneously using different CSPs. In such a case, it might be hard to distinguish between CSBs and CSPs, especially if the former use advanced Web interfaces to automatically provide services to users. The relationship between the CSC and CSB shall be established in clear terms, allowing further determination of the respective liability. Because the cloud appeared relatively recently on the ICT market, compliance with the law isn’t sufficiently clear, and many new legal questions could appear in the future.", :title "Cloud Brokering: Yesterday, Today and Tomorrow", :keyword2 41, :authors (26119 50709 50710 18733 5390), :session 35}, 70 {:keyword1 20, :keyword3 0, :abstract "We study parallel machine scheduling problems with jobs requiring some non-renewable resources (e.g. raw materials or money). Each resource has an initial stock, which is replenished in known quantities at given dates. A schedule is feasible if no two jobs overlap in time, and when a job is started enough resources are available to cover its requirements. The jobs consume the required resources. The problem has a great practical interest.\r\n\r\nWe have both new inapproximability and approximability results.\r\n\r\n1) If the number of the machines is not a constant (part of the input) then the problem is APX-hard even in case of 2 resources and 2 supply dates. We reduce the problem EVEN-PARTITION to our problem.\r\n\r\n2) There is a PTAS for the makespan minimization problem if the number of the machines and the number of the resources are both bounded by a constant. This is the first approximation scheme that does not require constant number of the supplies or a strong link between the processing times and the resource requirements.\r\n\r\nWe modeled the problem with an integer program and we reuse many techniques from our previous PTAS-es, however the proof became significantly complicated. First, we reduce our problem to a similar problem where there are only a constant number of supplies. Then we divide the jobs into big and small ones, and schedule them separately. We search several, but still a constant number of partial solutions of the IP. Each partial solution essentially gives a schedule of the big jobs. After that we define a residual problem for every partial solution and solve that approximately. We use an LP rounding at this phase. Finally, we piece together the reached results and specify a feasible schedule with a makespan at most 1+epsilon times greater than the optimal.\r\n\r\nWe have the same result if the jobs are (partially) dedicated to the machines. We can extend both results by enabling job specific release dates as well.\r\n\r\n3) If there is only one resource and the resource requirement of each job is equal to its processing time we consider lateness as an objective. Since the optimum lateness may be 0, a standard trick is to increase the lateness of the jobs by a constant. For this objective we have PTAS for constant number of machines. We divide the jobs into big and small ones and examine polynomial number of partial solutions that essentially meet the big job schedules before the last supply. We use a greedy-like algorithm to schedule the remaining jobs (and may modify some starting times by a little). According to our knowledge this is first approximation scheme of the topic for the (increased) lateness objective.\r\n\r\nAcknowledgements: This work has been supported by the OTKA grant K112881.\r\n", :title "Approximation schemes for parallel machine scheduling with non-renewable resources", :keyword2 0, :authors (49684 4503), :session 14}, 72 {:keyword1 20, :keyword3 0, :abstract "We consider the problem of designing polynomial time truthful mechanisms for machine scheduling problems with parallel identical machines where some of the jobs' characteristics are private information of their respective owners and a central decision maker is in charge of computing the schedule. We study a one-dimensional setting with private weights and a two-dimensional setting, where weights and due dates are private information. We characterize a monotonicity condition and analyze payment functions related to incentive compatibility for the class of List-Scheduling algorithms in the first setting. Furthermore, we derive truthful polynomial time mechanisms for the global objectives of minimizing the total weighted completion time for the one-dimensional case and minimizing the sum of the weights of those jobs that are completed after their due dates for the two-dimensional setting with only one machine. For the latter setting with more than one machine, we conjecture that any truthful polynomial time mechanism must be based on a heuristic framework differing from the one used in the case of one machine.", :title "Incentive Compatible Mechanisms for Machine Scheduling Problems with Job Agents", :keyword2 23, :authors (38193 29563 10954), :session 13}, 73 {:keyword1 14, :keyword3 0, :abstract "Workforce planning is of strategic importance to most organisations. It is in particular challenging when tasks may require various multiple specialised skills of the workforce and when the future demand for each type of task is uncertain. In such environments, the value of dynamic skill development within a workforce cannot be ignored. We are in particular interested in increasing our understanding of how multiple skills and their development should be distributed among a pool of technicians, and how this may depend on the operational environment.\r\n \r\nThis research develops a novel approach based on stochastic mixed integer linear programming for determining an optimal strategic plan of hiring and skill development of a multi-skilled workforce when there are high levels of uncertainty in the tasks and their requirements. In particular, we consider the case of a complex maintenance line operated by a multi-skilled workforce with these characteristics, and the problem calls for determining effective and efficient strategies for hiring, training, and operational allocation of technicians. Skill development can occur through various training exercises and through the experience of executing repeated tasks. This development is used to determine each employee’s skill sets over the time horizon given that they must renew their skills before a fixed time.\r\n \r\nIn this paper we focus on the development of the model and its application in organisations. We discuss the extension of this research through a sensitivity analysis of the optimal workforce strategy through various changes to demand, components of the maintenance lines, and training strategies. Employees are considered under different pay brackets to compare a multi-skilled to a specialist workforce where pay is linked to the number of skills", :title "Skill development in a multi-skilled workforce for maintenance operations", :keyword2 43, :authors (50699 29780 36610), :session 40}, 74 {:keyword1 29, :keyword3 16, :abstract "We consider a firm with, an already existing portfolio of renewable generation resources and customers dispersed over a certain geographical region, which is planning to invest in energy storage systems. The firm uses its renewable resources to generate electricity and the spot electricity markets to meet the demand from the customers. As a result, the firm faces a multi-period capacity management problem where each period corresponds to one hour. The complexity of the problem is further exacerbated by the transmission line constraints in between the supply and demand points. These constrains may also motivate the firm to store electricity when the transmission lines are blocked because of the capacities. The possibility of storing electricity links the operating periods with each other. In particular, the energy produced by the renewable generators can be stored in storage units when the prices are low or the production is high while this energy can be released to the system when either the prices are high or the production is low. In this setup, we investigate the optimal investment plan, i.e., the location, the type and the capacity of the storage facilities and how to optimally operate the whole system. This includes the buy or sell decision at each period to the spot electricity markets, store or release energy from the storage facilities and the shipment of power among the nodes in the network. We investigate optimal investment plan and how to operate storages. Deterministically, we constructed a mixed integer mathematical formulation. Because of the long planning horizon which is 1 year, it is hard to solve optimally. A heuristic approach is developed to get near-optimal solution.\r\n", :title "Optimization of Energy Storage Decisions in Power Networks with Renewable Generation", :keyword2 12, :authors (47432 2644 37025), :session 39}, 75 {:keyword1 12, :keyword3 23, :abstract "In collaborative truckload transportation procurement, shippers come together and negotiate with carriers as group. In transport sector, both shippers and carriers traditionally concentrate individually on how to improve their operational activities and decrease their operational cost.. Firms embark on quest to find new ways to achieve higher levels of efficiency because of reasons such as increased competition, lack of resources, climate change, security problems and legislative regulations. In collaborative truckload transportation procurement; selecting participants, which participant cooperates with which participant, calculating total gains obtained from cooperation and sharing gains among participants are important problems. Collaborating shippers seek the collaborative solution with minimum cost owing to the fact that gains obtained from collaboration result from decreasing costs. After the cost of the collaborative solution is shared among the collaborating firms, the savings of each firm in the collaboration becomes clear. If the costs allocated to the firms are not acceptable, the collaboration is in danger of breaking up. For this reason, a mechanism which provides acceptable cost allocation is needed. In the literature, calculating total cost and allocating total cost are considered separately. In other words, the problem minimizing total cost is solved optimally and the total collaborative cost is calculated first. Then, the total cost is allocated among stakeholders. In addition, most of the works in the literature focus on the stability of a given grand coalition. In this work, we consider finding the minimum cost collaborative solution and cost allocation together. We formulate a mixed integer programming model that selects a stable coalition which yields the highest system-wide savings.  The solution of this model also determines which firm cooperates with which firm. We develop a column and row generation approach for solving the coalition selection model. We test our solution methods on instances generated randomly. We also evaluate our solution methods according to stability condition.", :title "Stable Coalition Selection in Collaborative Truckload Transportation Procurement", :keyword2 16, :authors (41880 28899), :session 13}, 80 {:keyword1 43, :keyword3 16, :abstract "In this study, we deal with the cutting stock problem of a marble company. The marble plane cutting problem can be defined as follows: how to cut a set of stock lengths of marble blocks with known sizes, qualities and available quantities, in order to produce exactly a set of marble planes with specified sizes, qualities and demands, so that the total cost of transportation and over grading is minimized. One of the salient features of this problem is that it does not require a priori enumeration of all possible cutting patterns. In this study, generation of retail to reuse is permitted. Therefore, the present problem can be seen as a one-dimensional cutting stock problem with possible leftover generation and reuse. To the best of our knowledge, we are not aware of other studies in the literature dealing with cutting problems with usable leftover in marble plane manufacturing. We developed a mixed integer linear programming (MILP) model for formally describing the extended problem which is solved to global optimality by using standard techniques. However, the above constitutes a complex combinatorial problem therefore its solution is carried out by utilizing a specifically developed Stochastic Diffusion Search Algorithm (SDS). A number of example problems, including an industrial case study, are presented in order to illustrate the efficiency and applicability of the proposed model. Result shows the usefulness of the proposed approaches.", :title "A mathematical model and stochastic diffusion search algorithm for marble cutting problem", :keyword2 18, :authors (50838 36036), :session 40}, 86 {:keyword1 43, :keyword3 0, :abstract "The quadratic assignment problem (QAP), a classical problem in combinatorial optimization,  is very hard to deal with, both from the theoretical and from the practical point of view. Polynomially solvable special cases (PSSCs) of the problem arise by imposing certain structural and generally quite restrictive  properties on its input matrices. In this contribution we consider the usage of  such PSSCs  to obtain lower bounds for the general problem. More precisely we approximate the input matrices of a general instance of the QAP by matrices with particular structural properties which make the QAP polynomially solvable, such that the optimal objective function value of the involved PSSC is a lower bound for the original problem. This approximation is done in a stepwise approach, where in every step  certain particularly structured matrices are subtracted from the current (permuted) coefficient matrices of the QAP so as to obtain an increasing sequence of bounds. It is a challenging question to decide which PSSC to use in each step of this procedure in order to improve the quality of the bound as much as possible. To this end  we consider different PSSCs known in the literature and also introduce a  new PSCC which seems to be amenable to the computation of lower bounds.  ", :title "Using polynomially solvable special cases of the QAP to generate lower bounds ", :keyword2 41, :authors (28646 4991 55926), :session 29}, 88 {:keyword1 43, :keyword3 0, :abstract "Measuring the reliability of a network is one of the rich and complex areas of combinatorial optimization. Since the precise meaning of reliability highly depends on the application, there is an abundance of reliability metrics that have been proposed. \r\n\r\nApplying game-theoretical tools for measuring security has become very common. The basic idea is very natural: define a game between two virtual players, the Attacker and the Defender, such that the rules of the game capture the circumstances under which reliability is to be measured. Then analyzing the game might give rise to an appropriate security metric: the better the Attacker can do in the game, the lower the level of security is.\r\n\r\nAs an example for this, assume that the Attacker and Defender play the following Spanning Tree Game on a connected graph G. The Defender chooses a spanning tree T of G (that can be viewed as some communication infrastructure) and the Attacker  chooses (or \"attacks\") an edge e of G. If e is not in T then there is no payoff; if, on the other hand, e is in T then the Defender pays 1 to the Attacker. It is known that the Nash-equilibrium payoff of this game is the reciprocal of a well-known graph reliability metric: the strength of G is the minimum over subsets of edges U of the ratio of the size of U and the increase in the number of components caused by deleting U. For the purposes of this talk the most relevant point is that, as shown by the above mentioned result, the notion of graph strength is well captured by the Spanning Tree Game. \r\n\r\nThe main topic of this talk is a far-reaching generalization of the Spanning Tree Game that replaces spanning trees with the bases of an arbitrary matroid and that also allows for non-uniform gains and losses for the two players. Besides the above example, this generalization includes further special cases that came up in security-related applications. \r\n\r\nThe Matroid Base Game is defined as follows. A matroid together with a cost function and a non-negative valued weight function on the ground set are given. The Defender chooses a base B of the matroid and the Attacker chooses an element s of the ground set. In all cases, the Attacker pays the Defender the cost of attack, the cost value corresponding to s. Besides that, if s is in B then the Defender pays the Attacker the weight value corresponding to s; if, on the other hand, s is not in B then there is no further payoff.\r\n\r\nIn this talk we will present results on the Matroid Base Game: a minimax theorem that describes the Nash-equilibrium payoff of the game and a strongly polynomial time algorithm that computes Nash-equilibrium mixed strategies for both players. We will also consider a further generalization of the Matroid Base Game in which common bases of two matroids are chosen by the Defender and we will apply this to define and efficiently compute a new reliability metric on digraphs, a directed analogue of the above mentioned notion of graph strength. ", :title "Security Games on Matroids", :keyword2 23, :authors (50732), :session 13}, 90 {:keyword1 43, :keyword3 11, :abstract "A usual method performed in decision making in order to rank candidates consists in applying a pairwise comparison method: each pair {x, y} of distinct candidates are displayed to the decider and this one must choose x or y but not both; we write xPy when the decider prefers x to y. The result P is generally not transitive: the decider may prefer x to y, y to z and z to x (i.e. xPy, yPz and zPx). Thus the preference P of the decider is usually a tournament (antisymmetric and complete relation) while a linear order (i.e., a transitive tournament) is likely expected. \r\n\r\nTo explain such a behaviour, Tversky suggested to consider several ordered criteria C1, C2, .... If X denotes the set of candidates, the criteria C1, C2, ..., are assumed to be at least transitive relations defined on X. The first criterion, C1, which is assumed to be the most important among the criteria, explains a part of the preferences of the decider. Then, the second criterion, C2, is assumed to explain a part of the preferences of the decider which is not yet explained by C1. More precisely, when we have xPy, it can be because we have xC1y or because we have xC2y while C1 does not decide between x and y: in the first case, x is preferred to y by the first criterion; in the second case, y is not preferred to x (and conversely) by the first criterion but x is preferred to y by the second criterion. With this respect, we see that the role of C1 dominates the one of C2 and C2 decides only between incomparabilities of C1. We may thus explain the lack of transitivity xPy, yPz and zPx: for instance x is preferred to y according to C1 (xC1y) while z is not decided by C1 with respect to x nor y and, moreover, y is preferred to x and z and z is preferred to x according to C2 (yC2z, zC2x and yC2x). In other words, the fact that x is preferred to y by C1 hides the fact that y is preferred to x by C2. This can obviously be generalized to more than two criteria.\r\n\r\nThe lexicographic decomposition of P aims at providing such criteria (C1, C2, ..., Ck) to explain P with transitive structures organized into a hierarchy. The main questions related to the lexicographic decomposition are:\r\n1. does there exist such a decomposition?\r\n2. when such a decomposition exists, what is the minimum number of criteria required to explain P? This minimum number is called the lexicographic dimension of P, noted d(P).\r\n\r\nIf P is a tournament and if the criteria are assumed to be partial orders, this decomposition always exists. Then the computation of the lexicographic dimension leads to the following combinatorial optimization problem: \r\n\r\nProblem: given a tournament T, minimize the number k of partial orders C1, C2, ..., Ck such that the ordered k-tuple (C1, C2, ..., Ck) provides a lexicographic decomposition of T.\r\n\r\nIn this communication, we study the possible values of d(T). We show in particular that, if n denotes the number of candidates that the decider must rank, d(T) is no more than 2log(n).\r\n", :title "Lexicographic decomposition of preferences into partial orders", :keyword2 17, :authors (11277), :session 16}, 91 {:keyword1 12, :keyword3 16, :abstract "Clustering is a useful and important unsupervised learning technique widely studied in the literature. \r\nThe goal of clustering is to group similar units (or objects) into one cluster, \r\nwhile partitioning dissimilar units into different clusters. \r\nClustering becomes difficult if data contain features with no relevant information. \r\nWhen those features are not detected, the calculation of the dissimilarity between units is biased by their presence, \r\nresulting in inconsistent clusters. \r\nThe problem becomes more and more relevant as the the number of features in a data base increases, \r\nas frequently occurs nowadays with application data containing hundreds and even thousands of covariates. \r\nTherefore, researchers from different disciplines need tools to select the features that are important for the analysis\r\nand to discard what are called noisy or masking features. \r\nIn this paper, the variable selection problem is mainly motivated from its application to clustering, \r\nbut the problem is also important in classification and supervised learning. \r\n\r\nHere, the problem of selecting relevant features for clustering is formulated as a\r\nlinear optimization problem with binary unknowns representing the 0-1 decision of rejecting or selecting. \r\nThe elements of the problem are a set U of observations and a set R of cluster centers. \r\nA set of features V are measured for each element of U and R, so that a distance/dissimilarity measure\r\nis calculated between each pair. \r\nSelecting representative variables for clustering is then formulated as the combinatorial problem of finding \r\na subset of V, such that the total aggregation of the distances from the units to the closest center is minimized. \r\nIt is proved that this new combinatorial problem is NP-complete, but, \r\nin spite of this negative result, \r\nefficient exact and heuristic algorithms are proposed. \r\nThe exact methods take advantage of the mixed integer linear programming formulation of the problem, \r\nthat is solved through off-the-shelf solvers.  \r\nRegarding heuristics, it is proposed an algorithm called q-vars that alternates between the optimal\r\nvariables selection for given assignments of units to centers and vice-versa. \r\nIn computational tests, it is discussed what is the best MILP formulation and  \r\nthe best heuristic.\r\nFinally, the q-vars algorithm is applied as the preprocessing procedure \r\nin clustering algorithms and it is shown that clusterings are greatly improved through this methodology.", :title "The Combinatorial Formulation of the Features Selection Problem", :keyword2 24, :authors (5405 5876 1259), :session 20}, 97 {:keyword1 19, :keyword3 36, :abstract "The majority of real-life vehicle routing problems (VRP) cannot be limited to a single objective. Although, generally VRP aims to optimize a cost (for example, minimizing the total distance traveled, the fuel consumed or time spent), we often have to consider other dimensions of the problem. In particular, when there are some extreme conditions on the roads, like high traffic, icy roads, different types of damages, etc., one has to take into consideration not only the cost, but also the uncertainty connected with chosen routes.\r\nWe consider bi-criteria Fuzzy Vehicle Routing Problem (FVRP) for extreme conditions on the roads, where the first objective is minimization the cost (distance or time of traveling) and the second objective is minimization the uncertainty related to the extreme conditions.\r\nOur approach for solving the constructed bi-criteria VRP belongs to the class of two-phase strategies (G.Laporte's classification). Since constructing all admissible routes is practically impossible because of their large number for real-life problems, at the first phase, based on some heuristic considerations, we construct set of so called \"promising\" routes, which should serve as a good representation of all admissible routes. At the second phase we solve bi-criteria partitioning problem in order to cover (partition) all customers with constructed promising routes.\r\nConsidering the disadvantages of scalarization methods, where not all Pareto-optimal (efficient) solutions can be found in general, we use ε-constraint method for solving bi-criteria partitioning problem. Our algorithm is based on D. Knuth’s \"DLX\" algorithm and uses dancing links technique, which allows us to utilize computer memory (RAM) very effectively. Our modified version of DLX algorithm solves multi-criteria partitioning and covering problems, it has parallelization capabilities and can be distributed on multiple CPUs. Based on this algorithm, we have also developed a new algorithm for ε-constraint method, where exact Pareto front can be generated for integer valued bi-criteria partitioning problems. Compared to the standard ε-constraint algorithms, our algorithm filters dominated (weakly effective) solutions during the processing and outputs only efficient solutions as a result of processing.\r\nSince our algorithm has branch-and-bound type of nature, ε-constraint method fits to it perfectly for multi-criteria optimization problems because adding new constraints to a branch and bound procedures is not a complex task and it often reduces the size of the searched tree.\r\nThe test results show that our approach can be successfully applied to vehicle routing problems with practical applications and our algorithm can be used for creating real-life decision support systems.", :title "An Exact Algorithm of Bi-criteria Partitioning Problem for Fuzzy Vehicle Routing Problems", :keyword2 21, :authors (50930), :session 23}, 100 {:keyword1 20, :keyword3 0, :abstract "The Preemptive Discrete-Continuous Resource-Constrained Project Scheduling Problem (PDCRCPSP) is considered, defined as follows. A project consists of n precedence-related, preemptable activities which simultaneously require for their processing discrete and continuous renewable resources. It is assumed that R discrete resources are available and r_il, i=1,…,n; l=1,…,R, is the (fixed) discrete resource request of activity i for resource l. The total number of units of discrete renewable resource l available in each time period is R_l. Additionally, a single continuous resource occurs which can be allotted to activities in arbitrary amounts. Processing rate of activity i is defined by a continuous, increasing and convex function f_i of the amount of the continuous resource u_i(t) allotted to the activity at a time. The total available amount of the continuous resource varies over time. A number H_c of cyclically repeating intervals is given, and the amount U_h>0 of the continuous resource available and constant in the h-th interval, h=1,…,H_c, is known. The length of the h-th interval is also known in advance. The problem is to find a feasible assignment of discrete resources and, simultaneously, a continuous resource allocation that minimize the project duration. Solving the problem, a minimal number H of intervals in which all activities can be completed is simultaneously found.\r\nIt has been shown in previous works that the methodology for solving discrete-continuous project scheduling problems critically depends on the form of the processing rate functions of activities. For concave functions parallel schedules are optimal, whereas for convex functions sequential execution of activities leads to minimal project duration. In the latter case each activity has to use the total availability of the continuous resource. For the case of a constant continuous resource amount the problem is trivial since any schedule, in which activities are processed one after another in a precedence-feasible order each of them using the total amount of the continuous resource, is optimal. Also, preemption of activities is of no importance, since interrupting any activity is the sequence cannot improve the schedule. However, the generalization of the above problem in which the available amount of the continuous resource varies over time becomes more complicated. Moreover, preemptions of activities do matter in this case.\r\nIn this work an exact polynomial algorithm for the PDCRCPSP with convex processing rate functions of activities and the continuous resource amount varying over time is proposed. The algorithm is iterative, and a linear programming (LP) problem has to be solved in each iteration. The number of variables in the formulated LP problem is equal to n times H, and grows linearly with each iteration of the algorithm. In the future concave functions should also be analyzed, which is a more difficult case since parallel schedules have to be considered.\r\n", :title "Preemptive project scheduling with a time-varying continuous resource", :keyword2 41, :authors (10217), :session 30}, 101 {:keyword1 11, :keyword3 16, :abstract "The ILP (Integer Linearization Property), when it holds for a given Lagrangean relaxation, allows one to solve the Lagrangean problems cheaply while yielding strong  Lagrangean bounds if the Lagrangean problem does not have the integrality property. It can be used for an RLT-like  formulation (Sherali and Adams) of the GQAP (Generalized Quadratic Assignment Problem) and a special case of it, the CDAP (Crossdock Door Assignment Problem). The CHH (Convex Hull Heuristic), based on constructing a subset of the convex hull of integer feasible solutions, is a fast matheuristic approach that can be adapted to the model type. We will present a combination of both approaches that generates good feasible solutions and evaluates a corresponding percentage gap for a large number of instances of the GQAP and of the CDAP.  ", :title "Combining the ILP in Lagrangean relaxation and the Convex Hull Heuristic for some generalized quadratic assignment problems.", :keyword2 43, :authors (5994 50957), :session 29}, 104 {:keyword1 36, :keyword3 42, :abstract "We propose a new facility layout problem that we denote as Directed Circular Facility Layout Problem (DCFLP). An instance of the DCFLP consists of one-dimensional machines with given positive lengths and material flows between all ordered pairs of machines. The machines are arranged next to each other on a circle and the objective is to find a permutation of the machines such that the total weighted sum of the center-to-center distances between all pairs of machines (in clockwise direction) is minimized.\r\n\r\nThe DCFLP allows for a wide range of applications and it contains several other layout problems that have been widely investigated in literature as special cases. For example the DCFLP generalizes the Directed Circular Arrangement Problem (DCAP) by allowing the machines to have arbitrary lengths instead of having all the same lengths. The NP-hard DCAP has several nice applications in the areas of server design and ring networks and there exist interesting approximation results for DCAP.\r\n\r\nFurthermore the DCFLP is related to the NP-hard Unidirectional Cyclic Layout Problem (UCFLP). The UCFLP also considers a circular layout, but the objective is to find an assignment of machines to predetermined locations such that the total weighted sum of the center-to-center distances between all pairs of machines (in clockwise direction) is minimized. Hence compared to the DCFLP, the UCFLP considers distances of predetermined locations instead of machine lengths in the objective function.\r\n\r\nWe show that the DCFLP can be modeled as a Linear Ordering Problem and solve it using both semidefinite and integer linear programming approaches. We create a benchmark library building on well-known benchmarking instances from the facility layout literature and then we compare our exact methods on these instances in a computational study.", :title "Exact Optimization Approaches for the Directed Circular Facility Layout Problem", :keyword2 11, :authors (50992 30955 51035 50997), :session 32}, 108 {:keyword1 11, :keyword3 0, :abstract "We consider the problem of efficient recovery of air traffic from disruptions at airports.  Disruptions may be caused by bad weather, for example.  The problem is considered from a \"common good\" perspective rather than from the point of view of a particular airline.  The airport should recover back to normal operations at the shortest possible time and the least amount of inconvenience to passengers.  The available decision options are as follows: Flights may need to be (1) delayed on the ground at the departure airport (called \"ground holding\"), (2) wait in airborne holding patterns near the arrival airport, (3) cancelled, or (4) diverted to other airports.  The objective function is the sum total of delay costs and cancellation costs.\r\n\r\nWe model the problem with ground-holding and cancellations as an Integer Program.  Time is discretized into 15-minute intervals.  The problem is shown to be NP-hard.  We develop an approximation algorithm based on a primal-dual schema which guarantees an upper bound of F on the approximation ratio. (F is the maximum number of flights scheduled to arrive at any 15-minute interval, the maximum being taken over all such intervals).  We report on experimental results with actual flight arrival-departure data obtained from Sydney airport (Australia).  We found that both the heuristic as well as CPLEX computations are sensitive to how the 0-1 integer decision variables are defined.  If certain conditions are imposed on flight schedules and flight connections, and if the integer decision variables are defined in a certain manner, then desirable properties for the coefficient matrix such as Total Unimodularity can be obtained.\r\n", :title "Disruption Recovery at Airports: Integer Programming Formulations and Approximation Algorithms", :keyword2 16, :authors (50639), :session 34}, 113 {:keyword1 30, :keyword3 19, :abstract "The following location problem is considered. New 5G networks are deployed by two competitive operators, which we refer to as a leader and a follower due to their sequential entering a market. They compete to serve clients by installing and configuring base stations (BS). We assume that the leader had already made a decision and operating a 5G network. Follower arrives at the market knowing the decision of the leader and set it's own 5G network. Follower is able to set up his BS on all the available cites. It is also possible to share the cite with the leader. In latter case follower pays an additional \r\nsharing price to the leader. \r\nAfter the deployment of all base stations, clients sign a contract with the leaders or followers network. The choice of each client depends on the average service quality in the network which is in turn defined by the signal powers and the load of the base stations. The quality of a signal between the user and the base station depends on distance, thermal noise and interference. Noise in the band together with the interference between the base stations which are close to each other decreases the signal power. We assume, that the traffic demand is constant in the network that operators wish to serve. In every location there is a certain amount of demand, generated by users. This demand is statistical and can be shared by the leader and the follower or not served at all. Physical data rate, provided by the base station depends on the signal power and amount of the demand served. Users prefer the network, which provides higher average data rate. The problem is to find an optimal location of the follower base stations, providing maximal total income for the follower. We provide a mathematical model for this problem in terms of nonlinear mixed-integer programming. We suggest a fast tabu search based heuristic for this problem, exploiting probabilistic neighborhoods and intensification strategies. The numerical test results are provided.\r\n", :title "Fast tabu search for the competitive base station location problem in cellular network with sharing.", :keyword2 16, :authors (29418), :session 28}, 115 {:keyword1 43, :keyword3 26, :abstract "Charitable organizations make a lot of effort to improve the world and make it a better place to live for people in need. One of their tasks is to organize transportation for goods, which are not always offered for free, that are picked from one place and delivered to a different place, which obviously generates costs. For this optimization problem we propose a genetic algorithm that will aid such organizations in performing their tasks and lowering the accompanying cost factor.\r\n\r\nThe problem can be formulated as follows: given a set of depots (warehouses, donors, shops etc.) scattered across a country or a city, offering different amounts of the goods at varying prices, one has to find a subset of depots that should be visited, for which the total cost of the transportation (shortest path or cycle that visits all of the selected depots) and the total cost of the bought goods will be the lowest.\r\n\r\nWe propose a mathematical formulation for the problem and a genetic algorithm, for which we compare the efficiency of finding the solutions. For the computational experiments we propose different characteristics of input data to evaluate scenarios inspired by real-world situations. Finally, both solutions are compared with a strict time limit, due to the fact that it has to be embedded into an on-line tool that could be used by charitable organizations.", :title "Supply process in charitable organizations aided by genetic algorithm", :keyword2 41, :authors (31551 6621), :session 31}, 116 {:keyword1 17, :keyword3 36, :abstract "In the resource constrained shortest path problem (RCSPP) there is a directed graph along with a source node and a destination node, and each arc has a cost and a vector of weights specifying its requirements from a set of resource types with finite capacities.\r\nA minimum cost source-destination directed path is sought such that the total consumption of the arcs from each resource type does not exceed the capacity of the resource.\r\n\r\nWe investigated LP-based branch-and-bound methods to solve the RCSPP.\r\nWe generalized and extended cutting planes from the literature and provided separation procedures for them.\r\nIn addition, we gave an NP-hardness proof for the separation problem of a class of inequalities.\r\nWe developed a variable fixing method for reducing the size of the subproblems which based on analyzing the network of the subproblems corresponding to the branch-and-bound nodes.\r\nWe also developed a depth-first-search based primal heuristic procedure for obtaining a feasible solution in each branch-and-bound node.\r\n\r\nWe conducted two types of computational experiments.\r\nIn the first type of experiments we examined the components of our solution procedure using our randomly generated problem instances.\r\nThat is, first, we compared our new classes of cutting planes to their precursors, than we investigated the effectiveness of our variable fixing method and our primal heuristic.\r\nThe tests suggest that neither the new, nor the old cuts dominate one-another, and we could characterize the favorable instances for each class.\r\nMoreover, the variable fixing and primal heuristic methods are proved very effective in solving all the instances.\r\n\r\nIn the second type of experiments we compared our method to state-of-the-art approaches from the literature on widely-used problem instances.\r\nOur main finding is that most of the widely used test instances can be solved in a split of a second by applying a well-known preprocessing procedure provided that an efficient implementation is at hand, and for the rest of the instances, the computation times can be significantly reduced by applying our variable fixing and primal heuristic methods.\r\n\r\nThis work has been supported by the OTKA grant K112881.", :title "Solving resource constrained shortest path problems with LP-based methods", :keyword2 11, :authors (49869 4503), :session 32}, 117 {:keyword1 38, :keyword3 26, :abstract "We consider the newsvendor problem in a distribution-free setting when learning from experts. Assuming demand is known to varying degrees we suggest two Euclidean Distance Algorithms (EDA) that adaptively converge towards the critical fractile solution in finite-time. Experimental results show the near-optimal behavior of EDA for different types of unknown distributions.", :title "Censored Demand Newsvendor and Prediction with Expert Advice", :keyword2 41, :authors (15362 50302), :session 31}, 118 {:keyword1 20, :keyword3 0, :abstract "We study the Train Timetabling Problem (TTP) whose goal is to determine, in the planning phase, an optimal schedule for a given set of trains, while satisfying track capacity occupation constraints. \r\nIn particular, we focus on the high-speed Beijing-Shanghai line of the Chinese railways: it is a double-track line with 29 stations along which more than 300 trains run every day between 06:00 and midnight. \r\nWe are given on input a set of feasible timetables for the trains already planned along the line, and the primary goal consists of scheduling as many additional trains as possible. For each additional train, we are given its departure time, its traveling time between each pair of stations and its set of compulsory stops with the corresponding minimum stopping times. In order to schedule the additional trains, we are allowed to change their departure times and to increase their stopping times. Furthermore, we investigate the possibility of modifying the timetables of the already planned trains, even by changing their stopping patterns (i.e. we allow to add or remove some stops).\r\nA secondary objective we consider is to obtain a regular schedule, i.e. a schedule showing regularity in the train frequency at the main stations. We propose a heuristic algorithm to solve TTP with the described objectives, and test it on real-world instances of the Beijing-Shanghai line.", :title "Train Timetabling for the High Speed Beijing-Shanghai Line", :keyword2 19, :authors (50792 22920 710), :session 19}, 119 {:keyword1 17, :keyword3 0, :abstract "Extremal graph theory aims to determine bounds for graph invariants\r\nas well as the graphs that attain those bounds. For example, one can\r\nstudy the number of non-equivalent graph colorings (defined later and called NumCol) and, given a number of nodes and edges, search to minimize it.\r\n\r\nSome invariants (including NumCol) may be hard to compute for a human and it might be difficult for one to develop intuitions about how they meld with graph structure.\r\n\r\nThere is thus a need for tools to help researchers explore the\r\nintricacies of these invariants. There already are attempts to reach\r\nthat goal, e.g., Graph, GrInvIn, Graffiti, AutoGraphiX, Digenes,\r\nGraPHedron. However those tools do not meet our needs\r\nto obtain extremal graphs in an exact manner and to explore graph\r\ntransformations. Being able to quickly make queries on graph invariants\r\nis also an interesting feature to quickly lighten or kill ideas in a\r\ndiscussion, e.g., \"which graphs are local minima for some transformation\r\nwith respect to some invariant ?\" or \"on which connected graphs are two\r\ninvariants equal ?\".\r\n\r\nThose needs arise from our study of NumCol which is defined as\r\nfollows. We say that two vertex-colorings of a graph G are equivalent\r\nif they induce the same partition of the vertex set. The number of\r\nnon-equivalent proper colorings of a graph G that use exactly k\r\ncolors is defined as S(G,k) and the total number of non-equivalent\r\ncolorings of a graph G is defined as the sum of S(G,k) for k = 1 to n.\r\nAmongst all graphs with n vertices and m edges, we want to find the minimum possible value for NumCol.\r\n\r\nIn an attempt to answer that question (and others), we are currently\r\ndeveloping the Phoeg system, which can be viewed as a successor\r\nto GraPHedron. It uses a big database of graphs and works with the\r\nconvex hull of the graphs as points in the invariants space in order\r\nto exactly obtain the extremal graphs and infer optimal bounds on the\r\ninvariants. This database also allows us to make queries on those graphs\r\nas we mentioned it earlier. Phoeg goes one step further by helping in\r\nthe process of designing a proof guided by successive applications of\r\ntransformations from any graph to an extremal graph.\r\n\r\nThis talk will present the difficulties we encounter with the NumCol problem and how the preceding ideas could be used to deal with them.\r\n", :title "PHOEG Helps Obtaining Extremal Graphs ", :keyword2 0, :authors (51079 51088 48827), :session 12}, 120 {:keyword1 26, :keyword3 16, :abstract "Warehouses are very important and critical components in supply chains, even in the systems adopting 'zero stock' management philosophies. Particularly such philosophies introduce new challenges like tighter inventory control and shorter response time for warehouse systems under dynamic operating conditions of today’s competitive world. Therefore, order picking in warehouses requires more efficient policies and techniques as it is the most labor-intensive and costly activity involving almost 55 % of the total warehouse operating cost.  Inefficient policies in order picking can lead to unsatisfactory service and high operational cost for the warehouse, and consequently for the whole supply chain. It is obvious that efficient order picking process is highly related with order batching, so both of these operations need to be carefully considered and well controlled through an integrated planning approach. Unfortunately, this concept has not been sufficiently debated among the existing studies of the related literature. In this regard, the present paper addresses order batching and order picking problems simultaneously in order to improve the efficiency and response time of warehouses. Previous studies show that metaheuristic algorithms are more effective in resolving such warehousing problems because of their combinatorial natures. Due to its intrinsic features and easiness in application to combinatorial problems, Greedy Randomized Adaptive Search Procedure (GRASP) is employed as a modeling and solution approach to solve the present problem.", :title "A GRASP based Algorithm for Simultaneous Optimization of Order Batching and Picking Operations in Warehouses", :keyword2 43, :authors (48951 36036 25289 51087), :session 27}, 122 {:keyword1 43, :keyword3 0, :abstract "In the Internet Shopping Optimization Problem, a customer wants to buy a set of products, choosing them from many available suppliers, paying costs of products, but also all necessary delivery costs. New version of this problem will be introduced, where within the budget constraints, the user wants to receive a maximal number of items or maximal combined perceived value of the items. This way, an incomplete order realization is allowed. The problem resembles or even is a generalization of some other well-known optimization problems like the Multiple Knapsack Problem (MKP) or the Maximum Coverage Problem (MCP). Mathematical formulation of the problem will be presented and computational complexity will be analyzed. Algorithms solving the problem will be described and discussed.", :title "Internet Shopping Optimization Problem with budget constraints", :keyword2 41, :authors (39366 51098), :session 31}, 125 {:keyword1 18, :keyword3 43, :abstract "This work looks at so-called two-phase combinatorial packing problems - problems where there are multiple container types and multiple items, and it is required to find both the number of containers of each type (\"first phase\") and the optimal packing, i.e. the number of items to pack in each container (\"second phase\"). This can be seen as an extension of the either the knapsack problem or the bin packing problem, with multiple, variable sized containers.\r\nIn a previous short publication the \"Pseudo-Efficient Frontier Method\" was proposed for finding an exact solution in the special case where the target function is assumed to satisfy a weak unimodality requirement by the number of containers of each specific type (when the rest of the problem remains unchanged). The method utilizes this assumption to conduct a naïve search for a pseudo efficient frontier of solutions, thus significantly reducing the number of feasible solutions to be considered. An algorithm for the special two dimensional case (two container types) was presented along with proofs of correctness and complexity.\r\nIn this work we review the results in greater depth and the usefulness of the method in practical setting is considered. We amend some proofs of correctness in a manner that makes them hold for a larger set of problems. The algorithm is then applied to a real world problem of transporting a daily portfolio of goods. Goods are characterized by weight, income, and availability. The transportation is done by containers that are characterized by an allowable weight and a setup cost. We model and solve this problem using a simple Integer Programming (IP) model for the second phase. We provide a detailed running example, demonstrating the benefit of the method. We then provide results of extensive Monte Carlo simulations done to compare the method to a strict IP model which solves both phases at once. The algorithm was found to be faster in the majority of cases (between 30-50%). \r\nWe also consider the case where approximate solutions are allowed, specifically where 1% relative solution gap is allowed. While the algorithm was not designed for this, and it might be possible to build an adversary case where it reaches a \"wrong\" solution, simulation of real world cases did not find a single case where this occurs. Performance-wise the algorithm was, again, found to be faster than the strict IP model (with similar inaccuracy permission) in the majority of cases.", :title "A Study of the Practicality of the Pseudo-efficient Frontier Method for Solving Two-Phase Packing Problems", :keyword2 26, :authors (23682 2236 51121), :session 17}, 130 {:keyword1 20, :keyword3 0, :abstract "Our work considers a scheduling problem in which manufacturing companies with large energy demand are obligated to comply with total energy consumption limits in specified time intervals. Therefore, an energy-aware schedule of the operations for the machines is needed: the objective of the so called baseline schedule is to guarantee that the manufacturing company will not pay a penalty for exceeding the energy consumption limits.\r\n\r\nHowever, in reality unexpected events such as a machine breakdown or a delay caused by material unavailability may occur, which can cause a deviation of the operations' baseline start times. It is possible that in such a realised schedule some energy demanding operations will get closer to each other thus increasing the total consumed energy in some metering interval above the energy limit. Therefore, a robust baseline schedule is required; especially in production environments in which the manufacturing process is only represented by one baseline schedule that workers receive at the start of their shift. Such a robust baseline schedule guarantees that if the start times are arbitrary delayed within the given limits, then the energy consumption limits are not violated. The robustness is achieved by having a more suitable order of the operations and inserting small idle times.\r\n\r\nThe motivation for our work comes from a glass production company. We consider only scheduling on one machine in the most energy-demanding stage of the production. However, the less energy-demanding stages are not completely omitted since they arise in the problem formulation as release times and due dates. Due to timely shipment of the finished products to the customers, we are interested in minimising the sum of tardiness.\r\n\r\nTo search the solution space of the problem more efficiently, we propose a pseudo-polynomial algorithm for constructing an optimal schedule of a fixed permutation of the operations. Using the proposed algorithm, it is possible to solve the original problem by combining it with any heuristic that searches the space of distinct permutations instead of a larger space of the baseline start times. The idea of the proposed algorithm is to iteratively add operations at their earliest feasible time according to the permutation order and considering the deviations of the previously added operations.\r\n\r\n", :title "Energy-aware Robust Scheduling: Algorithm for Efficient Solution Space Search", :keyword2 27, :authors (51132 25227 15091), :session 14}, 131 {:keyword1 43, :keyword3 0, :abstract " We say that the algorithm for solving the problem is called asymptotically optimal if there are sequences of estimates of the relative error and the probability of failure, which are close to zero for unlimited growth in the size of the input data.\r\n\r\n  In this report, an overview of research topics on constructing polynomial time asymptotically optimal (exact) algorithms for several hard optimization problems presented. Relevant research results are mostly obtained in different years by the author and his younger colleagues in the laboratory \"Discrete Optimization in Operations Research\" of the Institute of Mathematics SB RAS, Novosibirsk, Russia.\r\n\r\n   Asymptotically optimal approach is applying to Travelling Salesman Problem (TSP) and some its variations: Maximum TSP on Multidimensional Euclidean Space, Euclidean Peripatetic Salesman Problem (PSP) on maximum, TSP and m-PSP on random distances bounded and unbounded from above, Degree Constrained Connected Subgraph Problem; Graph Covering Problems with given number of disjoint cycles; Random Multi-index Assignment Problems; Maximum total Weight Vector Subset Problem; Minimum Spanning Tree Problem with a bounded below diameter; Bin and Strip Packing Problem; Random p-median Problem; Random Vehicle Routing Problem with limited number of clients per rout; Project Scheduling Problem with limited deadlines and accumulative resources; Capacitated Facility Location Problem on random input distances.\r\n\r\n   Among the recently obtained results can be referred the m-Cycles Cover Problem, which consists in covering a complete undirected graph by m vertex-nonadjacent cycles with extremal total edge weight. The so-called TSP approach to the construction of an approximation algorithm for this problem with the use of a solution of the traveling salesman problem (TSP) is realized. We present modifications of the algorithm for the Euclidean Max m-Cycles Cover Problem with deterministic instances (edge weights) in a multidimensional Euclidean space and the Random Min m-Cycles Cover Problem with random instances UNI(0,1). It is shown that both algorithms have cubic time complexity and are asymptotically optimal for the given number of cycles equal to o(n).\r\n\r\n   Note also randomized approximation algorithm for the problem of finding a subset of the finite set of vectors in a Euclidean space with the maximal norm of the sum vector is presented. It is shown that with a corresponding choice of its parameters, the algorithm is polynomial and asymptotically optimal.\r\n\r\nResearch was supported by Russian Foundation for Basic Research (projects 150100976 and 160700168)\r\n \r\n", :title "On some realizations of asymptotically optimal approach  for solving several hard discrete optimization problems", :keyword2 41, :authors (10785), :session 38}, 136 {:keyword1 20, :keyword3 0, :abstract "We deal with the problem of scheduling control messages on a communication bus. In real-world applications, the communication is not fully reliable since some messages can get lost due to e.g. electromagnetic noise. One particular application domain is automotive industry. Many of modern cars use time-triggered communication protocols (e.g. FlexRay bus) where static schedule assigns a start time to each message. Lost messages can lead to failures degrading functionality and safety of the car. \r\n\r\nIn cases when message transmission is disrupted, it may be needed to send the same message once again. However, its retransmission could collide with an another message that is scheduled right after it if not enough space is reserved. Therefore, it can still lead to a dangerous failure. Static schedules that reserve an extra space for potential retransmission (e.g. by assuming the worst-case execution scenario) are often inefficient since disruptions do not occur as often. Moreover, not all of the messages are of the same criticality. For example in a car, pulling down driver’s window is not a critical task, however, stopping the car with the break pedal is.\r\n\r\nWe aim to obtain schedules that are both efficient and safe. We schedule messages according to their criticality. In cases, when a highly critical message is disrupted, we allow its prolongation due to retransmission and, as a trade-off, we may skip less critical messages. After the message is successfully transmitted, execution match-up with the original schedule. This problem leads to non-preemptive mixed-criticality match-up scheduling problem where tasks (messages) have multiple processing times based on the task criticality.\r\n\r\nWe propose an exact approach to the problem. We assume that all tasks are subject to deadlines and have one or two levels of criticality. Since some of the less critical tasks can be skipped during an online execution scenario, we aim to find a feasible schedule that maximizes the probability that a task will be executed. Moreover, in order to increase task's execution probability, we allow to schedule it multiple times. In this work, we show the complexity of the problem, describe the structure of the optimal solutions and we provide an efficient MILP model utilizing it.", :title "Maximizing Execution Probability in the Mixed-Criticality Match-up Scheduling Problem by Task Duplication", :keyword2 12, :authors (51093 15091 16865 25227), :session 26}, 137 {:keyword1 20, :keyword3 43, :abstract "In this abstract, we define a new relaxation of the Resource Constrained Project Scheduling Problem (RCPSP), based on a temporal aggregation of the resource constraints. We model it with an original Mixed Integer Linear Programming (MILP) formulation, adapt schedule generation schemes (SGS) for it, and build an iterative lower bounding scheme for the RCPSP from it.\r\n\r\nPrinciple of the relaxation\r\n\r\nThe RCPSP aims at minimizing the duration of a project, defined by a set of activities to be scheduled non-preemptively and a set of renewable resources with finite capacity, under precedence constraints (some activities cannot start before others finish) and resource constraints (for each resource, at each instant, the sum of the requirement of the ongoing activities cannot exceed the available capacity). A (uniform) subdivision of the time horizon is used to aggregate resource constraints : for each resource, in each period, the sum of the mean requirement of the ongoing activities (i.e. a fraction of the requirement proportional to the time execution of the activity in the period) cannot exceed the available capacity.\r\n\r\nOriginal MILP formulation\r\n\r\nThe relaxation is modeled by means of an original MILP formulation based on a mixed-time representation : continuous time variables permit to easily model precedence constraints, while discrete time variables are used to compute the mean requirements of activities per periods, so that aggregated recource constraints are easily modeled.\r\n\r\nAdaptation of schedule generation schemes\r\n\r\nThe serial SGS (S-SGS) and the parallel SGS (P-SGS) are standard algorithms based on priority lists (total orderings compatible with precedence relations) for the RCPSP. Their original design is preserved : either schedule one activity at a time (S-SGS) or fill successive periods (P-SGS). Their adaptation to the relaxation relies on the same subproblem : given a set of activities already scheduled, how long can an activity be executed in a period ?\r\n\r\nIterative lower bounding scheme\r\n\r\nLarge periods define MILP of reasonable size (quickly solvable) while shorter periods define more accurate relaxations but harder to solve. Starting with large periods, a pool of solutions is populated ; periods are shortened progressively, providing upper bounds (repaired solutions obtained with SGS) to the solver to speed up the solving process (warm start) while updating a global lower bound. During the last iteration, unit periods are considered ; in some cases, optimal solutions for the RCPSP are found.\r\n\r\nReferences\r\n\r\nA. Haït, C. Artigues, 2011, \"A hybrid CP/MILP method for scheduling with energy costs\", European Journal of Industrial Engineering, Vol. 5, pp. 471-489.\r\nA. Haït, G. Baydoun, 2012, \"A new event-based MILP model for the resource-constrained project scheduling problem with variable intensity activities (RCPSVP)\", Proc. IEEE International Conference on Industrial Engineering and Engineering Management, Hong Kong, 2012.", :title "A new relaxation for the Resource Constrained Project Scheduling Problem", :keyword2 12, :authors (50771 16865 36176), :session 30}, 146 {:keyword1 11, :keyword3 19, :abstract "The growing global demand for Natural Gas (NG) due to the reduction of oil resources, the regulation of NG flaring and the benefits received by reducing emissions of greenhouse gases, has enabled logistics studies for the transport of NG from platforms offshore to the treatment plants. Over the last decade, different transport technologies have been developed for monetization of remote NG reserves. Moreover, selection among these technologies depends on the distance to the consumer markets and the production rates of gas fields. Currently, NG can be transported by pipeline or as Liquefied Natural Gas (LNG). Logistics aims to optimize the supply chain and routing deliveries of products to their consumers, maximizing revenue profit and minimizing the costs involved in the transportation process. Integer Linear Programming (ILP) can be used to solve the transportation logistics problem. Taking advantage of the large NG reserves discovered in the Brazilian pre-salt and low transport capacity by the existing offshore pipeline, the aim of this study is to provide a viable solution to monetize the NG reserves in the pre-salt, ensuring flexibility to meet internal market and the possibility of export in the short-term market (spot) for periods of low demand. Through a mathematical model was obtained an optimum transport fleet configuration with the lowest distribution cost and aiming to meet the demand. This model considered two types of ships with different transmission capacity two liquefaction platforms and three plants of re-gasification with different processing capabilities. The model was tested in situations of simplified reality by a commercial solver, and the results showed that the proposed model solved the initial problem helping the end user in taking investment decisions.", :title "Logistics assessment for Liquid Natural Gas  (LNG) transportation in the Brazilian Pré-Sal.", :keyword2 26, :authors (50626 51208 1309), :session 39}, 150 {:keyword1 43, :keyword3 13, :abstract "There are plenty of areas where researchers continuously have to solve new optimization problems. These are areas such as scheduling, manufacturing, logistics and many more. In industrial applications, even a small improvement to the solution of the problem can translate into a big economic profit. For this reason, several websites have been recently implemented that are following the idea of crowdsourcing, occasionally supplemented with the cloud computing, to engage the community in solving the scientific or industrial problems. These are sites such as Kaggle, TopCoder, CrowdAnalytix or InnoCentive. However, most of these platforms limit the problems types to data mining and do not integrate the on-line judge system which can make possible to submit the solution in a form of a source code instead of results of its execution.\r\n\r\nDuring this talk, we would like to present the Optil.io platform which allows publishing optimization problems together with problem-oriented testing benchmarks and methodology used to evaluate them. Various organizations, academic or industrial, can propose the description of their problems that need to be solved by a crowdsourced community. Researchers can then solve them, submit source code of the solution to the on-line judge system that executes them in the cloud and instantly evaluates. Each participant can observe how his solution is being compared to others and improve it further. It is possible to organize programming challenges or never-ending competitions to continuously improve solutions to scientific problems. Users can submit solutions in almost any programming language. Then submitted solutions are carefully assessed taking into account resource limitations such as CPU time, virtual memory or disk space.\r\n\r\nThe approach implemented in Optil.io platform has a lot of advantages. First of all, it allows making use of a crowdsourced community of researchers who thanks to the competition can prepare much better solution than the single research team. Secondly, all algorithms are evaluated using the same instances, and it is possible to build a reliable ranking of all solutions to the particular problem. Thirdly, the contestants have access to the live, on-line ranking of all solutions. Finally, the source code of the solution is submitted to the system and can be used to compare algorithms using some new instances or to solve instances prepared by industrial partners.\r\n\r\nDuring the implementation of the Optil.io platform, we have solved several significant problems. First of all, how to ensure safe execution of the source code from an external source in the cloud. Secondly, how to define and set run-time environment resources limits (i.e. processing time and memory allocation). Finally, how to create a consistent, reliable ranking of algorithms by aggregating the results obtained on multiple benchmarks. The platform has been already tested by evaluating about 1500 algorithms.", :title "Optil.io: Solving Optimization Problems by Organizing Programming Challenges", :keyword2 41, :authors (18683 20145 50703 50702 51071), :session 33}, 154 {:keyword1 22, :keyword3 0, :abstract "Man has always been an interesting world around him. He wanted to know what constitutes its surroundings. Getting to know them gradually expanded the boundaries of horizons. It became possible to determine the qualitative and quantitative composition surrounding environment. This involved developing a number of physical, chemical and computer science analysis methods of studied systems.\r\nThe study has been focused on secondary metabolites. Commonly, to identify secondary metabolites one can use mass spectrometry. The elements observed in the mass spectra is identified by database searching algorithms. As a result the algorithm returns a list of potential chemical compounds.\r\nThe aim of this work was to develop, implement and test the combinatorial algorithm which allows, based on data from the mass spectrometer, to determine the chemical composition of the test compound. The algorithm for the given mass of the particle (mass to charge ratio of the fragmentation ion is converted to molecular weight), a particular set of elements (and their respective masses and valency) is trying to determine the molecular formula of this particle. The designed algorithm is backtracking, in which for finding all (or some) solutions to above defined problem (constraint satisfaction problem), incrementally builds candidates to the solutions, and abandons each partial candidate (\"backtracks\") as soon as it determines that found solution cannot possibly be completed to a valid solution. To reduce space solutions the algorithm uses additional restrictions related to the biological aspects of the problem - the conditions of formation of a stable molecule.\r\nThe algorithm was implemented as part of the internet application. The application allows users to load data in mass spectrometer format and interactive defining the conditions of the analysis.", :title "Algorithm of identification of components of secondary metabolites base on mass spectra", :keyword2 0, :authors (19853), :session 21}, 155 {:keyword1 23, :keyword3 0, :abstract "We generalize the notions of user equilibrium, system optimum and price of anarchy to congestion games with stochastic demands. In this generalized model, we extend the two bounding methods from Roughgarden and Tardos (2004) and Correa et al. (2008) to bound the price of anarchy. Our results show that the price of anarchy depends not only on the class of cost functions but also demand distributions and, to some extent, the network topology. The upper bounds are tight in some special cases, including the case of deterministic demands.\r\n\r\nJoint work with Chenlan Wang and Xuan Vinh Doan of University of Warwick.", :title "Price of Anarchy for Congestion Games with Stochastic Demands", :keyword2 17, :authors (2509), :session 25}, 158 {:keyword1 43, :keyword3 0, :abstract "The inverse optimization problem consists in changing parameters of the problem at minimum cost such that a prespecified solution becomes optimal. Inverse p-median problem has been investigated by Burkard,Pleschiutschnig and Zhang. They showed that the discrete inverse p-median problem with real weights can be solved in polynomial time provided p is fixed and not an input parameter. They presented a greedy-like O(n log n)-time algorithm for the inverse 1-median problem in the plane provided the distances between the points are measured in the Manhattan or maximum metric. Also,\r\nthey showed that the inverse 1-median problem on a cycle with positive\r\nvertex weights can be solved in O(n^2)-time. The inverse Fermat-Weber\r\nproblem was studied by Burkard, Galavii and Gassner. The authors derived a combinatorial approach which solves the problem in O(n log n)-time for unit cost and under the assumption that the pre-specified point that should become a 1-median does not coincide with a given point in the plane. Galavii showed that the inverse 1-median problem on a tree with positive weights can be solved in linear time and also he showed that the inverse 1-maxian problem on cycles can be solved in O(n^2)-time.\r\n Now, in this paper we investigate the inverse 1-median problem on a cycle with pos/neg weights. Let G=(V,E) be a cycle with pos/neg weights and positive edge lengths. The aim is to change the vertex weights at minimum total cost with respect to given modification bounds such that a pre-specified vertex becomes 1-median. We show that this problem can be formulated as a special case of a linear program that allows to solve the problem in O(n^2)-time.", :title "The inverse 1-median problem on a cycle with pos/neg weights", :keyword2 17, :authors (51258), :session 20}, 160 {:keyword1 17, :keyword3 0, :abstract "The `metric dimension’ dim(G) of a graph G is the minimum number of vertices such that every vertex of G is uniquely determined by its vector of distances to the chosen vertices. Metric dimension was introduced independently by Harary and Melter (1976) and by Slater (1975). Applications of metric dimension can be found in combinatorial optimization (Sebo and Tannier, 2004), sonar (Slater, 1975), robot navigation (Khuller, Raghavachari and Rosenfeld, 1996), and chemistry (Chartrand et al., 2000; Klein and Yi, 2012). It was noted that determining the metric dimension of a graph is an NP-hard problem (Garey and Johnson, 1979).  \r\n\r\nThe `zero forcing number’, Z(G), of a graph G is the minimum cardinality of a set S of black vertices (whereas vertices in V(G)-S are colored white) such that V(G) is turned black after finitely many applications of `the color-change rule’: a white vertex is converted black if it is the only white neighbor of a black vertex. The notion of a zero forcing set, as well  as the associated zero forcing number, of a simple graph was introduced and studies by the AIM group (2008) to bound the minimum rank of graphs. Independently, physicists have studied the zero forcing parameter, referring to it as the `graph infection number’, in conjunction with the control of quantum systems (Burgarth and Giovannetti, 2007; Burgarth and Maruyama, 2009; S. Severini, 2008). Zero forcing number has become a graph parameter studied for its own sake, as an interesting invariant of a graph. For example, keeping in mind applications such as disease control, the number of steps it takes for a zero forcing set to turn the entire graph black, named the `iteration index’ (Chilakamarri et al., 2012) or the `propagation time’ (Hogben et al., 2012), has been studied. Further, a probabilistic variation on the zero forcing parameter was introduced (Kang and Yi, 2013).\r\n\r\nIn this talk, we discuss the relationship between metric dimension and zero forcing number. We show that dim(T) is no greater than Z(T) for a tree T, and that dim(G) is no greater than Z(G)+1 if G is a unicyclic graph; along the way, we characterize trees T attaining dim(T)=Z(T). For a general graph G, we introduce the `cycle rank conjecture’: dim(T) is no greater than Z(G)+r(G), where r(G) is the cycle rank of G. \r\n\r\nThis talk is based on a joint work with Linda Eroh and Eunjeong Yi.\r\n\r\nReferences:\r\n\r\n[1] AIM Minimum Rank - Special Graphs Work Group (F. Barioli, W. Barrett, S. Butler, S.M. Cioaba, D. Cvetkovic, S.M. Fallat, C. Godsil, W. Haemers, L. Hogben, R. Mikkelson, S. Narayan, O. Pryporova, I. Sciriha, W. So, D. Stevanovic, H. van der Holst, K. Vander Meulen, A.W. Wehe). Zero forcing sets and the minimum rank of graphs. Linear Algebra Appl. Vol. 428 (2008) 1628-1648.\r\n\r\n[2] G. Chartrand, L. Eroh, M.A. Johnson, O.R. Oellermann, Resolvability in graphs and the metric dimension of a graph. Discrete Appl. Math. Vol. 105 (2000) 99-113.", :title "A Comparison between the Metric Dimension and Zero Forcing Number of Trees and Unicyclic Graphs", :keyword2 43, :authors (51273), :session 16}, 161 {:keyword1 43, :keyword3 16, :abstract "Since combinatorial optimization is a branch of optimization, its domain consists of solution sets having different combinations of feasible answers to a problem. Some of the most famous combinatorial optimization problems can be listed as: Finding the shortest path (Travelling Salesman Problem in more specific), finding minimum spanning tree in a graph, black box optimization, solving a maze, optimizing airline network and so on. Evolutionary computation (EC) is one of the best computing techniques for solving combinatorial optimization problems. In EC, there are some algorithms inspiring from nature to find the best solution among the possible solutions' set.  Genetic algorithm (GA) is a stochastic search technique which can be used to solve sequencing problems. Although it is being discussed for decades, GAs still finds very interesting application areas including most of the famous combinatorial optimization problems. All kinds of sequencing problems can be handled with GA. Its mechanisms (crossover, mutation and selection operators) simulate the behavior of reproduction process in nature and the result set is able to \"evolve\" to find better solutions. For this reason, they can easily be applied on problems which need to find the best solution among the solution candidates. GA is very convenient technique to observe performance with the changing parameters. For this reason, parameter tuning can be done on the same set of candidate solutions to find the best parameter combination of GA to solve the problem. When parameter tuning is applied, it has been observed that different parameter combinations can be more effective on different problems. In this study, the solution of a combinatorial optimization problem is searched by using GA. The operators used to simulate evolution mechanism play an important role on the behavior of the algorithm. The crossover rates for solving a sequencing problem with GA have been given as 0.7, 0.75, 0.8, 0.85, 0.9, 0.95 and 1.0. When the corresponding crossover rate values of the successful scenarios are examined, it is observed that the number of scenarios having crossover rates of 0.7 and 0.95 is more than the others. The same extraction can be done for the mutation rates. As mutation rates, 0.1, 0.15 and 0.2 were used. The number of successful scenarios with the mutation rate of 0.2 was more than the others. The population size interval is given as 100 – 200 (100, 120, 140, 160, 180 and 200) in the study. The system needs to test different sizes of populations because increasing the population size to a certain extent encourages the diversity of the population that the GA deals with. This means that as the population size increases, the possibility of having individuals with various values of fitness also increases. With populations of a small size, runtime and fitness values are more likely to be the best. As the population grows, finding “very reliable” solutions gets more difficult. Also ", :title "The Behavior of Evolutionary Algorithms in Combinatorial Optimization Problems", :keyword2 41, :authors (35317), :session 33}, 163 {:keyword1 41, :keyword3 17, :abstract "The minimum spanning trees problem is to find k edge-disjoint spanning trees in given undirected weighted graph. It can be solved in polynomial time [Roskind'85].\r\nIn the diameter bounded below minimum spanning trees problem there is an additional requirement: a diameter of every spanning tree must be not less than some predefined value d. \r\nThe diameter of a tree is the number of edges on the longest path between two leaves in the tree.\r\nWe will abbreviate this problem as DBBMSTs.\r\nThe DBBMSTs for k = 1 was considered [Gimadi'00].\r\nThe DBBMSTs is NP-hard since for k = 1 and d = n-1, where n is the number of vertices in the graph, it is equivalent to the Hamiltonian path problem.\r\n\r\nIn current work we consider the DBBMSTs for k = 2 on compete n-vertices undirected graphs. We propose a polynomial time algorithm to solve the problem.\r\n\r\nThe algorithm consist of two stages:\r\nStage 1: Select d+1 vertices in the graph. Build two edge-disjoint Hamiltonian chains with d edges each on these vertices.\r\nStage 2: Using the algorithm by Roskind and Tarjan [Roskind85] find two edge-disjoint spanning trees containing both chains built on the first stage.\r\n\r\nA probabilistic analysis was performed under conditions that graph edges weights are identically independent distributed random variables with uniform distribution on an interval [a_n, b_n], 0 < a_n < b_n < infty. Also it is supposed that d = d_n goes to infinity as n goes to infinity.\r\nThe sufficient conditions for asymptotic optimality of the proposed algorithm were obtained.\r\n\r\nThis research was supported by the Russian Foundation for Basic\r\nResearch (grants 15–01–00976 and 16-31-00389).", :title "On algorithm for the minimum spanning trees problem with diameter bounded below", :keyword2 43, :authors (51221 10785 51309), :session 16}, 165 {:keyword1 22, :keyword3 43, :abstract "Sequencing of genomes of living organisms, that is discovering their linear structure (sequence of nucleotides) is now a basic way of collecting biological data. Such data can be analyzed and interpret in several ways, but following the way to discover drugs one has to go into the higher level of research – prediction and modelling 3D structures of proteins and RNAs.\r\nUnfortunately, the biological approach for identification of 3D structure of particular biomolecules is not efficient, and there is a need to hire various computational methodologies to solve mentioned problem. Computationally derived 3D models still present deviations from the corresponding reference structures, thus there is a challenge to \r\nrecognize limitations of artificial 3D models in order to choose native-like models. \r\nSolving the problem, we divided 3D structure of protein or RNA into substructures, called descriptors that characterize specific local structural neighborhood observed around particular central atom, which is treated as a center of the descriptor. In principle, the descriptor is represented by a set of discontinuous fragments of a chain that are located around the atom. The important advantage of descriptors in comparison with continuous fragments of the chain is that descriptors take into consideration long range interactions that are observed in biomolecule structures. \r\nIn our approach we developed the strategy to evaluate the similarity of descriptors using structural alignment methods. Previously, the problem of structural alignment of descriptors was posed and solved by some heuristic methods but in these cases, results of the alignments when descriptor A is matched to descriptor B, and vice versa, were often different. Our approach cures that weakness and assures symmetry in the procedure. Actually, the former papers presented the problem from the biological point of view being characterized by a multicriterial assessment function, and only biologically oriented results were given.\r\nOur strategies can be applied in the process of protein model quality assessment making the process of assessment more efficient and more accurate as well as can serve to develop structural libraries of descriptors that can represent fingerprints of particular biomolecules.", :title "Efficient alignment strategies for structures of biomolecules", :keyword2 36, :authors (11807 20145 5421), :session 21}, 166 {:keyword1 12, :keyword3 26, :abstract "An important part of disaster operations management is relief efforts that take place after the disaster. Humanitarian logistics deals with  planning and implementing flow of relief goods such as food, clothing water etc. from storage to victims of the disaster. Due to big unexpected disasters during the last couple of decades, humanitarian logistics has attracted significant research attention from the field of Operations Research and specifically combinatorial optimization. Models that finds out the best possible storage locations and/or optimal distribution of the stored goods, based on the estimated demand after a disaster exists.  Unfortunately, sometimes the stochastic nature of disasters, ( either in location or intensity or both) and secondary disasters, leaves plans made beforehand hardly optimal. The relief efforts, then, have to continue based on location-inventory decisions made optimally for another problem. An important opportunity exists, if the problem of reconfiguration of mix and inventory of items can be solved optimally and quickly after the actual disaster happens. In this study, we present a new model to reconfigure the optimal mix and inventory of items while the deliveries continue, for a multi location multi commodity setting after a disaster. ", :title "Re-configuring Optimal Mix and Inventory for Multiple-items, Multiple-locations in Humanitarian Relief Distribution ", :keyword2 19, :authors (3578 51339), :session 19}, 173 {:keyword1 16, :keyword3 27, :abstract "ALBP is relevant for the allocation of the tasks, each having an operation processing time and a set of precedence relations, among workstations so that a given objective function is optimized and the precedence relations are satisfied. In classic ALBP, it is assumed that every task has a fixed operation time. However, in recent years the traditional ALBP has evolved and it is understood that the fixed operation time assumption is inconvenient for the real life manufacturing systems. Because every worker has unique characteristics such as skill, experience, ability, etc., especially in labor intensive assembly lines a task operation time differs depending on the worker who executes the task. In order to close this gap between the traditional ALBP and real life assembly line systems, a special case of ALBP which is called assembly line worker assignment and balancing problem (ALWABP) is introduced to the assembly line literature.\r\nALWABP arises when operation times of tasks vary due to the worker who executes the task, and some task-worker incompatibilities are occurred. Since task times are dependent on the worker, who operates the task, the concept of assigning tasks to workers is occurred in additional to the ALBP. In other words, ALWABP is a double assignment problem which includes assigning tasks to workers and workers to stations simultaneously. Even the traditional ALBP is NP-hard, the ALWABP is also NP-hard. Since the ALWABP is a NP-hard hot research topic, many researchers have proposed various solution techniques to solve the problem. However, none of the proposed solution strategies is proven to be optimal for every benchmark test instance, and the problem is still attractive for researchers. The aim of this paper is to introduce an efficient solution approach for the ALWABP, which tries to minimize the cycle time of the line, in order to provide satisfactory results to the literature. In this study, a rule based constructive randomized search algorithm is proposed for the problem. 39 different task priority rules and 4 worker priority rules are used to sequence tasks and select the most appropriate worker. The proposed heuristic is tested on ALWABP benchmark data. There are 320 test instances which are grouped into four families: Heskia, Roszieg, Tonge and Wee-Mag. Each one of the families contains 80 instances. Because the proposed algorithm is a heuristic method, in order to obtain accurate results we run every single instance 10 times (10 replications) for 1000 iterations. It means that we run our program for 3200 times and every run has a maximum iteration number of 1000. The results show that, the proposed heuristic approach is able to satisfactory results.", :title "A randomized constructive heuristic approach for solving assembly line worker assignment and balancing problem", :keyword2 43, :authors (20838 36036), :session 40}, 174 {:keyword1 19, :keyword3 41, :abstract "Public transport plays an essential role in reducing the traffic load, but disturbances due to congestion as well as planned or unplanned events such as maintenance work or accidents can have strong effects on travel times of public transport vehicles and its quality of service. As a result, public transport is often perceived as unreliable and therefore not always used to its full potential.\r\nJourney planning is a key process in public transport, where travelers get informed how to make the best use of a given public transport system for their individual travel needs. Nowadays, public transport providers routinely offer journey planning applications either on their websites or via mobile apps. For a given journey request, these applications usually offer one or several routes, which are linear sequences of activities or legs that form the itinerary. A common trait of the underlying journey planning algorithms is that they assume a deterministic environment. However, as changing traffic conditions can have strong effects on travel times, vehicles in public transport often deviate from their schedule.\r\nOn the other hand, there are often multiple alternative services which a passenger can choose from at a given location. Public transport providers start to take advantage of such options and offer dynamic journey planning capabilities, for example push services to alert travelers of broken connections and to deliver updated journey plans by re-planning the journey anew from the current location and based on the current traffic conditions. Despite providing some adaptability, linear journey plans are not able to capture the full amount of flexibility inherent in multi-service public transport systems, because re-planning always occurs after some deviation from the assumed original conditions has occurred.\r\nTo fully exploit the given flexibility and to pre-plan adaptive decisions accordingly, we propose to use the concept of a routing policy instead of a linear journey plan. A routing policy is a state dependent routing advice at each location. A routing advice may consist of more than one service and specifies exactly which service to take in which situation. The traveler may define an arrival time dependent utility value at the destination, representing her preferences regarding arrival time deviations and delays. The goal is to find a policy that maximizes the expected value of the utility that can be achieved by following the policy.\r\nVarious policy types can be defined (see Berczi et al., “Stochastic Route Planning in Public Transport”, Patent number US20150268052). This work deals with the arrival time dependent policies with multiple service choices for monotone non-increasing utility functions. We give NP-hardness proofs of the problems of finding optimal policies of this kind. Then, we also present a polynomial algorithms for the case when the number of services that the user may be recommended at each stop is bounded by a given number k.", :title "Arrival Time Dependent Routing Policies in Public Transport", :keyword2 14, :authors (35631 38451), :session 19}, 175 {:keyword1 22, :keyword3 41, :abstract "Subgraph isomorphism is a well-known NP-Complete problem, while its special case, the graph isomorphism problem is one of the few problems in NP neither known to be in P nor NP-Complete. Their appearance in many fields of application such as pattern analysis, computer vision questions and the analysis of chemical and biological systems has fostered the design of various algorithms for handling special graph structures.\r\n\r\nThe idea of using state space representation and checking some conditions in each state to prune the search tree has made the VF2 algorithm one of the state of the art graph matching algorithms for more than a decade. Recently, biological questions of ever increasing importance have required more efficient, specialized algorithms.\r\n\r\nThis paper presents VF2++, a new algorithm based on the original VF2, which runs significantly faster on most test cases and performs especially well on special graph classes stemming from biological questions. VF2++ handles graphs of thousands of nodes in practically near linear time including preprocessing. Not only is it an improved version of VF2, but in fact, it is by far the fastest existing algorithm regarding biological graphs.\r\n\r\nThe reason for VF2++' superiority over VF2 is twofold. Firstly, taking into account the structure and the node labeling of the graph, VF2++ determines a state order in which most of the unfruitful branches of the search space can be pruned immediately. Secondly, introducing more efficient - nevertheless still easier to compute - cutting rules reduces the chance of going astray even further.\r\n\r\nIn addition to the usual subgraph isomorphism, specialized versions for induced subgraph isomorphism and for graph isomorphism are presented. VF2++ has gained a runtime improvement of one order of magnitude respecting induced subgraph isomorphism and a better asymptotical behaviour in the case of graph isomorphism problem.\r\n\r\nAfter having provided the description of VF2++, in order to evaluate its effectiveness, an extensive comparison to the contemporary other algorithms is shown, using a wide range of inputs, including both real life biological and chemical datasets and standard randomly generated graph series.\r\n\r\nThe work was motivated and sponsored by QuantumBio Inc., and all the developed algorithms are available as the part of the open source LEMON graph and network optimization library (http://lemon.cs.elte.hu).", :title "Improved Algorithms for Matching Biological Graphs", :keyword2 36, :authors (50858 35631), :session 21}, 177 {:keyword1 20, :keyword3 43, :abstract "We present a major research and business project aimed at developing efficient and flexible software for automated airport staff scheduling. Industrial partner is Swissport International, the largest ground handling company worldwide, and pilot site is Zurich Airport in Switzerland. Swissport provides services for 230 million passengers a year, with a workforce of 61'000 personnel at 290 airports. Airport ground handling involves a broad range of tasks, including passenger and ramp services. The diversity of activities at Zurich Airport, the large number of operational duties, and the around-the-clock business hours result in hundreds of different types of shifts to be planned every month, and an employee base consisting of several thousand persons with numerous different skills. Further challenges come from a dynamic, demand-driven planning policy which does not rely on repetitive shift patterns rolled out over a long-term horizon, and from a so-called shift-bidding approach which attributes high importance to employee preferences regarding individual work plans.\r\nWe start with an introduction to the business environment of the project, and show its planning context which comprises other software tools and human planning activities. We discuss the various project requirements, challenges and goals that shaped the project, and the methods used. Employee scheduling involves a number of subproblems including demand modeling, task generation, shift design, days-off scheduling, and shift assignment. The rostering process considered here focuses on the days-off planning and shift assignment phase. The methodology used for solving the associated complex large-scale optimization problems comprises a broad range of optimization techniques including preprocessing, decomposition and relaxation, large-scale integer programming and various heuristic procedures. We provide insight into several aspects of the solution process, including the analysis and preprocessing phase which turned out to be crucial for the entire planning system. An important purpose of this phase is to deal with feasibility issues related to incorrect or inconsistent input data. In fact, experience shows that most of the operational instances submitted to the planning tool are infeasible, and detecting and patching infeasibility is difficult. The tools developed for this planning phase range from data checking and analysis modules to sophisticated mathematical models for bottleneck analysis, identification of minimal infeasible constraint systems, and rapid presolving techniques.\r\nFinally, we present computational real-world experience and discuss operational impacts of the developed planning tool. Operational deployment started at Zurich Airport and is continually being expanded to other airports. Bottom line benefits include faster and more robust planning processes, improved roster quality, better fairness, reduced planning effort, and as a result, substantial financial savings.", :title "Demand-Driven Rostering at Swissport International", :keyword2 11, :authors (24329), :session 34}, 180 {:keyword1 36, :keyword3 11, :abstract "In a recent work, a general class of linear programming (LP) problems – known as problems with column-dependent-rows (CDR-problems) has been identified and characterized. These LPs feature two sets of constraints with mutually exclusive groups of variables in addition to a set of structural linking constraints, in which variables from both groups appear together. In a typical CDR-problem,the number of linking constraints grows very quickly with the number of variables, which motivates generating both columns and their associated linking constraints simultaneously on-the-ﬂy as a general solution strategy. In this paper, we expose the decomposable\r\nstructure of CDR-problems via Benders decomposition. However, this approach brings on its own set of theoretical challenges. One group of variables is generated in the Benders master problem, while the generation of the linking constraints is relegated to the Benders subproblem\r\nalong with the second group of variables. A fallout of this separation is that only a partial description of the dual of the Benders subproblem is available over the course of the algorithm. We demonstrate how the pricing subproblem for the column generation applied to the Benders master problem does also update the dual polyhedron and the existing Benders cuts in the master problem to ensure convergence. Ultimately, a novel integration of\r\ndelayed Benders cut generation and the simultaneous generation of columns and structural constraints yields a brand-new algorithm for solving large-scale CDR-problems. We illustrate the application of the proposed method on a time-constrained routing problem. Our numerical experiments conﬁrm that the new decomposition method outperforms not only the oﬀ-the-shelf solvers but also the previous algorithm for CDR-problems.\r\n", :title "Benders Decomposition and Column-and-Row Generation for Solving Large-Scale Linear Programs with Column-Dependent-Rows", :keyword2 40, :authors (16992 406 10133), :session 17}, 181 {:keyword1 19, :keyword3 0, :abstract "The p-centre problem seeks to minimise the maximum distance or travel time whilst ensuring all the n demand points are covered by at least one of the p chosen facilities.  In this work, we revisit an early optimal algorithm proposed by Drezner (1984) to solve this problem.  This algorithm is based in the concept of maximal circles.  A circle is called maximal with respect to a specified value z, if (a) it has a radius less than z and (b) in order to cover all demand points covered by this circle and any one additional demand point a circle of at least radius z is required.  Drezner’s method looks at the centres of maximal circles to identify potential facility locations.  We have made a number of improvements to speed up Drezner’s algorithm.  We enhanced the way minimal covering circles are identified.  We record the maximal circles more efficiently so that information can be reused in subsequent iterations.  Together with other technical enhancements, these changes have made the algorithm much faster and we have also been able to solve some larger instances to optimality for the first time. ", :title "Drezner's Exact Method for the Continuous p-Centre Problem Revisited", :keyword2 36, :authors (5486 47956 3392), :session 19}, 183 {:keyword1 16, :keyword3 26, :abstract "Design of effective solution approaches to solve optimization problems is a challenging issue in the context of operations research. Researchers strive to find efficient solution methods to combinatorial optimization problems for many years. In logistics, routing problems have been widely studied, and a great number of studies in literature of combinatorial optimization are related with routing as a concept. Serving to demand points as quickly as possible with consideration of minimizing total transportation cost can be seen as main objective in most of the routing activities from the view of product/service supplier. Besides, routing problems are common problems that occur in many areas primarily logistics and manufacturing systems. One of the problems relevant to routing is the single row facility layout problem (SRFLP). SRFLP is the problem of arranging n facilities on a line so as to minimize transportation costs among the facilities. The problem is NP-hard, and this complexity motivates researchers to develop effective heuristic and metaheuristic approaches for the problem.\r\n\r\nIn this study, metaheuristics for the SRFLP are investigated. In the literature several metaheuristics such as genetic algorithm, particle swarm optimization, ant colony optimization, and tabu search algorithms are proposed to solve the problem. Combination of different solution techniques are also applied in a number of papers. In this paper, two different metaheuristics; a max-min ant system algorithm (MMAS) and a variable neighbourhood search (VNS) algorithm is hybridized and developed to solve SRFLP. This hybrid metaheuristic has the advantages of these two metaheuristics, and performance of the proposed algorithm is evaluated after the experimental study. Computational study is implemented with several test data which are commonly used by the researchers in the literature. It is also investigated that how parameter choices affect the solution quality. According to the results, this hybrid algorithm is found as competitive, and can be applied to many real life examples of the problem. \r\n\r\n", :title "Hybridization of max-min ant system and variable neighbourhood search for the single row facility layout problem", :keyword2 19, :authors (36653 5615), :session 40}, 184 {:keyword1 20, :keyword3 0, :abstract "We consider a practical scheduling problem that arises in a multiprocessor computer system where some processors may be shut down during computation to save some an amount of shared power. The system consists of m processors driven by a common power source. The processors are  modeled as a set of identical parallel machines. Moreover, we consider a set of n independent, nonpreemptive jobs which model a given set of computational tasks. Each job requires  both: a machine and an amount of power, for its processing. A processing time of a jobs is unknown a priori. Instead of this, each job is characterised by a size, determined by a number of CPU cycles necessary to complete this job. The processing rate of a job depends on an amount of power allotted to this job at a moment. This relation is expressed by an increasing, concave processing rate function.\r\nPower is treated as a renewable continuous resource available in a constant amount.  Each machine may be in one of two states, respectively: \"power on\", and \"power off\". In the \"power on\" state a machine uses a constant amount of power even if it does not process any job. A machine uses no  power in  the power off state. We assume that time of changing states between \"power off\" and \"power off\" may be neglected and brings no additional costs.\r\nWe consider a schedule length as a scheduling criterion. A sequence of jobs on each machine, power allocation to all jobs, and time intervals of \"power off\" states of each machine, have to be determined to solve the problem.\r\nWe propose a general approach to solve the problem and demonstrate some conditions of optimality for the simplest situation of two machines and jobs characterized by the same processing rate function.", :title "A power-dependent scheduling of computational jobs with ", :keyword2 0, :authors (14295), :session 14}, 186 {:keyword1 11, :keyword3 41, :abstract "Inspired by the breakthroughs of the polyhedral method for combinatorial optimization in the 1980s, generations of researchers have studied the facet structure of convex hulls to develop strong cutting planes.  We ask how much of this process can be automated: In particular, can we use algorithms to discover and prove theorems about cutting planes?  We focus on general integer and mixed integer programming, rather than combinatorial optimization, and use the framework of cut-generating functions (Conforti et al. 2013), specifically those of the classic single-row Gomory-Johnson (1972) model.  This is an attractive framework for several reasons.  (1) It is essentially dimensionless: A cut-generating function can be applied to problems of arbitrary dimension.  (2) It may be a way to the development of the mythical multi-row cuts.  (3) Work on new cuts in the single-row Gomory-Johnson model has become a routine, but error-prone task that leads to proofs of enormous complexity.  (4) Finding new cuts in the multi-row model has a daunting complexity, and few attempts at a systematic study have been made.  (5) Working on this model is timely because recently, after decades of theoretical investigations, the first computational tools became available at github.com/mkoeppe/infinite-group-relaxation-code, following Basu et al. (2014).\r\nOf course, automated theorem proving is not a new proposition. Examples best known in the optimization community are the proof of the Four Color Theorem, by Appel-Haken (1977), and of the Kepler Conjecture by Hales (2005, 2015+).  In combinatorics, number theory, and plane geometry, Zeilberger-Ekhad have pioneered automated discovery and proof of theorems.\r\nOur approach is pragmatic.  Our theorems and proofs come from a metaprogramming trick, applied to the above-mentioned software implementation; followed by practical computations with semialgebraic cell complexes.  The correctness of our proofs depends on that of the underlying implementation.  We make no claims that they can be formalized in the sense of formal proof systems.\r\nWe report on the early successes of our software.  At the time of submission of the abstract, we have computationally verified the results from the literature on the gj_forward_3_slope and drlm_backward_3_slope functions.  We have found a correction to a theorem by Chen (2011) regarding his chen_4_slope family.  (This new result should not be confused with our previous result (Koeppe-Zhou, 2015) regarding Chen's 3-slope functions.)  We have found a correction to a result by Miller et al. (2008) on the mlr_cpl3_...  functions. We have discovered several new families, kzh_3_slope_..., of extreme functions and corresponding theorems with automatic proofs.\r\nThe plan is to produce such new theorems in quantity.  We leave it to the reader to speculate about the possible computational implications of having a large, diverse, richly parameterized library of families of cut-generating functions available.", :title "Toward computer-assisted discovery and automated proofs of cutting plane theorems", :keyword2 12, :authors (11890 51548), :session 17}, 190 {:keyword1 20, :keyword3 12, :abstract "Energy aware scheduling of workflow applications in computational grids.\r\nThe infrastructure of the present-day distributed computer environments, such as grids, clouds or virtual data centres consists of many elements that are interconnected via computer networks. Links of such networks are used to connect users, computational resources, data storage equipment and large number of  devices. The growing demands for services offered by such environments generate increasing energy consumption by the entire infrastructure. Thus, one of the most  important challenges from the point of view of the owners/operators of computing and networking resources is to minimize the energy consumed by this equipment. Open standards, implementations of new resource management concepts and new technologies which became available in recent years provide new opportunities to the developers and operators of the distributed computer  environments. Now it is possible to allocate resources and schedule computational and network tasks taking into account various criteria. \r\nAccording to the literature the network contribution to the overall power consumption of ICT is from 20% to 30%. Thus, taking into consideration the energy aware criterion the network aspects cannot be neglected. Moreover, some recently published results show that in many cases the best results in minimization of energy consumption associated with the execution of a set of computational and networking tasks can be obtained by turning off devices which currently are not engaged in the  execution of any task.\r\nIn our research we try to model the problem of allocating both computational and network resources to computational and network tasks, as well as scheduling these tasks in order to minimize the total energy consumed by them. We take into account very time consuming and data intensive type of applications which are known as workflows and frequently occur in computational grids. Taking into account the viewpoint of the single owner of all resources constituting the considered distributed infrastructure we defined a set of assumptions about hardware and software aspects and propose a mixed integer programing model of the problem. This model has been used to optimally solve the small size instances of the problem using one of the available optimization software packages. A simple and fast heuristic algorithm has been developed to find semi-optimal solutions of the larger size instances. Finally, a computational experiment has  been developed and used to evaluate the efficiency of the proposed approaches.\r\n", :title "Energy aware scheduling of workflow applications in computational grids.", :keyword2 16, :authors (587), :session 14}, 192 {:keyword1 41, :keyword3 23, :abstract "In case of bin packing items of positive sizes are partitioned into subsets (called bins) of total sizes no larger than 1. The first bin packing game was defined by Bilo. In that model, the cost of a bin (i.e., 1) is shared among the items being in the bin, proportionally to their sizes. Any item can move to another item if it fits there, and the movement is advantegous for the item, as after  the movement the item will pay less for being in its (new) bin. The price of anarchy (PoA) is the asymptotic worst-case ratio between the number of bins in solutions that are Nash equilibria and the number of bins in a socially optimal solution. We define a new kind of bin packing game, which is a generalization of Bilo's version. Here an item i in bin B with size s_{i} has an incentive to move to another bin B′ (called target bin) if there is an (empty or not empty) set S of items in the target bin, so that s_{i} is (strictly) bigger than the total size of items of S, moreover after removing the items in S from the target bin (and putting them into B) item i fits into the free room in the target bin; and this change is advantageous for item i. That is, item i can enforce his will to the items in set S (in other words has a priority against them) if this change is advantageous for item i, no matter that this change is not advantageous for items in S. The PoA of Bilo's game is between 1.6413 and 1.6428. We prove that the PoA of the new bin packing game is between 1.606 and 1.6095.", :title "The bin-packing game with priorities", :keyword2 43, :authors (51460), :session 25}, 194 {:keyword1 11, :keyword3 0, :abstract "Routing a fleet of robots on a surface is a complex problem. It consists in the determination of the trajectories that robots follow to collect information. The objective is to maximize the exploration of the surface. Connectivity constraints guarantee that robots execute the mission in a collaborative manner and share information. The trajectories of robots respect autonomy constraints. Applications are found in the restock of resources to precise locations as water in emergency areas.\r\nThe problem can be modelled as follows. A set of robots visits, over a discrete time horizon, a set of points on a triangular (isometric) grid characterized by the length of the equilateral triangle edges that form it. Robots are characterized by three parameters: initial position, autonomy,  and covering radius. The latter determines the area monitored by a robot. The grid and the covering radius are such that visiting the three vertices of triangle, the whole area of the triangle is monitored. As a consequence, visiting all the vertices of the grid results in monitoring all the surface.\r\nAt each time step, robots move from the current vertex to a neighbour, i.e., that can be reached throughout an edge of the triangular grid. We suppose that each vertex is neighbour of itself. When a robot stands on a vertex, the vertex is declared visited. When two robots stand on two vertices of an edge, the robots are said to be connected, i.e., they can directly communicate.\r\nA configuration of the robots respects the connectivity constraints if and only if for each pair of robots, there exists a path that goes from the first robot to the second robot using only occupied edges. An occupied edge has a robot on each vertex.\r\nThe objective of the problem is to determine a trajectory for each robot to maximize the visited points respecting autonomy and connectivity constraints.\r\nWe propose a two-phase matheuristic. In the first phase, we determine a triangular sub-grid of the grid. The sub-grid is made of part of the vertices that form the original grid.\r\nWe suppose, we have a fictitious fleet of super-robots: their covering radius allows to monitor the surface of each triangle of the sub-grid when the three vertices are visited. The super-robots communicate standing on an occupied edge.\r\nWe set the trajectory of each super-robot moving on the sub-grid. The reduced size of the sub-grid and the fleet of super-robots allow to obtain first-level trajectories in a reasonable computation time.\r\nOnce the first-level trajectories are determined, we determine the trajectories of the robots as follows.\r\nWe assign a number of robots to each super-robot. At each time step, we determine the area of the original grid covered by the super-robot, and then the trajectories of robots assigned with the super-robot on this area. Next, We consider the next time-step and repeat the procedure. By merging the trajectories, we obtain the final trajectories of robots. Tests provide promising results.", :title "A two-phase matheuristic for the multi-robot routing problem under connectivity constraints", :keyword2 0, :authors (51294 25372 51575 51576 2247), :session 15}, 197 {:keyword1 36, :keyword3 0, :abstract "It is well known from Gallai's works in the 1950s that for a collection of intervals the minimum number of points meeting all intervals can be determined by a polynomial-time algorithm. We consider weighted and multiple-covering variants of the problem, in the discretized model of interval hypergraphs. In this setting the vertices (points) or the hyperedges (intervals) may have their weight and/or may have a requirement how many times they should be covered. The goal is to minimize the number or total weight of vertices or hyperedges in a (multiple) cover. For most of these problems we design polynomial-time algorithms, while the most general version is proved to be NP-complete (and even some of its subproblems are intractable).", :title "Weighted and multiple coverings of interval systems", :keyword2 17, :authors (51577 51596), :session 12}, 200 {:keyword1 17, :keyword3 0, :abstract "In a graph G, a set D of vertices is called k-dominating set, if each vertex not in D has at least k neighbors in D. The k-domination number is  the minimum cardinality of such a set D. This graph invariant was introduced by Fink and Jacobson in 1985. \r\n\r\nWe give an algorithm for the construction of 2-dominating sets, which also  yields upper bounds on the 2-domination number in terms of the minimum degree and the number of vertices. Our proof technique uses a  weight-assignment to the vertices where the weights are changed according to a greedy-type procedure. The optimal values of these weights and an upper bound on the 2-domination number are determined by the solution of an LP-problem. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", :title "On the 2-domination number of graphs: Upper bounds through an LP-problem", :keyword2 43, :authors (51596 51626), :session 12}, 204 {:keyword1 20, :keyword3 39, :abstract "Cyclic scheduling of Flexible Manufacturing Systems (FMS) is important if the FMS must work without human supervision. Modern manufacturing machines are often called work centers. They are able to make all necessary operations on the products. The FMS is served by a robot which loads and unloads the work centers. Work centers may work either in parallel way, i.e. one work center produces one part completely, or in a flow shop manner if each work center executes a part of the operations only. The flow shop type organization was investigated first in the literature. The cycles of the parallel method are called pure cycles by Gültekin, Aktürk and Karasan. They gave two lower bounds of the cycle time. One of them can be improved easily. The other one had a short proof without giving a deeper look into the structure of the problem. However its meaning can be understood by using a more complex mathematical formalism. It is the minimal total moving time of robot of the cell in one cycle. The same lower bound can be obtained as the optimal value of an assignment problem. This proof makes possible to analyze the structure of several optimal solution.\r\nIn the second part of the presentation the relation of the Traveling Salesman Problem (TSP) and the minimal pure cycle is discussed. The underlying mathematical problem of the pure cycle model is a TSP. In general, TSP has several exact mathematical models. The four most important types are the Dantzig-Fulkerson-Johnson, Miller-Tucker-Zemlin, n-step and flow models. Not all of them are suitable to model the pure cycle problem. The reasons of this phenomenon are explored. A new model of based on Vajda’s n-step TSP model is given.\r\nThe return time of a machine is the time difference between the loading of the machine and the arrival of the robot to the same machine for unloading the finished part. The minimal return time of a cycle is equal to the longest processing time such that the cycle time is not increased. Thus, maximization of the minimal return time is another important problem. A model of this problem is provided, as well. The model gives the maximal possible process time for a fixed cycle time.\r\n", :title "Combinatorial Analysis of the Pure Cycles of an FMS Consisting of Identical Work Centers", :keyword2 27, :authors (23034 51652 23927 51858), :session 22}, 211 {:keyword1 36, :keyword3 27, :abstract "We suggest and examine an extension of the Traveling Salesman Problem (TSP) motivated by an application in mechanical engineering. The TSP with forbidden neighborhoods (TSPN) with radius r is asking for a shortest Hamiltonian cycle of a given graph G, where vertices traversed successively have a distance larger than r.\r\nThe TSPN is motivated by an application in mechanical engineering, more precisely in laser beam melting.\r\nThis technology is used for building complex workpieces in several layers, similar to 3D printing. For each layer new material has to be heated up at several points. The question is now how to choose the order of the\r\npoints to be treated in each layer such that internal stresses are low. Furthermore, one is interested in low cycle times of the workpieces. One idea taken from the master thesis of Korda at Fraunhofer IWU was to\r\nlook for short paths between the points or more precisely between the segments in each layer that do not connect segments that are too close so that the heat quantity in each region is not too high in short periods.\r\nIn all instances of Korda the segments are rectangular which are arranged in rows and columns in a nonregular grid. We start in this work with the consideration of regular grids, i.e. adjacent vertices in the same row or column all have the same distance from each other.\r\nFirst we suggest a linear integer programming formulation of TSPN. Then we examine TSPN with r=0, r=1 and r= sqrt(2). We determine the length and structure of optimal solutions and show that these problems can be\r\nsolved in linear time.", :title "The Traveling Salesman Problem with Forbidden Neighborhoods on Grids", :keyword2 11, :authors (51662 30955 26471), :session 28}, 215 {:keyword1 12, :keyword3 0, :abstract "Optimization of production lines is an important task in industry. The classical model  of the optimization problem is the Permutation Flow Shop Problem (PFSP).\r\n Exact mixed integer linear programming (MILP) models for the PFSP can not be applied for real production systems due to the large scale of the problems. Instead, typically evolution type optimizers are applied in industry.\r\n However, better models of the physical systems can provide us with executable exact MILP models. The most important new feature at modelling is that we take into account the repetition of  jobs. Thus we arrive at the Permutation with Repetition Flow Shop Problems (R-PFSPs). In addition, modelling palettes and buffers of the production line results in the more accurate Permutation with Repetition Flow Shop with Palettes and Buffers Problem (PB-R-PFSP).\r\n    In this paper we present 3 different MILP models for PB-R-PFSPs which are the generalizations of the classical state-of-the-art exact solvers for PFSP. Furthermore, using a substitution technique a fourth model is introduced.\r\n  We demonstrate the efficiency of our approach by computational experiments on large scale problems.\r\n\r\n\r\n", :title "MILP models of the Permutation with Repetition Flow Shop with Palettes and Buffers Problem", :keyword2 20, :authors (51666 51675), :session 22}, 218 {:keyword1 41, :keyword3 11, :abstract "The Clar number of a (hydro)carbon molecule, introduced by Clar [E.~Clar, The aromatic sextet, (1972).], is the maximum number of mutually disjoint resonant hexagons in the molecule. Calculating the Clar number can be formulated as an optimization problem on 2-connected planar graphs.  Namely, it is the maximum number of mutually disjoint even faces a perfect matching can simultaneously alternate on.  It was proved by Abeledo and Atkinson [H.~G. Abeledo and G.~W. Atkinson, Unimodularity of the clar number problem, Linear algebra and its applications (2007), no.~2, 441--448] that the Clar number can be computed in polynomial time if the plane graph has even faces only.  We prove that calculating the Clar number in general 2-connected plane graphs is NP-hard.  We also prove NP-hardness of the maximum independent set problem for 2-connected plane graphs with odd faces only, which may be of independent interest. Finally, we give an FPT algorithm that determines the Clar number of a given 2-connected plane graph.  The parameter of the algorithm is the length of the shortest odd join in the planar dual graph.  For fullerenes this is not yet a polynomial algorithm, but for certain carbon nanotubes it gives an efficient algorithm.", :title "On the Clar number of benzenoid hydrocarbons", :keyword2 43, :authors (51698 51754), :session 37}, 219 {:keyword1 12, :keyword3 40, :abstract "Simulation optimization consists of optimally deciding the parameters of a discrete dynamical system (DDS) so it achieves an output with given properties. This problem is universal, since the Halting problem can be reduced to it. The DDS dynamics may be unpredictable, since they can approximate a chaotic dynamical system. They are also unlearnable, since a DDS can be encode a pseudorandom generator, making this problem arguably the most difficult I have ever seen. And yet this is the problem that most practitioners in industry ask me to solve, usually because they want to optimally set the parameters of a piece of software that cannot be \"opened\", either because the source is not available, or because it is unwieldy, or both. For a long time, my first reaction has been to throw my arms up in despair. Recently, however, I have been looking at special types of DDS, namely those having a fixed point which can be described independently of the dynamics. I will describe these as bilevel mixed-integer programs (MIP), illustrate their generality by showcasing some wildly different applications, and discuss a cutting plane algorithm for a fairly general class of bilevel MIPs which, notwithstanding its worst-case exponential behaviour, seems to work surprisingly well.\r\n", :title "Controlling fixed points", :keyword2 43, :authors (8446 22410 48546 48557), :session 4}, 224 {:keyword1 41, :keyword3 40, :abstract "We have a cycle of N nodes and there is a token on an odd number of nodes. At each step, each token independently moves to its clockwise neighbor or stays at its position with probability 1/2. If two tokens arrive to the same node, then we remove both of them. The process ends when only one token remains. The question is that for a fixed N, which is the initial configuration that maximizes the expected number of steps of the process. The Herman Protocol Conjecture says that this is the 3-token configuration with almost equal distances. We present a proof of this conjecture and different generalizations of it.", :title "A generalized solution for the Herman Protocol Conjecture", :keyword2 43, :authors (51718), :session 16}, 225 {:keyword1 17, :keyword3 0, :abstract "We propose a further development in the theory of packing arborescences. \r\nThe famous result of Edmonds (1973) on packing spanning arborescences has extensions in many directions, for example, \r\n\t- for directed hypergraphs (or shortly dypergraphs) by Frank, T. Király and Z. Király (2003), \r\n\t- for reachability arborescence packings by Katoh, Kamiyama and Takizawa (2009) and \r\n\t- for matroid-based matroid-rooted arborescence packings by Durand de Gevigney, Nguyen and Szigeti (2013). \r\n\r\nFirst we review some of these results and then we show how the existing hypergraphical results can be derived directly from their graphical counterparts. We note that the original proofs of these results were different. \r\n\t- Frank, Z. Király and T. Király proved Edmonds' disjoint branching theorem for dypergraphs by showing that a dypergraph holding the conditions of their extension can be trimmed to a digraph on the same set of nodes (by changing each dyperedge to an arc oriented towards the same head from one of the original tails) for which the conditions of Edmonds' result hold. \r\n\t- Frank and Bérczi (2008) proved the hypergraphical counterpart of the result of Katoh, Kamiyama and Takizawa by an abstract generalization of this latter result on set systems. \r\n\r\nOur method looks a bit similar to the first one however we also add some extra nodes to the graph to ensure that the conditions of the graphical results hold automatically for the digraph if they hold for the dypergraph. We also note that this method allows us to find a minimum cost solution of these problems for some cost function on the set of dyperedges.\r\n\r\nWe introduce and solve with the same method \r\n\t- the problem of matroid-based packing of matroid-rooted hyperarborescences, that is an extension of the result of Durand de Gevigney, Nguyen and Szigeti, and \r\n\t- the problem of reachability-based packing of matroid-rooted hyperarborescences, that is the hypergraphical counterpart of a recent result of Cs. Király (2016+). \r\n\r\nBy an orientation result relying on the techniques of Frank, T. Király and Z. Király, we also solve the problem of matroid-based packing of matroid-rooted mixed  hyperarborescences. As a special case, we obtain an extension for hypergraphs of a result of Katoh and Tanigawa (2013) on matroid-based packing of matroid-rooted trees.", :title "Old and new results on packing arborescences", :keyword2 43, :authors (51664 51731 51733 51732 51734), :session 37}, 228 {:keyword1 17, :keyword3 0, :abstract "A central role of min-max and feasibility theorems in combinatorial optimization is that\r\nthey serve as stopping rules for algorithms (e.g. by Kőnig’s theorem, the existence of k\r\nnodes hitting all the edges of a bipartite graph is a certificate for a given matching of k\r\nedges to be of maximum cardinality).\r\nTypically, when such a theorem is available for the cardinality-case, it can be extended\r\nto a weighted/min-cost version as well (e.g. Egerváry’s min-max theorem on max-weight\r\nmatching). Polyhedral combinatorics (in particular, lp duality, total unimodularity, total\r\ndual integrality) is the main tool in exploring such extensions.\r\nThere are, however, problems where cardinality-optimization is nicely tractable while\r\nthe min-cost version is already NP-complete (e.g. the theorem on Eswaran and Tarjan on\r\nmaking a digraph strongly connected by adding a minimum number of new arcs). In such\r\nsituations, classic polyhedral results, such as the ones on submodular flows, cannot help,\r\nand hence other general frameworks are needed.\r\nIn this talk, we overview recent developments in this area, and show that several ap-\r\nparently quite distant problems can be solved with the help of an earlier min-max result\r\non supermodular functions due to T. Jordan and the author. In particular, the following\r\nproblems and their variations will be analyzed.\r\n\r\n(A) Characterizing digraphs admitting k disjoint branchings of specified sizes.\r\n(B) Characterizing degree-sequences of simple k-connected digraphs.\r\n(C) Degree-constrained and matroidal extensions of Ryser’s max term-rank formula.\r\n(D) Extensions of Brualdi’s theorem on fully indecomposable matrices.\r\n\r\nThe new results are joint work with Kristóf Bérczi.", :title "Unweighted graph optimization", :keyword2 36, :authors (50624), :session 2}, 229 {:keyword1 20, :keyword3 0, :abstract "The jobs are to be processed on a single machine. Each job is given its \"normal\" processing time and two more parameters. An actual processing time of a job is expressed as the product of its normal processing time and a linear expression that depends on the cumulative values of one of the other parameters. The goal is to find a permutation that minimizes the makespan, i.e., the maximum completion time. This effect generalizes a cumulative effect introduced by Kuo and Yang (Information Processing Letters, 2006).\r\n\r\nWe prove that an optimal permutation can be found by sorting the jobs with respect to special priorities. If the jobs are subject to precedence constraints, then the objective function is priority generating and the problem under series-parallel precedence constraints can be solved in polynomial-time. If a single maintenance period (MP) is introduced into a schedule and the MP's duration linearly depends on its start time, the problem admits a fast fully polynomial-time approximation scheme (FPTAS). These results generalize those obtained by Gordon et al. (Journal of Scheduling, 2008) and by Kellerer et al. (Journal of Scheduling, 2013).", :title "Single Machine Scheduling under  A Generalized Cumulative Effect", :keyword2 36, :authors (22043 32753), :session 18}, 230 {:keyword1 19, :keyword3 26, :abstract "Seaborne trade constitutes nearly 80% of the world trade by volume and is linked into almost every international supply chain. In order to reduce freight rates and improve the environmental footprint of shipping, an number of logistic problems need to be solved. In particular within liner shipping, we see a number of large-scale combinatorial optimization problems involving hundreds of vessels, and millions of containers.\r\n\r\nThis talk will start by giving an introduction to a number of combinatorial optimization problems arising in the liner shipping industry, including container routing, stowage planning, bunkering planning, and disruption management. We will give a brief overview of the solution techniques applied and show how strategic, tactical and operational problems can be addressed.\r\n\r\nFinally we will go in depth with the Liner Shipping Network Design problem (LSND). The LSNDP is a core planning problem faced by carriers. Given an estimate of the demands to be transported and a set of possible ports to serve, a carrier wants to design routes for his fleet of vessels and select which demands of containers to satisfy, in order to minimize his operational costs. A route, or service, is a set of similar vessels sailing on a non-simple cyclic itinerary of ports according to a fixed, usually weekly, schedule. When the network has been determined the containers need to be routed through the network while satisfying some time constraints. Most containers are transshipped several times from one vessel to another before they reach their end destination making the design of services particularly challenging. A carrier aims for a network with high utilization, a low number of transshipments, and competitive transit times.\r\n\r\nWe will discuss how optimization methods can utilize special problem structures such as separable/independent subproblems and give examples of advanced heuristics using divide-and-conquer paradigms, decomposition and mathematical programming.  \r\n\r\nWe conclude the talk by discussing future challenges within maritime shipping and the LINERLIB set of public benchmark instances.\r\n\r\nCo-authors: Berit Dangaard Brouer, Christian Vad Karsten, Line Blander Reinhardt\r\n", :title "Large-scale optimization problems in Liner Shipping", :keyword2 36, :authors (11799), :session 3}, 232 {:keyword1 43, :keyword3 17, :abstract "We present two new proofs for the sufficient condition for having a spanning tree with prescribed lower bounds on the degrees, achieved recently by Egawa and Ozeki.\r\n\r\nThe first one is a natural proof using induction, and the second one is a simple reduction to the theorem of Lovász.  Using an old algorithm of Frank we show that the condition of the theorem can be checked in almost linear time, and moreover, in the same running time -- when the condition is satisfied -- we can also generate the spanning tree required.  This gives the first polynomial algorithm for this problem.\r\n\r\nNext we show some nice applications of this theorem, one for the simplest case of the Weak Nine Dragon Tree Conjecture, and another one for the game coloring number of planar graphs.\r\n\r\nFinally we give a shorter proof for a good characterization of having a spanning tree with prescribed degree lower bounds, for the special case when G is a cograph.  We also give the first polynomial algorithm for this problem.\r\n", :title "Spanning tree with lower bound on the degrees", :keyword2 40, :authors (51707), :session 24}, 233 {:keyword1 39, :keyword3 0, :abstract "We address the problem of minimizing the number of moves to unload a set of boxes off a gravity conveyor by a forklift. If the input data is known in advance, the problem is effciently solvable with a dynamic programming approach. However, this method is rarely applicable in practice for two reasons. First, the problem generally occurs in a real-time environment where the input data is revealed over time. Second, computing devices are in most cases not available in forklifts for decision making. Online approaches that can easily be applied by human operators are therefore sought in practice.\r\nWith this in mind, we first propose some intuitive approaches and analyze their performance through an extensive experimental study. The results show that these approaches are quite inefficient as they are on average between 14.7% and 59.3% above the optimum. A less intuitive but still simple approach is then designed that consistently produces good results with an average gap of 6.1% to the optimum.", :title "Online heuristics for unloading boxes off a gravity conveyor", :keyword2 43, :authors (9037 32557 51909 22191), :session 22}, 234 {:keyword1 16, :keyword3 20, :abstract "We present an applied study regarding an apparently new multi-objective scheduling problem derived from an electronic design problem. The problem stems from the field of so-called \"embedded vision systems\", meaning integrated systems handling visual data such as still images and video feeds. Visual treatments are usually applied in ad-hoc hardware because it is the only way to reach the desired performance for the system. But designing such a system presents a challenge: since images are big, they have to be stored in a big memory, and big memories have high latency. This latency is usually unacceptable, and something has to be done to improve the temporal behavior of the circuit. For treatments with linear patterns of access to the image, usual caches as used for regular CPUs solve the problem. For non-linear access patterns, one solution has been proposed by Mancini and Rousseau (Proc. DATE, 2012) in the form of a software tool (MMOpt) that creates an ad-hoc memory hierarchy for such a treatment. It creates a circuit called a Tile Processing Unit (TPU) that contains the circuit for the treatment, plus all that is necessary to fetch the pixels from the image in time to process them.\r\n\r\nThis software divides the input and output images into tiles, computes the requirement relation between output and input tiles, and then designs a fixed scheme for prefetching the tiles into the buffers of the TPU, so that when the computation of an output tile begins, all the needed input tiles are present in the buffers. It then outputs the TPU, that contains the schedules encoded into the circuit, and the parts that orchestrate those schedules.\r\n\r\nWe formalized this electronic problem as a 3-objective scheduling problem, with two objectives being parameters of the schedules themselves---the number of prefetches, and the total completion time---and one parameter being the number of buffers of the TPU. They correspond to the energy consumption, respectively performance, and size/cost of the circuit.\r\n\r\nWe identified two mono-objective variants of this problem as being equivalent to the Tool Switching Problem and the Tooling Problem arising in the field of flexible manufacturing. We solve at optimality two of the three mono-objective subproblems, and give a lower bound for the third. We propose an algorithm for the case where one of the objectives is fixed as input, compare it to the algorithms proposed by Mancini and Rousseau, and validate its quality as a solution for the 3-objective problem. For a given number of buffers, our algorithm's schedules have the optimal number of prefetches, and the total completion time is at most twice the lower bound. We also show numerical evidence that this lower bound is good through the solutions of another heuristic that are at most 15% away from this bound.\r\n", :title "Multi-objective optimization for the scheduling of embedded vision accelerators", :keyword2 21, :authors (19096 47019 51991), :session 26}, 235 {:keyword1 43, :keyword3 0, :abstract "The problem is part of a complex software solution for truck vehicle assignment and itinerary construction for one of the largest road transport companies in the EU. Our software optimizes the matching of tasks and trucks, the routes and the scheduling of the drivers and corridoring (decide if the plan is still tenable and is presumably optimal from the locations and state related data) in real time. The company started to apply and test our product in the beginning of 2015. The system still evolves and new logics and features are continuously implemented. Lastly we started to improve the results by extending the model with allowing the trucks to swap their trailers. The rules for the driver’s rests in the corresponding laws (Regulation (EC) No. 561/2006 and country dependent laws) and the time windows of the target places gives sense for that type of generalization.\r\nOn the other hand the corridoring can notice the set of tours that cannot be completed. In fact, roughly the third of the tours have to swap their trailers during a transportation. Until now the swaps were planned by the operators manually.\r\nThe referenced problem cannot be solved within a reasonable timeframe due to the complexity of the underlying mathematical model being NP-complete. To make the model solvable our first restrictions are the followings. Suppose that each cargo changes driver at most once. The swaps are only possible in registered parking places.\r\nOur first approach was to formulate an integer linear programing (ILP) model and try to find a quasi-optimal solution by relaxations. Without swapping we can formalize it as an assignment problem, and hence the matrix is totally unimodular (TU), the ILP solution and the LP solution are the same. The matrix in the extended model has about 10^7 times more entries. For example, if we use the Jonker-Volgenant algorithm then the running time will be multiplied by at least 8*10^21 (since it is Theta(n^3)). To reduce the running time, we make a new restriction that we do not want to calculate the values of the swaps by pairs of trucks but divide the tours to two parts and calculate the values of half-tours truck by truck. This way the matrix will be just 10^5 times bigger. In fact, the real problem is that in these cases the matrix will be no longer TU. That way after we solve the enormous LP we have to apply some heuristics such as Tabu-Search algorithm or Branch and Cut algorithm. Unfortunately, these solutions are still too slow for being applied in real life.\r\nAfter analysing these results, we decided to apply heuristics before the solution to decide which trucks need to get some help. That way the size of the problem is reduced, only a little percentage of the trucks are signed to need a swapping. Here we get a much smaller assignment problem. We give a solution for the signing and also for evaluating all the pairs of trucks to a swap.\r\nAs a consequence of the project a large cost saving is anticipated by the company.", :title "Route planning of trucks with trailer swapping", :keyword2 39, :authors (51930 52010 52011), :session 15}, 237 {:keyword1 23, :keyword3 11, :abstract "The Dedekind number M(n) counts the number of monotonic Boolean functions of n variables.  The Dedekind numbers are a rapidly growing sequence of integers named after Richard Dedekind, who defined them in 1897. Dedekind's problem of computing the values of M(n) remains difficult: no closed-form expression for M(n) is known, and exact values of M(n) have been found only for n lower than 9. When monotonic Boolean functions of n variables are taken up to isomorphism the (smaller) number m(n) remains still difficult to get and again no closed-form expression for m(n) is known. Important subclasses of monotonic Boolean functions of n variables are: threshold monotonic functions and more generally, regular monotonic functions. We will concentrate our attention in these subclasses up to isomorphism; for them the exact values, t(n) and r(n) respectively, have been found only for n lower than 10. \r\n\r\nIn the present work we specialize and generalize. We specialize to enumerate the numbers t(n) and r(n) when several components in the Boolean function are equivalent, i.e., they play an identical role in the function and therefore they are grouped in some few equivalence classes. We shall see that Fibonacci sequences and other exponential sequences commonly appear for two, three or four equivalence classes. We generalize to propose some extensions of the Dedekind’s problem to generalizations of Boolean functions and its associated subclasses.  For some small values of n and some few equivalence classes of components we will provide, by means of some combinatorial techniques, some new results. \r\n", :title "Some contributions and variants on the Dedekind’s problem", :keyword2 41, :authors (11762), :session 13}, 238 {:keyword1 29, :keyword3 0, :abstract "The hydrothermal dispatch optimization is a dynamic and stochastic problem. Its aim is to find the generation of hydroelectric and thermoelectric power source that suit the demand and minimize expected costs. The stochasticity can be represented by inflows tree, and the problem can be solved by the Stochastic Dual Dynamic Programming. Even though this technique allows a long-term solution, the computational effort could increase exponentially with the tree deep, and the uncertainty about solution optimality still remains. In this context, this article proposes the replacement of inflow tree for lattice in order to decrease the computational effort. Also, Conditional Value at Risk is applied to reduce the risk of not supply the demand. These proposals will be tested using the Lingo software based on data from Tocantins basin. Comparing the results from both approaches (using inflow tree and using lattice), it is possible to see that they match,  so the substitution of tree for lattice is viable,  and the expected cost increases when the CVaR is applied. ", :title "HYDROTHERMAL DISPATCH OPTIMIZATION ON TOCANTINS BASIN: APPLICATION OF BINOMIAL LATTICE AND CVaR", :keyword2 32, :authors (51208 1309 50626), :session 39}, 245 {:keyword1 43, :keyword3 0, :abstract "Allowing access to anonymised datasets for research has become an increasingly important business venture in recent years, and in some countries is legally mandated. It has led to breakthroughs in medical, financial and social fields. However, it is surprisingly difficult to successfully anonymise data so as to make identification of individuals and disclosure of sensitive individual information impossible, or at least improbable. For example,  in early 2000, querying anonymous US census data on birth date, zip code and gender has been shown to potentially uniquely identify around 70% of the population and was used to find the medical history of a prominent politician. \r\n\r\nIn this paper we give an outline of the primary types of attacks and the anonymisation techniques used to counter this, including k-anonymity and differential privacy. We then focus on one particular technique, the so-called k-compromise technique, where no statistics based on less than (k+1) individuals is allowed to be disclosed. We consider this problem  in the case of  one dimensional statistical databases, and we maximise the number of queries that can be asked of the database while ensuring that no statistics based on k or less individuals  can be disclosed  even values of k > 2. This problem was previously solved for odd values of k and for k = 2.\r\n\r\nThe statistical databases considered in this paper are equivalent to OLAP (Online-Analytic Processing) cubes, which have been used extensively for business intelligence. A one-dimensional OLAP cube can be seen as an ordered set of confidential values. Each query can be seen as an interval in such an ordered set. We decompose the ‘safe’ set of queries, i.e., the set that does not lead to a disclosure of statistics based on k or less records (known as a database compromise) into the threads containing consecutive queries (intervals). We then design a set of inequalities to model the constraints for the allocation of queries to threads so as to avoid database compromise, and we use quadratic programming to find an optimal solution. \r\n\r\nFinally, we implement k-compromise and we show that it favourable compares empirically to k-anonymity and differential privacy in terms of the cardinality of the safe set of queries.\r\n", :title "Maximising the Usability of a k-Compromise Free One-Dimensional OLAP cubes", :keyword2 0, :authors (52000 52002), :session 35}, 246 {:keyword1 11, :keyword3 0, :abstract "We consider the metric polytope MET(n) [4]. It is defined by the triangle inequalities that are the simplest facets of the cut polytope CUT(n). The integral vertices of metric polytope are the incidence vectors of the cuts of the complete graph Kn. Therefore, MET(n) is a LP relaxation of the cut polytope CUT(n). The metric polytope is tightly wrapped around the cut polytope, since all vertices, edges, 2-faces, and a great majority of the d-faces of the cut polytope are the faces of the metric polytope. Besides, max-cut problem on graphs not contractible to K5 is reduced to linear programming over MET(n) [1].\r\nIf we consider only the triangle inequalities, containing the index n, we obtain the rooted semimetric polytope RMET(n). It is known that all fractional faces (faces with only fractional vertices) of the RMET(n) are cut off by the triangle inequalities of the metric polytope. Using this fact, it is possible to construct a polynomial-time algorithm for integer recognition over rooted semimetric polytope [2]. The problem of integer recognition is to determine whenever the maximum of a linear objective function over polytope is achieved at an integral vertex. At the same time, integer recognition over the metric polytope is NP-complete. \r\nWe examine the possibility of cutting off fractional vertices and faces of the metric polytope by some cut polytope facets. It should be noted that the conjectured complete description of CUT(n) facets and MET(n) vertices are known only for n not greater than 9 [3,4]. However, in [5] there are described some special classes of MET(n) graphic vertices that are induced by metric on graph. In particular, fractional vertices with linearly growing denominators. \r\nWe establish that all fractional vertices of MET(n) for n up to 9 and most graphic vertices are cut off by pure hypermetric inequalities (the special class of cut polytope facets that includes the triangle inequalities). However, there exist both fractional vertices and faces of MET(n) that satisfy the pure hypermetric constrains. Thus, the pure hypermetric inequalities are not enough to solve integer recognition over the metric polytope.\r\nThe research was partially supported by the Russian Foundation for Basic Research, Project 14-01-00333, and the President of Russian Federation Grant MK-5400.2015.1.\r\n1.\tF. Barahona. On cuts and matchings in planar graphs. Math. Programming. 60 (1993), 53-68.\r\n2.\tV.A. Bondarenko, B.V. Uryvaev. On one problem of integer optimization. Automat. Rem. Contr. 68 (2007), 948-953.\r\n3.\tA. Deza, G. Indik. A counterexample to the dominating set conjecture. Optim. Lett. 1 (2007), 163-169.\r\n4.\tM.M. Deza, M. Laurent. Geometry of cuts and metrics (Algorithms and Combinatorics), Springer, 1997.\r\n5.\tM. Laurent. Graphic vertices of the metric polytope, Discrete Math. 151 (1996), 131-153. ", :title "On fractional vertices of the metric polytope", :keyword2 43, :authors (47171), :session 17}, 248 {:keyword1 40, :keyword3 17, :abstract "An optimum problem typically employs an optimality test to certify if\r\na given feasible solution is optimal. A naive nonetheless useful way\r\nis to establish upper and lower bounds for the value of the objective\r\nfunction. Note though that there can be several different ways to\r\nestablish such bounds. Careful algorithm design needs to consider\r\nthese possibilities.\r\n\r\nThe gap between the upper and lower bounds is the so-called optimality\r\nor duality gap. Vanishing duality gap indicates optimality. In case of\r\nan inconclusive optimality test one divides the problem into smaller\r\nsub-problems. We are interested in parallel clique search algorithms\r\nand consequently we are looking for principles to divide a clique\r\nsearch instance into a large number of smaller instances.\r\n\r\nThere are sub-structures that obstruct optimality tests. These\r\nobstructing or disturbing structures, as we named them, prohibit\r\nfarther narrowing of the optimality gap. These disturbing structures\r\nfocus our attention to certain sub-problems. In the usual algorithms\r\nthe problem divided into two subproblems. The first is the sub-problem\r\nconstructed by the sub-structure, while the second is the original\r\nproblem where we delete this sub-structure. Removing disturbing\r\nstructures eventually will allow us to narrow the optimality gap. From\r\nthe view of the actual clique search algorithms that use a\r\nBranch-and-Bound algorithm these disturbing structures will serve as\r\na branching rule.\r\n\r\nThese disturbing structures provide a unified framework to classify\r\nand design clique search algorithms based on different optimality\r\ntests. As it turns out many known branching methods fall into one of\r\nthese categories. New methods are discovered as a result of this\r\nsystematization and aid us in tactical choice for sub-problems. We\r\nwill show these in our talk.\r\n", :title "Decomposing clique search problems into smaller instances", :keyword2 43, :authors (52005 52130), :session 37}, 250 {:keyword1 41, :keyword3 0, :abstract "Heapable sequences were introduced by Byers et al. (ANALCO 2011) as a relaxed variant of the concept of increasing sequence of integers. \r\n\r\nSubsequently heapable sequences were investigated by the authors (Combinatorial Pattern Matching 2015). We developed an algorithm for the  partitioning of a sequence into a minimal number of heapable subsequences, and proposed a conjecture concerning the scaling behavior of this parameter in the case of a random permutation. A constant strikingly appearing in this conjecture is the golden ratio. \r\n\r\nIn this talk we will highlight several rigorous and computational results supporting this conjecture. New (unpublished) results on variants of heapability and connections with related topics, such as multiset extensions of Young tableaux will be presented too.  ", :title "Heapability of integer sequences: algorithmic and computational results. ", :keyword2 0, :authors (52008 52016), :session 38}, 251 {:keyword1 43, :keyword3 36, :abstract "The aim of this work is to establish a relation ship between star forest  polytope and the edge dominating set.  In precedent work   with V. H. Nguen et al., we  provide  a tight  relation  between edge dominating set polytope and star forest polytope  on  cycle graph.  In this paper we generalize this work to a  cactus graphs. \r\nBy the way a compact extended formulation for the edge dominating set polytope was given in such class of graphs. ", :title "On the edge dominating set polytope", :keyword2 11, :authors (15460), :session 38}, 256 {:keyword1 43, :keyword3 36, :abstract "We consider the traditional non-adaptive combinatorial search problem which can be defined as follows. Given a set S of n elements containing d faulty items, we wish to identify all the defectives by conducting tests of the following kind. Any subset of S can be tested, an answer to the test is defined like so: it is negative, if the subset contains no faulty items and positive if at least one defective is present. All tests are launched simultaneously, without any input about the outcome of the others. The goal is to establish tests that can unambiguously identify all d faulty items such that the number of tests is minimal.\r\n\r\nOne can examine the matrix representation of the problem. Let M be a t times n binary matrix, where the rows correspond to the tests and the columns to the items. An element of the matrix indexed (i,j) is equal to 1 if the ith test contains the jth item, and 0 otherwise. A sufficient condition for the identifiability of all d faulty items is that the union or Boolean sum of any up to d columns does not contain any other column. Such matrices are called d-disjunct matrices, and they constitute the basis for non-adaptive combinatorial search algorithms and binary d-superimposed codes. \r\n\r\nWe present an algorithm that can generate significantly fewer tests, or equivalently, a d-disjunct matrix with significantly fewer rows than any design before for real world input sizes. The proposed construction is based on an existential theorem by Yeh on the sufficient number of matrix rows to identify d faulty items [1]. He utilizes the Lovasz local lemma in his construction and gives a way to generate random columns, then calculates the probability that the union of any d columns contains another one. The proposed method is based on his theorem: one can calculate a sufficient number of rows t, such that a t times n d-disjunct matrix exists. Moreover, using the Moser-Tardos algorithm, also known as the Algorithmic Lovasz Local Lemma, we get an actual construction for such a matrix. \r\n\r\nFinally, we demonstrate the outstanding practical values of the construction. Exhaustive numerical evaluation shows that the proposed method guarantees significantly smaller-sized d-disjunct matrices than any construction before. To the best of our knowledge up until recently the best non-adaptive combinatorial search technique designing d-disjunct matrices was due to Eppstein et al. [2], using a Chinese Remainder Theorem based sieve method. \r\n\r\n[1] Yeh, H. G. (2002). d-Disjunct matrices: bounds and Lovász Local Lemma. Discrete Mathematics, 253(1), 97-107.\r\n\r\n[2] Eppstein, D., Goodrich, M. T., and Hirschberg, D. S. (2007). Improved combinatorial group testing algorithms for real-world problem sizes. SIAM Journal on Computing, 36(5), 1360-1375.", :title "Non-adaptive Combinatorial Search Construction for d Defective Items", :keyword2 41, :authors (51635 52023), :session 20}, 258 {:keyword1 26, :keyword3 20, :abstract "\r\nReverse logistics and closed-loop supply chains have gained attention in recent years as a means to maximize business value by recycling end-of-life products. Reverse logistics is particularly relevant in equipment-intensive industries where large quantities of parts are required. This paper addresses tactical distribution planning in closed-loop supply chains and builds on a case study related to field service operations in the telecommunications domain. Given a multi-echelon supply network and a demand forecast for spare parts, the general problem consists in generating a plan of transfer and repair operations that satisfies supply chain constraints, complies with inventory management policies and has minimal cost. We focus on a basic class of tactical distribution planning problems (TDPP) whose cost function is a linear combination of storage, transport, backorder and repair costs and where backordering preempts any transfer decision on every site. We have shown that TDPP is NP-hard and that both Mixed Integer Programming and Metaheuristics methods deliver good-quality plans and scale reasonably well.\r\n\r\nTactical plans are typically produced on a periodic basis (e.g., one plan every week) and planned transfers and repairs get implemented until the next plan is generated. In this setting and in the absence of any uncertainty on problem data, combinatorial optimization methods are relevant planning methods. In many cases, however, forecasts are inaccurate and the challenge is to produce robust and consistent plans over successive time periods. A common strategy relies on the use of safety stocks to meet unexpected demands which incurs inventory costs. Another strategy consists in increasing planning frequency. The frequency has to be precisely determined as it impacts both the robustness and the quality of a plan. Intuitively, these objectives are conflicting. For example, high frequencies provide more flexibility to face uncertainties but also increase  the risks to generate successive plans that significantly differ from one to another which is contrary to the idea of tactical planning. We present an empirical study of the impact of the frequency parameter against forecasts of varying accuracy. The goal is to determine in which case a proactive method should be used and with which planning frequency. We analyse accurate and non accurate forecasts for different parameters such as volume, density and space-time accuracy of forecasts. Results provide insights as to when and how a proactive method is better than a reactive method depending on the demand forecast. We also deduce how to generate a good forecast in order to use a proactive supply chain management method.\r\n", :title "Strategies for handling uncertainty in tactical distribution planning - an empirical study. ", :keyword2 43, :authors (49578 52026 52027 35483 52028 4436), :session 39}, 260 {:keyword1 17, :keyword3 0, :abstract "Given an undirected graph G, a matching M is called uniquely restricted (Golumbic et al, 2001) if there is no other matching of the same size on the vertices spanned by M. It is easy to see that a matching is uniquely restricted iff it does not support an even alternating cycle. The motivation of studying such matchings comes from matrix theory (Herschkowitz and Schneider, 1993), but the concept can be applied in scheduling problems in which pairs need to be constructed with respect to compatibility relation such that „flexibility” is also considered as a feasibility criterium. Determining a maximum uniquely restricted matching is NP-hard (Golumbic et al, 2001), but several other algorithmic problems have been inspired by this concept. The topic of our presentation was posed by Levit and Mandrescu in 2003: is it decidable in polynomial time if all maximum matchings are uniquely restricted?\r\n\r\nThe above question was implicitely answered by the authors in (Bartha and Krész, 2006) and, as an indipendent finding, Penso et al also gave a polynomial algorithm in 2015.  In the present study we consider  the same problem for vertex-weighted graphs and maximum-weight matchings. As shown by (Spencer and Mayr, 1984), we can assume without loss of generality that all weights are non-negative. We then introduce the binary relaxation of a vertex-weighted graph G by replacing all positive weights in G with 1. It is easy to see that every maximum-weight matching M of G is in fact one of its binary relaxation, and M is perfect in G (i.e. covers all vertices having a positive weight) if and only if it is perfect in the binary relaxation in the same sense.\r\n\r\nIn our analysis we use the generalization of the well-known Gallai-Edmonds decomposition of graphs for 0-1-vertex-weighted graphs, which was introduced by Bartha and Gombas in 1991. According to this generalization, the 0-weight vertices are all located in the C part of the decomposition, but otherwise the A and D parts are exactly the same as in the standard Gallai-Edmonds decomposition. Our problem of finding an even alternating cycle with respect to at least one maximum-weight matching in the original graph G then reduces to three separate subproblems.\r\n1: Find an even alternating cycle in the C part of the binary relaxation of G w.r.t. a perfect matching; \r\n2: Find such a cycle in a component of the D part w.r.t. a suitable near-perfect matching; and\r\n3: See if there is such a cycle in the bipartite graph running between the A and D parts w.r.t. a matching M that is maximum in the original graph G. As it turns out, all three subproblems can be solved by a polynomial-time algorithm. Moreover, if an even alternating cycle exists in G w.r.t. some maximum-weight matching, then this matching is actually constructed during the algorithm.\r\n", :title "Uniquely restricted maximum matchings in vertex-weighted graphs", :keyword2 41, :authors (20930 52029), :session 12}, 261 {:keyword1 19, :keyword3 21, :abstract "This paper is aimed to study different insular vehicle routing problems, in which a set of islands have to be served using barges for maritime freight transportation. The study is motivated by a real problem arisen in the south of Chile, in which a household waste collection system for a set of small rural islands is required urgently.\r\n\r\nDifferent particular problems are analyzed depending on the number of periods (single/multi period), the types and number of objective functions to be optimized, and other specific features and assumptions that must be addressed. Three objective functions are considered: maritime transportation costs, ground transportation costs inside islands, and environmental impacts generated at docks or collection sites at the islands. \r\n\r\nIn terms of model formulations, different alternatives are proposed and discussed, including binary and integer flow based formulations, Miller-Tucker-Zemlin sub tour elimination constraints, and other related modeling techniques. In particular, different formulations to model the ground transportation cost within islands are proposed and analyzed.\r\n\r\nFinally, different solution approaches are proposed and discussed, including Lagrangian Relaxation, Benders Decomposition, Branch and Cuts, among others. Numerical results based on real instances are presented and discussed, denoting the complex nature of the problem, the reasonable behavior and solution quality obtained by applying proposed models along with some of the implemented solution approaches.\r\n", :title "Insular Vehicle Routing Problems: Modeling and Solution Approaches", :keyword2 12, :authors (28949 46356 38450 52044 28952), :session 15}, 262 {:keyword1 43, :keyword3 42, :abstract "In the paper we focus on the problem of traffic matrix estimation in huge IP networks which is widely studied over last 20 years. The problem is to estimate the traffic demands between any (origin – destination) pair of nodes in the network being given information on the link loads.  A new insight into the problem is related to using network-monitoring tools (DPI, deep package inspection) measure all demands use a particular link.  Still, using deep package inspection significantly decrease traffic rate thus only a small number of network links can be measured. The goal of our research is to point out the links to be measured been given the constraint on the number of links to be measured. \r\nMathematically, the problem of traffic matrix estimation can be viewed as a problem to find a certain solution of undetermined system of linear equations Ax = b with binary matrix A stands to network topology, vector b consists of the link loads and vector x encodes traffic between any (origin - destination) pair of nodes. Using deep package inspection provides us with exact knowledge of some demands, thus to obtain the unique solution of the original system one needs to find a minimal hitting set for set of all paths over the network. Note, that due to highly loaded backbone edges exists in a typical Internet network one can not consider the problem as low-frequency system admits an efficient approximation by using linear programming relaxation. On the other hand deep package inspection in a backbone node crucially affects on the network performance thus one can measure only a few of them. \r\nIn the paper we focus on the hitting set problem for networks with two types of nodes: small number of higher frequency backbone edges and huge number of low frequency local edges. We provide linear and semi-definite programming relaxations for it, analyse approximation guarantees and the gap between them as well. Finally, we provide a version of Arora-Hazan-Kale multiplicative weights update algorithm to efficiently solve the semi-definite relaxation of the traffic matrix estimation problem and provide empirical support for our contribution.\r\nThe research is supported by the Russian Science Foundation, grant no. 14-50-00150.", :title "Efficient Traffic Measurement for Huge-Scale Internet Networks via Convex Optimization", :keyword2 17, :authors (36477 47786), :session 28}, 264 {:keyword1 43, :keyword3 27, :abstract "Eating local has been on the wish list of an increasing number of consumers. More and more initiatives are connecting local producers to their clients. As a result, one out of five French farmers currently sells part of his production through a short food supply chain. Furthermore, urban and suburban farms are increasingly popular in large cities, such as the LUFA farms in Quebec or the Gally farm around Paris. However, if many farmers are eager to live and work closer to cities, yet they need guidance to help them to design their farm and reach breakeven point, whether it be on plot sizes, resources they need or types of products they should grow to meet local demand. We propose in this work to help producers to optimize the strategic design of their urban farming system.\r\n\r\nWe has established a mixed integer linear programming (MILP) model to handle fresh fruit and vegetable production in an urban farm. We aim at maximizing the annual farm result while answering a fixed daily demand. Data are daily demands, available labor resources and sets of management practices including expected yields, dates and resources consumption. Variables are the area to grow using a specific set of management practices, each plot cultivation starting date, the workers to hire and each worker profile starting date.\r\nThe optimization problem we studied is a multiple-choice multidimensional knapsack problem (Akbar et al. 2006, Chen & Hao 2014). Objects – the sets of management practices – have to be selected into a three-dimensional knapsack, namely demand, labor resource and total farm area.\r\nThe knapsack problem is combined with a lot-sizing problem to take into account fresh product perishability (Ahumada & Villalobos 2009, Costa et al. 2011). We allow the crops to be harvested some days after the ideal harvest time, modeling both a standing storage on the plot and a cold-room storage, associated to loss functions. The selling price is lowered according to storage time and we force the unsold products left on the plots (losses) to be harvested before a deadline, to limit the spread of diseases. \r\nWe will present the MILP model along with the theoretical complexity of the problem, with and without the lot-sizing components. Preliminary results on real case instances will be shown and prospects drawn to add possibilities to have multi annual planning and pedagogical activities.\r\n\r\nAhumada, O., & Villalobos, J. R. (2009). A tactical model for planning the production and distribution of fresh produce. Annals of Operations Research, 190(1), 339–358. \r\nChen, Y., & Hao, J. K. (2014). A “reduce and solve” approach for the multiple-choice multidimensional knapsack problem. European Journal of Operational Research, 239(2), 313-322.\r\nCosta, A. M., dos Santos, L. M. R., Alem, D. J., & Santos, R. H. S. (2011). Sustainable vegetable crop supply problem with perishable stocks. Annals of Operations Research, 219, 265–283. ", :title "Optimizing the urban farming system design problem", :keyword2 12, :authors (11482 52040 31689 52041 52041), :session 31}, 266 {:keyword1 12, :keyword3 0, :abstract "Solving convex nonlinear mixed-integer optimization is still a challenge\r\nin the wide field of real world applications of mathematical models such\r\nas production or traffic models . Since handling the relaxed subproblems\r\nin the branch and cut method is very costly, we want to introduce a dual\r\nbound for subproblems to improve the decision strategy of the branch and\r\ncut method. This leads to a more direct way through the branching tree\r\nand therefore less relaxed problems have to be calculated.\r\nAt this juncture the new decision strategy for quadratic constraint\r\nmixed-integer quadratic problems yields to an improvement in the number\r\nof actual calculated relaxed problems compared to CPLEX as a benchmark,\r\ndeveloped by IBM.\r\nOne idea is to apply this new strategy to a traffic \r\nflow and on a production\r\nmodel. Both models are based on a hyperbolic conservation law and\r\nare fitted with coupling conditions to realize them on a network structure.\r\nFor the traffic \r\nflow model we consider a quadratic fundamental diagram,\r\nwhereas for the production \r\nflow we use a monotone increasing bounded\r\nflow function and an ordinary differential equation for the capacity restriction.", :title "A dual bounded Branch and Bound Algorithm for quadratic mixed integer Problems", :keyword2 19, :authors (50336 29675 20793), :session 29}, 267 {:keyword1 22, :keyword3 0, :abstract "The research in and around combinatorial optimization can be roughly described by two foci: the research in basic, theoretical knowledge; and the application of the combinatorial optimization methods in a real life applications. In this contribution we will touch the later. In particular we will describe two different problems and also two completely different approaches to solve them.\r\n\r\nThe first problem we describe is from the area of bioinformatics or chemoinformatics. In the last 30\r\nyears impressive 3D structures have been built using DNA (DNA nanotechnology, including so called \"DNA  origami\"). However, building complex structures from polypeptides would have many advantages, since amino acids provide much more functionality. The main difference or disadvantage comparing the two approaches is that there is no simple pairing rule between proteins like between DNA nucleotides. Fortunately, there exists a special class of protein structural assemblies called coiled-coils, among which pairing rules most closely resemble the pairing of DNA. For the design of complex polypeptide-based structures we require a set of orthogonal building elements that pair only with designated partners. In our contribution we will discuss how we can build such structures in-silico that they can be later verified in-vitro. We solve the problem by transformation to a maximum\r\nindependent set problem.\r\n\r\nThe logistic or more precisely the reverse logistic is our second problem. The area in which we apply the reverse logistic is the efficient use of natural resources, in particular of wood. Traditional use of waste wood would be to burn it or to landfill it. However, often the waste wood is still of such high quality that it can be reused. Therefore it is transferred from accumulation facilities to sorting facilities, where it is classified. According to its classification the wood is transferred to decontamination facilities, where it is processed for further sale as a raw material. Still however, the complete process of waste wood conversion into raw material has to be economically viable even considering categories like carbon footprint.  In our study we are interested about optimal placement of different facilities. For this purpose we first build a model and based on it construct an linear programme. In fact the linear programme is just use as an evaluation function of the quality of placement, while the real placement is done using metaheuristic.\r\n\r\nThe problems and results are from a joint research with\r\nMichael Burnard, Vladan Jovičić, Andreja Kutnar, Marko Palangetić, Daniel Siladji and Aleksandar Tošić, University of Primorska and\r\nRoman Jerala and Ajasja Ljubetič, National Institute of Chemistry\r\n\r\n† The work was in part supported by the WoodWisdom-Net and the Slovenian Ministry of Education, Science, and Sport of the Republic of Slovenia in the frame of Cascading Recovered Wood project.", :title "Two Tales from the Applied Combinatorial Optimization", :keyword2 19, :authors (20940), :session 5}, 268 {:keyword1 20, :keyword3 41, :abstract "This paper focus on resource-constrained scheduling problem. In\r\nparticular, we are interested in event-based mixed linear integer\r\nprograms for these problem. In this context, we have study two\r\nproblems: the Continuous Energy-Constrained Scheduling Problem (CECSP)\r\nand the Resource-Constrained Project Scheduling Problem (RCPSP).\r\n\r\nThe CECSP is a cumulative scheduling problem where a task duration\r\nand resource consumption are not fixed. The consumption profile of the\r\ntask, which can vary continuously over time, is a decision variable of\r\nthe problem to be determined and a task is completed as soon as the\r\nintegration over its time window of a non-decreasing and continuous\r\nefficiency function of the consumption profile has reached a\r\npredefined amount of energy.\r\n\r\nIn the RCPSP, we consider a set of tasks and a set of cumulative,\r\ndiscretly-divisible and renewable resource. Each task consumes a part\r\nof each resource during its execution. Furthermore, a set of precedence\r\nrelationship links the tasks together. The goal is to minimize the end\r\ntime of the schedule. \r\n\r\nFor the event based mixed integer linear program existing for these\r\nproblems, we provide several valid inequalities which are used to\r\nimprove the performance of the model. Furthermore, we give a minimal\r\ndescription of the polytope of all feasible assignments to the on/off\r\nbinary variable for a single activity along with a dedicated\r\nseparation algorithm. Computational experiments are reported in order\r\nto show the effectiveness of the results.", :title "Polyhedral results and valid inequalities for resource-constrained scheduling problem event-based models", :keyword2 11, :authors (50638 4503 16865 464), :session 30}}, :users {4 {:firstname "Chris", :lastname "Potts", :department "School of Mathematical Sciences", :institution "University of Southampton", :country "United Kingdom", :sessions (15)}, 406 {:firstname "Ilker", :lastname "Birbil", :department "Econometric Institute", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (17)}, 464 {:firstname "Pierre", :lastname "Lopez", :department "ROC", :institution "LAAS-CNRS", :country "France", :sessions (30)}, 587 {:firstname "Marek", :lastname "Mika", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (14)}, 710 {:firstname "Paolo", :lastname "Toth", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (19)}, 806 {:firstname "Maciej", :lastname "Drozdowski", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (18)}, 1252 {:firstname "Silvano", :lastname "Martello", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (41 3 42)}, 1259 {:firstname "Sergio", :lastname "García Quiles", :department "School of Mathematics", :institution "University of Edinburgh", :country "United Kingdom", :sessions (20)}, 1309 {:firstname "Paulo", :lastname "Correia", :department "Energy Department", :institution "Unicamp", :country "Brazil", :sessions (39)}, 2236 {:firstname "Arik", :lastname "Sadeh", :department "Technology Management Faculty", :institution "HIT Holon Institute of Technology", :country "Israel", :sessions (17)}, 2247 {:firstname "Frédéric", :lastname "Semet", :department "CRIStAL", :institution "Centrale Lille", :country "France", :sessions (15)}, 2435 {:firstname "Tolga", :lastname "Bektas", :department "University of Liverpool Management School", :institution "University of Liverpool", :country "United Kingdom", :sessions (15)}, 2509 {:firstname "Bo", :lastname "Chen", :department "Warwick Business School", :institution "University of Warwick", :country "United Kingdom", :sessions (25)}, 2644 {:firstname "Hakan", :lastname "Gultekin", :department "Mechanical & Industrial Engineering", :institution "Sultan Qaboos University", :country "Oman", :sessions (39)}, 3392 {:firstname "Said", :lastname "Salhi", :department "Kent Business School", :institution "University of Kent", :country "United Kingdom", :sessions (19)}, 3578 {:firstname "Mahmut Ali", :lastname "Gokce", :department "Industrial Engineering", :institution "Yaşar University", :country "Turkey", :sessions (19)}, 4436 {:firstname "Gilbert", :lastname "Owusu", :department "BT Exact", :institution "British Telecommunications plc", :country "United Kingdom", :sessions (39)}, 4503 {:firstname "Tamas", :lastname "Kis", :department "", :institution "Institute for Computer Science and Control", :country "Hungary", :sessions (41 14 2 30 5 32 42)}, 4991 {:firstname "Vladimir", :lastname "Deineko", :department "Warwick Business School", :institution "Warwick University", :country "United Kingdom", :sessions (29)}, 5390 {:firstname "Jacek", :lastname "Blazewicz", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (4 35)}, 5405 {:firstname "Stefano", :lastname "Benati", :department "School of International Studies", :institution "University of Trento", :country "Italy", :sessions (20)}, 5421 {:firstname "Marta", :lastname "Kasprzak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (21)}, 5486 {:firstname "Gábor", :lastname "Nagy", :department "Kent Business School", :institution "University of Kent", :country "United Kingdom", :sessions (19)}, 5615 {:firstname "A. Serdar", :lastname "Tasan", :department "Department of Industrial Engineering", :institution "Dokuz Eylul University", :country "Turkey", :sessions (40)}, 5876 {:firstname "Justo", :lastname "Puerto", :department "Estadistica e I.O.", :institution "Universidad de Sevilla", :country "Spain", :sessions (20)}, 5994 {:firstname "Monique", :lastname "Guignard-Spielberg", :department "Operations, Information and Decisions", :institution "University of Pennsylvania", :country "United States", :sessions (29)}, 6621 {:firstname "Malgorzata", :lastname "Sterna", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (31)}, 8446 {:firstname "Leo", :lastname "Liberti", :department "CNRS LIX", :institution "Ecole Polytechnique", :country "France", :sessions (4)}, 9037 {:firstname "Alain", :lastname "Hertz", :department "", :institution "Polytechnique Montreal and GERAD", :country "Canada", :sessions (22)}, 10133 {:firstname "Kerem", :lastname "Bulbul", :department "Manufacturing Sys. & Industrial Eng.", :institution "Sabanci University", :country "Turkey", :sessions (17)}, 10217 {:firstname "Grzegorz", :lastname "Waligora", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (30)}, 10785 {:firstname "Edward", :lastname "Gimadi", :department "Discrete Optimization in Operations Research", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (16 38)}, 10954 {:firstname "Erwin", :lastname "Pesch", :department "Faculty III", :institution "University of Siegen", :country "Germany", :sessions (13)}, 11277 {:firstname "Olivier", :lastname "Hudry", :department "Informatique et Reseaux", :institution "Télécom ParisTech", :country "France", :sessions (16)}, 11482 {:firstname "Van-Dat", :lastname "Cung", :department "Grenoble INP - Génie Industriel", :institution "Laboratory G-SCOP", :country "France", :sessions (31)}, 11762 {:firstname "Josep", :lastname "Freixas", :department "Matemàtiques", :institution "Universitat Politècnica de Catalunya", :country "Spain", :sessions (13)}, 11799 {:firstname "David", :lastname "Pisinger", :department "DTU Management", :institution "Technical University of Denmark", :country "Denmark", :sessions (3)}, 11807 {:firstname "Piotr", :lastname "Lukasiak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (21)}, 11890 {:firstname "Matthias", :lastname "Köppe", :department "Dept. of Mathematics", :institution "University of California, Davis", :country "United States", :sessions (17)}, 12453 {:firstname "Florian", :lastname "Jaehn", :department "Management Science and Operations Research", :institution "Helmut-Schmidt-University - University of the Federal Armed Forces Hamburg", :country "Germany", :sessions (18)}, 14295 {:firstname "Rafal", :lastname "Rozycki", :department "Institute of Computing Science", :institution "Poznań University of Technology", :country "Poland", :sessions (14)}, 15091 {:firstname "Zdenek", :lastname "Hanzalek", :department "", :institution "CTU Prague", :country "Czech Republic", :sessions (14 26)}, 15362 {:firstname "Esther", :lastname "Mohr", :department "Advanced Business Analytics", :institution "BASF Business Services GmbH", :country "Germany", :sessions (31)}, 15460 {:firstname "Lamia", :lastname "AOUDIA", :department "Mathematics", :institution "University", :country "Algeria", :sessions (38)}, 16077 {:firstname "Igor", :lastname "Averbakh", :department "Department of Management", :institution "University of Toronto at Scarborough", :country "Canada", :sessions (28)}, 16865 {:firstname "Christian", :lastname "Artigues", :department "LAAS", :institution "CNRS", :country "France", :sessions (26 30)}, 16992 {:firstname "Ibrahim", :lastname "Muter", :department "School of Management", :institution "University of Bath", :country "United Kingdom", :sessions (17)}, 18683 {:firstname "Szymon", :lastname "Wasik", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (33)}, 18733 {:firstname "Pascal", :lastname "Bouvry", :department "", :institution "Univ. of Luxembourg", :country "Luxembourg", :sessions (35)}, 19096 {:firstname "Yann", :lastname "Kieffer", :department "", :institution "Grenoble-INP", :country "France", :sessions (26)}, 19524 {:firstname "Eric", :lastname "Sanlaville", :department "UFR Sciences et Techniques", :institution "LITIS", :country "France", :sessions (18)}, 19853 {:firstname "Marcin", :lastname "Borowski", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (21)}, 20145 {:firstname "Maciej", :lastname "Antczak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (21 33)}, 20793 {:firstname "Michael", :lastname "Herty", :department "Fachbereich Mathematik", :institution "RWTH Aachen", :country "Germany", :sessions (29)}, 20838 {:firstname "Sebnem", :lastname "Demirkol Akyol", :department "Industrial Engineering", :institution "Dokuz Eylul University", :country "Turkey", :sessions (40)}, 20930 {:firstname "Miklos", :lastname "Kresz", :department "Department of Applied Informatics", :institution "University of Szeged", :country "Hungary", :sessions (12)}, 20940 {:firstname "Andrej", :lastname "Brodnik", :department "", :institution "University of Primorska, PINT", :country "Slovenia", :sessions (5)}, 22043 {:firstname "Vitaly", :lastname "Strusevich", :department "Department of Mathematical  Sciences", :institution "University of Greenwich", :country "United Kingdom", :sessions (18)}, 22191 {:firstname "Djamal", :lastname "Rebaine", :department "Informatique et mathématique", :institution "Université du Québec à Chicoutimi", :country "Canada", :sessions (22)}, 22410 {:firstname "Claudia", :lastname "D'Ambrosio", :department "LIX", :institution "CNRS - Ecole Polytechnique", :country "France", :sessions (4)}, 22920 {:firstname "Valentina", :lastname "Cacchiani", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (19)}, 23034 {:firstname "Bela", :lastname "Vizvari", :department "Industrial Engineering", :institution "Eastern Mediterranean University", :country "Turkey", :sessions (22)}, 23682 {:firstname "David", :lastname "Raz", :department "Management of Technology", :institution "Holon Institute of Technology", :country "Israel", :sessions (17)}, 23927 {:firstname "Huseyin ", :lastname "Guden", :department "Industrial Engineering", :institution "Baskent University", :country "Turkey", :sessions (22)}, 24329 {:firstname "Andreas", :lastname "Klinkert", :department "Institute of Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (34)}, 25227 {:firstname "Premysl", :lastname "Sucha", :department "Department of Control Engineering", :institution "Czech Technical University, Faculty of Electrical Engineering", :country "Czech Republic", :sessions (14 26)}, 25289 {:firstname "Fehmi Burcin", :lastname "Ozsoydan", :department "Industrial Engineering", :institution "Dokuz Eylul University", :country "Turkey", :sessions (27)}, 25372 {:firstname "Luce", :lastname "Brotcorne", :department "", :institution "INRIA", :country "France", :sessions (15)}, 26119 {:firstname "Jedrzej", :lastname "Musial", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (35)}, 26471 {:firstname "Anja", :lastname "Fischer", :department "", :institution "TU Dortmund", :country "Germany", :sessions (28)}, 28646 {:firstname "Eranda", :lastname "Cela", :department "Department of Discrete Mathematics", :institution "TU Graz", :country "Austria", :sessions (29)}, 28899 {:firstname "Gultekin", :lastname "Kuyzu", :department "Industrial Engineering", :institution "TOBB University of Economics and Technology", :country "Turkey", :sessions (13)}, 28949 {:firstname "Pablo A.", :lastname "Miranda", :department "Department of Engineering Sciences", :institution "Universidad Andres Bello", :country "Chile", :sessions (15)}, 28952 {:firstname "Gabriel", :lastname "Gutiérrez-Jarpa", :department "School of Industrial Engineering", :institution "Pontificia Universidad Católica de Valparaíso", :country "Chile", :sessions (15)}, 29418 {:firstname "Ivan", :lastname "Davydov", :department "Theoretical Cybernetics", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (28)}, 29563 {:firstname "Dominik", :lastname "Kress", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (13 18)}, 29675 {:firstname "Simone", :lastname "Göttlich", :department "School of Business Informatics and Mathematics", :institution "University of Mannheim", :country "Germany", :sessions (29)}, 29780 {:firstname "Joerg", :lastname "Fliege", :department "", :institution "University of Southampton", :country "United Kingdom", :sessions (40)}, 30955 {:firstname "Philipp", :lastname "Hungerländer", :department "Mathematics", :institution "University of Klagenfurt", :country "Austria", :sessions (28 32)}, 31551 {:firstname "Mateusz", :lastname "Cichenski", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (31)}, 31689 {:firstname "Nicolas", :lastname "Catusse", :department "", :institution "Grenoble INP / G-SCOP", :country "France", :sessions (31)}, 32557 {:firstname "Pierre", :lastname "Baptiste", :department "de mathématiques et de Génie Industriel", :institution "École Polytechnique de Montréal", :country "Canada", :sessions (22)}, 32753 {:firstname "Kabir", :lastname "Rustogi", :department "School of Computing and Mathematical ScienceMathema", :institution "University of Greenwich", :country "United Kingdom", :sessions (18)}, 35266 {:firstname "Gia", :lastname "Sirbiladze", :department "Department of Computer Sciences", :institution "Iv.Javakhishvili Tbilisi State University", :country "Georgia", :sessions (23)}, 35317 {:firstname "Didem", :lastname "Abidin", :department "Computer Engineering", :institution "Celal Bayar University", :country "Turkey", :sessions (33)}, 35483 {:firstname "Anne", :lastname "Liret", :department "R&T", :institution "British Telecom", :country "France", :sessions (39)}, 35631 {:firstname "Alpár", :lastname "Jüttner", :department "Dept of Operations Research", :institution "ELTE", :country "Hungary", :sessions (19 21)}, 36036 {:firstname "Adil", :lastname "Baykasoğlu", :department "Industrial Engineering", :institution "Dokuz Eylül University", :country "Turkey", :sessions (27 30 40)}, 36176 {:firstname "Alain", :lastname "Hait", :department "Complex systems Engineering", :institution "ISAE University of Toulouse", :country "France", :sessions (30)}, 36477 {:firstname "Yury", :lastname "Maximov", :department "", :institution "Institute for Information Transmission Problems", :country "Russian Federation", :sessions (28)}, 36610 {:firstname "Patrick", :lastname "Beullens", :department "School of Mathematics, School of Management", :institution "University of Southampton", :country "United Kingdom", :sessions (40)}, 36653 {:firstname "Çağla", :lastname "Cergibozan", :department "Department of Industrial Engineering", :institution "Dokuz Eylul University", :country "Turkey", :sessions (40)}, 36740 {:firstname "Xavier", :lastname "Schepler", :department "", :institution "Recommerce Lab", :country "France", :sessions (18)}, 37025 {:firstname "Salih", :lastname "Tekin", :department "Industrial Engineering", :institution "TOBB University of Economics and Technology", :country "Turkey", :sessions (39)}, 38193 {:firstname "Sebastian", :lastname "Meiswinkel", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (13)}, 38450 {:firstname "Carlos", :lastname "Obreque", :department "Industrial Enginnering", :institution "Universidad del Bío-Bío", :country "Chile", :sessions (15)}, 38451 {:firstname "Kristóf", :lastname "Bérczi", :department "", :institution "MTA-ELTE Egerváry Research Group", :country "Hungary", :sessions (19 24)}, 39366 {:firstname "Jakub", :lastname "Marszałkowski", :department "Institute of Computing Science", :institution "Poznań University of Technology", :country "Poland", :sessions (18 31)}, 41880 {:firstname "Nihat", :lastname "Öner", :department "Industrial Engineering Department", :institution "TOBB University of Economics and Technology", :country "Turkey", :sessions (13)}, 46356 {:firstname "Carola", :lastname "Blazquez", :department "Department of Engineering Science", :institution "Universidad Andres Bello", :country "Chile", :sessions (15)}, 47019 {:firstname "Khadija", :lastname "Hadj Salem", :department "", :institution "LCIS Valence - Univ Grenoble Alpes", :country "France", :sessions (26)}, 47171 {:firstname "Andrei", :lastname "Nikolaev", :department "Discrete Analysis", :institution "P.G. Demidov Yaroslavl State University", :country "Russian Federation", :sessions (17)}, 47432 {:firstname "Cansu", :lastname "Agrali", :department "Industrial Engineering", :institution "TOBB University of Economics and Technology", :country "Turkey", :sessions (39)}, 47786 {:firstname "Mikhail", :lastname "Mendel", :department "", :institution "MIPT", :country "Russian Federation", :sessions (28)}, 47956 {:firstname "Becky", :lastname "Callaghan", :department "Kent Business School", :institution "The University of Kent", :country "United Kingdom", :sessions (19)}, 48039 {:firstname "Jordi", :lastname "Pereira", :department "Department of Engineering and Sciences", :institution "Universidad Adolfo Ibáñez", :country "Chile", :sessions (28)}, 48546 {:firstname "Pierre-Louis", :lastname "Poirion", :department "", :institution "LIX-Ecole Polytechnique", :country "France", :sessions (4)}, 48557 {:firstname "Sonia", :lastname "Toubaline", :department "LIX", :institution "ECOLE POLYTECHNIQUE", :country "France", :sessions (4)}, 48827 {:firstname "Pierre", :lastname "Hauweele", :department "Algorithms Lab", :institution "UMONS", :country "Belgium", :sessions (12)}, 48951 {:firstname "Nurhan", :lastname "Dudaklı", :department "Industrial Engineering", :institution "Dokuz Eylül University", :country "Turkey", :sessions (27)}, 49578 {:firstname "Pierre", :lastname "Desport", :department "", :institution "Universite Angers", :country "France", :sessions (39)}, 49684 {:firstname "Péter", :lastname "Györgyi", :department "", :institution "MTA SZTAKI", :country "Hungary", :sessions (14)}, 49869 {:firstname "Markó", :lastname "Horváth", :department "", :institution "Institute for Computer Science and Control", :country "Hungary", :sessions (32)}, 50204 {:firstname "Jakub", :lastname "Wawrzyniak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (18)}, 50302 {:firstname "Semën", :lastname "Nikolajewski", :department "Operations Management and Process Innovation", :institution "German Graduate School of Management and Law", :country "Germany", :sessions (31)}, 50336 {:firstname "Kathinka", :lastname "Hameister", :department "Department of Mathematics", :institution "University of Mannheim", :country "Germany", :sessions (29)}, 50340 {:firstname "FULIN", :lastname "XIE", :department "Mathematical Science", :institution "University of Southampton", :country "United Kingdom", :sessions (15)}, 50490 {:firstname "Mümin Emre", :lastname "Şenol", :department "Industrial Engineering ", :institution "Dokuz Eylul University", :country "Turkey", :sessions (30)}, 50597 {:firstname "Bezhan", :lastname "Ghvaberidze", :department "Department of Computer Sciences", :institution "Iv. Javakhishvili Tbilisi State University", :country "Georgia", :sessions (23)}, 50616 {:firstname "Sumit", :lastname "Raut", :department "Innovation Lab", :institution "Tata Consultancy Services", :country "India", :sessions (27)}, 50624 {:firstname "András", :lastname "Frank", :department "", :institution "Eötvös Loránd University", :country "Hungary", :sessions (2 24)}, 50626 {:firstname "Laura", :lastname "Silva Granada", :department "", :institution "University of Campinas - UNICAMP", :country "Brazil", :sessions (39)}, 50638 {:firstname "Margaux", :lastname "Nattaf", :department "", :institution "LAAS-CNRS", :country "France", :sessions (30)}, 50639 {:firstname "Prabhu", :lastname "Manyem", :department "College of Science", :institution "Nanchang Institute of Technology", :country "China", :sessions (34)}, 50699 {:firstname "Alice", :lastname "Robins", :department "School of Mathematics", :institution "University of Southampton", :country "United Kingdom", :sessions (40)}, 50702 {:firstname "Artur", :lastname "Laskowski", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (33)}, 50703 {:firstname "Jan", :lastname "Badura", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (33)}, 50709 {:firstname "Mateusz", :lastname "Guzek", :department "", :institution "University of Luxembourg", :country "Luxembourg", :sessions (35)}, 50710 {:firstname "Alicja", :lastname "Gniewek", :department "", :institution "Univesity of Luxembourg", :country "Luxembourg", :sessions (35)}, 50732 {:firstname "Dávid", :lastname "Szeszlér", :department "Department of Computer Science and Information Theory", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (13)}, 50771 {:firstname "Pierre-Antoine", :lastname "Morin", :department "", :institution "ISAE-Supaero / LAAS-CNRS", :country "France", :sessions (30)}, 50792 {:firstname "Feng", :lastname "Jiang", :department "faculty of engineering/school of transportation and logistics", :institution "Univeristy of Bologna/Southwest Jiaotong University", :country "Italy", :sessions (19)}, 50838 {:firstname "Burcu", :lastname "Kubur", :department "Industrial Engineering Department", :institution "Dokuz Eylül Univesity", :country "Turkey", :sessions (40)}, 50858 {:firstname "Péter", :lastname "Madarasi", :department "", :institution "Eötvös Loránd University", :country "Hungary", :sessions (21)}, 50930 {:firstname "Bidzina", :lastname "Matsaberidze", :department "Department of Computer Sciences", :institution "Iv.Javakhishvili Tbilisi State University", :country "Georgia", :sessions (23)}, 50957 {:firstname "Jongwoo", :lastname "Park", :department "ESE", :institution "University of Pennsylvania", :country "Korea, Republic of", :sessions (29)}, 50992 {:firstname "Kerstin", :lastname "Maier", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (32)}, 50997 {:firstname "Christian", :lastname "Truden", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (32)}, 51035 {:firstname "Jörg", :lastname "Pöcher", :department "", :institution "AAU Klagenfurt", :country "Austria", :sessions (32)}, 51071 {:firstname "Tomasz", :lastname "Sternal", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (33)}, 51079 {:firstname "Hadrien", :lastname "Mélot", :department "Computer Science Dept", :institution "Université de Mons", :country "Belgium", :sessions (12)}, 51087 {:firstname "İlknur", :lastname "YENİLMEZ", :department "Industrial Engineering", :institution "The Graduate School of Natural and Applied Sciences", :country "Turkey", :sessions (27)}, 51088 {:firstname "Gauvain", :lastname "Devillez", :department "Computer science", :institution "UMONS", :country "Belgium", :sessions (12)}, 51093 {:firstname "Antonin", :lastname "Novak", :department "Department of Control Engineering, Faculty of Electrical Engineering", :institution "Czech Technical University in Prague", :country "Czech Republic", :sessions (26)}, 51098 {:firstname "Mateusz", :lastname "Ledzianowski", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (31)}, 51121 {:firstname "Micky", :lastname "Avitan", :department "Management of Technology Faculty", :institution "HIT, Holon Institute of Technology", :country "Israel", :sessions (17)}, 51132 {:firstname "Istvan", :lastname "Modos", :department "", :institution "Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague", :country "Czech Republic", :sessions (14)}, 51208 {:firstname "Fernanda", :lastname "Nakano Kazama", :department "Energy", :institution "University of Campinas - UNICAMP", :country "Brazil", :sessions (39)}, 51221 {:firstname "Alexey", :lastname "Istomin", :department "", :institution "Sobolev Institute of Mathematics SB RAS", :country "Russian Federation", :sessions (16)}, 51258 {:firstname "Mohammadreza", :lastname "Galavii", :department "Mathematics", :institution "Zabol University", :country "Iran, Islamic Republic of", :sessions (20)}, 51273 {:firstname "Cong", :lastname "Kang", :department "", :institution "Texas A&M University at Galveston", :country "United States", :sessions (16)}, 51294 {:firstname "Diego", :lastname "Cattaruzza", :department "", :institution "Centrale Lille", :country "France", :sessions (15)}, 51309 {:firstname "Ekaterina", :lastname "Shin", :department "", :institution "Sobolev Institute of Mathematics SB RAS", :country "Russian Federation", :sessions (16)}, 51339 {:firstname "Ali Engin", :lastname "DORUM", :department "Industrial Engineering", :institution "Antalya Bilim University", :country "Turkey", :sessions (19)}, 51460 {:firstname "Gyorgy", :lastname "Dosa", :department "Mathematical Department", :institution "University of Pannonia", :country "Hungary", :sessions (25)}, 51548 {:firstname "Yuan", :lastname "Zhou", :department "Mathematics", :institution "UC Davis", :country "United States", :sessions (17)}, 51575 {:firstname "Nathalie", :lastname "Mitton", :department "", :institution "INRIA", :country "France", :sessions (15)}, 51576 {:firstname "Tahiry", :lastname "Razafindralambo", :department "", :institution "INRIA", :country "France", :sessions (15)}, 51577 {:firstname "Zsolt", :lastname "Tuza", :department "", :institution "Alfréd Rényi Institute of Mathematics, Hungarian Academy of Sciences", :country "Hungary", :sessions (12)}, 51596 {:firstname "Csilla", :lastname "Bujtás", :department "", :institution "Alfréd Rényi Institute of Mathematics, Hungarian Academy of Sciences", :country "Hungary", :sessions (12)}, 51626 {:firstname "Szilárd", :lastname "Jaskó", :department "Department of Computer Science and Systems Technology", :institution "University of Pannonia", :country "Hungary", :sessions (12)}, 51635 {:firstname "Eva", :lastname "Hosszu", :department "", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (20)}, 51652 {:firstname "mazyar", :lastname "ghadirinejad", :department "Industrian Engineering", :institution "EMU", :country "Turkey", :sessions (22)}, 51662 {:firstname "Anna", :lastname "Jellen", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (28)}, 51664 {:firstname "Csaba", :lastname "Király", :department "Department of Operations Research", :institution "Eötvös University", :country "Hungary", :sessions (37)}, 51666 {:firstname "Tamás", :lastname "Hajba", :department "", :institution "Széchenyi István University", :country "Hungary", :sessions (22)}, 51675 {:firstname "Zoltán", :lastname "Horváth", :department "", :institution "Széchenyi István University", :country "Hungary", :sessions (22)}, 51698 {:firstname "Erika", :lastname "Bérczi-Kovács", :department "Operations Research", :institution "Eötvös Loránd University", :country "Hungary", :sessions (37)}, 51707 {:firstname "Zoltán", :lastname "Király", :department "", :institution "Alfréd Rényi Institute of Mathematics ", :country "Hungary", :sessions (24)}, 51718 {:firstname "Endre", :lastname "Csóka", :department "", :institution "Alfréd Rényi Institute of Mathematics", :country "Hungary", :sessions (16)}, 51731 {:firstname "Quentin", :lastname "Fortier", :department "", :institution "Univ. Grenoble Alpes, G-SCOP", :country "France", :sessions (37)}, 51732 {:firstname "Zoltán", :lastname "Szigeti", :department "", :institution "Univ. Grenoble Alpes, G-SCOP", :country "France", :sessions (37)}, 51733 {:firstname "Marion", :lastname "Léonard", :department "", :institution "Allegro DVT", :country "France", :sessions (37)}, 51734 {:firstname "Alexandre", :lastname "Talon", :department "", :institution "Ens de Lyon", :country "France", :sessions (37)}, 51754 {:firstname "Attila", :lastname "Bernáth", :department "", :institution "Lufthansa Systems Hungária", :country "Hungary", :sessions (37)}, 51858 {:firstname "Gergely", :lastname "Kovács", :department "", :institution "Edutus College", :country "Hungary", :sessions (22)}, 51909 {:firstname "Reinhard", :lastname "Bürgy", :department "Department of Informatics", :institution "University of Fribourg", :country "Switzerland", :sessions (22)}, 51930 {:firstname "Csongor György", :lastname "Csehi", :department "Department of Computer Science and Information Theory", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (15)}, 51991 {:firstname "Stéphane", :lastname "mancini", :department "TIMA Laboratory", :institution "Grenoble INP", :country "France", :sessions (26)}, 52000 {:firstname "Ljiljana", :lastname "Brankovic", :department "School of Electrical Engineering and Computer Science", :institution "The University of Newcastle", :country "Australia", :sessions (35)}, 52002 {:firstname "Jeremy", :lastname "Evans", :department "", :institution "The University of Newcastle", :country "Australia", :sessions (35)}, 52005 {:firstname "Bogdan", :lastname "Zavalnij", :department "Institute of Mathematics and Informatics", :institution "University of Pecs", :country "Hungary", :sessions (37)}, 52008 {:firstname "Gabriel", :lastname "Istrate", :department "Computer Science", :institution "West University of Timisoara and the e-Austria Research Institute", :country "Romania", :sessions (38)}, 52010 {:firstname "Márk", :lastname "Farkas", :department "", :institution "Nexogen", :country "Hungary", :sessions (15)}, 52011 {:firstname "Ádám", :lastname "Tóth", :department "", :institution "Nexogen", :country "Hungary", :sessions (15)}, 52016 {:firstname "Cosmin", :lastname "Bonchis", :department "CS", :institution "UVT", :country "Romania", :sessions (38)}, 52023 {:firstname "Janos", :lastname "Tapolcai", :department "", :institution "Budapest University of Technology and Economics", :country "Hungary", :sessions (20)}, 52026 {:firstname "Frédéric", :lastname "Lardeux", :department "", :institution "Université d'Angers", :country "France", :sessions (39)}, 52027 {:firstname "David", :lastname "Lesaint", :department "", :institution "Université d'Angers", :country "France", :sessions (39)}, 52028 {:firstname "Carla", :lastname "Di Cairano-Gilfedder", :department "", :institution "British Telecom", :country "United Kingdom", :sessions (39)}, 52029 {:firstname "Miklos", :lastname "Bartha", :department "Computer Science", :institution "Memorial University of Newfoundland", :country "Canada", :sessions (12)}, 52040 {:firstname "Nicolas", :lastname "BRULARD", :department "", :institution "Laboratory G-SCOP", :country "France", :sessions (31)}, 52041 {:firstname "Cyril", :lastname "DUTRIEUX", :department "", :institution "Laboratory G-SCOP", :country "France", :sessions (31)}, 52044 {:firstname "Elias", :lastname "Olivares-Benitez", :department "Graduate Studies and Research Interdisciplinary Center", :institution "UPAEP University", :country "Mexico", :sessions (15)}, 52130 {:firstname "Sandor", :lastname "Szabo", :department "Applied Mathematics", :institution "University of Pecs", :country "Hungary", :sessions (37)}, 55926 {:firstname "Gerhard", :lastname "Woeginger", :department "", :institution "RWTH Aachen", :country "Germany", :sessions (29)}}}