{:timeslots {1 {:schedule "Wednesday, 8:30-10:30", :day "W", :time "A", :sessions (240)}, 2 {:schedule "Wednesday, 11:00-12:30", :day "W", :time "B", :sessions (196 202 16 88 175 216 78 70 105 109 192 276 277 74 92 145 40)}, 3 {:schedule "Wednesday, 13:30-14:15", :day "W", :time "C", :sessions (262 261 260 259 263)}, 4 {:schedule "Wednesday, 14:30-16:00", :day "W", :time "D", :sessions (50 205 22 178 217 121 79 91 104 110 120 189 129 155 77 93 146 133 43)}, 5 {:schedule "Wednesday, 16:30-18:00", :day "W", :time "E", :sessions (227 207 23 135 179 218 122 228 100 111 128 193 130 156 96 94 147 134 44)}, 6 {:schedule "Thursday, 8:30-10:00", :day "T", :time "A", :sessions (197 206 28 181 219 37 230 63 103 112 258 188 131 157 142 124 148 85 166)}, 7 {:schedule "Thursday, 10:30-11:15", :day "T", :time "B", :sessions (264 267 265 266 268)}, 8 {:schedule "Thursday, 11:30-13:00", :day "T", :time "C", :sessions (198 209 274 29 180 220 65 229 84 106 113 234 195 132 158 154 125 152 162 167)}, 9 {:schedule "Thursday, 14:00-15:30", :day "T", :time "D", :sessions (199 210 257 32 226 221 137 231 87 99 115 76 194 172 159 95 126 245 163 168)}, 10 {:schedule "Thursday, 15:45-17:15", :day "T", :time "E", :sessions (241)}, 11 {:schedule "Friday, 8:30-10:00", :day "F", :time "A", :sessions (201 211 108 33 214 222 138 139 116 160 97 169)}, 12 {:schedule "Friday, 10:30-11:15", :day "F", :time "B", :sessions (278 273 271 270 272 269)}, 13 {:schedule "Friday, 11:30-13:00", :day "F", :time "C", :sessions (200 212 127 86 213 225 118 161 98 170)}}, :streams {3 {:name "I.1 Forecasting, Data Mining and Machine Learning", :order 2, :sessions (78 260 79 228 230 229 231)}, 4 {:name "I.2 Game Theory and Experimental Economics", :order 4, :sessions (192 259 189 193 188 195 194 272)}, 6 {:name "I.3 Managerial Accounting", :order 6, :sessions (261 121 122)}, 7 {:name "I.4 Financial Modelling and Numerical Methods", :order 8, :sessions (74 262 77 96 142 154 95 97 98)}, 8 {:name "I.5 Pricing and Revenue Management ", :order 10, :sessions (92 93 94)}, 9 {:name "I.6 Quantitative Models for Performance and Dependability", :order 12, :sessions (129 130 131 132 172 269)}, 10 {:name "I.7 Business Informatics and Artificial Intelligence", :order 14, :sessions (263 124 125 126)}, 11 {:name "II.1 Traffic, Transportation and Logistics", :order 16, :sessions (196 202 50 205 227 207 197 206 264 198 209 199 210 201 211 200 212)}, 12 {:name "II.2 Discrete Optimization, Graphs & Networks", :order 18, :sessions (216 217 218 219 220 221 214 222 213 225)}, 13 {:name "II.3 Stochastic Programming", :order 20, :sessions (70 91 270)}, 14 {:name "II.4 Continuous Optimization", :order 22, :sessions (105 104 100 63 103 265 84 106 87 99)}, 15 {:name "II.5 Production and Service Management", :order 24, :sessions (155 156 157 158 159 160 161)}, 16 {:name "II.6 Supply Chain Management & Inventory", :order 26, :sessions (109 110 120 111 128 112 266 113 115 116 118)}, 17 {:name "II.7 Scheduling and Project Management", :order 28, :sessions (145 146 147 148 152 245)}, 18 {:name "III.1 Environmental Management", :order 30, :sessions (40 133 134)}, 19 {:name "III.2 Energy Markets", :order 32, :sessions (85 162 163)}, 20 {:name "III.3 Health Care", :order 34, :sessions (37 267 65 137 138 139)}, 21 {:name "III.4 Multiple Criteria Decision Making", :order 36, :sessions (234 76)}, 22 {:name "III.5 Simulation and System Dynamics", :order 38, :sessions (43 44 166 268 167 168 169 170)}, 24 {:name "III.7 Young Scientist's Session: First results of on-going phd-projects", :order 42, :sessions (175 178 179 181 180 226 271)}, 26 {:name "III.6 OR in Life Sciences and Education - Trends, History and Ethics", :order 40, :sessions (16 88 22 23 135 28 29 32 108 33 273 127 86)}, 29 {:name "IV.1 Plenary", :order 44, :sessions (240 241)}, 30 {:name "IV.3 Others", :order 48, :sessions (276 277 258)}, 31 {:name "IV.2 Awards", :order 46, :sessions (274 257 278)}}, :sessions {16 {:name "Applications on Societal Criminality Analysis and Medical Tumor Investigations", :stream 26, :chairs (23449), :timeslot 2, :papers (1019 1042 296), :track 4}, 22 {:name "OR in Complex Societal Problems I", :stream 26, :chairs (1254), :timeslot 4, :papers (360 444 704 1038), :track 4}, 23 {:name "OR for Development and Developing Countries, and Intelligent Systems in OR, Applied to Life and Human Sciences", :stream 26, :chairs (3524 22309 50162), :timeslot 5, :papers (1022 798 1002 758), :track 4}, 28 {:name "OR:  Responsibility, Sharing and Cooperation ", :stream 26, :chairs (4837), :timeslot 6, :papers (854 1051 145 1056), :track 4}, 29 {:name "Applications of Nonsmooth, Conic and Robust Optimization in Life and Human Sciences", :stream 26, :chairs (3524 10929 11072), :specialroom "1131", :timeslot 8, :papers (980 813 836), :track 5}, 32 {:name "Data Mining and Optimization in Computational Biology, Bioinformatics and Medicine", :stream 26, :chairs (8923 12264), :timeslot 9, :papers (380 990 1024), :track 5}, 33 {:name "OR, Socio-Cultural Issues and Gender", :stream 26, :chairs (23389), :timeslot 11, :papers (262 264 1049), :track 5}, 37 {:name "Health Care Operations Management I", :stream 20, :chairs (15060), :timeslot 6, :papers (370 635 457), :track 8}, 40 {:name "Environmental management I", :stream 18, :chairs (11105), :timeslot 2, :papers (204 883 1027), :track 20}, 43 {:name "Hybrid Models I - Relationsship Management, Risk-Management & Inter-Organizational-Communication", :stream 22, :chairs (17364), :timeslot 4, :papers (461 755 991 1045), :track 21}, 44 {:name "System Dynamics I", :stream 22, :chairs (20167), :timeslot 5, :papers (757 915 693 324), :track 21}, 50 {:name "Dynamic vehicle routing II", :stream 11, :chairs (13264), :timeslot 4, :papers (610 611 612 614), :track 2}, 63 {:name "Nonsmooth Optimization I", :stream 14, :chairs (20607), :timeslot 6, :papers (580 406 358), :track 10}, 65 {:name "Health Care Modelling I", :stream 20, :chairs (770 18508), :timeslot 8, :papers (873 241 73), :track 8}, 70 {:name "Stochastic Programming Applications ", :stream 13, :chairs (26352), :timeslot 2, :papers (153 418 842), :track 10}, 74 {:name "Asset Pricing, Management, and Optimization", :stream 7, :chairs (14810), :timeslot 2, :papers (687 333 391 384), :track 17}, 76 {:name "AHP, ANP and MODM", :stream 21, :chairs (), :timeslot 9, :papers (942 955 997 936), :track 13}, 77 {:name "Risk and Uncertainty I", :stream 7, :chairs (8981), :timeslot 4, :papers (339 920 588), :track 17}, 78 {:name "Models ", :stream 3, :chairs (18385), :timeslot 2, :papers (188 787), :track 9}, 79 {:name "Optimization algorithm for machine learning", :stream 3, :chairs (10000), :timeslot 4, :papers (501 866 938), :track 9}, 84 {:name "Nonsmooth Optimimization II", :stream 14, :chairs (20607), :timeslot 8, :papers (347 352 298), :track 10}, 85 {:name "Energy Forecasting", :stream 19, :chairs (14818), :timeslot 6, :papers (661 439 662 725), :track 20}, 86 {:name "Advances in OR, Learning and Data Mining Tools in Life Sciences and Education", :stream 26, :chairs (19525 23978), :timeslot 13, :papers (325 517 976 829), :track 5}, 87 {:name "Generalized convexity and continuous optimization", :stream 14, :chairs (), :timeslot 9, :papers (948 950 964), :track 10}, 88 {:name "Complex Demands on Social Services concerning Problems of Social Complexity", :stream 26, :chairs (20972 26410), :timeslot 2, :papers (287 1030 943), :track 5}, 91 {:name "Stochastic Programming Software", :stream 13, :chairs (10542), :timeslot 4, :papers (665 727 615), :track 10}, 92 {:name "Innovative Revenue Management Applications", :stream 8, :chairs (17366), :timeslot 2, :papers (334 346 354), :track 18}, 93 {:name "Modern Sales Operations and Revenue Management", :stream 8, :chairs (22994), :timeslot 4, :papers (108 472 651), :track 18}, 94 {:name "Advanced Pricing Issues", :stream 8, :chairs (16305), :timeslot 5, :papers (393 778 809), :track 18}, 95 {:name "Foreasting and Neural Networks", :stream 7, :chairs (14818), :timeslot 9, :papers (432 655 659), :track 17}, 96 {:name "Credit Risk and Derivatives", :stream 7, :chairs (26467), :timeslot 5, :papers (289 888 584 378), :track 17}, 97 {:name "Financial Econometrics", :stream 7, :chairs (23961), :timeslot 11, :papers (427 503 232 750), :track 17}, 98 {:name "Financial Crisis and Distress", :stream 7, :chairs (26871), :timeslot 13, :papers (135 815 385), :track 17}, 99 {:name "Applications", :stream 14, :chairs (9150), :timeslot 9, :papers (228 320 523), :track 11}, 100 {:name "Geometrical Problems and Algorithms", :stream 14, :chairs (12179), :timeslot 5, :papers (57 832 865), :track 11}, 103 {:name "Set and Vector Valued Optimization", :stream 14, :chairs (20717), :timeslot 6, :papers (741 742 743), :track 11}, 104 {:name "Software", :stream 14, :chairs (14853), :timeslot 4, :papers (594 619 372 720), :track 11}, 105 {:name "Algorithmic Advances", :stream 14, :chairs (17006), :timeslot 2, :papers (707 850 470), :track 11}, 106 {:name "Multicriteria and infinite dimensional optimization", :stream 14, :chairs (21077), :timeslot 8, :papers (536 824 713), :track 11}, 108 {:name "Supporting Military Decisions in the 21st Century: Theory and Practice", :stream 26, :chairs (26684 26690), :timeslot 11, :papers (985 986 987 988), :track 4}, 109 {:name "Supply", :stream 16, :chairs (17140), :timeslot 2, :papers (641 379 525), :track 12}, 110 {:name "Supply Chain Planning", :stream 16, :chairs (909), :timeslot 4, :papers (879 217 285), :track 12}, 111 {:name "Inventory", :stream 16, :chairs (829), :timeslot 5, :papers (274 518 918), :track 12}, 112 {:name "Coordination", :stream 16, :chairs (2651), :timeslot 6, :papers (323 494 867), :track 12}, 113 {:name "Sequencing and Scheduling", :stream 16, :chairs (2448), :timeslot 8, :papers (430 433 812), :track 12}, 115 {:name "Lotsizing", :stream 16, :chairs (4889), :timeslot 9, :papers (773 881 539), :track 12}, 116 {:name "Retail and Storage", :stream 16, :chairs (1131), :timeslot 11, :papers (978 710 961), :track 12}, 118 {:name "Supply Chain Complexity", :stream 16, :chairs (17134), :timeslot 13, :papers (538 904 690), :track 12}, 120 {:name "Capacity Management and Levelling", :stream 16, :chairs (13503), :timeslot 4, :papers (640 435), :track 13}, 121 {:name "Budgeting, Pricing Systems and related Consequences", :stream 6, :chairs (1658), :timeslot 4, :papers (181 206 731), :track 8}, 122 {:name "Accounting and Information Quality", :stream 6, :chairs (13364), :timeslot 5, :papers (423 238 186), :track 8}, 124 {:name "Metaheuristics", :stream 10, :chairs (7569), :timeslot 6, :papers (730 162 1016), :track 18}, 125 {:name "Data Analysis: Classification and Inference", :stream 10, :chairs (14887), :timeslot 8, :papers (295 316 210), :track 18}, 126 {:name "Decentralized Decision Making and Swarm Intelligence", :stream 10, :chairs (5321), :timeslot 9, :papers (329 716 1035), :track 18}, 127 {:name "OR Methods for Satellite Communication", :stream 26, :chairs (26739), :timeslot 13, :papers (1044 1055 1058), :track 4}, 128 {:name "Diverse Issues", :stream 16, :chairs (26156), :timeslot 5, :papers (1017 1015 117), :track 13}, 129 {:name "Queueing Systems I", :stream 9, :chairs (26194), :timeslot 4, :papers (148 447 675), :track 15}, 130 {:name "Queueing Systems II", :stream 9, :chairs (17075), :timeslot 5, :papers (736 756 627), :track 15}, 131 {:name "Techniques and Tools", :stream 9, :chairs (22466), :timeslot 6, :papers (734 851 599), :track 15}, 132 {:name "Stochastic Modelling", :stream 9, :chairs (26842), :timeslot 8, :papers (935 498 714), :track 15}, 133 {:name "Environmental Management II", :stream 18, :chairs (1521 25972), :timeslot 4, :papers (315 383 96 1009), :track 20}, 134 {:name "Environmental Management III", :stream 18, :chairs (26199), :timeslot 5, :papers (155 795 214), :track 20}, 135 {:name "OR in Complex Societal Problems II, and OR and Ethics", :stream 26, :chairs (1254 22122), :timeslot 5, :papers (106 771 1001 994), :track 5}, 137 {:name "Health Care Operations Management II", :stream 20, :chairs (26566), :timeslot 9, :papers (377 76 785), :track 8}, 138 {:name "Health Care Logistics", :stream 20, :chairs (33285), :timeslot 11, :papers (927 697 328), :track 8}, 139 {:name "Health Care Modelling II", :stream 20, :chairs (15857), :timeslot 11, :papers (331 732 133), :track 9}, 142 {:name "Investment, Trading and Hedging", :stream 7, :chairs (14545), :timeslot 6, :papers (336 900 673 880), :track 17}, 145 {:name "Flow Shop Scheduling", :stream 17, :chairs (26387), :timeslot 2, :papers (235 177 61 429), :track 19}, 146 {:name "Scheduling Applications", :stream 17, :chairs (14742), :timeslot 4, :papers (695 409 443 143), :track 19}, 147 {:name "Project Management and Scheduling", :stream 17, :chairs (5454), :timeslot 5, :papers (838 208 558), :track 19}, 148 {:name "Job Shop and Open Shop Scheduling", :stream 17, :chairs (14742), :timeslot 6, :papers (166 286 846), :track 19}, 152 {:name "Machine Scheduling", :stream 17, :chairs (14155), :timeslot 8, :papers (318 387 706 227), :track 19}, 154 {:name "Risk and Uncertainty II", :stream 7, :chairs (8981), :timeslot 8, :papers (436 337 338), :track 17}, 155 {:name "Environmental Aspects", :stream 15, :chairs (26176), :timeslot 4, :papers (127 510 926), :track 16}, 156 {:name "Data Envelopment Analysis", :stream 15, :chairs (14865), :timeslot 5, :papers (196 907 516), :track 16}, 157 {:name "Product Service Systems", :stream 15, :chairs (26613), :timeslot 6, :papers (857 699 415 916), :track 16}, 158 {:name "Designing and Operating Manufacturing Lines", :stream 15, :chairs (), :timeslot 8, :papers (203 804 946), :track 16}, 159 {:name "Maintenance Planning", :stream 15, :chairs (26159), :timeslot 9, :papers (381 564 853 903), :track 16}, 160 {:name "Capacity Planning and Scheduling", :stream 15, :chairs (17090), :timeslot 11, :papers (455 193 608 642), :track 16}, 161 {:name "Lot Sizing and Program Planning", :stream 15, :chairs (16870), :timeslot 13, :papers (877 901 711), :track 16}, 162 {:name "Energy Planning and Contracting", :stream 19, :chairs (14818), :timeslot 8, :papers (408 426 632 691), :track 20}, 163 {:name "Energy Markets", :stream 19, :chairs (14817), :timeslot 9, :papers (442 554 937), :track 20}, 166 {:name "Hybrid Models II - Traffic and Infrastructure", :stream 22, :chairs (17364), :timeslot 6, :papers (310 759 831 1012), :track 21}, 167 {:name "Hybrid Models III - Usage of Simulation to conquer Complexity", :stream 22, :chairs (26654), :timeslot 8, :papers (197 293 940 125), :track 21}, 168 {:name "Hybrid Models IV - Methodology & Parametrization", :stream 22, :chairs (25320), :timeslot 9, :papers (168 220 305), :track 21}, 169 {:name "System Dynamics II", :stream 22, :chairs (16924), :timeslot 11, :papers (245 1010 540 899), :track 21}, 170 {:name "System Dynamics III", :stream 22, :chairs (26423), :timeslot 13, :papers (394 910 922), :track 21}, 172 {:name "Optimization", :stream 9, :chairs (22108), :timeslot 9, :papers (288 1014 1005), :track 15}, 175 {:name "Algorithm Engineering - Part I", :stream 24, :chairs (26180), :timeslot 2, :papers (431 460 878 1087), :track 6}, 178 {:name "Complex Planning Processes and Optimization", :stream 24, :chairs (15321), :timeslot 4, :papers (215 835 858 1034), :track 6}, 179 {:name "Industrial Applications of OR - Business Informatics", :stream 24, :chairs (11624), :timeslot 5, :papers (399 649 548 1053), :track 6}, 180 {:name "Decision Support Systems, Conflict Modeling and Judgement Based Analysis", :stream 24, :chairs (26679), :timeslot 8, :papers (321 975 1050 1046), :track 6}, 181 {:name "Algorithm Engineering - Part II", :stream 24, :chairs (4861), :timeslot 6, :papers (692 871 981 1088), :track 6}, 188 {:name "Contributions to Cooperative Game Theory", :stream 4, :chairs (26259), :timeslot 6, :papers (134 244 1081), :track 14}, 189 {:name "Incentive Schemes: Theory and Experiments", :stream 4, :chairs (26951), :timeslot 4, :papers (397 512), :track 14}, 192 {:name "Applied Games: Oligopolistic Competition", :stream 4, :chairs (26261), :timeslot 2, :papers (702 917 434), :track 14}, 193 {:name "Experimental Studies and Cooperative Games", :stream 4, :chairs (281), :timeslot 5, :papers (686 818 99), :track 14}, 194 {:name "Theoretical Contributions to Game Theory ", :stream 4, :chairs (26194), :timeslot 9, :papers (213 718 847), :track 14}, 195 {:name "Applied Games with Sequential Structures", :stream 4, :chairs (26585), :timeslot 8, :papers (216 1013 150), :track 14}, 196 {:name "Vehicle routing problems", :stream 11, :chairs (15322), :timeslot 2, :papers (243 265 550 855), :track 2}, 197 {:name "Location problems", :stream 11, :chairs (23479), :timeslot 6, :papers (159 269 335 629), :track 2}, 198 {:name "Disruption management", :stream 11, :chairs (5932), :timeslot 8, :papers (657 921 239), :track 2}, 199 {:name "Disaster management", :stream 11, :chairs (333), :timeslot 9, :papers (422 128 411 585), :track 2}, 200 {:name "Logistics", :stream 11, :chairs (15154), :timeslot 13, :papers (81 473 931), :track 2}, 201 {:name "Freight transportation", :stream 11, :chairs (23511), :timeslot 11, :papers (222 278 319 982), :track 2}, 202 {:name "Traffic management", :stream 11, :chairs (10347), :timeslot 2, :papers (728 754 897), :track 3}, 205 {:name "Operational problems in logistics", :stream 11, :chairs (26507), :timeslot 4, :papers (419 672 313), :track 3}, 206 {:name "Airline logistics", :stream 11, :chairs (18528), :timeslot 6, :papers (490 639 647 810), :track 3}, 207 {:name "Railway problems", :stream 11, :chairs (19332), :timeslot 5, :papers (374 606 674 1032), :track 3}, 209 {:name "Transportation", :stream 11, :chairs (11448), :timeslot 8, :papers (176 509 794), :track 3}, 210 {:name "Network management", :stream 11, :chairs (7309), :timeslot 9, :papers (402 466 782 993), :track 3}, 211 {:name "Integrated logistic problems", :stream 11, :chairs (26641), :timeslot 11, :papers (388 452 862 362), :track 3}, 212 {:name "Traffic problems", :stream 11, :chairs (26629), :timeslot 13, :papers (207 552 912), :track 3}, 213 {:name "Production Planning", :stream 12, :chairs (19474), :timeslot 13, :papers (637 495 568 1059), :track 6}, 214 {:name "Location Problems", :stream 12, :chairs (12666), :timeslot 11, :papers (376 474 908 722), :track 6}, 216 {:name "Network Routing", :stream 12, :chairs (22941), :timeslot 2, :papers (230 628 694), :track 7}, 217 {:name "Path Planning", :stream 12, :chairs (12666), :timeslot 4, :papers (386 556 581), :track 7}, 218 {:name "Network Design", :stream 12, :chairs (26431), :timeslot 5, :papers (643 698 709 1018), :track 7}, 219 {:name "Network Flows and Applications", :stream 12, :chairs (26431), :timeslot 6, :papers (363 724 914 1039), :track 7}, 220 {:name "Mixed Integer Programming", :stream 12, :chairs (19462), :timeslot 8, :papers (252 277 496 898), :track 7}, 221 {:name "Heuristics in Discrete Optimization", :stream 12, :chairs (19462), :timeslot 9, :papers (407 528 876 398), :track 7}, 222 {:name "Graph Theory and Applications", :stream 12, :chairs (14777), :timeslot 11, :papers (502 684 441), :track 7}, 225 {:name "Network Models", :stream 12, :chairs (12666), :timeslot 13, :papers (683 856 972), :track 7}, 226 {:name "Business Intelligence and Environmental Management", :stream 24, :chairs (4796), :timeslot 9, :papers (1047 1048 306), :track 6}, 227 {:name "Dynamic vehicle routing I", :stream 11, :chairs (12952), :timeslot 5, :papers (544 602 613 770), :track 2}, 228 {:name "Financial Applications 1", :stream 3, :chairs (19559), :timeslot 5, :papers (586 663 670 680), :track 9}, 229 {:name "Applications 1", :stream 3, :chairs (26270), :timeslot 8, :papers (229 650 890 157), :track 9}, 230 {:name "Financial Applications 2", :stream 3, :chairs (9182), :timeslot 6, :papers (777 781 861 183), :track 9}, 231 {:name "Applications 2", :stream 3, :chairs (2476 3524), :timeslot 9, :papers (395 766 834 887), :track 9}, 234 {:name "Preference elecitation in MCDM", :stream 21, :chairs (), :timeslot 8, :papers (317 482 705 747), :track 13}, 240 {:name "Opening Session - Roland Bulirsch", :stream 29, :chairs (4796), :timeslot 1, :papers nil, :track 1}, 241 {:name "Plenary Session: Dirk Taubner - Thomas Reiter", :stream 29, :chairs (22108), :timeslot 10, :papers (1054), :track 1}, 245 {:name "Innovative Scheduling Approaches", :stream 17, :chairs (829), :timeslot 9, :papers (799 989 403), :track 19}, 257 {:name "GOR Diplom Thesis Awards", :stream 31, :chairs (), :timeslot 9, :papers (1060 1061 1062), :track 4}, 258 {:name "AIMMS Tutorial", :stream 30, :chairs (10929), :timeslot 6, :papers nil, :track 13}, 259 {:name "Abdolkarim Sadrieh", :stream 4, :chairs (22306), :timeslot 3, :papers (1063), :track 14}, 260 {:name "Carlo Vercellis", :stream 3, :chairs (2476), :timeslot 3, :papers (1065), :track 9}, 261 {:name "Winfried Matthes", :stream 6, :chairs (13364), :timeslot 3, :papers (1067), :track 8}, 262 {:name "Benninga Simon / Menachem Abudy", :stream 7, :chairs (22180), :timeslot 3, :papers (1068), :track 1}, 263 {:name "Fourer Robert", :stream 10, :chairs (7569), :timeslot 3, :papers (1069), :track 18}, 264 {:name "Marielle Christiansen", :stream 11, :chairs (1182), :timeslot 7, :papers (1070), :track 1}, 265 {:name "Wolfgang Achtziger", :stream 14, :chairs (2795), :timeslot 7, :papers (1071), :track 11}, 266 {:name "Semi-Plenary Session:  Ahti Salo", :stream 16, :chairs (3524), :timeslot 7, :papers (1079), :track 12}, 267 {:name "Erwin Hans", :stream 20, :chairs (1256), :timeslot 7, :papers (1073), :track 8}, 268 {:name "Michael Pidd", :stream 22, :chairs (2650), :timeslot 7, :papers (1074), :track 21}, 269 {:name "Boudewijn Haverkort", :stream 9, :chairs (22108), :timeslot 12, :papers (1075), :track 15}, 270 {:name "Georg Pflug", :stream 13, :chairs (9512), :timeslot 12, :papers (1076), :track 10}, 271 {:name "Wolfgang Bein", :stream 24, :chairs (4796), :timeslot 12, :papers (1077), :track 6}, 272 {:name "Ulrike Leopold-Wildburger", :stream 4, :chairs (22306), :timeslot 12, :papers (992), :track 14}, 273 {:name "Semi-Plenary Session:  Manfred Mayer", :stream 26, :chairs (281), :timeslot 12, :papers (1080), :track 5}, 274 {:name "GOR Dissertation Awards", :stream 31, :chairs (13837), :timeslot 8, :papers (1083 1084 1085 1086), :track 4}, 276 {:name "Software Demonstration I", :stream 30, :chairs (3843), :timeslot 2, :papers nil, :track 15}, 277 {:name "Software Demonstration II", :stream 30, :chairs (), :timeslot 2, :papers nil, :track 16}, 278 {:name "Company Award", :stream 31, :chairs (10057), :timeslot 12, :papers nil, :track 4}}, :rooms {1 {:room "0145"}, 2 {:room "0101"}, 3 {:room "1101"}, 4 {:room "0131"}, 5 {:room "1131"}, 6 {:room "0231"}, 7 {:room "1231"}, 8 {:room "0301"}, 9 {:room "1301"}, 10 {:room "0331"}, 11 {:room "1331"}, 12 {:room "2331"}, 13 {:room "3331"}, 14 {:room "3101"}, 15 {:room "3131"}, 16 {:room "1201"}, 17 {:room "3201"}, 18 {:room "2211"}, 19 {:room "2216"}, 20 {:room "2111"}, 21 {:room "2116"}, 22 {:room "0201"}, 23 {:room "Room 23"}}, :keywords {}, :papers {57 {:keyword1 "Cutting and packing", :keyword3 "Phi-function ", :abstract "We study the cutting and packing problem in two dimensions. The cutting and packing problem is a part of computational geometry that has rich applications in garment industry, sheet metal cutting, furniture making, shoe manufacturing, etc. The common task in these areas is to place a certain set of figures of specified shapes and sizes within a given area (such as a sheet of metal, a strip of textile, etc.). To minimize waste, or minimize the space used, or maximize the number of objects, one wants to pack the latter as tightly as possible. The problem is NP-complete, and as a result nearly all practical algorithms utilize heuristics, are restricted to objects of certain simple shapes, and impose various limitations on their layout. In two dimensions, most methods work with polygons only, other shapes are simply approximated by polygons. Objects usually have a fixed orientation. Our approach is based on the notion of phi-objects and phi-functions. The phi-objects can be freely translated and rotated. The construction of convenient and easy-to-use phi-functions is important for fast performance of cutting and packing algorithms. Here we prove that whenever phi-objects are formed by linear segments and circular arcs (and this class includes all typical applications), then the phi-functions can be constructed via quite simple polynomial formulas without radicals. We also present an algorithmic procedure for constructing such phi-functions. A mathematical model of 2D-packing problem is constructed as nonlinear constrained optimisation problem. A general solution strategy using the phi-functions is outlined. A number of computational results are given.", :title "Mathematical and computer modeling of optimisation packing problem of arbitrary shaped 2D-objects", :keyword2 "Optimization", :authors (11875 8142 18428), :session 100}, 61 {:keyword1 "job scheduling ", :keyword3 "complexity", :abstract "The paper describes a case study of job scheduling in a mechanical-engineering production plant with a goal to minimise the overall processing time, or makespan. The production jobs are processed by machines, and each job is assigned to a certain machine for technological reasons. Before processing a job, the machine has to be adjusted; there is only one adjuster, who adjusts all of the machines. This problem is treated as a hybrid two-stage flow-shop: the first stage of the job processing is represented by the machine adjustment for the respective job, and the second stage by the processing of the job itself on the adjusted machine. A mathematical model is proposed, a heuristic method is formulated. Partition problem and 3-partition problem are reduced onto hybrid flow shop with adjustment so this is a proof that the flow shop with adjustment is NP hard in strong sense.", :title "Hybrid flow shop with adjustment", :keyword2 "integer programming", :authors (23717), :session 145}, 73 {:keyword1 "Discrete Event Simulation", :keyword3 "Disaster Planning for Ambulance Services", :abstract "Due to an increasing number of mass casualty incidents, their high complexity and uniqueness, decision makers need Operations Research-based policy models for training emergency staff on planning and scheduling at the emergency site. We develop a discrete event simulation policy model which is applied by the Austrian Samaritan Organization. By calculating realistic small, simple, urban to rather big, complex, remote mass casualty emergency scenarios, our policy model helps enhance the quality of planning and outcome. Furthermore, the organization of an advanced medical post can be improved in order to decrease fatalities as well as quickly treat and transport injured individuals to hospitals. Pre-triage saves lives but prolongs clearing the incident site. We illustrate our model with a realistic mass casualty incident scenario for a technical disaster at a brewery in a small town during late morning on a working day and discuss optimal scheduling strategies.", :title "A DES-based decision support system for disaster planning of ambulance services", :keyword2 "Decision Support System", :authors (770 24823 2713), :session 65}, 76 {:keyword1 "Health Care", :keyword3 "emergency department", :abstract "Iranian hospitals are facing a range of problems including lack of resources, shortage of qualified staff, high rates of service demands, and a low degree of satisfaction of customers. Emergency departments (EDs) are responsible for a fast and immediate primary medical care. Because of a high rate of accident and emergency, Iranian hospitals EDs often operate at full capacity. Therefore, the performance of ED could be seen as a good indicator of the hospital. Emergency department crowding is one of the most important problems facing the Iranian hospital today. Patients have to wait long time to receive critical treatments. \r\nWe have considered the ED as a queuing system. This paper proposes a modeling approach to evaluate the performance of ED under different working arrangements. In order to model and analyze the emergency department of Bushehr Salman Farsi General Hospital (BSFGH) we have used Queuing Petri nets (QPNs). It has been shown that QPN is a suitable tool to deal with queuing systems. \r\nIn order to make the model more realistic, patients are classified based on their medical conditions. The department physicians and nurses are considered as different class of resources. Different treatments follow different procedures. Therefore, a range of treatment processes have been captured in the model. According to the system behavior, the ED faces with different workload during a normal working day. To capture the real sense of the system, this paper provides a workload model as an input to the Petri net model. A wide range of performance measures have been calculated. The paper is concluded with a set of suggestions helping the BSFGH to improve the satisfaction of its customers.", :title "Analyzing Emergency Department Using Queuing Petri nets", :keyword2 "Queuing Petri nets ", :authors (205 24892), :session 137}, 81 {:keyword1 "Vehicle Routing", :keyword3 "Transshipments", :abstract "The talk gives an overview of applications and models for vehicle routing problems with multiple synchronization constraints.\r\n\r\nIn addition to the usual customer covering constraints, many practical vehicle routing applications require temporal, spatial, and load synchronization between vehicles. Such multiple synchronization constraints are relevant, for example, when different types of resource, such as lorries, trailers, and swap bodies, are needed to fulfil the given transport requests. Moreover, synchronization is relevant when splitting of requests is possible and when transshipments between vehicles are allowed.\r\n\r\nDespite its practical relevance and the scientific challenge it constitutes, this class of vehicle routing problem has received little attention in the scientific literature and lacks a unified and systematic treatment.\r\n\r\nIn particular, a generic algorithmic approach to the simultaneous consideration of multiple synchronization constraints is needed. From a practical point of view, the development of such an approach would mean a significant progress for many important fields of modern logistics.\r\n\r\nIn the talk, the vehicle routing problem with trailers and transshipments (VRPTT) is proposed as a unified model for vehicle routing problems with multiple synchronization constraints. It is shown how existing real-world applications and models from the literature can be represented as VRPTTs. Potential algorithmic approaches and their difficulties are also discussed.\r\n", :title "The Vehicle Routing Problem with Trailers and Transshipments—A Unified Model for Vehicle Routing Problems with Multiple Synchronization Constraints", :keyword2 "Synchronization", :authors (14973), :session 200}, 96 {:keyword1 "adjoint model", :keyword3 "pollution estimates", :abstract "Mathematical methods based on the adjoint model approach are given for the air-pollution\r\nestimation and control in an urban region. A simple 2D (vertically integrated) advection–diffusion-reaction model with industrial (point) and automobile (linearly distributed)sources and its adjoint model are used to illustrate the application of the methods. Of course, the methods can be applied to any 3D pollution transport model. Dual pollution concentration estimates in ecologically important zones are derived and used to develop two non-optimal strategies and one optimal strategy for controlling the emission rates of enterprises. A linear convex combination of these strategies represents a new sufficient strategy. A method for detecting the enterprises, which violate the emission rates prescribed by a control, is given. A method for determining an optimal position for a new enterprise in the region is also described.\r\n ", :title "AIR QUALITY ASSESSMENT AND CONTROL OF EMISSION RATES", :keyword2 "control and identification of emission rates", :authors (22850 25975), :session 133}, 99 {:keyword1 "cooperative game ", :keyword3 "nucleolus", :abstract "In some practical insurance situations the insurable risks are too heavy to be insured by only one company, for example environmental pollution risk. In such cases several insurance companies cooperate to share the liability and the premium. Then two important practical questions arise: which premium the insurance companies have to charge and how should the companies split the risk and the premium? In Fragnelli and Marina (2004) the problem is approached from the game theoretic point of view and a cooperative game reflecting this situation, the so-called co-insurance game, is introduced. In the paper we study the nonemptiness and the structure of the core and the nucleolus of a co-insurance game with respect to the variable premium value. If the premium is large enough, the core is empty. If the premium meets a critical upper bound, the nonemptiness of the core, being a single allocation composed of player's marginal contributions, turns out to be equivalent to the so-called 1-convexity property of the co-insurance game. Moreover, if nonemptiness applies, the co-insurance game inherits the 1-convexity property while lowering the premium till a critical lower bound induced by the individual evaluations of the given risk. It is important that the 1-convexity of a co-insurance game yields the linearity of the nucleolus which in this case appears to be a linear function of the premium. If 1-convexity does not apply, then for the premium below another critical number we show that a co-insurance game belongs to the class of veto-removed games and construct an efficient final algorithm for computing the nucleolus of a veto-removed game. \r\n", :title "A Game Theoretic Approach to Co-Insurance Situations", :keyword2 "insurance", :authors (10620 12659 11783 18846), :session 193}, 106 {:keyword1 "Local Administration", :keyword3 "Decision Support Systems ", :abstract "Bayesian Belief Networks (BBN) is graphical models that provide a compact and simple representation of probabilistic data. They depict the relationships among several variables and include conditional probability distributions that make probabilistic statements about those variables are interrelated.  This paper demonstrates how to create a decision support model, based on data from client-server interface in a local administration organization.  The paper also displays the results and describes how it can be applied to “what-if” analyses. In essence, it integrates various techniques originated from the fields of artificial intelligence and statistics into a computer-based decision making model.", :title "Bayesian Belief Networks Graphical Model of Decision Support for Local Administration         ", :keyword2 "Bayesian Belief Networks ", :authors (26382), :session 135}, 108 {:keyword1 "Internet shopping", :keyword3 "computational complexity", :abstract "Report by The Future Foundation states that 32% of EU customers make purchases in Internet stores. By 2013, almost half of Europeans are expected to make a purchase online, up from 21% in 2006. On-line shopping is one of key business activities offered over the Internet. However a high number of Internet shops makes it difficult for a customer to review manually all the available offers and select optimal outlets for shopping, especially if a customer wants to buy more than one product. A partial solution of this problem has been supported by software agents so-called price comparison sites. Unfortunately price comparison works only on a single product and if the customer's basket is composed of several products complete shopping list optimization needs to be done manually. \r\nOur present work is to define the problem (multiple-item shopping list over several shopping locations) in a formal way. The objective is to have all the shopping done at the minimum total expense. One should notice that dividing the original shopping list into several sublists whose items will be delivered by different providers increases delivery costs. \r\nIn the following sections a formal definition of the problem is given. Moreover a prove that problem is NP-hard in the strong sense was provided and that it is also proven taht it is not approximable in polynomial time. In the following section we demonstrate that shopping multiple items problem is polynomially solvable if the number of products to buy, n, or the number of shops, m, is a given constant. We also described an heuristic algorithm we propose and try to find some connections to known and defined problems. The paper concludes with a summary of the results and suggestions for future research.", :title "E-commerce evaluation. Multi-item Internet shopping. Optimization and heuristic algorithms.", :keyword2 "optimization", :authors (26119 5390), :session 93}, 117 {:keyword1 "Supplier Selection", :keyword3 "Analytical Hierarchy Process (AHP)", :abstract "\r\nSupplier evaluation and selection, which is the first step of purchasing is one of the most important decisions plays a major role in the success of the company.Supplier evaluation and selection is a multi-criteria problem which has to consider a lot of different factors. To solve this problem it is followed orderly the steps of setting the goal, defining the required criteria and alternative suppliers, selecting the appropriate supplier by interpreting and classifying the outputs of the solution model which is chosen according to the goal.In this paper, a supplier selection problem of a multinational company which aims to select the best supplier and to minimize the deviation from goals is investigated. The aim of the implementation part is to recommend to the company an alternative solution approach for the supplier selection problem.Because of the two gradual structure of the problem, the alternative approach is carried out in two phases with two different solution methods. In the first selection phase Data Envelopment Analysis (DEA), which defines the efficiency (performance) of the suppliers is applied via the software of EMS. In the final selection phase Analytical Hierarchy Process (AHP) is applied via a web based application. The criteria are weighted also by AHP for the final selection.The alternative solution is compared with the solution of the company. The advantages and disadvantages of the both solutions are investigated.\r\n", :title "SUPPLIER SELECTION STRATEGIES AND AN APPLICATION ", :keyword2 "Data Envelopment Analysis (DEA)", :authors (26156 26166), :session 128}, 125 {:keyword1 "Evolution", :keyword3 "risk-research", :abstract "The presentation will summarized the outcomes of an inter- and transdisciplinary program at the University of Ljubljana on the study and the modling of rare events or, alternatively, of RISC-processes (Rare Incidents, Strong Consequences)(See also K.H. Müller et al. (2010)(eds.), Modern RISC-Socities. Vienna:edition echoram). RISC-processes exhibit characteristic power-law distributions and can be found in natural domains (earthquakes, forest fires, eco-systems, etc.) and societal areas (innovations, income distributions, rank-size distribution of cities, etc.) The presentation will give an overview of RISC-processes and their changing relations and roles in the evolution of societies, past and present. The presentation will make three central claims. First, RISC-processes can be considered as the missing link for an evolutionary theory of contemporary societies. Second, RISC-processes, in conjunction with additional building blocks within the wider evolutionary framework, become necessary and sufficient for a new and comprehensive theory of societal evolution. In this presnetation, a short outline of this new theoretical perspective on societal evolution will be provided. Third, the current stage of societal RISC-development makes it imperative to reconsider the problem of sustainability. It will be argued that in the light of the preceding RISC-discussion one of the principal dimensions of sustainability must be related to RISC-processes and to the emergence of robust ensembles, resilient linkage structures and flexible support networks which, despite the impossibility to control RISC-processes locally or globally, are able to withstand most of the disastrous impacts of these rare events in the long run.", :title "The Evolkution of Comntemporary RISC-Societies", :keyword2 "Complex Modeling", :authors (26172), :session 167}, 127 {:keyword1 "optimal management", :keyword3 "PC equipment", :abstract "A recycling the used equipment of personal computers (PC) in region today is increasingly difficult. The used equipment of PC in region contains hazardous materials which can have potentially harmful effects. In this context, recovery, repair and old tiles and parts, as secondary resources, recycling into used PC equipment in region turns out to be the most practical way to reduce the dizequilibrated balance between input and output and thus to reach sustainability.\r\n\r\nA recycling as secondary resources of used and spoilt PC equipment in region is a traditional management forward flow with management channels reversed. In optimal management for recycling of PC used equipment in region are needed to replace only tiles, materials and space parts which are not remanufactured by the PC equipment and the end-users are the source of input tiles, materials and spare parts as well as customers of the PC equipment in region. \r\n\r\nThese old tiles and parts recycling aspects of PC equipment are concerned with optimal management of the flow materials, spare parts and tiles (know as cores) from the consumers, transformation of these cores into PC which satisfy the original quality and other standards, including informational safety and ecological factor specifications, and managing the flow of restoration, upgraded and remanufactured PC to service centers and the final customers in region.\r\n\r\nThe complex and effective decision of the given problem is probably by means of optimal management with dynamic mathematic models and method for old tiles and parts’ recycling of PC equipment in region and it is this problem flows that we seek to address in this paper.", :title "A dynamic mathematical model and method of optimal management of recycling the used equipment of personal computers in region", :keyword2 "mathematical model", :authors (26178 26176), :session 155}, 128 {:keyword1 "Disaster and Crisis Management", :keyword3 "Large Scale Optimization", :abstract "The basic ideas of the Cell-Transmission-Model (CTM) by Daganzo (1994) were picked up recently to formulate optimization models for evacuation planning, namely the CTEPM and ExCTEPM. These optimization models were able to generate high quality evacuation plans, but computational effort and requirements, especially in terms of real world applications were very high. In order to extend adaptability to much larger evacuation scenarios, a fast heuristic procedure for solving the ExCTEPM will be presented. In a computational study we will demonstrate the effectiveness of our approach.", :title "A Fast Heuristic Approach for Large Scale Cell-Transmission-Based Evacuation Planning", :keyword2 "Transportation and Logistics", :authors (19532 14715), :session 199}, 133 {:keyword1 "Simulation Models", :keyword3 "Cancer", :abstract "Die gesundheitsschädigende Wirkung des Rauchens ist bereits sehr gut erforscht. Typischerweise werden die Auswirkungen des Tabakrauches zunächst für jede Krankheit isoliert untersucht. Gesundheitsökonomische Daten zu medizinischen Behandlungskosten, krankheitsbedingten Ausfallzeiten etc. sind für Deutschland ebenfalls vorhanden.\r\nDas Kernziel unserer Studie ist die ökonomische Bewertung der Konsequenzen von Rauchentwöhnungsprogrammen und Präventionsprogrammen bei Jugendlichen. Dazu ist eine integrierte Berücksichtigung aller Hauptkrankheiten, Beachtung dynamischer Effekte (insbes. Gesundheitseffekte, da Krankheiten sich über Jahre hinziehen können), erfolgreiche und gescheiterte Versuche, sich das Rauchen abzugewöhnen und die Berücksichtigung des Passivrauchens notwendig.\r\nUnser System stellt ein erweitertes Markovmodell dar, bei dem der Lebenslauf einer Person bzw. Gruppe simuliert wird. Übergänge zwischen den Zuständen erfolgen stochastisch und können durch Policy-Maßnahmen (z. B. Rauchverbote am Arbeitsplatz) beeinflusst werden. Der gesundheitsökonomische Effekt von Maßnahmen wird unter Umständen erst Jahrzehnte später sichtbar, was in der Analyse berücksichtigt werden muss. In das Modell werden die Ergebnisse einer Vielzahl medizinischer Studien integriert, hinzukommen Informationen aus Raucherbefragungen sowie offiziellen Statistiken.\r\nSimulationsergebnisse zu Lungenkrebserkrankungen bei Rauchern, Nicht- und Exrauchern liegen bereits vor. Darauf aufbauend wurden Berechnungen zu den direkten und indirekten Krankheitskosten durchgeführt. Das Modell kann mit geringen Änderungen um neue Krankheitsbilder erweitert und angepasst werden. Dabei werden sowohl die Inzidenz als auch der Verlauf von Krankheiten im Modell berücksichtigt.\r\n\r\n\r\n", :title "Die ökonomischen Konsequenzen des Rauchens – ein Simulationsmodell", :keyword2 "Smoking", :authors (15857 12718), :session 139}, 134 {:keyword1 "cooperative game", :keyword3 "Shapley value", :abstract "We propose a modification of the Shapley value for monotonic games with a coalition structure. The resulting coalitional value is a twofold extension of the Shapley value since: (1) the amount obtained by any union coincides with the Shapley value of the union in the quotient game; and (2) the players of the union share this amount proportionally to their Shapley value in the original game. We provide axiomatic characterizations of this value that are close to those existing in the literature for the Owen value and include applications to coalition formation in bankruptcy and voting problems.", :title "A value for games with a coalition structure", :keyword2 "coalition structure", :authors (22964 58410), :session 188}, 135 {:keyword1 "copulas", :keyword3 "crisis", :abstract "The knowledge of the multivariate stochastic dependence between the returns of asset classes is of importance for many finance applications, such as, e.g., asset allocation or risk manage-ment. By means of goodness-of-fit tests, it is analyzed for a multitude of portfolios consisting of different asset classes whether the stochastic dependence between the portfolios’ constitu-ents can be adequately described by multivariate versions of some standard parametric copula functions. Furthermore, it is tested whether the stochastic dependence between the returns of different asset classes has changed during the recent financial crisis. The main findings are: First, whether a specific copula assumption can be rejected or not, crucially depends on the asset class and the time period considered. Second, different goodness-of-fit tests for copulas can yield very different results and these differences can vary for different asset classes. Third, even when using various goodness-of-fit tests for copulas, it is not always possible to differentiate between various copula assumptions. Fourth, during the financial crisis, copula assumptions are more frequently rejected.", :title "Crisis and Risk Dependencies", :keyword2 "goodness-of-fit test", :authors (26871 26182), :session 98}, 143 {:keyword1 "shift scheduling", :keyword3 "", :abstract "In this talk we deal with shift scheduling of tank trucks for a small oil\r\ncompany. Given are a set of tank trucks with different characteristics and\r\na set of drivers with different skills. The objective is to assign a\r\nfeasible driver to every shift of the tank trucks such that legal and\r\nsafety restrictions are satisfied, the total working times of the drivers are\r\nwithin desired intervals, requested vacation of the drivers is respected\r\nand the trucks are assigned to the most favored drivers.\r\nWe propose a two-phase solution algorithm which is based on a mixed integer\r\nlinear programming formulation and an improvement procedure. Computational\r\nresults are reported showing that the algorithm is able to generate good\r\nschedules in a small amount of time.", :title "Shift scheduling for tank trucks", :keyword2 "mixed integer programming", :authors (14742 26188), :session 146}, 145 {:keyword1 "Policy Models", :keyword3 "", :abstract "A policy narrative is a “story”, having a beginning, middle and end, outlining a specific course of events which has gained the status of conventional wisdom within a certain community. The “Tragedy of the Commons” is an example. A policy model, instead, describes a situation which, depending on the values of its parameters, can give origins to more than one story. Thus it is much more powerful in describing the knowledge we have about a particular situation. For instance, interesting policy models have been built to analyze the development of cooperation in a world in which, supposedly, everyone competes with everyone else trying to maximize his/her own utility. Most often policy narratives and policy models are intertwined, the latter being the development of the former ones.\r\nActually, if used in an uncritical way policy narratives and models may have negative consequences on the policies whose implementation they promote or justify. Again the “Tragedy of the Commons” is an example: its application in the development area has often produced more harm than good.\r\nIn this paper we will discuss the ethical implications of the use of policy narratives and of policy models.", :title "Ethical implications of Policy Narratives and Models", :keyword2 "Ethics in OR", :authors (4837 22744), :session 28}, 148 {:keyword1 "Processor sharing", :keyword3 "Sojourn time", :abstract "We consider a system with Poisson arrivals and i.i.d. service\r\ntimes. The requests are served according to the state-dependent\r\nprocessor-sharing discipline, where each request receives\r\na service capacity which depends on the actual number of requests\r\nin the system. The linear systems of PDEs describing the residual\r\nand attained sojourn times coincide for this system, which\r\nprovides time reversibility including sojourn times for this\r\nsystem, and their minimal non negative solution gives the LST\r\nof the conditional sojourn time of a request with given required\r\nservice time.\r\n\r\nFor the case that the service time distribution is exponential\r\nin a neighborhood of zero, we obtain a linear system of ODEs,\r\nwhose minimal non negative solution gives the LST of the conditional\r\nsojourn time, and which yields linear systems of ODEs for its moments\r\nin the considered neighborhood of zero. Numerical results are\r\npresented for the variance of the conditional sojourn time.\r\nIn the case of a two-server processor-sharing system, the LST\r\nof the conditional sojourn time is given in terms of the solution\r\nof a convolution equation in the considered neighborhood of zero.\r\nFor service times bounded from below, surprisingly simple expressions\r\nfor the LST and variance of the conditional sojourn time in this\r\nneighborhood of zero are given, which yield in particular the LST\r\nand variance of the conditional sojourn time in case of a two-server\r\nprocessor-sharing system with deterministic service times.\r\n", :title "On sojourn times in M/GI systems under state-dependent processor sharing", :keyword2 "Many-server", :authors (4170 4169), :session 129}, 150 {:keyword1 "Inspections", :keyword3 "Errors first and second kind", :abstract "In many situations an inspector has a number of inspections during some reference time interval in order to detect a single violation of an agreement. This violation shall be detected at the earliest subsequent inspection. The aim of the inspector is to minimize the time between start and detection of the illegal activity.\r\n\r\nIn reliability theory variants of this game have been studied by Derman and Diamond: An operating unit may fail – which corresponds in our context to the violation – creating costs that increases with the time until the failure is detected. A minmax analysis leads to a zero sum game with the operating unit as inspectee which cannot observe any inspections.\r\n\r\nAnother application are interim inspections of precious or dangerous material, e.g., direct use nuclear material. Nuclear plants are regularly inspected at the end of a reference time interval, e.g., one year. If nuclear material is diverted one may wish to discover this not only after a year but earlier which is the purpose of interim inspections.\r\n\r\nAlthough Diamonds model is very broad, it cannot be applied to inspection problems in which errors of the first kind (false alarms) and second kind (not detection of an illegal activity) may occur.\r\nIn this contribution we generalize Diamonds model to a model with errors of the first and second kind in case of one or two unannounced interim inspections, determine a Nash equilibrium and discuss its properties. This paper is also intended to bring Diamonds brilliant idea of solving those kind of games back to awareness.\r\n", :title "A generalization of Diamond’s inspection game: errors of the first and second kind", :keyword2 "Game Theory", :authors (26194), :session 195}, 153 {:keyword1 "threat model", :keyword3 "heuristics", :abstract "We consider the dynamics of threat of an infrastructure consisting of various sectors. The configuration of the infrastructure is given by its sectors and the dependency structure of the sectors. The dynamics are modelled by a finite state and finite action continuous-time Markov decision process. The basic idea of the model is the following: if threat appears in a certain sector, dependent sectors will be affected, too. Threats are modelled by threat events, which influence state transitions and costs. To manage the current threat situation, the decision maker can choose between three actions for each sector: he or she could stay passive, evaluate video pictures, or send a guard. Each of the latter two actions requires a human resource. Then the action space depends on the number of available security staff. The objective is to minimize overall threat which is measured by expected total discounted cost of endangered facilities. If the number of security staff is limited, a resource allocation problem arises in which actions have to be assigned to appropriate sectors. Since the state space grows exponentially with the number of sectors, optimal policies are not computable for large infrastructures. Therefore, we introduce a heuristics which solves the problem approximately. The heuristics is based on an index rule, and it is easy to implement. The underlying index is derived from a specific restless bandit model. The memory requirements for storing the suboptimal policy are considerably reduced by this approach.\\footnote{The underlying projects to this talk are funded by the Bundesministerium f\\\"{u}r Bildung und Forschung of the Federal Republic of Germany under promotional references 03BAPAC1 and 03GEPAC2. The author is responsible for the content of this talk.}", :title "A Continuous-Time Markov Decision Process for Infrastructure Surveillance", :keyword2 "continuos-time Markov decision process", :authors (26167), :session 70}, 155 {:keyword1 "growth", :keyword3 "simulation", :abstract "An increasing number of contributions show the existence of a stationary level of subjective wellbeing in developed country despite the ongoing economic growth. Moreover, the twofold constraint, on the natural resources use and extraction and on the capacity of the environment to absorb waste, makes unsustainable the actual path of growth. The question investigated in this paper is whether the economic system through appropriated policies may improve some indexes of performance without the need of relaying on economic growth.\r\nTo this aim, we present a dynamic simulation model based on a Keynesian macroeconomic framework, which explores no and low growth scenarios for Italy over a period of twenty years. First, we build a business as usual scenario showing the result in terms of rate of growth, unemployment, poverty, government debt and greenhouse gas emission. Secondly, we consider the impact of different macroeconomic policies on these outcomes. Our results are compared with a similar simulation for Canada by Victor and Rosenbluth [Victor, P. and G. Rosenbluth (2007). Managing without growth, Ecological Economics, 61, pp. 492-504.]. \r\nIn the last part of the paper we also explore a different scenario including the effect of a consistent substitution of renewable energy for fossil fuels imports. This inclusion fosters the reduction of GDP growth, but substantially improves the indicators of unemployment and GHG emissions. \r\n", :title "Managing without Growth: Italian Scenarios", :keyword2 "energy", :authors (26199 4837), :session 134}, 157 {:keyword1 "forecast combination", :keyword3 "OR in sports", :abstract "Approaches for pooling predictions individually generated by formal statistical models or domain experts have a long tradition in the OR and forecasting literature. It is widely accepted that combined forecasts are more accurate than those of individual models/experts, and this effect is commonly explained in the framework of the bias-variance decomposition. Roughly speaking, a prerequisite for forecast combination being effective is that the base models whose predictions are eventually pooled show some diversity, i.e., complement each other. We explore the appropriateness of forecast combination in a setting of competitive event prediction. This environment differs notably from ordinary forecasting application and experiences concerning the potential of forecast combination are yet lacking. Therefore, we develop a set of hypotheses how diversity among base models may be achieved in competitive event prediction and test these empirically. To that end, a real-world dataset from a speculative financial market, the horserace betting market, is employed.", :title "Forecast combination in competitive event prediction", :keyword2 "ensemble prediction", :authors (9422 4688 926), :session 229}, 159 {:keyword1 "GIS", :keyword3 "Decision Support Systems", :abstract "It is seen that current organizations try to make use of Geographical Information System (GIS) based decision support systems at many stages of strategic decision-making. Geographical information systems that are known as collection, arrangement, inquiry and analysis of spatial data in computer-aided systems are known as the systems producing solutions in almost every field today. \r\n\r\nThe most important strategic decision in the establishment phase of an enterprise is the selection of its location. Company location selection problem is defined as combinatorial optimization problem in operational research. Different approaches can be created in the solution of the problem with the possibilities provided by Geographical Information Systems.\r\n\r\nThe objective of this study was to perform the suitable location selection for shopping centres in Istanbul and its surroundings, which is the city where the largest and biggest numbers of shopping centres are located. In the study, evaluation of data concerning the suitable location selection was performed in Geographical Information System ArcInfo-GIS environment.\r\n", :title "Suitable Location Selection Optimization for Shopping Centres and Geographical Information System ", :keyword2 "Spatial Analysis", :authors (23959), :session 197}, 162 {:keyword1 "Knapsack", :keyword3 "Evolutionary Algorithm", :abstract "In general, mathematical programming problems optimize an objective function subject to constraints, but they have often to be reengineered to represent new background knowledge. For instance, one can think of projects that have to be assigned to a limited resource. Each project has a specific type, profit and resource consumption. Furthermore, there are sub-types and super-types of projects. The overall profit increases not only through each completed project, but also for combinations of projects due to synergistic effects. In this typical Knapsack problem, the combinations of projects that achieve synergistic effects can be defined on (1) specific instances of projects, but there can be also more (2) general rules that state that certain types of projects lead to synergistic effects. While the general problem remains the same, the background theory is different. Our approach separates background information as well as rules that describe the world of the problem from the mathematical problem to master complexity. The background information is encoded via a Semantic Web Description Logic. A Description Logic defines concepts, roles and object instances for relational data, which enables one to reason about complex objects and their relations. The mathematical program utilizes conjunctive queries on the knowledge base to calculate the objective function and constraints. The approach therefore combines the capabilities of distributed storage of Semantic Web based (meta-) information as well as efficient reasoning capabilities of Description Logics with the general framework of mathematical programming problems. We define a Knapsack problem to outline our methodology. Furthermore, we present a Genetic Algorithm to outline a heuristic approach to solve this problem.", :title "A Genetic Algorithm for Optimization of a Relational Knapsack Problem with respect to a Description Logic Knowledge Base", :keyword2 "Description Logic", :authors (25005 15857), :session 124}, 166 {:keyword1 "open shop", :keyword3 "scheduling", :abstract "We consider the routing open shop problem being a generalization of the open shop and the metric traveling salesman problems.\r\nThe jobs are located at nodes of some transportation network, and the machines travel on the network to execute the jobs in the open shop environment. The machines are initially located at the same node (depot) and must return to the depot after completing all the jobs. It is required to find a non-preemptive schedule that minimizes the makespan. The problem is NP-hard even on a two-node network with two machines. We determine some properties of optimal schedules and present a first PTAS for the case with two nodes and two machines. Next, we generalize our result for the case with a fixed number of nodes and a fixed number of machines.\r\n", :title "A PTAS for the routing open shop problem with two nodes and two machines", :keyword2 "routing", :authors (1834), :session 148}, 168 {:keyword1 "simulation optimization", :keyword3 "common random numbers", :abstract "A frequent problem in simulation optimization is the identification of the best of a given set of candidates. As best we define the candidate with the lowest expected costs. Usually the expected costs of a candidate must be estimated using statistical sampling. In this talk we assume, that the costs of the candidates are normally-distributed with unknown means and variances. The objective is to identify the best candidate of a given set with a desired probability of correctness using as few samples as possible. \r\n\r\nSequential Bayesian ranking and selection procedures are among the most efficient solution techniques for this problem. Such procedures successively increase the sample sizes of the candidates, until the desired propability of a correct selection is reached, which is estimated using methods from Bayesian statistics. It is reasonable to allocate the additional simulations for the candidates individually depending on the costs observed in the previous iterations. For candidates, which are almost certainly not the best, little or no additional simulations should be performed. \r\n\r\nMost Bayesian selection procedures proposed in literature require independent samples for the candidates. If the costs of the candidates are positive correlated, the use of common random numbers can dramatically reduce the total number of simulations compared with independent sampling. In this talk we present a new sequential Bayesian ranking and selection procedure, which allows variance reduction by common random numbers. ", :title "A new sequential Bayesian ranking and selection procedure supporting common random numbers", :keyword2 "ranking and selection", :authors (17284), :session 168}, 176 {:keyword1 "Auctions", :keyword3 "", :abstract "We consider a scenario in which some companies have a demand for logistic services. This demand is represented by single transport orders. These orders can be fulfilled by different service providers. Now the companies make a contract with some service providers. Only these providers will be considered by the company in the future. In some cases the company might change the contract from time to time. So far it is a typical situation, but we will give an example why this behavior does not always lead to efficient situations in the sense of cost saving for the companies. To improve this, companies could consider all service providers for each transport order. In order to do so the companies need to find an allocation mechanism. Different allocation mechanisms will be discussed and an argumentation for the suitability will be given. Due to this we propose to use typical second price auctions to allocate orders to service providers. For this allocation mechanism we will shortly develop the idea of implementing it in the form of an online auction platform for logistic orders. We will have a closer look on the service providers, on their motivation to use such a platform and also on their calculations for giving a bid on a single transport order. At last we will present further ideas about the bid calculation and give an outlook to our planned activities.", :title "An auction scenario for transport orders", :keyword2 "", :authors (14661), :session 209}, 177 {:keyword1 "flow shop", :keyword3 "", :abstract "We consider a buffer-constrained flow shop problem. It can be applied to schedule media objects presentation on a portable device (a player). The player takes objects from the remote database and prefetchs them into the buffer. The size of buffer is limited. The presentation of an object cannot be started earlier than the finish of its loading. An object leaves the buffer after the completion of its presentation.  The goal is to minimize the completion time of the whole presentation.\r\nThis problem is strongly NP–hard.  We develop a variable neighborhood search algorithm (VNS) for the problem. We use well-known swap and shift neighborhoods and a new very large Kernighan–Lin neighborhood. We present a branch-and-bound algorithm based on two new lower bounds.  We use the solution of a VNS algorithm as upper bound. Computation results for random generated test instances are discussed.   \r\n", :title "Heuristic and exact methods for a two stage multimedia problem with passive prefetch", :keyword2 "Variable Neighborhood Search", :authors (26205), :session 145}, 181 {:keyword1 "Internal Pricing", :keyword3 "Auman-Shapley prices", :abstract "From parametric programming, we know that shadow prices change in intervals and are stable within each interval (Dinkelbach 1969). While some of the price changes might be only marginal, others can change cost share ratios dramatically. Especially when we have multiple intervals with several price changes, such a pricing system is often not accepted by decision makers who are used to stable and constant prices. Therefore, increasing robustness of internal pricing schemes by limiting the number of price changes on a tolerable expense of price accuracy can enhance decision making as well as acceptance of cost allocation. \r\n\r\nIn this presentation, a new methodical approach is introduced allowing to find an optimal trade-off between robustness and accurateness of internal pricing systems. In the first step, we calculate all relevant marginal cost rates and Aumann-Shapley prices for each interval and optimize robustness with a combinatorial approach in the second step. Aumann-Shapley pricing is the only scheme which satisfies addivity, dummy, no merging and splitting, scale invariance, full cost allocation and decision making requirements (Sprumont 2005; Hougaard and Tint 2009) when discrete, linear cost sharing problems are considered (Samet et al. 1984). Our approach lead to optimal solution for most practical instances and will be illustrated by a numerical example.\r\n\r\n", :title "Aumann-Shapley prices and robustness of internal pricing schemes", :keyword2 "Decision Making", :authors (1658), :session 121}, 183 {:keyword1 "Time series", :keyword3 "SVM", :abstract "Support Vector Machines (SVMs) have been extensively used in classification and regression. In this talk we will show how SVMs can be used to predict spcific aggregated values from a time series. Applications in finance will also be discussed.", :title "Support Vector Machine for Time Series Regression", :keyword2 "Neural Networks", :authors (2476), :session 230}, 186 {:keyword1 "agent based modeling", :keyword3 "innovation", :abstract "Performance information used for decision-making usually is assumed to be the more beneficial, the more precise it is – with two exceptions: Firstly, the marginal contribution to precision might be too costly and, secondly, according to contracting theory the agent might utilise private pre-decision information for the own interest at the principal's expense.\r\nHowever, in this paper we present results of an agent-based simulation which show that in complex decisional situations imprecise performance information leads to higher organisational performance than achieved with perfect information. The simulation model is based on NK fitness landscapes and, especially, the NK model is adopted to organisational settings with multi-faceted informational imperfections which typically are related to the delegation of decisions.  \r\nBased on the simulation we argue that imprecision of information under certain conditions serves as driver to innovation: With imprecise information an organisation might go to astray which would, of course, not happen with perfect information; from a short-term \"wrong way\" there is a chance to discover new superior configurations of decisions. So, imprecise information may afford the opportunity to leave a local maximum and find a superior configuration of decisions, and, thus, serve as driver for innovations. The paper identifies conditions for the occurrence of the innovative effect of imprecision. Among these are organisational features as, for example, the incentive structure and, especially, the complexity of the decision problem. The results might throw some new light on management accounting and, obviously, put demands for perfection in management accounting into perspective. \r\n", :title "Imprecise Performance Information and Innovation in Complex Decisions", :keyword2 "imperfect performance information", :authors (25320), :session 122}, 188 {:keyword1 "recurrent neural networks", :keyword3 "forecasting", :abstract "We present a recurrent neural network topology, the Shared Layer Perceptron, which allows robust forecasts of complex systems. This is achieved by several means.\r\nFirst, the forecasts are multivariate, i. e., all observables are forecasted at once. We avoid overfitting the network to a specific observable. The output at timestep t, serves as input for the forecast at timestep t+1. In this way, multi step forecasts are easily achieved.\r\nSecond, training several networks allows us to get not only a point forecast, but a distribution of future realizations. This can be used, e. g., for risk management purposes to determine the uncertainty.\r\nThird, we acknowledge that the dynamic system we want to forecast is not isolated in the world. Rather, there may be a multitude of other variables not included in our analysis which may influence the dynamics. To accommodate this, the observable states are augmented by hidden states. The hidden states allow the system to develop its own internal dynamics and harden it against external shocks. Relatedly, the hidden states allow to build up a memory.\r\nOur example includes 25 financial time series, representing a market, i. e., stock indices, interest rates, currency rates, and commodities, all from different regions of the world. We use the Shared Layer Perceptron to produce forecasts up to 20 steps into the future and present three applications: transaction decision support with market timing, value at risk, and a simple trading strategy. While the forecasts do not always beat the benchmarks we still obtain good or even very good results. And, more importantly, the results are consistent: they are satisfying over all asset classes. The benchmarks, on the other hand, work well on some assets but perform catastrophically on others.", :title "Forecasting Complex Systems with Shared Layer Perceptrons", :keyword2 "complex systems", :authors (19080 19100), :session 78}, 193 {:keyword1 "Capacity Planning", :keyword3 "Seasonality", :abstract "In this study, we consider capacity planning and scheduling in a system involving jobs with fixed ready times and deadlines. Scheduling of fixed jobs is commonly known as Fixed Job Scheduling (FJS), which is frequently observed in manufacturing and service environments. The tactical FJS problem minimizes the total cost of identical parallel machines that will process all jobs in the system whereas the operational FJS problem selects a subset of jobs for processing that will maximize the total weight for a predetermined number of machines. The capacity, i.e. the number of machines in the system is the main determinant on the maximum achievable profit. Traditionally, tactical FJS is used for capacity planning, which requires long term forecasts of job reservations and ignores cancellations or possible changes in job times. Seasonal capacity planning, which is considerably important in systems showing demand fluctuations, has not been studied. We consider the integrated decisions of capacity planning and FJS in a system involving seasonality, and try to come up with a dynamic capacity plan that will yield maximum total profit for the planning horizon. For this purpose, we combine the structural properties of tactical and operational FJS models and handle both job profits and machine costs. A polynomial-time incremental capacity planning algorithm is proposed, which will be executed for each demand season. The algorithm is based on a combination of a tactical solution for each season followed by repeated operational solutions. Hence, the incremental solutions for different capacity levels will be generated to determine the optimal capacity expansion level for each season. The study is supported by the Scientific and Technological Research Council of Turkey (TUBITAK).", :title "Integrating Seasonal Capacity Planning and Fixed Job Scheduling", :keyword2 "Fixed Job Scheduling", :authors (19095), :session 160}, 196 {:keyword1 "Data Envelopment Analysis", :keyword3 "Logistic Services", :abstract "Regarding high competitive pressure on enterprises, measures to increase productivity become more and more relevant. Logistics both constitutes a significant part of service sector in enterprises and offers several productivity potentials. For this reason the paper deals with the question how to measure and benchmark productivity of several logistic services. After a general definition of productivity ratio, a survey of the constitutive attributes of logistic services forms the basis for the following research. The productivity of logistic services will be explained by two different descriptions of service productivity, based on the approaches by Corsten (1994) and Grönroos/ Ojasalo (2004). Both approaches are transferred from general definition of service productivity to a specific one including logistic attributes. Afterwards logistic service productivity is evaluated by the method of Data Envelopment Analysis (DEA). Through the use of linear programming, DEA indicates which production alternatives should be able to improve productivity and the amount of input savings respectively output increases. This is done by comparing service units considering actual outputs achieved with the set of actual inputs used. Analysed input factors are for example utilisation of personnel, means of transport and equipment while the delivery quantity constitutes an output factor. On the one hand input-oriented models optimize the input usage while the outputs are fixed and on the other hand output-oriented models focus increasing outputs while inputs are fixed. As a result DEA allows to separate efficient production alternatives building the reference from inefficient production alternatives. Identified inefficiencies can be interpreted as productivity potentials of logistic services. ", :title "Applying DEA for benchmarking Service Productivity in Logistics", :keyword2 "Productivity ", :authors (26056 14865), :session 156}, 197 {:keyword1 "particle swarm optimisation", :keyword3 "zinc recycling ", :abstract "A zinc recycling company is confronted with a complex decision problem. The fluctuation of mass and composition of the delivered input requires a flexible process operation. In addition, the prices of their product as well as auxiliary materials vary strongly. For example, the zinc price varied between 1,000 and 4,500 \\$/t in the last five years. This leads to the short-time optimisation problem to find a good process operation mode for each of the numerous combinations of input qualities and prices.\r\nThe process offers several variables to influence important characteristics like temperatures and kinetics. Adjustable variables are amongst others throughput, use of energy carriers and process air.  These variables also affect the rates of chemical key reactions which occur in series with other reactions important for the product quality. To obtain a realistic reproduction of this complex and nonlinear behaviour a detailed process simulation is needed which in turn makes it more difficult to solve the optimisation problem. \r\nIn this contribution an approach using flowsheet simulation combined with a particle swarm optimisation algorithm is presented. The particle positions in the solution area represent sets of the technical operation parameters. The swarm algorithm evaluates the quality of a set by passing it to the flowsheet simulation. The simulation engine computes the resulting mass and quality of the product as well as needed auxiliary materials. Using this information the contribution margin of the process as objective function is calculated. In dependence on this result the particles are moved iteratively until a solution is found.\r\nThe result is a good parameter setting under the given conditions which can be used as decision support for the operator.", :title "Process optimisation of a zinc recycling plant by a particle swarm algorithm combined with flowsheet simulation", :keyword2 "flowsheet simulation", :authors (26155 2675 1219), :session 167}, 203 {:keyword1 "Assembly lines", :keyword3 "Optimal design", :abstract "Assembly line balancing has considerable importance for production of high quantity standardized products. The most known problem among the assembly line balancing problems is the simple assembly line balancing problem (SALBP). Researchers focused on heuristic approaches for the solution of SALBP because of its complexity. Simple task assignment rules such as shortest processing time, greatest number of immediate successors etc. have been widely applied to balance simple assembly lines in practice. But their performance remains poor due to lack of a global view. In this study, simple assembly line balancing problem is solved by using composite assignment rules which are discovered through genetic programming (GP). Suitable parameters affecting the balance of line are evaluated and employed for discovering highly efficient composite assignment rules by the evolution of genetic programming. As it is known, the most important feature of GP as distinct from the traditional genetic algorithm is its ability to dynamically vary the size of evolved solution strings due to its hierarchical tree structure. In this study, this structure is turned into an advantage for evolving different sized assignment rules in order to obtain a balanced assembly line. As a preliminary experiment, one of the SALBP data sets is selected to analyze the performance of the proposed GP algorithm. For this data set, some of the cycle times are grouped for training the GP and the remaining ones are used to test the performance of the evolved assignment rules. Terminal and function sets are defined for the execution of the proposed GP. Preliminary results proved the efficiency of the proposed GP in producing generic composite assignment rules for balancing assembly lines.\r\n", :title "A genetic programming based approach to generate assembly line balancing heuristics", :keyword2 "Genetic programming", :authors (19699), :session 158}, 204 {:keyword1 "water resources planning", :keyword3 "simulation", :abstract "The European Water Framework Directive (WFD) (EC, 2000), demands a more integrated and multidisciplinary approaches in the development of water plans. This consideration introduces a higher degree of complexity into the already complex task of integrated water resources management. One of the main and most difficult points in the development of the current water plans is defining the environmental flows.  \r\nThis paper presents a new methodology to evaluate the impact on the water resources system of environmental flows using simulation management models. A Water Resources Simulation model is used to analyze the possible impact of environmental flows in the reliability of the demands. \r\nA simulation model of the whole Spanish basin of the Duero River was performed and calibrated. The model is composed by hundred of elements such as reservoirs, hydroelectric power plants, agricultural and urban demands, aquifers, etc. The management is simulated with a system of priorities that it is translated into the cost of the network arcs.\r\n A range of different environmental flows was obtained from hydrologic and habitat simulation environmental studies for several points in the basin. In order to evaluate the influence of each and every one of the environmental flows in the basin, a heuristic optimization approach was developed. \r\nThis paper explains the optimization approach and its application to a real case, the Duero basin, which helped to define environmental flows taking into account the other uses in the basin.\r\n", :title "Environmental flows in water resources planning. Duero Basin (Spain) case study", :keyword2 "Environmental flows", :authors (26252 26253 26255 26254 26848), :session 40}, 206 {:keyword1 "cost-oriented hospital location", :keyword3 "product mix", :abstract "Already in 1972 Dietrich Adam stated the problem of rising costs and weak profitability in the hospital market with co-operations and decreasing length of stays as possible solutions. The introduction of the DRG System (Diagnosis Related Group) in 2003 as a fixed pricing system increased the pressure on hospitals regarding cost reduction and efficiency caused by the bad financial situation of the public sector, health insurances, and hospitals and demographic trends. The outcome is a reduction in the length of stay and a rise in co-operations and M&A. This leads to a dynamic field of research and to a higher applicability of management concepts due to more competition and efficiency oriented regulations.\r\nRecent research includes optimization models with an economic perspective to help within hospital planning done by federal states or with the focus on individual hospitals. Basic models for horizontal integration have been developed, e.g., by Harfner (1999) and Fleßa et al. (2006). Both are static and base on the multi-level contribution income statement.\r\nThe aim of this research project is to develop a management-accounting based valuation tool for the integration process in a hospital network as well as an aid for budget negotiations with health insurances. In this optimization model logical, legal, organizational, and capacity restriction will be considered as well as timely factors. Additionally, by varying some parameters one can analyze different scenarios and see different effects in management accounting. This paper will give an overview of the conditions and developments in the hospital market and of the recent research. It will end with the introduction of the already generated basic management accounting model and an outlook for the research to come.\r\n\r\n", :title "Case-Mix-Optimization in a German Hospital Network", :keyword2 "optimization model", :authors (26158), :session 121}, 207 {:keyword1 "economic cost", :keyword3 "safety management", :abstract "Road Traffic injuries constitute a major public and development crisis and are predicted to increase if road safety is not addressed adequately. The appalling human misery and the serious economic loss caused by road accidents demand the attention of the society and call for the solution of the problem. Currently being in ninth place, it is predicted that by 2030, the amount of people who are killed in road traffic accidents will rise to almost first place in the leading causes of death around the world. \r\n\r\nWith man's invention of the wheel, the death knell has continued to toll for many, who are often innocent, but who may happen to be at the wrong place at the wrong time. A continuing global commitment to address the growing problem of road traffic injuries is the need of the hour. \r\n\r\nRoad traffic injury prevention and mitigation should be given the same attention and scale of resources that is currently paid to other prominent health issues if increasing human loss and injury on the roads, with their devastating human impact and large economic cost to society are to be averted.  We would like to highlight some of the efforts that can be undertaken for this global concern; in terms of improving emergency trauma care, upgrade road and vehicle safety standards, promote road safety education and enhance road safety management in general.\r\n", :title "Trends in Road Traffic Injuries – A Global impact", :keyword2 "health issues", :authors (26257 26207 41043), :session 212}, 208 {:keyword1 "critical path", :keyword3 "efficiency", :abstract "The objective of the critical path analysis is to estimate the total project duration and to assign starting and finishing times to all activities involved in a project. This basically helps to check the actual progress against scheduled duration of the project. Based on the computation of the earliest and latest times, we calculate the float associated with each activity. The float is the one that determines the critical path of a network. Being a deterministic model in the sense that its outcome is predetermined by the values fed into it -- in this case, the completion times of critical tasks. The computation is actually a mathematical based algorithm.\r\n\r\nActually critical path computation in network model is a graph approach.  The same network model can be relooked  as other data structure and determination of the path can be done. In this paper, we make an attempt to use tree  as  a data structure tool to determine critical path without actually going into the computation of earliest and latest times. Moving from the design part, we analyze the approach through the means of programming and after analyzing, a conclusion is drawn in terms of efficiency. We find that this  approach is better alternative to find critical path in project networks.\r\n", :title "Algorithmic approach to determine Critical Path in a Project Network.", :keyword2 "duration", :authors (26224 41043), :session 147}, 210 {:keyword1 "Credit client classification", :keyword3 "Semi-supervised training", :abstract "Fictitious training data points complementing empirical training examples have been observed within several contexts to enhance out-of-sample performance of classification methods. Investigating some simple generating rules for fictitious credit client scoring data, we showed in past work that the degree to which this desirable effect is achieved varies markedly. When using Support Vector Machines (SVM) as a modelling tool, effective performance enhancement depends on the combination of kernels and generating rules for fictitious training data. In past work fictitious training data were slight variations of some selected original training examples. For instance, they were chosen to be in the close vicinity of support vectors which belong to a SVM trained on the original data, while all the class labels of the fictitious data were assumed to be equal to those of the respective generating data points. In this paper we introduce more complex transformations of original data examples which generate unlabelled fictitious training data. Hence we explore a generating mechanism for fictitious credit clients, without fixing their defaulting behavior in advance. In order to propose labels for the new examples for which no a priori assumption was placed on their class membership, we use transductive SVM, a semi-supervised classification method. We also discuss how to adapt model performance validation to the enlarged training data sets.", :title "Semi-supervised SVM for Credit Client Classification with Fictitious Training Data", :keyword2 "Fictitious training data", :authors (14887), :session 125}, 213 {:keyword1 "Recursive Game", :keyword3 "Social Equilibrium", :abstract "This contribution deals with modeling difficulties which may arise if one tries to model real conflict situations with the help of non-cooperative normalform games: It may happen that strategy combinations occur which are totally unrealistic in practice but which, however, may be realized in equilibrium with positive probability.\r\nIn our contribution the battle of sexes paradigm is considered which is the most simple game owning this unrealisitc feature. It is shown that a slight modification of the rules of this game remedies the problem: If the unrealisitc strategy combination is realized, the game is repeated as long as it happens. This way one arrives at a recursive game which can be solved with the help of standard techniques. \r\nIt turns out that the expected run length of this new game is only slightly larger than one. In other words this modification practically does not change the outcome of the game.\r\nFrom these results general conclusions are drawn for the modeling and analysis of more complicated and realistic conflict situations.", :title "A fresh look on the battle of sexes paradigm", :keyword2 "Average Run Length", :authors (26259 26194), :session 194}, 214 {:keyword1 "bioenergy village", :keyword3 "uncertainties", :abstract "Increasing CO2 emissions and the emerging scarcity of fossil raw materials bring resource efficient concepts more and more into the focus of public interest. One resource efficient concept was realized in the German ‘bio-energy village’ Jühnde by using biomass instead of conventional energy sources to meet the electricity and heat demand. Electricity and heat are produced by burning biogas in a combined heat and power generator (CHP). Liquid manure and crops, cultivated on the agricultural land around the village, are the feedstock for the generation of biogas in an anaerobic digestion plant. The electricity is fed to the national electricity grid. The idea of a nearly self-sustaining village based on biomass energy sources could be an important basis for a resource efficient energy strategy. \r\n\r\nFor estimating the economic consequences of a bio-energy village, techno-economic optimization models can be used. They provide the ‘cost optimal’ energy supply over a given planning horizon. A linear programming optimization model is used, in which the size of the biogas plant and the heat network are optimized simultaneously. To start with, the model optimizes the process for a specific village. In a second step, this model is used to extract a more generalized optimization model, which then can be customized for other regions.\r\n \r\nFurthermore, any modeling is subject to various sources of uncertainty, like “data uncertainties”, “parameter uncertainties” and “model uncertainties” (spatial variability, temporal variability and variability of sources). Therefore, different types of uncertainties related to the use of biomass are analyzed and reflected in the model. \r\n", :title "Bioenergy villages - optimization of the production and distribution system", :keyword2 "linear programming", :authors (24622 15195), :session 134}, 215 {:keyword1 "Production Planning", :keyword3 "Kalman Filter", :abstract "The PhD project is going to cope with uncertainties in the forecast of the customer demand. First of all, two different methods of production planning are briefly introduced and compared in the theoretical part: Production planning based on lot sizing with the well-known economic order quantity (EOQ) model and a heijunka-levelled kanban system. Additionally, a case study based on real-world data is considered. In the second part of the PhD project the Kalman filter as the most well known sequential data assimilation scheme is introduced. Generally speaking, data assimilation is about combining model predictions and real world data to better estimate the state of a system. In the third part of the PhD project the Kalman filter is going to be implemented in the methods of production planning mentioned above. Concerning the described planning systems the Kalman filter is going to be programmed in MATLAB to estimate the most probable value of the unknown customer demand. Finally, a sensitivity analysis should release some information about the performance of the Kalman filter compared to the production planning without the filter. The conclusion of the PhD project will be a recommendation whether the new approaches are good or if there are some situations or products where it is better to use one of the described methods.", :title "Data Assimilation in Production Planning", :keyword2 "Data Assimilation", :authors (26264), :session 178}, 216 {:keyword1 "Entry Strategies", :keyword3 "Switching Costs", :abstract "Consider a homogeneous good market with switching costs initially served by a monopolistic incumbent. How can a competitor successfully enter this market? We model a three-stage game with a monopolistic incumbent, the potential entrant and consumers that initially buy from the incumbent. In this situation the incumbent might apply a limit pricing strategy. We discuss strategies that may overcome this entry barrier.\r\nWe analyze three entry strategies: The first option is to undercut the incumbent's price by a fixed margin that would be maintained if the incumbent changes its price in the second stage. The second option is to supplement the margin by a price ceiling that is determined by the initial monopoly price minus the undercutting margin. This implies that the entrant will follow a price decrease by the incumbent but will not increase its price if the incumbent chooses a price above the initial price level. The final option is entering the market as a normal competitor that is playing a simultaneous move price setting game with the incumbent.\r\nWe find that fixed margin price undercutting facilitates entry. The advantage particularly pronounced if a large fraction of consumers considers switching and/or switching costs are substantial. Furthermore, fixed margin price undercutting yields higher profits for the entrant even if traditional entry is successful. Adding a price ceiling further improves the performance of fixed margin price undercutting in settings with elastic demand. Without a price ceiling the entrant chooses an excessive margin to avoid that the incumbent has an incentive to increase its price to prevent switching. This is no longer necessary with a price ceiling, because the margin would be automatically expanded if the incumbent increases its price.", :title "Smart Entry Strategies for Markets with Switching Costs", :keyword2 "Price Competition", :authors (26261 22306), :session 195}, 217 {:keyword1 "production networks", :keyword3 "automotive", :abstract "Today’s automotive markets are characterized by an increasing number of market segments and strong competition for niches. Original equipment manufacturers (OEM) offer an increasingly diverse model portfolio, resulting in an explosion of the number of different models offered. Due to this product proliferation, demand volatility for specific car models is high, resulting in short and medium term demand shifts between market segments, which can hardly be anticipated. As a consequence, flexibility in the production networks is required, to match the production capacity for specific models with market demand. Technical advances, flexible tools, as well as platform and common part strategies, allow single model production lines to be modified to handle multiple models in parallel (multi-model-line). The sustained reallocation of models to production lines to adjust volume according to market demand is no longer a vision, but virtually industry standard. Hence, model-plant allocation decisions are moving from a strategical one time long-term decision to the more frequent tactical mid-term planning tasks. Due to the shifted time horizon and the reallocation of models within their life cycle, different requirements and restrictions apply, when compared to strategical models. Modified planning models are required as decision support to handle the increased flexibility. A modeling framework handling the increased flexibility will be presented.", :title "Tactical planning in flexible production networks in the automotive industry", :keyword2 "flexibility", :authors (15390 13503 2651 26443), :session 110}, 220 {:keyword1 "agent based modeling", :keyword3 "multi criteria decision making", :abstract "Increased turbulence and complexity contribute to the fact that firms have to face the challenge of achieving multiple goals simultaneously and, in consequence, that requirements of coordination at different levels of the firm are increased too . This paper addresses the following research question: How do different organisational design elements (such as organisational structure, structure in decision-making, incentive scheme) affect the levels of the achieved performance and the speed of performance improvements with respect to multiple goals.\r\nIn order to examine this question we apply an agent based simulation which is based on NK-fitness-landscapes. Especially, we model multiple criteria decision-making as adaptive processes on multiple NK-fitness landscapes with potential different degrees of complexity. Although -agent-based simulations and, especially, NK-fitness landscapes were successfully employed by management scholars it appears as innovative in the area of performance management and multiple criteria decision making.\r\nNot surprisingly, our results show that with respect to higher incentivized goals a higher level of performance is achieved and that the corresponding performance curve over time has a higher gradient, i.e. that performance is improved faster. Contrary to intuition, we also find that, if multiple equally incentivized goals are pursued, the achieved levels of performance increase with the complexity of the related performance landscapes. In contrast, when pursuing one goal a lower complexity leads to a higher degree of achieved performance.\r\nOur findings show that level and speed of performance achievement in multiple criteria decision-making subtly depend on complexity and organisational design elements.\r\n", :title "Positive effects of complexity on performance in multiple criteria setups", :keyword2 "complexity", :authors (26117 25320), :session 168}, 222 {:keyword1 "Freight consolidation", :keyword3 "Heuristic", :abstract "Confronting the fierce competition, many enterprises take it as a remedy to outsource their non-core activities to external suppliers, so that they can concentrate more on their core business fields to improve their operation efficiency and to reduce their costs. Logistic services are one of the most outsourced activities. The transportation tasks will no longer be fulfilled by own fleets but released to external freight carriers as transportation requests by indicating the pickup and delivery locations, time windows, transportation quantities and if necessary, other specifications. In order to reduce transaction costs caused by the outsourcing of transportation services, a tariff agreement serving as the basis for the determination of the freight payment will be signed. Freights will then be calculated for the released transportation requests depending on their quantities and distances. A common feature of such tariff structures is the economy of scale. In order to take advantage of this feature and to reduce their transportation costs, it is important for the outsourcing enterprises to efficiently bundle their transportation tasks first before releasing them to their logistic service providers. Thus, instead of the problem of vehicle routing, these outsourcing enterprises have to solve the problem of cargo bundling, which is called the Freight Consolidation Problem (FCP). In this contribution, the FCP is formally described and mathematically modeled. A heuristic approach is also presented to solve the problem.", :title "Modeling and Solving the Freight Consolidation Problem", :keyword2 "Operational transportation planning", :authors (17524 15277), :session 201}, 227 {:keyword1 "scheduling", :keyword3 "", :abstract "Earlier research by the author has provided a number of new theorems for deciding precedence between pairs of jobs for the single machine weighted tardiness scheduling problem. The theorems supplant those of Rinnooy Kan, Lageweg, and Lenstra (1975). Presented here are the results of a preliminary analysis of the added benefit these new theorems provide. Early results show that the new theorems can provide remarkable improvements in the ability to discover precedence relations between jobs. This improvement in the productivity in discovering precedence relations shows to be dependent on the coefficient of variation of the distribution of job weights.", :title "Weighted Tardiness for the Single Machine Scheduling Problem", :keyword2 "production planning", :authors (14155), :session 152}, 228 {:keyword1 "DEA", :keyword3 "stochastic frontier", :abstract "This paper addresses an application of DEA to media selection based on an empirical data.We present a simple non-parametric approach to an optimization problem in the stochastic frontier model with unknown functional form of the frontier based on DEA.Though much effort has been done on determining advertising-response curvbes to employ the parametric approach to media selection,there is little conclusive evidence so as to the shape of these curves. For an optimization problem in stochastic frontier model with inplicitly a Cobb-Douglas or non Cobb-Douglas form,we shall show by Monte Carlo simulation that in either case an optimum solution to the data envelopment approximation model(DEAM) is sufficiently close to that of the original problem.It is also shown that,in the problem with an implicitly non-Cobb-Douglas form DEAM outperforms the parametric approach in which it is required to specify the functional form.\r\nWe shall provide an illustrative example of DEAM to the problem of finding the \"best practice\" combination of media within each media type(TV,newspapers, magazines and radio)in which an advertising campaign is scheduled so as to maxmize some criterion(awareness value,knowledge level and so on) on the basis of advertising budget.When it come to using this model,it is critical that a large size of empirical data is available.   ", :title "A DEA approach to media selection", :keyword2 "media selection ", :authors (14775 26381), :session 99}, 229 {:keyword1 "Risk and Threat Modelling", :keyword3 "Stream Computing", :abstract "We present a method for forecasting threats. It relies on the analysis of reports written in natural language (NL). The method, developed at Fraunhofer FKIE, has already been implemented as part of a demonstrator produced by IABG for military intelligence. In the demonstrator, the analyzed reports contribute to the activation of a Bayesian network calculated from threat model developed by IABG which describes threats against own forces during peace-enforcing operations. Here, we shift the application focus to security threats within supply chains in general and container logistics in particular, where IBM has formerly engaged in applied research projects.\r\n\r\nIn order to use reports for forecasting threats in a timely fashion, we will use in-motion analytics technology on the NL data sources to perform a low-latency transformation of text into formal representation of it. This technology is the result of an ongoing IBM software research program aiming at the unlocking of insight and awareness in an event-driven world. As soon as the reports are represented formally, they can be matched against indicators calculated from the threat model in question.\r\n\r\nThe transformation of reports written in NL into formal representations is done in three steps. First, reports are parsed into syntactic structures using the GATE services developed by the University of Sheffield. GATE provides tools for linguistic operations. For parsing German reports, we added some of our own tools. Second, we combined information extraction and semantic role labeling, again using GATE and some tools created by us. Third, report content is adjusted ontologically: implicit information in the report is stated explicitly in the formal representation using a logistics business model and a domain ontology.\r\n", :title "Forecasting Threats by Analyzing Natural-Language Reports ", :keyword2 "Natural Language Analysis", :authors (26270 26269 26272), :session 229}, 230 {:keyword1 "network design", :keyword3 "location", :abstract "In this talk the design of a two- or three-level transportation network is considered. This type of network is typically established in national European less-than-truckload businesses.\r\nCargo shipment from source to sink customers can be divided into three to four segments. Goods are picked up at customer locations and shipped to a source depot. After that there is a long-haul transport to a sink depot. The long-haul can either be executed directly or indirectly with consolidation in a hub location. Finally cargo is distributed from the sink depots to their final destination.\r\nIn order to formalize this problem, different linear and nonlinear models are proposed and analyzed. The goal of optimizing this NP-hard problem is to minimize total costs by determining number, position and capacity of depots and hubs. In addition, customers have to be allocated to depots. Furthermore the execution mode (direct – indirect) of long-haul transports has to be defined for each depot pair.\r\nTo solve the optimization problem, two approaches are developed and compared. The first approach consists of a local search based metaheuristic, which aims at moves on the locations and chooses assignments as a results of the location decision. The second method utilizes relaxation of long-haul transports. The resulting problem is the well-known capacitated facility location problem. Using this procedures, real-world problem sizes can typically be solved in high quality, with a gap of less than 10% to the optimal solution.\r\n", :title "Design of less-than-truckload networks: models and methods", :keyword2 "metaheuristic", :authors (26273), :session 216}, 232 {:keyword1 "multi-period VaR forecast", :keyword3 "volatility scaling, GARCH", :abstract "Multi-period value-at-risk (VaR) forecasts are essential in many financial risk management applications. This paper addresses financial risk prediction for equity markets under long range dependence. Our empirical study of established equity markets covers daily index observations during the period January 1975 to December 2007. We document substantial long range dependence in absolute as well as squared returns, indicating a significant influence of long memory effects on volatility. We account for long memory in multi-period value-at-risk forecasts via a scaling based modification of the GARCH(1,1) forecast. We study the accuracy of VaR predictions for five days, ten days, 20 days and 60 days ahead forecast horizons. As benchmark model we use a fully parametric GARCH setting whose multi-day volatility is calculated by the Drost and Nijman (1993) formula. Moreover, the benchmark model uses the Cornish-Fisher expansion to calculate quantiles of the innovations distribution. Our results show that the scaling based GARCH-LM technique can improve VaR forecasting results. The scaling based GARCH-LM method outperforms the benchmark model for forecast horizons of five and ten days significantly. This outperformance is only in part due to higher levels of our risk forecasts. Even after controlling for the unconditional VaR levels of both approaches, our approach delivers results which are not dominated by the benchmark approach. In all, our results confirm that poorly estimated average capital levels can not be compensated by adequate adjustment to time varying market conditions.", :title "Market Risk Prediction under Long Memory: When VaR is Higher than Expected", :keyword2 "long memory, fractional Brownian motion", :authors (26274 26275), :session 97}, 235 {:keyword1 "Scheduling", :keyword3 "Hybrid Flow Shop", :abstract "The talk is concerned with hybrid flow shop scheduling taking account of different additional constraints namely release dates, no-waiting-time and transportation requests. Our objective is minimizing total weighted completion time. This research is motivated by a dynamic real-life problem with jobs arriving over time. In practice, it has to be solved within a very small amount of computational time, therefore, we develop a fast two phase heuristic solution technique, which is based on simple dispatching rules like the well-known WSTP (weighted shortest total processing time first) rule as well as bottleneck related strategies. To analyze our approach empirically, we introduce lower bounds for several variations of the problem that are based on the LP relaxation of time-indexed mixed-integer formulations. Furthermore, these bounds are evaluated within an extensive computational study on the one hand and in a more general and theoretical fashion on the other hand. Finally, the performance of our algorithm is explored in case of our practical application.", :title "Hybrid flow shop scheduling: Heuristic solutions and LP-based lower bounds", :keyword2 "Heuristics", :authors (15383), :session 145}, 238 {:keyword1 "Ohlson model", :keyword3 "persistence of earnings", :abstract "In todays’ world of economic uncertainty and scarce equity financing, it's becoming more and more crucial to cater to the needs of investors. Therefore it is necessary to know the impact of certain accounting options, bonus schemes, etc. on the capital market. This is not only of interest to companies preparing financial statements and investors but also to standard setters who want to gain insights on the implications of changes in accounting principles.\r\nModern empirical accounting research almost always applies some form of the Ohlson model (Ohlson, 1995) to test for value relevance of certain financial statement figures, as it explicitly connects market value of equity with various accounting variables. Ohlson’s model is based on three assumptions. The first two are somewhat interconnected. On the one hand the price of a stock is equal to the present value of future dividends – also known as the Dividend Discount Model. On the other hand the validity of the clean surplus relation which states that all changes in book value of equity are caused either by earnings or dividends. The third assumption is that there is additional information about future (abnormal) earnings which is not included in current earnings. Future abnormal returns follow the Linear Information Dynamic, a stochastic process for which consensus analyst forecasts can be used as one input variable (Dechow et al., 1999) while there is another variable for persistence of current abnormal earnings.\r\nTo get better results there are possible modifications. Long-window regressions can easily be biased by equally weighting all observations. Applying backtesting and optimization methods 1)biases in analysts’ projections of earnings as well as 2)errors in persistence parameters might be reduced.", :title "The interdependence of equity capital markets and accounting – a discussion of the Ohlson model, it’s application and possible modifications", :keyword2 "analyst forecasts", :authors (26285), :session 122}, 239 {:keyword1 "Disruption management", :keyword3 "", :abstract "Disruptions of a railway system are responsible for longer travel times and much discomfort for the passengers. Since disruptions are inevitable, the railway system should be prepared to deal with them effectively. In case of a disruption, it is often too complex to reschedule the timetable, the rolling stock circulation, and the crew duties manually, because it is too time consuming in a time critical situation where every minute counts. As a result, additional delays for passenger can occur. Therefore, algorithmic support is badly needed. \r\nTo that end, we describe Operations Research (OR) models and algorithms for real-time rolling stock rescheduling and real-time crew rescheduling that are currently being developed and that are to be used as the kernel of decision support tools for disruption management at Netherlands Railways, the largest operator on the Dutch railway network. \r\nIn addition, we discuss scientific challenges for the OR community and practical challenges for the railway operator to use these techniques in practice.", :title "Operations Research models and algorithms for railway disruption management", :keyword2 "Railways", :authors (5932 20288), :session 198}, 241 {:keyword1 "Gesundheitssysteme", :keyword3 "DEA", :abstract "In Zeiten steigenden Kosten- und Leistungsdrucks im Gesundheitswesen stehen insbesondere Krankenhäuser im Brennpunkt der Frage nach möglicher Effizienzsteigerung. Gemäß dem Statistischen Jahrbuch (2009) entfiel in Deutschland in den letzten fünf Jahren mit durchschnittlich 37% der größte Anteil der Gesundheitsausgaben in stationäre und teilstationäre Behandlungen. Aber auch in anderen europäischen Ländern stellen die Krankenhäuser den größten Kostenanteil des Gesundheitswesens dar, so z. B. in Österreich mit 27%. Aufgrund steigender Globalisierungsbestrebungen erscheinen internationale Vergleiche zweckmäßig, um damit zusätzliche Informationen für Effizienzverbesserungen zu gewinnen. Eine praktische Umsetzung dieser Idee lieferten die US-Amerikaner Charnes, Cooper und Rhodes mit einer Methode, die als Data Envelopment Analysis (DEA) bekannt wurde. Die DEA erfreut sich in der angelsächsischen betriebswirtschaftlichen Forschung einer weiten Verbreitung, aber auch im deutschen Schrifttum findet sie zunehmend ihre Anwendung. Der vorliegende Beitrag vergleicht europäische Gesundheitssysteme durch die Messung relativer Effizienzen von Akutkrankenhäusern mittels der DEA. Als In- und Outputdaten der Wirtschaftseinheiten werden von der World Health Organization (WHO) publizierte Daten über einen Zeitraum von 10 Jahren herangezogen. Die Effizienzmessungen werden dabei zeitlich dynamisch durchgeführt. Die Analysen lassen erkennen, ob Effizienzverbesserungen eines Akutkrankenhauses über die Zeit hinweg bloß aus der Angleichung an andere Krankenhäuser resultieren, oder ob tatsächlich besser gewirtschaftet wird. Sämtliche Ergebnisse werden vor dem Hintergrund realer Gegebenheiten interpretiert.", :title "Vergleichende Effizienzmessungen europäischer Gesundheitssysteme", :keyword2 "Effizienzmessung", :authors (25442 26296), :session 65}, 243 {:keyword1 "Multi-Depot VRP", :keyword3 "adaptivity", :abstract "Logistics plays an important role in economy: companies intend to deliver their products to customers as economical as possible. In operational research Vehicle Routing Problem (VRP) deals with this problem. There is a set of vehicles and customers with their orders. A set of routes has to be found which start and end in the central depot and satisfy the needs of the customers with the least cost. The cost depends on the number of routes and the time vehicles spend out of the depot. In several cases customers have time windows: a vehicle has to arrive at a target in the customer’s time window. This variant of VRP is often called VRP with Time Windows (VRP-TW). Usually solutions are separated into two main parts: clustering deals with the determination of route set and routing deals with ordering the customers on a route.\r\nIn real life situations companies usually have more depots at different locations instead of one and each depot has a set of vehicles. Multi-Depot VRP (MD-VRP) has much less literature than VRP. We found that popular and efficient solutions of this NP-complete problem use hybrid genetic algorithms. These algorithms take into account the length of routes, time constraints, sometimes capacity constraints and all of them are based on the assumption that there won’t be any problem during the transport. \r\nIn our approach we analyze how to take more advantage of cooperation between vehicles. Advanced cooperation offers better readiness for problems on the run (e.g. a vehicle breaks down or a road is closed) or may lead to more efficient transfer (for example in case of fleet with different capacity). In this issue we give a method to enrich former solutions of MD-VRP with advanced cooperation and show our experiences.\r\n", :title "Algorithm based on vehicle cooperation for Multi-Depot Vehicle Routing Problem", :keyword2 "cooperation", :authors (26251 26293), :session 196}, 244 {:keyword1 "values", :keyword3 "generating functions", :abstract "The main objective of this paper is to analyze whether some modification of\r\nthe generating function technique might be used to compute the\r\nDeegan-Packel, Public Good, and Shift power indices. The generating function method has been\r\nsuccessfully applied to compute the Shapley-Shubik and the Banzhaf-Coleman power indices.\r\n\r\nThe three indices we consider in this paper are defined on the basis of either minimal winning\r\ncoalitions (for the Deegan-Packel and Public Good indices) or\r\nshift-minimal winning coalitions (for the Shift-power index).\r\n\r\nIn games with a large number of players, it could be difficult to identify the list of minimal winning coalitions or shift-minimal winning. The procedure proposed provides a systematic method to compute these indices as long as the number of players is not huge. ", :title "On the use of generating functions to compute power indices based on minimal winning coalitions", :keyword2 "power indices", :authors (11762 19833 19815), :session 188}, 245 {:keyword1 "system dynamics", :keyword3 "product piracy", :abstract "Today, product counterfeiting and piracy are fully recognized as essential business risks to nearly any industry. As this issue has concerned literature for more than 30 years now, there is a whole bunch of supposedly effective counterstrategies available   and of which companies have but to choose from if there are to end this threat. However, this scourge is prevailing, and companies’ strategic decision makers are more often than not dumbstruck when the proposed remedies   deployed in the company’s specific business context   fail to yield the expected success. Recent research indicates that the decision makers have not yet been enabled to fully understand the scope and implications of industrial counterfeiting and product piracy in a strategic management context. Besides still open issues in understanding the dynamic complexity of this phenomenon, it is in particular decision support tools that stand for an immediate management need. This paper therefore aims at closing this gap and proposes a preliminary system dynamics framework to evaluate strategy options in fighting product piracy and counterfeiting. By elaborating on a previous contribution it will briefly outline the current state of research in this area and highlight the potential benefits of a system dynamics application in this context. It will then extensively elaborate and discuss a first simulation framework to prove the applicability of system dynamics as a strategic decision support tool for the management problem at hand. It will finally summarize open issues to motivate further research in this area.", :title "Exploring anti counterfeiting strategies: A preliminary system dynamics framework for a quantitative counterstrategy evaluation ", :keyword2 "decision support", :authors (20167), :session 169}, 252 {:keyword1 "Domino Portrait", :keyword3 "Rounding Technique", :abstract "A domino portrait is an approximation of an image using a given number\r\nof sets of dominoes. Bosch [2004] formulated the problem as an integer\r\nlinear programming problem. Given a tiling pattern of the image (a\r\npartition of an image to a set of 1x2 rectangles), Cambazard, et al.\r\n[2008] showed that an optimal arrangement of domino pieces is obtained\r\nby solving a traditional transportation problem.\r\n\r\n\r\nIn this paper, we propose a method based on a rounding technique. We\r\nformulate the problem as an integer linear programming problem which\r\nrepresents a tiling pattern by a perfect matching on a square lattice\r\ngraph. We solve a corresponding linear relaxation problem and apply a\r\nrounding technique to obtain a tiling pattern. Then we employ the\r\nobtained tiling pattern and find an arrangement by solving a\r\ntraditional transportation problem. In many instances, our method\r\noutputs an optimal solution of the original integer linear programming\r\nproblem.", :title "Linear Relaxation Method for Domino Portrait Generation", :keyword2 "Integer Programming", :authors (26300 13201), :session 220}, 262 {:keyword1 "gender", :keyword3 "ressources", :abstract "This paper describes the results of an exemplary analysis of informatics educational materials from a gender perspective. The study was performed by the Universität der Bundeswehr München in the context of the PREDIL project . School book research is often focused on subjects like history, languages and politics education (see Matthes & Heinze, 2005; www.edumeres.net). However, girls and boys show different interests and self-efficacy in using information and communication technologies (ICT) at school and at home (see Ertl & Helling, in press; Imhof, Vollmeyer & Beierlein, 2007, Initiative D21, 2008, OECD, 2005). Also, the uptake of careers in the ICT sector is subject to gender differences Women are clearly underrepresented in the ICT professions and at informatics at university (see Briedis et al., 2008, European Commission, 2006). For this reason, we consider it important to analyse the representations of females and males in informatics educational materials, presuming that gender sensitive design of educational materials could have an influence on the teachers’ and pupils’ perceptions of gender ICT.", :title "Gender Sensitivity of Informatics Educational Materials for Pupils and Teachers", :keyword2 "education", :authors (23389), :session 33}, 264 {:keyword1 "Gender", :keyword3 "Education", :abstract "Gender imbalance is an important issue in the context of information, and communication technologies (ICT). This paper focuses on gender equality in ICT usage in particular from the perspective of women at three levels: school, university, and professions. ICT include the internet and computer usage as well as digital literacy in general. For an overall overview in Germany the relevant statistical data and prevailing research findings of the fields of school, university, and career paths with respect to ICT usage will be analyzed. Findings of a study by Engeser et al. (2008) reveal that self-confidence is crucial aspect for the career choice in the ICT field; and Dick and Rallis (1991) report that the attitudes and expectations of socialisers, e.g. teachers, could have impact on the career choice of women. Based on the findings we are able to reveal supporting measures for enhancing girls and women in this field. A starting point would be raising the self-confidence of girls in school that girls could strengthen their interest for digital literacy, so they may consider a study or even an uptake of a career in ICT as an opportunity. For the development of self-confidence of girls, it should take into account the facilitating role of teachers in this respect who may have an influence on the perception of girls’ abilities in ICT subjects. Furthermore, the implementation of a unified curriculum for media education or informatics across Germany could enhance the gender balance. To sum up, measures for gender balance have to start as early as possible to increase the self-confidence of girls in digital literacy and in particular facilitations for women in ICT have to be consequently improved to affect the uptake of ICT careers by women.", :title "Gender and Career Paths in ICT", :keyword2 "Career", :authors (26313 23389), :session 33}, 265 {:keyword1 "vehicle routing", :keyword3 "OR software", :abstract "This contribution presents a new construction heuristic for general vehicle routing problems. The Merge-Savings algorithm is a generalization of the well-known Clarke & Wright Savings-algorithm. Moreover, our new approach implicitly includes the customer insertion operations found in the family of classical sequential and parallel insertion algorithms.\r\n\r\nWe present the design goals of this algorithm, e.g. improved handling of time-windows and duration constraints compared to the Clarke & Wright algorithm, the optimization of planning problems with both depot-related as well as pickup and delivery transports in arbitrary proportions , and incremental planning, i.e. the extension of a given plan with unscheduled orders.\r\n \r\nThe idea of Merge-Savings is, at each iteration, to merge two subtours into a new tour while maintaining each tour's precedence relations. Algorithmically, this is realized by dynamic programming where each state represents the new tour constructed so far. The action set consists of choosing the next stop either from the first or the second tour. This algorithmic approach is fairly general and allows for the inclusion of constraints like multiple time windows, pickup and delivery transports, waiting time restrictions, and others as typically found in rich problems. \r\n \r\nWe present computational results on real world instances realized with an implementation of Merge-Savings in the commercial vehicle routing package PTV Intertour and relate our approach to benchmark problems from the literature.", :title "Merge-Savings: A construction heuristic for rich vehicle routing problems", :keyword2 "heuristics", :authors (26315 17043 26316), :session 196}, 269 {:keyword1 "Electric-Drive Vehicles", :keyword3 "Mixed-Integer Optimization", :abstract "In the past decade electric vehicles have developed to a serious alternative for emission-free mobility \r\nin urban areas. National governments and the European Union try to accelerate the market \r\ndevelopment with subsidies and research projects to gain significant CO2 reduction in road traffic. \r\n\r\nFirst adopters will be small to medium size vehicle fleets in urban areas. In contrast to the higher investment costs \r\nelectric vehicles have lower costs for operating, energy and maintenance.  However, these fleets need proper charging \r\ninfrastructure available in the area of operation. The number of potential locations can be quite large with differing \r\ncosts for preparation, installations, operation and maintenance.\r\n\r\nWe consider a planning approach based on vehicle movement scenarios. Given a large set of vehicle movement and \r\nparking activities, we search for a cost minimal subset of all charging locations subject to a certain degree of service. \r\n\r\nWe present a mixed-integer linear programming model to optimize the planning decision, analyze its complexity and \r\npropose heuristic solution strategies.\r\n", :title "A New Model Approach on Cost-Optimal Charging Infrastructure for Electric-Drive Vehicle Fleets", :keyword2 "Charging Infrastructure", :authors (24921 1141 9272), :session 197}, 274 {:keyword1 "yield uncertainty", :keyword3 "dynamic safety stocks", :abstract "In environments where not only customer demand is stochastic but also production is exposed to stochastic yield, inventory control becomes an extremely challenging task. To cope with the influence of both risks we present two control parameters, which can be used in an MRP-type inventory control system: a safety stock and a yield inflation factor that accounts for yield losses. From earlier research it is well-known that a linear control rule works quite well in the case of zero production lead time. Just recently it has been investigated how an effective parameter determination can also be extended to cases with arbitrary lead times. \r\n\r\nUp to now all contributions in this research context refer to production environments that are characterized by stochastically proportional yield. In our research we will extend the parameter determination approaches to two further well-known types of yield randomness, namely binomial and interrupted geometric yield. The three mentioned yield models mainly differ in the level of correlation existing for individual unit yields within a single production lot. We show how for all yield models safety stocks can easily be determined following the same theoretic concept. Because in the case of non-zero lead time safety stocks vary from period to period, we additionally present different approaches of how these dynamic safety stocks can be transformed into static ones. Under interrupted geometric yield we point out that also the yield inflation factor turns out to be time-dependent and we develop a rule for transforming this factor into a static one. Finally, we investigate the impact of a misspecification of the yield model on cost performance via a comprehensive simulation study. \r\n", :title "Parameters for Production/Inventory Control in the Case of Stochastic Demand and Different Types of Yield Randomness", :keyword2 "inventory control parameters", :authors (26151 2801), :session 111}, 277 {:keyword1 "staircase", :keyword3 "decomposition algorithm", :abstract "For special matrix structures in mixed integer linear programs certain types of decomposition approaches may greatly improve the solution process. However, such a decomposition is currently done mostly ad-hoc which requires high skills and judgement from the implementer. The risk of a suboptimal implementation or an inappropriate decomposition is high. Additionally, it is not said that a person writing the model actually sees the hidden structure. It would be helpful if specialized solvers could detect such structures and perfom an efficient implementation of the best algorithm without the interaction of the user.\r\n\r\nTo go one step into that direction, the focus in this paper will be the detection of the so called staircase structure in matrices. We summarize the benefits of the staircase form and we propose an exact binary linear optimization model to minimize the number of pass on variables between the blocks. Since the solution of that model could be trivial, we show several kind of extensions which allow for more balanced solutions. As the number of blocks and pass on variables in a problem is unknown, we provide lower and upper bounds for the number of blocks and the number of pass on variables. We further test the model on various instances and show that many problems can be brought in a staircase form. At the end, we check if the detection of the structure provided a better solution process.", :title "Detecting staircase structures in matrices", :keyword2 "detection", :authors (14969), :session 220}, 278 {:keyword1 "lean SCM", :keyword3 "mixed integer heuristic", :abstract "More and more industrial companies – not limited to the automotive sector – successfully bring their production in line with lean principles of the Toyota Production System.\r\n \r\nUsually, the implementation of the concept does not cover long haul transports in the geographically widespread networks as they are found in Europe.  \r\n \r\nWe present an optimization approach adopting lean principles to the long haul transportation segment: The key innovation of the concept is a balanced and weekly recurring transportation plan on network level achieved by a two stage approach. \r\nFirst, and on the production site level, clients choose their optimal weekly transport frequencies for the forecasted transport volume on different relations while taking into account their holding and transportation cost.\r\n \r\nSecond, and on the network level, the network operator maps the frequency bookings of all clients with weekly transportation patterns considering the objective of balancing the volumes for the pickup and delivery regions.\r\n \r\nWe propose MIP formulations and corresponding solving methods for both problems. In the first case we chose a simulation based exact method giving consideration to the uncertainty of demand forecasts: Thus, a defined level of robustness of the first step results is guaranteed and reliable planning data for the next stage are ensured. For the solution of the large-scale problem on the network level we propose a simple heuristic using a MIP solver as a black-box component. \r\n \r\nTo evaluate computational performance as well as the logistical impact of the concept, detailed simulation studies with real network data have been conducted. We show the results along with implications for further research directions.", :title "A two stage approach for balancing a periodic long-haul transportation network", :keyword2 "network planning", :authors (17774 26322), :session 201}, 285 {:keyword1 "purchasing", :keyword3 "", :abstract "The trading unit of a Danish refinery is responsible for all purchasing decisions, with some support from the production planning and scheduling unit. There are mainly two factors which make the purchasing process complicated. The crude commodity market is very dynamic; prices fluctuate constantly and the timing of purchases becomes very important. Secondly, petroleum refining is a very complex production process. Crude oils have natural variability; they differ from one another, usually depending on their origin. The variability affects the downstream processing of the crude and product yields. Therefore it is essential to consider crude oil blending when making procurement decisions. \r\nThe benefits of using optimization for production planning for refineries were already identified in the 1950s, and a few years later, optimization models for scheduling of crude oil arrivals also became widely used. However, in the petroleum refining literature, most publications so far focus on the production segment of the refinery, or the crude oil scheduling. Little attention has been given to the procurement planning segment of the industry. \r\nWe develop an optimization model, which will be incorporated in a decision support tool. The model maximizes the refining margins of the refinery, while keeping the refinery’s feedstock within acceptable quality levels. It determines how much of which type of crude oil to procure and when, how to allocate arriving shipments into storage tanks and it determines inventory and composition profiles of storage tanks. The proposed approach results in an MINLP model. GAMS is used to implement the optimization model. The CONOPT solver has been selected in order to handle non-linear constraints.\r\n", :title "MINLP model for Procurement Planning for Petroleum Refineries", :keyword2 "blending", :authors (26321 909), :session 110}, 286 {:keyword1 "flexible job-shop", :keyword3 "blocking", :abstract "This paper deals with online scheduling of a flexible job-shop with blocking\r\nwhere jobs are transported between the machines by one or several automated\r\nguided vehicles. The objective is to minimize the total weighted tardiness of\r\nthe jobs. Schedules have to be generated online (i.e. jobs only become known\r\nto the scheduler at their respective release dates) as well as in real time\r\n(i.e. only a limited amount of computation time is allowed). We propose a\r\ntabu search algorithm that decomposes the problem into an assignment and a\r\nscheduling subproblem. Experimental results are presented for various problem\r\ninstances.", :title "Online scheduling of flexible job-shops with blocking  and transportation", :keyword2 "transportation", :authors (19076 14742 26345), :session 148}, 287 {:keyword1 "Soziale Netzwerkanalyse ", :keyword3 "SPIRIT", :abstract "Soziale Netzwerke sind feste Bestandteile unserer Gesellschaft und werden in spezialisierten Branchen natürlich auch für unternehmerische Aktivitäten genutzt. Die wissenschaftliche Forschung interessiert sich ebenfalls zunehmend für das Potenzial dieser Netzwerke. Während in den Sozialwissenschaften eher die Beziehungen einzelner Akteure analysiert und interpretiert werden, steht bei der Wirtschaftswissenschaft vor allem die erfolgs- und entscheidungsorientierte Sicht im Vordergrund. Unternehmen und praxisnahe Forschung verwenden bereits graphentheoretische Instrumente, um merkmalsbezogen die Verflechtungen innerhalb solcher Netzwerke zu visualisieren. Darauf aufbauend lassen sich sowohl Rollen einzelner Akteure als auch eigene Positionen zielgerichtet identifizieren. Die bekanntesten Instrumente, mit denen man über eine graphische Darstellung hinaus zu tragfähigen Erkenntnissen gelangt, werden unter dem Begriff Soziale Netzwerkanalyse (SNA) subsummiert. Mit ihr ist es etwa möglich, durch Fokussierung Informationen über die Relevanz von Knoten innerhalb eines hoch vermaschten Geflechts zu erhalten. In diesem Beitrag wird nach Vorstellung einiger klassischer Zentralitätsmaße ein entropieoptimaler Ansatz eingeführt, der es ermöglicht, auf Basis der Informationstheorie Beziehungsnetzwerke ganzheitlich zu bewerten. Im System SPIRIT können konditionale Strukturen wissensbasiert abgebildet und die dort zur Verfügung stehenden Methoden dann direkt für die SNA genutzt werden. Nach Erläuterung der generellen Vorgehensweise werden für klassische Beispiele entsprechende Ergebnisse vorgestellt. Mittels Szenarioanalysen und Untersuchungen lokaler Veränderungen im Netzwerk wird eindrucksvoll das Potenzial der neuartigen Bewertungsmethode verdeutlicht.", :title "Ein entropieoptimaler Ansatz zur Analyse Sozialer Netzwerke", :keyword2 "entropieoptimale Zentralitätsmaße ", :authors (26311 26286), :session 88}, 288 {:keyword1 "Mulimedia", :keyword3 "Cost-quality optimization", :abstract "In present days, the media industry is looking for concrete business opportunities in publishing the same product across different media. Moreover reduced time-to-market implies adopting higher quality standards in production (e.g. more skilled people, more efficient equipment) with an higher investment costs. This requires the careful planning to minimize the risks of each production without increasing its cost. \r\n\r\nWe consider a cross-media production as a content that is explicitly produced to be distributed across multiple media. We formalize it as a collection of several Media Production Objects (MPOs): abstract representations of production components such as audio and video footages, 3D models, screenplays, etc. MPOs can be aggregated using semantic rules specific for a given media channel. Once aggregated they become for example a film, a Video Game, or even another (more complex) MPO. We call “a view” the aggregated product ready to be published on a given channel. MPOs can have temporal constraints imposed to their realization, and are characterized by quality and costs metrics. We propose a formal model for the definition of MPOs, presenting an automatic procedure to create mixed-integer linear programming problems whose solution allows to optimize production costs and qualities. This scenario opens a wide range of possibilities, that a MIP solver – in our case, XPRESS-MP – can solve as a black-box tool. This allows efficient what-if analysis under different scenarios. More complex analysis are worth to be investigated: multi-criteria analysis with generation of the efficient frontier for exploring trade-off solutions, or robust optimization for obtaining guaranteed quality levels under every possible scenario.\r\n", :title "Modelling and optimization of cross-media production processes", :keyword2 "Performance model", :authors (26218 5692 38189 26327), :session 172}, 289 {:keyword1 "Arbitrage CDOs", :keyword3 "Systematic risk of CDO tranches", :abstract "The fair valuation of complex financial products for credit risk transfer (CRT) can provide a good basis for sustained growth of these markets. The study focuses on “arbitrage-CDOs”, a CRT-product whose enormous growth has contributed decisive to the current financial crisis. \r\n\r\nWe analyze the possibility of “CDO arbitrage”, that is due to a lack of valuation (of CRT-products like CDOs, CDS-Index and STCDO). The use of an identical rating scale both for structured products and corporate securities tempted many investors to apply identical risk profiles for all products with identical rating grades. Extensive simulation studies based on market and rating information show significantly different risk characteristics of CDO tranches in relation to systematic risk as corporate bonds with identical rating grades. The measurement of the increased systematic (and therefore pricing relevant) risk sensitivity of CDO tranches as well as their integration in a simple pricing model based on the CAPM and a single-factor Merton model represent the first step of the study. \r\n\r\nIn a next step we present an extended pricing model which - besides the increased systematic risk sensitivity - integrates the current risk aversion of investors as well as different states of the economy. Based on the Arrow/Debreu theory, state prices observed on benign markets should be, due to their high marginal utility, far smaller than state prices observed on stressed markets. Market indices (e.g. DJ Euro Stoxx) are used as proxies for deriving state prices of different states of the economy. On the base of option prices, the “volatility skew” is taken into account. The resulting implied risk-neutral density function is then included into the pricing of the CRT-products.  \r\n", :title "(Mis-)Pricing of complex financial instruments for credit risk transfer", :keyword2 "CDO pricing", :authors (26326 26328), :session 96}, 293 {:keyword1 "Soft Operations Research", :keyword3 "Relative Quantitative Modeling", :abstract "While hard operations research provides optimal solutions for idealized tasks, soft operations research, e.g. with system dynamics, allows to run scenarios on any kind of task.\r\nUnfortunately, in most cases the real challenges aren’t ideal so it is up to the modeler’s intuition and experience to try different scenarios on a model to identify better solutions.\r\nNon ideal tasks often depend on a variety of soft factors that are difficult to be put in mathematical relation to hard factors. Then, even if someone has developed a formula and some values for these factors, readers of the model tend to doubt these allegedly exact interrelationships. To describe those interrelations between factors and to agree on their meaning will become way easier, if we start with so called qualitative modeling. Qualitative modeling means to visualize interrelations and then roughly weight the impacts factors have on each other using attributes like weak, middle and strong - or percentage values without dimension. We can even analyze qualitative models and compare the short and longterm impacts of factors onto a chosen factor.\r\nOf course, an analysis with a simulation of dynamics over time is more sophisticated. To achieve this becomes fairly easy by transforming the qualitative weighting into a relative quantitative model of system dynamics. \r\nIf the assumptions then appear to be too arbitrarily, with the help of likelihood-functions and Monte-Carlo-simulations a variety of possible outcomes can be simulated.\r\nBy this easy way to use rough assumption to run scenarios on possible outcomes of any task it becomes possible to make operations research a daily routine within decision making and planning, executed by decision makers and not just OR experts as many practical examples already show.", :title "Insights from rough assumptions: the benefits of qualitative modeling and relative quantitative modeling", :keyword2 "Qualitative Modeling", :authors (26332), :session 167}, 295 {:keyword1 "subsystem inference representation", :keyword3 "approximating function", :abstract "A new representation for fuzzy systems in terms of additive and multiplicative subsystem inferences of single variable is proposed. This representation enables an approximate functional characterization of the inferred output. The form of the approximating function is dictated by the choice of polynomial, sinusoidal, or other designs of subsystem inferences.The paper is organized as follows. The first section gives a brief review on product sum fuzzy inference and introduces the concepts of additive and multiplicative decomposable systems.The second section presents the proposed subsystem inference representation.The third section focuses on subsystem inference of single variable. The sections IV to VI discuss the cases of polynomial, sinusoidal and other designs of subsystem inferences, and their applications. Finally, the section VII presents some conclusions.", :title "A New Representation for The Fuzzy Systems In Terms of Some Additive and Multiplicative Subsystem Inferences", :keyword2 "fuzzy systems", :authors (26312 23449), :session 125}, 296 {:keyword1 "Shape Analysis", :keyword3 "Permutation tests", :abstract "Most of the renal tumours affecting little children are Wilms-tumours. It is important but very difficult to differentiate Wilms-tumours from other renal tumour types like neuroblastoma, renal cell carcinoma etc.. since the correct therapy depends on the diagnosis. For the diagnosis the radiologist has only the magnetic resonance imaging.  \r\nOn the basis of magnetic resonance imaging a three-dimensional model of renal tumour is constructed. Then the centre of mass is calculated and the two-dimensional image of the area around the centre of mass is used for shape analysis. Landmarks are computed as the intersection of the boundary of the tumour and a straight line in a pre-determined angle from the centre of mass.\r\nThe landmarks describe the shape of the tumours. To get a “pre-shape” the figure has to be centred and standardised. This allows us to compare tumours with different sizes situated in different locations. \r\nThe “mean shape” is the expected “pre-shape” of a group of objects/tumours. The “mean shape” of a group of tumours with a same diagnosis should be able to separate them from tumours with another diagnosis. Tumours with another diagnosis should have a greater distance from the “mean shape” than the tumours whereby the “mean shape” is calculated.    \r\nThe applicability of the \"mean shape\" for separating groups with different diagnosis is tested by the test of Ziezold (1994) and Giebel (2007/2009). Finally, we present the three-dimensional landmarks and tests for identifying relevant landmarks to separate the different types of tumours. Furthermore we will classify the tumours accorrding to the three dimensional data.\r\n", :title "Application of Shape Analysis on Renal Tumours and Classification", :keyword2 "Renal tumours", :authors (23449), :session 16}, 298 {:keyword1 "Semidefinite Programming", :keyword3 "Polynomial Optimization", :abstract "To solve a system of nonlinear differential equations numerically, we formulate it as a polynomial optimization problem (POP) by discretizing it via a finite difference approximation. The resulting POP satisfies a structured sparsity, which we can exploit to apply the sparse semidefinite programming (SDP) relaxation of Waki, Kim, Kojima and Muramatsu to the POP to obtain a roughly approximate solution of the differential equation. More accurate solutions are derived by additionally applying locally convergent optimization methods as sequential quadratic programming. The main features  of this approach are: (a) we can choose an appropriate objective function, and (b) we can add inequality constraints on the unknown variables and their derivatives, in order to compute specific solutions of the system of differential equations. Fine grid discretizations of differential equations result in high dimensional POPs and large-scale SDP relaxations. We discuss techniques to reduce the size of sparse SDP relaxation. One is based on transforming a POP into an equivalent quadratic optimization problem. Another one is a primal standard form SDP relaxation exploiting so called domain-space sparsity, which complements the dual standard form SDP relaxation exploiting correlative sparsity by Waki et al. Finally, we apply this approach to solve examples of nonlinear differential equations with non-smooth solutions. Thus, we can approximate the solutions of challenging non-smooth problems by solving a sequence of convex programs.", :title "Sparse semidefinite programming relaxations for differential equations with non-smooth solutions", :keyword2 "Large Scale Optimization", :authors (19122 6982), :session 84}, 305 {:keyword1 "parameterization", :keyword3 "disaggregation", :abstract "Sub-scalar parameterization in a simulation model refers to the method of substituting processes that are too small-scale or complex to be physically represented in the model by parameters. A typical example for a sub-scalar parameterization is the representation of clouds in climate models. Unfortunately, not all of these parameters can be measured directly (as an average percentage of cloud covering, for example). Hence, it is often necessary to calculate sub-scalar parameters (for the primary simulation) using additional models, like special small-scale simulations (secondary simulations). In this case, the whole approach is a variant of multi-level modeling and simulation, in which the interface between the simulation models of different resolution is limited to single parameters. In many applications a dynamic exchange of data between primary and secondary simulation during runtime is necessary: Data produced during a simulation run of the aggregated model has to be transformed or “disaggregated” for the high-resolution model (and vice versa). The high-resolution model iteratively calculates new parameter values using information from the aggregated model.  Using such an approach in the climate example, the secondary model would calculate cloud distributions on the basis of simulation results from the primary climate model (e.g. based on global or local average temperatures). However, there is a certain amount of inherent uncertainty in the data flow from aggregated to a high-resolution models. If the output of the secondary high-resolution model is highly sensitive to this uncertainty, sub-scalar parameterization is at least questionable. The paper illustrates this challenge by examples, and sketches a way of dealing with it in decision making.\r\n", :title "Sub-scalar parameterization in aggregated simulation models ", :keyword2 "multi-level modeling", :authors (26180), :session 168}, 306 {:keyword1 "Multi-Attribute Choice", :keyword3 "Structural Heterogeneity", :abstract "In this paper, I propose an application of the GNL model for the product choice model at the level of the stock-keeping unit (SKU). Usually, the Nested Logit (NL) model is used for expressing similarity (i.e. heterogeneity) among alternatives of the discrete choice model, which relaxes the independence from irrelevant alternatives assumption and considers similarity among alternatives within the same nest. Such heterogeneity of brands or products is defined as “Structural Heterogeneity” in marketing science. However, the NL model can formulate the structure nested by only one attribute, which means that it cannot express complex heterogeneity among multi-attribute products. It could be accomplished by the cross-nested logit (CNL) model and the Generalized Nested Logit (GNL) model. The CNL model and the GNL model are a kind of extensions of the NL model. They are employed on expressing complicated relationship among alternatives of route or mode choice problems in the field of the transportation planning. By applying the GNL model for the product choice model at the level of the SKU, it is possible to express systematically complex heterogeneity among multi-attribute products which cannot be expressed with the NL model.\r\nAdditionally, I prove the GNL model can express the compromise effect which is inconsistent with utility maximization. Since the GNL model belongs to the general extreme value (GEV) family (see Wen and Koppelman, 2001), it is possible that the compromise effect occurs under utility maximization. \r\nThe last, I conduct an empirical analysis with scanner panel data of actual product lines (plastic bottle cokes). In this analysis, I demonstrate superiority of the GNL model to the NL model and the Multinomial Logit Model in actual reproduction.\r\n", :title "A Multi-Attribute Choice Model: An Application of the Generalized Nested Logit Model at the Stock-Keeping Unit Level", :keyword2 "Nested logit Model", :authors (26181), :session 226}, 310 {:keyword1 "Agent-based Simulation", :keyword3 "Alternative Powertrains", :abstract "Regulatory requirements concerning CO2 emissions of passenger cars as well as the expected scarcity of crude oil force car manufacturers to increase the fuel economy of new passenger cars. One promising measure is the introduction of alternative powertrains, which leads to an increasing number of powertrains available to manufacturers. With regard to long range vehicle portfolio planning these powertrains have to be assigned to different vehicle classes, leaving manufacturers with a high variety of portfolio options. Each option comprises decisions on the powertrains to be offered in a specific vehicle class at a certain point in time. The challenge is that the suitability of alternative options is both influenced by aggregated long term effects like infrastructure and technology development as well as by specific purchase decisions on short notice. Moreover, both effects are interdependent.\r\n\r\nThe aim of this contribution is the development of a simulation-based decision support for the economic and environmental assessment of different vehicle portfolios. Special focus is given to the introduction of alternative powertrains as well as the integrated analysis of long term development processes and detailed purchasing behavior. To this end, we propose a simulation model, which integrates System Dynamics and Agent-based Simulation. System Dynamics is utilized to consider diffusion processes of new powertrains based on long term effects. Agent-based Simulation provides the opportunity to incorporate detailed purchasing behavior based on customer and vehicle characteristics, which are influenced by the long term effects. This way considering the competition between powertrains and vehicle classes as well as diffusion processes based on customer behavior becomes possible.", :title "SIMULATION-BASED DECISION SUPPORT FOR THE INTRODUCTION OF ALTERNATIVE POWERTRAINS", :keyword2 "System Dynamics", :authors (17364 13503 2651), :session 166}, 313 {:keyword1 "Decision Support", :keyword3 "Waste Management Logistics", :abstract "By directive of the EU existing substances like glass waste have to be collected, recycled and commercialized as secondary raw materials. While the value of these substances is small, the expenses for recycling and transportation are considerable. Therefore waste management organizations are interested in minimizing their expenses for this process. For the case of deterministic input data a generalized two-stage assignment and transportation model for this real-world problem has been presented before. This model has been integrated into a custom-made DSS, and generates substantial savings for the waste management organization.\r\nIn this talk we highlight the impact of uncertainty in input data for the problem under consideration. Furthermore we present an adaption of the previous model, which is able to cope with this kind of uncertainty. Finally we present computational results for the new model, and discuss the benefits of considering uncertainty.", :title "The impact of uncertainty in Decision Support for waste management organizations", :keyword2 "Uncertainty", :authors (22897), :session 205}, 315 {:keyword1 "Participatory decision-making", :keyword3 "Proactive risk management", :abstract "Decision-makers face two major challenges when managing environmental risks.  Firstly, risk management decisions frequently involve trade-offs among complex and often competing environmental, social and economic objectives with potential consequences for various societal groups.  Secondly, scientific and economic understanding of these risks is marked by profound uncertainties.  When combined, these challenges too often become excuses for reactive risk response policies, as opposed to proactive risk mitigation strategies.  \r\n\r\nIn this paper we have put forward Deliberative Multi-Criteria Evaluation (DMCE) as a new and promising model to manage environmental risks proactively in the face of complex social values and profound uncertainty.  DMCE places a special emphasis on deliberation in the assessment of complex multi-dimensional objectives.  This approach provides an opportunity for diverse views to be incorporated within the decision-making, and provides a vehicle for consensus-building.  In addition, DMCE serves as a platform for risk analysts, stakeholders, and decision-makers to interact and to discuss the uncertainty associated with ecological process and risk analysis.  We examine two case studies that demonstrate how DMCE facilitates decision-making in risk management. Although both studies are related to invasive species management, we believe this approach can be applied to other areas in environmental management.  \r\n\r\n", :title "Using a participatory and structured decision-making approach to incorporate uncertainty and social values in managing bio-invasion risks", :keyword2 "Multiple social values", :authors (26338 26348 26349), :session 133}, 316 {:keyword1 "Dominance based Rough Sets Approach", :keyword3 "Business IT Value", :abstract "Questionnaires are a frequently used approach in social science research to collect data. Although a wide range of stochastic methods support the analysis of these data a sound analysis still remains as challenging as important, especially when the obtained data are of ordinal nature (or categorical). In our study, we utilised a data-driven approach called Dominance based Rough Sets Approach (DRSA) to induce rules between study factors (independent variables) and outcome factors (dependent variables). This approach was applied to analyse the impact of information technology on the business value of organisations. The survey dataset was collected by the Australian Department of Communications, Information Technology and the Arts among Australian companies of different size and industries. There were a total of eleven organisational factors (as independent variables) on ordinal scales (from 1 to 10) and four business value outcome factors (as dependent variables) on ordinal scales (from 1 to 5). The survey data were represented as a decision table. We argue that DRSA is a suitable method for survey data analysis due to its ability to induce rules from decision tables containing ordinal data. The DRSA method has been shown successful in diverse fields of research like CRM. Our objective was to apply DRSA to analyse data from large and complex questionnaire data such that results can be presented as interpretable rules. In our case study we were able to discover interesting rules to disclose the associations between organisational configurations and their impacts on different dimensions of business value. Our results have demonstrated the potential of DRSA to enrich the analysis of data collected from survey questionnaires which is commonly used in social science research.", :title "Analysing Questionnaires by Dominance based Rough Sets Approach – A Case Study in the field of Social Science Research", :keyword2 "Questionnaires ", :authors (18460 18630), :session 125}, 317 {:keyword1 "Multi-dimensional impacts", :keyword3 "Invasive alien species", :abstract "There are two issues at the core of invasive species risk management: on the one hand, decision-makers struggle to balance environmental goals against other often competing societal goals such as economic benefits and social welfare; on the other hand, uncertainty often prevails in understanding the invasion process and in communicating invasion risks to the stakeholders.  In this paper, we describe how an integrated Deliberative Multi-Criteria Evaluation (DMCE) and fuzzy set approach can tackle these two issues in the analysis of alternative risk management strategies, using the example of European House Borer (EHB, Hylotrupes bajulus Linnaeus).  The DMCE offers a platform for stakeholders to interact and to make a trade-off decision between multiple goals based on social learning and deliberation.  The fuzzy set approach, applied within a DMCE framework, explicitly incorporates the inherent uncertainty in both the science in estimating potential EHB impacts and DMCE participants’ subjective preferences in the evaluation process.  This integrated method therefore provides a promising approach for tackling the dual challenges of competing goals and uncertainty in the evaluation of invasive species risk management options.  ", :title "Using an integrated fuzzy set and deliberative multi-criteria evaluation approach to facilitate decision-making in invasive species management", :keyword2 "Group decision-making", :authors (26338 26347), :session 234}, 318 {:keyword1 "machine scheduling", :keyword3 "IP models", :abstract "This paper focuses on single machine scheduling subject to machine deterioration. The current maintenance state of the machine is determined by a maintenance\r\nlevel. While jobs are processed this maintenance level drops by a certain, possibly job-dependent, amount. A maintenance level of less than zero is associated with the machine's breakdown and is, therefore, forbidden. Consequently, scheduling maintenance activities raising the maintenance level may become necessary once in a while. We provide IP model for two types of maintenance activities and common scheduling objectives and discuss strengths and weaknesses of different model formulations.", :title "IP models for the scheduling of flexible maintenance activities on a single machine", :keyword2 "maintenance", :authors (5838), :session 152}, 319 {:keyword1 "EU driver regulations", :keyword3 "pickup and delivery problem", :abstract "We consider an extension of the classical pickup and delivery problem with time windows (PDPTW), in which driver activities and vehicle stops for refueling are to be planned in addition to the usual routing and scheduling activities for a set of customer orders. The problem is motivated by the business requirements of a long-haul freight transportation company operating in Europe. New legislation issued by the European Union on driving and rest periods has put increased pressure on the company to plan driver activities. Moreover, fuel cost has also become a critical factor as prices vary significantly across different countries in Europe. The integration of both issues – driver rest time scheduling and refueling policies – into the PDPTW has not been addressed so far in the literature. Due to the computational intractability of the problem at hand, we propose a sequential approach to find good solutions for the special case of a single vehicle. In the first phase, the optimal sequence of pickup and delivery locations is determined along with driving hours and rest periods for the driver. In addition, enough slack time for vehicle refueling is considered while generating such a route. In the second phase, an optimal refueling plan is determined. To this aim, a new model is proposed to identify the gas stations the driver is expected to choose, as well as the amount of fuel to purchase. Taking advantage of attractive fuel prices, the time needed for detours to access the chosen gas stations has to be considered as compliance with customer time windows has top priority. The objective is to minimize the total cost of refueling while preventing the quality of the initial route from declining. Tests about the applicably on real world problems will be presented.", :title "A new approach for long-haul freight transportation considering EU driver regulations and vehicle refueling policies", :keyword2 "refueling", :authors (23455 1256 15127 26342), :session 201}, 320 {:keyword1 "Perspective cuts", :keyword3 "Stochastic Programming", :abstract "The electric market regulation in Spain (MIBEL) establishes the rules for bilateral contracts in the day-ahead optimal bid problem. Our model allows a price-taker generation company to decide the unit commitment of the thermal units, the economic dispatch of the bilateral contracts between the thermal units and the optimal sale bids for the thermal units observing the MIBEL regulation. The uncertainty of the spot prices is represented through scenario sets. We solve this model as a deterministic MIQP problem by using perspective cuts to improve the performance of Branch and Cut. Numerical  results are reported.\r\n", :title "Solving electric market problems by perspective cuts", :keyword2 "Electric market", :authors (15051 5708), :session 99}, 321 {:keyword1 "", :keyword3 "", :abstract "Decision aiding in a complex situation implies understanding the elements of complexity and uncertainty that make the decision difficult or impossible,in order to limit or control them.A multidimensional and integrated analysis of the complexities should indicate which approaches and methodological have to be used to cope with specific criticalities and uncertainties.The PhD-project starts from an industrial project,which aims at creating a new \"advanced system to monitor the territory\".In order to design a monitoring system that integrates new unmanned aerial vehicles,UAV,all the requirements have to be identified and analyzed from the points of view of the stakeholders.One of the main complexities is that a decision context that involves the potential users of this system does not exist.It is therefore import to identify and clarify the possible roles and relationship of the organizations that should be involved as potential users in the product innovation process.It is also important to recognize and reduce the uncertainty about the correct acquisition of their different points of view, at both individual and organizational level.In addition it is essential to organize the acquired knowledge and information elements, not only to produce a list of functional requirements, but also to support the design process.All the processed information is fundamental in order to identify the technological, organizational and economic constraints that limit the generation of design alternatives and the criteria that should be used to test the performances of the UAV platforms and the technologies that acquire data from the territory in relation to monitoring aims.Network analysis and cognitive mapping are used and integrated with multicriteria analysis and mathematical programming.", :title "An integrated use of tools to identify and face the main complexities ", :keyword2 "", :authors (23560 23417), :session 180}, 323 {:keyword1 "Supply chain coordination", :keyword3 "Wholesale price contract ", :abstract "Coordinating the decisions of individual businesses in a supply chain (SC) can reduce efficiency losses which occur when companies solely act towards individual optimization. Incentives which ensure that all parties benefit from coordination can be set through contracts containing parameters of transfer payments such that no party is worse off than before. From research on SC coordination in many decision fields we know that a simple wholesale price (WP) contract will not enable coordination due to the so-called double marginalization effect. In this context, SCs with stochastic yield on the supplier side, however, have almost been ignored in research so far. \r\nIn this research a manufacturer-retailer SC is considered where the manufacturer’s production is exposed to random yield so that the retailer faces a stochastic fulfillment level of his order. Putting the respective inventory control problem into a game-theoretic context, it can be shown that in case of deterministic end customer demand the WP contract fails to achieve coordination under stochastic yield. If the manufacturer, however, is able to compensate yield losses by rework or a more costly, but reliable production mode the analysis reveals that the WP contract is able to coordinate. Interestingly, this coordination property gets lost again if customer demand is stochastic. Thus, it turns out that in the case of yield randomness the coordination power of the WP contract very much depends on the specific SC environment. This aspect will be analyzed in detail. ", :title "The effects of wholesale price contracts for supply chain coordination under stochastic yield", :keyword2 "Stochastic yield", :authors (26317 2801), :session 112}, 324 {:keyword1 "Balanced Scorecard", :keyword3 "Efficiency", :abstract "Today, Balanced Scorecard (BSC) is the instrument of choice to implement strategies. Empirical studies using surveys underpin the dissemination by asking respondents but are not able to elicit actual efficacy. Therefore researchers started to use experiments backed up by System Dynamics-based management flight simulators. The experiments showed that BSC users gained a better understanding of underlying strategic situations and contexts and, based on that, made better and more profitable decisions. \r\nHowever, experiments speed up critical processes of implementing actions, feedback and the like. They omit important aspects of real companies like delays, time to learn or various degrees of efficacy of actions. Inferring from such experiments to the reality is highly questionable. We conclude therefore that the efficacy of BSC is still open to question.\r\nIn this paper a generic System dynamics model is build to capture and understand the cause and effects of effectiveness of BSC as a first step. It includes variables for the BSC components, performance measures as well as delays, learning effects and weakening of measures and actions. The simulations highlight the drivers of efficacy of BSC, most prominently various delays and time lags between implemented actions and learning from their results.\r\nIn a second step, the model helps to clarify what empirical information is needed to ground the model – and BSC - in a real context. Different industries, different companies with different strategies face different delays, feedback structures and possibilities to learn. Further empirical research should explore specific values of the parameters mentioned above. With such data we will be able to provide valid evidence of BSC efficacy. \r\n", :title "Effectiveness of strategy implementation with Balanced Scorecard – a System Dynamics Approach", :keyword2 "System Dynamics", :authors (26210), :session 44}, 325 {:keyword1 "Learning Software ", :keyword3 "Education", :abstract "In this contribution we present a new interactive learning concept for modern Operations Research education and training methods. We will focus on specific topics like linear, nonlinear, discrete optimization, multiple criteria decision making, especially game-theory and crisis management. The electronic platform offers the possibility to distinguish between theoretical presentations, examples, exercises, so-called “test-exercises with planned errors” and comfortable comparative analysis techniques [1].\r\n\r\nRealization of training elements is carried out by means of special mathematical applets (written in Java) which give the chance to document the learning process of the students. How do they get a solution? How will the decision process be developed and characterized? Key element is the combination of analytical expressions and geometrical images. Such an attempt increases the speed of an information transfer within lecturer and student. Furthermore it raises the level of the underlying understanding processes. The software contains a lot of instruments of actual knowledge management techniques related to Operations Research Methods. Main focus is the individual use and the integration of distance/ blended learning elements.\r\n\r\nThe interactive elements are worked-out examples and interactive personalized exercises. The presented approaches avoid routine calculations and solves a visualization problem with a high amount of creative activity at the expense of prevalence cognitive approaches of the representation of knowledge.\r\n\r\nReferences:\r\n1. Izhutkin V.,Toktarova V.. Principles of construction and realization of training systems on numerical methods // Educational Technology & Society 9(1) 2006, ISSN 1436-4522, P. 397-410.\r\n", :title "An Interactive Learning Software for Modern Operations Research Education and Training", :keyword2 "Operations Research ", :authors (16938 4796), :session 86}, 328 {:keyword1 "Inventory model", :keyword3 "", :abstract "In many hospitals the supply of medical consumables like plaster, bandages, syringes and the like is organized as follows. For each type of medical consumable an external supplier delivers requested goods to a central warehouse of the hospital from where they are transferred to the demanding wards. At the wards the materials are consumed to serve the patients, seen as a set of anonymous customers. This leads to a divergent two-stage inventory system with articles being stored centrally at the warehouse and locally at the affiliated wards. Although the security of supply requires priority in the medical sector, experts suppose that a good portion of stocks is actually unneeded. \r\nWe focus on the development of suitable replenishment policies for the sketched inventory system. For the second stage of inventory holding, the ward storages, a replenishment policy is designed which allows for the compliance of a preset service level. The used inventory policy is described by a periodic review, order point, order quantity model, also referred to as (r,s,q) model. To extend the view beyond the supply of the wards, it is next steps purpose to integrate the first stage of inventory holding, the hospital’s central warehouse, into the model. Since shortages can occur at the central warehouse, additional waiting time must be taken into account which increases in turn the order lead time of the wards. The inventory policy for the central warehouse supply is implemented by an (r,s,nq) model.", :title "Inventory models for the supply of medical consumables in hospitals", :keyword2 "Hospital logistics", :authors (17093 14707), :session 138}, 329 {:keyword1 "multi-agent-system", :keyword3 "cooperative transportation planning", :abstract "In this talk, we discuss a cooperative transportation planning setting that can be found in the German food industry. Several companies try to cooperate by sharing their distribution network to reduce transportation cost. This leads to a transportation planning problem that includes rich vehicle routing problems (VRPs). Orders for delivery can be shipped between different depots. An outsourcing option exists for orders that cannot be transported on-time using vehicles of the companies. Arrivals of new orders, vehicles break downs, and delays of the vehicles have to be taken into account during decision-making.\r\nWe describe a prototype of a distributed hierarchically organized decision-support system. The overall problem is decomposed into several sub problems by the top-level. VRP type sub problems are the result. These sub problems are solved on the base-level by heuristics. An iterative scheme is proposed that modifies the decomposition by the top-level based on the decisions of the base-level. The decision-support system is implemented as a multi-agent-system. We differentiate between decision-making and staff agents. The identification and the design of the agents are described. Results of a simulation-based performance assessment of the multi-agent-system are presented.", :title "A Multi-Agent-System Approach to Cooperative Transportation Planning", :keyword2 "vehicle routing problem", :authors (17112 14225), :session 126}, 331 {:keyword1 "Multi Objective Evolutionary Algorithms", :keyword3 "Hot and Cold Spots", :abstract "The spatial distribution of events is a well known operational problem. A classical method is that of Poisson while the current standards are the Local Indicators of Spatial Aggregation (LISA) models and the Bayesian Conditional Autorregresive Model (CAR). The problem arises when the results obtained using some of these models show different spatial patterns. A group of spatially close spatial units that shows a similar pattern is called a hot spot (the prevalence is significantly high) or a cold one (significantly low). Note that our purpose is to identify spatial areas instead of particular spatial units. These areas will be identified and located through the evaluation of the degree of agreement between LISA and CAR scores. The objective is to identify and locate hot and cold spots for selected illnesses. LISA methods are carried out to evaluate local autocorrelation scores. The CAR model is used to evaluate Bayesian-based risk. A Multi Objective Evolutionary Algorithm (MOEA) is used to evaluate the degree of agreement. QQ-Plots are finally used to identify hot and cold spots. A Geographic Information System is then used to locate them in the space. Study case: Spatial prevalence of schizophrenia and depression in a large region (Andalusia, Spain). The spatial units are the municipalities (770), the highest spatial precision. Results: Both hot and cold spots have been identified and spatially located on maps. The results obtained using four MOEA strategies to evaluate the fitness function are analysed and compared. Our procedure is a robust method to identify both hot and cold-spots in the space and can be useful to organize the spatial distribution of health-care services.", :title "Spatial identification of hot and cold spots for the prevalence of schizophrenia and depression", :keyword2 "Spatial Analysis", :authors (6218 26355 26356), :session 139}, 333 {:keyword1 "Illiquidity and Asset Pricing", :keyword3 "Monte-Carlo Simulation", :abstract "Many important asset classes are illiquid in the sense that they cannot be traded. When including such illiquid investments into a portfolio, portfolio decisions take on an important dimension of permanence or irreversibility. Using a continuous-time model, this paper shows that this irreversibility leads to portfolio proportions being stochastic variables over time as they can no-longer be controlled by the investor. We study the continuous-time system in terms of its asymptotic behavior and show that portfolio proportions converge to long-run equilibrium or steady-state distributions over time. Stochastic portfolio proportions have major implications since they change portfolio dynamics in a fundamental way. First, it is shown that stochastic proportions implied by illiquidity increase overall portfolio risk. Interestingly, this effect gets more pronounced when the return correlation between the illiquid and liquid asset is low, i.e., illiquidity costs of a portfolio, as measured by the increase in portfolio risk, are inversely related the the return correlation of the illiquid and liquid assets. Second, the paper illustrates that illiquidity also affects the choice of an optimal portfolio. Particularly, it is shown that a traditional mean-variance approach that assumes that portfolio proportions can be kept constant over time leads to biased results when applied to portfolios that consist of liquid and illiquid assets. Third, the paper extends the model to an equilibrium setting and derives a novel liquidity-adjusted CAPM. This valuation framework shows that stochastic portfolio proportions give rise to a new form of systematic risk. The additional premium investors require for this systematic risk could be regarded as a compensation for a form of liquidity risk.", :title "New Insights on Asset Pricing and Illiquidity", :keyword2 "Stochastic Modeling and Steady-State Equilibria", :authors (26351), :session 74}, 334 {:keyword1 "Revenue Management", :keyword3 "Dynamic Programming Decomposition", :abstract "In recent years, opaque selling has evolved into a popular instrument of price discrimination used in many service industries. Opaque products are designed in such a way that some of their characteristics are hidden from the customer until after purchase. Prominent examples include Internet-based intermediaries like Hotwire and Priceline, which sell, for example, airline tickets by disguising details of the service provision like the departure time or the operating airline until the booking has been made. The main benefit of opaque products is the induction of additional low-value demand; however, due to the inherent supplier-driven substitution, the traditional revenue management process changes. \r\nIn this talk, we therefore propose a capacity control approach that allows opaque products to be incorporated. Our approach is based on the well-known dynamic programming decomposition that is widely used for traditional revenue management – in theory as well as in commercial software implementations. Analytically, we show that the obtained upper bound on the original dynamic program’s value is tighter than the one obtained by constructing a deterministic linear approximation. Furthermore, we perform computational experiments, using typical airline revenue management scenarios, which show that the developed approach significantly outperforms other well-known capacity control approaches adapted to the opaque product setting.", :title "Revenue Management with Opaque Products", :keyword2 "Opaque Products", :authors (22994 16305), :session 92}, 335 {:keyword1 "Vehicle routing and scheduling", :keyword3 "case study", :abstract "This contribution handles the challenging task of supporting the strategic decision problem of location planning by solving the short-term decision problems of vehicle routing and scheduling for several scenarios resulting from the decisions on the strategic level. By means of a case study the authors show a practical implementation concept for an automotive distribution company. Hereby the aim is to identify one additional location for the current distribution network. The additional location is intended to be used for the reduction of the total transportation costs. In the first step of the location planning process four potential location nodes are identified with the help of the Fermat-Weber problem. In the second step the identified locations are evaluated by analyzing the resulting vehicle routing and scheduling problems. A realistic virtual distribution process for each location is modeled and the location with the lowest value for the expected operational transportation cost is chosen as the solution of the location planning problem. A comparison between the actual and the potential new distribution network shows significant tour and transportation cost savings up to 40% and thus demonstrates that vehicle routing and scheduling can successfully be integrated with location planning to a joint planning process.", :title "A case study for integrating vehicle routing and scheduling in the location planning process", :keyword2 "location planning", :authors (26353 17524 15277), :session 197}, 336 {:keyword1 "emerging markets", :keyword3 "international diversification effects", :abstract "By the progression of the globalization and the increase of emerging markets on international capital markets the number of investment alternatives changes as for private as also for institutional investors. Therefore worldwide the amount of marketable stocks increased from 40.000 in 2004 to 47.000 in 2009 (www.fibv.com). Coherently investors ask for an efficient international asset allocation. International orientated portfolio managers question, which equities of which countries are useful for an international asset allocation. These empirical studies show possible advantages of an international diversification of portfolios from the view of an USD investor. At first we tested all data for normality. Then, the serial correlation in each market is tested for deviation from zero. Then we use the serial correlation adjusted returns for the optimal portfolios. Afterwards, we make a calculation of the optimal portfolios with international markets with historical return estimators as well as with alternative return estimators (Bayes–Stein estimator, CAPM estimator and Black–Litterman estimators). Then, we replace the volatility by the alternative risk measures ((m)VaR, (m)CVaR). Therefore, the paper combines the best-known risk measure, also modified for the skewness and the excess kurtosis, with different estimators for returns. In this manner, influences of the higher moments to the international asset allocation can also be examined in connection with different risk measures and varied estimators for expected returns. ", :title "International Diversification Effects with Emerging Markets", :keyword2 "asset allocation", :authors (12922), :session 142}, 337 {:keyword1 "valuation of options and guarantees", :keyword3 "", :abstract "In contrast to the standard approach of pricing and evaluating options in the financial world, in insurance we typically have no existing market for the underlying. We will show on two examples, namely renewal options in term life products and longevity guarantees in annuity products, what current methods are and how we could establish markets to enable hedging to a certain extend of the risks.", :title "Valuation of options and guarantees in actuarial practice", :keyword2 "hedging in incomplete markets", :authors (26357), :session 154}, 338 {:keyword1 "interest rate derivatives", :keyword3 "", :abstract "Since the beginning of the subprime crisis in early 2008, the pricing of interest rate swaps following the standard text book methods fails in general, depending on the tenor of the floating rate side. The market expresses the difference between tenors by the so-called basis spread. In the same context, the forward interest rates projected by the standard methods are far away from the rates quoted in the market. This talk gives an overview of the valuation of simple linear instruments like forward rate agreements and swaps in times of non-zero basis spreads. The necessary adjustments have a direct practical impact on banks’ valuations of their derivatives.", :title "Valuations under basis spreads", :keyword2 "basis spreads", :authors (26358), :session 154}, 339 {:keyword1 "interest rate models", :keyword3 "", :abstract "In order to valuate insurance liabilities a risk-free interest rate curve and volatility surface has to be chosen. Since there are no deep and liquid markets for the very long maturities Solvency II is using interest rate extrapolation mechanisms. We will present the currently discussed approaches and discuss their effects on the valuation. \r\n", :title "Challenges of interest rate modelling in life insurance", :keyword2 "life insurance", :authors (26360), :session 77}, 346 {:keyword1 "revenue management", :keyword3 "revenue sharing", :abstract "In an alliance, partner airlines are allowed to sell tickets for the same flight. Moreover, the flights may consist of several flight legs, which are operated by different airlines. We consider the problem of how to share the revenue generated from selling a fight ticket among the airlines. In practice, for technical and legal reasons, alliance decisions are not given centrally. Each airline makes capacity allocations individually to maximize its own revenue.  We study several decentralized revenue sharing mechanisms and compare them with the centralized revenue allocations, which are based on cooperative game theory solutions. \r\n", :title "Decentralized Revenue Sharing Mechanisms for Airline Alliances", :keyword2 "airline alliance", :authors (17366 14715), :session 92}, 347 {:keyword1 "Generalized Nash equilibrium", :keyword3 "Computable generalized Jacobian", :abstract "In the generalized Nash game, not only the player's cost function depends on the\r\nrival players' decisions, but also his strategy set.\r\nAmong others, generalized Nash games\r\n appear in models of environmental pollution control,\r\nelectricity markets and internet communication.\r\nHere we compute a solution of the generalized Nash\r\nequilibrium problem through a fixed point reformulation\r\nthat leads to a nonlinear equation. We introduce the computable\r\ngeneralized Jacobian to define a Newton method for the solution \r\nof this nonlinear equation. A result on local quadratic convergence\r\nand numerical results are given.", :title "A nonsmooth Newton method for the computation of a normalized equilibrium in the generalized Nash game", :keyword2 "Nonsmooth Newton method", :authors (19553), :session 84}, 352 {:keyword1 "SIP", :keyword3 "parametric optimization", :abstract "We consider Semi-infinite programming problems P(t) depending\r\non a finite dimensional parameter t.\r\nProvided that x is a strongly stable stationary point of P(t),\r\nthere is a locally unique stationary point function x(t).\r\nThis defines the local critical value function \r\nPHI(t):=f(x(t),t),\r\nwhere f(x,t) denotes the objective function of P(t).\r\nWe show that PHI has finite modulus of concavity,\r\nsaying that it constitutes the sum of a smooth with convex function. \r\n\r\nThis talk is about joint research with H. Günzel, F. Guerra-Vazquez, H.Th. Jongen and J.-J. Rückmann.", :title "SIP: Critical Value Functions have Finite Modulus of Concavity", :keyword2 "strong stability", :authors (26361), :session 84}, 354 {:keyword1 "Revenue Management", :keyword3 "Hierarchical Planning", :abstract "While theoretical revenue management approaches usually assume that capacity is fixed, current practice shows that this assumption in most cases no longer holds. Prominent examples include car rental companies who are able to spontaneously adjust capacity to a certain extent in order to accurately match the market needs. This is usually accomplished by either injecting additional cars into the fleet or by migrating the inventory from one rental station to another. Due to this given possibility of short-term capacity adjustments, a pure revenue-based perspective like in traditional approaches is not valid. Instead, the inventory costs, which in case of car rental companies are mainly driven by the holding costs caused by the cars in fleet, have to be taken into consideration.\r\nIn this talk, we present an approach that incorporates capacity decisions into traditional revenue management’s capacity control. In order to derive capacity decisions, the approach uses a linear programming formulation that can be seen as a straightforward extension of the well-known DLP-model. The model is then used in a hierarchical planning context with a rolling horizon which allows the combination with arbitrary traditional approaches of standard capacity control. We conduct extensive simulation studies based on real-world data from a major European car rental company, which reveal the potential of the approach.\r\n", :title "Revenue Management with Capacity Decisions: A Hierarchical Planning Approach", :keyword2 "Capacity Decisions", :authors (16305 22994), :session 92}, 358 {:keyword1 "GSIP", :keyword3 "Disjunctive Programming", :abstract "We introduce the Nonsmooth Symmetric Reduction Ansatz (NSRA) on the closure of the feasible set cl(M) in GSIP. NSRA is motivated by the description of cl(M) given by infinitely many constraints of maximum-type. Under NSRA cl(M) is proven locally to be the feasible set of a so called Disjunctive Optimization Problem given by finitely many constraints of maximum-type. NSRA includes the well-known Symmetric Reduction Ansatz. The new issue in NSRA is that the Lagrange polytope at the lower level can not be assumed to be a singleton. However, certain ''full-dimensionality'' of its vertices is generically given. We introduce the notion of a nondegenerate Karush-Kuhn-Tucker (KKT) point for GSIP and its GSIP-index. For a generic GSIP we prove that NSRA holds at all KKT points, moreover, all KKT points are nondegenerate. We also show that NSRA is stable at a nondegenerate KKT point. We discuss the consequences of NSRA w.r.t. the critical point theory for GSIP.", :title "Generalized Semi-Infinite Programming: the Nonsmooth Symmetric Reduction Ansatz", :keyword2 "Nonsmooth Symmetric Reduction Ansatz", :authors (20607 8657), :session 63}, 360 {:keyword1 "complex societal problem", :keyword3 "cognitive science", :abstract "Any attempt towards a solution of the complex societal problem of climate change must acknowledge the nature of the human mind, its strengths and weaknesses. Necessary changes in thinking, experiencing, and behavior of individuals and collectives relate to cognition and its interfaces – emotion, motivation, and action. While some skeptics doubt whether knowledge or insight alone may lead to a change in behavior, studies on collective risk social dilemmas show that knowledge does guide subjects’ behavior.  However, behavioral change may succeed only if cognition is properly combined with emotion and motivation. Emotion and motivation can thus become the transmission belt between the otherwise unconnected spheres of knowledge and action. Therefore, it is important to bring our knowledge to bear on our everyday life experience in a relevant way. Otherwise it remains merely abstract or media knowledge. Reversing the direction between action, experience and knowledge and exposing oneself to novel experiences may produce new and more relevant forms of knowledge. Commensurable action, experience, and cognition are necessary for humans to establish new and more sustainable solutions for their own life and the society they (want to) live in. In this respect OR with its systemic approach to the implementation of viable structural solutions on the level of collective institutions can be used as a framework also for the individual. Aspects of well-established methodologies like COMPRAM can also be applied by individuals for the accomplishment of their own conception of life. On the other hand, these methodologies have profited already and might profit further from explicitly incorporating cognitive aspects into their design. \r\n", :title "Cognitive aspects of the complex societal problem of climate change ", :keyword2 "climate change", :authors (18215), :session 22}, 362 {:keyword1 "Vehicle Routing", :keyword3 "Integer Programming", :abstract "Difficult financial situations in most German cities and increasing competition in waste management between private and public companies require an efficient allocation of all resources that are involved in the waste disposal process. The two major resources are collection-vehicles and crews. An ongoing project with two waste disposal companies aims at simultaneously planning the routes of the vehicles and the crew schedules. In this talk we present our integrated optimization approach. Due to the enormous complexity of the problem and of real instances we suggest a decomposition of the overall problem into interdependent (NP-hard) subproblems. For these subproblems we show formulations as Mixed Integer Programs and we compare the computational times of various solution methods and their impact on the quality of the overall solutions. We finish the talk with a presentation of results for large real-world instances.", :title "Integrated Vehicle Routing and Crew Scheduling in Waste Management", :keyword2 "Waste Disposal", :authors (15375 13837), :session 211}, 363 {:keyword1 "Evacuation Planning", :keyword3 "Cellular Automaton", :abstract "Modelling evacuations requires the incorporation of building structure, human behavior and the interrelation between the two. The very nature of evacuations demands that we need to find the best strategy possible - anything less could result in a loss of human life.\r\n\r\nThe challenge now consists in using a model that, on the one hand, is complex enough to model evacuations realistically and, on the other hand, abstract enough to allow the computation of optimal solutions. In order to master this problem, we combine cellular automaton based simulations with network flow based techniques from combinatorial optimization.\r\n\r\nOur cellular automata consist of a grid of cells which can be occupied by at most one human each. The movement of these humans is computed using local rules, allowing for detailed, large scale simulations of evacuations. Using this approach, complex behavior like building knowledge, individual characteristics and psychological effects are taken into account. While optimization is difficult in this setting, it is not when using network based techniques: earliest arrival transshipments are special network flows over time that route flow from multiple source areas to a single sink. The distinctive feature of earliest arrival transshipments is that the amount of flow sent to the sink is maximal at every point in time. In terms of evacuations this means that as many people as possible are saved regardless of the amount of time available for the evacuation.\r\n\r\nWithin our software tool ZET (http://www.zet-evakuierung.de/), we calculate earliest arrival transshipments in order to obtain escape routes for people. The escape routes are then transferred to the simulation and tested. Based on the results of the tests, adjustments can be made to the network underlying the flow computation to improve the results further - this process can be iterated.", :title "Simulation and Optimization of Building Evacuations", :keyword2 "Network Flows over Time", :authors (26250 26365), :session 219}, 370 {:keyword1 "Kapazitätszuteilung", :keyword3 "Notfälle", :abstract "Durch die Einführung von Fallpauschalen im deutschen Gesundheitssystem ist die Planung einer ausgewogenen Ressourcenverwendung im Krankenhaus von besonderem Interesse. Unsicherheit herrscht insbesondere im Zusammenhang mit dem Eintreten und der Dauer von Notfallbehandlungen. Für Entscheidungsmodelle zur Ermittlung optimaler OP-Schedules werden in der Literatur verschiedene Ansätze zur Berücksichtigung von Notfallzeiten vorgeschlagen. Die durch das Krankenhaus zu gewährleistende Versorgungssicherheit erfordert insbesondere in Operationssälen die Möglichkeit, flexibel auf zufällig auftretende Notfälle reagieren zu können. In der Literatur werden unterschiedliche Kriterien zur Unterstützung einer Belegungsplanung für Operationssäle vorgeschlagen. Bei der Modellierung wird meist eine stochastische Nachfrage nach Behandlungskapazität angenommen.\r\n\r\nZur Planung einer flexiblen OP-Saal-Belegung müssen neben der Berücksichtigung von Notfällen auch zusätzliche Anforderungen, die durch Ansprüche verschiedener Gruppen wie z.B. Patienten oder Beschäftigte entstehen, beachtet werden. Ausgehend von einem stochastischen LP-Modell werden systematische Erweiterungen vorgestellt, die vor dem Hintergrund dieser multikriteriellen Anspruchsgrundlage diskutiert werden. Anhand einer beispielhaften Bestimmung flexibler Belegungen eines Operationssaals wird die Eignung verschiedener Kriterien und Modellierungsmöglichkeiten in Entscheidungsmodellen diskutiert. Die unterschiedlichen Modellierungsansätze werden im Hinblick auf Zielerreichungsgrade einzelner Anspruchsgruppen evaluiert.", :title "Multikriterielle Optimierung flexibler Kapazitätszuteilung in Krankenhäusern", :keyword2 "Robustheit", :authors (17358 10057), :session 37}, 372 {:keyword1 "software presentation", :keyword3 "teaching OR", :abstract "AIMMS is a mathematical modeling system that enables fast development of advanced optimization models and convenient deployment of these models to end-users. In this presentation we will introduce the key components of the AIMMS software. \r\n\r\nFirstly, the intuitive modeling environment enables you to quickly define and modify mathematical models. Secondly, data can be exchanged with text files, XML, Excel, ODBC and OLE DB. Next, AIMMS offers links to many solvers (such as XA, CONOPT, CPLEX, GUROBI, Xpress, BARON, etc) and procedures such as stochastic programming, Benders decomposition, Robust Optimization, and MINLP outer approximation. And finally, you can use the integrated visualization tools to construct a GUI around the model, or you can integrate your model via the COM object, API, programming language interfaces, or WebServices.\r\n\r\nWe will illustrate with industry cases how AIMMS is used to develop successful OR applications for complex business problems. We will also illustrate how universities use AIMMS to teach Operations Research effectively, focusing students on problem analysis, model formulation and interpretation of results.\r\n\r\nTo experience AIMMS hands-on yourself, you can participate in the short AIMMS Tutorial that we offer for free later during the conference. ", :title "Model development & deployment with AIMMS", :keyword2 "modeling language", :authors (10297 10929 19332 19332), :session 104}, 374 {:keyword1 "Railway", :keyword3 "Planning", :abstract "OR applications can bring benefits in many areas in society and business, and we\r\nfocus on enabling such  successful OR applications. As an example, this\r\npresentation will discuss an application in railway track  inspection and\r\nmaintenance.\r\n\r\nOn the railroad network in the Netherlands, every switch must be inpected once\r\nevery 2, 4, or 13 weeks. Before 2008 this was done by people visiting each\r\nswitch. With the introduction of the Video Inspection Train (VST)  in 2008 the\r\nefficiency of this task was improved: instead of people phyiscally visiting each\r\nswitch, now the VST drives over all switches and makes  a video of them. The\r\ninspection can then be performed by looking at this video.\r\n\r\nTo inspect the switches, a route needs to be planned for the VST that visits all\r\nswitches at least twice, once for each possible position of the switch. This\r\nplan must be efficient, because the  less time required for inspection of the\r\nswitches, the more time the tracks are available for regular train services. \r\nPossible requirements for the plan are that certain tracks cannot be used and\r\nthat certain switches must be checked within given time windows.\r\n\r\nOriginally, the problem of determining the inspection tours was solved by hand.\r\nIn 2009 the  AIMMS Service Partner CQM developed a model in AIMMS that solves\r\nthis problem via mathematical optimization and  provides efficient plans for the\r\ntrain to visit all switches at least twice.\r\n\r\nWhen comparing the new approach to the manually created plans for a part of the\r\nNetherlands,  the new plans require only half the amount of time to inspect an\r\neven larger number of switches. In 2010, the new approach will be implemented\r\nfor the complete network of the Netherlands.", :title "Planning routes for the Video Inspection Train", :keyword2 "AIMMS", :authors (19332), :session 207}, 376 {:keyword1 "Integer Programming", :keyword3 "Core Problem", :abstract "We consider P-median problems with an additional constraint on the assignment variables. This kind of problem arises when one applies the epsilon constraint method to bi-objective P-median problems. Since the P-median problem is NP-hard, the addition of a restriction maintains its complexity and one must turn to heuristic algorithms, at least for problems above a certain size. \tIn this paper we develop four kinds of heuristic algorithms. First, by employing Lagrangian relaxation methods, we design a very efficient LARAC-type heuristic (Lagrangian Relaxation Based Aggregated Cost), based on resolving heuristically a series of unrestricted P-median problems. Second, we develop both exact and heuristic methods to complete a solution with the assignment variables given any solution for the location variables. The algorithms are based on the multiple choice knapsack problems and the LARAC method. This allows us to design multistar complete heuristics, as well as GRASP heuristics. Lastly, we have designed exchange heuristics which extend the well-known Teitz-Bart and Whitaker heuristics to the case of an additional constraint. Thirdly, using the resulting Lagrangian reduced costs, we define a Core problem which can be efficiently resolved by fixing variables and the Branch-and-Cut algorithm. Finally, we compare the computational efficiency of the various methods by applying them to a variety of problems of diverse sizes.", :title "P-Median problems with an additional constraint on the assignment variables", :keyword2 "LARAC Heuristic", :authors (26373 26371), :session 214}, 377 {:keyword1 "Markov model", :keyword3 "stroke", :abstract "In western industrialized countries, stroke is the third most common cause of death as well as the main reason for significant long-term disability and high health care treatment costs. Because specialized stroke care cannot be offered in rural areas different telemedical concepts were implemented worldwide. Clinical studies have shown improvement of telestroke patient outcome but have hitherto failed to include economic aspects. This is one reason why third party payers hesitate to include telemedical treatment into their billing system. The objective of this study was to develop a model that allows the evaluation of medical and economical aspects in telestroke care jointly. Additionally, the model should build on a data structure, which is available for all networks and so allows a comparison among them. The results should demonstrate third-party payers their value-creation potential and thus give a basis for the calculation of an economic based price for telestroke care. Based on a comprehensive literature review and expert interviews with neurologists, third-party payers and health care economists, a Markov model was developed from the third-party payer's perspective. The medical outcome of patients is measured by care level. The majority of the cost and effect data for the model can be extracted from the data base of health insurance funds. Due to the reason that the number of stroke patients and thus the healthcare costs for stroke care will continuously rise the outcome of the evaluation of different telemedical concepts is of importance to give further recommendations for healthcare planning. Besides the results will show the potential cost-savings for different third-party payers and so might offer a basis for a dialog on cost sharing.\r\n\r\n \r\n", :title "A Model for Telestroke Network Evaluation", :keyword2 "telemedicine", :authors (26372 26774 26775), :session 137}, 378 {:keyword1 "structured microfinance", :keyword3 "survey", :abstract "We study the perspectives and develop a quantitative model for structured microfinance instruments, which have suffered as a result of the financial crisis of 2008/2009. A survey addressed to relevant world-wide experts on microfinance shows that structured instruments are still regarded as an important means for refinancing microfinance institutions in the future. \r\nIn a second step we introduce a quantitative credit risk model that takes into account the peculiarities of microfinance institutions and can be used for pricing purposes and analyzing the risk inherence in different tranches of a structured microfinance vehicle. Additionally we introduce an innovative pricing methodology that abstains from using the martingale probability measure. This approach seems more appropriate for illiquid securitized debt of microfinance institutions. In a realistic application we check the robustness and demonstrate the advantages of the model presented.", :title "Perspectives and a Quantitative Model for Structured Microfinance", :keyword2 "MC based pricing", :authors (26331 9578), :session 96}, 379 {:keyword1 "procurement", :keyword3 "stochastic programming", :abstract "In recent years managing risk in supply chains became an important issue, especially in the procurement of materials. Traditional approaches which focus solely on improving cost efficiency and reducing inventory decrease the flexibility of supply chains to adapt to changes and make them more vulnerable in turbulent business cycles. In this work, we consider a mid-term procurement decision problem where a buyer can choose among various long term and short term contracts from multiple suppliers while facing both demand and supply uncertainty. The objective is to minimize expected total supply cost over the planning horizon by deciding whether to purchase long term contracts now or short term contracts later when more information is available. By long term contracts the buyer and supplier can agree on a huge amount of quantities to low price. Whereas by short term contracts the buyer can adjust the quantities required from available markets. In addition to both type of contracts we also allow suppliers to offer option contracts, in which the buyer get the right but not the obligation to buy a certain amount of quantities in future for a pre-defined price. Similar to methods from modern portfolio theory we optimize the procurement by combining supply contracts into portfolios in order to reduce costs and to mitigate risk. We model our sourcing problem as a Stochastic Linear Programming Model and make use of Mixed Integer techniques to capture typical quantity discounts of long term contracts. Furthermore, we show that our generic model can consider a variety of contracts seen in practice such as quantity flexibility contracts with a minimum and maximum quantity to buy from a specific supplier. Finally, we evaluate our model by numerical examples.", :title "Optimizing procurement portfolios to mitigate risk in supply chains", :keyword2 "supply contracts", :authors (26280 9272), :session 109}, 380 {:keyword1 "comparative genomics", :keyword3 "genomic signature", :abstract "Background: Hidden genomic structures may hold the key to understanding functional and evolutionary aspects of sequential DNA attributes. Such structures can also provide the means for identifying and discriminating organisms using genomic data. All kinds of genomic signatures appear to be useful in evolutionary analysis. Results: We have analyzed genomic sequences of eukaryotic chromosomes using linguistic complexity. We confirm the existence of a taxa specific distribution of linguistic complexity around start of translation (LC profile). A distance measure based on these profiles reflects the phylogenetic relationships between genomic sequences. We use this distance measure to clustering eukaryotic chromosomes of 11 species. Conclusion: LC profiles of eukaryotic DNA sequences prove to be taxa specific and easy to compute. The structure of LC profiles is conserved, mirroring typical genomic properties of regulatomes. This kind of genomic signature can be used to visualize and strengthen genomic differences and for biological classification.", :title "Genomic Clustering Based on Linguisitic Complexity ", :keyword2 "sequence complexity", :authors (9122 8923), :session 32}, 381 {:keyword1 "condition-based maintenance", :keyword3 "simultaneous production and maintenance planning", :abstract "Many model formulations for either production or maintenance planning in the literature do not explicitly consider the interdependencies between these two fields. Instead, the respective planning problems are often approached separately. Hence, the idea of an integrated production and maintenance planning is presented. For this purpose it is necessary to model the continuous state of the production resource, which is modeled through a continuous abrasion function and considered in the decision process. The particular state of the resource depends on the ongoing production and on the executed maintenance activities. By taking into consideration different maintenance concepts, adjustments of established dynamic lot sizing models are presented. In these models, production and maintenance activities are considered simultaneously.", :title "Integrated Dynamic Production and Maintenance Planning under Capacity Constraints", :keyword2 "lot sizing", :authors (26159), :session 159}, 383 {:keyword1 "water resources", :keyword3 "cost risk analysis", :abstract "A level of uncertainty mainly regarding the value of hydrological exogenous inflows and demand patterns typically characterizes water resource management problems. When scarce water resources events occur a correct rationing strategy must be adopted. An effective management policy must be able to establish a target value for delivering resources to the demand centre. We develop some cost optimization and risk management models that can assist the RMA in its decision about striking the balance between the level of target delivery to the users and the level of risk that this delivery will not be met. These models are based on utilization and further development of the general methodology of stochastic programming for scenario optimization. By a scenario optimization model we obtain a target barycentric value with respect to selected decision variables. A successive re-optimization of deterministic model allows the reduction of the risk of negative consequences derived from unmet resources demand. Our reference case study is the distribution of scarce water resources. We show results of some numerical experiments in real physical systems.\r\nReferences\r\nGaivoronski, A., de Lange, P.E., (2000). An asset liability management model for casualty insurers: Complexity reduction vs. parametrized decision rules. Annals of Operations Research, 99:227—250.\r\nManca A., Sechi G. M., Zuddas, P., (2004). Scenario Reoptimisation under Data Uncertainty. In (Pahl-Wostl, C., Schmidt, S., Rizzoli, A. E. and Jakeman, A. J. eds), Complexity and Integrated Resources Management, iEMSs Transactions, 1, 771—776\r\nPallottino, S., Sechi, G. M., Zuddas, P., (2004). A DSS for Water Resources Management under Uncertainty by Scenario Analysis, Environmental Modelling & Software, 20 (8), 1031—1042.\r\n\r\n", :title "Management of scarce water resources by a scenario analysis approach", :keyword2 "scarcity", :authors (1521 2901 11105), :session 133}, 384 {:keyword1 "portfolio optimization", :keyword3 "multi-objective model", :abstract "In this paper, we present a single-period multi-objective model for portfolio selection in which the risk is taken into account first, by considering an utility function which captures the attitude towards risk of the decision maker and second, by optimizing the portfolio through minimizing Conditional Value at Risk (CVaR) of the disutility of the loss such that the risk of high losses is reduced. Following the approach  in Rockafellar and Uryasev (Optimization of conditional value-at-risk, J. Risk, 2000, 21-42), we use an auxiliary function to characterize the Value at Risk (VaR) and CVaR of the disutility of the loss. We show that, in order to determine a portfolio that yields the minimum of the CVaR of the disutility of the loss, it is not necessary to work directly with this risk function, which may be hard to do because of the integral in its definition in terms of VaR, but with the auxiliary function previously defined which has better properties from both theoretical and optimization techniques point of vue. Practical issues such as transaction costs are incorporated in the multi-objective decision model. Related optimization models which generate equivalent representations of the efficient frontier are also given. The set of instruments to invest in was set to ten from the most representative securities in the Bucharest Stock Exchange. Historical data were analyzed for a period of almost three years. In order to model the time behavior of the uncertainty related to future prices, the MGARCH model was used. The Expected Utility - CVaR efficient frontier of portfolios in Return/CVaR scales for different risk confidence levels were traced and compared with the efficient frontier obtained for the Expected Utility - CVaR of the disutility of the loss model.", :title "Single-period portfolio optimization in a reward-risk framework", :keyword2 "risk measure", :authors (10811), :session 74}, 385 {:keyword1 "Bond Valuation", :keyword3 "Haircuts", :abstract "Due to the sharp increase of return spreads in the market during the recent financial market crisis, financial institutes faced considerable losses to the value of their bond portfolios. These losses were significant as institutes typically hold such portfolios as a means of liquidity reserve and to assure refinancing with the ECB. The reliable estimation of haircuts on bond values has become increasingly important, given this background and together with the newly published requirements and recommendations for liquidity risk management of the banking supervision. For deducing haircuts we analyse observable spreads of Bloomberg Fair Market Curves for different sectors, credit qualities, and maturities against the Bloomberg Fair Market Government Curve. We use two data sets, one running from 2002 up to the beginning of the financial market crisis and one running from 2002 up to the end of 2008, thus including the crisis. Assuming normally distributed spreads we compare expected spreads as well as p-quantiles under regular market conditions with those during the crisis. On the basis of spread expansions we calculate the relative changes in value of zero bonds. The analysis indicates evident rises in average spreads, i.e. up to 13 times for one-year maturities even for AAA securities. Thus, the increase in spreads was mainly driven by liquidity premiums. Starting with a regular market environment as basis, the analysis shows a clear ex ante underestimation of spreads as well as haircuts. In the crisis situation we already see haircuts of up to 25% for investment grade bonds. The results of the analysis demonstrate the increasing importance risk and liquidity management plays in the future to minimise estimation errors of bond haircuts.", :title "Return Spreads and Bond Values During the Crisis – An Empirical Analysis", :keyword2 "Spreads", :authors (26184), :session 98}, 386 {:keyword1 "Route Planning", :keyword3 "Collision Avoidance", :abstract "Robotic welding cells are at the core of many  complex production  systems, especially in automotive industry. In these welding cells, a certain number of robots perform spot welding tasks on a workpiece. For instance, four robots have to make 50 weld points on a car door. The tours of the welding robots are planned in such a way that all weld points on the component are visited and processed within the cycle time of the production line. During this operation the robot arms must not collide with each other and safety clearances have to be kept.\r\n\r\nOn the basis of these specifications, we consider a slight simplification concentrating on the Discrete Optimization aspects of the stated problem. This leads to a Vehicle Routing based problem with additional scheduling and timing aspects induced by the necessary collision avoidance. This problem can then be solved as an Integer Linear Program by Column Generation techniques. In this context, we adapt the Resource Constrained Shortest Path Problem, so that it can be used to solve the pricing problem with collision avoidance. Using this approach, we are able to solve generated test instances based on real world welding cell problems of reasonable sizes with four robots processing about 30 weld points to optimality.", :title "Route Planning for Robot Systems", :keyword2 "Column Generation", :authors (26292 22814), :session 217}, 387 {:keyword1 "single-machine scheduling", :keyword3 "Branch&Bound", :abstract "In industry and services shift work is a common employment practice in order to enable a 24-hour production. We consider single-machine scheduling problems with shift-varying processing times. These are caused by unsteady resource capacities and described by step functions. In contrast to other authors, we take additionally into account that a job must be started and completed within the same interval. The objective is makespan minimization. After proving the NP-completeness of different problem variants, we introduce a mixed-integer formulation for this bin-packing related problem and propose a Branch&Bound procedure that makes use of a specific enumeration scheme. The performance of the algorithm is validated by computational tests and compared with standardized solvers.", :title "Single-machine scheduling with shift-varying processing times", :keyword2 "shift-varying processing times", :authors (17331 14800), :session 152}, 388 {:keyword1 "maritime transportation", :keyword3 "branch-and-price", :abstract "The split pickup split delivery crude oil tanker routing and scheduling problem (COTRASP) is a difficult combinatorial optimization problem to solve. However, due to the large expenses in crude oil shipping it is attractive to use optimization that exploits as many degrees of freedom as possible to save transportation cost.\r\n\r\nWe propose a nested column generation algorithm for this particular split pickup split delivery problem (SPSDP). There are major problem inherent complexities such as a heterogeneous fleet, multiple commodities, many-to-many relations for pickup and delivery of each commodity, sequence depended vehicle capacities, and cargo quantity dependent pickup and delivery times. \r\n\r\nThe problem is decomposed in an all-ship master problem with variables describing ship routes and service quantities. The single-ship route and service quantity generation subproblems are solved with branch-and-price themselves and are decomposed in a route selection and service quantity problem with route generation subproblem. We describe the implementation of the nested column generation algorithm in the branch-cut-and-price framework SCIP. Results for realistic COTRASP test instances obtained with SCIP and CPLEX are reported. Despite the high complexity of the problem we obtain high quality schedules for these instances, improving on previous studies.", :title "Nested Column Generation applied on the Crude Oil Tanker Routing and Scheduling Problem with Split Pickup and Split Delivery", :keyword2 "split delivery", :authors (14969 9821 6887), :session 211}, 391 {:keyword1 "option game", :keyword3 "patent licensing", :abstract " In this paper, we propose a financial model of a game situation about patent license agreements and calculate optimal terms of agreements for licensers. When contracting license agreements, strategies of licensers and licensees interact with each other. We model this situation as an option problem game between them. Option game is a theory which integrates of game theory and real option theory. We can analyze mutual interactions of strategies under uncertainty by using this.\r\n\r\n For calculating optimal terms of agreements, we propose how to solve a game option problem with a finite expiration. Since a patent has a expiration date, strategies of licensers and licensees change every moment. Therefore, we should solve this situation as a problem with finite expiration. Although Grenadier(1996) proposed how to solve an option game problem with a infinite expiration, very few previous researches proposed how to solve the problem with a finite expiration. Because the problem can't solve analytically, we employed numerical method like finite differential method.\r\n\r\n When developing our model, we take into account some patent features. License agreements consist of a combination of variable and fixed fee. Variable fee is paid to licensers in portion to sales but fixed fee is paid independently of the sales. We calculate optimal terms of agreements as a combination of them. Additionally, we built a particular risk associated with patents into the model. It is called \"Sudden-death risk\" It indicates that value of some patent will suddenly drop to zero when new technologies invented.\r\n\r\n After that, we conduct numerical experiments of our model. These experiments indicate relations between optimal terms of license agreements and the risks; cash flow and sudden-death risk.", :title "Solving an Option Game Problem with Finite Expiration: Optimizing Terms of Patent License Agreements", :keyword2 "finite differential method", :authors (26379 26181 26404), :session 74}, 393 {:keyword1 "Pricing", :keyword3 "Coordination of Marketing and Operations Decisions", :abstract "Inventory models traditionally assume that the price of each product is determined exogenously.  In more recent times however, researchers have focused on the coordination of endogenous pricing and inventory control decisions in either service industries or manufacturing systems. For example, Revenue Management is a technique which has been applied to integrate the pricing and capacity control problems in the service industry. For the manufacturing sector, numerous models have been developed to solve joint pricing and production planning problems with shared capacity within a continuous time frame. However, problems concerning multi-product systems over a multi-period horizon have attracted very little attention.\r\nIn this paper, we focus on the coordination of pricing and production planning in make-to-stock manufacturing systems with multiple products over a multi-period horizon. We consider demand-based models where the demand is a function of the price. We look at both the deterministic and stochastic demand/price scenarios. There is an assumption that the production setup costs are negligible. The deterministic problem is computationally difficult, because it involves a nonlinear objective function and some nonlinear constraints. Our strategy to reduce the level of difficulty is to utilize a method that solves the relaxed problem which considers only linear constraints. However, our method keeps track of the feasibility with respect to the nonlinear constraints in the original problem. For the stochastic case, we develop a robust optimization model that considers the optimality and feasibility of all scenarios. The robust solution is obtained by solving a series of nonlinear programming problems. We demonstrate our methodology with numerical examples.", :title "Mathematical Programming Models for Pricing and Production Planning of Multiple Products over a Multi-Period Horizon", :keyword2 "Production Planning", :authors (26378 23531), :session 94}, 394 {:keyword1 "Organisational Behaviour Representation", :keyword3 "System Dynamics Model", :abstract "In this paper the method “Organisational Behaviour Representation” (OBR) will be presented including its basic concepts and the resulting software-demonstrator. The main objective of the OBR-Method covers the investigation of principles needed to build effective reachback organisations. \r\nDislocated command and control structures are necessary to meet present and future challenges of military operations and their organization. Improved communication and collaboration tools enable this kind of virtual staff work and offer advantages for the conduct of military operations as e.g. a small “footprint”, flexible and agile manning of reach back and deployed units, additional “ad hoc” expertise or industrial support.\r\nVirtual military staff work is often degraded due to misunderstandings in collaboration. The OBR model considers the complex interconnections of many social and personnel parameters. The OBR method models mainly social and cognitive processes founded in human factors research and military experience which are coupled tightly to organizational performance. Accordingly a System Dynamics based model has been designed which implements important effects in dislocated organizations. \r\nA user friendly application of the OBR method has been developed which enables OA specialist to evaluating the structure of dislocated organizations and further to scrutinizing possible implications for training and development in the pre-deployment phase.\r\nA great number of different load tests with regard to validation of the System Dynamics Model and the resulting demonstrator through case studies were and will be conducted to ensure the models credibility based on real facts and actual operational data.\r\n", :title "Decision Making in a complex environment: Human Performance Modeling for Military application in dislocated organizations", :keyword2 "Reachback", :authors (26388 26320), :session 170}, 395 {:keyword1 "Bayesian belief network", :keyword3 "cellular automata", :abstract "A statistical influence diagram, called Bayesian Belief Network (BBN), was investigated in modeling the problem of medical breast cancer diagnosis.  The proposed BBN was constructed under supervision by medical experts and data training for structure.  Four  types of datasets, namely,  historic biodata,  indirect mammographic,  physical findings and direct mammographic findings were taken into account for  modeling the BBN network.   Biodata were  comprised of age,  number of relatives having breast cancer, age at first live birth,  and age at menarche.  Indirect mammographic data consist of breast composition. Physical findings  consisted  of  pain,  axilla,  inflame  and nipple discharge. Finally, direct mammographic findings  consisted  of  information , such as mass and calcification, obtained by mammogram image processing by using the proposed cellular automata model.   Datasets  were  collected  in real cases of  the breast cancer patients who come to get serviced at Srinakarind Hospital, Khon Kaen University, Thailand.  An  80% of data was used for training the model, while the rest of 20% was utilized for testing  the model.   For evaluation purposes, the trained BBN model was tested on 100 patients consisting of 50, 25 and 25 for normal, benign and malignant, respectively.  The proposed BBN provides the promising results reporting the 96.5 percentage of accuracy in the diagnoses.", :title "A Bayesian Belief Network Model for Breast Cancer Diagnosis", :keyword2 "breast cancer", :authors (26382), :session 231}, 397 {:keyword1 "Awards", :keyword3 "Experiment", :abstract "We analyze the motivational effect of symbolic rewards through status disclosure on work performance in a real effort lab experiment and provide evidence that the implementation of awards without any monetary attachment could increase performance. The awards in our experiment are buttons in the colors of Olympic medals. Therefore on the one hand no monetary value is attached to our reward and on the other hand the meaning is unambiguous embossed by the linkage to sport tournaments. However, our results show that the motivation effect by awards could not be taken for granted but depends on the amplitude of hierarchy levels and the initial relative standing of performers. In smaller groups awards have a higher incentive effect because the absolute number of winners and losers decreases and work performance is more exposed. This enhances the trophy value and intensifies the feelings of distinction and disgrace due to status revealing. Furthermore top performers, who have a reasonable chance to be one of the winners of the tournament, feel a higher motivation due to status disclosure by awards.", :title "Trophy Value of Symbolic Rewards and their Impact on Effort", :keyword2 "Work Motivation", :authors (26339), :session 189}, 398 {:keyword1 "Contingency Tables", :keyword3 "Markov Chain", :abstract "In this paper, we propose a perfect sampling algorithm for two-way contingency tables. A contingency table is a non-negative integer matrix satisfying given pair of marginal vectors (row sum vector and column sum vector).\r\n\r\nWhen the number of rows is equal to 2, Kijima and Matsui [2006] proposed a Markov chain which gives a perfect sampler of contingency tables such that the expected number of transitions is bounded by a polynomial of the input size of marginal vectors. Recently, Wicker [2010] proposed a perfect sampling algorithm for general case. The time complexity of Wicker’s algorithm is exponential of the number of columns.\r\n\r\nOur perfect sampling algorithm generates (n-1) two-rowed contingency tables by Kijima and Matsui’s method when row sum vector is an n-dimensional vector. The first row of a generated two-rowed table represents a specified row of original table and the second row corresponds to the sum of remained row vectors. By generating (n-1) two-rowed table, we reconstruct a table whose size is equal to original table. If all the entries of obtained table is non-negative, we output the table. Else, we generate (n-1) two-rowed tables from scratch.\r\n\r\nOur computational experiments show that our algorithm is much faster than Wicker’s algorithm when the number of rows is greater than or equal to 4.", :title "Computational Experiments of Perfect Sampling Algorithms for Two-way Contingency Tables", :keyword2 "Perfect Sampling", :authors (26301 26384 13201), :session 221}, 399 {:keyword1 "Scheduling", :keyword3 "Mixed integer linear programming", :abstract "Except for a few special applications, including cutting processes, the excavation of potash in Germany is based almost exclusively on conventional methods involving drilling and blasting. Thereby, this kind of underground mining is characterized by many production cycles that consist of several consecutive sub-steps (operations), such as filling blast holes with explosive substance or loading broken material. Each processing step requires one machine from a set of unrelated parallel mobile machines, e.g. drilling jumbos or loaders with different shovel capacities. The resulting mining process represents a manufacturing environment that can be identified as a hybrid flow shop scheduling problem. Consequently, we formulate the problem as a mixed integer linear programming model where the makespan has to be minimized. In contrast to the standard problem described in the literature some additional real-world restrictions have to be considered in the planning process. These restrictions include chain precedence constraints, which ensure that a job occurring at a special underground location cannot be processed before all sub-steps of the preceding production cycle have been finished completely. In addition, if jobs have not been finished within a certain time period, a security precaution is needed that leads to an additional production step beyond the common production cycle. An extension of the problem considering the impact of incorporating stochastic machine breakdowns on the processing times is discussed. Finally, we present a first solution approach.", :title "Scheduling in the context of underground mining", :keyword2 "Underground mining", :authors (26121 5965), :session 179}, 402 {:keyword1 "Network design", :keyword3 "Strategic and operational aspects", :abstract "Transportation networks consist of nodes with either a surplus or a deficit of resources, central transshipment facilities (hubs) and interconnecting links. Hubs centralise product handling and sorting, and allow companies to take advantage of scale economies through consolidation of flows. Strategic hub network design problems decide on the number and location of hubs in the network. Tactical network design problems assign nodes to hubs and route products through the network. Subsequently, fleet scheduling algorithms create routes for vehicles operated in the network. The strong relationship between hub construction, flow routing and fleet scheduling makes it difficult to optimise the overall network costs. To address this problem, we introduce a new network design model that incorporates strategic and operational aspects in a unique way. Thereby, three critical design questions need to be considered: (a) how many hub facilities are required? (b) should node-to-node links be connected directly or by one hub? (c) is it possible to combine nodes to vehicle routes, where every route starts and ends at an assigned hub? We present a mixed-integer linear programming formulation for the problem which is inspired by practical applications. Additionally, we sketch an efficient multi-start solution framework that combines greedy heuristics with randomisation.", :title "Transportation network design and vehicle routing", :keyword2 "Vehicle Routing", :authors (9524 5965), :session 210}, 403 {:keyword1 "Scheduling", :keyword3 "Perishable product", :abstract "We consider a model for integrated production and distribution scheduling, where a perishable product must be produced at a central depot and delivered to a set of geographically dispersed customers within a certain time limit. Additionally, customers specify their demand for the product for the planning period as well as delivery time windows, within which they prefer their goods to be supplied.\r\n\r\nSince the production facility and the delivery vehicle(s) are limited resources, it is generally impossible to serve all customers within their specified time windows and/or product lifespan. Thus, the goal is to satisfy a maximum amount of demand while minimizing the total cost of distribution. This implies simultaneously finding a best subset of customers to be supplied as well as sequences for production and deliveries, which essentially makes the problem NP-hard in the strong sense.\r\n\r\nIn traditional approaches, production planning and transportation scheduling are considered separately from each other. Especially for make-to-order manufacturing, where the production is triggered by customer orders and the amount of finished goods inventory in the system is typically low, these approaches have been shown to yield inferior results compared to integrated strategies. In this talk, we present mathematical programming models for the integrated production and distribution scheduling problem, propose heuristic solution methods and illustrate that the combined planning approach is advantageous for these models.", :title "Integrated Production and Distribution Scheduling", :keyword2 "Make-to-order", :authors (15150), :session 245}, 406 {:keyword1 "constraint qualifications", :keyword3 "subdifferential calculus", :abstract "A mathematical program with vanishing constraints (MPVC) is an optimization problem with important applications in the field of topology opimization. Due to the combinatorial nature in the constraints, an MPVC is likely to violate most of the prominent regularity conditions, including the Abadie constraint qualification, e.g. Hence, more problem tailored conditions are investigated. Moreover, an exact penalty result combined with tools from nonsmooth analysis is  used to derive necessary optimality conditions.", :title "Mathematical programs with vanishing constraints", :keyword2 "exact penalization", :authors (18961), :session 63}, 407 {:keyword1 "Combinatorial Optimization", :keyword3 "Heuristics", :abstract "We propose a combinatorial optimization problem, motivated by, and a simplification of, a TV Self-promotion Assignment Problem. \r\nTV stations typically reserve a promotion space (broadcasting time) for self-promotion (future programs, etc.) that is regulated and limited. Hence, optimizing its usage is of upmost importance.\r\n\r\nThe problem consists of, given the weekly self-promotion space (a set of breaks with known duration) and a set of products to promote, to assign the products to the breaks in the ``best'' possible way. The objective is to maximize contacts in the target audience for each product, while satisfying all constraints.\r\n\r\nGiven the problem complexity and dimensionality, only heuristic approaches are expected to obtain solutions in a reasonable amount of time. We develop a Hybrid Genetic Algorithm (HGA) that incorporates a greedy heuristic to initialize part of the population and uses a repair routine to guarantee feasibility of each member of the population. The HGA works on a simplified version of the problem that, nevertheless, maintains its essential features. The proposed simplified problem is a binary programming problem that has similarities with other known combinatorial optimization problems, such as the assignment problem or the multiple knapsack problem, but has some distinctive features that characterize it as a new problem.\r\n\r\nAlthough we were mainly interested in solving problems of high dimension (of about 200 breaks by 50 spots), the quality of the solution was tested for smaller dimension problems for which we could find the exact global minimum using a branch-and-bound algorithm. For these smaller dimension problems we have obtained solutions on average within 1% of the optimal solution value.", :title "A Hybrid Genetic Algorithm for Constrained Combinatorial Problems: An application to promotion planning problems.", :keyword2 "Genetic Algorithms", :authors (26266 7032 23499), :session 221}, 408 {:keyword1 "Optimization under uncertainty", :keyword3 "Natural gas", :abstract "The conclusion of medium term supply contracts for natural gas contributes significantly to strategic procurement in energy business. Trading with gas bears two central types of risk. On the one hand there is volume risk which is caused by the seasonally varying and highly fluctuative demand for natural gas. On the other hand the gas price is highly affected by exogenous influences which causes price risk. Producers and retailers usually balance these risks by means of long term contracts that leave the volume risk to the retailer and the price risk to the producer. The present analysis will emphasize volume risk. Take Or Pay contracts play a central role in this field since they allow the retailer to vary the purchase volume within a frame. The combination of different contract types, the application of gas storages and the spot market provide a comprehensive strategic instrument that allows the retailer to meet his customer’s demands. The question arises, which volume for which type of contract should be concluded at present in order to fulfill prospective uncertain demand at minimal costs. This problem will be treated by means of linear integer optimization under uncertainty. Decisions are being made based upon a scenario approximation of an Ornstein-Uhlenbeck process for natural gas demand. A static model will be compared to a dynamic approach that considers possible developments of the market. The dynamic model takes into account that concluding a contract today or postponing its conclusion and making the decision at a later point of time involves different states of knowledge. Therefore special attention will be paid to the question, which decisions are being made at which point of time under which state of information.", :title "Quantitative models for conclusion of strategic gas supply contracts under uncertainty", :keyword2 "Supply contracts", :authors (15398 10057), :session 162}, 409 {:keyword1 "earth observing satellite constellation", :keyword3 "branch-and-price", :abstract "The scheduling problem of the earth observing satellite constellation has to assign the unary resource of satellite observing and data-downloading time to different weighted spot targets on earth, respecting special constraints, such as observing and data-downloading time windows, consecutive observing and data-downloading transition time, and on-board memory capacity. Since the problem is NP-hard, previous research mainly focused on heuristics and meta-heuristics. We first propose a constraint-based formulation, and then decompose the original problem into a set-packing master problem and a series of longest path sub-problems with resource constraints and time windows. The sub-problem corresponds to determining the best single-satellite feasible schedule in order to improve the optimal solution value of the linear-relaxed restricted master problem. The linear-relaxed master problem is recursively solved by CPLEX, and the sub-problem is solved by a labeling-based dynamic programming in a graph. The vertexes of the graph are the observing and data-downloading time windows, and the arcs are the vertex pair satisfying the time compatibility. A constructive primal heuristic integrating target weights and conflict-avoided ideas is used to speed up the branch-and-bound tree search. Instead of directly branching on the fractional solution of the master problem, we branch on the flow variables of the sub-problem, decomposing the graph into two complemented parts. Realistic instances of Chinese environmental and disaster small satellite constellation are used to test the effectiveness of the proposed model and algorithm, and the experimental results show a promising perspective.", :title "Solving the earth observing satellite constellation scheduling problem by branch-and-price", :keyword2 "scheduling", :authors (26305), :session 146}, 411 {:keyword1 "network flow", :keyword3 "evacuation", :abstract "Finding optimal evacuation solutions is an important task in evacuation planning. We investigate the following objectives: a Nash equilibrium (NE), in which no evacuee benefits from choosing a different but the assigned route, a system optimum (SO), in which the total travel time is minimized, and an earliest arrival flow (EAF), which guarantees that at any point in time the maximum number of evacuees has left the network. NE and SO are computed in the transport simulation framework MATSim, while EAF is computed combinatorially.\r\n\r\nThe results are compared in MATSim on a real-world scenario, modeling the city of Padang (Indonesia), with its high threat of tsunamis. The network comprises 4,000 nodes and contains 250,000 evacuees. The different approaches lead to qualitatively similar results, with the EAF performing slightly better. The computation times vary between a few hours (EAF) and a day (SO) on standard hardware.\r\n\r\nAn EAF can, in principal, be found with standard algorithms in the time-expanded network (TEN). However, the TEN models each time step as a copy of the network, creating large and redundant instances. Taking the repeating structure of the network into account, we design an EAF algorithm to handle fine discretizations.\r\n\r\nIn the simulation, for NE and SO each evacuee iteratively optimizes its personal evacuation plan.  After each iteration, every evacuee scores and revises its plan. New \"best-response\" plans are generated using a time-dependent router. The outcome depends on the cost function. If the cost comprises travel times only, this approach converges towards a NE. If the cost represents the \"marginal cost\", i.e., the increase in total travel time generated by a single additional evacuee entering a link, it converges towards a SO.", :title "Optimal evacuation solutions for large-scale scenarios", :keyword2 "simulation", :authors (26367 26386 26392 26401 22814), :session 199}, 415 {:keyword1 "Industrial Product-Service System", :keyword3 "Adaptation", :abstract "This paper examines the development and operation of Industrial Product-Service-Systems (IPS²) within a long-term business connection from an incomplete contract perspective. Especially the interrelationship between the design of an IPS²  and the contractual allocation of decision rights with regard to an adaptation of the initial design is analyzed. \r\n\r\nIndustrial Product-Service Systems constitute a problem solution for Business-to-Business markets, customized for individual customers’ needs along the IPS² life cycle. They are characterized by an integrated and mutually determining process of both planning and developing as well as of provisioning and use of goods and services. Thus, we develop a model for to two periods, the development and the operating phase, to analyze IPS². During the first period it has to be decided on how much effort to spend in design and how to design the IPS². There is a trade off between an integrated design, which is favorable with respect to the performance of the initial IPS², and a modularized design which comes with cost-advantages in adapting the system. As the amount and nature of changes to the initial design cannot be determined ex ante, development of the initial IPS² takes place within an incomplete contract framework. Due to the incomplete character of this framework, control rights regarding the adaptation of the system in the second period have to be allocated.\r\n\r\nWe determine adequate control structures for specific designs of Industrial Product-Service Systems in a profit maximizing framework.\r\n", :title "Efficient Design and Adaptation of Industrial Product-Service Systems ", :keyword2 "Incomplete Contracts", :authors (14863), :session 157}, 418 {:keyword1 "Probabilistic programming", :keyword3 "Water reservoir management", :abstract "The Authors should be given in alphabetical order:\r\nW. Van Ackooij EDF, \r\nR. Henrion WIAS, \r\nA. Möller WIAS, \r\nR. Zorgati EDF\r\n\r\n<br><br>\r\nThe Speaker \r\nA. Möller WIAS \r\nmay be emphasized\r\n\r\n<br><br>\r\nThe problem of hydro prower management consists in finding an optimal hydro\r\npower production policy, such that the expected profit over an optimization\r\nhorizon is maximized. Power is generated by releasing water from an upper\r\nreservoir through turbines. Reservoirs and hydro power plants may be cascaded,\r\nsuch that one hydro power plant feeds the upper reservoir of the next\r\nhydro power plant. The inflows into the reservoirs are assumed to be stochastic.\r\nBy upper and lower level constraints we ensure that the upper reservoirs of the\r\nhydro power plants do not run empty on the one hand and that no spill exists\r\non the other hand.\r\n<br>\r\n\r\n<br>\r\nDue to the stochastic behaviour of the inflow the upper and lower level\r\nconstraints are modelled as chance constraints such that these constraints have\r\nto be fulfilled with a given (high) probability level. The inflow is assumed to\r\nhave a multivariate normal distribution. The model fits into a problem class\r\nwhere the random variable is constrained from below and above. Numerical\r\noptimization requires function values and gradients of such multivariate normal\r\ndistributions on rectangular sets. We give a new derivative formula for normal\r\ndistributions on rectangles which allows do deal with normal distributed random\r\nvectors in higher dimensions.\r\n<br>\r\n\r\n<br>\r\nNumerical results are presented and different types of modelling the upper\r\nand lower level constraints are discussed. We show that probabilistic constraints\r\nensure a high level of robustness while the loss in the objective is small compared\r\nto other alternatives.", :title "Probabilistic Programming in Hydro Power Management", :keyword2 "Derivative of probabilities of rectangles", :authors (26352), :session 70}, 419 {:keyword1 "Warehouse Management", :keyword3 "Genetic Algorithm", :abstract "Order picking is a warehouse function dealing with the retrieval of articles from their storage location in order to satisfy a specified customer demand. It is regarded as a critical function, since underperformance will result in unsatisfactory customer service on the one hand and higher costs on the other hand. Several studies reveal that more than 50% of the warehousing operating cost can be attributed to order picking. \r\n\r\nIn this paper the Order Batching Problem in manual order picking systems is considered, i.e. the problem of grouping customer orders into picking orders such that the corresponding total length of all picker tours required for collecting the requested articles is minimized. This problem is known to be NP-hard (in the strong sense), and heuristic methods are required to solve problem instances encountered in practice.\r\n\r\nThe authors have developed a Genetic Algorithm for the Order Batching Problem which will be presented in this talk. In particular, the selection of a suitable encoding scheme and of appropriate genetic operators will be discussed. Based on extensive numerical experiments, the performance of the proposed method will be evaluated with respect to the problem size (number of customer orders), the different characteristics of the warehouse (e.g. size and equipment of the warehouse) and the chosen routing strategy (S-Shape Routing; Largest-Gap Routing). It will be shown that the proposed method leads to significant improvements in comparison to existing approaches.\r\n", :title "Genetic Algorithms for the Order Batching Problem in Manual Order Picking Systems", :keyword2 "Order Batching", :authors (15153 333), :session 205}, 422 {:keyword1 "Disaster Management", :keyword3 "Mixed-Integer Programming", :abstract "In recent years, often attributed to global warming, an increasing number of extreme river flood events has been observed in Central Europe. In addition to that, these events seem to have more severe consequences due to higher flood peaks, but also due to more intensive land utilization in areas close to river banks and former flood plains. Efficient flood protection management, thus, is a vital issue for each community located in a zone vulnerable to river floods.\r\n\r\nApproaching river floods threatening the safety of human beings and assets are often dealt with by means of mobile dike systems, i.e. dike systems which are built of sandbags. This paper deals with planning and controlling the logistic operations related to the establishment of such dikes, namely: (1) the determination of the number and the locations of sites where the sandbags are to be filled (location problem), (2) the organization of the transports of the sandbags from the filling locations to the areas at risk (transportation problem), and (3) the assignment of staff to the areas at risk (staff assignment problem). These problems are closely interrelated; however, their respective sizes do not permit to solve them simultaneously. The authors, therefore, suggest a successive approach which is based on mixed-integer programming. Several variants of this approach will be evaluated for different flood scenarios for the City of Magdeburg, which include different flood peaks of the River Elbe and different seasonal conditions.", :title "Planning Logistic Operations for Flood Protection Management", :keyword2 "Flood Protection Management", :authors (26359 333), :session 199}, 423 {:keyword1 "Monte Carlo simulation", :keyword3 "defined benefit pension plans", :abstract "Accounting for defined benefit pension plans is complex. Experienced differences between assumed and realised calculation assumptions cause actuarial gains or losses. The fundamental condition of the current International Accounting Standard (IAS) 19 is that there will be an offsetting of actuarial gains and losses in the long run. IAS 19 offers a variety of accounting policies to cope with these actuarial gains or losses. Some of them are based on the fundamental assumption of offsetting. Because of the various stochastic elements in the complex accounting system and the long-term nature, human expectations on system behaviour generally fail. The offsetting assumption has never been proved by the International Accounting Standards Board (IASB). An analytical approach is impossible because of the complex calculations and combinations of a variety of stochastic parameters. Therefore, we use Monte Carlo simulation technique to analyse the system behaviour. In this paper we concentrate on a degenerating instead of a regenerating workforce and simulate for an initial workforce for a lifetime period. This enables to get a final state at the end of the simulation horizon. All parameters for characterizing the workforce, for the mortality and fluctuation process as well as the parameters for the financial assumptions like pension and salary increases, are representative for Germany. – The main result is that the fundamental assumption of an offsetting of actuarial gains and losses is inappropriate. As a consequence we are faced with a strong tendency of cumulated actuarial losses. In case of recognising the actuarial gains and losses outside profit and loss we discover a huge information bias during the years.", :title "Information bias in international accounting for defined benefit pension plans - results for the case of a degenerating workforce", :keyword2 "international accounting", :authors (13364), :session 122}, 426 {:keyword1 "portfolio theory", :keyword3 "investments", :abstract "It is common practice to base investment decisions on price projections which are gained from simulations using price processes. Particularly in the electricity industry with its diverse fuels, homogenous output and long-lived assets the choice of the underlying process is crucial for the simulation outcome. At the most fundamental level stands the question of the existence of stable long-term cointegration relations. Since this question is very difficult to answer empirically, it is also appropriate to investigate the implications of varying assumptions. Not only the specific parameter values but also the specification of the price processes has therefore to be scrutinized.\r\nIn the presence of fuel price risk, portfolio diversification will usually be drawn into consideration in investment decisions. Therefore we examine the impacts of different ways to model price movements in a portfolio selection model for the German electricity market. \r\nThree different approaches of modeling fuel prices are compared:  Initially, all prices are modeled as correlated random walks. Thereafter the coal price is modeled as random walk and leading price while the other prices follow through mean-reversion processes. Last, all prices are modeled as mean reversion processes with correlated residuals. \r\nThe prices of electricity base and peak futures are simulated using historical correlations with gas and coal prices. Yearly base and peak prices are transformed into an estimated price duration curve followed by the steps power plant dispatch, operational margin and NPV calculation and finally the portfolio selection. \r\nThe analysis shows that the chosen price process assumptions have significant impacts on the resulting portfolio structure and the weights of individual technologies.\r\n", :title "Stationary or Instationary Spreads - Impacts on Optimal Investments in Electricity Generation Portfolios", :keyword2 "price processes", :authors (26303 16562 24773), :session 162}, 427 {:keyword1 "Financial markets", :keyword3 "1/f noise", :abstract "A class of nonlinear stochastic differential equations (SDE) giving the power-law behavior of spectra, including 1/f noise, and power-law distribution of the probability density has been proposed [1, 2]. The model, based on these equations and generating q-exponential and q-Gaussian distributions has been applied for simulation of the financial processes [3]. The scaled dimensionless form of the equations gives an opportunity to deal with averaged statistics of various stocks and compare behavior of different markets. \r\nThe proposed double stochastic process driven by the nonlinear scaled SDE reproduces main statistical properties of the financial activity and absolute return, observable in the financial markets [4]. \r\nSeeking to discover the universal nature of return statistics we analyze and compare extremely different markets in New York and Vilnius, and adjust the model parameters to match statistics of both markets. A further analysis of empirical data and proposed model interpretation by agent behavior is in progress. \r\n\r\n[1]. Kaulakys B. and Alaburda M. (2009) “Modeling scaled processes and 1/f noise using nonlinear stochastic differential equations”, J. Stat. Mech. P02051 \r\n[2]. Ruseckas J. and Kaulakys B. (2010): „1/f noise from nonlinear stochastic differential equations“, Phys. Rev. E 81, 031105. \r\n[3]. Gontis V., Ruseckas J. and Kononovicius A. (2010): “A long-range memory stochastic model of the return in financial markets”, Physica A 389, 100. \r\n[4]. Gontis V. and Kononovicius A. (2010): “Nonlinear stochastic model of return matching to the data of New York and Vilnius Stock Exchanges”, arXiv:1003.5356v1.\r\n", :title "Modeling of financial processes by the nonlinear stochastic differential equations ", :keyword2 "Power-law distributions", :authors (26397 19620), :session 97}, 429 {:keyword1 "Hybrid flow shop scheduling", :keyword3 "Railcar maintenance", :abstract "In this talk we deal with the real-world problem of servicing railcars in view of a planned cooperation with a company. In regular intervals railcars have to be checked and serviced just like cars. This is done in some sequential maintenance steps depending on the degree of wear. For this purpose, there is a service hall at the site of our partner. In this hall, there are several parallel rail tracks with a dead end at the opposite side of the gate. At each track a couple of machines perform the same maintenance step. Hence, a railcar has to visit several tracks in order to finish its service. Interruptions of maintenance steps are not allowed. Thus, no railcar can pass another railcar being currently serviced on the same track. Shortly, we refer to this fact as blockings. As a result of blockings, some railcars possibly have to wait on a track though no service is done. We describe the above problem in a particular hybrid flow shop model considering the above-mentioned blockings with identical machines at each stage. In particular, we develop a mixed integer linear programming model. We take a look at the complexity of the problem and present heuristical as well as exact solution methods. Finally, we discuss computational results for several data sets.", :title "Hybrid flow shop scheduling with blockings and an application in railcar maintenance", :keyword2 "Integer programming", :authors (26387 13837), :session 145}, 430 {:keyword1 "production sequencing", :keyword3 "Distribution-oriented Car Sequencing Problem", :abstract "An essential task in production planning of OEMs in the automotive industry is finding an optimal production sequence for mixed-model assembly lines (MMAS). At present sequencing is focussed on production driven goals solving the NP-hard Car Sequencing Problem (CSP) as a common relating problem class. Besides optimisation of production, the order sequence has a strong impact on KPIs of connected logistic processes. Yet they are not sufficiently considered in sequencing algorithms. Thus in this paper we have a closer look on how and if logistics-related objectives are considered in current publications. First we present requirements from logistics concerning the production sequence. Based on these we present a review of research papers dealing with order sequencing of MMAS and analyse their focus production, supply and distribution logistics. We then show that currently no solution sufficiently considers logistics-related objectives, in particular distribution logistics, which we focus in our further research. Overcoming this deficit the Distribution-oriented CSP (DCSP) as an extension of the traditional CSP is defined. We present an Evolutionary Algorithm (EA) using a Variable Neighbourhood Search (VNS) to solve the DCSP, since metaheuristics perform well on CSP. For a fast fitness evaluation we present an approach that divides the sequence’s overall fitness on single orders, which enables changes to be calculated locally saving processing time. The performance of the algorithm is evaluated based on real data from an OEM’s production program. For now results are compared with the OEM‘s productive system solving the CSP. We show that our algorithm can enhance KPIs of logistics radically while at the same time a high level of production performance is maintained.", :title "Considering Distribution Logistics in Production Sequencing: Problem Definition and Solution Algorithm", :keyword2 "Evolutionary Algorithm", :authors (26197 26398), :session 113}, 431 {:keyword1 "Generalized Convexity", :keyword3 "Dose-volume criteria", :abstract "Intensity Modulated Radiation Therapy (IMRT) is among the most commonly used treatment options in cancer therapy. The degrees of freedom are given by dividing the beams into smaller entities which can be modulated separately. A Dose Volume Histogram (DVH) aggregates the 3D dose distribution to a 2D curve for each volume of interest in the body. The planner uses DVHs to evaluate treatment plans in a detailed and meaningful way. Also, clinical protocols specify therapeutic dose prescriptions in terms of DVH points.\r\n\r\nDespite of their usefulness in treatment planning, DVH curves are mathematically difficult to handle. Dose-volume objectives and constraints are non-convex, and multiple local minima can exist (see [1] and [2]). Handling dose-volume criteria in multicriteria optimization is a field of ongoing research.\r\n\r\nOur work presents a novel approach in DVH modelling. The concept of invexity is a generalization of convexity. We prove this property for a class of DVH optimization problems. Using invex optimization models, DVH criteria can be efficiently applied in the treatment planning process. Local minima can be excluded in realistic use cases, thus taking a step towards deterministic global DVH-based optimization. This approach also provides means to balance the influence of DVH criteria and some other common planning criteria (refer to [3], e.g.) on the plan outcome. Promising numerical results are presented.\r\n\r\n[1] J.O. Deasy, Multiple local minima in radiotherapy optimization problems with dose-volume constraints, Med. Phys. 24(7) 1997, 1157-1161\r\n[2] Q. Wu and R. Mohan, Multiple local minima in IMRT optimization based on dose-volume criteria, Med. Phys. 29(7) 2002, 1514-1527\r\n[3] A. Niemierko, A Generalized Concept of Equivalent Uniform Dose, Med. Phys. 26, 1999", :title "An approach towards DVH modelling in IMRT using generalized convexity", :keyword2 "IMRT", :authors (26191 15433), :session 175}, 432 {:keyword1 "bond", :keyword3 "neural network", :abstract "Corporate ratings, which are published by rating agencies, are based not only on quantitative data but also qualitative data that each agency acquires from corporations seeking to obtain corporate ratings through interviews and other approach. Each rating agency thus officially states that ratings are the opinions of the individual rating agencies and so the ratings of a corporation vary from agency to agency. Behind the growing importance of corporate ratings lie the problems of asymmetric information. No matter how hard one may try to disclose the information of individual corporations, it is not possible to remove asymmetric information in the market altogether. \r\nThe distribution of ratings changes plays a crucial role in many credit risk models. As is well-known, these distributions vary across time and different issuer types. Ignoring such dependencies may lead to inaccurate assessments of credit risk. We introduce a new approach to improve the performance of rating prediction models for multinational corporations. In the last decade, neural networks have emerged from an esoteric instrument in academic research to a rather common tool assisting auditors, investors, portfolio managers and investment advisors in making critical financial decisions. It is apparent that a better understanding of the network's performance and limitations would help both researchers and practitioners in analysing real-world problems. The objectives of this research is to verify the effectiveness of artificial neural networks (ANNs) and examine and compare the stability of rating structures of rating agencies in the United States and Japan. Method to predict corporate ratings by public quantitative information in a inter-temporally stable manner would be useful from the perspective of cost-benefit performance especially in recent rapidly changing economic situation. We find that ANNs has more explanatory power in many cases than models by previous research and that R&I and Moody’s changed rating structure significantly in 2006 and 2007 respectively.\r\n", :title "On the Time Consistency of Rating Structure -Empirical study using an Artificial Neural Network-", :keyword2 "credit risk", :authors (17174 17344 14775 19917 26672), :session 95}, 433 {:keyword1 "flow-shop", :keyword3 "mip", :abstract "A body shop in an automotive plant resembles a flexible flow-shop that is highly automated through the use of lots of industrial robots. Each of these robots has to handle different tasks ranging from lifting and holding heavy parts to laser welding. Robots by themselves consume a lot of power and, depending on their purpose, power consumption may increase drastically. Laser welding, for example, requires an enormous amount of power compared to rotating a small part. Each robot is able to switch to one or more standby modes. Each standby mode saves a different amount of power and requires idle time that is positively correlated with the amount of power saved.\r\nA key problem is to build blocks of idle time to make use of the most-efficient standby modes and still meet job due dates. Using the connecting conveyor system as a buffer it is possible to let jobs pause at certain stages so that blocks of jobs are possible.\r\nAnother problem is the diversity of products. With an increasing amount of product variants even at the body shop stage, the amount of setup time increases. A standard method is to build blocks of the car body variants to reduce the total setup time.\r\nThe optimal production sequence for a body shop is in great contrast to the optimal sequences for the paint shop and final assembly and compensation needs to be done between each of these stages. The stages are decoupled using buffers where the compensation takes place. The stock balance naturally has an upper limit which has to be considered when creating a production plan for a body shop.\r\nWe present a mixed integer programming model and a heuristic that are able to create a production schedule for a flexible flow-shop minimizing power consumption and setup times with regard to due dates.", :title "Body Shop Scheduling With Regard to Power Consumption", :keyword2 "power consumption", :authors (26343 9272 1141), :session 113}, 434 {:keyword1 "mixed oligopoly", :keyword3 "consistent conjectures", :abstract "A model of mixed oligopoly with conjectured variations equilibrium\r\n(CVE) is considered. The agents’ conjectures concern the price variations depending\r\nupon their production increase or increase. We establish existence and uniqueness\r\nresults for the CVE (called an exterior equilibrium) for any set of feasible conjectures.\r\nTo introduce the notion of an interior (or consistent) equilibrium, we develop\r\na consistency criterion for the conjectures and prove the existence theorem for such\r\nan equilibrium. For the extension of our results to the case of non-differentiable\r\ndemand functions, we also investigate the behavior of the consistent conjectures in\r\ndependence upon a parameter. Finally, a model of electricity market has been investigated,\r\nconsistent conjectural equilibrium states computed and compared to the\r\nclassical Cournot and perfect competition equilibrium states.", :title "Computing Consistent Conjectural Equilibrium in Electricity Market Models", :keyword2 "conjectural variations equilibrium", :authors (24144 24007), :session 192}, 435 {:keyword1 "inventory routing", :keyword3 "leveling", :abstract "Motivated by the success of Japanese car manufacturers, there is an increasing interest in the introduction of leveled logistics concepts. These concepts are characterized by leveled quantities and periodic pick up and arrival times. As a consequence, new requirements regarding the planning of material replenishment result. Planning systems based on the sequential MRP-logic do not take leveling into account and might therefore result in inacceptable volatility. To this end, we propose a modeling framework for leveled replenishment. Building blocks comprise a module for transportation planning, where costs optimal schedules are determined, and inventory control, where leveled quantities are generated. By integrating both modules we ensure periodic pick up and arrival times with leveled quantities, while taking into account uncertainty. The approach extends the well-known concepts of inventory routing with respect to the requirements of the automotive industry.", :title "Towards leveled inventory routing for the automotive industry", :keyword2 "inventory control", :authors (26368 13503 2651), :session 120}, 436 {:keyword1 "Credit Spread", :keyword3 "Contigent Claim Pricing", :abstract "The estimation of credit spreads or implied probabilities of default, which is equivalent for continuously compounded interest rates, is crucial not only as input for credit risk models but also for the pricing of credit derivatives. In case of bonds denominated of the same issuer in different currencies this raises the question as to what extent the credit spreads differ.\r\nThe aim of this paper is twofold: First, the existing theoretical models cannot draw a conclusion about the case, that the variables default, exchange (FX) and interest rate are dependent. Therefore, we show by means of a Jarrow/Turnbull model, which is to be extended by a second currency, that given a positive correlation between FX rate – defined as EUR/USD – and the event of default, the credit spreads in USD should theoretically be higher than in EUR and vice versa. \r\nSecond, the empirical studies published so far partially compare credit spreads of different issuers or the same issuer with different contractual specifications. Additionally, these surveys do not take into account that the term structure estimation error might influence the differences in credit spreads. Moreover, given the drawback of the applied theoretical models the influence of the correlation structure cannot be measured.\r\nIn our paper the theoretical model is followed up by an empirical study, in which these shortcomings could be excluded. Therefore our data set comprises carefully selected government bonds for the period from 1996 to 2006. \r\nAs a major result we found out that the credit spreads and implied cumulated default probabilities of nearly all bonds denominated in USD were significantly higher for all terms. A major part of the results could be explained by the dependence between event of default and FX rate.", :title "Currency Dependent Differences in Credit Spreads of Euro-  and US-Dollar Denominated Foreign Currency Government Bonds", :keyword2 "Currency", :authors (26304 26399), :session 154}, 439 {:keyword1 "electrical load balancing", :keyword3 "artificial neural network", :abstract "The rising share of renewable energy poses new challenges to actors of electricity markets: Wind and solar energy are not available without variation and interruption, so there is a rising need of high priced control energy. Smart grids are introduced to deal with this problem, by load balancing at the electricity consumers and producers. We analyze the capabilities of electrical load balancing and present initial results, starting with a short review of relevant literature.\r\nSecond part is an analysis of load balancing potentials at consumer household. A software prototype is developed for simulation of reaction to dynamically changing electricity rates, by implementing two generic classes of smart devices. a) Devices running once in a defined limited time slice, as as simplified model of real devices like dish washer, clothes washer, or laundry dryer. b) Devices without time restriction and a given daily runtime, as a simplified model of water heater with large storage. Both classes are tested with different optimization parameters.\r\nThird part is an analysis of centrally controlled combined heat and power plants (CHPP) for load balancing in a virtual power plant composed of CHPPs,  wind and solar energy plants. CHPP load is driven by heating requirements but we want to forecast the (uninfluenced) produced electricity. Our neural network forecast of CHPP load allows to alter the behavior of heat (and electricity) production. In times of low demand or high production by wind and solar energy, the CHPP can be switched off, provided that sufficient heat reserves have been accumulated before. Based on the neural network forecast, a software prototype simulates the effects of load balancing in virtual power \r\nplants by controlling the CHPPs.", :title "Analysis of Electrical Load Balancing by Simulation and Neural Network Forecast", :keyword2 "smart grid", :authors (26402 19080 19092 19100), :session 85}, 441 {:keyword1 "Matroid", :keyword3 "binary costs", :abstract "Connectedness of efficient solutions is a powerful property in\r\nmultiple objective combinatorial optimization since it allows the\r\nconstruction of the complete efficient set using neighborhood search\r\ntechniques. While most classes of multiple objective combinatorial\r\noptimization problems possess an unconnected efficient set in general\r\n(including problems on matroids), we show that for special classes\r\nof biobjective optimization problems on matroids involving\r\none objective function with binary costs the efficient set is always\r\nconnected.\r\nThis is the first non-trivial problem on matroids where\r\nconnectedness of the efficient set can be established.\r\n \r\nConnectedness of efficient solutions is a powerful property in\r\nmultiple objective combinatorial optimization since it allows the\r\nconstruction of the complete efficient set using neighborhood search\r\ntechniques. While most classes of multiple objective combinatorial\r\noptimization problems possess an unconnected efficient set in general\r\n(including problems on matroids), we show that for special classes\r\nof biobjective optimization problems on matroids involving\r\none objective function with binary costs the efficient set is always\r\nconnected.\r\nThis is the first non-trivial problem on matroids where\r\nconnectedness of the efficient set can be established.\r\nCorresponding references are given and related to our results.\r\n", :title "Biobjective Optimization Problems on Matroids with 0-1 Objectives", :keyword2 "Multiple Objective Optimization", :authors (1560 19059), :session 222}, 442 {:keyword1 "Lineare Optimierung", :keyword3 "Regelleistung", :abstract "Netzdienstleistungen und insbesondere die Bereitstellung von Regelleistung gewinnen vor dem Hintergrund steigender Einspeisung fluktuierender Erzeugungseinheiten immer mehr an Bedeutung. Angesichts der Vielzahl an geplanten und in Bau befindlichen Windparks auf offener See, nimmt die installierte Windenenergiekapazität in den kommenden Jahren auf ähnlich hohem Niveau zu, wie in den zurückliegenden Jahren, was voraussichtlich einen weiter steigenden Bedarf an Regelleistung zur Folge hat. Da die Fähigkeit, Regelleistung bereitstellen zu können, zwischen den einzelnen Kraftwerkstypen variiert, hat der Bedarf an Regelleistung einen signifikanten Einfluss auf Investitionsentscheidungen des Kraftwerksparks. Daher ist es für eine verlässliche Investitionsplanung bzw. eine Analyse des Energiesystems unabdingbar, den Regelenergiemarkt detailliert abzubilden.\r\nZur Entscheidungsunterstützung bei der Investitionsplanung werden häufig sogenannte Energiesystemmodelle eingesetzt. Im vorliegenden Artikel wird aufgezeigt, wie Reservekapazitäten in Energiesystemmodellen bislang modelliert wurden und welche Möglichkeiten gegeben sind, die einzelnen Produkte des Regelenergiemarktes detailliert abzubilden. Es werden sowohl die den Regelenergiemarkt abbildenden neuen Nebenbedingungen als auch ausgewählte Nebenbedingungen sowie die Zielfunktion des Modells vorgestellt. Die Umsetzung wird beispielhaft am Energiesystemmodell PERSEUS aufgezeigt. Dieses ist als ein lineares Optimierungsmodell mit der Zielfunktion der Ausgabenminimierung des gesamten Systems implementiert. Ausgewählte Ergebnisse der Modellrechungen zum Einfluss der Reservekapazitäten auf die Entwicklung der Elektrizitätssysteme werden präsentiert.", :title "MODELLIERUNG VON REGELLEISTUNSMÄRKTEN IN ENERGIESYSTEMMODELLEN", :keyword2 "Energiesystemmodell", :authors (19571 14876 22954), :session 163}, 443 {:keyword1 "berth allocation", :keyword3 "worst case analysis", :abstract "We model the berth and quay cranes allocation problem as a moldable task scheduling problem.\r\nThe moldable task scheduling problem can be stated formally as follows: we consider a set of m identical processors (quay cranes) used for executing the set of n independent, non-preemptable (i.e., once a task starts its execution, it has to be processed on the processors it is assigned to without any interruption for the period of its processing time) moldable tasks (ships). Each moldable task (MT) has a processing time which is dependent on the number of processors to be allocated for its execution. As the number of processors allocated to a task is a decision variable by definition of moldable tasks.\r\nAs a result, we define the processing speed of a moldable task which depends on the number of processors allocated to it. The dependence of a moldable task processing time on the number of processors allocated is given as a discrete function; that is, it takes values at the integer points only. \r\nThe criterion assumed is the schedule length. The problem of scheduling independent MT without preemption is NP-hard.\r\n\r\nFrom a different point of view, we may consider a problem in which the processors represent a continuously divisible renewable resource bounded from above. In this problem the processor (resource) allocation is not required to be integer. To transform a continuous allotment of the number of processors greater than one for any task into a discrete one, it is sufficient to round off the number of processors used to the largest integer values smaller than the continuous ones. Then, the execution time of any task is not increased more than by a factor of 2. The tasks for which the continuous allotment is less than 1 are assigned on only one processor. Their execution times will decrease but their surface does not change. Since the total number of processors used by these tasks is no smaller than that of a continuous solution, their execution time achieves the Graham's bound at most. Thus, the makespan of the discrete version is at most twice as long as the optimal continuous one. In our algorithm we use a special rounding scheme to provide better results.\r\n\r\nWhen the number of processors assigned in the continuous solution is between 0 and 1 for each task, the speed function is linear, and then the continuous solution is equal to the discrete one where preemptions are allowed. In this case, in the worst case schedule length generated by our algorithm achieves the Grahambound.\r\n\r\nWhen the processor allocation in a continuous solution is greater than 1 and less than 1.5 or greater\r\nthan 2, processor allocation in the discrete moldable solution is the first integer number less than continuous allocation (rounding down). In this case, the completion time of a task grows but no more than 50\\% as compared to the continuous solution. Moreover, the sum of the processors allocated to these tasks is\r\nlower than m.", :title "Worst case analysis for berth and quay crane allocation problem", :keyword2 "moldable task", :authors (26362 5390 8542), :session 146}, 444 {:keyword1 "Technology of the information ", :keyword3 "Maturity Model", :abstract "INTRODUCTION: There is no precedent on similar studies for entities filed at the local level, is the first study conducted on the basis of a model and methodology validated internationally as a standard in the field of Information Technology (IT). The study was conducted for two entities the private sector and of government of Peru. OBJECTIVE: Evaluation of their systems and the risks of IT to improve services and maximize resources\r\nMETHODOLOGY: COBIT (Control Objectives for Information and related Technology), proposed by ISACA, is a model for auditing the management and control of information systems, and is the internationally accepted as best practice in IT. Maturity Model, measures the degree of development of the processes of the organization. Their approach is based on or CMMI Maturity Model (Capability Maturity Model Integration) software development (CMM-SW) of the SEI-Software Engineering Institute of Carnegie Mellon University. COSO is a methodology for assessment and risk analysis. RESULTS: With the Maturity Model was applied a scoring method by which each organization can self-evaluate its reality with the COBIT's processes on a scale ranging from non-existent to optimized (0 to 5). To obtain the results we lined the 24 components evaluated with COSO at the 4 domains (34 IT processes) of COBIT. CONCLUSION: Of the study, we found weaknesses in control systems and IT services, the corrective actions were over 40 technical recommendations. We conclude then in the need that the entities under study give a strategic thrust to implement the recommendations that were structured in a plan to improve IT (2012) in the medium term, with which the organizations will achieve a level 3 within the scale CMMI maturity model.", :title "Evaluation of the computer system and risks of the technology of the information of peruvian entities", :keyword2 "Systems ", :authors (23601), :session 22}, 447 {:keyword1 "Jackson networks", :keyword3 "Quasi-stationary distribution", :abstract "This talk tries to contribute to a better understanding of the behavior of networks that cannot approach a classical equilibrium state.\r\nWe consider Jackson networks. A common ergodicity condition for classical Jackson networks is a rate condition: The arrival rate of each node has to be strictly less than its service rate. If this condition is violated for some nodes, the complete network process is not ergodic and no stationary distribution exists. Nevertheless, it is known that parts of the network (where the rate condition is fulfilled) stabilize in the long run.\r\nThe asymptotics of such stable subnetworks were derived by Goodman and Massey (1984): The state distribution of the stable subnetwork converges to a Jackson-type product form distribution. Having observed such a special asymptotic behavior we use a quasi-stationary approach to obtain information about the finite time behavior of the stable subnetworks.", :title "On the behavior of stable subnetworks in non-ergodic Jackson networks: A quasi-stationary approach", :keyword2 "Non-ergodic Markov process", :authors (26281 17075), :session 129}, 452 {:keyword1 "integrated vehicle-crew-roster", :keyword3 "multi-objective optimization", :abstract "The integrated vehicle-crew-roster problem (VCR) aims to simultaneously determine a minimum cost set of vehicle blocks that daily covers all timetabled trips, a set of crew duties that daily covers all vehicle blocks and a minimum cost roster where the daily crews are assigned to the company drivers for the time horizon. This paper presents a special case of the VCR, the VCR_P, where the rosters for a specific group of drivers, besides satisfying all labor rules of the company, should follow a pre-defined days-off pattern. In the VCR_P, taking into account the days-off pattern in use at a major mass transit company operating in the city of Lisbon, for a time horizon of 7 weeks, each pattern includes 4 rest periods of 2 consecutive days-off (do2) and 2 rest periods of 3 consecutive days-off (do3), which include Saturday. The two rest periods of type do3 occur in sequence and between them there is a work period of 5 days. The remaining work periods have 6 consecutive work days. \r\nThe objectives of the VCR_P derive from the minimization of vehicle and driver costs. Since “unpopular” duties and overtime are undesirable they should also be minimized and equitably distributed. All these objectives represent various conflicting interests that usually cannot be fulfilled simultaneously thus leading to a multi-objective perspective for the problem. Hence, the VCR_P is modelled as a multi-objective mixed binary linear problem where three main combinatorial structures may be identified: an integer multi-commodity network flow problem, a set partitioning/covering structure and an assignment/covering structure. Taking advantage of this mathematical model we propose a heuristic approach with embedded column generation and branch-and-bound techniques within a Benders decomposition. The decomposition approach alternates between the solution of an integrated vehicle-crew scheduling problem and the solution of a multi-objective rostering problem. The methodology was tested on some instances from a bus company operating in Lisbon and the computational results are promising.", :title "An integrated vehicle-crew-roster problem with days-off pattern", :keyword2 "Benders decomposition", :authors (2707 2135 2139 2136), :session 211}, 455 {:keyword1 "process design", :keyword3 "random capacity requirements", :abstract "In this paper, we develop models for capacity planning within the framework of stochastic processing times and stochastic demand for different process outcomes in high-flexibility environments. High-flexibility environments include flexible and fully utilizable capacity in each period, e.g. through flexible work contracts. We particularly address stochastic interdependencies between processing times for different processes (inter-process correlation), interdependencies between capacity consumption (task times) of different executions of the same task in a given production stage (intra-process correlation) as well as interdependencies between demand for different process outcomes. In practice, these interdependencies might be caused by follow-up inefficiencies if quality problems in a production stage have occurred. Another potential source of correlations are employees with varying skill levels flexibly assigned to different stages. These arguments show that stochastic influences are not purely random. However, for modeling purposes we consider “as-if” random variables to analyze the impact of stochastic influences and their interdependencies. After presenting the base model, we discuss different implications of normal and gamma distributed processing times. Furthermore we conduct extensive sensitivity analyses and scenario-based examples (based on real world data) showing the relevance of stochastic influences on both demand and processing times. Moreover, we demonstrate that demand-related, intra-process and inter-process correlations can reduce overall variance with positive consequences for capacity management.", :title "Capacity management under uncertainty with inter-process, intra-process and demand interdependencies in high-flexibility environments", :keyword2 "capacity planning", :authors (17120 17090 1658), :session 160}, 457 {:keyword1 "Implicit shift scheduling", :keyword3 "physician rostering", :abstract "We present a strategic model to solve the long term staffing problem of physicians in hospitals using flexible shifts. The objective is to minimize the total number of staff subject to several labor agreements. A wide range of legal restrictions and facility-specific staffing policies are considered. Furthermore, the model decides about staffing ratios, i.e. the number of full-time versus part-time physicians. The resulting model constructs shifts implicitly rather than starting with a predefined set of several shift types. We formulate the problem as a mixed-integer program and solve it applying standard software. Using data provided by an anesthesia department of an 1100-bed hospital, computational results demonstrate the usage of the model as decision supporting tool when staffing decision are made by hospital management.", :title "Long Term Staffing of Physicians in Hospitals", :keyword2 "workforce planning", :authors (15060 26673), :session 37}, 460 {:keyword1 "Offline time synchronization", :keyword3 "Least squares", :abstract "In the design process of communication protocols it is necessary to perform repeated network communication experiments. Each run results in large event logs. The analysis of these logs is crucial to find and to understand unexpected behaviors and design flaws. Intrinsic to network communication these logs suffer from random delays, drop outs, and deviating clocks, which complicate the analysis.\r\n\r\nOnline synchronization protocols may interfere an experiment gravely and are unable to handle delays and drop outs. Offline synchronization approaches based on affine linear clocks using maximum likelihood estimation and least squares estimation are introduced by Scheuermann et al. [On the time synchronization of distributed log files in networks with local broadcast media; 2009] and Jarre et al. [Least squares timestamp synchronization for local broadcast networks; 2010]. We show that their approaches can be extended easily to non-linear clocks with principal properties preserved: The maximum likelihood estimator leads to a sparse linear program with well-known structure, which can be readily solved by an interior point method, and the least squares estimator is consistent under weak assumptions.\r\n", :title "Offline Time Synchronization", :keyword2 "Maximum likelihood", :authors (26190 27025), :session 175}, 461 {:keyword1 "network analysis", :keyword3 "", :abstract "Interorganizational networks have become more important as pressure from competition and technological innovation is continuously increasing. Studies have proven that e.g. logistic networks can meet new requirements resulting from globalization and therefore higher competition better than a single organization. Thus, each organization is interested in a sustainable and functioning network. It also pursues individual aims such as profits, gaining knowledge or influence resulting from relationships with network partners. With respect to the sustainability of the network, there are still open questions as examples from failing networks show. For example, what happens if a company (or country) is forced to leave the network? Then the other network companies have to decide whether to help e.g. by monetary aid. In other words, the question remains whether to optimize the individual gain or the network’s objectives.\r\nBased on this, the research question is to find out what happens if the network is threatened to get in disequilibrium. Then companies have to decide whether to help if an organization becomes needy. Thus, organizations consider various consequences. They mainly depend on the importance of the needy organization, if it can e.g. be replaced or if the network will decompose without it. To answer the research question the attributes that determine the term ”systemic relevancy” must be defined and it must be shown how systemic relevant organizations can be defined and modeled with their respective attributes.\r\nA game theoretical approach is chosen to model opportunities and strategies for the network partners. Furthermore, different network relationships have to be explored. For modeling and simulation runs at the end we use agent based simulation.", :title "A framework for exploring systemic relevant nodes in a network and simulating behavior of dynamic networks based on agent-based simulation", :keyword2 "agent based modeling", :authors (26211 16971 26417), :session 43}, 466 {:keyword1 "Transit fares", :keyword3 "Transportation", :abstract "In this paper a model for the optimisation of transit fares is proposed and tested on a real-scale network. The aim of this model is to optimise the transit fares minimising the total costs (transit and car user costs, operational costs and external costs). This model considers a multimodal transportation system under the assumption of elastic demand for simulating the impacts of fare policies on modal split.\r\nThis problem can be seen as a multimodal network design problem in which transit fares assume the role of decision variables.\r\nIn the paper we test two objective functions; the first objective function considers only system costs and user costs, adapted to our multimodal problem; the second also considers the external costs produced by road traffic.\r\nFor solving the problem on real-scale networks two approaches and related algorithms have been proposed; an approach considers the problem as monodimensional, optimising only a “basic fare” and all other fares are proportional to the basic one. In this case a heuristic mono-dimensional algorithm will be proposed and compared with an exhaustive search, that can be applied in acceptable computing times.\r\nThe second approach considers the problem as multidimensional, optimising all fares of transit services, changing also the current fare framework. In this case a meta-heuristic algorithm (Scatter Search) will be proposed; it shall lead to local optimal solutions in acceptable computing times. A comparison between results obtained with the proposed approaches will be presented, in order to verify if the greater computational effort due to multidimensional approach is compensated by a significant improvement of final solution.\r\nThe proposed approaches and solution algorithms will be tested on a real-scale network.\r\n", :title "Optimisation of transit fares on real-scale networks", :keyword2 "Scatter Search", :authors (1943 1891 1892), :session 210}, 470 {:keyword1 "large scale semidefinite optimization", :keyword3 "nonsmooth second order methods", :abstract "The usefulness of semidefinite optimization is increasingly recognized\r\nin ever wider areas of mathematics and entails increasing demand for\r\nefficient and hopefully reliable numerical solvers. The spectral\r\nbundle method is a nonsmooth first order solver developed for \r\nsemidefinite optimization over large sparse matrices. In theory it is well known through\r\nthe work of Oustry how to combine this first order approach with the\r\nsecond order approach of Overton, but no tool offering this\r\nfunctionality is available and it is not clear how to best approach\r\nthis in a large scale setting. In this presentation we report on work\r\nin progress towards including second order functionality in a\r\npractical implementation of the spectral bundle method within the\r\nConicBundle callable library and present some first numerical results.\r\n", :title "Towards Second Order Implementations of the Spectral Bundle Method", :keyword2 "spectral bundle method", :authors (17006 23189), :session 105}, 472 {:keyword1 "Clearance pricing", :keyword3 "Dual channels", :abstract "We consider a problem faced by a catalog retailer in clearing common stock from two channels - catalog and web. On the web the retailer can change prices based on sales feedback but for fashion items the retailer can set the clearance price only once for catalog customers. We develop a two-stage stochastic program to determine the optimal prices and allocation of stock between the two channels.", :title "Clearance pricing for dual channel catalog retailers", :keyword2 "Dynamic pricing", :authors (26413), :session 93}, 473 {:keyword1 "Flughafenmanagement", :keyword3 "Simulation", :abstract "Bei der Gestaltung von Mobilitätsstrukturen stellen Flughäfen die zentralen Infrastruktureinrichtungen dar. Deren Bau bzw. Erweiterung ist mit einem hohen Investitionsaufwand verbunden und erfordert einen langen Planungs- und Realisierungszeitraum. Hinzu kommt, dass Verkehrsinfrastrukturmaßnahmen immer wieder in der Umsetzung zeitlich behindert (und auch endgültig verhindert) werden. Aufgrund dieser Rahmenbedingungen sind langfristige Lösungen erforderlich, die für einen vorgegebenen Planungshorizont eine effiziente Betriebsdurchführung erlauben.\r\nHieraus ergibt sich die Problemstellung, eine Kapazitätsauslegung zu ermitteln, die neben den bestehenden auch die zu erwartenden Bedarfsstrukturen abdecken kann. Ausgehend von den infrastrukturbedingten Restriktionen sowie den technischen Vorgaben im Flugbetrieb (u.a. Einhaltung von Abständen bei Starts und Landungen) wird mit Hilfe eines Simulationsansatzes analysiert, welche Aufkommenszuwächse bei einer bestimmten Infrastrukturkonfiguration bewältigt werden können.\r\nUntersucht wird diese Fragestellung am Beispiel des Flughafens BBI. Ausgangspunkt ist ein Basisszenario im unabhängigen getrennten Parallelbahnbetrieb auf Grundlage des bestehenden Aufkommens an Flugbewegungen im Tagesverlauf sowie dem Mix bei den Flugzeugtypen (nach Turbulenz- und Gewichtsklassen) auf den Flughäfen Tegel und Schönefeld. Dieses wird variiert hinsichtlich der Klassenverteilungen im Mix und einer schrittweisen Aufkommenssteigerung. Es zeigt sich dabei, dass ein Bedarfsanstieg in einem gewissen Rahmen verkraftet werden kann, aber auch, dass bei bestimmten Entwicklungen die Grenzen erreicht werden können, insbesondere beim Anwachsen von Verspätungen.\r\n", :title "Analyse der luftseitigen Kapazitätsanforderungen bei der Planung von  Flughäfen durch Simulation", :keyword2 "Kapazitätsplanung", :authors (15154), :session 200}, 474 {:keyword1 "Connected facility location", :keyword3 "approximation algorithms", :abstract "Connected facility location problems have gained a lot of attention in recent years. Given a set of clients and potential facilities, one has to construct a connected facility network and attach the remaining clients to the chosen facilities via access links. Problems of this type arise in many different applications areas, such as transportation, logistics, or telecommunications.\r\n\r\nHere, we consider interconnected facility location problems, where we request connectivity in the subnetwork of facilities disregarding all non-facility nodes.  This type of connectivity is required in telecommunication networks, where facilities correspond to core nodes, which communicate with each other directly, excluding clients.  For network reliability, it is desirable to have (at least) 2-connectivity among facilities.\r\n\r\nWe show that the interconnected facility location problem is strongly NP-hard for both 1- and 2-connectivity, even in graphs with metric weights. We present simple randomized approximation algorithms with expected approximation ratios 4.53 for 1-connectivity and 4.52 for 2-connectivity.  For the classical 2-connected facility location problem, which allows to use non-facility nodes to connect facilities, we obtain an algorithm with expected approximation guarantee of 4.35.\r\n", :title "Securely Connected Facility Location in Metric Graphs", :keyword2 "telecommunication networks", :authors (56196 13058), :session 214}, 482 {:keyword1 "MAUT", :keyword3 "Aggregation of preferences", :abstract "Traditional decision theories such as the multi-attribute utility theory (MAUT) require the independence of preferences. In practice, however, preferences of different attributes are often correlated, e. g. by synergy effects. Therefore it is desirable to develop a decision theory that allows for such interdependencies.\r\nThis paper introduces a new model called aggregate utility coefficient model (AUCM) that extends the traditional MAUT such that dependent preferences can be accounted for. In such case, decision makers articulate their preferences relatively to an average of an alternative by means of interaction coefficients. The dimensional-specific preferences are multiplied to yield utility level on which the final decision is based.\r\nThe terms obtained by a second or higher order Taylor expansion of the product at the average preference level are economically interpreted. Terms depending on one attribute are only virtually identical with the utility function of one attribute in the traditional MAUT. Terms depending on more than one attribute are used for modeling interdependencies. A straightfor-ward algorithm allows computing the utility level according to the expressed preferences and their interdependencies. Therefore, AUCM appears as a useful extension of MAUT.\r\n", :title "Modeling of complementary interactions – conception of an innovative approach in multi-attribute utility theory", :keyword2 "Elicitation of preferences", :authors (23271), :session 234}, 490 {:keyword1 "Traffic planing", :keyword3 "Airports", :abstract "In 2007 the worldwide passenger numbers have increase by 7% and the European Union is predicting a shortage of airport capacity in Europe for the next decade. Many airports are facing the decision to enlarge their capacity but is this economically reasonable? Will air travelling enjoy increasing popularity? But the neighbours of airport are very much against more traffic. Also, air passenger forecasting on a disaggregated level is a very volatile enterprise. In this paper we propose a macro-economic approach to estimate the air passenger traffic in Europe and we estimate an air demand equation econometrically. We can show that there is empirical evidence that increasing airport capacity has a macron-economic growth effect on the whole economy. With the data of Austria and Vienna we show that air passengers have a long-range positive impact for GDP growth and investments. In a European model we try to estimate the individual country effects and the limited influence of competition between airports.", :title "Are larger airports a motor of growth? A case study for the Vienna airport ", :keyword2 "Forecasting", :authors (11148), :session 206}, 494 {:keyword1 "Quantity Flexibility", :keyword3 "Inventory Management", :abstract "This study is motivated by the operations of an international firm that has a sales headquarters placing orders to the manufacturing facilities for multiple items. Although the aggregate order quantity is firm, the headquarters has the opportunity to modify the composition of the aggregate order after gathering further information on demand.\r\nWe consider a supply chain consisting of a single retailer and a single manufacturer, where the retailer sells two products in a single period. The products differ in a few number of parts only. The retailer places initial orders based on preliminary demand forecasts and has an opportunity to modify his initial order after receiving perfect demand information. However, the aggregate final order quantity should be equal to the aggregate initial order. The manufacturer places a regular order for the common parts of the products, which exactly matches the aggregate order quantity of the retailer. She also places individual initial orders for the distinct parts. Once the retailer’s individual orders are finalized, she may have to place an expedited order depending on her initial stock of distinct parts.  \r\nIn this setting, we analyze the problem in two stages and first characterize the final orders of both parties given the demand realization and the initial orders. Incorporating these into the first stage problem, we then optimize for the initial orders. We investigate the effects of various system parameters on the order quantities of both parties analytically. Through an extensive computational study, we compare the flexibility scheme described above to a traditional, single-order opportunity system. Our preliminary findings indicate that the benefits of such a flexibility arrangement can be substantial for both parties.\r\n", :title "Quantity Flexibility for Multiple Products in a Decentralized Supply Chain", :keyword2 "Supply Contracts", :authors (1838 25631), :session 112}, 495 {:keyword1 "Two dimensional cutting problem", :keyword3 "Simulated annealing", :abstract "Selection of cutting patterns in order to minimize production waste is an important issue in operations research, which has attracted many researchers. Solving this problem is very important in the industries that have priorities in minimizing the waste in the Pages section.\r\nIn this paper, the two-dimensional cutting stock problem has been studied to reduce the cutting waste, with focus on men’s clothing (male pants size 42).\r\nIn this method, regular and irregular shapes are enclosed by rectangles the goal is to minimize waste in total fabric. As solving these problems optimally are infeasible with current optimization algorithms because of the large solution space, the metaheuristic algorithm of simulated annealing (SA) was used.\r\nOne of the main objectives of this research is to calculate the optimum length of fabric rolls, such that when several of such rolls are put together, the amount of cutting waste is minimized. To achieve this goal, we initially consider an unlimited length for each roll, and then obtain the optimum length of each roll.\r\nThis research shows that the amount of required stock can be reduced in fabric cutting by using the SA algorithm. Moreover, if the length of pieces is not fixed, incontrollable stock can be changed into controllable ones; e.g., stock could be concentrated in a form which is usable in future consumption.\r\n", :title "Two-Dimensional Cutting Stock Management in Fabric Industries with simulated annealing ", :keyword2 "Metaheuristic methods", :authors (23143), :session 213}, 496 {:keyword1 "Ground Crew Rostering", :keyword3 "Vehicle Routing", :abstract "This thesis addresses an Airline Ground Crew Rostering Problem (GCRP) provided by an international airline in Europe: Given the demand in number of staff for each shift, the objective is to construct rosters that minimize the total overcover and undercover while satisfying the time regulations including max number of consecutive night shifts; min consecutive day on; no morning shift after a night shift, etc. Day off pattern can either be repeating or non-repeating. Three different scenarios are considered: only repeating rosters are allowed; only non-repeating rosters are allowed; both are allowed while the repeating ones are preferred.\r\nThe problem can be formulated as a Vehicle Routing Problem (VRP) with time regulations. A column generation approach is proposed where the subproblem is an Elementary Shortest Path Problem with Resources Constraints (ESPPRC). A label-setting algorithm with tight dominant conditions is developed to solve the subproblem. However, column generation approaches with a difficult subproblem are proved to be inefficient in many literatures especially for large problem size. This thesis contributes a novel column generation approach to work around this difficulty. Large problems are first decomposed into blocks of smaller problems and then solved sequentially. Additional constraints are introduced in advanced and in runtime to improve the solution value and to ensure the feasibility respectively. The proposed algorithm gives a tight lower bound and a feasible solution. Extensive computational result shows that the proposed approach outperforms the standard column generation approach. Solution of all datasets spanning up to 6 months, 10 shifts and 1600 staff (1800 nodes) can be solved to near optimality within a few minutes.", :title "A column generation approach for large scale Airline Ground Crew Rostering Problem ", :keyword2 "Column Generation", :authors (23007), :session 220}, 498 {:keyword1 "web service composition", :keyword3 "fault tree", :abstract "Web services composition is an emerging software development paradigm for the implementation of distributed computing systems. A service integrator can produce added value by delivering more abstract and complex services obtained by composition: but while isolated services availability can be improved by tuning and reconfiguring their hosting servers, in the case of Composed Web Services (CWS) basic services have to be taken as they are; in this case a reasonable measure is to evaluate the effects of the composition. We propose an analysis methodology that allows availability evaluation of CWS by transforming BPEL descriptions into models based on the fault tree formalisms family. BPEL definition of a CWS intrinsically describes the relations by which the availability of component basic services influences the availability of the composed one. Systematic analysis of BPEL language elements allows the definition of equivalent fault tree patterns that represent their effects on the composition. With this premises, it is possible to obtain an evaluation of the availability of a CWS given components availability and the expected execution behaviour of the CWS. When used in a system development cycle, such a tool enables designers to compare alternative BPEL compositions of the same or of different sets of services and to explore the benefits of redundant configurations or of the implementation of different fall back mechanisms. Moreover, this approach guides service integrators in the choice of single component services by unveiling their actual influence on the overall service with usual fault tree based analysis techniques. The proposed paper aims to present translations criteria of BPEL elements into fault tree patterns to apply them to the evaluation of an example CWS.", :title "Evaluating availability of composed web services", :keyword2 "service availability", :authors (26389 26428), :session 132}, 501 {:keyword1 "Feature Selection", :keyword3 "Concave Programming", :abstract "In this work we consider the feature selection problem, a challenging task arising in several real-world applications. Given an unknown functional dependency, we aim to find the relevant features of the input space, namely we aim to detect the smallest number of input variables while granting no loss in accuracy. Our main motivation lies in the fact that the detection of the relevant features provides a better understanding of the underlying phenomenon, and this can be of great interest in important fields such as medicine and biology. Feature selection involves two competing objectives: the prediction capability (to be maximized) of the learning machine and the number of features (to be minimized) employed. In order to take into account both the objectives, we propose a feature selection strategy based on the combination of support vector machines (for obtaining good learning machines) with a concave optimization approach (for finding sparse solutions). We report results of an extensive computational experience showing the efficiency of the proposed methodology.", :title "Feature selection via concave programming and support vector machines", :keyword2 "Support Vector Machines", :authors (19340 20723 26429), :session 79}, 502 {:keyword1 "spectral graph theory", :keyword3 "embedding", :abstract "In order to better understand spectral properties of the Laplace matrix of a graph, we optimize the edge weights so as to minimize the maximal eigenvalue of the weighted Laplacian. Using a semidefinite programming formulation, the dual program allows to interpret the dual solution living in the optimized eigenspace as a graph realization. We study connections between structural properties of the graph and geometrical properties of this graph realization. In an analogous way we minimize the difference of the maximal an the second smallest eigenvalue of the graph and present properties of the corresponding embeddings.", :title "Optimizing extremal eigenvalues of the weighted Laplacian of a graph", :keyword2 "eigenvalue optimization", :authors (15080 17006), :session 222}, 503 {:keyword1 "wavelets", :keyword3 "filters", :abstract "\r\n\r\nAbstract\r\nAn ideal band-pass filter removes the frequency components of a time series that lie within a particular range of frequencies. In practice, it is difficult to construct an \"ideal\" band-pass filter as it requires an infinite number of data points. Therefore, an approximation to an ideal filter is used to extract the components of a time series in a particular frequency range, such as business cycles with known duration. We present several examples of filters in economics and finance, exponentially weighted moving average (EWMA) estimate of volatility in a foreign exchange market, Hodrick and Prescott filter in macroeconomics, and other examples of filters used in the technical analysis of prices in financial markets.\r\n", :title "Wavelets in Economics and Finance ", :keyword2 "volatility", :authors (23961), :session 97}, 509 {:keyword1 "Optimal path problem", :keyword3 "OSM", :abstract "Among the recent advancements in the field of single source - single destination optimal path algorithms is the introduction of Contraction Hierarchies. After building a total order on the nodes of the graph a bidirectional Dijkstra-search is performed on the hierarchy implied hereby. The search space needed is drastically cut compared to other approaches, consequently queries are strongly accelerated.\r\nWe present an application on OpenStreetMap (OSM) data using a Java implementation of the algorithm. Additionally we show a modification of the original algorithm even more increasing its performance.\r\nBased on the road-network of Lower Saxony extracted from OSM we present results of a set of benchmarks and measure computing times for driving time and distance estimates. These estimates are very frequently needed while solving large real-world tour planning problems. Depending on the problem instance, thousands or even millions of time/distance comparisons are executed. Hence this usually forms the major bottleneck of such problems.\r\n", :title "Contraction Hierarchies and OpenStreetMap: Fast Optimal Routing", :keyword2 "Contraction Hierarchies", :authors (14705 14704 14803), :session 209}, 510 {:keyword1 "nonlinear optimization", :keyword3 "gas networks", :abstract "In this paper we consider the nomination validation problem in natural\r\ngas distribution networks. The flow of gas in a pipeline is driven by\r\nthe pressure square difference of its end nodes as modeled in\r\nWeymouth's equation, while active devices like compressors and valves\r\nare modeled by being in a so-called free mode.  A nomination is a\r\nspecified input and output demand at each entry and exit node of the\r\nnetwork whose total sum is zero, and the nomination validation problem\r\nmeans to decide whether there exists a pressure configuration at the\r\nnodes generating a given nomination.  Using variational inequality, we\r\nprove the existence of at least one solution to this problem. In the\r\nspecial case when only pipes are contained in the network, the\r\nfeasible pressure configurations form a straight line in the pressure\r\nsquare space, and by formulating the system as the\r\nKarush-Kuhn-Tucker-conditions of a strictly convex program, we prove\r\nthat this line can be calculated efficiently by solving a convex\r\nprogram.  We also give an imaginable interpretation of our model by\r\nassociating every pipe with a rubber band. This allows us to\r\ndemonstrate the so-called more-edge-less-capacity phenomenon arising\r\nin such networks, which we further analyze in the paper.  By imitating\r\nthe physical process during which the set of rubber bands reaches its\r\nsteady state we develop a specifically tailored optimization method to\r\ncompute a pressure configuration which generates a nomination.  Both\r\nthis optimization method and the above mentioned convexifying approach\r\nhave a dual variant, which were also implemented. Finally, we evaluate\r\nthe performance of all these optimization methods on large-sized,\r\nreal-world gas distribution networks, provided by our industry\r\npartner.", :title "Efficient optimization methods to nomination validation in gas transmission networks", :keyword2 "convex optimization", :authors (25350 26282), :session 155}, 512 {:keyword1 "Data Envelopment Analysis", :keyword3 "centralized resource planning", :abstract "Among other reasons, due to asymmetric information and individual ambitions of semi-autonomous decision makers, the production of goods and/or services in decentralized organizations rarely is efficient. Branch managers and entire branches, pursuing own interests and fighting for larger fractions of shared resources, impede any efforts made by a central management to enhance the organization’s overall performance. Such intra-organizational market failure could cause a suboptimal allocation of resources, resulting in inefficiencies. In the recent past, promising approaches to dynamic incentives and performance management have been developed based on Data Envelopment Analysis (DEA). However, these incentive mechanisms are unable to account for the interdependences of strategic behavioral changes, the reactions of other branch managers and possible improvements by a reallocation of resources between the branches. To suit the specific needs of intraorganizational performance management, we suggest changing the perspective of performance evaluation. Based on a DEA model for centralized resource planning by Lozano and Villa(2004), we develop three new performance measures that can be used to define optimal, dynamic incentive schemes for branches and branch managers and increase the overall performance of decentralized organizations. For suggestive evidence, we evaluate the performances of branches of a German bank and develop an optimal incentive scheme.", :title "Centralized Super-Efficiency and Yardstick Competition - Incentives in Decentralized Organizations", :keyword2 "Yardstick Competition", :authors (26411 6136 13887), :session 189}, 516 {:keyword1 "Performance Assessment", :keyword3 "Fuzzy DEA", :abstract "The literary works in performance assessment provides a variety of assessment approaches in Health, Safety, and Environment contexts. Sophisticated expert system methods (e.g., fuzzy logic), score-based models (e.g., BSC, EFQM), and statistical techniques (e.g., Spearman Correlation, Safety Culture Checklists Analysis) have been effectively adopted to further enrich this area of study. However, despite the growing need for optimization- and process-based methods as well as standard-based indicators, which simultaneously consider inputs and outputs; this discipline, is yet to enjoy effective methods to reduce the human error, to interpret the large amount of vague data, and to recommend improvement and system optimization solutions. Through FDEA (Fuzzy Data Envelopment Analysis), a multivariate method based on linear programming, this study assesses the HSE-IMS (Health, Safety, and Environment Integrated Management System) performance of a holding company in power plant industries. In doing so, it integrates HSE-MS specifically with OHSAS 18001 as well ISO 14001 to collectively analyze the inputs and outputs of over thirty (30) subsidiary HSE departments, as Decision-Making Units (DMUs), with equivalent mission and objectives. DMUs consume 3 resources as the main inputs to produce 7 outputs that meet the HSE-IMS requirements (clauses). These outputs are gathered through observations of the certified HSE auditors and are scored on the scale of zero to hundred in a specifically-designed checklists of HSE-IMS clauses. Not only does the FDEA results rank the relevant performance efficiency of the DMUs, but also competently determines the optimum model for each of them, and could assure the continuous improvement in the organization at its entirety.  ", :title "Performance assessment and optimization of HSE-IMS by Fuzzy DEA: The Case of a holding company in power plant industries", :keyword2 "HSE-IMS", :authors (17401 7862 26505 26865), :session 156}, 517 {:keyword1 "One-Dimensional Cutting Stock Problem", :keyword3 "Trim loss-Oriented CSP", :abstract "Nowadays, One-Dimensional Cutting Stock Problem (1D-CSP) is used in many industrial processes and recently has been considered as one of the most important research topics. In this paper, an optimization model is represented to minimize the trim loss and also to focus the trim loss on minimum number of large objects in CSP. In this Trim loss-Oriented model, the remaining large objects will be appeared on the minimum number of beams with the largest possible length, so they can be used easier in the future cutting orders.\r\nThis model minimizes a cost function which is created by assigning a virtual cost to the trim loss of each stock.", :title "Trim Loss Concentration Modeling in One-Dimensional Cutting Stock Problem by Defining a Virtual Cost “Trim Loss-Oriented Model”", :keyword2 "Trim Loss Concentration", :authors (22670 25095), :session 86}, 518 {:keyword1 "Production/Inventory Control", :keyword3 "Make-to-stock Queues", :abstract "In this paper, we study a system consisting of a manufacturer or supplier serving several retailers or clients. The manufacturer produces a standard product in a make-to-stock fashion in anticipation of orders emanating from n retailers with different contractual agreements hence ranked/prioritized according to their importance. Orders from the retailers are non-unitary and have sizes that follow a discrete distribution. The total production time is assumed to follow a k0-Erlang distribution. Order inter-arrival time for class l demand is assumed to follow a kl-Erlang distribution. Work-in-process as well as the finished product incur a, per unit per unit of time, carrying cost. Unsatisfied units from an order from a particular demand class are assumed lost and incur a class specific lost sale cost. The objective is to determine the optimal production and inventory allocation policies so as to minimize the expected total (discounted or average) cost. We formulate the problem as a Markov decision process and show that the optimal production policy is of the base-stock type with base-stock levels non-decreasing in the demand stages. We also show that the optimal inventory allocation policy is a rationing policy with rationing levels non-decreasing in the demand stages. We also study several important special cases and provide, through numerical experiments, managerial insights including the effect of the different sources of variability on the operating cost and the benefits of such contracts as Vendor Managed Inventory or Collaborative Planning, Forecasting, and Replenishment. Also, we show that a heuristic that ignores the dependence of the base-stock and rationing levels on the demands stages can perform very poorly compared to the optimal policy.", :title "Managing a Production System with Information on the Production and Demand Status and Multiple Non-Unitary Demand Classes", :keyword2 "Markov Decision Process", :authors (10744), :session 111}, 523 {:keyword1 "optimization s.t. partial differential equation sy", :keyword3 "load change ", :abstract "Molten carbonate fuel cells provide a promising technology for the operation of future stationary power plants. In order to enhance service life, a detailed understanding of the dynamical behavior of such fuel cell systems is necessary. In particular, fast load changes shall be simulated and optimized without risking material stress. Fast load changes are usually accompanied with extreme temperature differences, which may lead to irreparable damage of the fuel cell stack. On the other side, fast load changes are important for daily operation. For these contradicting goals, a family of hierachically ordered mathematical models has been developed with the aim of simulating and optimizing the temporal and spatial dynamical behavior of the gas streams, chemical reactions and electrical potential fields within the fuel cell. The validated system consists of coupled system of parabolic and hyperbolic partial differential equations involving integral terms. Part of the boundary conditions is given by a differential-algebraic equation system. The variables in this coupled multiphysics system live on considerably different time scales. Optimization results are presented for faster load changes. ", :title "Optimization of load changes for molten carbonate fuel cells", :keyword2 "fuel cell", :authors (9150), :session 99}, 525 {:keyword1 "Supplier default risk", :keyword3 "Credit risk models", :abstract "Many automotive firms have experienced suppliers prone to default. The situation has become more dramatic during the financial crisis. In a 2009 Moody’s rating of 59 global auto suppliers, 24% were investment-grade, while 76% were rated speculative. The outlook was much worse: For 1% it was positive, for 34% it was stable, and for 65% it was negative. Therefore, automotive firms need to put systems in place to identify and assess supplier bankruptcies in their effort to manage disruptions in inbound supply. The main purpose of this research is to quantify the risk in a buying firm’s supplier portfolio that stems from the financial default of suppliers. Modeling supplier defaults on the portfolio level is consistent with the extant literature that buying firms need to manage the risk in their supplier portfolios – as opposed to managing the risk of individual suppliers. Based on credit risk models we develop a methodology that buying firms can use to determine their exposure to supplier default risk. Data pertaining to supplier portfolios of upper-class car models from three German automotive manufacturers is used to illustrate the application of the methodology. We show that some car models are exposed to higher risk. This places them at a disadvantage, because the higher the supplier default risk, the more likely it is that the supply of components can be disrupted and cars cannot be built and sold. Buying firms can use this methodology for the pro-active assessment of supplier default risk. This research contributes to the literature at the interface of operations and finance.", :title "Assessing Supplier Default Risk on the Portfolio Level: A Method and Application", :keyword2 "Supplier portfolios", :authors (17140 26436), :session 109}, 528 {:keyword1 "Territory design", :keyword3 "Adaptive memory", :abstract "In some distribution companies a districting or division of the corresponding geographical basic units (city blocks in this case) must be done prior to the actual distribution of the product.  The problem of figuring out how to make this districting in the best possible way according to the company needs is referred to as a territory design problem.  This problem is modeled as a combinatorial optimization problem where the goal is to minimize a measure of territory compactness subject to several planning criteria such as territory connectivity, territory balancing with respect to two attributes (number of customers and product demand), and a budget limit in the actual routing of the product.  \r\n\r\nAll of the work developed to date focused on minimizing territory compactness neglecting the effect of the routing cost.  It is true that this makes the problem relatively more tractable.  However, this may cause the undesired effect of implementing a costly design based merely on the compactness measure. In our work, we attempt to address this issue by incorporating a budget constraint for the routing costs.  This of course makes the problem more challenging from the solution methodology perspective.\r\n\r\nIn this paper we present a model for this NP-hard optimization problem and a greedy randomized adaptive search procedure (GRASP) for generating good quality solutions.  GRASP is a metaheuristic that has proven successful to many combinatorial optimization problems.  Our technique includes an adaptive memory component that attempts to make use of frequency-based attributes to guide the search process towards better solutions.  In the empirical work, the proposed procedure is evaluated over a wide variety of problem instances.  The results indicate its effectiveness.\r\n", :title "A GRASP with Adaptive Memory for Territory Design Planning under Routing Cost Considerations", :keyword2 "GRASP", :authors (1165 26438), :session 221}, 536 {:keyword1 "Reference points", :keyword3 "Branch & Cut", :abstract "Reference point techniques provide a useful means for calculating nondominated solutions of multiobjective linear fractional programming (MOLFP) problems, since they can reach not only supported but also unsupported nondominated solutions (i.e., nondominated solutions that are dominated by unfeasible convex combinations of other nondominated solutions). In fact, it can be observed that the nondominated solution set of a MOLFP problem has, in general, a significant part of unsupported nondominated solutions. The achievement scalarizing functions (ASF) (which temporarily transform the vector optimization problem into a scalar problem) used by reference point techniques need to have a sum of objective functions component in order to guarantee that the solutions are nondominated. Otherwise, the ASF will only guarantee that the computed solutions are weakly-nondominated (thus dominated). In MOLFP the sum of the objective functions leads to a very hard problem to solve (also known as the sum-of-ratios problem) which is essentially NP-hard, and hence it is a global optimization problem.\r\nBased on some previous work on a Branch & Bound algorithm to compute nondominated solutions in MOLFP using reference points, we now present a new algorithm where special cuts are introduced. These cuts stem from some conditions that identify parts of the feasible region where the non dominated solution that optimizes the ASF cannot be obtained. Introducing the cuts substantially improves the performance of the previous algorithm. The results of several tests carried out to evaluate the performance of the new Branch & Cut algorithm against the old Branch & Bound will be reported.\r\n", :title "A Branch & Cut Algorithm to Compute Nondominated Solutions in MOLFP Via Reference Points", :keyword2 "Multiobjective linear fractional", :authors (12756 12412), :session 106}, 538 {:keyword1 "supply chain visibility", :keyword3 "low-latency decision making", :abstract "The bar for achieving real-time supply chain visibilit has been significantly raised. Buyers and suppliers emphasize the need to make smarter decisions. In this context smarter includes ‘fine grained’ and ‘on demand’. Sense and respond is a continuous process, with continuous flows of information resulting in decisions which continuously modify resource disposition, priorities and actions. \r\nSupply chain management requires the interaction and coherent cooperation between heterogeneous organizations. They rely on shared situational awareness gained through advanced intelligence and data analytics able to fuse information and detect the patterns and trends that planners and controllers must respond to.\r\nAs we move forward into the era of a smart planet, which is instrumented, interconnected and intelligent, data volumes relevant for decision making are expected to double every two years over the next decade and challenge the need for real-time decisions. Collaboration services are mandatory to enable continuous exchange of fused information ensuring very-low latency situational awareness for fine-grained decisions which continuously tune plans. \r\nIn the distributed and heterogeneous world of information, the currently needed detour to persistent storage proves to be a too long way round for any savvy business. \r\nStream Computing is a new paradigm moving away from viewing data as relatively static and running various single queries against it and rather running continuous (static) queries against data in motion.  \r\nThis paper will introduce the state-of-the technologies and position them in the framework to deliver network-enabled supply chain visibility.", :title "Supply Chain Visibility - Leveraging Stream Computing and Low-Latency Decision Making", :keyword2 "stream computing", :authors (26272 26556), :session 118}, 539 {:keyword1 "lot sizing", :keyword3 "", :abstract "This paper deals with the dynamic multi-item capacitated lot-sizing\r\nproblem under random period demands (SCLSP). Unfilled demands are backordered\r\nand a fillrate constraint is in effect. It is assumed that, according to the\r\nstatic-uncertainty strategy ofBookbinder and Tan(1988}, all decisions\r\nconcerning the time and the production quantities are made in advance for the\r\nentire planning horizon regardless of the realization of the demands. The problem\r\nis approximated with the set partitioning model and a heuristic solution\r\nprocedure that combines column generation and the recently developed\r\nABC(ß) heuristic is proposed.", :title "A Column Generation Heuristic for Dynamic Capacitated Lot Sizing with Random Demand under a Fillrate Constraint", :keyword2 "uncertainty", :authors (4889), :session 115}, 540 {:keyword1 "System dynamics", :keyword3 "Strategic planning", :abstract "In recent years, business models are becoming increasingly more important for manu-factures in the capital goods industry. However, manufacturers of plants still hesitate to offer these customer-oriented solutions, due to existing uncertainties resulting from economic risks. The offering of business models requires a stronger integration of the supplier into the life cycle of a plant, leading to the consequence that manufacturers have to restructure their previous activities extensively. Certainly these business models do not only hold hazards, but unexplored potentials, too. If suppliers of capital goods offer these customer-oriented solutions, a higher utility for the customer arises and hence, a competitive advantage for the manufacturer. Due to these high chances and risks, decision models are required, which identify and assess the impacts resulting from the implementation of these business models. Aspects like time delay, due to the reorganisation of the service department or the set up of adequat human resources have to be considered, just as the transfer of market risks to the supplier. Therefore, the aim of this contribution is to develop a system dynamics model for the analysis of long-ranging consequences due to the implementation of business models and hence, to assess strategic decisions of enterprises. The practical usability of the tool will be pointed out by means of an industrial case study, describing the implementation of availability guarantees of a machine tool builder.", :title "Strategic Planning of Business Models in the Capital Goods Industry – A System Dynamics Approach", :keyword2 "Business models", :authors (17103), :session 169}, 544 {:keyword1 "Transportation", :keyword3 "Forecasting", :abstract "In this talk, we present a variant of the well-known Dynamic Vehicle Routing Problem (DVRP) inspired by a real-world application. In the considered DVRP variant, goods have to be delivered under high time pressure due to their high perishability. Particularly, customer requests arrive dynamically over time. They have to be fulfilled as quickly as possible after their arrival in favor of satisfying customers and to keep customers’ inconvenience low.\r\nIn order to reduce request delivery times and to increase quality of customer service, the arrival of future requests is anticipated. For this purpose, sophisticated methods for analyzing historical request data and generating request forecast information are integrated. The attained information is integrated directly into the tour plan execution process to guide vehicles into request-likely areas.\r\nRecent computational results obtained on designed as well as on real-world data are presented that show the efficiency of the developed methods.", :title "Real-time delivery of perishable goods using historical request data to increase service quality", :keyword2 "Dynamic Vehicle Routing", :authors (14856 14800 2189), :session 227}, 548 {:keyword1 "Approximation ", :keyword3 "GAP", :abstract "We consider the problem of assigning personalized advertisements (ads) to viewers in order to maximize revenue. \r\nEach viewer has a limited capacity and each ad has a given length and a revenue that is obtained if it is assigned to a given number, say R, of different viewers.  \r\nThis problem can be split into two decision problems: which ads to select and how to pack the selected ads for the viewers.\r\nBoth of these problems, which we refer to as the Ads Selecting and the Ads Packing problems, respectively, are NP-hard.\r\nIn this study we focus on the Ads Packing problem assuming a given subset of ads that can be packed.\r\nThis problem is a special case of the Generalized Assignment Problem (GAP) and the Generalized Multi Assignment Problem (GMAP), which has a fixed reward and length per ad, assignment restrictions and multi all-or-nothing assignment constraints.\r\nDespite the fact that GAP is well known and well studied, GMAP and the additional multi all-or-nothing assignment constraints have not been sufficiently investigated.\r\n\r\nIn this work we present two approximation algorithms for the Ads Packing problem.\r\nThe first is the Extra-Packing algorithm which is a (1,2)-approximation to the Ads Packing problem. \r\nThis approximation is interesting as reaching the same well known (1,2)-approximation of Shmoys and Tardos for GAP, while solving a generalization of GAP.\r\nThe second is the Deep-Search-Replacer algorithm, which is an (R+1)-approximation of the Ads Packing problem. \r\nThis approximation can also be considered a generalization of Shmoys and Tardos' 2-approximation for GAP.\r\nBoth approximation algorithms were obtained by rounding a relaxed solution to the mathematical programming formulation of the problem. ", :title "Approximation Algorithms for The Personalized Advertisements Packing Problem", :keyword2 "Algorithm", :authors (24048 24377 6813), :session 179}, 550 {:keyword1 "vehicle routing", :keyword3 "granular neighborhood", :abstract "The Vehicle Routing Problem (VRP) and its variants are among the most well studied combinatorial optimization problems and a multitude of metaheuristic solution methods have been proposed for this problem class in the last fifteen years. Granular tabu search, introduced by Toth and Vigo in 2003 for the classical VRP and the distance constrained VRP, is based on the use of drastically restricted neighborhoods, called granular neighborhoods. These neighborhoods involve only moves that are likely to belong to good feasible solutions. Due to the significantly reduced number of possible moves to evaluate, they obtained very good solutions in short computational time. Motivated by their results, we transfer the idea of granular neighborhoods to the VRP with Time Windows (VRPTW). By studying a series of optimal or near-optimal solutions to the classical Solomon VRPTW instances, we identify structural commonalities between these solutions. Thus, we create measures that indicate rough probabilities with which a certain edge is present in good VRPTW solutions. We use these measures to construct a sparse graph from the original problem. By operating on this sparse graph, solution methods should be able to obtain very fast solutions without strong negative influence on the solution quality. We perform numerical studies to investigate the impact of utilizing this sparse graph on the solution behavior of a VRPTW metaheuristic.", :title "Graph Sparsification for the Vehicle Routing Problem with Time Windows", :keyword2 "sparse graph", :authors (25563 19320 25028 26906 24902 19999), :session 196}, 552 {:keyword1 "online optimization", :keyword3 "", :abstract "We consider elevator control algorithms for destination call systems,\r\nwhere passengers specify the destination floor when calling an\r\nelevator. The task of a control is to schedule the elevators of a\r\ngroup such that small waiting and travel times for the passengers are\r\nobtained.\r\n\r\nIn earlier work we developed a heuristic and an exact reoptimization\r\nalgorithm for this problem. A reoptimization algorithm computes a new\r\nschedule for the elevator group each time a new passenger arrives.\r\nThe most demanding traffic situation is heavy up peak traffic. Up peak\r\nmeans the traffic flow is in an upward direction, with the majority of\r\npassengers entering the elevator at the main floor.\r\n\r\nIt turns out that optimizing only the waiting and travel times does not\r\nlead to a good performance under heavy up peak traffic. We therefore\r\npropose a number of extensions to our model and algorithms aimed to\r\nimprove the performance in this traffic situations.\r\n\r\nOne goal is to group passengers with the same target floor and to\r\nserve them by the same elevator, which reduce the time span between\r\ntow stops of an elevator at the main floor and hence improve the\r\nperformance of the elevator system. A good aggregation can be achieved\r\nby assigning a subset of floors to each elevator, which is called\r\nzoning.  This can be done statically, where each elevator serves a\r\nfixed set of floors, or dynamically where the set of floors served by\r\nan elevator may change over time. We consider model variants of both\r\ntypes.  We provide extensive simulation results comparing the\r\nperformance achieved with the presented extensions and find that one\r\nof them provides very good up peak performance under high intensity\r\ntraffic and good performance at lower traffic intensities.", :title "Improved destination call elevator control algorithms for Up-peak traffic", :keyword2 "destination hall call", :authors (26325 14736 14796), :session 212}, 554 {:keyword1 "Energy markets", :keyword3 "Value at Risk", :abstract "We look at the compatibility and interaction between the well established Value at risk (VaR) metric and a “coherent” risk measure Expected shortfall (ES). Although theoretically a superior risk measure ES is not accepted by the regulators for the purpose of calculating economic capital of an institutional investor. Furthermore, the concept of ES is lagging behind VaR when it comes to empirical research, model comparison and backtesting methodology. VaR and ES are connected in the sense that from the VaR surface we can easily calculate ES. We test a wide range of VaR and ES models at high confidence levels (95, 99, 99,5 and 99,9%) during the ongoing economic crisis which significantly contributed to the turmoil in the energy markets. The obtained results in VaR and ES estimation show consistency in that the best performing VaR models are almost identical to the best performing ES models. Our findings point to the conclusion that the strong points and weaknesses of every model remain with them and that is why knowledge obtained in developing VaR models should not be forsaken. Knowing both figures leads to better understanding of risks an institution is facing. As we show VaR estimation techniques can easily be adopted to serve a new coherent risk measure – ES.", :title "SIMILARITIES BETWEEN EXPECTED SHORTFALL AND VALUE AT RISK: APPLICATION TO ENERGY MARKETS", :keyword2 "Expected shortfall", :authors (26453 26488 16785), :session 163}, 556 {:keyword1 "combinatorial optimization", :keyword3 "", :abstract "The universal combinatorial optimization problem (Univ-COP) generalizes classical and new objective functions for combinatorial problems given by a ground set, a set of feasible solutions and costs assigned to the elements in this ground set. The corresponding universal objective function is of sum type and associates additional multiplicative weights with the ordered cost coefficients of a feasible solution such that sum, bottleneck or balanced objectives can, for instance, be modeled as special cases. The crucial assumption that all feasible solutions have\r\nthe same cardinality is, however, not satisfied for the shortest path problem with source s and sink t. To deal with paths of different length, we propose two alternative definitions for the univeral shortest path problem denoted Univ-SPP, one based on a sequence of cardinality contrained subproblems, the other using an auxiliary construction to establish uniform length for all paths from s to t. We show that the\r\nproblem is (strongly) NP-hard and give integer programming formulations for both definitions. On graphs with specific assumptions on edge costs and path lengths, Univ-SPP is solvable as classical sum shortest path problem. For appropriately chosen weights, we also consider special types of Univ-SPPs like (k+k')-max, (k,k')-balanced or (k,k')-trimmed-mean SPP which can be solved in polynomial time by a sequence of constrained path problems applying results on k-sum and k-max optimization.\r\n", :title "On Universal Shortest Paths", :keyword2 "shortest paths", :authors (26442 694), :session 217}, 558 {:keyword1 "project management", :keyword3 "vagueness", :abstract "In the scientific literature no comprehensive approach can be found for scheduling in project management that takes into account vagueness of non-stochastic origin, which means that no approach exists starting with modeling, proceeding with scheduling, and finishing with evaluating and interpreting the results taking into account in a systematic way the effects of vagueness of non-stochastic origin.  The aim of the PhD-thesis of the author, which is currently in progress, is to show that such a comprehensive approach is feasible, and more importantly, the usefulness of such an approach for handling real-life problems will be demonstrated by means of a realistic practical example. This paper presents the starting point, the goals, and the methods of this work. To a large extent the methods are based on Fuzzy Theory, whose main aim is to handle vagueness in a mathematically precise way.  ", :title "Vagueness-enabled Scheduling in Project Management based on Fuzzy-methods", :keyword2 "fuzzy", :authors (5454), :session 147}, 564 {:keyword1 "Maintenance Scheduling", :keyword3 "Binary Patterns", :abstract "In this paper we consider the problem of scheduling the maintenance of fleet of N different vehicles over a given period T. Each vehicle is assumed to have different time-dependant productivity, mean time to repair, and cost of repair with possible limitations on the maximum number of vehicles that can be repaired at a time period. The objective is to maximize the total productivity minus the cost of repairs. We propose an efficient dynamic programming (DP) approach to the solution of this problem. The constraints are translated into feasible binary assignment patterns. The dynamic programming considers each vehicle as a state which takes one of possible feasible patterns. The algorithm seeks to maximize the objective function subject to specific constrains on the sequence of the selected patterns. The DP was tested on various cases and compared with the exhaustive search solutions for small cases. For larger problems, an example is given and the DP solution is compared with the best of 50,000 randomly selected feasible assignments. The developed algorithm can also be applied to a factory of N production machines, power generators, car rental, or airplanes of an airline.", :title "Optimal Maintenance Scheduling for N-Vehicles with Time-Varying Reward Functions and Constrained Maintenance Decisions", :keyword2 "Constrained Dynamic Programming", :authors (26458 26461), :session 159}, 568 {:keyword1 "Network flow model", :keyword3 "Batch production", :abstract "In this paper, we consider an extended network flow model for dynamic routing in production, addressing the problem of calculating capacity requirements to support investment decisions. The focus of our concept is, in particular, batch production. This is motivated by the high complexity of allocating product quantities to alternative work cycle elements for economic planning due to shorter product life cycles, more product variants and smaller batch sizes. Thus, the necessity arises to develop a model for the evaluation of capacities, representing these dynamics. Markov models and discrete event simulation are suitable tools if information on probability distributions and production control is available, though this is not the case in general for future demand and production lines in an early planning stage. Further, the dynamic routing must be an essential feature of the model. Therefore, we suggest an extended network flow model to allocate product quantities for defined time intervals to work cycle elements on common, finite capacities. The model is designed with respect to the following objectives: First, transparency and generality are provided by a limited set of elements, represented by a transmission function, while a more advanced routing is modeled by an arbitrary combination of these elements. Second, referring to the dynamic aspect of the routing, the allocation of product quantities to work cycle elements is optimized to satisfy demand. Thus, the network is traversed and represented by a set of linear equations and constraints, while complexity is reduced. Subsequently, linear optimization is applied. Finally, the optimization follows defined priorities to utilize preferred work cycle elements, leading to a recursive linear optimization approach.", :title "An Extended Network Flow Model for Dynamic Routing in Batch Production", :keyword2 "Dynamic routing", :authors (26334), :session 213}, 580 {:keyword1 "Nonsmooth optimization", :keyword3 "Semi-infinite optimization", :abstract "In recent works of the authors [1,2] a nonsmooth Newton was developed in an abstract framework and applied to certain finite dimensional optimization problems with C^{1,1} data. The C^{1,1} structure stems from the presence of an optimal value function of a lower level problem in the objective or the constraints. Such problems arise, for example, in semi-infinite programs under a reduction approach without strict complementarity and in generalized Nash equilibrium models. \r\nUsing results from parametric optimization and variational analysis, we worked out [2] in detail the concrete Newton schemes for these applications and discussed wide numerical results for (generalized) semi-infinite problems. This Newton scheme requests the computation of stationary points of the lower level problem, which is problematic from a numerical point of view.\r\nIn this talk we discuss the influence of inexact stationary points on the feasibility and the convergence properties of the Newton scheme.\r\n\r\nReferences:\r\n[1] S. Buetikofer, Globalizing a nonsmooth Newton method via nonmonotone path search, Mathematical Methods of Operations Research 68 No. 2 (2008)\r\n[2] S. Buetikofer, D. Klatte, A nonsmooth Newton method with path search and its use in solving C^{1,1} programs and semi-infinite problems, SIOPT (2009), accepted\r\n\r\n", :title "Influence of inexact solutions in a lower level problem on the convergence behaviour of a nonsmooth Newton method", :keyword2 "Newton's method", :authors (21140 10871), :session 63}, 581 {:keyword1 "routing", :keyword3 "branch-and-bound", :abstract "In modern production facilities industrial robots play an important role.\r\nWhen two ore more of them are moving in the same area, care must be taken to avoid collisions between them.\r\nDue to expensive equipment costs our approach to handle this is very conservative: Each critical area is modeled as a shared resource where only one robot is allowed to use it at a time. We studied collision avoidance in the context of arc welding robots in car manufacture industry. Here another shared resource comes into place. When using laser welding technology every robot needs to be connected to a laser source supplying it with the necessary energy. Each laser source can be connected to up to six robots but serve only one at a time. An instance of the problem consists of a set of robots, a set of welding task, a number of laser sources, a distance table, collision information and a production cycle time. The goal is to design robot tours covering all task and schedule them resource conflict free such that the makespan does not exceed the cycle time.\r\nWe propose a general model for integrated routing and scheduling including collision avoidance as well as a branch-and-bound algorithm for it. Computational results on data generated with the robot simulation software KuKa Sim Pro are also provided showing that our algorithm outperforms standard mixed-integer models for our applications.", :title "How to avoid collisions in scheduling industrial robots? ", :keyword2 "scheduling", :authors (16717 16606), :session 217}, 584 {:keyword1 "asymptotic single risk factor model", :keyword3 "confidence interval", :abstract "The asymptotic single risk factor (ASRF) model forms the basis for the calculation of the regulatory capital requirements according to Basel II. Therefore, it has become a standard credit portfolio model in the banking industry. It is parameterized by default probabilities and correlation parameters. As most of the literature focuses on the point and interval estimation of default probabilities, the opposite approach is taken in this paper. In the context of the ASRF model, individual and simultaneous confidence intervals for asset, default and survival time correlations are developed based on time series of observed default rates. Since the length of these confidence intervals depends on the confidence level chosen, they can be used to define stress scenarios for the correlation parameters considered.", :title "Confidence Intervals for Correlations in the Asymptotic Single Risk Factor Model", :keyword2 "asset correlation", :authors (26467 26468), :session 96}, 585 {:keyword1 "disaster management", :keyword3 "integer programming", :abstract "Disasters include natural and man-made disasters, which are further categorized as sudden and slow-onset disasters. While earthquakes, hurricanes, flood and forest-fire are examples of sudden-onset natural disasters, famine, drought and poverty are slow-onset natural disasters. Disaster relief operations are defined as the transportation of first aid material, food, equipment, and rescue personnel from supply points to a large number of destination nodes geographically scattered over the disaster region and the evacuation and transfer of people affected by the disaster to the health care centers safely and very rapidly. Each governorships has the primary responsibility for the initiation, organization, coordination and implementation of humanitarian assistance, and taking effective measures to reduce disaster risk, including the protection of people on its territory and infrastructure from the impact of disasters. In this context, governorships are expected to have their own national emergency response plans to mitigate the effects of natural disasters. One of the important parts of the plan is to determine the locations of warehouses and to organize the transportation of relief items in these warehouses. While realizing this by employing a MIP model, the governorship has to consider how much damage a disaster may cause which is obviously uncertain. In our study, we try to model this uncertain situation by adding a probabilistic aspect in to MIP model. We use probability as a measure of risk that the governorship wants to take. With this model, a governor can determine parametric risk level before the plan is constructed.            ", :title "A PROBABILISTIC APPROACH FOR DETERMINING LOCATION OF WAREHOUSES AND TRANSPORTATION OF RELIEF ITEMS", :keyword2 "probablistic risks", :authors (26466 23205), :session 199}, 586 {:keyword1 "earnings accuracy", :keyword3 "profitability of recommendations", :abstract "We find that while analyst characteristics have economically small predictive power for the accuracy of earnings forecasts, they have economically significant predictive power for the profitability of stock recommendations. Analyst characteristics can be used to identify ex ante more profitable stock recommendations and therefore they are helpful for identifying profit opportunities. Taking an investor-oriented, calendar-time approach, we project the firm-specific earnings accuracy of analysts based on their individual characteristics. We show that analysts with higher projected earnings accuracy issue significantly more profitable recommendations than analysts with lower projected earnings accuracy. The long portfolio based on the recommendations of the analysts within the highest projected accuracy quintile earns excess returns of up to 7.53% per year (before transactions costs) in the 1994 to 2007 time period. Analysts with characteristics that are related to higher earnings accuracy also issue more profitable stock recommendations.", :title "Projected earnings accuracy and the profitability of stock recommendations", :keyword2 "analyst characteristics", :authors (26469), :session 228}, 588 {:keyword1 "robust risk management", :keyword3 "", :abstract "The hydro-electric pumped storage plant management can be formulated as a multi-stage stochastic optimization problem. Recent research has identified efficient policies that minimize the risk of the plant value in a finite horizon framework by aggregating the spot price information into epochs. The most widely accepted models describe the spot price as being affected by a number of factors, each one following a mean-reverting type stochastic process. Yet, the conditions that affect those factors are rather volatile, making the adoption of a single probability model dangerous. Indeed, historical data show that the estimation of the stochastic models parameters is heavily dependent on the set of samples used. To tackle this problem, we follow a robust risk management approach and propose a method to compute optimal dispatch policies that minimize the Robust CVaR of the final plant value. We compare the optimal-Robust CVaR to the optimal-CVaR policies in probability models constructed using spot price data from EPEX for the period between 2005 and 2010. The computational overhead of computing optimal-Robust CVaR policies is linear in the number of scenarios and the computational complexity can be adjusted to achieve the desired level of accuracy in planning.", :title "Robust Risk Management in Hydro-Electric Pumped Storage Plants", :keyword2 "hydro-electric pumped storage plant management", :authors (24762 26470), :session 77}, 594 {:keyword1 "Software for OR/MS Analysis", :keyword3 "", :abstract "From the beginning in the 1970 at the World Bank till today, GAMS, the General Algebraic Modeling System, has evolved continuously in response to user requirements, changes in computing environments and advances in the theory and practice of mathematical programing. We will outline several recent enhancements of GAMS supporting efficient and productive development of optimizationbased decision support applications.", :title "Recent enhancements in GAMS", :keyword2 "Modeling Systems and Languages", :authors (14898), :session 104}, 599 {:keyword1 "location", :keyword3 "communication", :abstract "Standard covering location problems consider that a customer or demand is covered” if it is within a threshold distance from at least one facility. When more than one facility is within the threshold distance, there is overlap between the coverage areas of two or more facilities. A customer located in such an overlap area is assumed to receive the service from exactly one of the facilities. There are cases in which multiple-facility coverage of a customer needs to be explicitly taken into account, because it either has synergic or destructive effects. Examples of destructive effects are found in broadcast networks using the Single Frequency Network concept (usual in digital TV transmissions), or in other telecommunications systems (5th generation mobile telephony). Coverage of customers by the service is required; however if a customer has more than one facility within threshold distance, the second and following facilities act as sources of interference. In this case, facilities should be located so as to avoid redundant or overlapping coverage. A community may need having such a facility within a reasonable distance, but locating more than one in the neighborhood is an excessive punishment for a particular community. \r\n\r\nWe propose several models that maximize coverage, or minimize the number of facilities needed to cover all customers, while minimizing redundant or overlapping coverage as a second objective. We discuss different formulations, including both standard covering functions and gradual covering functions; and we also locate variable coverage radius facilities and consider the case in which coverage and destructive effects have different radii. Finally, we analyze issues related to the customer facility assignment, and provide computational experience.\r\n", :title "Minimum Overlap Covering Models", :keyword2 "covering", :authors (12245 1646), :session 131}, 602 {:keyword1 "", :keyword3 "", :abstract "In this talk we present an example of a system that implements real-time optimization and is in daily use at a German company. As in many other applications of real-time optimization the majority of orders are known in advance. But also for these orders, a direct optimization is only possible for the subset of so-called ‘known-location’ orders.  The remaining orders can only be fulfilled if they have been confirmed by the customers. In order to support the scheduling of appointments the system generates so-called ‘planning suggestions’. These are sorted by cost and enriched with other information such as, e.g., the possible time window and presented to the dispatcher. During the appointment scheduling one of these suggestions is selected by the dispatcher and fixed. When new orders occur, a similar process takes place, based on the current plans of the evaluators. The complete workflow is supported by GPS tracking and real-time communication using standard mobile phone technology.", :title "Dispatching of Evaluators with TransIT – A Real-World Implementation of Dynamic Staff Routing", :keyword2 "", :authors (5885), :session 227}, 606 {:keyword1 "Timetabling", :keyword3 "Convex Optimization", :abstract "The train timetabling problem is to find conflict free time slots for\r\npredefined train routes in a given railway network. We model this\r\naperiodic problem in a classical way using a time-discretized network\r\nfor each train. The main difficulties in solving such problems arise\r\nfrom capacities on tracks and stations influenced by train dependent\r\nrunning and headway times. On large networks with general topology,\r\nrelaxed solutions tend to generated tightly packed schedules without\r\nbuffer-time. Such solutions are neither robust nor is it easy to\r\nidentify feasible integer solutions in the vicinity of the relaxation.\r\nIt is not advisable to mend this by enforcing a prefixed minimal\r\nbuffer space because the spare capacities on tracks in each\r\ntime-interval are unknown a priori. In order to improve load\r\ndistribution over the arcs we propose convex load balancing functions.\r\nThis model is solved by Lagrangian relaxation using a bundle-method\r\ncombined with dynamic graph generation and separation.\r\nRounding-heuristics are employed for finding integer solutions. Our\r\ncomputational results indicate that load-balancing helps the\r\nrounding-heuristics to create solutions closer to the relaxed\r\nsolution. In combination with a rolling-horizon approach this allows\r\nto generate acceptable solutions on a subnetwork consisting of roughly\r\n10% of the german railway network in reasonable time.\r\n", :title "Large-Scale Train Timetabling Problems with Load Balancing", :keyword2 "Optimization Modeling", :authors (16988 17006 19268), :session 207}, 608 {:keyword1 "layout planning", :keyword3 "", :abstract "One important task in factory planning is the placement of rectangular \r\nfacilities/machines of varying sizes and the simultaneous design of the\r\ntransportation path structure within a given bounded area. While these\r\npaths should be designed so that the weighted sum of transportation lengths\r\nbetween any two machines is small, practical realizability requires the \r\npath structure to be rather simple. Indeed, practical planning procedures \r\nemploy little more than shapes in the form of L, H or T. Therefore we \r\npropose an optimization model for the case where the path structure \r\nis restricted to a double-comb with teeth of variable lengths on both \r\nsides of the handle and present first computational experiments\r\nfor a real world application with this model. We will also investigate \r\nmathematical properties of and relaxation possibilities for planning \r\ninstances with a single path, i.e., a double row facility \r\nlayout problem.", :title "Positioning machines along double-comb path structures", :keyword2 "integer programming", :authors (26471 17006 26480), :session 160}, 610 {:keyword1 "Dynamic vehicle routing", :keyword3 "", :abstract "We address a Dynamic Multi-Period Routing Problem with on-line pickup requests served by a fleet of uncapacitated vehicles. Every pickup request is characterized by a deadline of a given number of days d<=2. A deadline d=1 forces the decision maker to schedule the request for service today while a deadline d=2 enables its postponement until tomorrow. The vehicles leave the depot in the morning and have to return by the end of the day. The requests which were postponed yesterday are known in the morning while others may arrive while the vehicles process their tours. Every request has to be satisfied. If a request cannot be inserted into the tours without violating the vehicles shifts it will be forwarded to a backup service at a high cost. The goal is to minimize the average operational cost. Therefore it is mandatory to serve as many requests as possible by our own fleet and keep the service plans flexible to be able to include new arriving requests. A heuristic algorithm is proposed to the problem and first results simulating different scenarios based on the solomon vrp instances are presented.", :title "Multi-Period fleet management with on-line pickup requests", :keyword2 "Multi period routing", :authors (17686 13264 12952), :session 50}, 611 {:keyword1 "", :keyword3 "", :abstract "A vehicle schedule determines the arrival times of vehicles at customer sites. After the schedule determination arrival times at pickup and/or delivery locations are announced to the corresponding customers, who coordinate their upstream and downstream activities with the announced arrival times. If a dispatcher accepts additional customer-specified requests after the initial determination of the schedule then the schedule must be updated accordingly. However, revisions of once announced arrival times annoy customers. Therefore, the dispatcher has to keep schedule modifications as rare as possible in order to prevent nervousness comprising all kinds of revisions of once made schedule-related decisions. We test in computational simulation experiments if the nervousness of a schedule can be reduced and evaluate the idea to make a schedule more resistant against arrival time modifications in an update situation. To do so, we insert time buffers at a vehicle route during the initial schedule generation (e.g. a vehicle waits a certain period after having completed an activity at a customer location). We compare the overall costs of these techniques with a simple myopic re-optimization approach that does not take care of later revisions of once made decisions but penalizes arrival time modifications.", :title "Preventing Arrival Time Shifts in Online Vehicle Routing", :keyword2 "", :authors (5931 15277), :session 50}, 612 {:keyword1 "", :keyword3 "", :abstract "In this contribution, we propose and evaluate a simulated annealing approach for solving a\r\nvehicle routing problem where pickup and delivery orders dynamically arrive during the\r\nplanning period but no information on future requests is available.\r\nIn order to meet the dynamic planning requirements, we use a rolling horizon framework, i.e.,\r\nthe dynamic problem is traced back to a series of static PDPTW’s. The latter are solved by\r\nmeans of the simulated annealing algorithm (SAA).\r\nThe SAA metaheuristic guides a destruction/reconstruction neighborhood search comprising\r\ndifferent deletion and insertion operators. The deletion operators differ in the way how they\r\nselect the requests to be deleted: with respect to similarity or cost criteria, or at random. For\r\nre-insertion, a myopic cost based strategy and a regret heuristic are used. In addition, the\r\napproach features an adaptive cost function which dynamically adjusts its parameters in the\r\ncourse of the search.\r\nDuring search, the operators are chosen adaptively, with reference to the current state of the\r\nsearch process. Alternatively, the operators can be statically preselected or picked randomly.\r\nThe parameters of the SAA are set according to well-proven recommendations from the\r\nliterature.\r\nThe proposed SAA-based approach is subjected to a comparative test including previous\r\napproaches from the literature. The results show that the developed SAA-based approach\r\nsignificantly outperforms the previous methods. Improvements over the competing methods\r\nincrease with the degree of dynamism.", :title "A Simulated Annealing Approach for Solving a Dynamic Vehicle Routing Problem", :keyword2 "", :authors (1109 5643), :session 50}, 613 {:keyword1 "", :keyword3 "", :abstract "The problem of transporting patients or elderly people has been widely studied in literature and is usually modeled as a dial-a-ride-problem (DARP). We analyze a corresponding problem arising in the daily operation of the Austrian Red Cross. The aim is to design vehicle routes to serve transportation requests using a fixed vehicle fleet. Each request requires transportation from a patient’s home location to a hospital (outbound request) or back home from the hospital (inbound request). Some of these requests are known in advance, others are dynamic in the sense that they appear during the day without any prior information. Additionally, travel times show stochastic deviations around time dependent average values. We propose four different modifications of metaheuristic solution approaches for the DDARPTD. In detail, we test dynamic versions of VNS and S-VNS as well as modified versions of MPA and MSA. Tests are performed using 32 sets of test instances based on a real road network. Various demand scenarios are generated based on available real data representing both static settings as well as settings with 30%, 50%, and 80% dynamic requests. Test instance sizes vary between approximately 100 and 800 requests for a 10 hour day. The averages of the time dependent travel times are known from available floating car data and we assume that the maximum amount of stochastic deviation from these averages (e.g., +/- 20%) is known as well. Results show, that stochastic approaches benefit from this stochastic information leading to significant improvements compared to myopic approaches using only the time dependent average values. For static instances, average solution quality can be improved by around 14.5%. For dynamic instances, even larger improvements can be observed.", :title "Solution methods for the dynamic Dial-a-Ride Problem with stochastic time dependent travel times", :keyword2 "", :authors (23282 2769), :session 227}, 614 {:keyword1 "", :keyword3 "", :abstract "Emergency service providers are supposed to locate ambulances such that in case of emergency patients can be reached in a timeefficient manner. Two fundamental decisions and choices need to be made real-time. First of all immediately after a request emerges an appropriate vehicle needs to be dispatched and send to the requests’ site. After having served a request the vehicle needs to be relocated to its next waiting location. We are going to propose a model and solve the underlying optimization problem using Approximate Dynamic Programming (ADP), an emerging and powerful tool for solving stochastic and dynamic problems typically arising in the field of operations research. Empirical tests based on real data from the city of Vienna indicate that by deviating from the classical dispatching rules the average response time can be can be decreased from 4.4 to 4.0 minutes,\r\nwhich corresponds to an improvement of 7%. Furthermore we are going to show that it is essential to consider time-dependent information such as travel times and changes with respect to the request volume explicitly. Ignoring the current time and its consequences thereafter during the stage of modeling and optimization leads to suboptimal decisions.\r\n", :title "Solving the Dynamic Ambulance Relocation and Dispatching Problem using Approximate Dynamic Programming", :keyword2 "", :authors (15802), :session 50}, 615 {:keyword1 "", :keyword3 "", :abstract "With all the uncertainty in data there is considerable demand for stochastic optimization in operational, tactical and strategical planning. Nevertheless, there exist a fairly small number of commercial applications building on stochastic optimization techniques. After a decade without much progress on the software side, modeling system providers have recently entered the second round of making it easier to go from a deterministic model to a stochastic version of such a model. We will review the different concepts emphasizing on recent enhancements in the GAMS system. ", :title "Stochastic optimization: recent enhancements in algebraic modeling systems", :keyword2 "", :authors (10542), :session 91}, 619 {:keyword1 "modeling", :keyword3 "GAMS", :abstract "Some years ago the classical interface between a modeling system and a MP solver consisted of passing on information about the constraint matrix as well as function and derivative evaluations for non-linear problems. With emerging new model types and advanced solver technology the need increased for exchanging more structural model information in the namespace of the original model. In this paper we will discuss a state of the art interface between GAMS and the solvers connected.", :title "Interactions between a Modeling System and Advanced Solvers", :keyword2 "solvers", :authors (14778), :session 104}, 627 {:keyword1 "queuing", :keyword3 "simulation", :abstract "Performance information of a complex service network system is essential for evaluating the required system behavior. It is also important both for new systems to be built and for operating systems to be developed. This paper presents the utilization of  the Queuing theory , Markov Chain, Decision tree and Simulation techniques to model and modify the nature of these systems. A model can be developed to suit the validity of the real system layout configuration. It can be used to estimate and offer all the required information to Measure current (or predict future) dependability, estimate the system performance parameters, test the system or the critical units efficiency, vulnerability, Availability, quality and reliability. These quantitative analysis helps managers and  designing engineers in their economic and technical decisions in each level of the developing or creating stages. ", :title "DEVELOPING  QUANTITATIVE TECHNIQUES TO EVALUATE THE COMPLEX SERVICE NETWORK SYSTEMS QUALITY AND PERFORMANCE", :keyword2 "markov chains", :authors (15205), :session 130}, 628 {:keyword1 "Routing in Optical Networks", :keyword3 "Translation to SAT", :abstract "We propose a novel representation of routing instances in optical networks as equivalent Pseudo-Boolean Satisfiability (PB-SAT) problems. The contributions of this paper are: \r\n\r\n1)\ta novel representation of routing instances in optical networks as equivalent PB-SAT problems by introducing edge observability variables to indicate whether an edge is on the optimal route, combined with either a simple [2] or a hierarchical SAT encoding [3] to select a wavelength for that edge; in a hierarchical encoding, several levels of simple encodings are used to recursively subdivide the domain of values into smaller subdomains;\r\n\r\n2)\ta tool that implements the new approach with two simple encodings and 6 types of parameterizable hierarchical encodings that can be instantiated into many specific hierarchical encodings based on the parameter values used; \r\n\r\n3)\texperimental results for routing instances with up to 3,000 nodes, 15,000 edges, and 2,048 wavelengths per edge, indicating at least 8 orders of magnitude speedup relative to a previous approach by Aloul et al [1], such that the speedup is increasing with the number of nodes and edges, and the number of wavelengths per edge; and \r\n\r\n4)\texperimental results with a portfolio of 4 parallel strategies, each based on the new approach and a different hierarchical encoding, resulted in additional speedup of up to 6 times, and reduced the variability of the run times for large networks.\r\n\r\nReferences:\r\n[1] Aloul et al., “Routing in Optical and Non-Optical Networks using Boolean Satisfiability,” Journal of Communications, Vol. 2, No. 4, June 2007.\r\n[2] de Kleer, “A Comparison of ATMS and CSP Techniques,” IJCAI’89.\r\n[3] Velev, “Exploiting Hierarchy and Structure to Efficiently Solve Graph Coloring as SAT,” ICCAD ’07.\r\n", :title "Efficient Pseudo-Boolean Satisfiability Encodings for Routing in Optical Networks", :keyword2 "Boolean Satisfiability (SAT)", :authors (26483 26487), :session 216}, 629 {:keyword1 "Relocation", :keyword3 "A Micro-Simulation Model", :abstract "This paper presents an overview of a relocation choice model for logistic firms; the presented conceptual model distinguishes a separate relocation decision and a conditional decision for an alternative new location. This means that the joint decision of firm i to move and to relocate to location j is the product of the probability firm i will move and the conditional probability that firm i chooses location j from a subset of alternatives. This model takes into account spatial effects in the conditional decision for an alternative new location. A modeling framework is developed to analyze decisions regarding relocation choice for logistic firms based on mixed logit models. In this framework, spatial effects such as the correlation among firms in deterministic terms and the spatial correlation among zones in the error term are captured by mixed logit models.  \r\n\r\nIn a case study, the developed framework is applied to the Tokyo metropolitan area. The data set used in this case study was compiled from numerous sources such as the Establishment and Enterprise Census 2004, the Road Traffic Census 2004 survey, and the Tokyo Metropolitan Goods Movement Survey 2004. \r\n\r\nAll estimations in this research were implemented using the GAUSS programming language. The results of the study indicate that for relocation decision, the number of employees and the distance to IC highway are more important determinant for manufacturers than that for retailers and product wholesalers. Additionally, the results indicate that the spatial parameters are statistically significant in terms of the t-statistics with reasonable signs for all type of firm. Furthermore, the land prices in a given zone strongly affect the decision-making process of all the firms in the metropolitan area.\r\n", :title "A Micro-Simulation Model of Logistic Firm Relocations: Applications of Concepts of the Spatial Effects", :keyword2 "Logistic Firm", :authors (23479), :session 197}, 632 {:keyword1 "Stochastic programming", :keyword3 "Large scale optimization", :abstract "Medium-term generation planning is an essential tool for Generation Companies (GenCos) that participate in liberalized electricity markets as it permits to predict revenues and to plan fuel procurements for the next year, while managing limited renewable resources, as hydro, and emission limit compliance.\r\n\r\nSeveral features of medium-term electricity generation planning and some characteristics of liberalized markets lead to large continuous nonconvex optimization problems where the variables are the expected energy productions over the successive subperiods of a yearly horizon.\r\n\r\nThe model must take into account the matching of the load-duration curve (LDC) of each subperiod by units having a predictable outage probability, the uncertainty of some parameters, as the natural water inflows in reservoirs, the wind-power generation, or the price of fuels, the endogenous market-price model, the equilibrium behaviour of the market participants, and the mixed-market system of pool auction and bilateral contracts.\r\n\r\nIn the model implemented the matching of the load duration curve of each subperiod is represented by the Bloom and Gallant load-matching linear inequality constraints. An endogenous market price function with respect to load duration is employed to calculate the expected revenue from participating in the market of the optimized expected generated energies of GenCos' units. The market price function is endogenous with respect to hydro generation, and the Nikaido-Isoda relaxation procedure of successive optimizations is employed to reach the equilibrium solution.\r\n\r\nFor systems with pool auction and bilateral contracts a time-sharing hypothesis is adopted. The expected generation of each unit has then two parts: that that matches the market LDC, and that that matches the bilateral contract LDC, and the revenue to be optimized depends only on the part of the energies that matches the market LDC, which causes the objective function to be nonconvex.\r\n\r\nThe stochasticity of some parameters, such as the wind-power generation, requires a special formulation. \r\n", :title "Medium-term generation planning in liberalized mixed electricity markets", :keyword2 "Power Planning", :authors (24314 24311), :session 162}, 635 {:keyword1 "scheduling", :keyword3 "rehab hospitals", :abstract "Physicians in rehab hospitals decide on the kind and the number of therapeutic activities for any patient. Based on this decision, clerks typically create an appointment schedule in a patient-by-patient manner. This schedule determines the time and the location of therapeutic and other activities for the patients. Scheduling the activities for the patients therefore also determines the use of the necessary resources (such as therapists, rooms, medical devices) and also the resulting cost and revenues of the hospital.\r\nWe present an algebraic decision model to support this scheduling task. This model explicitly considers many different requirements from both the hospital and the patients perspective. We comment on the numerical solution of the model and on preconditions and likely consequences of the use of such a decision support system.\r\n", :title "Model-based planning of processes in rehab hospitals", :keyword2 "algebraic decision model", :authors (16870 17428), :session 37}, 637 {:keyword1 "Scheduling problems", :keyword3 "mixed integer linear programs", :abstract "The steel industry has experienced dramatic changes during the last years. To maximize the profit, it must be ensured that the operational costs are kept as low as possible and the production can flexibly adapt to rapidly changing conditions. \r\n\r\nThis raises the challenge for industrial solutions on plant-wide scheduling problems. Subsystems of plants are often optimized locally without an overall coordination on plant level. We present a new optimization method that utilizes local scheduling algorithms and optimizes the overall schedule by coordinating coupling parameters. \r\n\r\nThe production constraints in the melt shop mainly result from metallurgical rules, whereas in the hot rolling mill the production constraints mainly arise from physical restrictions and the quest for small changes in product changeovers. Because of the complex and different production constraints in these two processes, we have developed scheduling algorithms separately for both plants with different optimization objectives for each of them. Both scheduling problems are large, complex and highly constrained. Therefore, we decompose the problems into smaller optimization problems, which are solved by formulating them as mixed integer linear programs (MILP) and putting them together again using integer programming. \r\nThe coordination method is based on the idea to take up the local solutions and automatically tune the parameters of the distributed schedulers, such that they are coordinated iteratively. \r\n\r\nThe performance is evaluated on a real steel plant coupling melt shops and hot rolling mills This industrial-size example illustrates the potential benefits and solution time. Potential benefits do not only comprise lower production costs but also reduced energy demand and lower emissions. \r\n", :title "A Coordinated Steel Plant Scheduling Solution", :keyword2 "Plant wide optimization", :authors (19462 26682 8732 19030 26683), :session 213}, 639 {:keyword1 "column generation", :keyword3 "aircraft scheduling", :abstract "This talk reviews possibilities for problem decomposition and concurrent solving from a modelling point of view.\r\nWe discuss different approaches and hint at their implementation with Xpress-Mosel, using Mosel's capacity of handling multiple models, multiple problems within a model, and as a new feature, distributed computation using multiple processors.\r\nAs an application of these techniques we present a decomposition approach for the problem of routing aircraft subject to maintenance constraints.", :title "Modelling techniques for large scale optimization problems with application to aircraft routing", :keyword2 "parallelism", :authors (21574), :session 206}, 640 {:keyword1 "Capacity Modeling", :keyword3 "Practical Implementation", :abstract "The purpose of supply chain planning is to fulfill customer demands through efficient utilization of the resources of the company and of its subcontractors. The capacity modeling is a crucial point for the long-term resource planning and the demand-supply match as it states the main quantitative restriction of the resource optimization problem. So far Infineon has been using a capacity modeling approach based on aggregated capacity groups (ACG). An ACG encompasses products that are interchangeable in production resources as they use similar equipment with identical capacity consumption. Hence using ACGs provides flexibility as demands for these products can be switched within the group without altering the supply plan. However this capacity model has quite some loopholes, e.g. lacking transparency. In this paper we introduce a different capacity modeling concept and we assess its performance. The new approach improves demand-supply match results by means of appropriate capacity constraints and suitable consumption factors. By this all critical resources can be made visible. It also enables the first step toward a better product prioritization. This capacity model has been successfully implemented in Infineon’s planning landscape during a pilot project. For this we took advantage of the moving bottleneck functionality in existing demand-supply match tool. This concept has been tested with real-world figures for semiconductor backend resources. Results show that the new approach achieves 7% more production requests. And with 14% less capacity a 6% higher loading level is reached. Knowing the level of investments for building and maintaining production capacities in semiconductor industry, this improvement has a significant financial impact for the company.", :title "Achieving a Better Utilization of Semiconductor Supply Chain Resources by Using an Appropriate Capacity Modeling Approach on the Example of Infineon Technologies AG", :keyword2 "Semiconductor Supply Chains", :authors (26495 26491 26550), :session 120}, 641 {:keyword1 "supply chain management", :keyword3 "interdependent uncertainties", :abstract "In high-technology manufacturing, the continuity of product delivery process can be disrupted by procurement problems. These problems are largely caused by uncertainties in i) end product demand, ii) availability of components due to limited supplier capacity and iii) component prices. The resulting risks are often addressed by building product families that use common components; yet this approach can aggregate worst-case risks. For example, if all products contain the same component, disrupted access to this component can paralyze production if there are no substitute suppliers or SPOT-markets. Also, ordering different kinds of components from a single capacity constrained supplier can cause supply problems, if the high output of one component causes shortfalls of other components. \r\n\r\nIn this paper, we develop a stylized structural model for evaluating different procurement strategies which consist of 1) fixed quantity contracts for cost minimization and 2) flexible quantity contracts for risk management. In the model, demand and supply are stochastic and possibly correlated. It is assumed that there is no SPOT-market and hence supply capacity is limited and component price is deterministic. The model is optimized to determine the cost-minimizing portfolio strategy that satisfies downside risk constraints. \r\n\r\nUsing the model, the manufacturer can determine the optimal contract portfolio and hedge downside risks. The results indicate which contracts outperform others and how causal dependencies and correlated risks affect the optimal contract portfolio and the level of overall procurement risk. The relevance of the model is illustrated in a case study at a consumer electronics manufacturer.", :title "Evaluating procurement strategies under interdependent product demand and supply of components", :keyword2 "procurement risks", :authors (26336 2268), :session 109}, 642 {:keyword1 "flow shop scheduling", :keyword3 "", :abstract "We propose a new approach for the sequencing of slabs at the continuous caster, one central process in integrated steel mills. The typical characteristics of slab sequencing are taken into account. They can be categorized in four categories as follows: First, orders, in terms of jobs to be scheduled, are specified by a specific steel grade, a casting weight and a continuous range of casting widths. Second, material to be cast is supplied in charges of a specific grade with a weight that by far exceeds a single orders weight. Due to process restrictions, the casting of a charge may not be interrupted. Third, the casting width can be changed continuously during casting process. Thus, the casting width at the beginning of an order can be different to the casting width at the end of the same order. Nevertheless, due to the technological process, casting width at the end of an order has to be equal to the one at the beginning of the subsequent order. Fourth, setup times have to be taken into account based on several rules such as accumulated casting lengths, steel grade sequences or stepwise width changes. The most special feature of the approach is that we integrate the dynamically changing parameter “casting width” as decision variable into a combined lot sizing and scheduling model with flexible job specifications. In our contribution we present an extended MIP modeling approach for the introduced decision situation based on a standard scheduling problem formulation.", :title "Flow shop scheduling at continuous casters with flexible job specifications", :keyword2 "flexible job specifications", :authors (17130 13503 2651), :session 160}, 643 {:keyword1 "complexity of agorithms", :keyword3 "spanning tree", :abstract "This work is concerned with the minimum routing cost spanning tree (MRCST) problem, which is to find a spanning subtree of a given graph that minimizes the sum of shortest paths between all vertex pairs. MRCSTs find application in various research areas such as network design and computational biology. Tree structures are of special importance because they constitute the connected subgraph with minimum number of edges and routing in trees is simple due to the uniqueness of paths. Finding a MRCST was shown to be NP-hard, even in unweighted graphs. Good approximation algorithms are particularly hard to construct, because both, the topology of the resulting tree and the edge weights have influence on the routing cost. This work proposes a simple approximation algorithm for the MRCST problem that can be implemented to run in linear time.", :title "A Linear Time Approximation Algorithm for the Minimum Routing Cost Spanning Tree Problem", :keyword2 "routing", :authors (26431), :session 218}, 647 {:keyword1 "Airline Crew Scheduling", :keyword3 "Standby Planning", :abstract "Airline crew schedules are often subject to disruptions caused by illness, flight delays or other reasons. In order to cope with such disruptions, some crew members (temporarily) act as reserves and are assigned standby duties which allows the airline to call them to a flight duty within a short time before departure. The scheduling of standby duties depends on the estimated disruptions, the availability of crews and the standby policy of the airline. As the availability of crew members and the needed standbys depend on the planned crew pairings, airlines often use a sequential planning process in which crew pairings are optimized before the standby duties are generated and assigned. Especially in airlines with multiple crew domiciles, this can lead to problems if the remaining capacities are not allocated in a way that allows to schedule standby duties to meet the desired standby policy. To achieve the respective standby coverage levels, local adjustments to the pairings have to be performed which can lead to additional costs. \r\n\r\nIn this talk, we propose a MIP model which integrates the planning of standby duties into the optimization of crew pairings. The integrated model is based on the state-expanded time space network model for the crew pairing chain problem proposed by Mellouli. It can be used to implement different standby policies, including cases when multi-day pairings need to be covered by fitting multi-day standby duties. Additionally, the model captures the fact that standby crews can be transferred from their domicile to another airport to take over a disrupted flight duty which is a typical situation arising in airlines with multiple domiciles. Computational results from experiments with real world data from a medium-sized German airline are presented.", :title "Integrating Standby Planning into Airline Crew Pairing Optimization", :keyword2 "Crew Pairing Chain Problem", :authors (17038), :session 206}, 649 {:keyword1 "heuristics", :keyword3 "lock scheduling", :abstract "The lock scheduling problem is a combinatorial optimization problem that involves two objectives. During a given time period, both the water usage of a lock and the waiting time of all ships passing through the lock should be minimized.\r\nIn order to pass through a lock, a ship must be placed in one of the chambers of the lock, and the  chamber needs to be scheduled for lockage.\r\nThe lock scheduling problem shows characteristics of scheduling and packing problems. Therefore we call it a structured combinatorial optimization problem.\r\nWe identify the ship placement problem as a sub problem of the lock scheduling problem. The ship placement problem only deals with packing ships into chambers, subject to a set of constraints. It is a variant of the 2D bin packing problem with additional constraints. The goal of  this sub problem is to place the ships into as few chambers as possible, using a first-come-first-served policy towards the arrival time of the ships.\r\nWe present several heuristics that can be used to solve this packing problem. We compare the performance of a problem specific heuristic to that of an integer programming approach and an an adaptation of the currently best performing heuristic for the orthogonal stock-cutting problem. We improve the performance of the last heuristic on our problem by introducing an additional preprocessing step. The comparison between the solution methods is based on a large set of test instances, both randomly generated and real life data.", :title "A best fit heuristic for the lock scheduling problem", :keyword2 "bin packing", :authors (23886 23268 7432), :session 179}, 650 {:keyword1 "intrusions Detection", :keyword3 "agent system", :abstract "A data mining techniques that incorporates the mobile agent system based Intrusion Detection System (IDS) has been defined to guaranty an efficient computer network security architecture.\r\n We provide an overview on data mining algorithms that we have implemented: association rules algorithm. Whose is used to compute the intra- and inter- audit record patterns, which are essential in describing program or user behavior. We propose an agent-based architecture for intrusion detection systems where the learning agents continuously compute and provide the updated (detection) models to the detection agents.\r\n", :title "A Software Implementation of a Data mining approach for network intrusion detection ", :keyword2 "Data mining", :authors (22533 22515 9736 22534), :session 229}, 651 {:keyword1 "revenue management", :keyword3 "slot allocation", :abstract "The main characteristics for the successful use of revenue management – e.g. limited and perishable capacities and advance booking – are present in the liner shipping industry. Hence, revenue management methods can be applied to obtain the best container acceptance strategy. In the literature, slot allocation models are developed to create booking limits for the different segments in the liner network. The segmentation which is normally used in these models is based on the structure of the liner shipping market and divides it by the different container types, routes and/or customers.\r\nStudies and expert interviews show that reliability and delivery speed are important factors for customers in the liner shipping industry, and that containers with different commodities often have different priority. Therefore, the model which is developed here creates booking limits for standard segmentations and incorporates an additional segmentation approach similar to the air cargo industry. The new segments are “Express Container” (EC) and “Standard Container” (SC). The EC segment is intended for urgent cargo and gets priority on the next ship. A container in the SC segment only needs to be transported until a fixed delivery date and can be postponed as long as the delivery date is not violated. In the EC segment, the customer has the benefit of a prioritization of the container, and the carrier can charge a higher freight rate. The benefits of the SC segment are a lower freight rate for the customer and more flexibility in container slot allocation for the carrier. Hence, the segmentation approach which is proposed generates new advantages for both parties involved.", :title "A revenue management slot allocation model with prioritization for the liner shipping industry ", :keyword2 "liner shipping", :authors (26490 20937), :session 93}, 655 {:keyword1 "Neural Networks", :keyword3 "Dynamical Systems", :abstract "The recent developments leading to the financial crisis and the assessments to quantify its impact on industry at large, on economics and on companies and even states show that there is a dramatic need to use other ways and methods in forecasting. One major request is to move away from mostly linear relationships in the models to non-linear dependencies. Moreover, the concept of “risk” may be considered from a different perspective.\r\n\r\nWe present a new model class called Large Recurrent Neural Networks (LRNN). LRNN represent dynamic systems in the form of high-dimensional and non-linear state models. Market dynamics can be forecasted without the need to assume constant environment conditions. Risk is seen not as volatility of markets but rather as the level of uncertainty involved in forecasting.\r\n\r\nWe have applied LRNN to forecast the development of 12 currencies for the next 10 trading days. The results indicate that LRNN are superior to standard methods of time series forecasting and risk analysis.\r\n", :title "Forecasting FX-Rates with Large Recurrent Neural Networks", :keyword2 "Forecasting", :authors (14946 14817 14818), :session 95}, 657 {:keyword1 "Humanitarian Logistics", :keyword3 "Post-disaster", :abstract "The number of world-wide emergencies and disasters which trigger humanitarian operations is ever-expanding. Meanwhile, supply chain management in the context of humanitarian operations is becoming an increasingly popular field in science and practice. Although the number of research contributions has risen significantly over the past years, methods of operations research have not yet comprehensively been applied in this field.\r\n\r\nIn this work, the question how to react to sudden demand peaks, for example because of a pandemic, or to sudden supply lacks due to a fire in a warehouse or other disruptions, is considered. These situations require quick delivery of relief goods to the affected region. The most obvious solution would be to deliver those goods from warehouses in neighbouring regions, but this might lead to shortages in those regions as well.\r\n\r\nConcerning these circumstances, a model for stock relocation under uncertainty in post-disaster scenarios is formulated. The model is based on a transshipment network and solved with different approaches. Costs which are taken into account are transport, replenishment, inventory holding costs and penalty costs for unsatisfied demand. A special focus of the study is on the evaluation of progressively increasing penalty costs for unsatisfied demand, which did occur in a previous period. This represents the fact that the disaster affected community might be able to cope without a certain item such as blankets or chlorine tablets for some time. However, if these items are not delivered within a certain timeframe, this will not be possible any longer. It is found that shortages can be significantly reduced compared to a deterministic reference model when uncertainty of demand in post-disaster scenarios is taken into account.", :title "A Transshipment Model for Inventory Allocation under Uncertainty in Humanitarian Operations", :keyword2 "Stock Allocation", :authors (26489 20937 26607 26530), :session 198}, 659 {:keyword1 "Neural Networks", :keyword3 "Risk Management", :abstract "Large recurrent neural networks (LRNN) are a new approach to explaining markets and market trends. LRNN represent dynamic systems in the form of high-dimensional and non-linear state models. One of their key characteristics is the fact that they allow market dynamics to be forecast without the need to assume constant environment conditions. The environment and its future developments can be included in the forecasting system. \r\n\r\nLRNN also allow us to formulate a new concept of risk. Central to this concept is the interaction between observable and hidden variables. Given a finite number of observations, there are always many ways to reconstruct these hidden variables. Consequently, while many forecasting models can describe a historical trend perfectly, they may differ in the description of future trends, resulting in different scenarios. The range of fluctuation between the individual scenarios can be viewed as the risk, and a scenario based on the mean values from the different scenarios can be assumed to be the most probable future trend. The market risk is characterized by the variation between the scenarios.\r\n\r\nWe have applied large neural networks to forecast the development of the Dow Jones Industrial Average stock index. Here we also use the ensemble distribution for the valuation of corresponding options and derive appropriate trading strategies.  \r\n", :title "Option Valuation with Neural Networks: A New View on Market Risks ", :keyword2 "Forecasting", :authors (14818 14817 14946), :session 95}, 661 {:keyword1 "Neural Networks", :keyword3 "Market Modelling", :abstract "The liberalization of the German energy market in 2002 along with the deregulation of neighbouring European energy markets in recent years has created several needs for energy companies, public services, energy brokers and large scale energy consumers. Innovative procurement concepts must be developed in order to make use of market chances, to minimize risks or to leverage energy resources efficiently.\r\n\r\nIn this context, energy price forecasting is probably one of the most demanding tasks for market oriented energy procurement. Since the primary energy markets are highly interrelated, an isolated analysis of a single domestic energy market is questionable. What is required is a joint modelling of all interrelated energy and commodity markets. \r\n\r\nWe present an approach of coherent market modeling to forecast energy prices, which is based on large time-delay recurrent neural networks (LRNN). These nonlinear state space models combine different operations of small neural networks into only one shared state transition matrix. We use unfolding in time to transfer the network equations into a spatial architecture. The training is done with error backpropagation through time. Unlikely to small networks and standard econometric techniques, overfitting and the associated loss of generalization abilities is not a major problem in large networks due to the self-created eigen-noise of the systems.\r\nWe exemplify our approach of market modeling by forecasting the long- and short-term development EEX base future prices. \r\n", :title "Energy Price Forecasting with Neural Networks", :keyword2 "Forecasting", :authors (14818 14946 14817), :session 85}, 662 {:keyword1 "Neural Networks", :keyword3 "", :abstract "Electricity and Gas Load forecasts are a corner stone of a holistic energy management concept. \r\nTypically a load dynamics is partially driven by an autonomous development (e.g. load characteristics of different day types, holidays and special calendar events) and a variety of external influences (e.g. customer specific inputs or weather conditions).\r\n\r\nFor the modeling of such open dynamical systems we have developed a special class of time-delay recurrent neural networks which do not only incorporate the mentioned external influences but also the measured forecast errors. These models are called error correction neural networks (ECNN). An ECNN considers the sequence of the observed forecast errors as reactions of the load dynamics to unknown external information or system shocks.\r\n\r\nThe prediction of a load curve can be simplified, if it is possible to separate the load dynamics into time variant and invariant structures. Clearly, only the variants of the load dynamics have to be forecasted, while the time invariant structures remain constant over time. We use a suitable coordinate transformation in form of so-called bottleneck neural network for the separation of time variant and invariant structures. The bottleneck is embedded into the ECNN.\r\n\r\nWe successfully applied the ECNN models to forecast the day-ahead development of electricity and gas load curves. \r\n", :title "Short-Term Load Forecasting with Error Correction Neural Networks ", :keyword2 "Forecasting", :authors (14818 14817 14946), :session 85}, 663 {:keyword1 "Forecasting", :keyword3 "Dynamical Systems", :abstract "In the age of globalization, extensive deregulations and considerable developments in information technology, financial markets are highly interrelated. Segregated market analyses which are often performed in econometrics or in technical studies of market actions are therefore questionable. What is required is a joint modeling of all interrelated markets. We have developed large time-delay recurrent neural networks that model coherent markets as interacting dynamical systems.\r\n\r\nLarge recurrent neural networks are formulated as nonlinear state space models. These models combine different operations of small neural networks (e.g. processing of input information) into only one shared state transition matrix. We use unfolding in time to transfer the network equations into a spatial architecture. The training is done with error backpropagation through time. Unlikely to small networks and standard econometric techniques, overfitting and the associated loss of generalization abilities is not a major problem for large networks due to their self-created eigen-noise. \r\n\r\nWe have successfully applied large neural networks to forecast the development of commodity markets (namely the LME copper market and the EEX energy market). Our integrated market model not only takes into account the target commodity markets, but also major international stock, bond and foreign exchange markets as well as major primary energy markets.\r\n", :title "Forecasting Commodity Prices with Large Recurrent Neural Networks", :keyword2 "Market Modeling", :authors (14817 14946 14818), :session 228}, 665 {:keyword1 "GAMS", :keyword3 "stochastic programming", :abstract "The main focus in stochastic programming (SP) has been on developing new algorithms for narrow problem classes for the last years. In order to broaden the audience for SP, first steps in providing support for SP models have been taken by all major algebraic modeling languages. Our investigation shows that some of the SP tools do not scale, others are cumbersome to use, and good examples are extremely scarce. We will also look accurately into the details of implementing a multistage recourse model motivated by some production planning problem of chemicals. The deterministic equivalent of this problem is too big to provide a solution alternative for this SP. We will look into some alternative algorithms and their implementation in GAMS using some advanced features for rapid algorithm development.", :title "Stochastic programming using algebraic modeling languages", :keyword2 "multistage recourse modeling", :authors (26501), :session 91}, 670 {:keyword1 "Index Tracking", :keyword3 "Support Vector Regression", :abstract "Today, in many portfolio strategies indices are used as portfolio components. Because an index cannot be purchased directly, it has to be rebuilt. This is called Index Tracking. One widely used method of Index Tracking is Sampling, where the performance of an index is reproduced by purchasing a smaller selection of its components. For this, a tracking portfolio is calculated using an optimization algorithm based on the given data of an estimation period. The assumption is that an optimal portfolio in the estimation period also has a high tracking quality in the investment period.\r\nIn literature many approaches for optimizing a tracking portfolio are published. The majority creates portfolios with constant weights. Empirical studies show, that applied to real indices these approaches are able to produce excellent results for the estimation periods but in the crucial investment period the results are barely better than those of simple heuristics using the market capitalization.\r\nThe subject of our work was to develop a method with the focus on the generalization and thus to produce robust tracking portfolios even in the investment period. The method is based on the technique of support vector machines. One special advantage of this technique is the possibility to control the quality of fitting in the estimation period to reduce the overfitting effect. This can be done via an appropriate parameterization. To identify the parameters, we examined different techniques, like cross validation or effective VC dimension. Using these findings, we developed a method to construct robust tracking portfolios. Empirical results based on the DAX100 and S&P500 demonstrate the quality of our approach.", :title "A Method for Robust Index Tracking", :keyword2 "Passive fund management", :authors (19559 19565), :session 228}, 672 {:keyword1 "Real-Time Scheduling", :keyword3 "Optimization", :abstract "We address the field of internal logistics embodied in automated Material Handling Systems (MHS), which are complex installations employed in sectors such as Baggage Handling, Physical Distribution, and Parcel & Postal. We work on designing an integral planning and real-time control architecture, and a set of generic algorithms for MHSs. Planning and control of these systems need to be robust, and to yield close-to-optimal system performance. Currently, planning and control of automated MHS is highly customized and project specific. This has important drawbacks for at least two reasons. From a customer point of view, the environment and user requirements of systems may vary over time, yielding the need for adaptation of the planning and control procedures. From a systems’ deliverer point of view, an overall planning and control architecture that optimally exploits synergies between the different market sectors, and at the same time is flexible with respect to changing business parameters and objectives is highly valuable. An integral planning and control architecture should clearly describe the hierarchical framework of decisions to be taken at various levels, as well as the required information for decisions at each level, e.g., from overall workload planning to local traffic control. In this research, we identify synergies among the different sectors, and exploit these synergies to decompose MHSs into functional modules that represent generic building blocks. Thereafter, we develop generic algorithms that achieve (near) optimal performance of the modules. As an example, we present a functional module from the Parcel & Postal sector. In this module, we study merge configurations of conveyor systems, and develop a generic priority-based real-time scheduling algorithm.", :title "Integral Planning and Real-Time Scheduling of Automated Material Handling Systems", :keyword2 "Material Handling Systems", :authors (26507 16852 8513 3029 2336), :session 205}, 673 {:keyword1 "efficiency", :keyword3 "mutual funds", :abstract "Over the last few years the literature evaluating the performance of mutual funds using techniques for measuring economic efficiency has evolved rapidly. The instruments applied (mostly DEA and FDH) have the ability of encompassing several dimensions of performance, but they have also some drawbacks that may have prevented a wider acceptance. The recently developed order-m and order-alpha partial frontiers overcome most of the disadvantages while keeping the main virtues. In this article we apply not only the nonconvex counterpart of DEA, namely, FDH but also order-m and order-alpha partial frontiers to a sample of Spanish mutual funds. The results obtained for both order-m and order-alpha are quite useful, since a full ranking of performance is obtained. Although results hinge on the specified m and alpha parameter, this in fact can guide the selection of a picking rule.", :title "EVALUATING MUTUAL FUNDS USING ROBUST NONPARAMETRIC TECHNIQUES", :keyword2 "performance", :authors (26496 2505 25958), :session 142}, 674 {:keyword1 "Transportation and Logistics", :keyword3 "Scheduling", :abstract "In modern rail-rail transshipment yards huge gantry cranes transship containers between different freight trains, so that hub-and-spoke railway systems are enabled. In this context, we consider the transshipment yard scheduling problem (TYSP) in which trains have to be assigned to bundles, which jointly enter and leave the yard. Although feasible solutions can easily be obtained, the problem is NP-hard if certain, realistic objectives are chosen. We present different approaches for solving the problem exactly or heuristically. Finally, computational results are presented.\r\n", :title "Solving the Transshipment Yard Scheduling Problem", :keyword2 "Combinatorial Optimization", :authors (12453 5934), :session 207}, 675 {:keyword1 "queueing system", :keyword3 "effective production rates", :abstract "We describe a simple model of a production system which is represented as a queueing system,\r\nwhich experiences degradation of service and breakdown of the server.\r\nRepair is provided whenever the production machine (server) breaks down.\r\n\r\nWe consider two types of failures that occur: \r\nQuality failures, when the  production suffers from degradation of the machine and the produced parts are of minor quality,\r\nand  operational failures, when due to a fatal event the machine completely stops production. \r\n\r\nBecause the production and reliability issues are encompassed by a single Markovian model we are able to study the interrelation and interaction of this two aspects of the production process.\r\n\r\nWe are interested in obtaining simple terms  for the the steady state yield of the system, the effective production rate of good parts, the total production rate of parts of good and minor quality, and similar objectives.\r\n", :title " Integrated modeling of quantity and quality in a production system", :keyword2 "unreliability", :authors (17075 26509), :session 129}, 680 {:keyword1 "Text Mining", :keyword3 "SVM", :abstract "Text mining has become a widely used technology which heavily employs statistical and machine learning methods.\r\nThis paper addresses the question, whether text mining is appropriate for forecasting economic indices, like the Chicago Fed National Activity Index (CFNAI). On the basis of newspaper articles and economic indices, we try to find evidence how the sentiment reflected by those articles can be used to forecast the development of the indices. This is an important question, since media news affect the expectations about the economy by several ways: Firstly, the media covers the economic data and the outlook of economic development. Secondly, through the tone of economic articles individuals obtain an estimate about the significance of the topic. Finally, news coverage may influence people in their consumption behavior as well as in their expectations about economic development.  \r\nOur study will concern medium to short length articles from the New York Times Annotated Corpus published between Jan. 1, 1987 and June 19, 2007. As an economic index we use the CFNAI. To calculate the sentiments expressed in a newspaper article, we use two methods: One is based on tag categories provided in the General Inquirer to derive sentiment scores from term frequencies. The second approach makes use of statistical learning methods, like support vector machines (SVM). Finally, we discuss how media sentiments can be used for possible index forecasts.\r\nTypically, deriving sentiment scores from several million articles is computational expensive, and often requires high performance computing (HPC) tools. We use R, a language for statistical computing and graphics, since it offers both\r\ninfrastructure for text mining and tools for HPC to process large data sets efficiently.", :title "Do Media Sentiments Reflect Economic Indices?", :keyword2 "Sentiment Analysis", :authors (26514 16672 17141), :session 228}, 683 {:keyword1 "online social networks", :keyword3 "viral marketing", :abstract "The diffusion of information such as ideas or the promotion of products through online social networks (OSN) has been studied in numerous domains. The effect of “word of mouth” in the diffusion process has received major attention especially in applications of viral marketing. The majority of recent investigations has primarily addressed finding the most influential nodes in a social network as a starting set for message propagation. For this NP-hard selection problem, various algorithms have been introduced to determine a subset of influential individuals within a network. This subset is supposed to trigger a large number of individuals in later steps and lead to a high diffusion within the network. As this optimization process is nontrivial and cost intensive, we examine an alternative approach in this paper. We will show that within a large-scale OSN with particular characteristics, such as the small-world property, the selection of the most influential nodes is not necessarily required to achieve high diffusion rates. Based on a real world graph of the OSN XING including 963,947 vertices and 2,555,073 edges, we ran simulations on message propagation through the network. The simulations were based on both the selection of influential nodes as well as the selection of randomly chosen nodes as a starting set. As a result, we illustrate that both methods produce comparably high diffusion rates among all network individuals. Furthermore, we show that the relation between the parameters of the simulation and the resulting diffusion can be modeled as a cubic regression. Based on the regression equation we introduce a utility function including cost parameters and show how the trade-off between lowest cost and highest diffusion can be optimized using linear programming.", :title "Message propagation in large-scale online social networks – Why finding influential nodes in viral marketing may be a wasted effort", :keyword2 "information diffusion", :authors (26497 15857), :session 225}, 684 {:keyword1 "graph product", :keyword3 "wheel inequality", :abstract "A stable set in a graph G is a set of pairwise nonadjacent\r\nvertices. The problem of finding a maximum weight stable set\r\nis one of the most basic NP-hard problems. An important\r\napproach to this problem\r\nis to formulate it as the problem of optimizing a linear function over\r\nthe convex hull STAB(G) of incidence vectors of stable sets. Then\r\none has to solve separation problems over it.\r\nCheng and Cunningham (1997) introduced the wheel\r\ninequalities and presented an algorithm for their separation using\r\ntime O(n^4) for a graph with n vertices and m edges.  \r\nUsing graph products we present a new separation algorithm running in O(mn^2+n^3\\log n).", :title "Graph Products for Faster Separation of Wheel Inequalities", :keyword2 "separation algorithm", :authors (14777), :session 222}, 686 {:keyword1 "auctions", :keyword3 "group / individual behavior", :abstract "Combinatorial auctions have been studied analytically for several years, but only limited experimental results are available, in particular for auctions with more than 10 items. While large parts of the literature focus on differences in auction rules and pricing, we find experimental evidence that cognitive bounds of bidders are the biggest barrier to full efficiency. Remarkably, the most auction formats that were used or suggested for selling spectrum licenses use linear ask prices although only non-linear competitive equilibrium prices can always be efficient for general valuations. The main arguments for the use of linear-price auction are based on a limited number of lab experiments in the literature. We investigate experimentally the Hierarchical Package Bidding (HPB), the Combinatorial Clock (CC) and one pseudo-dual price auction, as all these formats were used or suggested for high-stakes spectrum auctions. While the differences in the aggregate results are small between the formats, CC achieves high efficiency and revenue in our experiments, but HPB also yields good results even without an obvious pre-packaging. We find that the main source of inefficiencies in all formats is the bidders' selection of packages, rather than strategies or auction rules; bidders mostly preselect a small number of packages of interest early in the auction. Our findings furthermore reveal that small bidders have more difficulties in coordinating their bids to outbid a national bidder in a threshold problem with HPB. ", :title "On the Impact of Cognitive Limits in Combinatorial Auctions: An Experimental Study in the Context of Spectrum Auction Design", :keyword2 "laboratory experiments", :authors (18553 18767 55333), :session 193}, 687 {:keyword1 "skewness", :keyword3 "portfolio selection", :abstract "Higher moments of asset price distributions – especially skewness – have long been recognized as important characteristics in asset pricing and risk management. However, it is less well known that portfolio characteristics other than variance may not diversify on a portfolio level but even accumulate. We study this behavior based on a parameterized description of asset price processes using GARCH-type models and non-normal increments. We analyze historical buy-and-hold-portfolios of German stocks and also study aggregation effects of simulated returns. The results not only confirm previously found non-diversification effects but provide new insight into return characteristics. ", :title "Diversification effects of asset price process parameters – an empirical investigation", :keyword2 "asset price processes", :authors (14810), :session 74}, 690 {:keyword1 "strategic logistics planning", :keyword3 "consolidation effects", :abstract "In global logistics operations, strategic and tactic planning aims at\r\nlaying the groundwork for cost-efficient day-to-day operation by\r\ndeciding on transport modes, routes, and delivery frequencies between\r\nfacilities in the network. Large shipments usually yield lower\r\nper-unit shipping cost, while high delivery frequencies reduce capital\r\ncommitment and storage cost. This crucial tradeoff encourages the\r\nconsolidation of shipments, which may take place spatially by\r\ncombining goods at hub locations, and temporally by accumulating goods\r\nover time for shipping.\r\n\r\nTraditional network flows frequently fail to adequately model reality\r\nin the realm of logistics, as shipping charges of multi-modal freight\r\ncarriers are highly heterogeneous and cost is rarely incurred on a\r\nsimple per-unit basis. We propose an optimization model for strategic\r\nand tactic logistics planning taking into account both spatial and\r\ntemporal consolidation effects, while being able to represent a broad\r\nrange of shipping rate schemes commonly used. Our model is susceptible\r\nto integer programming as well as flow-based heuristics and\r\nmeta-heuristics.\r\n\r\nIn this work-in-progress, we present our model along with an outlook\r\non our set of test instances from various industries, as well as some\r\npreliminary computational results. It is part of the MultiTrans\r\nproject, a cooperation between the COGA group at TU Berlin and 4flow\r\nAG, a market leader in logistics and supply chain management\r\nconsulting.\r\n", :title "A Fixed-Charge Flow Model for Strategic Logistics Planning with Delivery Frequencies", :keyword2 "delivery frequencies", :authors (17134 26518 26508), :session 118}, 691 {:keyword1 "Virtual Power Plant", :keyword3 "Smart Grid", :abstract "Increasing energy prices and the greenhouse effect lead to more awareness of energy efficiency and sustainability of electricity supply. During the last years, a lot of technologies have been developed to improve this efficiency and sustainability. Next to large scale technologies such as wind-turbine parks, domestic technologies are developed. These domestic technologies can be divided in 1) Distributed Generation (DG), 2) Energy Storage and 3) Demand Side Load Management. Each of these techniques has its own potential of reducing the energy consumption or increasing the efficiency or sustainability of the energy generation. However, using these technologies in an uncontrolled way, on the one hand, parts of the potentials may be wasted and, on the other hand, an instable grid may result.\r\n\r\nIn this talk we present a general concept for a combined planning and control of a large fleet of individual houses allowing the fleet of houses to act as a Virtual Power Plant. Based on this concept, a three-step optimization methodology is proposed using 1) off-line local prediction, 2) off-line global planning and 3) on-line local scheduling. The main focus of the talk is on methods for the global planning.\r\n", :title "Planning and control of a virtual power plant consiting of a large set of domestic houses", :keyword2 "Planning and Control", :authors (8513 26517 26519 26520 26521), :session 162}, 692 {:keyword1 "Trading System", :keyword3 "Parameterized Simulation", :abstract "The success of trading systems based on technical analysis still seems puzzling. Previous research delivered mixed results regarding the performance of technical trading and is predominantly based on historical backtests and bootstraps of different markets. Under the hypothesis that trend following systems should profit from autocorrelated returns, this work considers the interdependency of the implementation of a trading system and the parameterization of different underlying stochastic processes, which simulate the asset return. This sensitivity analysis is run to detect which factors are responsible for a trading system to work. The different parameters, which are put into the simulation, are estimated from real market data to obtain a realistic bandwidth. The return distributions generated by trading systems are compared to those of the corresponding buy-and-hold strategy as a reference. Evaluation of outperformance is not only done by using standard performance measures, but also by applying the concepts of stochastic dominance as well as expected utility, including a loss averse utility function. It can be shown that the success of a trading system depends both on the degree of autocorrelation of the asset return driving process as well as on the implementation of the trading system itself.\r\n", :title "Is Timing Money? The Return Shaping Effect of Technical Trading Systems", :keyword2 "Stochastic Dominance", :authors (21117), :session 181}, 693 {:keyword1 "System Dynamics", :keyword3 "Production Systems", :abstract "Manufacturers of the capital goods industry have been facing changing business conditions, e.g. shortening product life cycles or the increasing demand for product variants. In order to strength their competitiveness, companies have to react on these challenges and consequently, they have to adapt their internal resources, e.g. plants, production processes or personnel staff, to the changing conditions. Accordingly, there exist high economic risks for these companies, especially for small end medium sized enterprises, depending on the restructuring of the production system due to the high dynamics and the fast changes of the markets. Due to the described dynamics, the complex dependencies between internal reorganisation and external market conditions and the long-ranging consequences because of intra-company decisions concerning the modernisation of the production system, dynamic simulation models are required, which assess various intra-company strategies and their long-ranging impacts on the enterprise. Accordingly, the aim of this contribution is to develop a generic system dynamics model which illustrates how external market conditions interact with internal resources of a production system and which is able to evaluate various strategies concerning the modernisation of technical and non-technical processes in manufacturing companies. The practical usability of the instrument will be shown by means of a case study.", :title "System Dynamics Simulation for strategic Process Modernisation in Production Systems", :keyword2 "Process Modernisation", :authors (26451 17103), :session 44}, 694 {:keyword1 "Location Routing", :keyword3 "Logistics", :abstract "In countless logistics applications, operating cost is essentially tied to two major cost drivers: Opening facilities from which clients are served on the one hand, and operating vehicles performing pickups and/or deliveries from the facilities on the other. The two corresponding families of optimization problems, namely  facility location and  vehicle routing, have been studied extensively from practical as well as theoretical points of view. The integrated problem of jointly making location and routing decisions is known as location routing and has also received significant attention in the operations research community. While many heuristics for different variants of the problem have been proposed, no efficient algorithm with guaranteed approximation ratio has been known to date. \r\n\r\nWe fill this gap by devising the first polynomial time constant factor approximation for capacitated location routing. Furthermore, a specialization of our algorithm also yields an improved constant factor approximation for the multi-depot capacitated vehicle routing problem with arbitrary demands. Finally, we consider a variant of both problems where cross-docking is allowed: Here, nodes may also function as hubs to consolidate demand between different tours. Our algorithms can be adapted to yield even better approximation guarantees for this case.\r\n\r\nThis work is part of the MultiTrans project, a cooperation between the COGA group at TU Berlin and 4flow AG, a market leader in logistics and supply chain management consulting.", :title "Approximation Algorithms for Capacitated Location Routing", :keyword2 "Approximation Algorithm", :authors (26508 26518 17134), :session 216}, 695 {:keyword1 "sports scheduling", :keyword3 "round robin tournament", :abstract "For decades, the Belgian football league was a double round robin tournament with 18 teams. This season, the competition format was changed drastically: it now consists of a regular stage (a double round robin tournament with 16 teams), followed by play-offs. These play-offs consist of 3 double round robin tournaments: one has 6 teams, keeping half of their points from the regular stage, and competing for the league title, while the other 2 have 4 teams, losing all their points, and aiming for the final ticket for European football.\r\n\r\nApart from the classic sport scheduling constraints, the schedule of the regular stage has a constraint that concerns what  we call a “generalized break”: two home game (or two away games) on a pair of rounds. Notice that this pair of rounds is not necessarily consecutive, as is the case for a normal break. The play-off stage has the peculiarity that a number of constraints linking the 3 tournaments should be taken into account. For instance, two teams playing in different play-off competitions share the same stadium and thus should not play at home in the same round. Furthermore, the TV station broadcasting the play-offs is strongly interested in a schedule that postpones the decision on the league title for as long as possible.\r\n\r\nIn this presentation, we describe our experiences in scheduling this reformed competition. We show how we developed the schedules for both stages, which were used in practice to determine the 2009-2010 champion.\r\n", :title "Experiences in scheduling the reformed Belgian football league", :keyword2 "football", :authors (9583 6251), :session 146}, 697 {:keyword1 "production planning", :keyword3 "stochastic constraint programming", :abstract "Pharmaceutical companies must obey strict regulations for manufacturing their products.  These regulations are usually referred to as Good Manufacturing Practices (GMPs) and are enforced by the national regulatory agencies, who perform inspections to ensure that products are produced safely and correctly.  It is therefore important for a company to quantify and manage its resulting risk exposure.\r\n\r\nOf particular importance for production planning is the risk transfer between products, since all drugs produced at a site might be considered adulterated if any one fails the inspection. We show how these interdependencies can be modeled as single- and multi-period production planning problems under uncertainty.\r\n\r\nThe random events faced by the company are separated into two phases: the selection of which sites to inspect by the agency, and the success or failure of each inspection.  For the first phase, the inspection strategy is typically unknown so we assume the worst case, and model the agency as a perfect-information adversary.  For the second phase, different coherent risk measures are considered.  We show that the resulting production planning problem is NP-hard, but give compact MIP formulations for both worst-case and expected revenue.  However, we show that computing the CVaR of the revenue for a given plan is NP-hard.  In a numerical study, we compare the performance of the MIP formulations to a recently developed Stochastic Constraint Programming solver for both single- and multi-period problems.", :title "Production Planning under Non-Compliance Risk", :keyword2 "robust optimization", :authors (17127 12769 10025 33615), :session 138}, 698 {:keyword1 "Networks", :keyword3 "TELCO", :abstract "Routing traffic with demands and capacity constraints over a fixed network, is a well known NP-Complete problem.\r\nMoreover, finding a path distribution over an uncapacitated network, that connects certain nodes with a logical topology resilient to physical link failures, is an NP-Complete problem as well.\r\n\r\nNowadays most network traffic is data traffic, and real network implementations can be though as overlays where: the bottom one represents a Transport Network, the overlaying next a Data Network (typically an IP/MPLS network) whose links are physically and statically deployed over the Transport Layer.\r\n\r\nBesides, customers’ traffic is sent through paths (tunnels), which are dynamically routed over the current operational links of the Data Network, and therefore may be seen as new and dynamic layer itself.\r\n\r\nFinally, competition among different carriers pushes network engineers to optimize as much as possible network resources, whereas different quality of service requirements impose overbooking constraints.\r\n\r\nAs a result of the previous facts, the goal: optimize simultaneously the compound problem, may easily lead to a new class of problems computationally very hard to solve.\r\n\r\nThe approach presented in this work is the result of an investigation issued for a real South American TELCO. It covers: models and algorithms for the overall problem, as well as concrete results for several data scenarios.", :title "Multi-overlay Robust Network Design. An Application Case Study.", :keyword2 "Optimization", :authors (26457 13273), :session 218}, 699 {:keyword1 "Produktkonfiguration", :keyword3 "Robuste Optimierung", :abstract "Quantitative Modelle werden für Produktprogrammkonfigurationen vorgeschlagen, um unter Berücksichtigung von Zahlungsbereitschaften und entstehenden betrieblichen Kosten kundenrelevante Produkte zu identifizieren und aufeinander abzustimmen. Basierend auf unsicherer Kundennachfrage und einem mehrperiodischen Betrachtungszeitraum ist es wichtig, Veränderungen des Produktprogramms wie Produktinnovationen, -modifikationen und -eliminationen in die verwendeten mathematischen Optimierungsmodelle aufzunehmen. Flexibilität zum Umgang mit Veränderungen in Produktlebenszyklen sollte bei der Entwicklung von Produktprogrammen berücksichtigt werden.\r\n\r\nZur Modularisierung von Produkten werden mehrere Komponenten zu Modulen zusammengeschlossen, welche in unterschiedliche Produktkonfigurationen einfließen und durch Variation einzelner Komponenten Produktmodifikationen und dadurch Flexibilität begünstigen. Welche Produktkomponenten unter Beachtung der technischen Realisierbarkeit und betriebswirtschaftlichen Vorteilhaftigkeit in Module einfließen sollten, lässt sich durch quantitative Modelle optimieren.\r\n\r\nAufbauend auf einem geeigneten Modellierungsansatz für den deterministischen Fall wird untersucht, wie Unsicherheit und Dynamik zu berücksichtigen sind. Insbesondere das Potenzial robuster Optimierungsansätze zur Entscheidungsunterstützung wird anhand eines Fallbeispiels demonstriert.", :title "Optimale Modularisierung zur Flexibilitätssteigerung von Produktprogrammen", :keyword2 "Modularisierung", :authors (15182 10057), :session 157}, 702 {:keyword1 "mixed oligopoly", :keyword3 "software and hardware market", :abstract "The aim of this paper is to explain the structure of the market of hardware, proprietary and free software, and illegal copies of proprietary software. We propose a simple model of market interactions between hardware vendors, proprietary and free software developers, and pirates. We consider two hardware suppliers, Intel and AMD, both maximize profits forming a traditional duopoly, while proprietary software supplier, Microsoft, pirates (who sell illegal copies of Microsoft software), and the community of free software developers, form a mixed oligopoly, in which only the first two parties maximize their profits. At the Cournot equilibrium Microsoft Windows price is ten times greater than AMD CPU price, illegal copies of proprietary software are two times cheaper than legal copies of the same software, the profit of Microsoft is approximately five times greater than the profit of Intel, and approximately twenty times greater than the profit of AMD, integrated profit of pirates is 26% greater than the profit of Intel. The market share of Intel is two times greater than AMD share, and 33% greater than Microsoft Windows share which, in turn, is 33% greater than Microsoft Office share; Microsoft Windows and Microsoft Office illegal copies market shares are two times smaller than the shares of corresponding legal copies; Linux share is the same as of illegal Windows share, and OpenOffice share is 17% greater than the legal Microsoft Office share. ", :title "Equlibrium in a market of computer hardware, proprietary, free and pirated software", :keyword2 "Cournot equilibrium", :authors (24840 26526 26527), :session 192}, 704 {:keyword1 "communication", :keyword3 "synchronization", :abstract "We developed a model for feedback loops in the exchange of information between two actors. Feedback loops were constructed in that model, according to hypotheses about positive and negative feedback between the actors. For the actors themselves we supposed entangled ‘inner’ feedback loops between the information task and related psycho-social and control processes. Those processes were modeled as limit to growth processes, that will say as non linear differential equations of logistic growth. In a number of simulation studies, using STELLA and Madonna, we proved at face value that this complex model fit patterns we found in video observations as it was put in SPSS data (Dijkum et al 2008). To explore the model in a more exact way we reprogrammed the model in Matlab as an extension of a model that was explored earlier by Savi (2007).  The leading question of our exploration is: is it possible to bring the task variable to an optimal state (for example a maximum) when both actors are in a state of (relative) chaos, by using processes of synchronization and coordination? Or a more weak question. Is it possible when one or more of the components (represented by basic logistic equations) of the system (in actor1, or actor2, or in both actors) are in a state of chaos, to optimize goal variables in processes of synchronization and coordination?\r\n\r\nReference;\r\nDijkum, C. van, Verheul W., Lam N., Bensing J. (2008). Non Linear Models for the Feedback between GP and Patients. In Trappl R. (Ed). Cybernetics and Systems. Vienna: Austrian Society for Cybernetic Studies, pp. 629-634.  \r\nSavi M., (2007). Effects of randomness on chaos and order of coupled logistic maps. Physics Letters A, 364, pp 389–395.\r\n", :title "Exploring a complex model of communication ", :keyword2 "logistic equations", :authors (18947 18948), :session 22}, 705 {:keyword1 "preference learning", :keyword3 "", :abstract "\r\nThe traditional user preference modeling in economy is focused on direct specification of utility functions and criteria. We propose a method to learn these from a user’s rating of a small sample of alternatives. This approach is applicable to more simple domains – we do not dare to learn preferences for e.g. medical treatment. Learning approach is more convenient way for less experienced user, because rating of an object is simpler than specifying utility functions.\r\nOur approach is divided in two steps with learning of criteria for each attribute. This step transforms attribute from ‘price’ to ‘cheap’ and ‘weight’ to ‘light’ (or ‘heavy’, which depends on the user). The second step then compute the overall utility of the alternative, based on the satisfaction of the (learnt) criteria.\r\nThe main problems is that the sample rated by the user is very small (up to 50 objects) and the rating is given on a small set of rating, usually 1,2,3,4,5. This results in very many objects obtaining the highest utility, but we want to recommend only e.g. top 10 objects. We propose a way for solving this undecidability.\r\nOur approach is tested on an artificial user represented by predefined criteria and utility. The comparison is to UTA method and traditional machine learning methods such as support vector machine or multilayer perceptron.\r\n\r\n", :title "Aquiring changing user objectives in large product search systems", :keyword2 "top k querying", :authors (26531 15858), :session 234}, 706 {:keyword1 "parallel machine scheduling", :keyword3 "mixed integer linear programming", :abstract "The addressed problem in this paper considers joint load balancing and parallel machines scheduling context. Two decisions are taken at once: the search for the best scheduling of the n tasks on m identical parallel machines in order to minimize total tardiness and find the equitable distribution of the machine’s time activity. At our knowledge, these two criteria have never been simultaneously studied for the case of parallel machines. The problem considered is NP-hard since the problem with only the total tardiness is NP-hard. We propose an exact and approached method. The first one is based on the mixed integer linear programming method solved by Cplex software. The second one is an adapted genetic algorithm. The test examples were generated using the scheme proposed by Koulamas [Christos Koulamas,”Single-machine scheduling with time windows and earliness/tardiness penalties”, European Journal of Operational Research 91(1996), 190-202.] for the total tardiness problem. The obtained results are promising.", :title "THE JOINT LOAD BALANCING AND PARALLEL MACHINES SCHEDULING", :keyword2 "load balancing", :authors (26532 29382 16003 15915), :session 152}, 707 {:keyword1 "linear programming", :keyword3 "", :abstract "We present an algorithm for solving systems of linear inequalities. The algorithm is polynomial. Moreover, in strongly polynomial time the algorithm  either finds a solution of the system or decides that there is no {0,1}-solution. The algorithm uses a divide-and-conquer procedure which is based on projections onto the affine subspace. The affine subspace may be replaced by another convex set. Thus the algorithm may be applied to a more general class of convex problems than linear ones.", :title "A polynomial algorithm for linear and convex programming", :keyword2 "polynomial algorithm", :authors (6281), :session 105}, 709 {:keyword1 "Integer programming", :keyword3 "", :abstract "We study the problem of designing telecommunication networks using transmission facilities of two different capacities. This problem is known as network loading/ network design problem (NDP) in the literature. Point-to-point communication demands are met by installing a mix of facilities of both capacities on the edges so that the overall cost is minimized. Applications of this problem and its variants arise frequently in the telecommunications industry for both service providers and their customers. \r\n\r\nThe model tries to exploit the strong economies of scale provided by the higher capacity facilities. This problem has been proved to be NP-hard and the integrality gap has been observed to be generally very high.\r\n\r\nWe consider 3-partitions of the original NDP graph which results in smaller 3-node NDPs. We extend a theorem, proposed in the literature, according to which a facet inequality of the k-node subproblem resulting from a k-partition translates into a facet of the original problem for two-facility NDP. We also propose a set of theorems that help to enumerate all the extreme points of the underlying polyhedron of the 3-node subproblem. We introduce a new approach for computing the facets of 3-node subproblem using polarity theory after obtaining the extreme points. The extended theorem is utilized thereafter to translate the facets of the 3-node subproblem to the facets of the original NDP.\r\n\r\n        \tWe have tested our approach on several randomly generated networks. The computational results show that 3-partition facets reduce the integrality gap, compared to that provided by 2-partition facets, by approximately 30-60%. Also there is a substantial reduction in the size of the branch-and-bound tree if these facets are used.\r\n", :title "A Polyhedral Approach for Solving Two Facility Network Design Problem", :keyword2 "Telecommunications", :authors (25650 15580), :session 218}, 710 {:keyword1 "warehousing", :keyword3 "product structure", :abstract "Warehouse plays an important part in any supply chain as a point of storage, segregation and consolidation. A warehouse also contributes a significant cost component to the overall supply chain cost. A major portion of the warehousing cost is attributed to the warehouse picking activity as it is carried out manually in many warehouses. This paper addresses the problem of part storage layout in a typical manufacturing warehouse that serves a manufacturing assembly. The paper focuses on using product structure information to assign location to parts by utilizing family based grouping technique. Product structure influences the assembly process of the product and consequently the picking process of parts in the warehouse is also affected. A typical engineering product structure consists of multiple ‘options’ which together constitute a bill of material. An option is a collection or subassembly or parts that serve a particular functionality. Thus product structure induces a correlation between the parts that constitute the product. The paper proposes to use a two step linear model to cluster options and parts on the basis of the correlation between them. Options belonging to the same family are clustered in step one of the model while individual parts within clusters so formed are grouped in the second step. The novelty of this paper lies in the fact that it considers options and compatibility rules as criteria for clustering along with the bill of material information.", :title " Part Storage Layout in a Manufacturing Warehouse Using Product Structure Information", :keyword2 "clustering", :authors (26534 20599), :session 116}, 711 {:keyword1 "CONWIP", :keyword3 "Simulation", :abstract "CONWIP is a push-pull production method that seeks controlling the inventory l in flowshops. This system accomplishes this control by starting production of a new unit only when a unit is made.  Only when a unit is completed exits the system, a production request is released to the starting station. This paper proposes complementing the information provided by the production request with information about total product net-requirement for each product in each workstation.  Net-requirement for a product at a workstation is the difference between the number of customers waiting (product request) and the sum of the work-in-process units of that product in the workstation and all of its downstream.  A simulation study is performed to analyze critical measures of performance that include customer wait-time and total inventory. The analysis reveals substantial and statistically significant improvements from considering product net-requirement information.", :title "CONWIP and Net-Requirement CONWIP: A Simulation Study", :keyword2 "Production", :authors (20599), :session 161}, 713 {:keyword1 "quadratic order", :keyword3 "critical cone ", :abstract "For the control system linear in one tuple of control variables and nonlinear in another tuple, \r\nwe consider the problem of minimizing the cost of the Mayer type under equality and inequality \r\nendpoint constraints.  Take a process with an interior controls satisfying the first order necessary conditions for a weak minimum with a unique collection of multipliers, and calculate the second variation of the corresponding Lagrange function.  If the reference process provides a weak minimum\r\nwith respect to both control tuples (weak--weak minimum), then the second variation must be \r\nnonnegative on the cone of critical variations, i.e. those satisfying the linearized relations of the problem. If, on the other hand, the second variation is positive definite on this cone with respect to \r\na special quadratic order, then the reference process provides a strict weak--weak minimum, \r\nand moreover, in some uniform neighborhood of the reference process the increment of the cost is\r\nestimated from below by this order. These conditions are close to each other with no gap between them.\r\nThe above nonnegativity  implies some pointwise conditions of the Legendre and Goh type. \r\nWe also consider a weak minimum with respect to “nonlinear” control and a so-called Pontryagin\r\nminimum with respect to “linear” control (weak--Pontryagin minimum).  The above result remains \r\nvalid if the Legendre and Goh conditions are complemented by some condition of equality type on \r\nthe third variation of the Lagrange function. \r\n\r\n\r\n", :title "Quadratic order optimality conditions for extremals completely singular in part of controls", :keyword2 "second variation", :authors (21077), :session 106}, 714 {:keyword1 "Queues", :keyword3 "Performance Evaluation", :abstract "It is an important and urgent OR issue to evaluate the access delay in a web-server system handling internet commerce real-time services.  However, there exists almost no literature on the access delay analyses for the web-server system with multiple proxy servers.\r\n  \r\nThe goal of this paper is to provide an access-delay modeling and a queueing analysis for the web-server system with multiple proxy servers.  Our approach is based on the diffusion approximation technique [2].  We derive the squared coefficients of variation of the individual output processes from the proxy servers.  Regarding the unfinished workload in the web-server system with input (which is nothing but the superposition of the output processes from the proxy servers) as a diffusion process, we derive the mean unfinished workload in the web-server system.  The relationship between the mean unfinished workload and the mean waiting time in the system is then applied to find a new mean-delay approximate formula.\r\n  \r\nOur approximate formula is shown to be consistent with the previously obtained exact result for a special case (single proxy server and Poissonian arrival model [1]).  The accuracy of our approximation for a non-Poissonian arrival model is validated by simulation results.\r\n  \r\nReferences: [1] Y. Takahashi and T. Takenaka, Performance modeling a web-server access operation with proxy-server caching mechanism. Proceedings of the 45-th ORSJ (Operations Research Society of Japan) Symposium, pp. 1—9 (2001). [2] A. Takahashi, Y. Takahashi, S. Kaneda, and N. Shinagawa, Diffusion approximations for the GI/G/c/K queue.  Proc. the 16th IEEE International Conference on Computer and Communication Networks, pp. 681-686 (2007).\r\n", :title "Diffusion Approximation for a Web-Server System with Proxy Servers", :keyword2 "Diffusion Process", :authors (25356 25364 25363), :session 132}, 716 {:keyword1 "Supply Chain Coordination", :keyword3 "Cooperative Agents", :abstract "We present an agent-based decentralized cooperative scheduling (ADCS) approach for integrated production and distribution planning processes in a multi-tier supply chain network (SCN). \r\nThe common objective of each agent is to minimize the total operating and outsourcing costs of its tasks by determining an optimal production schedule or a transportation route and schedule. In addition, agents can try to increase their temporal flexibility -- and thus the utility of their individual contract situation -- by renegotiating for new contract dates with their contract partners, possibly incurring side payments. \r\nOur ADCS approach comprises two parts: the individual optimization of an agent's local schedule and the cooperative contract optimization, either by outsourcing or by (re-)contracting aiming to maximize their total profits. Due to the distributed structure of the network a slim Distributed Recursive Converging 2-Phase Net Protocol (DRC2PNP) is developed for contracting and negotiation processes between agents.\r\nTo foster truthful bidding of price and contract execution times, a service time dependent contract price function has to be provides by the agent initiating the (re-)contracting process. Agents participate in a kind of closed auction for efficient contracting with network participants.\r\nIn order to benchmark the agent's distributed planning mechanism a set of SCN instances is generated by using an instance generator we developed and bounds on the globally optimal solution quality are obtained using ILOG's CPLEX Optimizer.\r\nExtensions of the network allowing for geographically distributed depots (i.e. transport agents) and a heterogeneous fleet can be modeled straightforwardly.", :title "Agent-based Cooperative and Dispositive Optimization of Integrated Production and Distribution Planning", :keyword2 "Decentralized Scheduling", :authors (26263 26680 24583), :session 126}, 718 {:keyword1 "information value", :keyword3 "information asymmetry", :abstract "In the context of optimization problems of an agent “having more information without additional cost is always beneficial” (D. Blackwell, 1953). Nevertheless, in cases with strategic interaction this is not always true. Under what conditions more information is (socially) beneficial in games? How characteristics of the players and the interaction among them affect the information value?\r\nExisting literature varies between two ends: on the one hand, we find works that compute the information value of particular cases not always easy to generalize; on the other hand, there are also abstract studies which make difficult the analysis.\r\nIn order to fill this gap, we computed the information value in the general case of constrained quadratic games in the framework of Hilbert spaces; we determined conditions to assure its no-negativity; and, we studied some characteristics of the players affect their value.\r\nThis work presents the most important results and a revision of the possible applications.\r\nWe found a close relationship between the symmetry of information and the mathematical property of invariance (of subspaces). Such property is the base to compute the information value and demonstrating its non-negativity.\r\nSuch results improve the understanding of conditions that assure the non-negativity of information value and how this depends on some characteristics of the players and their interaction.\r\nThis work can be extended in several directions, the most interesting are games with information asymmetry that satisfy invariance conditions.", :title "Non-negativity of information value in games, symmetry and invariance", :keyword2 "quadratic games", :authors (26217 12787), :session 194}, 720 {:keyword1 "Cloud Computing", :keyword3 "", :abstract "Utility computing (or on-demand computing) is the packaging of computing resources, such as computation, memory, and storage, as a metered service similar to a physical public utility.\r\n\r\nWe will start with a brief overview on the history of utility computing applied to mathematical programming projects and show two different prominent available technologies (Amazon's Computing Cloud and the Microsoft Windows Azure platform). \r\nWe will use some large scale example applications and discuss how these approaches are already suitable for the requirements of (commercial) mathematical programming problems.\r\n\r\n\r\nNote: The author is not available on Friday.", :title "Using Utility Computing to provide Mathematical Programming Resources", :keyword2 "Utility computing", :authors (14853), :session 104}, 722 {:keyword1 "quadratic assignment problem", :keyword3 "graph", :abstract "The quadratic assignment problem (QAP) is a classical model of the facilities layout problem. A lot of real-life applications can be modeled as QAPs such as computer manufacturing, hospital planning, process communication, placement of electronic components and so on. The QAP belongs to the class of NP-complete problems but polynomial algorithms were introduced for special cases. We consider the following statement of the QAP (graph formulation of the problem). Structure of connections between facilities is defined by a weighted graph. Positions in which the facilities will be located are nodes of a weighted network. The problem is to find permutation of the graph vertices on the network nodes that minimizes the sum of the connections cost. We provide polynomial algorithms for solving special cases of the problem such as layout of non-weighted chain on weighted tree, common graph on star and so on.", :title "Polynomial Algorithms for Some Cases of Quadratic Assignment Problem", :keyword2 "polynomial algorythm", :authors (24983 23719), :session 214}, 724 {:keyword1 "Network flows", :keyword3 "min-cost fixed flow ", :abstract "                                                       Abstract\r\n          In this paper we consider a network flow system in which setting up a flow incurs a fixed cost. This cost affects the total average cost of operating the system. Our goal is to find the maximum flow that minimizes the average cost of sending flow from the source node to the sink node. In the classical maximum flow problem no cost is considered. Also, min-cost fixed flow problem tries to send a given amount of flow from the source to the sink at the least cost. Here, in addition to the fixed set-up cost, we take into account both the transferring flow cost and possible maximum amount of flow. A mathematical model with the objective of minimizing the average cost of operating the system is constructed.  Then, by defining residual network and augmenting paths, we develop an algorithm to compute a flow with maximum value and minimum average cost. The polynomial time order of the algorithm is O (n^2m).\r\n     Exhaustive sensitivity analysis of the fixed set-up cost, at the end, helps to determine the suitable values of the system parameters.\r\n\r\n \r\n", :title "The Maximum Flow Minimum Average Cost Problem", :keyword2 "maximum flow problem", :authors (17396), :session 219}, 725 {:keyword1 "Renewable Energies", :keyword3 "Energy Markets", :abstract "In Germany, the transmission system operators are in charge of integrating the intermittent electricity production from renewable energy sources (RES-E) into the energy markets. A critical factor for the whole process is the quality and reliability of RES-E forecasts. Therefore EnBW Transportnetze AG and the department of Quantitative Methods at University of Hohenheim jointly develop advanced models for the forecasting of RES-E. In the first step a parameter based model for shortest term forecasting of wind energy was developed which is already operationally used for intraday trading activities.\r\nThe presentation describes the main ideas of the model, the algorithmic challenges and the results of the model in relation to other forecasting systems.\r\n", :title "Market Integration of Renewable Energies: Parameter based models for shortest term forecasting", :keyword2 "Forecasting Systems", :authors (26499), :session 85}, 727 {:keyword1 "stochastic programming", :keyword3 "open-source  optimisation software", :abstract "We extend the open-source modelling language FlopC++, which is part of the COIN-OR project, to support multi-stage stochastic programs with recourse. We connect the stochastic version of FlopC++ to the existing COIN class stochastic modelling interface (SMI) to provide a direct interface to specialized solution algorithms. The new stochastic version of FlopC++ can be used to specify scenario-based problems and distribution-based problems with independent random variables. A data-driven scenario tree generation method transforms a given scenario fan, a collection of different data paths with specified probabilities, into a scenario tree. We illustrate our extensions by means of a two-stage mixed integer strategic supply chain design problem and a multi-stage investment model.", :title "Stochastic Extensions to FlopC++", :keyword2 "modelling languages", :authors (26302 9272 13680), :session 91}, 728 {:keyword1 "traffic simulation", :keyword3 "what if analysis", :abstract "Many aspects of the traffic control system may have influence on the logistic system in the factory. In the paper the WHAT IF analysis was considered. The purpose of the paper was to prepare the simulation model for the traffic in the urban environment due to the transport between the two plants of the car factory.  The motivation for this work was generated by the necessity of observation the renovation influence in the roads network. The one of the main junction is rebuilding in the route of internal lorry’s traffic in the car factory.  The observation was made for the several types of the vehicles: delivery final product trucks, suppliers chain trucks, JIT lorries and shuttles between two plants involved in the car factory logistic system.  \r\nThe simulation model has been constructed for the considered area of the city map. The real data has been collected either from the road traffic control operators or the car factory logistic control system.\r\nThe graph junction model has been proposed and adapted to the traffic model. The main junctions in the areas were modelled according to the real design. The traffic light control program was incorporated into the simulation models. The real traffic density data on the observed area were collected. \r\nThe goal was to prepare the simulation model for the one hypothetical average working day – 24h. The distribution of the traffic was constructed out of the real data set.  Also the distribution of the car routing on the each junction have been designed. For several types of the vehicles  like buses and shuttles the routing was determined.  \r\nThe traffic jams were defined and observed during the simulation. Analysis generates several reports aiding the decision maker of the logistic control. \r\n", :title "WHAT IF  analysis in the urban traffic system for car factory logistics", :keyword2 "logistic", :authors (4224), :session 202}, 730 {:keyword1 "Personnel Planning", :keyword3 "Decision Support Systems", :abstract "The talk presents a heuristic optimization approach for personnel planning problems. The considered case is motivated by the very recent Nurse Rostering Competition NRC 2010, in which a set of shifts must be covered by employees. Complex side constraints and multiple criteria further complicate the solution of the derived models. Moreover, the computation of solutions must be done within a given time limit.\r\nOur algorithmic work is based on Variable Neighborhood Search (VNS), a metaheuristic allowing the comparable fast computation of relatively good solutions for the problem at hand. Starting with an initial constructive approach, we investigate the possibilities of VNS for the NRC personnel planning instances. Experiments are carried out for the NRC data sets, and results are presented.\r\nWe are, in particular, interested in the cases for which the computation of solutions must be completed within a strict time limit of a few (around ten) seconds. The main motivation of this particular experimental setting lies in the combination of the heuristic search procedure with a succeeding decision making phase, in which the planner might interact with the proposed decision support system, e.g. by altering side constraints or criteria. ", :title "On variable neighborhood search and decision support for personnel planning problems", :keyword2 "Metaheuristics", :authors (5321), :session 124}, 731 {:keyword1 "Budget negotiations", :keyword3 "planning", :abstract "We analyze two functions of budgeting, planning and performance evaluation, in a real effort experiment where superiors negotiate budgets with their subordinates who have slack creating incentives. This is an important question as there is a major conflict between the two functions, and consequently, the planning and the performance evaluation budgets should be set differently. In the experiment, superiors are either restricted to use a single budget for both planning and performance evaluation or can set two separate budgets. We find that the planning task per se does not affect the performance evaluation function and its process. If superiors have the possibility to set distinct budgets for planning and performance evaluation, planning budgets are set to minimize planning slack ex ante and motivation budgets include the same slack as in a case without planning task. In contrast, if superiors are restricted to use a single budget for both purposes, the planning task becomes more relevant for the process and the outcome of budget negotiations. However, in contrast to the expectations that can be derived from an economic perspective, the restriction does not lead to an efficiency loss. This is due to the fact that subordinates react more cooperatively during and after the negotiation in the single-budget case. In particular, budget impositions by the superiors following a negotiation impasse seem to be more acceptable for the subordinates, and the motivation loss in the single-budget case is much smaller than in the two other cases. Moreover, while the subordinates’ bids during the negotiation in the separate-budgets case do not convey any private information about their capabilities, their bids in the single-budget case are positively related to their capabilities.", :title "Using Negotiated Budgets for Planning and Performance Evaluation: an Experimental Study", :keyword2 "performance evaluation", :authors (8892 9667), :session 121}, 732 {:keyword1 "scheduling", :keyword3 "simulation", :abstract "Kidney exchanges between incompatible donor-recipient pairs, as first suggested by the medical community, are nowadays organized in several countries. The aim is to increase the number of available organs for transplantation. From the mathematical point of view, the practical organization of a kidney exchange system raises several problems.\r\nDespite a wide literature is devoted to the study of the optimal organization of such exchanges in a static situation, considerably less attention has been devoted to the dynamic setting, though the latter is  fairly more realistic than the former, since donor-recipient pairs join the system over time and not all at the same time.\r\n\r\nIn this paper we develop a simulator which models the real situation, in which donor-recipient pairs with characteristics drawn from realistic distributions join the system over time, and a centralized authority organizes a suitably chosen set of exchanges among the pairs in the pool at regular intervals of time, as it happens for instance in the Netherlands or in the US.   \r\n\r\nWe discuss the results of numerical simulations obtained using this model, analyzing the performance of the chosen  exchanges policy,  in terms of some relevant performance indices such as the number of matched and unmatched patients, the average quality of completed exchanges,  or the average waiting time with respect to the pair's characteristics. Moreover, a comparison of the performance corresponding  to different choices of the time interval between one slot of exchanges and the other one is presented.  ", :title " Dynamic simulations of kidney exchanges", :keyword2 "dynamic models", :authors (26346 26540 26541 9278), :session 139}, 734 {:keyword1 "PEPA", :keyword3 "Fluid models", :abstract "Analytical models based on discrete-state representations such as Markov chains play a fundamental role in the performance evaluation of computer systems due to their mathematical tractability. However, the analysis of large-scale systems is fundamentally hampered by the infamous problem of state-space explosion. This paper discusses recent advances in the development of a software tool --- the PEPA Eclipse Plug-in --- which provides a unified modelling framework for the analysis of small- to large-scale concurrent distributed systems. The software implements the stochastic process algebra PEPA and incorporates the most recent developments of the language. For small- to medium-sized models, the modeller has access to a toolkit for the numerical solution of the underlying Markov chain which is capable to handle up to some million states. Importantly the PEPA Eclipse Plug-in offers a completely re-engineered module for the evaluation of larger state spaces, either via an efficient stochastic simulation algorithm or through fluid analysis based on ordinary differential equations. In either case, the functionality is provided by a common user interface, which presents the user with a number of wizards that ease the specification of typical performance measures such as average response time or throughput. Behind the scenes, the engine for stochastic simulation has been extended in order to support both transient and steady-state simulation and to calculate confidence levels and correlations without resorting to external tools. The core functionality has also been re-factored to seamlessly permit its adoption in computing environments where the rich graphical user interface provided by the tool is not required. ", :title "Large-scale Modelling with the PEPA Eclipse Plug-in", :keyword2 "Markov chains", :authors (26545 26544), :session 131}, 736 {:keyword1 "Queues", :keyword3 "Performance Evaluation", :abstract "Under the RR (round-robin) rule, the processor allocates to each job a fixed amount of time, called a quantum. If a job’s service time (the total time required from the processor) is completed in less than the quantum, it leaves; otherwise, it feeds back to the end of the queue of waiting jobs, waits its turn to receive another quantum of service, and continues in this fashion until its total service time has been obtained from the processor. The processor-sharing (PS) rule is then defined by taking the limit of the RR rule as the quantum length tends to zero. There are many references on the PS rule, started with pioneering work of Kleinrock. To the best of the authors’ knowledge, however, most of them treat a Poisson-input M/G/1 (PS) system. This paper treats a renewal-input GI/G/1 (PS) system. Using the relationship between the waiting time and the unfinished work, along with the unfinished-work based diffusion approximation technique, we obtain a new mean-delay approximate formula. Our approximation is shown to be consistent with the previously-obtained exact result for the Poisson-input M/G/1 (PS) system. The accuracy of our approximation for the non-Poisson-input system is validated by computer simulation results. References \r\n[1] L. Kleinrock, \"Time-shared systems: A theoretical treatment,\" J.ACM, vol.14, 242-261 (1967). \r\n[2] M. Sakata, S. Noguchi, and J. Oizumi, “An analysis of the M/G/1 queue under round robin scheduling,” Operations Research, vol.19, 371-385 (1971). \r\n[3] J.L. van den Berg and O.J. Boxma, \"The M/G/1 queue with processor sharing and its relation to a feedback queue,\" Queueing Systems, vol.9, 365-402 (1991).\r\n", :title "A New Mean-Delay Approximate Formula for a GI/G/1 Processor-Sharing System", :keyword2 "Diffusion Process", :authors (26485 25364 25356 26546), :session 130}, 741 {:keyword1 "weak conjugate maps", :keyword3 "vector optimization", :abstract "In this work, by using the concepts of supremal,  infimal element of a set and the concept of vectorial norm, we defined weak conjugate, weak biconjugate maps and weak subdifferential of a set valued map in a partially ordered normed space. We present some relationships between a set valued map and weak conjugate and weak biconjugate of this set valued map.  Furthermore, weak subdifferentiability conditions for set valued maps are given. At the end, under some assumptions, it is shown that weak subdifferentiability of a set valued map implies the equality of this set valued map and  weak biconjugate map.", :title "WEAK CONJUGATE MAPS AND SUBDIFFERENTIALS FOR SET VALUED MAPS", :keyword2 "weak subdifferentials", :authors (20717 20714 20715), :session 103}, 742 {:keyword1 "weak conjugate maps", :keyword3 "vector optimization", :abstract "In this work, we  construct a weak conjugate dual problem for nonconvex vector optimization problem, by using weak conjugate maps. In addition, weak duality theorem and strong duality theorem are given. At the end, by using a special perturbation function we construct weak Fenchel dual problem for nonconvex vector optimization problem.", :title "WEAK CONJUGATE DUALITY FOR NONCONVEX VECTOR OPTIMIZATION ", :keyword2 "weak subdifferentials", :authors (20714 20717 20715), :session 103}, 743 {:keyword1 "Set valued optimization", :keyword3 "scalarization", :abstract "A construction method of total order cone on n dimensional Euclidean space was given, it was shown that any total ordering cone in n dimensional Euclidean space is isomorphic to the lexicographic cone of  n dimensional Euclidean space, also, existence of a total ordering cone that contain given cone with a compact base was shown and by using this cone, a new scalarization method of vector and set-valued optimization problems was given by Küçük et.al. In this work, it is shown that the minimal elements  for the vector optimization problem with respect to total ordering cone are also minimal elements for the given optimization problem. In addition, the relationships between the continuity of set valued map and vector valued map derived by the minimal element of this set valued map with respect to the total ordering cone are given on examples. \r\n", :title "ON THE SCALARIZATION OF SET-VALUED OPTIMIZATION PROBLEMS WITH RESPECT TO TOTAL ORDERING CONES", :keyword2 "total ordering cone", :authors (20715 26515 20717), :session 103}, 747 {:keyword1 "multi criteria", :keyword3 "transportation problem", :abstract "Each term hundreds of students intend to write their bachelor thesis at a faculty. Often, many students prefer a few professors which have only a limited capacity. Consequently a lot of students have to look for an alternative. Usually this process is time consuming, especially if first best and second best are fully booked. For that reason the faculty of business and economics at the University of Hohenheim developed a registration tool supporting the allocation of bachelor theses for all students. This tool applies a linear program that is based on a transportation problem.  With the allocation tool the faculty has two goals: optimizing preferences of students on the one hand and balancing resources of professorships on the other hand.  The second objective utilizes a quadratic deviation function, which is transformed into a linear one. The presentation introduces the resulting linear program, i.e. the lexicographic program of the underlying bicriterion transportation problem.  Moreover, the faculty has initiated a multi-stage process in order to guarantee that each student gets at least one of his favorites. The results of the allocation process at the University of Hohenheim will be presented in detail.", :title "Allocation of bachelor theses: a bicriterion linear program", :keyword2 "linear program", :authors (14890), :session 234}, 750 {:keyword1 "Power law correlation", :keyword3 "Detrended fluctuation analysis", :abstract "This paper investigates the long range power law autocorrelations and cross-correlations of six major stock indices of the US (S\\&P 500), UK (FTSE), France (CAC 40), Germany (DAX), Switzerland (SSMI) and Japan (Nikkei 225). We tried to examine the changes in daily cross-correlations among these markets, during the period between January 1991 and December 2009. To obtain the correlations we use detrended fluctuation analysis (DFA) and detrended cross-correlation analysis (DCCA) which are methods adapted from Econophysics. Our results indicate that, in the referred period, cross correlations have not changed significantly. We also found that there are remarkable correlations between Nikkei and S\\&P500 as well as Nikkei and DAX. Moreover, the results indicate that correlations exist between some of these markets but not in a power law manner.", :title "Applying The Detrended Cross-Correlation Analysis To Six Major Stock Index Returns", :keyword2 "Detrended cross-correlation analysis", :authors (26561 25150 26955), :session 97}, 754 {:keyword1 "traffic management", :keyword3 "autonomic systems", :abstract "The task of managing traffic in local and regional road networks is highly complex due to: the nature of the traffic flow as the collective outcome of individual drivers’ decisions; the rules/regulations and policies network operators have to follow; the sophistication of the methods/tools used in Traffic Control Centres. A network operator receives a large number of information feeds, resulting to overload. A lot of information is available but understanding and correlating events and consequences of possible actions is impossible. To address this complex problem, new and innovative systems need to be developed.\r\n\r\nAutonomic systems have been suggested by computer science as an answer to the problems system administrators are faced when trying to manage heterogeneous distributed computing systems. They are inspired from the biological paradigm of the autonomic nervous system. In general autonomic systems properties are described as self-*, e.g. self-management. The resulting systems are highly stable and undertake and hide the details of high level policy implementation.\r\n\r\nThe same design principle can be used for traffic management systems. Network operators should function on a high level and subsequently autonomic systems should take all necessary steps to disaggregate policies to actions in a robust, trustworthy and stable way, hiding the associated complexity. By exploiting sophisticated soft computing methods and the potential provided by existing and emerging technology new system designs can be realised. \r\n\r\nHere, traffic control operations are viewed and examined from the autonomic systems perspective and the meaning of self-* properties for this particular case is discussed.\r\n", :title "Addressing the Complexity of Road Traffic Management Problems Based on Autonomic Systems Design Principles", :keyword2 "traffic control", :authors (10347), :session 202}, 755 {:keyword1 "Operations research", :keyword3 "supply chain ", :abstract "The emergence of new and complex relational arrangements between companies is a consequence of important changes promoted by globalization processes. Despite the intense transformation of this scenario it is perceived that most of the existing models only partially considering the phenomenon where logistics systems balanced, efficient and responsiveness have high importance in the maintenance and survival of the supply chains. The integrated use of simulation methods opens the possibility to exploring old and new problems through a new perspective that can promote better solutions to real-world problems. This strategy is rare in the literature, since most of the studies found focus on single method applications. Thus, this article contributes to better use of computer modeling simulation proposing combined use strategies of these methods what offers the potential to increase the strengths of these methods and reduce individual limitations. Three methods are discussed: Discrete Event Simulation (DES), System Dynamics (SD), Modeling and Agent-based Modeling and Simulation (ABMS). A comparative analysis between these methods is presented and in the following one practical application in a Brazilian case is discussed.", :title "Integrated methods of modeling and simulation applied to relational arrangements on supply chains: analysis and practical applications", :keyword2 "simulation", :authors (26434 26551 15586), :session 43}, 756 {:keyword1 "Queues", :keyword3 "Performance Evaluation", :abstract "The diffusion approximations are widely used to evaluate the performance measures in the renewal input, general service time queueing systems, since the Markovian approach sometimes requires an elegant and subtle numerical technique. The queue-length process has been mainly approximated by a diffusion process with either elementary return (ER) or reflecting barrier (RB) boundary condition. The ER has been introduced by Gelenbe while the RB by Gaver, Heyman, and Kobayashi. However, there is almost no literature to answer the question which boundary condition (ER or RB) will result in better accuracy (see [1]). These queue-length based diffusion approximations are no longer consistent with the exact result for the Poisson-input single-server (M/G/1) system.\r\nOur approach is different from the previous results, because by a diffusion process we do not approximate the queue-length but the unfinished-work process. However,the mean unfinished-work is not practical performance from a customer’s view point, while the mean queue-length leads to the mean waiting time by Little’s law. We note the stochastic relation between the mean unfinished-work and the mean waiting-time is necessary to derive the mean-delay formula in the single-server(G/G/1) system. The unfinished-work based diffusion approximation with ER or RB boundary condition is respectively shown to be consistent with the exact result for the Poisson-input single-server(M/G/1) system. We present a wide class of numerical examples to?answer the question which boundary condition leads to higher accuracy via computer simulations.\r\n\r\nReferences [1] A. Takahashi, Y. Takahashi, S. Kaneda, and N. Shinagawa, Diffusion approximations for the GI/G/c/K queue. Proc. the 16th IEEE International Conference on Computer and Communication Networks, pp. 681—686 (2007).\r\n", :title "A Further Remark on Diffusion Approximations with Elementary Return and Reflecting Barrier Boundaries", :keyword2 "Diffusion Process", :authors (26439 26485 25356 26546), :session 130}, 757 {:keyword1 "Simulation", :keyword3 "Hospital", :abstract "The main objective of this paper is to present a simulation model, using systems dynamics, to analyze different hospital logistic policies. The model allows an integrated analysis of how the management of different stock and capacities policies impacts the hospital attendance costs. The main factors of this process considered in the modeling are the medicine stock management and attendance capacity, defined as the specialized work source availability (physicians). Other important factors in this process were considered as capacity restrictions: hammock and equipments availability. In order to show the model suitability, the Emergency Room of Unicamp Clínicas Hospital case was studied. Different scenarios analyses were done combining stock policies, capacities and their costs. Using these results, integrated strategies of stock policies and capacities were proposed in order to reduce costs.", :title "Dynamics System Simulation in Hospital Logistics: Stock and Capacity Management ", :keyword2 "Logistics", :authors (26552 26551 26434), :session 44}, 758 {:keyword1 "Robust Optimization", :keyword3 "Data Mining", :abstract "CMARS is an alternative method to regression/classification tool MARS. It bases on a penalized residual sum of squares (Tikhonov regularization) and treats them by Conic Quadratic Programming (CQP). We improve CMARS so that it can imply uncertainty in the data in both output and input variables. Furthermore, the data may undergo small changes by variations in the optimal experimental design. Therefore, solutions of the optimization problem may present a remarkable sensitivity to perturbations in parameters of the problem. To overcome this difficulty, we refine our CMARS model and algorithm by a robust optimization technique proposed to deal with data uncertainty. Robust optimization is a modeling methodology to process optimization problems in which the data are uncertain and are only known to belong to some uncertainty set, except of outliers. Our robustification addresses polyhedral and ellipsoidal uncertainty. Because of the computational effort which our robustification of CMARS will easily need, we also present the concept of a weak robustification. We present both our new Robust CMARS (RCMARS) and its modification Weak Robust CMARS (WRCMARS) in theory, method and applied to real life problems, we discuss structural frontiers and give an outlook. ", :title "RCMARS - The New Robust CMARS Method", :keyword2 "Data Uncertainty", :authors (20485 3524 3616), :session 23}, 759 {:keyword1 "Complex dynamic system", :keyword3 "Efficiency estimation, optimisation", :abstract "Efficiency estimation problem for traffic process modes is considered. Railway field operation indices are computed.\r\nMathematical description of the traffic process is constructed. System component operation, component interaction, information processing are imitated.\r\nMathematical modeling system is introduced. Traffic process improvement tasks are stated and analyzed, new technologies and rail transit efficiency are estimated.\r\nThe imitating system is developed by the stages.\r\n1.Traffic process regularities and peculiarities are studied, problem is investigated, system development goals are generated, system main tasks are stated.\r\n2.Modeling principles are analyzed, model description language, construction methods are chosen, the nature and form of aggregate representation objects are standardized.\r\n3.Due to module modeling principle, complex of typical model component-aggregates reflecting traffic process characteristics, complex of constructive parameters reflecting legislative aspects are elaborated.\r\nThe model is to solve a wide range of traffic process improvement problems. Any traffic route with service stations of various types can be investigated.\r\nBesides, optimization problems for car traffic volume and work amount distribution among service stations with respect to their way and technical characteristics can be set. The reasonability and the cost-effectiveness of service station modernization is analyzed.\r\nVarious performance indices are calculated. On the base of such equipment operation efficiency indices as transit wagon turn-over and wagon transport capacity under standard and non-traditional technologies, it is possible to decide whether new technologies lead to transport time reduction.", :title "Imitating model of estimation the efficiency of the ways of traffic process transport time reduction", :keyword2 "Imitating modeling", :authors (19977), :session 166}, 766 {:keyword1 "Data Mining", :keyword3 "Business Analyst", :abstract "Acquiring new customers in any business is much more expensive than trying to keep the existing one. This becomes more challenging for customer-oriented organizations because of saturation and fierce competition in this market. Thus a business analyst shifted their focus from building a large customer base into keeping customers ‘in house’ (Defensive Marketing). Acquiring new customers is more expensive than retaining existing customers. Because of these reservations the need of step by step process to make sure the appropriate selection of dataset and model to guarantee the quality of forecasted result become more important. In this paper will use the best practices of data mining processes to model the whole problem. We will use standard data mining process CRISP-DM to structure customer churn prediction model. Discuss best variable selection techniques with reason relative to telecom industry. We will investigate the pros & cons of LOLIMOT and ADTreesLogit model to find out the appropriate one.  The idea is to provide detailed decision analysis for the decision makers and other stakeholders to give them better insight of their business for making strategic decisions. Data can be used from data warehouses, data marts or specialized data mining systems.", :title "Best Practices for Customer Churn Prediction", :keyword2 "Customer Churn Prediction", :authors (26555 21496), :session 231}, 770 {:keyword1 "Approximate Dynamic Programming", :keyword3 "Waiting Strategies", :abstract "We consider a dynamic vehicle routing problem with one vehicle and stochastic customer requests. Customer locations are known. Customers are divided into the two distinct sets of early requesting customers and late requesting customers. Early requesting customers definitely request for service, whereas late requests appear randomly over time according to individual request probabilities. Late requests must be either confirmed or rejected directly after becoming known. The goal is maximization of the expected number of requesting customers within a fixed period of time. Throughout this period of time the vehicle must move from a specified start depot to a specified end depot. This problem setting corresponds to the situation of a service provider (e.g. a less-than-truckload carrier) having one vehicle assigned to a geographical region in order to serve the different customers there.\r\nWe provide and compare a number of anticipatory approaches to the problem. In particular we consider two approaches based on Approximate Dynamic Programming and compare them to a number of waiting heuristics for the problem.", :title "Anticipatory optimization for routing a service vehicle with stochastic customer requests", :keyword2 "Dynamic Vehicle Routing", :authors (13264 12952), :session 227}, 771 {:keyword1 "Medical communication", :keyword3 "synchronization", :abstract "We developed a model for feedback loops in the exchange of information between a GP and a Patient. Feedback loops were constructed in that model, according to hypotheses about positive and negative feedback between the GP and a Patient. For the actors themselves we supposed entangled ‘inner’ feedback loops between the information task and related psycho-social and control processes. Those processes were modeled as limit to growth processes, that will say as non linear differential equations of logistic growth. In a number of simulation studies, using STELLA and Madonna, we proved at face value that this complex model fit patterns we found in video observations as it was put in SPSS data (Dijkum et al 2008). To explore the model in a more exact way we reprogrammed the model in Matlab as an extension of a model that was explored earlier by Savi (2007).  The leading question of our exploration is: is it possible to bring the task variable to an optimal state (for example a maximum) when GP and a Patient are in a state of (relative) chaos, by using processes of synchronization and coordination? Or a more weak question. Is it possible when one or more of the components (represented by basic logistic equations) of the system (in GP, or Patient, or in both actors) are in a state of chaos, to optimize goal variables in processes of synchronization and coordination?\r\n\r\nReference;\r\nDijkum, C. van, Verheul W., Lam N., Bensing J. (2008). Non Linear Models for the Feedback between GP and Patients. In Trappl R. (Ed). Cybernetics and Systems. Vienna: Austrian Society for Cybernetic Studies, pp. 629-634.  \r\nSavi M., (2007). Effects of randomness on chaos and order of coupled logistic maps. Physics Letters A, 364, pp 389–395.\r\n\r\n", :title "A complex model for the interaction between GP and Patient", :keyword2 "Complex model", :authors (18948 18947), :session 135}, 773 {:keyword1 "lot sizing", :keyword3 "service levels", :abstract "In the Wagner-Within-Problem – a simple example for dynamic lot sizing – all decisions can be made at once. Since the demand is deterministic, there is no need to delay the decisions on determining the lot sizes throughout the periods of the planning horizon.\r\n\r\nIn the stochastic case however, we can distinguish between two different types of planning situations for the decision maker. For both different models have to be used. \r\n\r\nThe first one is the situation where a setup and production pattern has to be fixed for a  predetermined planning horizon. Once the decision is made, there is no possibility to change it. The second one is a successive process, where the decision for setups and production is made at the beginning of each of the regarded time periods.\r\n\r\nAssuming the actual lot sizes are determined by a given service level, the first case can easily be solved by modifying the solution methods for the deterministic problem. In the second case however one has to consider that the realization of random demand changes the situation of the decision maker each period. Therefore a dynamic programming approach modeling this situation seems appropriate.\r\n\r\nWe examine a simple example to show the problems occurring when modeling a successive decision process with a fixed decision model. Furthermore we conduct a numerical study to compare both models on different kinds of experimental data sets, to get an idea how far the solutions with the more simple model are away from the ones of the more sophisticated model.", :title "Stochastic Dynamic Lot Sizing as Successive Decisions Process", :keyword2 "dynamic programming", :authors (26390 1131), :session 115}, 777 {:keyword1 "Dynamic prediction", :keyword3 "Model dependencies", :abstract "Our interest focuses on forecasting the total amount of individual income tax collected in the following year in a given macroeconomic scenario, which affects the inflation, the variation of employment and a modification of the tax rates. The government fixes this scenario every year at the time of setting a new Budget for the following year; therefore, the practical use of our proposal centres on this public budgeting context. We propose a forecasting procedure which (1) starts identifying the different sources of variability of the lump tax charge, (2) calculates several types of elasticities of this charge with respect to the variability sources mentioned above, and (3) uses a functional approach to predict or estimate the lump tax charges in the different particular scenarios mentioned above. The key point of our procedure requires distinguishing distinct types of elasticities, all with different meanings, which need to be clearly recognized and correctly calculated (by means of ad hoc decomposition techniques). Some of these elasticities define the so-called patterns of change, which are very stable throughout time. The remarkable prediction ability of our procedure leans on the stability of these patterns. This will be shown with an empirical evaluation of the procedure in a real life case study.", :title "Forecasting tax charges from elasticities and patterns of change: a case study", :keyword2 "Total, partial and Empirical elasticities", :authors (9182 9841), :session 230}, 778 {:keyword1 "Pricing", :keyword3 "Supply chain", :abstract "The present paper attempts to associate the profit maximizing pricing policy of a supply chain network with the standard problem of minimizing the cost of transporting and storing products, while satisfying end-point customers and to tackle them both simultaneously within an integrated framework.\r\nIn a nutshell, product price manipulation can be used to alleviate congested transportation routes, or to relieve heavily utilized inventory nodes, by altering appropriately the demand profile at the end-point nodes of the supply chain network. Essentially, a flexible node-level pricing policy can be understood as a substitute instrument to supply chain management, as it succeeds in altering the flow of orders customers place either by increasing or decreasing aggregate network demand for specific products, or by redirecting orders from one end-point node to others. As a result, the supply chain network does not have to reroute as strenuously inventories from one node to another to accommodate demand fluctuations, avoiding thus excessive costs due to clogged transportation routes and delays in deliveries. Instead, it finds preferable to persuade its customers, via the appropriate pricing policy, to redirect their orders to the desired end-point nodes.\r\nFor the time scale of interest, a discrete time difference model is developed, capable of analysing networks of arbitrary structure. To treat product demand uncertainty within a deterministic supply chain network model, a rolling horizon control approach is employed. A centralized optimization-based control strategy determines simultaneously the optimal product inventory, distribution and pricing policies for the maximization of network profits (gross of manufacturing costs) and satisfaction of service quality specifications.", :title "Pricing-cum-inventory decisions in supply chain networks", :keyword2 "Inventory", :authors (5054 26559), :session 94}, 781 {:keyword1 "Life insurance", :keyword3 "ANFIS", :abstract "Risk classification, which can be defined as categorizing insured risks according to their probability of generating claims and according to the size of those claims, is one of the most important topics in actuarial science. Traditionally, life insurance policyholders are classified by using classical mortality tables and generally according to limited number of risk characteristics, many other risk factors are ignored. Conventional clustering algorithms are organized in contemplation of the fact that objects are either in the set or not. However, the boundaries of each class are not always sharply defined. In these circumstances, fuzzy set methodology provides a convenient way for constructing a model that represents system more accurately since it allows integrating multiple fuzzy or non-fuzzy factors in the evaluation and classification of risks. The theory aims at modeling situations described in vague or imprecise terms, or situations that are too complex or ill-defined to be analyzed by conventional methods.   \r\n\r\nIn this paper, we propose ANFIS based system modeling for classifying risks in life insurance. We differentiate policyholders on the basis of their cardiovascular risk characteristics and estimate risk loading ratio to obtain gross premiums paid by the insured. In this context, an algorithm which expresses the relation between the dependent and independent variables by more than one model is proposed to use. Estimated values are obtained by using this algorithm, based on ANFIS.\r\n", :title "An Approach of Adaptive Network Based Fuzzy Inference System to Risk Classification in Life Insurance", :keyword2 "Risk classification", :authors (26560 26563 26565 25783), :session 230}, 782 {:keyword1 "multiobjective optimization", :keyword3 "applied sciences", :abstract "The field of distribution planning has been focused in research and applied sciences for several decades. But distribution networks have changed substantially over time. They have become larger and more complicated. Furthermore, the number of criteria for evaluating distribution networks has increased. Next to minimal costs, several other aspects as service level, eco-balance or robustness have evolved. In general, enterprises still tend to minimize their logistics costs, but also considering additional criteria. In this connection, the decision maker is interested in analysing the trade-offs between different criteria. For example, he wants to know which additional costs will occur, if the transportation network should achieve a given service-level.\r\nFor the strategic planning of a large-scale distribution network the model definition is commonly formulated as a p-median problem solved by approaches like DUALOC. Although these approaches may find good solutions for mono-criteria instances, they are not able to solve them in a multiobjective context. \r\nIn this paper an approach is presented for solving the multiobjective p-median problem sufficiently in context of applied sciences. For this purpose, a strategy based on the well known 1-interchange method has been adapted to an evolutionary multiobjective optimizer. These kind of optimizers focus on approximating the pareto-frontier, which describes the footprint of trade-offs between the evaluated criteria. Hence, this paper additionally describes in which way the results of a multiobjective p-median optimization can be analyzed and evaluated. This is illustrated with the help of a recent real world problem, which consists of planning a large-scale european distribution network considering multiple decision criteria. ", :title "Optimization Of Distribution Networks Under Multiple Decision Criteria", :keyword2 "distribution planning", :authors (16971), :session 210}, 785 {:keyword1 "clinical pathways", :keyword3 "", :abstract "Seit der Einführung des DRG-Systems (Diagnosis Related Groups) in 2003 besteht im deutschen Gesundheitswesen ein Anreizsystem, das sowohl eine hochwertige medizinische Versorgung als auch die Wirtschaftlichkeit von Krankenhausbetrieben gewährleisten soll. Bisherige Organisationsformen in Krankenhäusern konnten den DRG-Anforderungen bei der Planung nur teilweise gerecht werden.\r\nDie Planungsprobleme von Patientenpfaden in Krankenhäusern sind den Planungsproblemen von Prozessketten in der Produktionsplanung strukturell ähnlich. Dieser Artikel zeigt, wie Produktionsplanungswerkzeuge angepasst und erweitert werden können, um den stark multikriteriellen Zielsetzungen des Gesundheitswesens gerecht zu werden. Dabei werden die zurzeit vorwiegend zur Dokumentation verwendeten Behandlungsmuster so geplant, dass die Ressourcenauslastung erhöht und die Kosten gesenkt werden. Da der Patient im Gesundheitswesen im Mittelpunkt steht, müssen insbesondere individuelle Patientenziele wie z.B. möglichst kurze Wartezeiten, kurze Aufenthaltsdauern und die Einhaltung von Operationsterminen beachtet werden.\r\nIm Rahmen dieser Forschungsarbeit werden heuristische und exakte Verfahren erforscht, die die Qualität der medizinischen Versorgung durch eine optimale Auslastung der verfügbaren Ressourcen maximieren sowie die Kosten durch Einhalten von DRG-Vorgaben minimieren. Mit der Kenntnis des berechneten voraussichtlichen Patientenpfades aufgrund der Behandlungsmuster sowie der verfügbaren Kapazität der Leistungsstellen kann eine detaillierte Planung vorgenommen werden. Erste Ergebnisse zeigen, dass die Senkung von Kosten durch die Einhaltung der DRG-Vorgaben nicht den individuellen Zielen der Patienten widerspricht.", :title "Multikriterielle Planung von Behandlungspfaden", :keyword2 "", :authors (26566), :session 137}, 787 {:keyword1 "Nonlinear dimensionality reduction", :keyword3 "Classification", :abstract "Nonlinear dimensionality reduction techniques based on manifold learning, aimed at unveiling a low dimensional manifold along which data lie, have shown great potential in visualization and classification of high dimensional datasets. However, most of these methods are negatively affected by the presence of outliers, and this pitfall may prevent their application to noisy data.\r\nIn this paper we propose a variant of isometric mapping (Isomap) aimed at being more robust to noise and outliers when used for classification. In particular, we apply a preliminary coordinate projection aimed at emphasizing the distances among points, in order to avoid the concentration of the Euclidean distance between points in high dimensional spaces which has been observed both theoretically and empirically. Furthermore, in our method the neighborhood graph approximating the manifold is generated by an efficient combination of an approximate k-nearest neighbor method and a minimum spanning tree problem.\r\nComputational experiments show that the new method performs better in terms of classification accuracy on several benchmark high dimensional datasets.", :title "Nonlinear dimensionality reduction through an improved Isomap algorithm for the classification of large datasets", :keyword2 "Isometric mapping", :authors (18385 26568 4747), :session 78}, 794 {:keyword1 "transportation procurement auction", :keyword3 "branch-and-bound based path-relinking", :abstract "The procurement of transportation services via large-scale combinatorial auctions involves a couple of complex decisions whose outcome highly influences the economic effectiveness and efficiency of the tender process. The aim of our work is to support a shipper during the assignment of transportation contracts to adequately qualified carriers. For that purpose we propose a bi-objective winner determination model and a solution procedure which hybridizes a metaheuristic with an exact solution approach.\r\n\r\nFirst, a bi-objective winner determination problem is described which is based on the well-known set covering problem. The model supports bundle-bidding to account for valuation interdependencies between transportation orders. Furthermore, it jointly considers the objectives of minimizing the total procurement costs and maximizing the quality of the procured services. The model helps a shipper to decide which subset of the submitted bids he should accept.\r\n\r\nTo solve the bi-objective winner determination problem, a novel solution method based on GRASP with hybrid Path-Relinking is introduced. The search applies the Pareto dominance principle, accordingly, the aim is not to identify a single best solution depending on the shippers preferences (which anyway are often hard to elicit); instead the proposed procedure heuristically searches for the whole set of preference-independent non-dominated solutions. This is done via GRASP. A hybrid path-relinking procedure which applies a problem-specific epsilon-constraint branch-and-bound method is used for post-optimization. The performance of the proposed Pareto solver is compared to a previously published genetic algorithm by means of numerical benchmark tests.\r\n", :title "Hybridizing Path-Relinking with Branch-and-Bound for Carrier Selection in Transportation Procurement Auctions", :keyword2 "multicriteria winner determination problem", :authors (11448 1109), :session 209}, 795 {:keyword1 "Emission Trade System", :keyword3 "linear programming", :abstract "In order to counteract anthropogenic climate change the United Nations Framework Convention on Climate Change (UNFCCC), the European Union and national political decision makers use a package of different environmental policy instruments. This study focuses on the European Emission Trade System (ETS) introduced in 2005, since in contrast to other regulatory instruments it remains relatively untested in so far as it fulfills the OECD criteria for “ecological effectiveness and economic efficiency”. Due to different mechanism the research results of other instruments (e.g. legal requirements, subsidies or taxes) cannot easily be transferred. This econometric study employs a contribution margin accounting and production functions of the available power generation technologies as well as combined heat and power installations in Germany to estimate the short-term impact of the ETS. Because of the inherent uncertainty of the price of emission allowances and the switch load effect we use a sensitivity analysis in our linear programming problem. The annual carbon emissions and the emission costs per output unit are investigated as a function of the allowance price within the data set of the German energy sector.", :title "Estimating the short-term impact of the European Emission Trade System on the German energy sector", :keyword2 "econometric study ", :authors (26412), :session 134}, 798 {:keyword1 "Dimensional optimization", :keyword3 "Reuse of leftovers", :abstract "Enterprises that work with bars from aluminum have, like one of the alternatives to reduce his costs, the optimization of the cut of materials. This is a type of problem classified like problem of cut and package. In case of bars from aluminum, like only the length it is considered, it is characterized like problem one-dimensional. This problem consists, theoretically, in formulating a standard of cut that, from the stocked objects, manages less items according to the demand, producing the least possible number of losses. In this work small and middle demands were treated, where differential is proposed, besides the minimization of the losses, competitively of re-using the leftovers. To differentiate what they are losses and what they are you are left, there was opted to formulate a mathematical model that uses the historical of the items that were demanded in the last months and the relative accrued frequency of each belt of size. In the process of optimization a model was developed, where from different algorithms of exhaustive repetition, which basically consist of adaptations of the heurístic FFD, possible standards of cut are produced and those are subjected to an evolutionary strategy, considering the number of losses, leftovers and of whole used bars. For realization of the tests one used real data of enterprises of the branch glazier. On basis of the results of the fulfilled tests one checked that the initial solution already presents results better than them at present checked and, after the evolutive process the solutions are still better. In this way the developed proceeding appeared robust and ready to be collected to the software ECG ® already used by several enterprises.", :title "OPTIMIZATION ONE-DIMENSIONAL BAR ALUMINUM", :keyword2 "Standard cut", :authors (26572 15579), :session 23}, 799 {:keyword1 "Approximate dynamic programming", :keyword3 "", :abstract "We introduce a price-directed dynamic policy for the well-known economic lot scheduling problem with sequence dependent setup times and costs, which is based on approximate dynamic programming. Since in the underlying Semi-Markov decision process, the set of feasible actions is neither convex nor closed, we suggest a dynamic approximation of this set and test the policy in numerical examples.", :title "An approximate dynamic programming policy for the economic lot scheduling problem", :keyword2 "economic lot scheduling", :authors (25676 26574), :session 245}, 804 {:keyword1 "bucket brigades", :keyword3 "dynamics of production systems", :abstract "A bucket brigade is a production line in which each worker processes an item through a sequence of stations until the worker encounters his successor, and hands over the item for further processing. The reset is initiated when the last worker reaches the end of the production line; he then walks back with infinite velocity to take over the job of the predecessor, initiating a chain reaction until the first worker starts production on a new item. The term bucket brigade was coined by Bartholdi and Eisenstein (1996) who showed that by ordering the workers from slowest to fastest, a stable partition that maximizes throughput emerges.  Most of the previous work on bucket brigades allows handovers to occur at any point throughout the production line. In this study, we restrict handovers to occur only at station endpoints. This restriction creates the possibility of different reset protocols. We define two distinct handover protocols: synchronous and asynchronous handovers.\r\nUnder the synchronous handover protocol, once the last worker reaches the end of the production line, he waits until all upstream workers reach the end of their stations. Once all workers are at station endpoints, the line reset takes place. Under the asynchronous protocol, once the last worker reaches the end of the line, he walks back to the station the predecessor is located at. Once the predecessor meets the last worker, a handover occurs, and the predecessor walks to take over the job in a cascading manner. We provide an analysis of the behavior of the bucket brigade under both protocols and a comparison of the performance of each protocol. In particular we find that possible dynamics include globally stable fixed points and periodic orbits, as well as locally stable fixed points and periodic orbits.", :title "Bucket brigade handover protocols in the presence of discrete workstations", :keyword2 "dynamical analysis", :authors (26575 852 26576), :session 158}, 809 {:keyword1 "Revenue management", :keyword3 "Bundles", :abstract "In S&E, one of the most important market segmentations is that some customers buy season packages, or bundles of tickets to events during the season, while others buy individual tickets to events. Most S&E firms offer season tickets first, and they open purchasing for single tickets at a later date but before the start of the season. A sequential product offering with season tickets sold exclusively first allows the firm to sell the highest quality seats to season ticket purchasers, thereby encouraging commitment\r\nto entire bundles to ensure good seats. In some cases, the switching date is announced in advance, but in many other cases the date is announced after the start of the selling season. A key reason for this is simple: the organization can adapt the switching time to single tickets according to the realization of demand and improve overall profit. The uncertainty in the sales date for single tickets can also encourage customers to buy season tickets to ensure they are able to attend popular events or obtain good seats. \r\n\r\nWe studied an earlier version of this problem where limited venue capacity can be sold as either bundled or single tickets. In this paper, we developed the basic problem to a version with two switching times where early switch to low-demand game is allowed. That is, we start selling bundle tickets, at the first switch time we start selling the low demand game tickets individually along with the bundle tickets and at the second switch we start selling the high demand game tickets along with the low demand game tickets. We find that the structure of the problem leads to an optimal timing policy that is relatively easy to understand and implement. The resulting policy is defined by a set of threshold pairs of times and remaining inventory.\r\n", :title "Dynamic Switching Times from Season to Single Tickets with an Early Switch Option to Low Demand Tickets in Sports and Entertainment Industry", :keyword2 "Stochastic Models", :authors (23543 26584), :session 94}, 810 {:keyword1 "seasonal flight scheduling", :keyword3 "airline operation", :abstract "Seasonal flight scheduling is a multi-stage planning process by using historical seasonal flight plans, which on adjusted to the actual market situation and basic conditions. The goal is to maximize airline benefit under certain operational constraints. The main idea of our basic approach is a dynamic combination of airline flight schedule work-flow with forecast of passenger demand. The concept works like iterative optimization process and find more realistic seasonal flight schedule solutions.", :title "Increase benefit of seasonal flight scheduling by using linear optimization and forecast of passenger demand", :keyword2 "linear optimization", :authors (18528 14909), :session 206}, 812 {:keyword1 "generalized lot-sizing and scheduling", :keyword3 "threshold accepting", :abstract "We present a master planning model for the production of incontinence slips, which bases on the General Lot-sizing and Scheduling Problem (GLSP). Apart from sequence-dependent lot-sizing, this model includes several practice-relevant features such as time-dependent production coefficients. We outline a model-based solution procedure combining threshold accepting with dual reoptimization. Numerical tests show that this local search heuristic yields promising solutions for real-word planning problems after a reasonale amount of computing time.", :title "Using the GLSP for Master Planning in a real-world case from the health-care industry ", :keyword2 "production planning", :authors (14869 2448 26583), :session 113}, 813 {:keyword1 "Generalized Partial Linear Models", :keyword3 "CMARS", :abstract "In our study, we analyzed Generalized Partial Linear Models (GPLMs), which decomposes input variables into two sets and additively combines classical linear models with nonlinear model part. We aim to smooth this nonparametric part by using a modified form of MARS. The MARS algorithm has two steps: the forward and backward stepwise. In the first one, the model is built by adding basis functions until a maximum level of complexity is reached. In the backward stepwise algorithm, it starts with removing the least significant basis functions from the model. Here, we propose to use a penalized residual sum of squares (PRSS) instead of the backward stepwise algorithm and construct PRSS for MARS as a Tikhonov regularization (TR) problem. Moreover, we treat this problem using continuous optimization technique Conic Quadratic Programming (CQP); this recently developed method is called as CMARS. Then, we compare these two methods at different parameter values for two different data sets; with and without interaction. We observe that Tikhonov solver gives better results than CPQ at initial points while CQP is better at last points for both data sets. Actually, they give almost the same results at initial TR and at last CQP parameters. As well, they are approximately equal at last TR and at initial CQP parameter values. We think that this can be due to the fact that CQP uses interior point while Tikhonov uses exterior point method. Moreover, we also compared the two methods at corner points and observe that they are approximately equal for both data sets. However, for the data without interaction Tikhonov gives slightly better results, while CMARS is slightly better for the data with interaction as we expect. Our presentation concludes with an outlook on future research.     ", :title "Parameter Estimation in Generalized Partial Linear Models with Tikhonov Regularization and Conic Quadratic Programming", :keyword2 "Tikhonov Regularization", :authors (26578 3524 5344), :session 29}, 815 {:keyword1 "debt restructuring", :keyword3 "", :abstract "This paper examines optimal debt reorganization strategies in the presence of agency problems arising from asymmetric information between a firm and a bank during financial distress. In particular, in the structural model, we incorporate complete verification strategies for private information that the firm holds under asymmetric information. We show that under complete verification strategies, the agency conflict because of asymmetric information delays the debt reorganization, leading to a decrease in equity and debt values. These results fits well with the findings of previous empirical works in this area. ", :title "Debt restructuring timing during financial distress under asymmetric information", :keyword2 "asymmetric information", :authors (2266 26588), :session 98}, 818 {:keyword1 "information overload", :keyword3 "controlling", :abstract "Information overload may lead to a drastic deterioration of the quality of manager decisions, entailing considerable financial consequences. In this paper, we intend to show the determinants that are responsible for an information overload and to which extent such determinants can be influenced by the controller. In a laboratory experiment with 135 professionals experienced in making decisions we succeeded in proofing the existence and relevance of information overload in the context of an investment decision, and to identify the Quantity of information as the specific major factor of influence. Apart from an effective operative parameter for the containment of overload effects in the context of investment decisions, we also provide a corridor in the view of an \"optimal” quantitative reporting design.   ", :title "Volume-induced information overload in reporting– the quantitative report volume as an operative parameter for the controller ", :keyword2 "experiment", :authors (26585 26589), :session 193}, 824 {:keyword1 "Multi-objective optimization", :keyword3 "genetic algorithm", :abstract "When modeling an activated sludge (AS) system of a wastewater treatment plant (WWTP), several conflicting objectives may arise. The proposed formulation is a highly constrained bi-objective problem where the minimization of the investment and operation costs and the maximization of the quality of the effluent are simultaneously optimized. These two conflicting objectives give rise to a set of Pareto optimal solutions, reflecting different compromises between the objectives. Population based algorithms are particularly suitable to tackle multi-objective problems since they can, in principle, find multiple widely different approximations to the Pareto-optimal solutions in a single run. In this work, the formulated problem is solved through an elitist multi-objective genetic algorithm coupled with a constrained tournament technique. Several trade-offs between objectives are obtained through the optimization process. The direct visualization of the trade-offs through a Pareto curve assists the decision maker in the selection of crucial design and operation variables. The experimental results are promising, with physical meaning and highlight the advantages of using a multi-objective approach.", :title "USING A GENETIC ALGORITHM TO SOLVE A BI-OBJECTIVE WWTP PROCESS OPTIMIZATION", :keyword2 "WWTP - activated sludge system", :authors (9758 17049 1769 26591), :session 106}, 829 {:keyword1 "Model generation", :keyword3 "Coherent Bayesian inference", :abstract "Let us investigate an algorithm of regression model construction. The constructed model will be used to solve problems of the Financial Sector: it might be a scoring model, an energy price forecasting model or a European option volatility smile model. We suppose that given historical data are not sufficient to discover hidden dependencies in an investigated problem. So we propose the following approach to the model construction. Together with historical data we use expert-given set of primitive functions. It is recommended to collect functions, which already widely used to model the investigated problem. Then we assign a generating function, which will be used to generate the set of the competitive models. We estimate evidence of the models using coherent Bayesian inference and select a model of the best structure. Since generating functions make a countable set of models, we organize an iterative generation-selection procedure.\r\nEach cycle of the procedure include the following steps. First, we modify competitive models so that the structural distance between an original and a derivative model will as minimal as possible. Second, we estimate parameters and hyperparameters of the derivative model to cut-off some model modifications at the following steps and reduce the algorithm complexity. Third, we analyze the evidence of the derivative model to find the probability to become it a model of the optimal structure. Also, we analyze some restrictions applied to the model structure and robustness of the model.\r\nAs the result we obtain a model, interpretable from the expert’s point-of view; if fits historical data well and robust. Additional tests are applied to verify the result model: cross-validation and retrospective forecasting to ensure quality of the further use.", :title "Evidence of successively generated models", :keyword2 "Model selection", :authors (19525), :session 86}, 831 {:keyword1 "Agent based simulation", :keyword3 "complex systems behaviour", :abstract "In this work a complex dynamic economic model has been studied using agent based simulation. The actors are many firms and some banks, specified through financial objects like balance sheet, costs, etc. The related agents cooperate and compete in one economic world driven by global market rules and by their specific individual base strategies. \r\n\r\nThe different strategies gives a specific behavior for the economic trades and deals between the players acting in their business. \r\n\r\nInteraction was simulated randomly. The results of these economic actions are influencing actors vitality (possible down to bankruptcy) and system stability. \r\n\r\nThe system can be driven by outer variables, modeled by system dynamics cause-effect-chains, and global outer behavior like economic cycles up to crises and shocks. \r\n\r\nThe results give hints for dynamic risk management through compliance structures and regulations (limitations, as the simplest example) in complex dynamic global economy to lead to robust system and individual behavior. \r\n", :title "Agent based simulation for dynamic risk management", :keyword2 "dynamic risk management", :authors (15381 26596), :session 166}, 832 {:keyword1 "q-derivative", :keyword3 "q-steepest descent method", :abstract "In the beginning of nineteenth century, Frank Hilton Jackson generalized the concepts of derivative in the q-calculus context and created the q-derivative, widely known as Jackson's derivative. In the q-derivative, instead of the independent variable be shifted by a positive value close to zero, it is multiplied by a parameter q and in the limit, when q tends to 1, the q-derivative is reduced to the usual derivative. In this work we make use of the first-order partial q-derivatives of a function of n variables to define here the q-gradient vector and take the negative direction as a new search direction of optimization methods. Therefore, we present a q-version of the classical steepest descent method called the q-steepest descent method, that is reduced to the classical version whenever the parameter q is equal to 1. We applied the classical steepest descent method and the q-steepest descent method to an unimodal and a multimodal test function. The results show the great performance of the q-steepest descent method, and for the multimodal function it was able to escape from local minima and reach the global minimum.", :title "The q-steepest descent method for unconstrained functions", :keyword2 "q-gradient", :authors (25742 25812 14267), :session 100}, 834 {:keyword1 "feature selection", :keyword3 "kernel methods", :abstract "Single nucleotide polymorphisms (SNPs) are DNA sequence variations that occur when a single nucleotide (A,T,C,or G) in the genome sequence is altered. The number of SNPs on the human genome is estimated at more than 11 million. SNPs and other less common sequence variants are the ultimate basis for genetic differences among individuals, and thus the basis for most genetic contributions to disease. However, the huge number of SNPs makes it neither practical nor feasible to obtain and analyze the information of all the SNPs on the human genome. Thus, selecting a subset of SNPs that is informative and small enough to conduct association studies and reduce the experimental and analysis overhead has become an important step toward effective disease-gene association studies.\r\n \r\nIn this study, we developed methods for selecting optimal SNP subsets for greater association with complex disease by making use of newly developed methods in machine learning, like infinite kernel learning.  We constructed an integrated system that makes use of major SNP databases and that integrates functional effects of SNPs alongside with pathway data to gain insights for understanding the complex web of SNPs and gene interactions and integrate as much as possible of the molecular level data relevant to the mechanisms that link genetic variation and disease. We tested the validity and accuracy of developed model by applying it to various data sets for different diseases and got promising results. We hope that results of this study will support timely diagnosis, personalized treatments, and targeted drug design, through facilitating reliable identi?cation of SNPs that are involved in the etiology of complex diseases.\r\n", :title "ANALYSIS OF SNP-COMPLEX DISEASE ASSOCIATION BY A NOVEL FEATURE SELECTION METHOD", :keyword2 "single nucleotide polymorphism", :authors (24325 11028 3524), :session 231}, 835 {:keyword1 "Routing", :keyword3 "Lower bound", :abstract "The Vehicle Routing Problem with Conflicts (VRPC) is a new problem for which only few algorithms have been developed. This variant of the classical VRP concerns the sectors where the transported materials may be incompatible, such as in Hazardous Material transportation. The conflicting items have to be transported in different vehicles. In previous works, three adapted constructive heuristics, a new heuristic based on the hazardous materials properties, an Iterated Local Search and a hybrid GRASP-ELS were developed to approximately solve the problem. This paper presents a lower bound on the routing cost.\r\nA branch-and-cut algorithm is proposed for this problem. It consists in an adaptation of the known branch-and-cut algorithm developed by Lysgaard et al. in 2004 for the classical VRP. The objective of the development of this approach is to estimate the quality of the solutions found by the metaheuristics by computing an effective lower bound. \r\nThe method resolves a compact formulation of the initial integer linear program as a sequence of linear programs. At first, certain constraints are relaxed, in particular the integrity and capacity constraints. This generally gives an extremely weak lower bound, which can be then strengthened by adding cutting planes. To generate these cutting planes, separation algorithms are needed, such as capacity inequalities, comb inequalities and multi-stars inequalities.\r\nIn order to strengthen the capacity inequalities, the compatibilities between items are partially taken into account. For this purpose, the lower bound developed by Gendreau et al. in 2004  for the bin Paching with conflicts is integrated in our Branch and  Cut. The main aim is to improve the lower bound on the number of needed vehicles.", :title "A lower bound for the Vehicle Routing Problem with Conflicts", :keyword2 "Conflicts", :authors (23097 22934 23689), :session 178}, 836 {:keyword1 "Regression", :keyword3 "Continuous Optimization", :abstract "The outlier detection problems is a very important problem in statistics. Because, outliers observation affects estimation and inference as negatively. There are several outliers detection methods. One of these methods is given by Mean Shift Outlier model. In our study we consider Mean Shift Outlier model and construct Tikhonov Regularization problem for it. Then, we approach solving this problem using continuous optimization techniques, in particular, by the elegant framework of conic quadratic programming which will become an important complementary technology and alternative to the outliers detection methods.", :title "A New Contribution to  Mean Shift Outlier Model with Continuous Optimization", :keyword2 "Mean Shift Outlier model ", :authors (10957 3524 22442), :session 29}, 838 {:keyword1 "Workforce allocation", :keyword3 "Team Building", :abstract "In a big IT organization, building an effective software project team has been a challenging task. Imperfect allocation and improper assessment of employee’s skills set causes: delay in the project schedule, members leaving the project and hence increase in overall project cost. In this paper, we have addressed the multi attribute people allocation problem and proposed a novel approach of Team Staffing Index (TSI) to bridge the gap between the expertise needed from a team and the allocated team, for a given project. At the start of the project, Project Manager (PM) prepares a complete estimate of the varied skill-sets people required at different phases of the project and sends it to the Human Resource (HR) manager. These estimates are exaggerated and also there is a difference between the skills expertise rated by an associate and the expertise perceived by the Project Manager. The HR manager does the final allocation. To address these issues, we have built an Allocation module for HR and a Consulting module for PM in MS Excel using VBA, which makes it easy to use and share. The allocation problem has been formulated similar to an assignment problem and solved using linear programming. The various attributes such as multiple skill set, location preferences, etc are considered. Each attribute is assigned with weights, which is governed by the company’s allocation policies. Accordingly, we suggest different teams, back-up plans against each requirement and cost justification for every allocation. Using analysis of the successful and unsuccessful projects, we arrive at the TSI of the expected team and check it against the TSI of the allocated team. If there is a gap in the TSI, we make internal hiring and transfer recommendations to the project manager. ", :title "A novel approach to team formation for software projects", :keyword2 "Linear Programming", :authors (15665 26598), :session 147}, 842 {:keyword1 "stochastic programming", :keyword3 "Mobile ad-hoc networks", :abstract "We propose a two-stage stochastic second-order  cone programming formulation (see Maggioni et al. 2009) of the semi-definite stochastic location-aided routing (SLAR) model, described in Ariyawansa and Zhu (2006). The aim is to provide a sender node S, with an algorithm for optimally determining a region that is expected to contain a destination node D (the expected zone). The movements of the destination node are represented by ellipsoid scenarios, randomly generated by uniform and normal distributions in a neighborhood of the starting position of the destination node. By using a second-order cone model, we are able to solve problems with a much larger number of scenarios (20250) than it is possible with the semi-definite model (500). The use of a large number of scenarios, allows for the computation of a new expected zone, that may be very effective in practical applications, and  for obtaining performance measures for the optimal cost function values.  \r\nProperties of the stochastic expected zone inherited from the derministic solution is discussed and sensitivity analysis on VSS and EVPI against the latency penalty to reveal the stochasticity of the problem is included.\r\n\r\nREFERENCES\r\nMaggioni, F., Potra, F., and Bertocchi, M., Stochastic second order cone programming  in mobile ad-hoc networks, JOTA ,143/2, Nov., pp. 309-328, 2009.\r\n\r\nAriyawansa, K.A., and Zhu, Y., Stochastic semidefinite programming: a new paradigm for stochastic optimization, 4OR, A Quarterly Journal of Operations Research, 4/3, pp. 239-253, 2006.\r\n", :title "STOCHASTIC SECOND-ORDER CONE PROGRAMMING IN MOBILE AD HOC NETWORKS", :keyword2 "second order cone", :authors (24015 8459 23456 9925), :session 70}, 846 {:keyword1 "pricing scheme", :keyword3 "resource management", :abstract "In this paper, we develop optimal resource pricing schemes and job scheduling mechanisms for applications which can access and react to pricing. The objective is to ensure high resource utilization and to minimize the cost of completing a job subject to time constraints (i.e. the overall job must be finished by given time). The solutions are developed by combinatorial optimization, and by quadratic programming methods and can be applied to numerous fields, such as processor scheduling, QoS services in telecommunication networks, business scheduling …etc. Simulation results demonstrate that the novel approach can outperform the traditional solutions.\r\n\r\nIn the approach presented by the paper, each task is partitioned into “sub-tasks” represented by a vector. The components of these vectors identify the job distribution of the associated task, while the maximum  lengths of these vectors represent the constraints imposed upon the completion time. Since each task is then characterized by a corresponding vector, we search for the optimal matrix (constructed form these vectors) which minimize the cost under a given pricing scheme. Optimal job scheduling is then broken down to a discrete quadratic optimization problem and the optimum is sought by a Hopfield net in polynomial time. This enables real-time job scheduling and cost minimization. \r\n", :title "Optimal pricing based resource management", :keyword2 "scheduling algorithms", :authors (26553 23121 26595 26608), :session 148}, 847 {:keyword1 "stable marriage ", :keyword3 "equilibrium", :abstract "This paper deals with a strategic issue in the stable marriage model with complete preference lists. It is well-known that if we use men-proposing Gale-Shapley algorithm, there are cases in which a woman can obtain a better partner by falsifying her preference. We discuss algorithmic aspects of the strategic possibilities for the women.\r\n\t\r\nGiven (true) preference lists of men and women, we introduce a game among women. In a play of the game, each woman choose a strategy which corresponds to a complete preference list over men. The resulting payoff of a woman is her mate determined by men-proposing Gale-Shapley algorithm executed on men's (true) preference lists and women's joint strategy. We propose a  polynomial time algorithm for checking whether a given marriage is an equilibrium outcome or not. ", :title "Algorithmic Aspects of Equilibria of Stable Marriage Model with Complete Preference Lists", :keyword2 "Gale-Shapley algorithm", :authors (13201), :session 194}, 850 {:keyword1 "Exact penalty method", :keyword3 "Structured Hessian", :abstract "We present a new structured algorithm for solving constrained\r\nnonlinear least squares problems. The approach is based on an adaptive structured scheme due to Mahdavi-Amiri and Bartels of the exact penalty method of Coleman and Conn for nonlinearly constrained optimization problems. The structured adaptation also makes use of the ideas of Nocedal and Overton for handling quasi-Newton updates of projected Hessians. We provide comparative results of the testing of our programs and three nonlinear programming codes from KNITRO on test problems (both small and large residual) from Hock and Schittkowski and some randomly generated ones due to Bartels and Mahdavi-Amiri, showing the practical relevance of our special considerations for the inherent structure of the least squares. ", :title "New Projected Structured Hessian Updating Schemes for Constrained Nonlinear Least Squares Problems", :keyword2 "Nonlinear least squares", :authors (26323 26330), :session 105}, 851 {:keyword1 "eneralized Stochastic  Petri Net", :keyword3 "tokens scheduling policies", :abstract "The Stochastic Petri Nets formalism and its generalizations (e.g. Generalized SPN - GSPN, Stochastic Well-Formed Nets - SWN) are powerful languages for the specification of  stochastic processes (Continuous Time Markov Chains - CTMC).\r\nThe model state in these models is described  in a distributed way as the number of tokens in each place while transitions represent \r\nthe causes of possible state changes. If the tokens are statistically identical (as in GSPNs), the choice of the token that a transition removes from its input place(s) upon firing is irrelevant when average performance indices are computed, while it is important when the tagged token technique is used to compute the first passage time distribution.\r\n\r\nThe introduction of colored tokens makes the formalism more parametric, and leads to more compact models. However it also leads to hiding part of the model structure, including choice points and conflicts. For this reasons the extraction order of colored tokens from places may have a relevant impact on (average) performance indices, the modeler should thus be careful in considering this aspect.\r\n\r\nIn SWNs the color structure is such that behavioral symmetries can be easily detected and exploited to reduce the state space size (by expressing the state in a more abstract form); the same (average) performance measures can be computed on the reduced state space (which in some cases can be of the same size as that of the model without colors).\r\n\r\nIn this paper, the sensitivity of some (locally) symmetric SWN models to tokens scheduling policies is investigated. In conclusion, an extension of SWNs in the direction of the Queueing Petri Nets formalism is proposed, and its impact on the possibility of still exploiting behavioral symmetries is discussed.", :title "On the importance of token scheduling policies in Stochastic Petri nets", :keyword2 "Stochastic Well-formed Net", :authors (26540 26604 26541 26605), :session 131}, 853 {:keyword1 "sevice systems", :keyword3 "transient approximation", :abstract "This presentation proposes an approach for the time-dependent analysis of stochastic and non-stationary queueing systems with retrials. Many customer service systems have to scope with impatient customers, for example call centers, check-in counters at airports, or services like automated teller machines. For examples in call centers, impatient customers leave the queue before receiving service dependent on the behavior of the customers and the current or expected waiting time. A fraction of those customers retry again later on. The feature of retrials is often found in combination with a non-stationary behavior of the system. This can be due a transient phase after the start of the system or time-dependent capacities, for\r\nexamples varying number of staff or breakdowns of the system. Especially in service system the customer demand varies highly over the time. We model such systems as an M(t)/M/c(t)+M queue with exponentially distributed inter-arrival times, processing times, and patience.  \r\n\r\nThe main contribution of this paper is the development of a new approximation method for the M(t)/M/c(t)+M queueing model with retrials. We describe the main idea of the stationary backlog carryover (SBC) approach and show how it could be extended to scope with impatient customers. Because of the lack of stationary closed form solutions for retrial systems we show that retrials could be integrated as additional carryovers. A numerical study shows the reliability of this approach.\r\n", :title "Approximation of transient performance measures of service systems with retrials", :keyword2 "retrial queues", :authors (10255), :session 159}, 854 {:keyword1 "Cross-cultural education", :keyword3 "Analytic Hierarchy Process", :abstract "The phenomenon of cross-culture in the plural school (European Commission, 2008; Council of Europe, 2008) is of great importance in the contemporary societies, which are undergoing deep changing, because of globalisation processes and International migrations (Featherstone, 1996; 1998; Bauman, 1998; 2000; Portes & Rumbaut, 2005; Sassen, 2007; Castles, 2009).\r\nThe characterizing trait of such societies is their multi-cultural and multi-ethnic dimension.\r\nCross-culture is very complex and it can be only partially handled with the use of particular techniques of the operative research.\r\nThe techniques used in this research are:\r\n-\tthe Analytic Hierarchy Process (AHP), for the division of a complex objective in sub-objectives, sub-sub-objectives, etc., in a hierarchical structure, assessment of scores, and ranking of alternative strategies (Saaty, 1980; Saaty & Peniwati, 2007; Saaty, 2008);\r\n-\tstatistic analysis made up of questionnaires administered to a high number of preadolescents attending the second and third year of first degree secondary school in Abruzzo (Italy) (1314 students, of which 881 Italians, 317 foreigners and 116 children of mixed couples), and research of the latent structures of phenomenon.\r\nThe fundamental tools used for the interpretation of the results of the questionnaires, and the treatment of the uncertainty are the subjective probability, the multivariate statistics, and the fuzzy logic and algebraic structures.\r\n", :title "Formalization of Models for the Analysis of the Phenomenon of Cross-Culture in a Multi-Ethnic Scholastic Environment", :keyword2 "Fuzzy sets and numbers", :authors (20942 20933), :session 28}, 855 {:keyword1 "open vehicle routing problem", :keyword3 "meta-heuristics", :abstract "This study presents an electromagnetism-like algorithm (EMA) for solving the open vehicle routing problem (OVRP) which is an important variant of the capacitated vehicle routing problem (CVRP). OVRP aims to design minimum cost tours starting from depot and satisfying the customer needs while using homogeneous fleet of non-depot returning vehicles. The cost is generally determined by the number of vehicles and distance traveled. Electromagnetism-like Algorithm is a population-based meta-heuristic, based on attraction-repulsion mechanisms between charged particles in a multi-dimensional (particle) space. Proposed algorithm is tested on several benchmark problems taken form literature. Computational results show that EMA is comparable in terms of solution quality to published algorithms.", :title "Solving the Open Vehicle Problem via Electromagnetism-like Algorithm", :keyword2 "electromagnetism-like algorithm", :authors (15322 15313), :session 196}, 856 {:keyword1 "Bayesian networks", :keyword3 "Uncertain Reasoning", :abstract "Most of the systems for automatic decision making are intended to detect a single optimal decision irrespectively of the available information. This is perfectly suited for many applications. Yet, there are situations characterised by little or contradictory information available and for which the cost and the consequences of a wrong decision are very important. In those cases, it would be preferable to suspend any judgement and emphasise a condition of indecision between two or more options.\r\n\r\nThis paper presents credal networks as a well suited formalism for this kind of military decision making. Credal Networks are probabilistic graphical models, whose quantification does not force the experts to choose precise numerical values for the probabilities at stake.\r\nQualitative or incomplete judgements, as well as interval-value estimates of the probabilities can be used in order to provide a more realistic modelling of the expert's knowledge.\r\n\r\nThe main features of this approach are outlined by the means of a credal Network which performs a risk analysis in the case of intrusions in a restricted-flight area. We describe how different decision-making criteria can be implemented in this framework, and how it is possible to identify which factors are related on a particular decision (or indecision) delivered by the system.\r\n\r\n", :title "Making and explaining military decisions by credal networks", :keyword2 "Imprecise Probabilities", :authors (26452 26609), :session 225}, 857 {:keyword1 "service", :keyword3 "partitioning", :abstract "Modularisation of services obtains increasing attention in service research; especially the contrast between individualisation and standardisation is discussed. Thereby the methodical fundamentals of modularization are rarely\r\ndescribed and special requirements of services are often neglected. In context of work-sharing service processes the coordination of modules and sub-processes acquires great importance.\r\n\r\nVarious procedures have been suggested to design modular services. Our work focuses on quantitative approaches, applying Design Structure Matrices (DSM) to represent service processes and dependencies of their sub-processes. On the basis of DSM, partitioning algorithms can be utilized to identify modules. A technique, which is often used is the approach described by D. V. Steward (Steward, 1981, pp. 40), involving a generic partitioning heuristic and the tearing of the resulting blocks. However the performance of this approach has not been examined in adequate detail.\r\n\r\nOur contribution aims at a test-based comparison of Steward’s heuristic. To compute an optimal solution we model a quadratic assignment problem and apply a standard solver. Steward’s algorithms performance is compared with the algorithm suggested by J. Reichardt (Reichardt and Bornholdt, 2006; Reichardt, 2009), which aims at the detection of structure in large networks and the algorithm suggested by Capelle et al (2002) and McConnell and de Montgolfier (2005) aiming at the decomposition of graphs. To evaluate the performance we use the standard criteria solution time and solution quality. Additionally, we consider the influences of the DSM’s composition and examine the effects of size, structure, and density of the matrix.", :title "Alternative Quantitative Approaches for Designing Modular Services: A Comparative Analysis of Steward’s Partitioning and Tearing Approach", :keyword2 "modularisation", :authors (26554 26613 26529), :session 157}, 858 {:keyword1 "Energy-efficiency and Energy savings", :keyword3 "Bottom-up energy models", :abstract "The growing costs and the availability of fuels make it necessary to reduce energy consumption in industrial processes.Almost three-quarters of final energy use are for thermal purposes (boilers,thermal end-uses),but one third of them are wasted through losses while the production of this heat (mainly by combustion of fossil fuels) generates great amounts of CO2 emissions.However,the lower temperature range of this heat could be (technically and economically) recovered through heat pumps (HP) systems although it is seldom reused for the moment.HPs have made great technological progresses by providing at the same time useful heat at higher temperatures and the possibility of replacing boilers (main heat source).Therefore, it seems important to recover and reuse this heat in order to achieve the 20/20/20 EU scheme against climate change for an energy efficient and low-carbon economy.HPs represent an important technology which can reduce significantly CO2 emissions.\r\nOur work’s aim consist in estimating the opportunities of HPs in French food and beverages sector, examining conditions of accessibility to the potential of heat recovery (specifically in low temperatures) and the reduction of CO2 emissions until 2020 through TIMES,a “bottom-up” energy model.In this energy forecasting analysis,an economic dimension is integrated to simulate competition between current and future HPs by taking into account the evolution of energy prices and industry demand.Our model gives, among other things,the evolution of the share of HP-substitutable fuel consumption related to consumption of fuels for steam boiler in different temperature range in this industry.It is a business policy tool in opportunities for HPs in heat recovery potential to better achieves energy savings.", :title "The heat recovery potential in French industry: a survey of opportunities for Heat pumps systems in food and beverages sector", :keyword2 "Heat recovery and Heat pumps", :authors (26571 10496 10504 26611), :session 178}, 861 {:keyword1 "Regression", :keyword3 "Karnaugh Map", :abstract "Considering the existing methods of Segmented Regression, and Multivariate adaptive regression splines (MARS) both of them divide the data on the periodic basis to improve the precision, in Karnaugh Map it would be on the basis of change in parameters. The Karnaugh Map requires that the data be translated into binary based on the change of each of the considered parameters, thereby having the new number of variables of 2 to the power the original number of parameters. These variables are then to be combined to the biggest groups of 2 to the power n using the modified Karnaugh Map method. The number of groups from Karnaugh Map would determine the number of regressions. Then follows the regression of these groups similar as in Segmented Regression, just instead of having segmentation based on time, it would be based on parameters, and regression would be done on the basis of percentage change of those parameters rather than their real values, as the time period between them would vary. The expected improvement is in the precision of the final output.", :title "Financial Data Regression Analysis using modified Karnough Map", :keyword2 "Finance", :authors (17495), :session 230}, 862 {:keyword1 "time-space network", :keyword3 "vehicle and crew scheduling", :abstract "Some decades ago, time-space networks were introduced and at first successfully applied to fleet assignment in the airline industry. The main idea of introducing time-lines aggregating resource flows at the same station at different times can be applied and extended to the scheduling of both vehicles and crews. Additional aggregation techniques developed by the author played a crucial role to the success of several research projects in the last ten years leading to systems in productive use. They deal with the modeling of change in place and of the state of resources during service.\r\n\r\nFirst, alternative displacements of resources between scheduled trips/activities over different stations, such as deadheads in bus scheduling, can be aggregated by constructing first-matches and latest-first-matches (LFM). This LFM-technique led to a new complexity bound for the vehicle/bus scheduling problem and to tractable mathematical flow models for extensions with multiple vehicle types and depots. Second, (explicit) states can be introduced for instance for a train or an aircraft according to a given cyclic maintenance requirement or for a crew member according to a weekly rest rule. Time-space networks can be expanded by these states leading to models directly solvable by optimizers. Such a state network can be used (instead of resource variables and decomposition techniques) whenever one can suitably discretize states of resources. For the more complex working rules of crew scheduling leading to numerous resource variables, our technique is further developed to allow computing implicit states as they occur in alternative legal pairings organized in duty trees. The flow model on the resulting aggregated state network is the basis of the TUIfly productive system CrewOptimizer.", :title "Aggregating deadheads and resource states in time-space network flows towards tractable mathematical models for vehicle and crew scheduling", :keyword2 "aggregation techniques", :authors (19902), :session 211}, 865 {:keyword1 "dimensional facility", :keyword3 "finite dominating set", :abstract "In this presentation we approximate a set of given points by a general hypersphere. More precisely, given two norms u and v and a set of points, we consider the problem of locating and scaling the unit hypersphere of norm u such that the sum of weighted distances between the circumference of the hypersphere and the given points is minimized, where the distance is measured by norm v. We consider the case where norm u and v coincide and present results for the general case. Furthermore, we discuss applications of special cases. \r\n \r\nFrom a geometrical point of view the presented problem is a generalization of the well-known Fermat-Torricelli problem. The problem is related to the problem of locating a hypersphere in a normed space. We discuss this relation and point out differences.\r\n", :title "Geometric fit of a point set by generalized hyperspheres", :keyword2 "minisum", :authors (12179), :session 100}, 866 {:keyword1 "Mixed integer linear programming", :keyword3 "Machine learning", :abstract "We study the problem of obtaining a linear combination of a set of base classifiers, called dictionary, to yield a classifier that is stronger than each individual base classifier. The problem arises in boosting techniques that have emerged as one of the most promising and effective algorithms for supervised learning. We consider large dictionaries and propose an efficient solution algorithm to optimize a piecewise linear error function of the combination. We model the boosting problem as a linear programming problem (LP) and consider dictionaries of Support Vector Machines (SVMs). As each SVM can separate the points in the feature space, the LP contains a huge number of variables. We then tackle it through column generation. We show that both master and auxiliary problems are themselves classification problems, and we give an exact algorithm that solves them through column generation. The main contribution is represented by the implicit description of base classifiers in the dictionary and the efficient optimization approach to problem of simultaneously generating and combining the classifiers to define a strong learner. Moreover we study the regularization path described by minimizing the piecewise linear error function with respect to a family of increasing dictionaries. Finally, we present computational results on real-life datasets that demonstrate the high quality of our solution to boosting and the achieved predictive accuracies are compared with other machine learning approaches.\r\n", :title "Minimizing piecewise linear error function in large dictionaries", :keyword2 "Column generation technique", :authors (26570 24924), :session 79}, 867 {:keyword1 "Coordination", :keyword3 "Automotive industry", :abstract "The shortage of natural resources and rising amounts of waste require sustainable economic management across industries. During the design phase all future stages of the product`s lifecycle, production, usage as well as recycling and disposal, are influenced to a large degree. For this reason, the legislator tries to impair the product design. For example, automotive manufacturers are obligated to demonstrate a certain recycling rate of a new vehicle when certifying this vehicle.\r\nIn current practice, design processes are distributed over companies. Hence, the components of a vehicle are not designed centrally at the OEM, but at a variety of specialized suppliers. In this distributed design process the OEM acts as an integrator and bears responsibility for the compliance of statutory recycling rates. However, the recycling rates depend on the characteristics of each component of the vehicle and thus on the design effort of the suppliers.\r\nSince the partners of this decentralized design process are usually legally and economically independent companies, the cooperation is regularized by contractual agreements. If inappropriate contract structures are used, existing uncertainties and differing objectives of the partners can lead to inefficiencies in the design process and to the non-compliance of recycling rates. Furthermore, the economic risk for suppliers and OEMs is increased. Overcoming these difficulties requires improved coordination between the partners before and during the design process.\r\nTo this end, the aim of this contribution is to improve decentralized design processes in the automotive industry. Therefore, fixed price and incentive contracts are analyzed with regard to their coordination capability and applied to the case of compliance of recycling rates.", :title "Coordination by contracts in decentralized design processes – towards efficient compliance of recycling rates in the automotive industry", :keyword2 "Contracting", :authors (15178 13503 2651), :session 112}, 871 {:keyword1 "Skiba/DNSS points", :keyword3 "stochastic dynamic programming", :abstract "Skiba or DNSS points – or, more generally, Skiba/DNSS sets – naturally occur in optimal control problems with multiple equilibria. Heuristically, a Skiba point is a threshold seperating two basins of attraction of the optimally controlled dynamics. Studying stochastic dynamic programming problems we find solution structures similar to the deterministic concept of Skiba points. We call these structures stochastic Skiba sets. A stochastic Skiba set is a transient set seperating the basins of attraction of the optimally controlled Markov dynamics (i.e., its recurrent sets). In this talk we will present a numerical example to illustrate the concept of stochastic Skiba sets and the dependence of the numerical solution on the probability distribution of the random state.", :title "On Stochastic Skiba Sets – A Numerical Example", :keyword2 "optimal control", :authors (19575 4861), :session 181}, 873 {:keyword1 "illicit drug use", :keyword3 "drug prevention, treatment, and supply reduction", :abstract "Illicit drug consumption imposes enormous health care costs to societies all around the globe. For many years OR has already set a focus on the management of drug epidemics, but so far, the supply and demand of drugs has hardly been analysed in a joint study. Here we present a dynamic model of both the supply and the demand of drugs with the main objective of minimizing the social costs that arise from drug use. In mathematical terms, we present a system of ordinary differential equations (ODEs) with three state variables representing the number of susceptibles, the number of users, and the throughput capacity of supply. The model is parameterized both with data for the U.S. cocaine epidemic and injection drug use (IDU) in Australia. We consider control instruments such as prevention, treatment, and supply reductions. To measure social costs, we include up to four different terms in the objective function: the number of users; the amount of drugs used; the money spent for drug use (often used as a proxy for drug-related crimes); and the amount of drugs available in the market (strongly related to the number of drug sellers). One of our main findings is that the policy recommendation crucially depends on the relative weights that one puts on these quantities, which is not so surprising but definitely challenging for policy makers.", :title "Policy Implications in Dynamic Models of Drug Supply and Demand", :keyword2 "drug supply and demand", :authors (4861), :session 65}, 876 {:keyword1 "large-scale optimization", :keyword3 "electricity market", :abstract "We consider a problem of choosing nodes for trading hubs in the electricity grid of a wholesale electricity spot market with locational marginal pricing. Since the price varies from one node of the power grid to another and from one pricing period to another, the market participants are interested in one or several reference prices to hedge the price risks by settling the futures contracts. These reference prices can be calculated by taking the average of energy prices in a number of nodes with typical price dynamics in some region. A set of such nodes is called a trading hub (hub for short).\r\nThe Hubs Construction Problem consists in finding a given number of sufficiently large hubs which would allow to approximate as much as possible the price dynamics of the market participants. It is required to ensure acceptable level of competition in each of the hubs, where the level of competition is measured by the Herfindahl-Hirschmann Index. Since the exact values of nodal prices in future are unknown, in most practical cases it is acceptable to assume that in future the price dynamics will be similar to that in a preceding sufficiently long historic period (one year or more).\r\nThe Hubs Construction Problem is known to be NP-hard even if the number of hubs is equal to 1. The real-life data contains thousands of nodes and historical nodal prices over thousands of pricing periods (e.g. hours), therefore finding an exact solution is computationally too expensive. We propose two heuristic methods: a genetic algorithm and a hybrid heuristic combining local search with the (1+1)-evolutionary algorithm. Both algorithms were implemented to run on multiprocessor computers. The computational results are presented and discussed.\r\n\r\nWork is partially supported by RFBR grant 07-01-00410.", :title "HEURISTIC ALGORITHMS FOR TRADING HUBS CONSTRUCTION IN ELECTRICITY MARKET", :keyword2 "heuristic algorithms", :authors (13893 14840 14965 14966), :session 221}, 877 {:keyword1 "Lot Sizing", :keyword3 "service level", :abstract "We present a non-linear model formulation for the stochastic single-level, multi-product dynamic lot sizing problem with a gamma service level constraint. Based on demand forecasts, the subject is to determine an efficient, robust and stable production schedule which minimizes the expected setup and holding costs. The proposed model formulation is approximated by a mixed-integer linear program using a scenario approach. A numerical investigation of synthetic problem instances shows under which conditions precise demand forecasts are particularly useful. ", :title "A scenario approach for the stochastic capacitated lot sizing problem ", :keyword2 "stochastic CLSP", :authors (13866 16870 17428), :session 161}, 878 {:keyword1 "Purchase", :keyword3 "Discount", :abstract "Depending on growing globalization and internationalization enterprises are\r\nunder pressure to optimize their business activities. Current results of\r\nRevenue Management and pricing policy research enable business units to find\r\nout and realize optimal sale decisions and strategies. In contrast,\r\nenterprises which have to deal with the results of pricing policies are\r\ncompelled to optimize their purchase. The complexity of economic\r\ninterdependencies and decision-making demand situations under uncertainty with\r\nintegrated kinds of volume discounts reveal the necessity of creating new\r\nsolutions based on quantitative models in highly competitive markets. Business\r\nunits take a great interest in flexibility and robustness. On the one hand\r\nenterprises target to react on different situations on the other hand they\r\naspire to reach steady trading results, independent of the scenario occurred.\r\nPurchase decision-makers have to deal with different complex supply offers,\r\nintegrated types of volume discounts, several prices and types of products and\r\nan uncertain demand for different products. Quantitative models based on\r\nanalysis of purchase situations, handling with stochastic demand and different\r\nvolume discounts are to be presented. Influence and effects of volume discount\r\nimplications and different types of robust mathematical models and features on\r\noptimal purchase solutions are examined. This is the basis of further research\r\nand comparisons between several effects of purchase decisions as a result of\r\nquantitative purchase models considering uncertainty and multi-criteria\r\nanalysis.", :title "Robust solution of purchase models with discount consideration", :keyword2 "Robust Optimization", :authors (26288), :session 175}, 879 {:keyword1 "aggregate production planning", :keyword3 "Risk management", :abstract "In this paper we are to develop a robust multi-objective stochastic programming approach to solve a multi-period multi-product multi-site aggregate production planning problem for a medium-term planning horizon under uncertainty. Some of the features of the proposed model are as follows: (i) Considering the majority of supply chain cost parameters such as transportation cost, inventory holding cost, shortage cost, production cost; (ii) Considering some respects as employment, dismissal and workers productivity; (iii) Considering the lead time between suppliers and sites and between sites and customer zones; (iv) Cost parameters and demand fluctuations are subject to uncertainty. To develop a robust model, two additional objective functions are added to the traditional aggregate production planning. So, our multi-objective model includes (i) the minimization of the total losses of supply chain, consists of production cost, human related cost, raw material and end product inventory holding cost, transportation and shortage cost, (ii) the minimization of the variance of the total losses of supply chain and (iii) the minimization of the financial risk or the probability of not meeting a certain budget. Then, the proposed model is solved as a single-objective mixed integer programming model applying the LP-metrics method. Finally, a sensitivity analysis is done to determine the sensitivity of the model to fluctuations in each of the input data.", :title "A multi-objective stochastic programming approach for aggregate production planning in an uncertain supply chain considering risk", :keyword2 "Stochastic programming", :authors (26617), :session 110}, 880 {:keyword1 "Portfolio selection", :keyword3 "Robust optimization", :abstract "This paper develops a multiperiod framework for portfolio selection, risk management and financing decisions for a non life insurance company. An important feature of our model consists in the use of the robust optimization approach to deal with uncertainty, in place of stochastic programming. The objective is to maximize the return on risk adjusted capital subject to conditional value at risk regulatory constraint.  We suggest for the multiperiod insurer problem different linear robust optimization formulations. The linearity of the optimization problems provides a comprehensible framework and reduces the computational cost. It is an advantage when complex additional requirements are imposed on the portfolio structure such as limitations on positions in certain assets or transaction costs. Theoretical developments are applied to a published financial data of a sample of a non life insurance companies. We compare the ex ante performance of our robust formulations to the performance of the traditional single period formulation frequently employed in the financial industry. The backtesting results indicate that the robust approach is indeed more stable and ensuring higher expected return rate in comparison with the competing expected return rate maximizing stochastic programming model at the expense of solving larger linear programs. ", :title "Hedging, investment and financing decisions: A Robust optimization approach", :keyword2 "Risk management", :authors (25943), :session 142}, 881 {:keyword1 "Production Planning", :keyword3 "Heuristics", :abstract "We consider a production planning problem where a raw material is used in the manufacturing of several end products and where the storage capacity of the raw material warehouse is finite. In addition to the setup, holding and unit production costs of finished goods, the holding cost of the raw material in the warehouse is taken into consideration. Most papers neglect the holding cost of the raw material. However, there are situations where the holding cost of raw material is too large to be negligible compared to the holding cost of finished goods. This is particularly the case in food industry because of the refrigeration cost of the fresh food products (vegetables, milk, etc.) and the long shelf life of the derived products such as canned vegetables. We suppose that the arrivals of raw material are known and can not be changed. This usually happens because of long term contracts between the supplier and the manufacturing companies.\r\n\r\nThe objective is to minimize the total cost composed of raw material holding cost, and the setup, production and holding costs of finished goods. The complicating constraint of the problem is the warehouse capacity. This means that the production of the finished goods should be high enough to satisfy the demands of the customers, to reduce the setup costs, to reduce the holding cost of raw material, and to release warehouse space for the next supply of raw material. On the other hand, high production quantities will generate high inventory costs for finished goods. \r\n\r\nWe show in the paper that this is an NP-hard problem and present some simple heuristics to solve it. The performance of the heuristics is analyzed by comparing their solutions with the best existing solutions and lower bounds which are obtained using a commercial solver.\r\n", :title "A two level lot sizing problem with raw material warehouse capacity", :keyword2 "Lot Sizing", :authors (19188 16259), :session 115}, 883 {:keyword1 "Pinch Analysis", :keyword3 "Cooperative Game Theory", :abstract "For industrial processes using significant amounts of heat, the reuse of waste heat through heat exchanger networks has been a key measure for increasing energy-efficiency for a long time. Pinch analysis is a commonly used method for a systematic matching of process streams in heat integration, e.g. by formulating the energy flows as a transportation problem. \r\nTypically, matching of process streams is limited to a single company or even plant. Enlarging the system boundaries to a network of multiple companies like an eco-industrial park increases the potential for energy savings as well as the number and quality of issues to be considered in the planning approach. One such issue are piping distances if the heat exchanger networks extends over a larger area, another the risk of interruptions when linking independent production processes across plants.\r\nA final challenge in such joint efforts of independent companies is the fair distribution of costs and savings among participants, e.g by cooperative game theory. Its application in this case is promising, as in practice such inter-company networks are often not realized because of lacking motivation for long-term cooperation and dependency. The basic application of allocation methods is shown for an exemplary co-siting concept for wood processing companies. ", :title "Inter-Company Process Integration: An Application Area for Cooperative Game Theory", :keyword2 "Inter-Company", :authors (26614 25791 2675), :session 40}, 887 {:keyword1 "Data Mining", :keyword3 "", :abstract "Urban cities face capacity constraints on their service systems in annoyance of citizens. Data Mining helps to predict urban crisis. This study proposes a novel framework of data mining application in urban management. We presented an efficient data mining approach to describe urban crisis based on call center’s messages. We developed a procedure for data mining extended by researchers. We gathered actual citizen messages from the service operation of a municipality, pinpointed problematic areas, relationships among problems and the root cause.", :title "Urban Crisis Management using data mining algorithms", :keyword2 "Decision Making", :authors (24510 26618 24508), :session 231}, 888 {:keyword1 "Top-down framework", :keyword3 "valuation of collateralized debt obligation, iTrax", :abstract "Over the last years two alternative modelling approaches, bottom-up and top-\r\ndown, have been discussed in the literature for the valuation of multi-name\r\ncredit derivatives. Whereas in the bottom-up approach the default times of\r\neach single portfolio entity is modelled and then aggregated on portfolio level to\r\nderive the loss distribution, the top-down approach directly models the default\r\ntimes of the portfolio which is especially sufficient when having portfolios with\r\nhomogeneous shares of each entity, e.g., iTraxx tranches. Both approaches\r\nhave their advantages and disadvantages which will also be discussed in the\r\npaper. Naturally, the question arises which approach is outperforms the other\r\nin the sense of having only little errors between model and market observed\r\nprices.\r\nAs concrete valuation frameworks we select the double-t-model as bottom-up\r\napproach and the framework of Longstaff/Rajan (2008) as representative for\r\na top-down approach. Both are the state-of-the-art models in their classes.\r\nAfter some theoretical insights and results of a comparative-static analysis, we\r\ncalibrate both models to market data. We especially focus on the behavior\r\nof the pricing errors before and during the financial crisis. Beside the pricing\r\nbehavior in the in- and out-of-sample analysis, we also investigate the resulting\r\nloss distribution.\r\n", :title "A Comparison of a Top-Down to a Bottom-up Approach", :keyword2 "double-t-model ", :authors (26597 26606), :session 96}, 890 {:keyword1 "artificial intelligence", :keyword3 "data mining", :abstract "During the last decade the economic impact of call centers has been growing strongly. As a critical success factor, quality management can be supported by automatically rating call center talks. Existing software systems in this area (e.g. ELSBETH VocalCoach of ItCampus GmbH) are able to detect key words in structured outbound talks like sales conversations. However, rating unstructured inbound talks such as counseling interviews is more difficult and constitutes an open research area.\r\nThis article describes an interdisciplinary research project whose main goal is to develop a decision support system rating talks based on several phonetic and rhetorical features. We present models and techniques for the automatic recognition and classification of phonetic and rhetorical features that are important within the process of speech perception in call center talks. We propose a hybrid top-down and bottom-up approach that incorporates methods of artificial intelligence and data mining. The bottom-up part classifies segments of speech recordings based on frequency and temporal features extracted from the audio signal. The goal of the new complementary top-down procedure is to find rules predicting speech perception based on qualitative phonetic features that are quantified by the bottom-up method. To reach better classification results, expert knowledge from the Institute of Speech Science and Phonetics is integrated into the classifier. The automatic detection has two main goals which lead to different models. The first is to obtain highly self-explanatory models like decision trees from which new knowledge within the speech science of call center talks can be derived. The second goal is to find methods for practical use with a good performance and a high classification rate.", :title "Rating call center talks by detecting prosodic and phonetic  features", :keyword2 "speech perception", :authors (26557 19902 26651), :session 229}, 897 {:keyword1 "line planning", :keyword3 "integer programming", :abstract "The line planning problem is a classical optimization problem in public transport. It is about the construction of a system of lines and associated frequencies in a transportation network, such that a given travel demand can be satisfied. We propose an integer programming model for this problem that integrates line construction and passenger routing, and develop a column generation algorithm for its solution. This algorithm had a share in the construction of the line plan 2010 for the city of Potsdam. The results of the project prove that mathematical optimization methods can be successfully applied to complex problems of service design and that they can produce solutions that are at least as good as manual line plans by experienced experts. ", :title "Optimizing Line Plans in Public Transport", :keyword2 "column generation", :authors (14923 15059), :session 202}, 898 {:keyword1 "Examination Timetabling", :keyword3 "Network Flows", :abstract "The Examination Timetabling Problem (ETP) deals with the coordination of exams at an university. Usually the exams take place in the free period. This paper describes how an exam timetable can be generated, which allows every student to take conflict free his exams and to have enough time to prepare for every exam. It is not trivial to generate such an exam timetable for an university of similar size as the TU Berlin. Since at the moment the exam timetables are created manually at many universities, heavy conflicts arise for a lot of students. This leads to justifiable displeasure for the concerned persons and to prolonged duration of study.A technique will be introduced, which generates conflict free exam timetables for universities of similar size as the TU Berlin. The model, which underlies this technique for optimizing an exam timetable\r\nat the TU Berlin is a decomposition model. That means, that the problem is divided into two partproblems, which are solved consecutively using integer programming techniques.The solution procedure of the first  partproblem implicates in a certain manner the second partproblem, in order to obtain a conflictfree solution of the whole problem. Consequently during the solution process of the first part the existence of a conflictfree solution of the second partproblem is guaranteed. In order to ensure such a conflictfree solution of the whole problem, a specific separation algorithm based on network flow algorithms is used.Finally the two solutions of the two partproblems are merged into a complete solution of the original problem. The introduced decomposition model was implemented and successfully applied for almost all written exams of the bachelor degree programs at the TU Berlin.\r\n", :title "Examination Timetabling at the TU Berlin", :keyword2 "Integer Programming", :authors (26621 17158 26655), :session 220}, 899 {:keyword1 "business model", :keyword3 "simulation", :abstract "One fundamental question every firm has to answer is \"How do we make money in this business?\" Due to the continuously\r\nand rapidly changing economic environment it is not enough to answer this question once, when a firm has freshly\r\nstarted up: on the contrary, this question has to be considered again and again during the life cycle of every firm.\r\n\r\nThe underlying economic logic that defines how a firm creates value for its customers (and all the firms\r\nother stakeholders) is typically what is meant by the term \"business model\". A good business model is essential to\r\nevery firm, whether it is a new venture or an established player, because —next to defining the logic of value\r\ncreation— it also positions the firm within its value network, shows how it transacts with customers and suppliers,\r\nand highlights the products that are exchanged. Many firms operate with a conceptually very simple business model:\r\nThey supply a product that meets a consumer need and sell it at a price that exceeds the cost of production. Other\r\nfirms have more complex business models: They supply a (basic) service for free but charge for advertising or other\r\n\"value added\" services .\r\n\r\nThis contribution first introduces a metamodel that can be used to analyse and design both the structure and the\r\ndynamics of a business model. Based on this metamodel, a number of \"business model blueprints\" are\r\ndeveloped that illustrate the economic logic of various industries at a generic level. \r\n\r\nA case study from a concrete company illustrates how such a blueprint can\r\nbe further refined to create a detailed simulation model of this companies business model. The simulation model is used to answer questions pertaining to improving the value created by this company.", :title "The dynamics of business models", :keyword2 "metamodel", :authors (15432), :session 169}, 900 {:keyword1 "trading strategies", :keyword3 "stock key figures", :abstract "Famas Efficient Market Hypothesis claims future stock returns to be entirely random. However, practitioners make remarkable effort to generate extra returns with their investments. By generating data driven portfolios, we find evidence for several strategies to induce alphas, contradicting EMH. \r\nMany authors have already disclosed effects, which are not consistent with the EMH. For instance, a short run reversal of returns, a medium termed continuation (momentum) have been documented, others report predictive power of trading volume, the firm size, price to book ratio or a stocks 52 week high. \r\nIn contrast to these papers focusing mainly on monthly data, we use higher frequency data from the German Stock Market including prices, number of shares, price to book ratio and firm size of the most liquid shares comprised in the DAX and MDAX on a daily resolution, covering the period from 2004 to 2009. \r\nWe implement a large variety of trading strategies. Each day, all stocks are assigned to Q portfolios corresponding to the value of our figures over a specified formation period comprising f days and subsequently are held for h days. Firstly, we analyze the performance of univariate strategies using only one of these figures. Secondly, bivariate strategies are assessed. Overall, we have 27 strategies with 304 combinations of f and h respectively. We report simple annualized returns, as well as abnormal returns for each strategy. \r\nBesides a small cap premium and a value stock premium, our results fortify a short run return reversal of return and volume based portfolios. When considering a second criterion when forming portfolios, trading profits can be improved substantially. Even when correcting for trading costs, some strategies still exhibit significant abnormal returns.", :title "Trading Strategy Profits reexamined - Evidence from the German Stock Market", :keyword2 "market anomalies", :authors (14545 14609), :session 142}, 901 {:keyword1 "aggregate production planning", :keyword3 "multi-objective programming", :abstract "Risk is inherent in most economic activities. This is especially true of production activities where results of decisions made today may have many possible different outcomes depending on future events. Since companies cannot usually insure themselves completely against risk, they have to manage it. In this paper we present a multi-objective model to deal with a multi-period multi-product multi-site aggregate production planning problem for a medium-term planning horizon under uncertainty. The first objective function attempts to minimize total costs with reference to inventory levels, labor levels, overtime, subcontracting and back ordering levels, and labor, machine and warehouse capacity. The second objective function aim to minimize the financial risk the probability of not meeting a certain budget using the concept of conditional value at risk. The results demonstrate the practicability of our model in the uncertain environments. ", :title "A multi-objective aggregate production planning in an uncertain environment: A CVaR approach ", :keyword2 "conditional value at risk", :authors (26623), :session 161}, 903 {:keyword1 "Scheduling", :keyword3 "Quality Performance", :abstract "Modern manufacturing strives for high Quality and short Flow-Time (FT) due to their significant impact on profit, yet practice and research rarely consider them simultaneously. Our study relies on simulation and analytical queueing models representing a short segment of a typical production-line. We investigate the impact of Inspection Policies (IP) on FT and Quality, measured by Out-Of-Control (OOC) rate, in a deteriorating production system with partially available inspection. This work originates in semiconductors manufacturing, but applicable in other industries.\r\nResults indicate that OOC rate decreases and FT increases with growing inspection rate, until OOC reaches a minimum and starts to increase with FT. The cause for OOC increase is longer waiting time for inspection. OOC rate depends on: (i) inspection rate and (ii) inspection feedback delay. Dynamic IP's are superior to known static IP, enabling increased inspection rate and shorter feedback delay. Minimum OOC is not achieved at maximum inspection utilization, yet dynamic IP's illustrate higher utilization. Inspection availability is modeled by operation (MTBF) and down (MTTR) times. Clearly, higher availability improves quality performance. Operation and down times variability, measured by Coefficient of Variation, impacts OOC rate more than the distribution type (e.g. Exponential, Lognormal). Lower availability drives reduced utilization, explained by the need to reduce waiting time for inspection. Preference of dynamic over static IP's is greater at low availability and at higher variability of operation and down times.\r\nDecision support tool is provided to apply best performing IP at various line streaming and inspection availability scenarios, while simultaneously considering Quality and FT.", :title "Quality Performance Modeling in a Deteriorating Production System with Partially Available Inspection", :keyword2 "Availability and Utilization", :authors (22274 10323), :session 159}, 904 {:keyword1 "supply chain complexity", :keyword3 "Supply Chain Complexity Management", :abstract "Supply chains grow and change as customer requirements, competitive environment and industry standards change, and as the companies in the supply chain form strategic alliances, engage in mergers and acquisitions, outsource functions to third parties, adopt new technologies, launch new products/services, and extend their operations to new geographies, time zones and markets. These supply chains involve situations that are complex, messy, and that cannot be independent of the people involved (such as stakeholders with shared interests, yet with different worldviews and with possibly conflicting perceptions about the problem). In this kind of situations, it may become meaningless to speak of optimization. Instead use of interpretive approaches (i.e. soft OR) that facilitate structuring the problem and provide a thinking framework that helps people to share a common language and understanding of the situation/system may produce more effective results. This, in turn, enables people to master the complexity they face in their supply chains more effectively.\r\nThis paper presents the supply chain complexity management framework that encompasses the three essential elements for understanding and managing supply chain complexity (i.e., supply chain structure, supply chain flows, and supply chain decision-making). And it suggests an interpretive methodology utilizing Theory of Constraints’ Thinking Process Tools to help implement the framework, which mainly facilitates decision-making process when dealing with supply chain complexity. Finally the paper illustrates the application of the methodology to a success case.\r\n", :title "An interpretive approach to managing complexity in the supply chain", :keyword2 "theory of constraints' thinking processes", :authors (11750), :session 118}, 907 {:keyword1 "Data Envelopment Analysis", :keyword3 "efficiency", :abstract "The increasing importance of the service sector as a whole has created demand for more efficiency in service productions. Many services require an integration of customers in the production process. From the service provider’s point of view the customer constitutes an external stochastic factor that may influence the production process significantly. As the quality of the external factor is stochastic, the service provider faces uncertainties in the production process. Thus varying efforts have to be made to deliver the same service. In other words the service provider has to use different inputs, such as working time, to produce the same output for different customers. These differences may be due to inefficiency but also due to the necessity to integrate the customer in the production process.\r\nA generally accepted method for efficiency measurement with numerous applications in the service sector is Data Envelopment Analysis (DEA). However the necessity to integrate the external factor and the resulting uncertainty in production often are not considered in DEA approaches. This presentation discusses a DEA based methodology which accounts for the customer’s influence on service production. The service provider (Decision Making Unit, DMU) is described by a sample of observations (input output data) and the underlying empirical distribution of the input output data. Chance constraints are introduced in the DEA model to consider the uncertainty in production. With an aggregated efficiency measure a ranking of the DMUs according to their performance is possible.\r\n", :title "Efficiency measurement of stochastic service productions ", :keyword2 "service production", :authors (), :session 156}, 908 {:keyword1 "facility Location", :keyword3 "Dynamic (multi-period)", :abstract "The objective of this paper is to investigate dynamic facility location-network design problems with a changing in clients demand, facility and link costs. Fundamentally, Facility location-network design problem is a combination of facility location and network design that involves the determination of the location of the facilities (as in facility location) required to satisfy a set of clients’ demands, and the determination of travelable links (as in network design) to connect clients to facilities. Therefore, in dynamic version of this problem the optimal locations of facilities and the configuration of the underlying network are determined simultaneously in each period of planning horizon. \r\nGenerally, this class of location problem is useful for modeling a number of real-world applications in which tradeoffs between facility costs, network design costs, and operating costs must be made. Such applications arise in regional planning problems and in the automated guided vehicles (AGVs) systems, design of less-than-truckload (LTL) distribution systems, pipeline systems, power transmission networks, airline networks, and telecommunications networks, to name just a few contexts.\r\nThe proposed model is a mixed-integer non-linear programming model that minimizes the total cost over a discrete and finite time horizon for opening, operating and closing facilities as well as for opening and operating links. Also, the transportation costs for shipping demand from facilities to clients are considered. ", :title "The multi-period facility location- network design problem", :keyword2 "Network design", :authors (), :session 214}, 910 {:keyword1 "Supply Chain Management", :keyword3 "Optimization", :abstract "The paper will adress the urgent need, the options, some of the available tools as well as the difficulties for Simulation Support to German Armed Forces Supply Chain Management/ -Optimization. \r\nIt will adress the options and the need to use simulation \r\n-  for long term planning, \r\n-  for training, \r\n-  decision support and \r\n-  controlling \r\nof supply chains at different levels.\r\nThe paper will adress selected criteria and relate them to different types of simulations.\r\nProblem areas will be adressed such as \r\n-  the difficulty to link to existing systems with their databases and mass data (like SAP)\r\n-  the difficulty to relate the simulation to the multi-criteria requirements of the German Armed Forces\r\n-  the fact, that big players so far have not included simulations in their portfolio etc.", :title "Simulation Support to German Armed Forces Supply Chain Optimization - When do we finally get there?", :keyword2 "Simulation", :authors (26627), :session 170}, 912 {:keyword1 "maritime traffic", :keyword3 "integer programming", :abstract "The Kiel Canal connects the North and Baltic seas and is ranked among the world's three major canals. In terms of number of passages, it is the busiest artifical waterway in the world. In a major effort, the canal is going to be enlarged (wider and deeper) at certain points in order to cope with the ever increasing traffic. This project is about giving advice about which enlargement measurements should be taken. In order to do so, we need a model and algorithm which is able to control the ship traffic, so that we can evaluate the different measurements.\r\n\r\nThe problem very roughly is as follows. There is bi-directional ship traffic, passing and overtaking is constrained, depending on the size category of the respective ships and the meeting point. If a conflict occurs, ships have to wait at designated, capacitated places, so-called turnouts or sidings (just as in railroads). The obvious decisions are which ships have to wait where and for how long. The objective is to minimize the total passage time of all ships.  The scheduling is currently done by experienced planners.\r\n\r\nTo evaluate the enlargement measurements a method that mildly imitates the manual planner's procedure was used. For this, we develope a local search heuristic, based on graph algorithms which can handle a remarkable amount of detail, embedded in a rolling horizon manner. Furthermore, the heuristic gives the opportunity to indicate some bottlenecks within the canal. To assess the quality of our heuristic solutions we use integer programming techniques. We investigate an advanced model which promises strengthened lower bounds than the canonical formulation, which needs to be solved with branch-and-price.", :title "Ship Traffic Optimization for the Kiel Canal", :keyword2 "graph algorithms", :authors (26629 14969 20420), :session 212}, 914 {:keyword1 "network flow optimization", :keyword3 "", :abstract "Economies of scale often appear as decreasing marginal costs, but may also occur as a constraint that at least a minimum quantity should be produced or nothing at all. This occured in a network optimization project with a european beverage manufacturer, where this new minimum quantity constraint was imposed on some edges of the network, enforcing the amount produced at a production site to be either zero or above the minimum quantity threshold. Solutions to this problem can support decisions about keeping a production site, setting up a new one, establishing new routes in logistics network, and many more. In our work, we define the corresponding problem ‘minimum cost network flow with minimum quantities’ and prove its computational hardness. Following that, we devise a tailored Branch-&-Bound algorithm with an efficient update step that usually affects only small parts of the network. Experiments are conducted on real problems and artificial networks. In our results, the update step made the inevitable but well-studied subproblem of the initial computation of a minimum cost network flow problem taking most of the actual total running time. As our method does also compares favorably with a heuristic algorithm that has been in use before, we recommend it for practical use. ", :title "Network Flow Optimization with Minimum Quantities", :keyword2 "minimum quantities", :authors (26622), :session 219}, 915 {:keyword1 "Bologna", :keyword3 "Quality in universities", :abstract "In order to keep track with the requirements of today’s business and to fulfill the needs of tomorrow it is eminent for people to hold an academic degree. The OECD e.g. claims that in many European countries the number of students is too low, the dropout rate of the one that start at universities is too high – resulting in a graduate quote that is not appropriate – clearly too low. Hence, politicians try to control the process and its outcome by different means:\r\n1.\tLowering the prerequisites that are mandatory as an entry level to universities. \r\n2.\tIncreasing the possible (teaching-)capacity within the university system\r\n3.\tReducing the time to graduate by referring to the “Bologna Process”\r\nThe effects of these activities are diverse. The question is whether the output of high school system which is crucial for the input of the university system can keep pace with that claim. \r\nThis paper describes the research that has been undertaken to analyze the effects of the requirements to accept more students and shows the effects on the university according to the level of knowledge by the students. A model and simulation runs try to describe the effects. \r\nThe steps of research are the following:\r\n1.\tStudy of the qualifications of high school  and their specific grades in relevant subjects\r\n2.\tModeling causal loop diagrams\r\n3.\tModeling the stock flow diagrams including, validation and simulation runs\r\n4.\tDiscussion of results and recommendation\r\nThe results should provide possible answers to the question:\r\nWhich decisions and employment strategy have to be undertaken by universities to provide an “acceptable” output of academics not only focusing on quantity but quality?\r\n", :title "Effects of increasing numbers of freshmen onto the university – implications for the curriculum and the hiring process", :keyword2 "System Dynamics", :authors (), :session 44}, 916 {:keyword1 "shortest path", :keyword3 "service composition", :abstract "The rise of the services economy promotes the usage of IT services across all kinds of industries. Customers requiring individualized service configurations and flexible service delivery create significant challenges for providers of software services. Combined with the specialization of service providers and the strong globalization in IT services, this leads to the formation of so-called service value networks (SVNs). In a SVN, several service providers collaborate for achieving added value for customers. The primary technical approach for creating SVNs is the service composition based on service-oriented infrastructures (SOAs).\r\n\r\nAs soon as service consumers rely on complex service value networks for operating their business, the quality of service (QoS) becomes crucial. Quality criteria include service level metrics like availability, response time, throughput and others. The service composition has to solve the decision problem of selecting appropriate services to optimize quality metrics and constraints of the overall composition. These  constraints are expressed towards service consumers via service level agreements (SLAs). It has been noticed that the quality of a sequence of services can be modelled as multi-dimensional shortest-path problem [Yu \\& Lin 2005]. However, the non-additivity of the quality metrics has not received much attention yet.\r\n\r\nThis paper contributes to the described challenges by providing a detailed analysis of the aggregation properties of quality metrics for IT services. Based on these findings, dynamic programming approaches for identifying the set of pareto optimal solutions are discussed. In addition, a solution for the simultaneous service selection for different quality goals (based on different SLAs) is proposed.", :title "Quality-aware service composition via multi dimensional shortest paths", :keyword2 "non-additive", :authors (26632), :session 157}, 917 {:keyword1 "Intermediation", :keyword3 "Game Theory", :abstract "In his book on Market Microstructure Spulber presented some strange results with respect to the impact of the subustituability parameter in an intermediation model with differentiated products and inputs. Intuitively, effects in the product and the input market should be similar: if firms become more homogeneous, they loose market power, which should yield lower bid-ask-spreads and higher output. However, in Spulber's analysis parameter changes in the product market yield different results for bid-ask-spreads and output than equivalent changes in the input market. \r\n\r\nThe present paper shows that this outcome stems from an inadequate normalization of demand in upstream and downstream markets, respectively. By appropriately controlling for market size effects, intuitive results are obtained. Beyond that, this setting also allows to address the impact of changes in the number of competitors on the market outcome. \r\n", :title "Intermediation by Heterogeneous Oligopolists", :keyword2 "Oligopoly", :authors (22306), :session 192}, 918 {:keyword1 "Newsvendor Problem", :keyword3 "", :abstract "Our research investigates differences in the behavior of individuals in a profit- vs. a cost- orientated newsvendor problem. Our hypothesis is that individuals order more in the cost orientated than in the profit orientated newsvendor setting. Previous studies (e.g. Schweitzer and Cachon 2000) show that individuals deviate from the expected optimal decision in the newsvendor game. In fact, they tend to order less (more) than the expected profit maximizing order quantity if per unit profit margin is high (low). To test our hypothesis we set up a laboratory study which takes into account the profit or the cost perspective and three critical ratios. Our results confirm our hypothesis as well as the findings of previous studies. In each of the defined critical ratios the average order quantity in the cost orientated newsvendor game is significantly higher than in the profit orientated problem. The results imply that people underlie systematical different biases when facing profit and cost orientated situations. ", :title "Profit- vs. Cost- Orientated Newsvendor Problem: Insights from a Behavioral Study", :keyword2 "Behavioral Operations Management", :authors (26634 53427 15060 829), :session 111}, 920 {:keyword1 "Model risk", :keyword3 "Risk management", :abstract "Model risk arising from uncertainty in model and parameter choice is an important risk faced by financial institutions, but has historically not been considered very thoroughly. \r\nIn recent years attention has increased and a growing number of contributions have been made, for example by Cairns (2000), Hardy (2002), Buraschi and Corielli (2005), or Cont (2006). \r\nIn our study we address the impact of parameter and model uncertainty in maximum likelihood estimates upon risk measures of long-running interest rate and equity options under stochastic interest rates. \r\n\r\nSimilar to Bunnin (2002) we apply a Bayesian methodology to capture model \r\nand parameter uncertainty in historic estimates with predictive densities.\r\nSpecifically, joint posterior distributions of the model parameters are \r\nderived via Markov chain Monte Carlo methods for short-term interest rate and equity models. \r\nThe extent of parameter and model uncertainty, its implications for model results, and the validity\r\nof the Bayesian approach are demonstrated in a large simulation study. \r\nThe methodology is applied in an example with long-running options which\r\ncould be of particular relevance to insurance companies.", :title "The effects of parameter and model uncertainty on long-running options", :keyword2 "Bayesian methods", :authors (26612), :session 77}, 921 {:keyword1 "Airline Applications", :keyword3 "Simulation", :abstract "Airline transportation frequently has to deal with occurring delays, which may lead to infeasible schedules during the day of operations. This forces the Operations Control Center of an airline to recover those schedules by mostly expensive recovery actions. Regarding this difficulty robust scheduling deals with the construction of schedules which are less affected by disruptions or provide possibilities for low-cost recovery actions during the day of operations. Robustness consists of two aspects, stability and flexibility. Stability allows schedules to remain feasible though disruptions may occur. Flexibility is the ability to adapt schedules to the changing environment regarding present disruptions in operations. However, robustness of schedules accompanies with an increase of the planning costs of a schedule. For the offline scheduling problem there exist a lot of indicators for stability and flexibility with possibly mutual impacts. To objectively measure these impacts a preferably realistic evaluation framework including real-time applicable recovery actions is needed. In this context, we present a comparison of a rule-based online approach with a re-optimization approach. A theoretical upper bound for the recovery problem is computed by offline rescheduling, knowing all upcoming disruptions in advance. All recovery actions consider both crew and aircraft connections at the same time. The competing strategies are evaluated by a scenario based simulation.", :title "A Comparison of Rule-based Recovery Strategies for Airline Operations", :keyword2 "Recovery", :authors (24175 27195 1194), :session 198}, 922 {:keyword1 "crises management collaboration", :keyword3 "blended learning", :abstract "“Learning for security” is an EU (IST FP7 225634) co-funded 2-years project aimed at improving softskills relevant to complexities within the context of crisis management, complex behaviour and interdependencies under substantial constraints like collaboration and improvisation under time pressure and high risk.\r\nWe model small parts of decision making processes through exploratory analysis, experimental design and heuristics. We analyze and model such decision making, integrating results into simulation games embedded in blended learning experiences for experienced European crisis management experts.\r\nOur focus lies on the so-called tactical level, where specific inter-organisational workflows must be implemented by actors, who do not know each other in advance, matching the decision making process under consideration. Characteristics of this tactical level also comprise some aspects of strategic and operational planning tasks.\r\nPaper findings include:\r\n1 a model of inter-organisational collaboration and improvisation for decision making during crises under time pressure and high risk\r\n2 a model of inter-organisational information flows and information management during crises\r\n3 a simulation of inter-organisational collaborative decision making without improvisation, based on both collaboration and information management models\r\n4 an attempt to further explore and design a suitable model for improvisation in crisis decision makings\r\n5 an attempt to explore and design some improvisational decision support options for future research.\r\nOur research is currently approaching the practical “experts” point of view by preparing a solid validation phase, and includes reflections on dynamic system theory and agent based simulation tools employed.", :title "Improvisation in decision making during crises management", :keyword2 "simulation games", :authors (26633), :session 170}, 926 {:keyword1 "Disaster relief logistics", :keyword3 "Multi-objective optimization", :abstract "Disaster relief logistics in natural or man-made disaster is one of the major activities in disaster management. The significance of accounting for uncertainty in such context stimulates an interest to develop appropriate decision making tools to cope with uncertain and imprecise parameters in relief logistics system design problems. This paper proposes a two-phase multi-objective possibilistic mixed integer programming model (MOPMIP) to deal with such issues. Our multi-objective model contains: (i) the minimization of the sum of setup cost, transportation cost from relief collection point to relief distribution centers and from relief distribution centers to affected areas and shortage cost of commodity in affected area; (ii) the maximization customer satisfaction through minimizing sum of the maximum shortage in affected areas. The proposed approach uses the strategy of simultaneously minimizing the most possible value of the imprecise total costs, maximizing the possibility of obtaining lower total costs, and minimizing the risk of obtaining higher total costs. The model includes the imprecise nature of some critical parameters such as demands for various types of relief commodities, cost coefficients and capacity levels. To solve the proposed model, an interactive fuzzy solution approach is developed. To demonstrate the significance and applicability of the developed possibilistic model, a case study of IRAN is presented. Consequently, the proposed approach yields an efficient compromise solution and overall degree of decision maker satisfaction with determined goal values.", :title "A multi-objective possibilistic programming model for disaster relief logistics under uncertainty", :keyword2 "Possibilistic linear programming", :authors (26637 24910), :session 155}, 927 {:keyword1 "Disaster management", :keyword3 "Multi-objective optimization", :abstract "Many uncertainties within a disaster relief logistics can substantially affect its performance. The significance of uncertainty and risk has motivated an interest to develop appropriate robust optimization model in disaster relief planning. In this article, a multi-objective robust optimization programming model is developed which considering risk management. Supply, demand, capacity, transportation, inventory and shortage costs are considered as the uncertain parameters. Our multi-objective model includes: (i) the minimization of the sum of current investment costs and the expected future transportation, inventory and shortage costs; (ii) the minimization of the variance of the total cost and (iii) the minimization of the downside risk or the risk of loss. We use the STEM method, which is an interactive multi-objective technique with implicit trade-off information given, to solve the problem. A numerical example demonstrates the feasibility of applying the proposed approach to real decision problems.", :title "A multi-objective robust stochastic optimization model for disaster relief logistics under uncertainty considering risk", :keyword2 "Risk management", :authors (26637 26640), :session 138}, 931 {:keyword1 "Combinatorial optimization", :keyword3 "Vehicle routing", :abstract "Electric utilities are frequently faced with a great number of service orders, which are related to customer’s claims or simply due to distribution system maintenance. Deciding which set of service orders should be assigned and routed to a given work team involves costs related to traveling time, productivity and economic penalties due to agency regulations.\r\nResource management to provide services in electric power distribution systems demands a significant effort from information systems, associating customer data, staff constraints and supply materials from the company. Some commercial systems are available to such a task, however these solutions involve the integration with corporative systems already adopted and require proper management policies for resource management.\r\nAnalyzing into more details the problem of deciding which set of service orders each work team will be assigned, one can note the closely relation to the capacitated clustering problem. Nevertheless, one special requirement is that of specifying the route associated with each set of orders, letting this context compatible with the problem of vehicle routing.\r\nConsidering the large demand and the limited resource available in the utilities, it is convenient to improve the assessment, the classifying and the scheduling of service orders in a centralized dispatching way. This purpose makes easy the standardization of procedures in order to reduce the traveling time and increment the number of orders that each work team can serve.\r\nThis work proposes a model to define the set of orders with the corresponding route for each work team from the utility.", :title "A new approach to clustering and routing service orders in electric utilities", :keyword2 "Clustering", :authors (26641 26642 26643), :session 200}, 935 {:keyword1 "Maintainability", :keyword3 "Decision process", :abstract "A Boolean Markovian System is a logical combination of boolean components with exponentially distributed failure time such that the induced state space of this system can be described by a continuous time Markov chain (CTMC). The life expectancy of such systems can be measured by the mean time to failure (MTTF). In order to maximize the mean life time of such systems a scheduler can assign repair units in each system state to failed components with exponentially distributed repair time. In principle, the optimal repair policy can be found by solving a combinatorial optimization problem, but the number of repair policies can grow exponentially with the number of components. We avoid this by defining an equivalent discrete time Markov decision process (MDP) such that state-dependent decisions are modelled by an action set and action dependent rewards describe the mean exit time of a state. We use the method of value iteration to find the optimal policy by maximizing the MTTF objective function. On the one hand, the optimal policy for the class of purely parallel systems can be gained analytically and we show that failed components with smallest failure rate should be repaired first independent of the repair rate. On the other hand we show that for the general class of coherent systems the optimal repair policy indeed depends on the repair rate.", :title "Optimal maintainability for Boolean Markovian Systems", :keyword2 "Markov chain", :authors (22383 22108), :session 132}, 936 {:keyword1 "multi-objective optimization", :keyword3 "Levenberg-Marquardt method", :abstract "In the last years there have been some Newton based algorithms for solving a multi-objective optimization problem (MOP). All of these methods show a quadratic convergence to a Pareto-critical point of the MOP. We review these methods with respect to the assumptions that they require for the local rate of convergence. Moreover, we propose a Levenberg-Marquardt based method for finding a Pareto-critical point of a convex unconstrained MOP.  \r\n", :title "On Newton-based algorithms for multi-objective optimization", :keyword2 "Pareto-critical point", :authors (14587), :session 76}, 937 {:keyword1 "electricity markets modeling", :keyword3 "simulation", :abstract "We introduce a model for analysing the behaviour of market prices in electricity markets where a large dimensional producer operates. The electricity markets are supposed to be divided in zones interconnected by capacitated transmission lines. The model determines the optimal medium-term resource scheduling of the large dimensional producer, so as to maximize his own market share while garanteeing a minimum preassigned profit level and satisfying technical constraints. The model also includes constraints representing the Market Operator clearing process and therefore it yields the hourly zonal electricity prices. The nonlinearities of the constraints representing the market clearing rules, are linearized by means of binary variables. The model can be used by investors as a simulation tool for analysing both impact on the market and profitability of investment decisions in the zonal electricity market. A case study related to the Italian electricity market is discussed. \r\n", :title "A MILP Model for Analysing Investment Decisions in a Zonal Electricity Market with a Dominant Producer", :keyword2 "market power", :authors (9921 10054), :session 163}, 938 {:keyword1 "Decomposition method", :keyword3 "", :abstract "We present a block decomposition Jacobi-type method\r\nfor nonlinear optimization problems with one linear constraint and\r\nbound constraints on the variables. We prove convergence of the\r\nmethod to stationary points of the problem under quite general\r\nassumptions.", :title "On the convergence of a Jacobi-type algorithm for Singly Linearly-Constrained Problems Subject to simple Bounds", :keyword2 "SVM", :authors (10000), :session 79}, 940 {:keyword1 "Decision Support System", :keyword3 "OR-Cell", :abstract "Modern decision support systems are essential for a comfortable judgement based\r\nanalysis. It is based on a combination of quantitative and qualitative approaches.\r\nThis contribution demonstrates that such an holistic, user-oriented approach asks for a combination\r\nof soft and hard OR techniques. They will not be separated but integrated. The\r\nauthors present distinghuished examples (Complex Modelling Scenarios and\r\nReachback Architectures in the context of the so-called \"OR-Cell\" in an in-theatre-approach) where\r\nmultilayered decision support processes are elaborated and characterized.\r\n", :title "Judgement Based Analysis via the Integration of Soft and Hard OR-Techniques, Methods and Theories", :keyword2 "Hard-Soft OR", :authors (26654 4796), :session 167}, 942 {:keyword1 "ANP", :keyword3 "Customer Selection", :abstract "In this study, we consider 3rd Party Logistics (3PL). Some companies in this sector are distinguished with the high quality of their service, and thus, are dealing with growing demands from customers. In order to work cost effectively, these companies have to work with selected customers.\r\n\r\nSince there are many criteria concerning the customer selection problem in logistics, this is handled with a multi-criteria decision making (MCDM) method. In this paper, we use analytical network process (ANP) to determine the best alternative to work with, for this method allows considering the importance of a criterion in a cluster over another one in a different cluster.\r\n\r\nWe get the view of an expert professional in 3PL sector to determine the clusters and the sub-criteria of this problem and the relations between them, and make pairwise comparisons.\r\n\r\nThree customers are determined as alternatives. At the end of our work, the alternative with the highest rank is the customer which the company should select.", :title "SELECTING CUSTOMERS IN LOGISTICS: AN ANP APPLICATION", :keyword2 "Logistics", :authors (26656 5500 26658 26660), :session 76}, 943 {:keyword1 "", :keyword3 "", :abstract "Quantified moral motives as a basis for action-decisions in social work? \r\nTheoretical possibilities and practical limitations\r\n\r\nResources in social work are limited and will be limited increasingly, while the demand for the performance possibilities of social work is growing steadily. Thus, there is a growing difference between what social work can perform and what can be implemented actually. The problem is comparable with medical care. The best cannot be done because of cost. The result of this is the permanent need for the actors to make decisions for or against support whereas there is still more possible in theory than in practice.\r\nOn what basis can decisions be made, where and how much should be invested in support? This ought to be considered solely in terms of morals. The axiom is clear: non-help is always morally inacceptable. However, exactly this extent of resources of current performed support will not be longer available for future assistance. So, every social-worker needs to develop a moral system, in which he can insert his actions and decisions; at least this system legitimates his actions for himself. A number-based morality scale seems to be most practicable – in theory: decisions can be made better when they are based on numbers in scales. In practice a quantified morality scale has to be established with debatable and questionable elements. Furthermore, it is very difficult to implement this one, since nether suitable instruments exist, nor unique data can be collected. This is less promising and perhaps even less satisfactory. The alternative is: either to do nothing or to decide on gut feelings. I regard both possibilities as morally more questionable than the attempt of a moral scale. However, number based scales are not new: are used in nursing, as well as preventive and emergency medicine. Therefore the question is: can we think about quantified morality motives as a basis for action decisions in social work? And a step forward: Can they be developed and implemented, perhaps?\r\n", :title "Quantified moral motives as a basis for action-decisions in social work? ", :keyword2 "", :authors (26659 26410), :session 88}, 946 {:keyword1 "U-shaped production lines", :keyword3 "assembly line balancing", :abstract "In today’s production systems, U-shaped assembly lines have been increasingly substituted for traditional straight assembly lines. The role of facility layout in JIT production systems is crucial to obtain main benefits of one-piece flow manufacturing, smoothed workload, multi-skilled workforce, and other principles of JIT. Many researchers agree that the U-shaped layout is one of the most important components for a successful implementation of JIT production. The U-shaped assembly lines provide potential benefits including increasing productivity, reduced work-in-process inventory, shorter throughput, simpler material handling, easier production planning and control, and improved quality. The U-line arranges machines around a U-shaped line in the order in which production operations are performed. Operators work inside of the U-shaped layout. \r\nIn this study, first of all, a simple U- shaped production line is designed and then one of the heuristic line balancing techniques applied to a Turkish company.\r\n", :title "DESIGNING AND BALANCING A SIMPLE U-SHAPED PRODUCTION LINE BY USING HEURISTIC BALANCING TECHNIQUES", :keyword2 "heuristics", :authors (26660 26658 5500 26656), :session 158}, 948 {:keyword1 "parameterized measure", :keyword3 "relaxation", :abstract "Firstly we give an overview of the various notions of generalized convexity in nonconvex\r\nvectorial calculus of variations that are applicable in nonlinear elasticity. Our exposition\r\ncenters at the notion of quasiconvexity in the sense of Morrey, polyconvexity\r\ndue to Ball, and rank-one-convexity. Let us mention in passing that this notion of\r\nquasiconvexity should not be confused with quasiconvexity as convexity of lower level\r\nsets in optimization theory and also used in quasilinear elliptic equations.\r\nWe focus our contribution to \ffirst order problems of the calculus of variations. We elaborate\r\non the general framework of Pedregal [1, Section 1.3] to parametrized measures\r\nin nonconvex calculus of variations. We discuss the recent notion of A - convexity, its\r\nrelation to Young measure and its application to relaxation in nonlinear elasticity. In\r\nthis context we present a Jensen's inequality for A - convex functions which is shown\r\nto extend the classical Jensen's inequality for convex functions.\r\nThis talk is based on joint work with K. Dvorsky.\r\nReferences\r\n[1] P. Pedregal, Parametrized Measures and Variational Principles (Birkhaeuser,\r\n1997).", :title "Concepts of Generalized Convexity and a Jensen's Inequality for A - Convex Functions", :keyword2 "nonlinear elasticity", :authors (26058), :session 87}, 950 {:keyword1 "", :keyword3 "", :abstract "In this talk we present new results for the unilateral contact problem in nonlinear\r\nelasticity. Here we do not enter in the derivation of a Euler Lagrange equation or a\r\nmore general Euler Lagrange inclusion using Clarke's generalized dierential calculus,\r\nwhat had recently been established by Schuricht [6] and by Habeck and Schuricht [5].\r\nAlso we do not discuss the formulation of penalty methods and study their convergence\r\nproperties what is well known at least in convex programming to provide a constructive\r\napproach to the existence of Lagrange multipliers; for an investigation of penalty con-\r\nvergence in nonlinear elasticity in a polyconvex setting we refer to [4]. Instead we stick\r\nto the variational problem of minimizing the strain energy subject to the unilateral\r\nconstraint of rigid friction-free contact with a given foundation.\r\nIn particular we study the pure contact-traction problem. Under the assumption of\r\nquasiconvexity and an appropriate recession condition we derive an existence result\r\nthat parallels the existence result of Ciarlet and Necas in their classical paper [3] (see\r\nalso book[2] of Ciarlet) under the more stringent assumption of polyconvexity. Here we\r\ngive a self-contained proof which uses an recession argument that in elasticity theory\r\ngoes back at least to Fichera and has raised to a higher abstract level by Baiocchi,\r\nButtazzo, Gastaldi and Tomarelli in their seminal paper [1]. Finally we deal with\r\nnonquasiconvex energy densities and present an analogous existence result for the pure\r\ncontact-traction problem using the Young measure approach.\r\nThis talk is based on joint work with J. Gwinner.", :title "Application of Concepts of Generalized Convexity to Unilateral Contact", :keyword2 "", :authors (26661), :session 87}, 955 {:keyword1 "Analytic Network Process", :keyword3 "", :abstract "Iranian Automotive market is oligopoly, developing and dynamic. For this reason we are interested on knowing how the relevant components of the automotive market affect their brands’ market share. Considering that the conditions of the problem are adjusted perfectly to the ANP structure, we developed a model based on this tool to estimate the market share for the Corporation automotive brands. The relevant components on the model are: principal brands, consumer segmentation, cost, automotive features and corporation brand features. The results were validated by comparing the ANP model’s estimation with market share’s ones done by relevant organizations. These results show that there is no significant difference between the ANP results and the statistics results. Results also indicate that the model is a good approach to represent this market’s behavior. Advantage of this method is that in addition to forecast market share of the corporation brand, determine the weight of different factors on the formation of the market share, and therefore this is a good guide for producer’s marketing activities.\r\n", :title "ANP APPLICATION TO ESTIMATE IRANIAN AUTOMOTIVE MARKET SHARE", :keyword2 "market share", :authors (24676 26677), :session 76}, 961 {:keyword1 "Shelf Space Management", :keyword3 "Instore Replenishment", :abstract "Managing limited shelf space is a core decision in retail as the increase of product variety is in conflict with limited shelf space and operational replenishment costs. Shelf inventories have on top of the classical supply function a demand generating function, as more shelf positions resulting in increasing consumer demand. Therefore, an efficient decision support model needs to reflect space-elastic demand and logistical components of shelf replenishment. \r\n\r\nTraditional shelf space management models assume efficient replenishment systems and assume replenishment costs as not decision relevant. But, empirical studies show the importance of instore logistic, which may contribute up to 50% of the total retail supply chain costs. Shelf space and inventory management are interdependent, e.g., low space allocation requires frequent restocking.\r\n\r\nOur multi-product shelf space and inventory management problem integrates consumer interaction and hierarchical decision aspects. We extend shelf space models into three directions. First, it takes into account facing dependent replenishment costs. Second, it integrates store inventory holding costs. Finally, we transform the mixed-integer non-linear problem into a knapsack structure. \r\n\r\nThus, it provides a practical solution for retail category specific problem sizes. In our numerical examples we show that an integrated demand and supply inventory management improves the solution quality. Sensitivity analyses are used to compute additionally error bounds for the parameter estimations. Finally, we analyze managerial decisions and constraints of operative fulfillment as part of a comprehensive hierarchical retail planning framework. \r\n", :title "Retail shelf and inventory management with space-elastic demand", :keyword2 "Retail Inventory", :authors (22691 1131), :session 116}, 964 {:keyword1 "Multiobjective Programming", :keyword3 "nondifferentiable Programming", :abstract "A nondifferentiable multiobjective fractional programming problems is\r\nconsidered. Fritz John and Kuhn-Tucker type necessary and sufficient conditions\r\nare derived for a weak efficient solution. Kuhn-Tucker type necessary conditions\r\nobtained by Bector Chandra and Husain (Jounal of Optimization Theory and Applications, 79(1993), 105-125) are shown to be sufficient for a properly efficient\r\nsolution. This result gives conditions under which an efficient solution is\r\nproperly efficient. An example is discussed to illustrate this result.", :title "Weak Efficency and Proper Efficiency in Nondifferentiable Multiobjective Fractional Programming", :keyword2 "Fractional Programming", :authors (26667), :session 87}, 972 {:keyword1 "Linking pin organization structure", :keyword3 "Total distance", :abstract "In a linking pin organization there exist relations between each superior and his direct subordinates and those between members which have the same direct subordinate. The linking pin organization structure can be expressed as a structure where every pair of siblings which have the same parent in a rooted tree is adjacent, if we let nodes and edges in the structure correspond to members and relations between members in the organization respectively. Then the linking pin organization structure is characterized by the number of subordinates of each member, that is, the number of children of each node and the number of levels in the organization, that is, the height of the rooted tree. Moreover, the path between a pair of nodes in the structure is equivalent to the route of communication of information between a pair of members in the organization.\r\nThe purpose of this study is to obtain an optimal set of additional relations to the linking pin organization such that the communication of information between every member becomes the most efficient. This means that we obtain an optimal set of additional edges to the structure minimizing the total distance which is the sum of lengths of shortest paths between every pair of all nodes.\r\nThis study proposes a model of adding relations in two levels of a linking pin organization structure where every pair of siblings in a complete binary tree of height H is adjacent. When edges between every pair of nodes with the same depth M and those between every pair of nodes with the same depth N which is greater than M are added, an optimal pair of depth (M,N)* is obtained by minimizing the total distance.", :title "A Model of Adding Relations in Two Levels of a Linking Pin Organization Structure Minimizing Total Distance", :keyword2 "Complete binary tree", :authors (19032), :session 225}, 975 {:keyword1 "Human Factors", :keyword3 "Prozessoptimierung", :abstract "Örtlich verteiltes Arbeiten ist für militärische Einsätze nichts Neues. Der Aufbau von virtuellen Teams für die Bewältigung von komplexen wissenschaftlichen Analysen zur Unterstützung des militärischen Führungsprozess hingegen schon. Aktuelle Herausforderungen an heutige und zukünftige Einsatzorganisationen befördern die Diskussion um die Gestaltung und die Maintenance von Reach Back Prozessen für die OR-Unterstützung für den Einsatz. Wobei die Ansprüche hoch sind: virtuelles Arbeiten soll neue Ressourcen und Kapazitäten bspw. in Richtung wissenschaftlicher Institutionen oder industrieller Dienstleister erschließen. Aus vorliegenden Forschungen weiß man, dass räumlich verteiltes Arbeiten jedoch sowohl Chancen als auch Risiken mit sich bringt, die es durch präventive Prozessanalysen und Organisationsentwicklung nach Human Factors Überlegungen abzuwägen gilt. Mögliche Architekturen und Werkzeuge der IT-basierten Entscheidungsunterstützung, die in diesem Kontext Verwendung finden können, bilden einen weiteren Schwerpunkt dieser Arbeit.\r\nDer vorliegende Beitrag erörtert entlang der Ergebnisse einer empirischen Fallstudie, Möglichkeiten der Ausgestaltung von Arbeitsprozessen virtueller militärischer Stabsarbeit. \r\n", :title "Prozessgestaltung und Organisationsentwicklung von Reach Back Prozessen in der OR-Unterstützung für den Einsatz", :keyword2 "Organisationsentwicklung", :authors (26388 26679), :session 180}, 976 {:keyword1 "population dynamics", :keyword3 "natural selection", :abstract " The standard assumptions on utility functions in economic models are questionable in many cases. The present paper studies whether it is possible to endogenize determination of payoff functions and what are the mechanisms of their changing. The main conclusion of this investigation is that ''natural'' payoff functions concern reproduction of individuals. We confirm this conclusion by the known results on the Replicator Dynamics and by a model of evolutionary mechanisms' natural selection.\r\nAnother model shows that altruistic or cooperative behavior among relatives is evolutionary stable if it maximizes the total fitness of the family. Finally, we discuss why the mentioned models do not work for social populations, what mechanisms provide a possibility to influence individual behavior and who or what changes individual utility function.In this context we consider demographic dynamics in Europe.\r\n", :title "Evolutionary Games, Utility Functions and Human Reproduction", :keyword2 "demographic crysis", :authors (23978), :session 86}, 978 {:keyword1 "Fast Supply Chain", :keyword3 "", :abstract "We considers the operations of \"fast-fashion\" retailers. Zara and others have developed and invested in merchandize procurement strategies that permit lead times as short as two weeks. This has resulted in flexibility that allows retailers to adjust the assortment of products offered on sale at their stores quickly enough to adapt to popular fashion trends. In particular, firms can chose from a large number of potential styles to produce and offer for sale, and then use weekly sales data to renew their estimates specific items’ popularity. Based on such revised estimates, they then weed out unpopular items, or else re-stock demonstrably popular ones on a week-by-week basis. In sharp contrast, traditional retailers such as Marks and Spencer face lead times on the order of several months.\r\n \r\nIn this context, we focus on the assortment decision of such a retailer with regard to the most valuable resource of a retailer: shelf space. Particularly in high street fashion retailing, stores are usually located in high-street venues with high rent, which is more or less proportional to the available shelf space. In the recent OR literature there have been different approaches to handle the sequential resource allocation problems that arises in this context with a concurrent need for learning. We investigate the use of multi-armed bandits to model the assortment decisions under demand learning, whereby this aspect is captured by a Bayesian Gamma-Poisson model. We consider the flexible handling of shelf space requirements of individual products. We propose a knapsack based index heuristic that results in policies that are close to theoretically derived upper bounds. An important result of our search for assortment strategies is insight into the marginal value of shelf space.", :title "Shelf Space Driven Assortment Planning for Seasonal Consumer Goods", :keyword2 "Assortment", :authors (18872 10803 25933), :session 116}, 980 {:keyword1 "desirability functions", :keyword3 "", :abstract "Desirability function approach is one of the known scalarization methods for multiresponse optimization problems arising in the quality studies of manufacturing and finance. Derringer and Suich’s type desirability functions have nondifferentiable points as a drawback. To solve the optimization of the overall desirability function, one way is to modify the individual desirability functions by approximation and then to use the gradient-based methods. Another way is to use the search techniques that do not employ the derivative information. We propose a new approach which includes writing the mixed-integer formulations of two-sided desirability functions in the multiresponse problem and then converting it into continuous form by a constraint enforcing integer-valuedness. We show our approach on two classical multi-response problem taken from the literature, one of which includes only two-sided desirability functions and the other includes both one-sided and two-sided. After reformulating the overall desirability functions for both problems and by analyzing their differentiability properties, we choose two different methods suitable for the resulting optimization problems. Firstly, the problems are considered as a nonlinear model having discontinuous first order derivatives (DNLP) and solved with BARON solver of GAMS. Secondly, MSG is implemented which is based on writing the convex dual of the problem with the Sharp Augmented Lagrangian and solve the dual problems as a nonlinear model (NLP) with CONOPT of GAMS.", :title "Optimization of Desirability Functions ", :keyword2 "nonsmooth optimization", :authors (11072 51147 3524), :session 29}, 981 {:keyword1 "watermarking", :keyword3 "decision making", :abstract "Abstract\r\n\r\nThis study aims to develop an optimized Metrics Evaluator to evaluate watermarking metrics and balance its feasible required criteria in a numerical form for many watermarking techniques. These metrics are fidelity (quality), capacity, and robustness. \r\nThis evaluator Based on the results of detailed study of the current available status of image watermarking, and discussing the different approaches applied to solve the integrity problems related to the digital image.\r\n We will try to suggest or propose an approach as (an optimization Decision Making Model) to find a reasonable tradeoff for solving the problem of three conflicting performance metrics of watermarking systems: high fidelity, strong robustness, and large payload size. \r\n", :title "Developing of Metrics Evaluator for Digital Image Watermarking Techniques", :keyword2 "optimization", :authors (26685 15205), :session 181}, 982 {:keyword1 "Intermodal Container Transportation", :keyword3 "", :abstract "We address a truck scheduling problem that arises in the pre- and end- haulage of intermodal container transportation, where containers need to be transported between customer places (shipper or receiver) and container terminals (rail or maritime) and vice versa. The transportation requests are handled by a trucking company which operates several depots and a fleet of homogeneous trucks that must be assigned and scheduled to minimize the total truck operating time under hard time window constraints imposed by the customers and terminals. Empty containers are considered as transportation resource and are provided by the trucking company for transportation. The truck scheduling problem at hand\r\nis formulated as Full Truckload Pickup and Delivery Problem. Solution approaches and computational results for randomly generated instances are presented.", :title "Truck Scheduling Problem arising in the Pre- and End- Haulage of Intermodal Container Transportation", :keyword2 "Pickup and Delivery Problem with Time Windows", :authors (26619), :session 201}, 985 {:keyword1 "OR in Military", :keyword3 "OR in Ethics", :abstract "Wie die Beispiele Somalia, Irak und Afghanistan demonstrieren, stehen gescheiterte Staaten oder Gesellschaften nach einem Regimewechsel vor der zentralen Herausforderung, eine tragfähige Verfassung zu entwickeln. Dies soll die zuvor verfeindeten Gesellschaftsgruppen dazu motivieren, zumindest eine Koexistenz oder sogar Kooperationslösungen im Rahmen eines gemeinsamen stabilen Staates anzustreben. Doch bereits allein die Entwicklung eines entsprechenden Verfassungswerks (ganz zu schweigen von seiner erfolgreichen Durchsetzung) als Gegengewicht zu zentrifugal wirkenden Kräften sieht sich mit signifikanten Schwierigkeiten konfrontiert: Erstens scheinen die in der Literatur entwickelten Ermittlungskonzepte für moralisch gerechtfertigte Verfassungen (wie insbesondere der sogenannte Rawlssche Schleier) für die Realität kaum nutzbar zu sein. Zweitens existiert zwischen den verschieden Beteiligten und Betroffenen fast immer eine fundamentale Informationsasymmetrie: Welche Elemente muss eine moralisch gerechtfertigte Verfassung überhaupt aufweisen, damit sie sowohl universell geltende Moralprinzipien enthält als auch von den Einheimischen als Werk akzeptiert wird, das dem landesspezifischen Kontext angemessen Rechnung trägt? Der Beitrag zeigt zunächst auf, welche moralisch gerechtfertigten Prinzipien für Verfassungen aus Sicht der Wirtschaftswissenschaften anzustreben sind. Anschliessend wird ein spieltheoretisches Kommissionendesign vorgestellt, das eine Replikation des Rawlsschen Schleiers unter realen Bedingungen darstellt und mit dessen Hilfe sich diese Prinzipien bei der Verfassungsfindung durchsetzen lassen.", :title "Ein Kommissionenmodell zur Entwicklung moralisch gerechtfertigter Verfassungen ", :keyword2 "Decision Making", :authors (26690), :session 108}, 986 {:keyword1 "OR in Military", :keyword3 "OR in Ethics", :abstract "Zu Beginn des 21. Jahrhunderts wird von der Schweizer Armee erwartet, dass sie auch auf diskontinuierliche Veränderungen in der Sicherheitslage angemessen reagieren kann. Diese Flexibilität soll insbesondere durch das 2005 publizierte Aufwuchskonzept sichergestellt werden. Bislang fehlt diesem Konzept noch in weiten Teilen ein überzeugender theoretischer Unterbau. Vor diesem Hintergrund untersucht der Beitrag, welche Erkenntnisgewinne sich für den militärischen Entscheidungsträger ergeben, wenn der Aufwuchs aus Sicht des betriebswirtschaftlichen Ansatzes der Realoptionen beleuchtet wird. Um hierzu erste Einsichten erzielen zu können, konzentriert sich die Analyse auf die folgende Frage: Unter welchen Bedingungen sollte die Politik und die Armeeführung grundsätzlich einem (flexiblen) Aufwuchskonzept den Vorzug gegenüber einer starren Kapazitätslösung geben. Anhand eines einfachen Beispiels, das den fiktiven Konferenzschutz durch militärische Sicherungskräfte behandelt, werden die Wirkungszusammenhänge zwischen Bedrohungsausmass, Eintrittswahrscheinlichkeiten und politischen Folgekosten identifiziert und entsprechende Handlungsempfehlungen abgeleitet.", :title "Der betriebswirtschaftliche Realoptionen-Ansatz: Ein Unterstützungsinstrument bei der Aufwuchsentscheidung?", :keyword2 "Human Resources", :authors (26690), :session 108}, 987 {:keyword1 "OR in Military", :keyword3 "OR in Ethics", :abstract "Das 2005 publizierte Aufwuchskonzept der Schweizer Armee macht keine Aussagen zu den Lageveränderungen, die einem politischen Entscheid vorausgehen müssen, sowie zur Art, wie der Aufwuchs stattfindet („selektiv, gestaffelt oder auch in einem Zug“). Eine in vensim modellierte Simulation versucht Bedrohungslage und Variantenentscheid zu verbinden: Danach wird der Aufwuchsentscheid provoziert durch eine dramatische Verschlechterung der Sicherheitslage der Schweiz, sei es durch den Aufstieg einer aggressiven Hegemonialmacht in Europa, verbunden mit einem Niedergang bestehender Sicherheitsstrukturen, oder durch das Erstarken einer gegen die Schweiz gerichteten terroristischen (Gross-)Bedrohung. Für beide (exogenen) Szenarien werden Indikatoren festgelegt, die eine Früherkennung erlauben, deren Wechselwirkung bestimmt und – soweit möglich – mit quantifizierten Schwellenwerten unterlegt, die eine Simulation erlauben. Die Modellierung richtet sich an politische Entscheidungsträger als die Verantwortlichen für die Bereitstellung von Ressourcen für die Vorbereitung des Aufwuchses und wird in der Ausbildung von Berufsoffizieren der Schweizer Armee als Instrument der Bedrohungsanalyse verwendet. Der Konferenzbeitrag versteht sich damit als Beispiel für „OR in education“ (Sektion III.6 der Konferenz) und als Ergänzung zur Modellierung des theoretischen Unterbaus des Aufwuchskonzeptes (P. Baltes, oben).", :title "Modellierung des politischen Entscheids zur Teil-Mobilmachung („Aufwuchs“)", :keyword2 "OR in Education", :authors (26684 26671), :session 108}, 988 {:keyword1 "OR in Military", :keyword3 "OR in Ethics", :abstract "Im Rahmen eines umfassenden Forschungs- und Lehransatz entwickelt und vermittelt die Militärakademie an der ETH in Zürich den zukünftigen Berufsoffizieren der Schweizer Armee Modelle und Simulationen zu wahrscheinlichen Einsatzformen. Ein Basismodell ist das durch die MILAK in Zusammenarbeit mit dem Schweizerischen Beschaffungsamt \"armasuisse\" erarbeitete \"NOBRA\"-Modell, welches die künftigen Entscheidungsträger mit der Komplexität eines Konferenzschutzauftrages konfrontiert. Das Modell berücksichtigt nebst \"klassischen\" militärischen Faktoren wie Anzahl Sicherheitskräfte oder Bedrohungsszenarien vor allem auch wichtige Einflussfaktoren aus dem zivilen Bereich, welche nachhaltige Auswirkungen auf die Erfüllung eines Sicherheitsauftrages haben. Ein Beispiel hierfür ist die Zufriedenheit der Anwohner (Was sich im Modell unter anderem auf bessere nachrichtendienstliche Informationen aus den Reihen der Bevölkerung auswirkt). Die Modellbildung profitiert hier unter anderem auch von Erkenntnissen, welche in den vergangenen Jahren durch Simulationen des irregulären Kriegsbildes in Afghanistan und Irak durch die amerikanische OR-Forschung gewonnen wurden. Die Methodik von \"Modelling & Simulation\" soll den Studenten der Militärakademie aufzeigen, wie sie ihre persönliche Entscheidungskompetenz durch ein systematisches Systemdenken kontinuierlich verbessern können. ", :title "Modellierung einer zivil-militärischen Operation zum Konferenzschutz", :keyword2 "Modelling", :authors (26684 26671), :session 108}, 989 {:keyword1 "Multi Project Scheduling", :keyword3 "", :abstract "We consider the problem of scheduling multiple projects subject to resource constraints, a stochastic arrival of projects and stochastic activity durations. The objective is to minimize the expected weighted makespan. For the computation of optimal policies a continuous-time Markov decision process (CTMDP) can be used. Since due to the curse of dimensionality exact solutions are only possible for small problem instances, we present approaches for the approximate solution of the CTMDP. Computational results will be reported.", :title "Scheduling R&D projects in a stochastic dynamic environment using a Markov Decision Process", :keyword2 "Markov Decision Process", :authors (829 16877), :session 245}, 990 {:keyword1 "continuous optimization", :keyword3 "uncertainty", :abstract "Many regulatory systems in system dynamics, computational biology and finance depend on functionally related groups or coalitions of data items that are influenced by various kinds of errors and uncertainty. Recently, so-called target-environment networks under ellipsoidal uncertainty have been introduced as a new modeling approach for dynamic systems with uncertain multivariate states. The dynamic behaviour of these systems is determined by affine-linear coupling rules. Explicit representations of the uncertain multivariate states are obtained by ellipsoidal calculus. We introduce various set-theoretic regression models for an estimation of the unknown system parameters and an identification of the underlying network structure. We discuss the solvability by semidefinite programming and conclude with future research challenges.\r\n", :title "Identification and Optimization of Target-Environment Networks under Ellipsoidal Uncertainty", :keyword2 "regulatory networks", :authors (12264 3524), :session 32}, 991 {:keyword1 "System Dynamics modelling", :keyword3 "stochastic risk analysis", :abstract "The Public-private partnership (PPP) infrastructure projects are generally very complex and have highly dynamic, interdependent risks and uncertainties that occur over the life cycle of a project. Value for money (VFM), a core objective when conducting PPP projects, is defined as the optimal combination of whole life costs and benefits of the project to meet user requirements. By using PPP arrangements, experts transfer and allocate risks to the party who is most capable of managing them in a cost efficient manner. This requires the optimization of risk allocation between the public and private sectors in order to achieve the best VFM. Risk assessment is a critical element when selecting a project partner and examining projected VFM performance. Many studies have revealed that the current PPP project contractor selection methods used in the industry do not address interdependently dynamic and non-linear risk interactions over project life cycles. Such methods are unable to address unstructured or even semi-structured real world problems. The paper developed a decision support system that applied hybrid techniques to the PPP project contractor selection from the public perspective. Using System Dynamics modeling and relevant statistical techniques, the dynamic risk interactions and interdependencies over project life were interpreted and quantified. By employing Monte Carlo simulation and stochastic analysis, the probability distribution of the overall project net present value with compounding both downside and beneficial effects over project life was estimated. The model validation tests indicated that the proposed approach is applicable to a decision model building which can solve the common issues of the current PPP project contractor selection method.", :title "A Hybrid Decision Support System for the Contractor Selection of the Public-Private Partnership Infrastructure Projects", :keyword2 "Monte Carlo simulation", :authors (23985), :session 43}, 992 {:keyword1 "experimental economics", :keyword3 "gametheory", :abstract "In social cognitive science we have to deal with the problem of reliability of human behavior in cooperative situations. In animal societies cooperation is mainly based on genetic relationship. In human societies, however, cooperation is mainly based on social norms and values. A considerable amount of cooperation follows from the legal basis.\r\n\r\nWe study the development of cooperation in a repeated prisoners´ dilemma experiment with unknown length. Subjects are rematched with new partners several times. The study examines the influence of pre existing individual differences in social value orientations by measuring preferences for certain patterns of outcomes to oneself and others. Cooperation is significantly dependent on the type of subject: People with prosocial value orientations demonstrate significantly more cooperation than proself value oriented.\r\n\r\nWe found that a significant majority of the participants use prior experience to anticipate the end of cooperation. This can be interpreted in the following way: The shadow of the past is transferred to future. Furtheron, there is a strong restart effect. This can be interpreted as an increase of trust, at least for a while. Stability of mutual cooperation crucially depends on the initial move of both players: The first impression counts!\r\n\r\nIn the simulation study we raise the question whether the experimentally observed time pattern of cooperation can be reconstructed with a simple Markov model of individual behavior. The model parameters are inferred from the experimental data. The resulting Markov model is used to simulate experimental outcomes. Our model indicates that a simple Markov model can be used as a reasonable description of transition probabilities for successive states of cooperation. ", :title "The Influence of Social Values in Human Cooperation - Experimental Evidence and Simulation of an Iterated Prisoners' Dilemma", :keyword2 "simulation", :authors (281), :session 272}, 993 {:keyword1 "optimization application", :keyword3 "", :abstract "Military airlift planners must decide daily how to use about aircraft of different types, based at different airfields to move two commodities, passengers and cargo pallets, between up to 20 airports.  Each aircraft and aircrew has restrictions on its daily use, such as the total amount of time it can fly, how far it can fly without refueling, and how many landings it can make.  This is a unique vehicle routing problem and we are able to solve most real-world instances optimally.  We have also developed a heuristic that quickly provides optimal or near optimal solutions.  We report real-world tactical and operational results obtained by airlift planners.", :title "Planning Intra-Theater Airlift", :keyword2 "vehicle routing", :authors (7309 26702 2534), :session 210}, 994 {:keyword1 "OR for Development", :keyword3 "System Dynamics", :abstract "The system dynamics approach is a holistic way of solving problems in real-time scenarios. This is a powerful methodology and computer simulation modeling technique for framing, analyzing, and discussing complex issues and problems. System dynamics modeling and simulation is often the background of a systemic thinking approach and has become a management and organizational development paradigm. This paper proposes a system dynamics approach for study the importance of infrastructure facilities on quality of primary education system in developing nations. The model is proposed to be built using the Cross Impact Analysis (CIA) method of relating entities and attributes relevant to the primary education system in any given community. We offer a survey to build the crossimpact correlation matrix and, hence, to better understand the primary education system and importance of infrastructural facilities on quality of primary education. The resulting model enables us to predict the effects of infrastructural facilities on the access of primary education by the community. This may support policy makers to take more effective actions in campaigns. We will discuss the situation of primary education in countries such as Turkey, discuss structural frontiers and challenges, and we conclude with an outlook.", :title "A System Dynamics Model to Study the Importance of Infrastructure Facilities on Quality of Primary Education", :keyword2 "OR in Education", :authors (8942 3524 8416 12264 18430), :session 135}, 997 {:keyword1 "Multiple-Criterion Decision Making (MCDM)", :keyword3 "Organizational Strategy", :abstract "Henry Mintzberg defines strategy as “the mediating force between a dynamic environment and a stable operating system. Strategy is the organization’s ‘conception’ of how to deal with its environment for a time.” The environment of an organization can be viewed as a layered system with different degrees of coupling among these layers themselves, and, between the layers and the organization. Strategic alternatives for the organization should be evaluated by considering the interactions among the environmental layers, each consisting of a set of factors that impact organizational strategy either directly or indirectly. In turn, organizational strategy may have an impact on these factors during the implementation of the strategy. \r\n\r\nThis study is based on a system view of a firm and its environment. An analytic network process (ANP) model is proposed to investigate the impact of the relevant environmental factors on the strategic alternatives of the firm, and the impact of the firm’s strategic choices on its environment. In the model, strategic choices constitute the decision alternatives. The environmental layers and the environmental factors constitute the clusters and decision elements respectively. Influences consist of the impact of the decision elements from higher level elements to lower level elements down to strategic alternatives, whereas feedback is made up of the strategic alternatives on the higher level elements, or, among the elements at different levels, or at a particular level. An application of the ANP model is presented, and its usefulness, advantages and limitations are also discussed. \r\n", :title "An Analytic Network Process Model for Evaluating Strategic Alternatives", :keyword2 "Analytic Network Process (ANP)", :authors (19309), :session 76}, 1001 {:keyword1 "Russia-Georgia Conflict", :keyword3 "Caucasus", :abstract "Early on 8 August 2008, a short war began between South Ossetia and her Russian ally against the Republic of Georgia. The war touched off a series of events which cost several thousand lives, effectively neutralized Georgia’s military capabilities and reduced her borders substantially. Additionally, the critically important energy supply corridor, for which Europe is dependent, was threatened, and the war precipitated a massive capital flight from Russia. \r\nFrom a Georgian perspective, its security and sovereignty are under direct challenge. From a European perspective, the ability of Georgia to defend itself and protect the energy corridor is of the utmost importance. For the Russians, maintaining stability on its southern border is critical to its own national security. Therefore, discerning and applying lessons from the conflict are of vital importance to all parties. \r\nIt is not the intent of this presentation to discuss in depth the political events that lead to the confrontation or assign blame for the causes of the war. Indeed, this presentation will look at the factual data as available in open sources and replicate the conflict as faithfully as possible. The quantitative tool will be the Tactical Numerical Deterministic Model (TNDM), an empirically-based computerized combat simulation model designed specifically for force-on-force scenarios. The model has been in use by both government and private sector entities worldwide for nearly twenty years. \r\nThis analysis will replicate the tactical operations, and derive unbiased and realistic lessons learned. Alternative scenarios will also be evaluated, particularly those which could shed light on varying force postures, weapons mixes or even the impact of external interventions.   \r\n", :title "A Quantitative Analysis of the Russia-Georgia Conflict of August 2008: Lessons Learned and Analytic Survey", :keyword2 "combat simulation", :authors (26729), :session 135}, 1002 {:keyword1 "Logistics Management", :keyword3 "Transportation Modes", :abstract "The selection of an optimal transportation mode is one of the most important factors in supply chain and logistic planning. Furthermore, the selection transportation mode is a complex, multi-criteria decision problem. The decision makers have to face and take attention with a lot of criteria; such as cost, quality, delivery time, safety, accessibility and etc while choosing the best mode. Under these criteria, there must be a selection between motorway, seaway, airway, pipeline, railway and also intermodal modes. Selection the transportation mode is very promising issue because it affects about 60-65 % of total logistic cake. There are some techniques which can be heuristics and logical approaches are used to reach the best option. The analytical hierarchy process (AHP) which is one of the mathematical methods can be very useful in involving several decision makers with different conflicting objectives to arrive at a consensus decision. In this paper, the selection of an optimal transportation mode using an AHP-based model was evaluated for logistic activities. To solve this transportation mode selection problem, we developed a decision support system based AHP. By using the developed decision support system, the best transportation modes is determined and discussed.", :title "Comparing the Transportation Modes in Logistics: an Analytic Hierarchy Process Based Decision Support System", :keyword2 "Multi Criteria Decision Making", :authors (21056 3524), :session 23}, 1005 {:keyword1 "battery lifetime", :keyword3 "", :abstract "The usage of wireless devices like cell phones, notebooks or wireless sensors is often limited by the lifetime of the batteries. Besides the capacity and the discharged rate, the lifetime depends on the discharge pattern. When a battery is continuously discharged, a high current causes it to provide less energy until the end of its lifetime than a low current, i.e., the rate-capacity effect. However, during periods of low or no current the battery can recover partly, i.e., the recovery effect. To properly model the impact of the usage pattern on the battery, one has to combine a workload model with a battery model. \r\nTo model the battery we use the Kinetic Battery Model (KiBaM), in which the battery charge is distributed over two wells: the available-charge well (acw) and the bound-charge (bcw) well. The acw supplies charge directly to the load, whereas the charge in the bcw first flows to the acw before it can be used. A set of two differential equations describes the dynamics of the model. We combine the KiBaM model with a continuous-time Markov Model to describe the usage pattern of the device. Each state represents a mode in which the device can be used, with its own discharge current. \r\nIn combining the two models, the differential equations of the KiBaM are integrated into the Markov model as accumulated rewards, which represent the levels of charge in the two charge wells. This leads to an inhomogeneous Markov Reward Model, since the reward rates depend on the level of the accumulated rewards. \r\nPreviously, we used this model to compute battery lifetime distributions for different workloads. In this paper we extend our analysis means, in order to also compute the expected battery lifetime, as well as the distribution and expected value of the delivered charge.", :title "Computing Lifetimes for Battery-Powered Devices", :keyword2 "inhomogeneous Markov Reward Model", :authors (26694 26744), :session 172}, 1009 {:keyword1 "CARP", :keyword3 "Problem instances", :abstract "This Article tackles a specification of real world urban Capacitated Arc Routing Problems (CARP). It deals with the collection of solid household waste in heterogeneous containers (bins, bags) with different service frequencies which belong to directed arcs of streets considering area structures and service levels. We face the challenge to find daily tours starting at depots traveling over arcs to be serviced and ending at waste plants. We consider real heterogeneous collection vehicles with fixed teams and some special constraints. Following the description of this specific problem this article proposes a multi-stage solution idea and real world problem instances.", :title "CARP of Urban Municipal Solid Waste Collection", :keyword2 "Solid Waste Collection", :authors (25312 26657), :session 133}, 1010 {:keyword1 "innovation system", :keyword3 "methodology", :abstract "In this paper we reflect on effective research strategies for building helpful system dynamics models on induced technology change that are substantiated in the relevant literature and empirical data sources. The paper positions the innovation system literature within the overall field of induced technology change as a distinct systemic approach that offer relevant conceptual starting points for a system dynamics modeling experiment on induced technology change analyses. Innovation system research is interested in identifying the processes underlying innovation, industrial transformation and economic growth. Also, the interest in the functional dynamics of innovation systems creates an opportunity for system dynamics researchers that are applying a scholarly developed modeling approach aiming to identify the structure and processes that explain behavior patterns of induced technology change. \r\nBased on literature research the paper summarizes the main modeling steps applied by system dynamics scholars and compare it with research approaches of innovation system scholars. An unifying research strategy framework for a scientific modeling approach is introduced that highlights the main necessary requirements in order to be most useful for a real world problem situation and for theory building and refinement in general, and specifically for system approaches on induced technology change.\r\n", :title "Towards a methodical synthesis of innovation system modeling", :keyword2 "system dynamics", :authors (26748), :session 169}, 1012 {:keyword1 "pedestrian dynamics", :keyword3 "", :abstract "Pedestrian dynamics play an important role in diverse fields of application such as optimizing traffic logistics, e.g. the optimization of passenger exchange times, or egress planning of buildings, ships and even whole regions. Quantitative predictions of pedestrian dynamics, namely of egress times, is an essential part for optimizing pedestrian flows. To obtain quantitative results it is vital that simulations be as realistic as possible.\r\nIn this talk we present a new microscopic pedestrian simulator which can simulate up to 50 000 pedestrians in real time. The simulator is based on a cellular automaton model introducing a spatial discretization allowing efficient and fast computational algorithms. Effects introduced via the spatial discretization are corrected within the movement strategies such that paths and travel times of virtual pedestrians do not reflect any artefacts. Their movement can hardly be distinguished from continuum approaches typically showing the most realistic movement behaviour but requiring significantly more computational effort. To enhance the quality of the simulator all parameters have been verified according to certain qualitative as well as quantitative test scenarios.\r\nDue to its computational efficiency and realism, the developed simulator could be used for online prediction of pedestrian flows based on camera input as well as a tool for optimizing pedestrian flows. The latter could be based on manually testing different scenarios or even on the optimization algorithms, which are currently used within the simulator for parameter estimation.\r\n", :title "Microscopic pedestrian simulations - From passenger exchange times to regional evacuation", :keyword2 "cellular automata", :authors (26752 26750 26751), :session 166}, 1013 {:keyword1 "Stackelberg games", :keyword3 "Risk analysis", :abstract "\r\nThe United States faces a daunting problem: how do we fortify and defend \r\nour vast national critical infrastructure from damage inflicted by terrorist \r\nattack?  The Department of Homeland Security has developed well-\r\nintentioned policy to address this problem, adopting probabilistic risk \r\nassessment (PRA) as a central theme in numerous models that help allocate \r\nbillions of dollars for protecting infrastructure.  PRA may be acceptable for \r\nassessing risk from acts of Nature or accidents at large scale, but we have \r\ndeep misgivings about using it to assess deliberate terrorist threats.  We \r\npropose an alternative that begins by modeling what we do know: how we \r\noperate our own infrastructure.  Terrorists are then modeled only through \r\ntheir capability to mount worst-case attacks: such analyses are standard \r\nmilitary fare, and (a) do not rely on subject-matter experts who cannot be \r\ntested for accuracy, (b) do not require us to model how the enemy values our \r\ninfrastructure as targets, (c) do not require us to guess at the enemy’s \r\nintentions using subjective, conditional probabilities, and (d) do not require us \r\nto combine thousands of such probabilities in a PRA model.  Finally, we \r\nshow how to use a limited budget to plan long-term defensive investments \r\nthat maximize the resilience of infrastructure to attack.  We base a simple, \r\nillustrative example on the well-known \"Seven Bridges of Königsberg,\" \r\nwhich would follow guidance from the White House’s U.S. Homeland \r\nSecurity Council...if Königsberg were in the United States.\r\n\r\n", :title "Maximizing the Resilience of Critical Infrastructure to Terrorist Attack without Guessing", :keyword2 "Critical infrastructure protection", :authors (26755 23582 26702 2534), :session 195}, 1014 {:keyword1 "Maintenance planning", :keyword3 "", :abstract "As systems become larger and more complex, the task of maintaining system efficiency becomes increasingly difficult.  Some of the issues that have to be considered are differential rates of usage and deterioration, diverse performance metrics, replacement costs and limited budgets.  Additional factors that can complicate planning include limited spare availability, lead times for replenishment and randomness in usage and lifetime parameters.  This talk discusses optimization models for planning the best replacement strategy for components of complex systems so that some measure of system efficiency is either maximized or meets target goals. Mixed Integer models and heuristic solutions approaches are outlined and the quality of solutions obtained is compared. Other approaches for solution including dynamic programming, genetic algorithms and simulation are also discussed.  A practical application of this model for a system at the Naval Undersea Warfare Center is presented.", :title "Planning upgrades in complex systems", :keyword2 "system efficiency", :authors (6914 26763), :session 172}, 1015 {:keyword1 "Performance-Based Logistics", :keyword3 "", :abstract "This paper discusses the use of a simulation model for setting terms of performance based contracts. Metrics commonly used in measuring service and supply performance are examined for their utility in achieving the outcomes of interest for contracts, and the correlations amongst these metrics are determined using simulation models. These correlations are used to highlight the most significant measurable quantities, and the performance limits for these are specified so as to achieve desired outcomes for various system performance indicators. The impact of penalties and incentives are also evaluated using the simulations. Practical issues such as obsolescence, reliability, and cost are also discussed. The exploration of this concept in setting terms for a contract at the Naval Undersea Warfare Center is also illustrated.", :title "Using simulation for setting terms of performance based contracts", :keyword2 "Supply Chain Metrics", :authors (26762 6914), :session 128}, 1016 {:keyword1 "Attribute based hill climbing", :keyword3 "Metaheuristics", :abstract "Attribute based hill climbing (ABHC) is a local search based metaheuristic. Within an iterative search process a move to a neighbour solution is enabled depending on the aspiration level of solution attributes (elementary features of a solution). In particular, a neighbour solution is taken into account (non-tabu) if it would be the best solution found so far for at least one of its attributes. In the literature there are a few promising reports on the use of ABHC. We analyze the influence of different design decisions on the performance of ABHC for different kinds of problems in comparison to other methods.", :title "On the Effectiveness of Attribute Based Hill Climbing", :keyword2 "Tabu search", :authors (7569), :session 124}, 1017 {:keyword1 "supply chain management", :keyword3 "fuzzy linear programming", :abstract "In real world, the traveling time along a particular road changes with the period of the day owing to predictable events such as accidents, vehicle breakdowns. Because of these events, the information about traveling time along a particular road is often not precise enough. For example, based on experience, it can be concluded that the traveling time along a particular road is “around 5 hours”, “between 4 and 6 hours”. Generally, it could be possible to use fuzzy numbers to deal with these uncertain parameters. According to the literature there is no paper which uses fuzzy data in LRP. So this work considers traveling time along a particular road as a triangular fuzzy numbers.\r\nFirst, this work presents a fuzzy location-routing model which has been formulated as a fuzzy linear programming. The proposed model attempts to minimize total costs with reference to vehicle capacity and maximum travel time, as well as customer demands and distribution center capacity. \r\nThen, this work presents a linear programming (LP) approach for solving the LRP with imprecise traveling times. The proposed approach uses the strategy of simultaneously minimizing the most possible value of the imprecise total cost, maximizing the possibility of obtaining lower total costs, and minimizing the risk of obtaining higher total costs. Because of using this structure, the original fuzzy objective function converted into the three crisp (auxiliary) objectives. Then, the auxiliary multiple objective linear programming problems can be converted into an equivalent single goal LP problem using Bellman and Zadeh (1970) and Zimmrman’s fuzzy programming method (1978). A numerical example is solved with Lingo 8 to illustrate the procedure of the proposed method.\r\n\r\n", :title "Application of multiple objective linear programming to solve fuzzy location-routing problem", :keyword2 "location-routing problem", :authors (26746 26790), :session 128}, 1018 {:keyword1 "Network", :keyword3 "Optimization", :abstract "The network-diversion problem (NDP) seeks a minimum-weight, minimal s-t cut in a graph that contains a pre-specified \"diversion edge.\"  The problem arises in intelligence-gathering and war-fighting scenarios.  We begin by providing new complexity results on this problem, for example: (a) NDP is NP-complete even on a directed acyclic graph when the diversion edge is incident to t, and (b) NDP is solvable in polynomial time on an undirected s-t planar graph.  We then describe new integer-programming formulations that enable the solution of substantially larger problems.  Improvements include (a) two-commodity constructs for a \"flow-preserving path,\" (b) new constraints that link flow-preserving paths and vertices, and (c) new constraints that exploit the cut and flow-preserving-path relationship.  Duality\r\ngaps for the new formulation decrease by as much as 51%, and we solve problems with up to 10,000 vertices and 40,000 edges in one hour using CPLEX 12.1 on a Sun Fire x4150; the largest problem solvable with the original formulation in one hour has 2,502 vertices and 9,900 edges.", :title "New Results on the Network Diversion Problem ", :keyword2 "Graph", :authors (26758 26755 6146), :session 218}, 1019 {:keyword1 "OR in Social Complexity", :keyword3 "OR in Education", :abstract "This longitudinal study examined stability and change of delinquency among young offenders after their release. The sample consists of male Germans (N=2405) who were incarcerated in five juvenile prisons in different federal states. Standardised interviews were repeatedly conducted with the prisoners during imprisonment and after release to gather information about personal and social risk as well as protective factors. Based on official criminal records, delinquency was registered up to eight years after the first incarceration. The time interval between release and recidivism, severity of offending and the kind of punishment was observed. Applying \"Growth Mixture Models\" three distinct developmental trajectories can be identified differing in both level of and change in offending over time: Occasional offenders, high level offenders and age-limited offenders. The groups differ in personal and social factors. Results are discussed with regard to offender treatment and prison aftercare.", :title "Criminal Careers of Young Adult Offenders after Release", :keyword2 "OR in Ethics", :authors (23449 26791), :session 16}, 1022 {:keyword1 "Energy", :keyword3 "OR as a Key Technology", :abstract "This presentation surveys the the-of-the-art of the energy sector, mainly in Turkey, towards the end of the talk also in the Philippines, including elements of comparison. It explains the “portfolio” of energy sources and its consumptions. A special emphasis is paid to the present research challenges where Operational Research with its quantitative methods and its experience in interdisciplinary collaboration has the potential to become a key technology. The financial sector is one very important example in this context. This survey is written firstly about and for the nation of Turkey with its 70 million citizens – a nation between continents and cultures, between being developed and, regionally, still in the state a developing country. In this respect, our paper means an invitation to future research in Turkey, in the Philippines and worldwide, for joint academical efforts and to foster development, both wealth of the people and a protection of the environment in the world. In this sense, our contribution and invitation mean a special address sent out by us in this time after the Copenhagen Climate Summit 2009 and at OR 2010 in Munich.", :title "A Review on Development States as Expressed by the Energy Sector - the Examples of Turkey and the Philippines", :keyword2 "Development", :authors (20232 3524 21056 26728 30804 12264), :session 23}, 1024 {:keyword1 "Computational Biology", :keyword3 "Nonlinear Programming", :abstract "In this survey paper, we present advances achieved during the last years in the development and use of OR, in particular, optimization methods in the new gene-environment and eco-finance networks, based on usually finite data series, with an emphasis on uncertainty in them and in the interactions of the model items. Indeed, our networks represent models in the form of time-continuous and time-discrete dynamics, whose unknown parameters we estimate under constraints on complexity and regularization by various kinds of optimization techniques, ranging from linear, mixed-integer, spline, semi-infinite and robust optimization to conic, e.g., semidefinite programming. We present different kinds of uncertainties and a new time-discretization technique, address aspects of data preprocessing and of stability, related aspects from game theory and financial mathematics, we work out structural frontiers and discuss chances for future research and OR application in our real world.", :title "Modeling, Inference and Optimization of Regulatory Networks Based on Time Series Data", :keyword2 "Uncertainty", :authors (26768 3524 12264 12477), :session 32}, 1027 {:keyword1 "•\tWater Resource Systems", :keyword3 "•\tCooperative Game Theory", :abstract "Abstract\r\nThe interdisciplinary nature of water pricing problems requires methods to integrates the technical, economic, environmental, social and legal aspects into a comprehensive framework that allows the development of efficient and sustainable water management strategies. The research presents a methodology for allocating costs among water users using a cooperative game theory approach based on the integral river basin modelling. The proposed approach starts from the hydrologic and economic characterization of the system to be modelled. The hydraulic characterization of the water system includes extended time-horizon data of surface hydrology, given by monthly runoff time series, the application of continuity equations and balance equations in the reservoirs and aquifers nodes. The characterization of water costs is based on the determination of the construction, management and operation cost functions for the hydraulic infrastructures. A Decision Support System for optimising the water resources system is then used to achieve a the best water system performances under a prefixed system configuration and to calculate the characteristic function of each one of the user coalitions that may arise using the resources. The cost allocations is evaluated both giving the admissible values in the nucleus, solving the game allocation problem and by the Shapley Value. \r\n", :title "The Water Pricing Problem in a Complex Water Resources System:A Cooperative Game Theory Approach", :keyword2 "•\tCost allocation", :authors (11105 26662 1521), :session 40}, 1030 {:keyword1 "", :keyword3 "", :abstract "Modern societies have a tendency to exhibit an infinite standard of conflicts o.f complexity and contingency. The reasons for this are based upon the permanent differentiation of social structures, economic functions, technological changes as well as culturally-conditioned values and anomies. Simultaneously, these patterns of conflict run through all levels of social acting\r\n\r\nFurther challenges are coming up in addition, which are of serious importance, since they are vital for the semantics, emergence and the social peace of modern, open-market and democratically organized societies: questions of inclusion, integration and distributive justice. \r\n\r\nA third level of influence is finally constituted by the scientific progress itself: in this context above all the gains in knowledge in the sphere of educational science, social psychology, scientific social policy and economic sciences as well as – of absolutely vital significance for the real progress in the social services – their interpenetrative mediation by means of the information technology.\r\n\r\nSocial services, social work and the modern forms of mediation- and support-management are thus confronted by the challenges of harmonizing four different demands and degrees of complexity with one another in appropriateness to the reality in the course of operationalization-specific measures:\r\n\r\nEfficiency \r\nBudget corresponding Economy \r\nProfessional Excellence \r\nIndividualisation and authenticity \r\nWe have sought to harmonize these demands within the framework of a model of analysis and prognosis, the „Biographical factors-tableau (BFT)“. Based upon the biographical foundations that a person exhibits with respect to employment, lifestyle, dwelling, mobility etc., a quantifiable categorization regarding further opportunities of arranging employment is conducted according to this model. The results are thus made per factor – 10 of such individual factors are concerned altogether – on a scale between 0 and 1. The value “0” signifies this person’s absolute absence of opportunities of being able to be re-integrated enduringly into the labor market within the subsequent three years, at a value of “1” the opportunities of a direct, successful re-integration into the labor market amount to 100 % per paper form.\r\n\r\nBeyond the individual factors, however, the “case-typical” overall evaluation in the sense of a solid prognosis for the future means a further crucial point. The closer the total value of a person may tend towards the direction of “1”, the more dynamical the opportunities of re-integration are increasing realiter.\r\n\r\nOur own manifold individual empirical studies show that precisely the previous practice of support suffers from making use in a one-sided manner of authoritarian methods. That means: Blocking factors in a subject’s entire everyday-life-organization are merely covered inadequately and smoothed over by “ideological” assumptions. Our own method in contrast therefore practice tools of authentic enforcements given to concrete persons by a specific way of model validation \r\n", :title "Mastering Social and Occupational Differentiations as Challenges toward Modern Social Services – An Attempt of a Methodological Answer", :keyword2 "", :authors (26410 20972), :session 88}, 1032 {:keyword1 "Railway traffic control", :keyword3 "regenerative energy", :abstract "In a modern railway system, most of the energy required by trains is supplied by the electric network. Since the efficiency of the electric network depends on the real-time states of the trains charged at the same substation, it is important to construct an energy-efficient traffic control system to manage the train’s real-time states. As startup of the work, an overview about the existing work on this topic is firstly made in this study. The objective is to find out interesting ideas that will be able to achieve our final goal: developing a decision-making tool for the dispatching center to manage the real-time railway traffic in an energy-efficient way. This study is mainly concentrated on two topics: the disruption management and the synchronization management. According to the literature, most of the existing studies are focused on the former. Furthermore, most of them only attempt to retrieve the train timetable from the disrupted schedule by minimizing the train delay. Various methods, such as exact method and heuristics for solving mathematic programming models, heuristic and meta-heuristics for solving graphic models, evolutionary algorithms and even hybrid methods have been proposed to solve the disruption management problems. Synchronization management is mainly concerned with the synchronization of the operations of different trains that are charged at the same substation in order that the energy produced by one train’s braking can be re-utilized by the others. Since it is quite a new topic, few achievements can be found in the literature. We have browsed all recent studies, aiming at getting multiple trains out of interlocking or reutilizing regenerated energy. Several studies are found dealing with railway traffic disruption management problems while none of them takes into account the regenerative energy. Only two papers discuss about the regenerative energy, but they focus on rather the management of train stops during the journey than the synchronization of the traction and braking. However, some ideas such as the decomposition of the problem and the utilization of meta-heuristics are fairly constructive.", :title "The state-of-art about energy-efficient railway traffic control", :keyword2 "disruption management", :authors (20852 24151), :session 207}, 1034 {:keyword1 "car pool", :keyword3 "decision support", :abstract "Mobility plays a central role in the support of military staff of the German Federal Armed Forces. This demand most often is fulfilled by a central organizational unit which allocates needed vehicles out of a local car pool of the military facility. \r\nOne essential maxim is to meet the “approved” demand for mobility for any military employee of that facility at any time. \r\nThis paper is based upon the experience out of an optimization project that has been conducted at a large German military facility with about 3000 employees. \r\nThe optimization effort aimed at two dimensions:\r\nOptimization at business process level (qualitative) \r\nOptimization at the cost level (quantitative)\r\nA short introduction is given into the overall process from the application for a vehicle to the allocation of the needed vehicle. After analyzing the old process and its inefficiencies, a proposal for an improved process design supported by a service oriented software approach is given. \r\nThe second part of this paper is focused on potential mathematical optimization approaches that can be chosen to reduce cost and make “intelligent” allocations to the given demands.\r\nThe demanding goal was a user-friendly decision support system that is able to make intelligent allocations. ", :title "Car Pool Optimization", :keyword2 "optimization", :authors (15321 4796 26679), :session 178}, 1035 {:keyword1 "Particle Swarm Optimization", :keyword3 "", :abstract "Particle swarm optimization (PSO), introduced by Kennedy and Eberhart in the 1990s, belongs to the class of swarm intelligence methods. In PSO a swarm of particles moves through the search space – orientating the movement on the position of the best solution of the individual particle and the best solution in a neighborhood. Various variants exist. Due to the nature of the underlying stochastic process, a theoretical analysis is difficult. We will use the dynamical system approach, first introduced by H.-G. Beyer for evolution strategies, and present  first results for the sphere.", :title "Particle Swarm Optimization: First results from the dynamical systems approach", :keyword2 "Dynamical Systems", :authors (10162), :session 126}, 1038 {:keyword1 "Compram Methodology", :keyword3 "Prevention", :abstract "The credit crisis of 2008 threatens people, the economy and the stability of states. The claim of this field is that complex societal problems should be handled in according to the approaches, the methods and tools, in this field. \r\nFrom the 80ties on many activities of the government were privatized. Banks sold and resold mortgage packages, hedge funds and private equities took over companies which had been built up by hard work by local people over the last fifty years, split them and sold them to other companies leaving the original company with huge debts, and all kinds of securities were being swapped over the world. This approach led to the credit crisis of 2008 leaving many people unemployed, bankrupt and in misery.\r\nIn order to create a safer society one should be able to prevent this ruthless behavior of some people due to others. A carefully analyze of the start of the crisis, of former crisis and the causes of the crisis is needed. Each complex societal problem has a knowledge, power and an emotional element. To find out what we know about the problem, who is affected by it, which parties are involved, who benefits and who suffers, what emotions and political vulnerability are going on, one has to analyze the problem. This needs an interdisciplinary approach. A multi-disciplinary team of knowledge experts should analyze the situation and discuss possible changes. Then actors are invited to give their opinion on the situation. Together the experts and actors should find mutual accepted and sustainable interventions. The interventions should be carefully implemented and evaluated on their desired effect on the problem. This problem handling process can be done by applying the Compram methodology of handling complex societal problems.\r\n\r\n", :title "Prevention of the Credit Crisis", :keyword2 "Credit Crisis", :authors (1254), :session 22}, 1039 {:keyword1 "", :keyword3 "", :abstract "We present an exact algorithm for computing an earliest arrival flow in a discrete time setting on series-parallel graphs. In contrast to previous results for the earliest arrival flow problem this algorithm runs in polynomial time. The problem of computing an earliest arrival flow arises for example in transportation problems or evacuation planning.", :title "Earliest Arrival Flows on Series-Parallel Graphs", :keyword2 "", :authors (12666), :session 219}, 1042 {:keyword1 "Collaborative Game Theory", :keyword3 "Dynamics", :abstract "This paper deals with the ellipsoidal core for cooperative ellipsoidal games, a class of transferable utility\r\ngames where the worth of each coalition is an ellipsoid instead of a real number. Ellipsoids are a suitable\r\ndata structure whenever data are affected by uncertainty and there are some correlations between the\r\nitems under consideration. In the real world, noise in observation and experimental design, incomplete\r\ninformation, vagueness in preference structures and decision making are common sources of uncertainty,\r\nbesides technological and market uncertainty. It is often easy to forecast ranges of values for uncertain\r\ndata. Nevertheless, the representation of data uncertainty in terms of ellipsoids is more suitable than\r\nthe error intervals of single variables since ellipsoids are directly related to covariance matrices. The\r\nellipsoidal core has been recently introduced to answer the important question “How to deal with\r\nreward/cost sharing problems under ellipsoidal uncertainty?”. Here, we study properties of this solution\r\nconcept and present conditions for the non-emptiness of the ellipsoidal core of a cooperative ellipsoidal\r\ngame.", :title "On the Ellipsoidal Core for Cooperative Games under Ellipsoidal Uncertainty", :keyword2 "Uncertainty", :authors (17910 3524 12477), :session 16}, 1044 {:keyword1 "OR in Satellite Communication", :keyword3 "", :abstract "The author will show some of the key challenges for Armed Forces to use satellite communication in an optimal way. There are many different frequency bands requiring different anchor stations and moveable antenna stations. One challenge is to find the right mix to provide capacity with own space segments (be it own satellites or hosted payloads) and rented space segments in order to minimize costs and on the same end to maximise flexibility by providing the right capacity at the right time in the right spot of the world during military operations. There are other challenges finding the right mix of resources in order to minimize a potential shortage of satellite communication capacity.\r\n", :title "Potential Use of OR Methods for Satellite Communication", :keyword2 "Optimization", :authors (26739), :session 127}, 1045 {:keyword1 "", :keyword3 "", :abstract "By discussing successful implementations in finance, airline and retail we show that predictive analytics and business rules are often key for creating successful optimization applications. \r\nIn our examples business rules are used for computing feasible crew pairings (airline), for verifying eligibility of a given loan for a customer (finance), or feasibility of store layouts (retail).\r\nPredictive analytics help by predicting  customer behavior for revenue management (airline), computing best offerings (finance) or shelf layouts (retail).\r\nIn particular in the finance and insurance industry fair treatment of customers  is enforced by regulations. We show how deployment of optimization solutions using business rules can help to achieve this requirement.\r\n", :title "Combining Optimization with Business Rules and Predictive Analytics", :keyword2 "", :authors (10087), :session 43}, 1046 {:keyword1 "", :keyword3 "", :abstract "The author develops a new framework for decision support systems.\r\nKey element is a SOA based approach: Services can be combined\r\nand integrated to a support system in order to establish an efficient analytic toolbox. In a first approach\r\nsoft OR analyses shall be supported. In a second step the service-based system shall be\r\nextended to general (\"soft and hard\"-oriented) OR techniques. ", :title "Soft OR and Design of Service Orientated Architectures for DSS", :keyword2 "", :authors (26679), :session 180}, 1047 {:keyword1 "", :keyword3 "", :abstract "Assessing costs and benefits within climate change issues can be done either within\r\na so-called cost-benefit analysis, or by taking a non-economic evaluation approach.\r\nIn both cases, some measures of costs and effectivenes should be estimated.\r\nThe authors present an overview about several economic, ecological and juristic\r\naspects and offer a multicriteria analysis. They embed their results in a holistic judgement based\r\napproach for hard and soft adaptation investments, for example in the contex of the world bank.\r\n", :title "Modelling and Simluation of Kyoto Protocol - An Interdisciplinary Judgement Based Approach", :keyword2 "", :authors (4796 26861), :session 226}, 1048 {:keyword1 "", :keyword3 "", :abstract "This talk introduces the well-known theorem of Fenchel. The classical proof is presented. In the main part the author presents a new strategy which leads to an alternative proof and interesting theoretical and\r\npractical consequences. ", :title "A New Proof for Fenchel's Theorem ", :keyword2 "", :authors (26862), :session 226}, 1049 {:keyword1 "gender", :keyword3 "facilitation", :abstract "This paper deals with gender phenomena in the context of digital literacy. Studies show that computer use, computer skills, and computer related self-concepts are subject to gender differences. These differences may affect classroom interactions as well as learning processes and have therefore to be considered carefully by teachers who apply computer supported learning. This paper presents a quantitative study to illustrate particular fields affected from gender differences. Furthermore, a qualitative study reveals students’ perceptions of gender differences. The paper presents four dimensions that may help teachers to analyze origins of emerging gender inequalities and closes with suggestions for facilitation methods. ", :title "Gender equality for digital literacy: Issues and solutions", :keyword2 "education", :authors (23389), :session 33}, 1050 {:keyword1 "", :keyword3 "", :abstract "The Defence Science & Technology Organisation (DSTO) provides direct support to commanders in the field through the attachment of operations analysis (OA) teams - usually comprising a DSTO scientist and an Australian Defence Force (ADF) officer. OA teams are tasked to quickly deliver science and technology support to deployed commanders in the form of discrete, carefully-focused studies. Undertaking OR studies in time frames commensurate with the tempo of military operations, and relevant to the decisions made by Commanders in the field, has always been challenging. The diversity of modern military operations, coupled with the complexity being introduced through the use of new and networked technologies by both our military forces and their adversaries, adds additional dimensions to this challenge.\r\n\r\nThe immediacy of the fast OR studies being undertaken precludes the use of the typical post-analysis, peer-review processes used extensively in other fields of science. However, there remains a need for a rigorous and structured process to ensure that the findings of such fast OR studies are not only timely, relevant and useful but also scientifically valid. This presentation will provide an overview of the development of fast OR in Australia and its successful application to current military operations.", :title "Complexity and the application of fast OR in support of military operations: an Australian perspective", :keyword2 "", :authors (26864), :session 180}, 1051 {:keyword1 "Environmental Elements", :keyword3 "Disaster Management", :abstract "Natural elements of the cities' environment are always considered in\r\nsustainable development and to safeguard the environmental values and\r\ncities' livelihood. They are also important part of the city's\r\nspatial, perceptual and structural organization, meaning they can have\r\nan important role in shaping the city's main elements such as network\r\nof roads, defining districts and neighborhoods and strengthening\r\nlandmarks both formally and perceptually. But we have to look again\r\nsince safeguarding the natural elements can actually be used in\r\ndecreasing environmental risks in all phases of disaster management's\r\ncycle. Their contribution goes a long way from strengthening the sense\r\nof place and belonging to it and increase public participation to\r\ntheir usage as emergency access ways and relief routes.\r\nThe enhancement of the natural urban elements can be used both in\r\nmitigation and in post disaster procedures, in decision making and way\r\nfinding, in providing stable elements in the environments specially in\r\nhazards such as earthquakes. Natural elements can have different roles\r\nin case of different hazards and help increase the resiliency\r\naccording to characteristics of each.", :title "Use of Natural Environmental Elements in the Cities for Risk", :keyword2 "Risk reduction", :authors (26874), :session 28}, 1053 {:keyword1 "", :keyword3 "", :abstract "Technical systems of all kinds have become more complex over the last decades. So far, these systems have been mainly developed for providing maximum functionality. But highly sophisticated systems are also more prone to fail. Therefore, reliability is getting more and more important in design of new technical systems.\r\nAutomotive industry in particular, has a great interest in reliability of technical systems, since modern cars contain many highly developed, but also safety-related systems. A breakdown of any safety-related system (e.g. braking system) poses a risk to life and limb of the driver and other involved persons.\r\n\r\nThis presentation is about functional safety of electrical drive systems in the chassis of motor vehicles. Functional safety is the technique to guarantee maximum reliability and to minimize the hazardous effects of potential failures in safety-related systems.\r\nFor this purpose, safety architectures shall be designed, which will contain many degrees of freedom, but also have to meet several conflicting goals. These safety architectures consist of a tree structure with many continuous design parameters including constraints, variable branches and the possibility to insert redundancy or diversity. \r\nIn other words, designing a well-shaped safety architecture raises a multiobjective, mixed integer optimization problem with high complexity and several (nonlinear) constraints.\r\n\r\nThe presentation intends to introduce the abovementioned, current problem in automotive industry to operations research scientists. It shall provide new incentives to find tailored solution techniques and start discussions about how to tackle such problems.\r\n", :title "Introduction to a new optimization problem in functional safety of motor vehicles", :keyword2 "", :authors (26879), :session 179}, 1054 {:keyword1 "", :keyword3 "", :abstract "The topic of the conference is mastering complexity. As it is the annual conference of the operations research community obviously the focus is on mastering complexity by using newest knowledge and methods from the field of operations research to master the continuiously increasing complexity of our world.\r\nIn contrast this guest talk wants to glance at the much less numbercrunching much softer field of management principles and wisdoms. Similarly here mastering complexity is the major issue. Many principles sound very simple and easy - however they are true and all the difficulty lies in putting them into action. Some principles evolved over time and some are a matter of fashion.\r\nFor illustration I take my personal field of experience - the management of large IT projects.  Besides a number of eternally valid truths which are nevertheless worth to repeat and think about regularly the talk sketches a number of interesting approaches to transfer ideas from lean manufacturing with its roots in automotive industry to the management of IT projects.\r\nHopefully this talk broadens the view to the fact that really big, complex, difficult and hard tasks are only solved with a bundle of means ranging from highest sophisticated science to well-done human interaction and leadership.\r\n", :title "Managerial means for mastering complexity", :keyword2 "", :authors (26897), :session 241}, 1055 {:keyword1 "", :keyword3 "", :abstract "Real-life optimization problems such as design, identification, design of controlled systems, decomposition and aggregation of large-scale systems, predicting from observational data, finite element models and so on are essentially multicriteria. Numerous attempts to reduce these problems to single-criterion problems have proved to be fruitless. Application of conventional optimization methods implies that an expert can state an optimization problem correctly and thus determine the feasible solution set (i.e., the constraints imposed on the parameters, functional relationships, and criteria). Unfortunately, this is not always the case, especially when dealing with contradictory criteria. As a result, an expert ends up solving ill-posed problems. Definition of the feasible solution set represents significant, sometimes insurmountable difficulties and existing optimization methods are not helpful in this situation. Taking into account difficulties of determining constraints, the feasible solution set can be poor or even empty. Therefore it is very important to help the expert to determine the constraints correctly. The authors present the PSI method and the MOVI software system; furthermore they formulate and solve new examples which occur in the context of the MIO experiments.\r\n", :title "Compromise solutions in problems with contradictory criteria:  PSI method and MOVI software system within CENETIX to support MIO experiments", :keyword2 "", :authors (17152 4796), :session 127}, 1056 {:keyword1 "Integrated Planning", :keyword3 "Solid Waste Management", :abstract "We consider a problem encountered in the waste collection industry. For a number of waste collection sites we have to determine the service frequency over a given planning period as well as the number of bins to place there. The problem consists of a routing and an allocation\r\naspect. More precisely, if a site has a higher service frequency, the routing cost will increase, since we have to visit this site more often, but at the same time the allocation cost is less, because we use a smaller number of bins. The bins used have different types and different cost and there is a limit on space at each collection site as well as a limit on the total number of bins of each type that can be used. We present solution methods based on a combination of a metaheuristic for the routing part and a MILP for the allocation part.", :title "Models and Algorithms for the Integrated Planning of Bin Allocation and Vehicle Routing in Solid Waste Management", :keyword2 "Vehicle Routing", :authors (15827 2769 10538 24902), :session 28}, 1058 {:keyword1 "OR in Satellite Communication", :keyword3 "", :abstract "This paper shows a framework to optimally distribute anchor stations around the globe in order to maximise response times / contact times of LEO satellites. Especially LEOs on a polar flight path offer an opportunity to use anchor stations close to the poles. This clearly increases the time to communicate with the LEO. \r\nAt the end the paper compares the results of German reconnaissance satellite network with the current setting and a possibly different setting to show the value of optimally distributing anchor stations.\r\n", :title "Optimal Usage of Satellites Based on an Intelligent Distributed Anchor Network, Explained by a Real-World Example Called SAR-Lupe", :keyword2 "Networks", :authors (26923 26739), :session 127}, 1059 {:keyword1 "approximation algorithm", :keyword3 "edge-disjoint Hamiltonian circuits", :abstract "   A problem of finding two edge-disjoint Hamiltonian circuits in complete graph with the extremal total weight of chosen edges is known also as “Two Peripatetic Salesmen Problem“ (2-PSP) [Krarup J. in: Proc. NATO Advanced Study Inst., Versailles, 1974]. We present some polynomial approximation al-gorithms with performance guarantees for the maximum-weight  problem. \r\n   The following statement was useful for construction and analysis algorithms: in  n-vertex 4-regular graph a pair of edge-disjoint partial tours with total number of edges at least 8n/5  can be found in running time  O(n^2) [Gimadi E., Glazkov Yu., and Glebov A. in: Journal of Applied and Industrial Mathematics, 2009]. \r\n   We present approximation algorithms with performance ratios 7/9 and 5/6 in the case of symmetric and metric weight function respectively. For the graphs with distances in the segment (1,q) the problem can be solved with performance ratio (3q+2)/(4q+1) (that means the bound 8/9 for q=2).\r\n   For distances in the segment (1,2) in the case of two independent metric weight functions of both Hamiltonian circuits, the polynomial algorithm with the bound 11/16 was known. Now an improved  ratio 20/27 can be achieved using approximation algorithms with performance ratios 8/9 (for the maximum-weight TSP) and 4/3 (for the minimum-weight 2-PSP) respectively. \r\n   In the case of graphs in multidimensional Euclidean space R^k asymptotic optimal polynomial algorithms for MAX 2-PSP (Gimadi E, 2008) and MAX m-PSP (Baburin E. and Gimadi E., 2010) are constructed [in:  Proc. of the Steklov Institute of Mathematics]. In this report conditions of asymptotic optimality in the case of graphs on integer lattice in R^k are presented also. \r\nThe work is supported by RFBR (project 08-01-00516).\r\n", :title "Some polynomial algorithms with performance guarantees for the maximum-weight problem  of two edge-disjoint traveling salesmen in complete graph", :keyword2 "performance ratio", :authors (10785 13857 26221 26222 20155), :session 213}, 1060 {:keyword1 "", :keyword3 "", :abstract "Due to increasing global competition in the automotive market, most efforts in current planning concern the minimization of the overall process costs. The task of the operational production planning at Volkswagen Commercial Vehicles (VWN) is to determine schedules with a horizon of one year. This planning is currently achieved through decentralization with vertical (hierarchical) and partly horizontal decomposition.  The subsequent aggregation of data and division into sub-problems result in a simplification of the overall problem. Furthermore, it is impossible to consider all interdependencies of the problem. For this reason, a new mixed integer linear programming approach for the optimization of the operational production planning is presented in this work. The approach captures most of the important interdependencies of the problem and is characterized by a high degree of detail. Thereby it is possible to model the given flexibility possibilities of the production system at VWN and plan them in a cost optimal way. The validation of the decision model is illustrated for the problem instance of the year 2008. The results closely match with reality, and reveal significant potential for improvements in the current planning. ", :title "Optimization of the operational production planning at Volkswagen Commercial Vehicles in the T5 vehicle manufacturing, using mathematical decision models ", :keyword2 "", :authors (26948), :session 257}, 1061 {:keyword1 "", :keyword3 "", :abstract "Fleet assignment is a major decision problem of the airline planning process. It assigns fleet types to scheduled flights so that profit is maximized. Basic fleet assignment models are solved irrespective of other planning steps. Although this leads to an optimal assignment solution, it might cause suboptimal solutions in subsequent\r\nplanning steps. This thesis provides at first a comprehensive overview of existing models integrating fleet assignment and at least one further planning step. The majority of fleet assignment models do not revise their solution if demand and thus profitability of flights turns out to be different than expected. This thesis presents a detailed analysis of dynamic fleet assignment which combines an initial fleet assignment and later demand-driven re-fleeting. Further, we incorporate robustness into the initial fleet assignment, which we assume to increase re-fleeting\r\nflexibility. Additionally, we propose an extension of an existing robustness concept. In computational experiments a dynamic fleet assignment process incorporating robustness is simulated based on a schedule containing 700 flights. The results demonstrate that a robust initial fleet assignment leads to higher re-fleeting profits than\r\na basic fleet assignment model if demand variation is large. Further, our proposed robustness strategy leads to significantly lower run times and achieves greater profits than the traditional robustness concept. ", :title "Dynamic Airline Fleet Assignment and Integrated Modeling", :keyword2 "", :authors (26949), :session 257}, 1062 {:keyword1 "", :keyword3 "", :abstract "In recent years, a lot of attention has been devoted to classes of games that always admit pure Nash equilibria (PNE). Since Rosenthal used a potential argument in order to establish the existence of PNE in all congestion games, potential functions are an important tool to prove their existence. It is well known that a slight generalization of\r\nRosenthal‘s congestion games allowing for player-specific demands need not be potential games. First, we study the existence of potential functions in such weighted congestion games. Let C be an arbitrary set of locally bounded functions and let G(C) be the set of weighted congestion games with cost functions in C. We show that every weighted\r\ncongestion game G in G(C) admits an exact potential if and only if C contains only affine functions. We also give a similar characterization for weighted potentials with the difference that here C consists either of affine functions or of certain exponential functions. Our results establish for the first time a complete charcterization of maximal\r\nsets of cost functions that guarantee the existence of potentials in weighted congestion games. We finally extend our characterizations to weighted congestion games with facility-dependent demands and elastic demands, respectively.", :title "Congestion Games and Potentials", :keyword2 "", :authors (26950), :session 257}, 1063 {:keyword1 "Game Theory", :keyword3 "Supply-Chain-Management", :abstract "Non-cooperative game-theory has strongly influenced supply-chain management, enabling us to identify and to model the conflicts of interest that interfere with supply-chain performance. Unlike the efficient outcomes that are achieved with cooperative game-theory (i.e. the optimization of supply-chain performance), the solutions that non-cooperative game-theory offers are incentive compatible, but often only second-best concerning the supply-chain’s total performance. These solutions usually involve principle-agent contracts with “knife’s edge” incentives for the agents to comply and, thus, to reveal their private information. \r\nRecently, game-theory based experiments have been conducted to test the effectiveness of such principle-agent contracts in supply-chain management and to compare behavioral outcomes to those predicted by non-cooperative game-theory. The experimental studies reveal a number of interesting behavioral effects. First, it seems that the minimal incentives provided in principle-agent contracts in many cases may not be sufficiently strong to induce the intended behavior. Second, there is some evidence that under certain circumstances communication can help supply-chain actors to overcome their conflicts of interest and to jointly optimize the supply-chain performance. Third, experiments show that sometimes simple profit-sharing contracts that minimize strategic risk and optimize supply-chain performance are preferred to complicated screening-contracts, even though the former are out of equilibrium, while the latter are predicted by non-cooperative game-theory. However, the recent experimental studies also show that non-cooperative game-theory in general generates excellent hypotheses about the conflicts of interest in supply-chain interaction. Hence, the most promising approach to understanding supply-chain behavior combines non-cooperative game theory and experimentation.\r\n", :title "Non-Cooperative Game-Theory and Experimentation in Supply-Chain Management", :keyword2 "Experimental Economics", :authors (26951), :session 259}, 1065 {:keyword1 "", :keyword3 "", :abstract "The talk focuses on a family of classification methods called discrete support vector machines (discrete SVM) and based on mixed-integer optimization. These methods aim at deriving optimal separating hyperplanes by replacing the traditional hinge function with a 0-1 loss function to accurately express the empirical error. Starting from the original formulation, which is a variant of 1-norm SVM, discrete SVM have been extended in several directions to deal with multicategory, fuzzy and time series classification problems or to learn from few examples. Kernel versions have also been proposed, as a variant of 2-norm SVM, by framing the formulation in the context of quadratic mixed-integer optimization. Discrete SVM have been applied to well-known problems in different application domains, such as marketing and biolife sciences, for the prediction of HIV protease cleavage sites in peptide sequences, secondary structure and protein folding recognition, cancer microarray data classification, showing excellent performances in terms of accuracy, sensitivity and generalization capability.", :title "Discrete support vector machines: classification methods based on mixed-integer optimization", :keyword2 "", :authors (4747), :session 260}, 1067 {:keyword1 "", :keyword3 "", :abstract "Main  objects of the presentation:\r\n•\tdefinition and tasks of Controlling/Management Accounting\r\n•\tFocussing problem kernels by a framework of 10 axiom types\r\n•\tselecting and discussing main methodological problems and some hints at solutions/handling realistic developments of controlling methods/rules – a survey and insight in a proposal to extend the hitherto existing standard case of business process controlling to open decision and business process  controlling\r\n•\tbased on empirical analysis of selected controlling cases and systems in small,  middle \r\n            and big enterprises, selected industrial y and military development projects,\r\n            regarding the manifold discussions of decision and steering support systems, collective \r\n            decision approaches/corresponding organization theory, IT-supported Controlling and \r\n            Management Accounting Systems.\r\n\r\nA minimal set of axiom types is presented to define problem kernels of controlling as a participative approach helping to develop and adapt development policies of the firm within a  framework of realistic change management: \r\n- Basic/Object axiom types:\r\n  (1) Evolution of  potentials for steering and execution processes \r\n  (2) Evolution of products/programs and their internal and external decision and \r\n        execution processes and corresponding dynamic variables \r\n  (3) Evolution of process structures – conjunctions and disjunctions  of sequencing relations     \r\n  (4) Evolution of con- and disjunctive process effect quanta\r\n- Steering axiom types:\r\n  (5) –( 9) Evolution of controlling institutions, information, steering goals and restrictions,\r\n               controlling/ rules, and aggregation levels\r\n- General motivation axiom type:\r\n  (10) Ethical and political postulates\r\n \r\nSelected special methodological problems are stated and hints at their practical solution/handling  are given:\r\n1.  Separation into controlling areas/modules and their integration - the problem of heuristic \r\n     participation in controlling systems by overlapping goals, definition of cuts and   \r\n     communication rules according to problem structures and steering methods\r\n2.  Measurement of criteria, restrictions, effects, and variables using quantitative scales to\r\n    synthesize goals/aspiration levels of business evolution and their chances and risks within \r\n     open decision and execution networks and under open/rolling horizons\r\n3.  Principles of flexible business evolution by collective simulations and piecewise robust  \r\n     planning and supply of  reserves/adaptation potentials\r\n4.  Rules/Methods of multi-criteria and multi-institutional decision, auditing, adaptation and  \r\n     Innovation in controlling processes: enrichment of standard accounting systems with \r\n     regard to the pattern of open process effects and their constraints    \r\n5.- Insurance of the “open sight seeing“of controlling problems\r\n6.  Controlling of  a controlling system in the realm of Change Management", :title "Controlling/Management Accounting As An Open Management Support System – A Contribute To Evolution of Business Processes and Systems", :keyword2 "", :authors (26956), :session 261}, 1068 {:keyword1 "", :keyword3 "", :abstract "This paper uses the Benninga-Helmantel-Sarig (2005) framework to value employee stock options (ESOs) and restricted stocks units (RSU) in a framework which takes explicit account of employee non-diversification in addition to the standard features of vesting and forfeit of the stock options. This framework provides an endogenous explanation of early exercise of employee stock options. Incorporating non-diversification, we find that the pricing model is aligned with empirical findings of ESOs and results in lower values compare to alternative employee option pricing models such the widely-used Hull-White (2004) model. This pricing has implication for the FAS 123(R) for estimating the fair value of equity based compensation.", :title "Non-Marketability and the Value of Equity Based Compensation", :keyword2 "", :authors (26957 26958), :session 262}, 1069 {:keyword1 "", :keyword3 "", :abstract "Cyberinfrastructure refers to computing tools that facilitate a variety of activities through the use of generally available hardware, data networks, software, and communications standards.  This presentation will survey cyberinfrastructure projects that involve software and standards for optimization, with particular relevance to applications in operations research.  Topics to be covered will include:\r\n•\topen-source software repositories, notably COIN-OR;\r\n•\tproviders of modeling and solving software over the Internet, particularly NEOS and the Optimization Services framework;\r\n•\tautomated analysis of optimization problems and choice of solvers in the context of cyberinfrastructures; and\r\n•\taccess to optimization software on high-performance, distributed, and high-throughput computing platforms.\r\nSuggestions for getting started using some of these projects will be provided.  Concluding remarks will focus on implications of recent developments, such as cloud computing and multi-core processor architectures, for the design and maintenance of optimization cyberinfrastructures.", :title "Cyberinfrastructure and Optimization", :keyword2 "", :authors (3753), :session 263}, 1070 {:keyword1 "", :keyword3 "", :abstract "In this presentation, we will give a short introduction to the shipping industry and an overview of some OR-focused planning problems within maritime transportation. Examples from several real cases, elements of models and solution methods will be given. Finally, we present some trends regarding future developments, use, need and benefits from optimization-based decision support systems for maritime transportation.", :title "Optimization of Maritime Transportation", :keyword2 "", :authors (6744), :session 264}, 1071 {:keyword1 "", :keyword3 "", :abstract "During the past two decades a novel approach to design optimization\r\nof mechanical structures has been developed up to its first successful\r\nindustrial applications. In classical approaches of design (or shape)\r\noptimization the boundary of the mechanical structure is parameterized,\r\nand optimization is done in terms of these parameters describing the\r\nboundary. This methodology predetermines the design within a certain class.\r\nIn sharp contrast to this, any a priori knowledge on the shape of boundaries,\r\nthe number of holes in the structure etc. is not used in topology optimization.\r\nTopology optimization regards a mechanical structure as a material\r\ndistribution on given structural elements in 2D or 3D. Here structural\r\nelements may be elements from a finite element discretization or ficticious\r\nelements based on certain manufacturing demands. The viewpoint of material\r\ndistribution allows a so-called free design of the structure and thus makes\r\nthe approach extremely powerful. The optimization process, however, is\r\nmathematically challenging and requires extensive computational effort.\r\n\r\nThe talk gives an introduction to topology optimization where we focus\r\non the optimization of discrete and discretized mechanical structures\r\nresulting in various problem formulations of continuous optimization or\r\nmixed-integer optimization.\r\nSevere mathematical difficulties arise from the fact that structural\r\nelements with vanishing material (holes) must be covered by the optimization\r\nmodel. This leads to singular stiffness matrices and other pitfalls preventing\r\nthe application of standard theory in finite elements and optimization.\r\nAs a result we observe certain unpleasant effects in calculations and in\r\nthe application of standard optimization methods.\r\nIn some situations, however, these difficulties can be governed or circumvented\r\nby, e.g., appropriate problem transformations, duality, or the use of adapted\r\nor perturbed optimality conditions.\r\n\r\nWe present a small collection of known and new problem formulations,\r\ndifficulties, solutions, workarounds, and numerical results.", :title "Topology Optimization of Mechanical Structures", :keyword2 "", :authors (25674), :session 265}, 1073 {:keyword1 "", :keyword3 "", :abstract "Rising healthcare expenditures across the world and a changing attitude\r\nof patients are forcing a radical change in the way healthcare delivery is\r\norganized. This rises many challenges for researchers from the OR community.\r\nThis presentation focuses on the optimization of healthcare delivery\r\nprocesses in hospitals within the Center for Healthcare Operations\r\nImprovement and Research (CHOIR) of University of Twente in the Netherlands.\r\nAn overview will be given of recent work, and challenging topics of future\r\nresearch will be outlined. Finally, it will be discussed how we have set up\r\na fruitful collaboration with a large group of healthcare providers.", :title "Challenges for operations research in the new healthcare landscape", :keyword2 "", :authors (11732), :session 267}, 1074 {:keyword1 "", :keyword3 "", :abstract "The technical core of most Operational Research (OR) involves the development, testing, creation and use of a model that captures the important features of a system of interest in a mathematical or computer-based representation. Since OR aims to make a difference to the world, it is important to consider how OR models are used and how this might affect the way they are built and the way we teach our students. Here we review the fundamentals of modelling and model use, primarily focusing on computer simulation methods, though the discussion is relevant to most other technical areas of OR. Examples to illustrate the argument come from successful work in developing a generic model of whole hospital processes for use in the UK NHS and also a project completed for the European Commission that led to a new staff appraisal and promotion system for Commission officials. If there is time, we shall also reflect on the use of models for policy analysis in the government sector.", :title "Why model use matters in computer simulation (and in all OR)", :keyword2 "", :authors (2403), :session 268}, 1075 {:keyword1 "", :keyword3 "", :abstract "Since the early 1970's, the field of model-based performance and \r\ndependability evaluation has been flourishing. A large variety of \r\ntechniques and tools has been developed, e.g., based on queuing \r\nnetworks, stochastic or timed Petri nets, or directly based on Markov \r\nprocesses. However, recent advances in computer-communication systems \r\nmake many of the existing techniques fall short, for at least two \r\nreasons: (i) the supported model class, and (ii) their scalability.\r\n\r\nAs for the model class, one observes an important trend toward hybrid \r\nsystems, that is, systems in which discrete and continuous quantities \r\nare equally important, e.g., in the context of embedded systems. As for \r\nthe scalability, well-established techniques cannot be used easily to \r\nassess the performance of true large-scale systems, such as wireless \r\nsensor networks or gossiping protocols. For the latter, techniques based \r\non new types of abstractions, such as mean field analysis, appear most \r\npromising.\r\n\r\nAfter presenting an overview of the challenges the field is facing from \r\nan application perspective, I will address in particular our recent \r\nadvances on mean-field analysis of gossip-based systems.", :title "Dealing with the scalability challenge for model-based performance  analysis: the mean-field approach", :keyword2 "", :authors (26744), :session 269}, 1076 {:keyword1 "", :keyword3 "", :abstract "The main assumption in stochastic optimization is that  the \r\nprobability distribution of the  uncertain parameters  is known.  The \r\nambiguity  problem  weakens this assumption by defining an admissible  \r\nset of distributions which are all  good models for the uncertainty. \r\nThis implies that one searches for minimax (maximin)  solutions, that is \r\nto optimize the problem for the worst distribution among all admissible \r\nones.\r\n\r\nThis talk reviews some results of the minimax type and identifies in \r\nsome cases the worst case distributions within some balls of admissible \r\ndistributions, where a Kantorovich-type metric is employed.  The \r\napproach is especially suited, if the ambiguity set of distributions is \r\ngiven by a confidence ball based on a statistical estimation of the \r\n\"true\" distribution.\r\n\r\nThis is a joint work with David Wozabal and Alois Pichler.\r\n", :title "Ambiguity in stochastic optimization", :keyword2 "", :authors (3122), :session 270}, 1077 {:keyword1 "", :keyword3 "", :abstract "In online computation, an algorithm must make decisions without\r\nknowledge of future inputs. Online problems occur naturally\r\nacross computer science and operation research, with applications\r\nin areas such as robotics, resource allocation, network routing,\r\nand scheduling. \r\n\r\nOnline algorithms benefit from randomization. But a good number \r\nof approaches are ad-hoc and have limited scope. Our vision is \r\nto ``de-adhocify\" the approaches and gain broader insight. \r\n\r\nWe introduce the concept of knowledge states; many well-known \r\nrandomized online algorithms can be viewed as knowledge state \r\nalgorithms. The knowledge state approach can be used to\r\nto construct competitive randomized online algorithms and \r\nstudy the tradeoff between competitiveness and memory.\r\n\r\nWe give new results for the two server problem and the paging problem.  \r\nWe present a knowledge state algorithm for the two server problem \r\nover Cross Polytope Spaces with a competitive ratio of 19/12, and show \r\nthat it is optimal against the oblivious adversary.\r\nRegarding the paging problem, Borodin and El-Yaniv had listed as an\r\nopen question whether there exists an H_k-competitive randomized \r\nalgorithm which requires O(k) memory for k-paging.\r\nWe have answered this question in the affirmative using knowledge\r\nstate techniques.", :title "The Design of Randomized Online Algorithms", :keyword2 "", :authors (11624), :session 271}, 1079 {:keyword1 "Project Portfolio Selection", :keyword3 "", :abstract "The success of industrial and public organizations depends on how they succeed in choosing the projects that add most value to the organization. This semi-plenary talk reviews several widely employed decision analytic methods and considers their uses in project portfolio selection. Much of the attention is given to methods based on multi-attribute value theory (MAVT) which assist decision makers choose a project portfolio that contributes most to the organization’s overall objectives, considering the decision makers’ preferences, the performance levels and resource requirements of proposed projects, as well as possible interdependencies among the projects. However, standard MAVT methods assume that complete information in terms of exact estimates about the model parameters can be acquired, even if this can be difficult if not impossible in practice. Motivated by this realization, we describe the Robust Portfolio Modelling (RPM) approach which extends standard methods (i) by admitting incomplete information about the model parameters and (ii) by exploring the implications of such information for decision recommendations both at the level of individual projects and at the level of the entire portfolio. At best, such a staged approach improves decision quality while reducing the cost of analysis. We illustrate uses of RPM with real case studies. We also consider how project selection decisions can be assisted when the projects’ performance is contingent on a small set of scenarios whose probabilities may not be exactly known. While this approach tends to involve many parameters (i.e., all projects need to be evaluated in every scenario), the explicit consideration of scenarios makes it possible to shape the risk characteristics of project portfolios. ", :title "Uses of Decision Analysis in Project Portfolio Selection", :keyword2 "Decision Analysis", :authors (2268), :session 266}, 1080 {:keyword1 "Administrative Processes", :keyword3 "Service Oriented Architecture", :abstract "The complexity of services for cross-level administrative processes for the\r\npublic and the economy through information and communication technologies\r\n(eGovernment) can be efficiently modeled with a Service Oriented\r\nArchitecture (SOA). The integration of the Federal Republic of Germany in\r\nthe European Community, the division of work between the Federal Government\r\nof Germany and its 16 States and the constitutionally protected autonomy of\r\nmore than 4.000 cities and communities involuntarily generate a complexity,\r\nwhich is difficult to represent electronically.  The cross-level use of\r\nbasic software components for a various number of administrative software\r\napplications, like e-payment, make the use of a SOA infrastructure\r\nindispensable.", :title "Solving Complex and Electronically Based Administrative Processes with a Service Oriented Architecture (SOA)", :keyword2 "Complexity", :authors (33678), :session 273}, 1081 {:keyword1 "cooperative game", :keyword3 "nucleolus", :abstract "The data cost situation involves a group of agents each of which owns a set of pure public goods with exclusion like knowledge, information, patents, copyrights, or data. With each public good there is associated a cost figure. In accordance with the cooperative game theoretical approach, a so-called TU game called data game has been proposed by P.\r\nDehez and D. Tellone (2008). The cost of any coalition is defined as the total sum of costs of data NOT owned by the agents of the relevant coalition. The main goal is to present a necessary and sufficient condition for the so-called 1-concavity property of the data cost game.\r\nIt is shown that the 1-concavity condition covers the two cases studied by Dehez-Tellone. The first case concerns any partition of the entire data set and the second case concerns nested (weakly increasing) data sets in that the more important the agent, the larger the data set. The motivation of the study of the 1-concavity property is based on the corresponding theoretical results for solution concepts like the core and the nucleolus.\r\n", :title "Data cost games: the 1-concavity and core properties", :keyword2 "data cost game", :authors (12659 10620 2566), :session 188}, 1083 {:keyword1 "", :keyword3 "", :abstract "The subject of this thesis is \\emph{online optimization}, which deals\r\nwith making decisions in an environment where the data describing the\r\nprocess to optimize becomes available over time, \\ie \\emph{online}.\r\n\r\nThe first part of the thesis deals with algorithms for the online\r\ncontrol of complex real-world systems. We develop rigorous\r\noptimization algorithms based on Integer Programming for two\r\napplications: The automatic dispatching of a large fleet of ADAC\r\nservice vehicles and the scheduling of elevators in high rise\r\nbuildings. In particular, we propose algorithms for destination call\r\nelevator systems, in which a passenger enters his desired destination\r\nfloor already at his current floor. Based on extensive simulations, we\r\nfind that our methods improve the performance in both applications,\r\nleading to shorter waiting times for the customers/passengers.\r\n\r\nThe second part introduces a novel probabilistic analysis for online\r\nalgorithms based on the notion of stochastic dominance. Using this\r\napproach we are able to show new results for paging and bin coloring\r\nalgorithms. These results provide more detailed insights into the\r\nrelative performance of online algorithms than existing approaches.\r\n", :title "Online Optimization: Probabilistic Analysis and Algorithm Engineering", :keyword2 "", :authors (14736), :session 274}, 1084 {:keyword1 "", :keyword3 "", :abstract "This thesis proposes a comprehensive approach for the railway scheduling\r\nproblem. The input of this problem is a commercial description of intended\r\ntrain services and the goal is to generate a conflict-free detailed schedule\r\nfulfilling all the requirements. The approach consists of three description\r\nlevels and corresponding interfaces that enable a hierarchical\r\ndivide-and-conquer approach. The starting point is a formal structure for\r\ndescribing the service intention including periodicity information. As\r\ntypical timetables are neither entirely periodic nor aperiodic, a projection\r\nscheme is used to create an equivalent augmented periodic problem. This\r\naugmented periodic timetabling problem is solved first globally on an\r\naggregated topology and simplified safety model, and subsequently refined\r\nlocally by considering all details of the infrastructure and train dynamics.\r\nFinally, the generated periodic conflict-free schedule is rolled out over\r\nthe complete day to create a production plan fulfilling all requirements\r\nspecified in the service intention. The validity and practicability of the\r\napproach is demonstrated on a real-world case study for the train services\r\ncurrently in place in the Lucerne region, a highly utilised part of railway\r\nnetwork in central Switzerland.\r\n", :title "Algorithmic decision support for train scheduling in a large and highly utilised railway network", :keyword2 "", :authors (9216), :session 274}, 1085 {:keyword1 "", :keyword3 "", :abstract "This work is concerned with the development and implementation of an optimization\r\nmethod for the solution of multistage stochastic mixed-integer programs arising in energy production.\r\nWe consider a multistage stochastic mixed-integer problem, where uncertainty is described by a scenario tree. For its solution a decomposition approach is elaborated which rests on the specific structure of a multistage problem. Based on splitting the scenario tree into subtrees, we decompose the original formulation into several subproblems by relaxing new coupling constraints. With the aim of obtaining global optimal solutions, this approach is integrated into a branch-and-bound framework.\r\nIn order to support the solution process, we also investigate the polyhedral substructure which results from the description of switching processes, integrate several branching strategies, and develop a primal heuristic which generates feasible solutions with low computational effort.\r\nAs an application, we are motivated by the strong increase in electricity produced from wind energy and investigate the question of how energy storages may contribute to integrate the strongly fluctuating wind power into the electric power network. Here, we aim at optimizing the commitment of the facilities over several days minimizing the overall costs. Altogether, we obtain a stochastic multistage mixed-integer problem of high complexity.\r\nOn this basis, we evaluate the performance of the developed methods using a set of realistic test instances and discuss the resulting computational results. \r\n", :title "A Scenario Tree-Based Decomposition for Solving Multistage Stochastic Programs with Application in Energy Production", :keyword2 "", :authors (26969), :session 274}, 1086 {:keyword1 "", :keyword3 "", :abstract "We present a solution approach for the dynamic multi-level capacitated lot sizing problem (MLCLSP). The objective is to determine a cost minimizing production plan for discrete products on multiple resources. The time-varying demand is assumed to be given for every product in every period and has to be completely fulfilled. The production is located on capacity constrained resources for the different production stages.\r\nIn an iterative fashion, our Fix-and-Optimize approach solves a series of mixed-integer programs. In each of these programs all real-valued variables are treated, but only a small and iteration-specific subset of binary setup variables is optimized. A numerical study shows that the algorithm provides high-quality results and that the computational effort is moderate.\r\n", :title "Solving multi-level capacitated lot sizing problems with a Fix-and-Optimize approach", :keyword2 "", :authors (13866), :session 274}, 1087 {:keyword1 "", :keyword3 "", :abstract "Ant colony optimization (ACO) is a metaheuristic. The idea at the basis of the approach has been proposed in the early 1990's. In the following, it has become an important research area in operations research and artificial intelligence. An increasing number of researchers focus their work on ant colony optimization. Every two years, a dedicated workshop is held in Brussels, Belgium. The seventh edition will take place in 2010. A rather new international journal, entitled Swarm Intelligence, includes research on ACO as a main focus.\r\nNowadays, ant colony optimization is commonly considered as a reference metaheuristics. It is used for tackling several optimization problems, and it represents the state of the art for some of them. In the literature, ACO is object of many experimental studies. They are focused in applying this approach to new problems or to case studies. This kind of research is certainly crucial for confirming the validity of ant colony optimization. Nonetheless, the focus on empirical analysis has somehow drove the attention away from the investigation of theoretical properties and methodological aspects concerning the metaheuristic. The first theoretical papers on ACO are published around the year 2000, i.e. around ten years after the first studies on this metaheuristic.\r\nMany questions are still open, both on the theory behind ACO, and on the practice of using this approach as other metaheuristics. The contribution given with this thesis consists in answering to some of these open questions. The main area in which the research is developed is the analysis of the role of the parameters that are present in ACO algorithms. In particular, I aim at understanding how they impact on the exploration of the search space, and then on the quality of the solutions found. Intuitive relations can be pointed out among these elements. What is still missing in the literature is a definition of these relations. The works presented in this thesis represent a move in this direction. \r\nThe first aspect analyzed concerns a theoretical analysis on the relation between the values of the parameters of one of the main ACO algorithms and the exploration of the search space. I consider MAX-MIN Ant System as representative of ant algorithms. The analysis proposed is problem independent. The main four parameters of the algorithm are considered: the number of ants included in a colony, the pheromone evaporation rate and the exponent values of pheromone and heuristic measure in the state transition rule. For observing how the conclusion drawn display in practice, some experiments on the traveling salesman problem are proposed.\r\nSecondly, I study the invariance of ant colony optimization with respect to the cost unit used in the instances to tackle. The issue of the invariance of ACO algorithms to transformation of units has been explicitly raised in the literature. The performance of ACO algorithms were said to be strongly dependent on the scale of the problem. This would be a significant drawback of the metaheuristic, and would represent a limit for our analysis on the impact of the parameters on the performance achieved. In other words, if ACO were not invariant, any reasoning on the values chosen for the parameters would depend on the fact that costs are expressed in dollars instead of euros, for example. In the thesis I formally prove that this is not the case: three among the most successful ant colony optimization algorithms are actually invariant, and the reasoning can be easily extended to other ACO algorithms. \r\nFurther, I report I study that  aims at underlying the impact of the implementation effort on the performance of metaheuristics. The implementation effort is represented by the method of selection of the values of the parameters: A low effort corresponds to a random choice. A high effort corresponds to the application of a tuning procedure. Metaheuristics are said to be implemented in an out-of-the-box way in the first case, and in a custom way in the second. The custom versions perform significantly better than the out-of-the-box ones on the problem considered as a case study. Different researches may have different goals, that may justify the use of either out-of-the-box or custom versions of metaheuristics. Nonetheless, we should be aware of the fact that the results achieved may not be generalizable. By considering the method of selection of the parameters as the element of diversity, the fact that the two contexts appear clearly different, supports the intuition according to which the values of the parameters strongly impact on the performance achieved. \r\nFinally, I propose an empirical analysis that supports the intuition according to which it may be possible to find some functional form that describes the relation between the quality of the solutions found and the values of the parameters of the algorithm. \r\n", :title "ACO:  parameters, exploration and quality of solutions", :keyword2 "", :authors (9471), :session 175}, 1088 {:keyword1 "", :keyword3 "", :abstract "We present in this article the application of a site selection algorithm combining Fuzzy Sets Theory\r\nwith Structured Hierarchical Analysis (AHP). The model employs fuzzy mathematical tools, in\r\norder to analize and combine factors which are difficult to be quantified precisely, along with more\r\nquantifiable ones, though not precisely (i.e. financial variables about real estate values), which will\r\nbe formalized in a fuzzy manner, through linguistic variables, being merged this way with the first\r\nones in the overall evaluation. The same tools will be employed in the assessment of possible sites\r\nas to their suitability, according to the same factors, to the enterprise: the set up of an odontologicalclinic in the city of Rio de Janeiro.", :title "LOCATION OF AN ODONTOLOGICAL CLINIC IN RIO DE JANEIRO USING A FUZZY MULTI-CRITERIA SITE SELECTION METHOD", :keyword2 "", :authors (26995), :session 181}}, :users {205 {:firstname "Khodakaram", :lastname "Salimifard", :department "Industrial Management Department", :institution "Persian Gulf University", :country "Iran, Islamic Republic of", :sessions (137)}, 281 {:firstname "Ulrike", :lastname "Leopold-Wildburger", :department "Statistics and Operations Research", :institution "Karl-Franzens-University", :country "Austria", :sessions (193 272 273)}, 333 {:firstname "Gerhard", :lastname "Wäscher", :department "Fakultät für Wirtschaftswissenschaft", :institution "Otto-von-Guericke Universität Magdeburg", :country "Germany", :sessions (205 199)}, 694 {:firstname "Horst W.", :lastname "Hamacher", :department "Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (217)}, 770 {:firstname "Marion", :lastname "Rauner", :department "Faculty of Business, Economics, and Statistics", :institution "University of Vienna", :country "Austria", :sessions (65)}, 829 {:firstname "Rainer", :lastname "Kolisch", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (38 111 245)}, 852 {:firstname "Esma", :lastname "Gel", :department "School of Computing, Informatics and Decision Systems Engineering", :institution "Arizona State University", :country "United States", :sessions (158)}, 899 {:firstname "Geir", :lastname "Hasle", :department "Mathematics and Cybernetics", :institution "SINTEF Digital", :country "Norway", :sessions (53)}, 909 {:firstname "Martin", :lastname "Grunow", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (110)}, 926 {:firstname "Johnnie", :lastname "Johnson", :department "Centre for Risk Research", :institution "University of Southampton", :country "United Kingdom", :sessions (229)}, 1090 {:firstname "Juan José", :lastname "Salazar González", :department "Estadística e Investigación Operativa", :institution "Universidad de La Laguna (Tenerife)", :country "Spain", :sessions (54)}, 1109 {:firstname "Giselher", :lastname "Pankratz", :department "Dept. of Information Systems", :institution "FernUniversität - University of Hagen", :country "Germany", :sessions (50 209)}, 1131 {:firstname "Heinrich", :lastname "Kuhn", :department "Operations Management", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (115 116)}, 1141 {:firstname "Leena", :lastname "Suhl", :department "Dept. Business Information Systems", :institution "University of Paderborn", :country "Germany", :sessions (197 113)}, 1165 {:firstname "Roger Z.", :lastname "Rios-Mercado", :department "Graduate Program in Systems Engineering", :institution "Universidad Autonoma de Nuevo Leon", :country "Mexico", :sessions (221)}, 1182 {:firstname "M. Grazia", :lastname "Speranza", :department "Dept. of Quantitative Methods", :institution "University of Brescia", :country "Italy", :sessions (264)}, 1194 {:firstname "Natalia", :lastname "Kliewer", :department "Information Systems", :institution "Freie Universitaet Berlin", :country "Germany", :sessions (198)}, 1219 {:firstname "Otto", :lastname "Rentz", :department "Economic Engineering", :institution "institute of industrial production", :country "Germany", :sessions (167)}, 1254 {:firstname "Dorien", :lastname "DeTombe", :department "Methodology of Societal Complexity", :institution "Founder and Chair Euro Working Group", :country "Netherlands", :sessions (22 135)}, 1256 {:firstname "Teresa", :lastname "Melo", :department "Business School", :institution "Saarland University of Applied Sciences", :country "Germany", :sessions (267 201)}, 1521 {:firstname "Paola", :lastname "Zuddas", :department "Matematica e Informatica", :institution "University of Cagliari", :country "Italy", :sessions (40 133)}, 1560 {:firstname "Kathrin", :lastname "Klamroth", :department "Department of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (222)}, 1646 {:firstname "Vladimir", :lastname "Marianov", :department "Electrical Engineering", :institution "Pontificia Universidad Catolica de Chile", :country "Chile", :sessions (131)}, 1658 {:firstname "Peter", :lastname "Letmathe", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (121 160)}, 1769 {:firstname "Edite M.G.P.", :lastname "Fernandes", :department "Algoritmi Research Centre", :institution "University of Minho", :country "Portugal", :sessions (106)}, 1834 {:firstname "Alexander", :lastname "Kononov", :department "", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (148)}, 1838 {:firstname "İsmail Serdar", :lastname "Bakal", :department "Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (112)}, 1891 {:firstname "Luca", :lastname "D'Acierno", :department "Department of Civil, Architectural and Environmental Engineering", :institution "'Federico II' University of Naples", :country "Italy", :sessions (210)}, 1892 {:firstname "Bruno", :lastname "Montella", :department "Department of Civil, Architectural and Environmental Engineering", :institution "'Federico II' University of Naples", :country "Italy", :sessions (210)}, 1943 {:firstname "Mariano", :lastname "Gallo", :department "Dipartimento di Ingegneria", :institution "Università degli Studi del Sannio", :country "Italy", :sessions (210)}, 2135 {:firstname "Margarida", :lastname "Moz", :department "ISEG, Technical University of Lisbon", :institution "Centro de Investigação Operacional, University of Lisbon", :country "Portugal", :sessions (211)}, 2136 {:firstname "Margarida", :lastname "Pato", :department "", :institution "ISEG, CMAFcIO, Universidade de Lisboa", :country "Portugal", :sessions (211)}, 2139 {:firstname "Ana", :lastname "Paias", :department "DEIO - CMAFCIO", :institution "Universidade de Lisboa, Faculdade de Ciências", :country "Portugal", :sessions (211)}, 2189 {:firstname "Michel", :lastname "Gendreau", :department "MAGI and CIRRELT", :institution "Polytechnique Montréal", :country "Canada", :sessions (227)}, 2247 {:firstname "Frédéric", :lastname "Semet", :department "CRIStAL", :institution "Centrale Lille", :country "France", :sessions (52)}, 2266 {:firstname "Takashi", :lastname "Shibata", :department "Graduate School of Management", :institution "Tokyo Metropolitan University", :country "Japan", :sessions (98)}, 2268 {:firstname "Ahti", :lastname "Salo", :department "Systems Analysis Laboratory", :institution "Aalto University School of Science", :country "Finland", :sessions (109 266)}, 2336 {:firstname "Henk", :lastname "Zijm", :department "Faculty of Electrical Engineering &Mathematics and Computer Science", :institution "University of Twente", :country "Netherlands", :sessions (205)}, 2403 {:firstname "Michael", :lastname "Pidd", :department "The Management School", :institution "Lancaster University", :country "United Kingdom", :sessions (268)}, 2448 {:firstname "Herbert", :lastname "Meyr", :department "Department of Supply Chain Management", :institution "University of Hohenheim", :country "Germany", :sessions (113)}, 2476 {:firstname "Renato", :lastname "De Leone", :department "School of Science and Technologies", :institution "Università di Camerino", :country "Italy", :sessions (260 230 231)}, 2505 {:firstname "Emili", :lastname "Tortosa-Ausina", :department "Departament d'Economia", :institution "Universitat Jaume I", :country "Spain", :sessions (142)}, 2534 {:firstname "Matthew", :lastname "Carlyle", :department "Operations Research", :institution "Naval Postgraduate School", :country "United States", :sessions (195 210)}, 2566 {:firstname "Pierre", :lastname "Dejax", :department "DAPI", :institution "IMT Atlantique - LS2N", :country "France", :sessions (188)}, 2650 {:firstname "Grit", :lastname "Walther", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (268)}, 2651 {:firstname "Thomas", :lastname "Spengler", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (120 110 112 166 160)}, 2675 {:firstname "Frank", :lastname "Schultmann", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (40 167)}, 2707 {:firstname "Marta", :lastname "Mesquita", :department "ISA, CMAFCIO", :institution "University of Lisbon", :country "Portugal", :sessions (211)}, 2713 {:firstname "Michaela", :lastname "Schaffhauser-Linzatti", :department "Business Administration", :institution "University of Vienna", :country "Austria", :sessions (65)}, 2769 {:firstname "Karl", :lastname "Doerner", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (55 227 28)}, 2795 {:firstname "Oliver", :lastname "Stein", :department "Institute of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (265)}, 2801 {:firstname "Karl", :lastname "Inderfurth", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University of Magdeburg", :country "Germany", :sessions (111 112)}, 2901 {:firstname "Alexei", :lastname "Gaivoronski", :department "Industrial Economics and Technology Management", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (133)}, 3029 {:firstname "Peter", :lastname "Schuur", :department "Faculty of Technology & Management", :institution "University of Twente", :country "Netherlands", :sessions (205)}, 3122 {:firstname "Georg", :lastname "Pflug", :department "Department of Statistics and Decision Support Systems", :institution "University of Vienna", :country "Austria", :sessions (270)}, 3392 {:firstname "Said", :lastname "Salhi", :department "Kent Business School", :institution "University of Kent", :country "United Kingdom", :sessions (59)}, 3524 {:firstname "Gerhard-Wilhelm", :lastname "Weber", :department "Faculty of Engineering Management, Chair of Marketing and Economic Engineering", :institution "Poznan University of Technology", :country "Poland", :sessions (31 24 27 16 23 135 266 29 231 32)}, 3616 {:firstname "Inci", :lastname "Batmaz", :department "Department of Statistics", :institution "Middle East Technical University", :country "Turkey", :sessions (23)}, 3753 {:firstname "Robert", :lastname "Fourer", :department "", :institution "AMPL Optimization Inc.", :country "United States", :sessions (263)}, 3843 {:firstname "Bjarni", :lastname "Kristjansson", :department "", :institution "Maximal Software", :country "Iceland", :sessions (276)}, 3951 {:firstname "Alberto", :lastname "Colorni", :department "Department of Industrial Design, delle Arti e della Comunicazione", :institution "Politecnico di Milano", :country "Italy", :sessions (46)}, 4169 {:firstname "Andreas", :lastname "Brandt", :department "Wirtschaftswissenschaftliche Fakultät, Institut of Operations Research", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (129)}, 4170 {:firstname "Manfred", :lastname "Brandt", :department " Optimization ", :institution " Konrad-Zuse-Zentrum für Informationstechnik Berlin (ZIB)", :country "Germany", :sessions (129)}, 4207 {:firstname "Gabor", :lastname "Nagy", :department "Canterbury Business School", :institution "University of Kent", :country "United Kingdom", :sessions (60)}, 4224 {:firstname "Grzegorz", :lastname "Pawlak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (202)}, 4688 {:firstname "Ming-Chien", :lastname "Sung", :department "School of Management", :institution "University of Southampton", :country "United Kingdom", :sessions (229)}, 4747 {:firstname "Carlo", :lastname "Vercellis", :department "Management Economics and Industrial Engineering", :institution "Politecnico di Milano", :country "Italy", :sessions (78 260)}, 4796 {:firstname "Stefan Wolfgang", :lastname "Pickl", :department "Department of Computer Science", :institution "UBw München COMTESSA", :country "Germany", :sessions (239 27 240 178 167 226 271 127 86)}, 4837 {:firstname "Giorgio", :lastname "Gallo", :department "Informatica", :institution "University of Pisa", :country "Italy", :sessions (134 28)}, 4861 {:firstname "Gernot", :lastname "Tragler", :department "OR and Control Systems", :institution "Vienna University of Technology", :country "Austria", :sessions (181 65)}, 4889 {:firstname "Horst", :lastname "Tempelmeier", :department "Supply Chain  Management and Production", :institution "University of Cologne", :country "Germany", :sessions (115)}, 5054 {:firstname "Lambros", :lastname "Pechlivanos", :department "", :institution "Athens University of Economics and Business", :country "Greece", :sessions (94)}, 5321 {:firstname "Martin Josef", :lastname "Geiger", :department "Logistics Management Department", :institution "Helmut-Schmidt-University/ University of the Federal Armed Forces Hamburg", :country "Germany", :sessions (124 126)}, 5344 {:firstname "Bulent", :lastname "Karasozen", :department "Inst. of Appl. Mathematics", :institution "Middle East Technical University", :country "Turkey", :sessions (29)}, 5390 {:firstname "Jacek", :lastname "Blazewicz", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (146 93)}, 5454 {:firstname "Wolfgang Anthony", :lastname "Eiden", :department "", :institution "", :country "Germany", :sessions (147)}, 5500 {:firstname "bahadir", :lastname "gulsun", :department "", :institution "Yildiz Technical University", :country "Turkey", :sessions (158 76)}, 5643 {:firstname "Hermann", :lastname "Gehring", :department "", :institution "Fernuni Universitaet in Hagen", :country "Germany", :sessions (50)}, 5692 {:firstname "Andrea", :lastname "Grosso", :department "", :institution "Università di Torino", :country "Italy", :sessions (172)}, 5708 {:firstname "F.-Javier", :lastname "Heredia", :department "Statistics and Operations Research", :institution "Universitat Politècnica de Catalunya - BarcelonaTech", :country "Spain", :sessions (99)}, 5838 {:firstname "Dirk", :lastname "Briskorn", :department "", :institution "University of Wuppertal", :country "Germany", :sessions (152)}, 5885 {:firstname "Tore", :lastname "Grünert", :department "", :institution "GTS Systems and Consulting GmbH", :country "Germany", :sessions (227)}, 5931 {:firstname "Stefan", :lastname "Voss", :department "Wirtschaftsinformatik/Information Systems", :institution "University of Hamburg", :country "Germany", :sessions (50)}, 5932 {:firstname "Dennis", :lastname "Huisman", :department "Econometric Institute", :institution "Erasmus University", :country "Netherlands", :sessions (198)}, 5934 {:firstname "Nils", :lastname "Boysen", :department "Lehrstuhl für ABWL/ Operations Management", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (207)}, 5965 {:firstname "Jürgen", :lastname "Zimmermann", :department "Operations Research", :institution "TU Clausthal", :country "Germany", :sessions (179 210)}, 6136 {:firstname "Armin", :lastname "Varmaz", :department "Department of Finance", :institution "University of Bremen, Faculty of Business Studies and Economics", :country "Germany", :sessions (189)}, 6146 {:firstname "Alexandra", :lastname "Newman", :department "Division of Economics and Business", :institution "Colorado School of Mines", :country "United States", :sessions (218)}, 6218 {:firstname "Carlos Ramón", :lastname "García Alonso", :department "Management", :institution "ETEA, Business Administration Faculty. University of Córdoba. Spain", :country "Spain", :sessions (139)}, 6251 {:firstname "Frits", :lastname "Spieksma", :department "Mathematics and Computer Science", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (146)}, 6281 {:firstname "Sergei", :lastname "Chubanov", :department "", :institution "University of Siegen", :country "Germany", :sessions (105)}, 6744 {:firstname "Marielle", :lastname "Christiansen", :department "Department of Industrial Economics and Technology Management", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (57 237 264)}, 6813 {:firstname "Fernando", :lastname "Ordonez", :department "Industrial and Systems Engineering", :institution "University of Southern California", :country "United States", :sessions (179)}, 6887 {:firstname "Bjørn", :lastname "Nygreen", :department "Department of Industrial Economics and Technology Management", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (211)}, 6914 {:firstname "Manbir", :lastname "Sodhi", :department "Industrial & Manufacturing Engineering", :institution "University of Rhode Island", :country "United States", :sessions (128 172)}, 6982 {:firstname "Masakazu", :lastname "Kojima", :department "", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (84)}, 7032 {:firstname "Fernando A. C. C.", :lastname "Fontes", :department "Systec-ISR, Dept. of Electrical and Computer Engineering, Faculdade de Engenharia", :institution "Universidade do Porto", :country "Portugal", :sessions (221)}, 7309 {:firstname "Robert", :lastname "Dell", :department "Operations Research", :institution "Naval Postgraduate School", :country "United States", :sessions (210)}, 7432 {:firstname "Patrick", :lastname "De Causmaecker", :department "Computer Science, CODeS research group", :institution "KU Leuven", :country "Belgium", :sessions (179)}, 7569 {:firstname "Andreas", :lastname "Fink", :department "Chair of Information Systems", :institution "Helmut-Schmidt-University", :country "Germany", :sessions (263 124)}, 7862 {:firstname "Ali", :lastname "Azadeh", :department "Industrial Engineering", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (156)}, 8142 {:firstname "Yuri", :lastname "Stoyan", :department "Department of Mathematical Modeling and Optimal Design", :institution "Institute for Mechanical Engineering Problems of the National Academy of Sciences of Ukraine", :country "Ukraine", :sessions (100)}, 8416 {:firstname "Pedamallu", :lastname "Chandra Sekhar", :department "Department of Medical Oncology", :institution "Dana-Farber Cancer Institute", :country "United States", :sessions (24 135)}, 8459 {:firstname "Marida", :lastname "Bertocchi", :department "Department of Management, Economics and Quantitative Methods", :institution "University of Bergamo", :country "Italy", :sessions (70)}, 8513 {:firstname "Johann", :lastname "Hurink", :department "Department of Applied Mathematics", :institution "University of Twente", :country "Netherlands", :sessions (205 162)}, 8542 {:firstname "Ceyda", :lastname "Oguz", :department "Department of Industrial Engineering", :institution "Koc University", :country "Turkey", :sessions (146)}, 8657 {:firstname "Hubertus Th.", :lastname "Jongen", :department "Dept. Mathematics", :institution "RWTH Aachen University", :country "Germany", :sessions (63)}, 8732 {:firstname "Guido", :lastname "Sand", :department "Corporate Research Germany", :institution "ABB AG", :country "Germany", :sessions (213)}, 8892 {:firstname "Markus", :lastname "Arnold", :department "Department of Social Economics", :institution "Universität Hamburg", :country "Germany", :sessions (121)}, 8923 {:firstname "Zeev (Vladimir)", :lastname "Volkovich", :department "", :institution "Ort Braude Academic College", :country "Israel", :sessions (32)}, 8942 {:firstname "Linet", :lastname "Ozdamar", :department "Industrial & Systems Engineering Department", :institution "Yeditepe University", :country "Turkey", :sessions (135)}, 8981 {:firstname "Ralf", :lastname "Werner", :department "Institut für Mathematik", :institution "Universität Augsburg", :country "Germany", :sessions (77 154)}, 9122 {:firstname "Alexander", :lastname "Bolshoy", :department "Evolutionary Biology", :institution "University of Haifa", :country "Israel", :sessions (32)}, 9150 {:firstname "Kurt", :lastname "Chudej", :department "Lehrstuhl für Ingenieurmathematik", :institution "University of Bayreuth", :country "Germany", :sessions (99)}, 9182 {:firstname "Carmen", :lastname "Anido", :department "Economic Analysis: Quantitatve Economy", :institution "Autonoma University of Madrid", :country "Spain", :sessions (230)}, 9216 {:firstname "Gabrio Curzio", :lastname "Caimi", :department "Netzentwicklung", :institution "BLS Netz AG", :country "Switzerland", :sessions (274)}, 9272 {:firstname "Achim", :lastname "Koberstein", :department "Information and Operations Management", :institution "European University Viadrina Frankfurt (Oder)", :country "Germany", :sessions (109 91 197 113)}, 9278 {:firstname "VITO", :lastname "FRAGNELLI", :department "", :institution "Università del Piemonte Orientale ", :country "Italy", :sessions (139)}, 9422 {:firstname "Stefan", :lastname "Lessmann", :department "School of Business and Economics", :institution "Humboldt-University of Berlin", :country "Germany", :sessions (229)}, 9471 {:firstname "Paola", :lastname "Pellegrini", :department "Applied Mathematics", :institution "Ca' Foscari University", :country "Italy", :sessions (175)}, 9512 {:firstname "Rüdiger", :lastname "Schultz", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (270)}, 9524 {:firstname "Julia", :lastname "Rieck", :department "Operations Research Group", :institution "University of Hildesheim", :country "Germany", :sessions (210)}, 9578 {:firstname "Gregor", :lastname "Dorfleitner", :department "Dep. of Finance", :institution "University  of Regensburg", :country "Germany", :sessions (96)}, 9583 {:firstname "Dries", :lastname "Goossens", :department "Business Informatics and Operations Management", :institution "Ghent University", :country "Belgium", :sessions (146)}, 9667 {:firstname "Robert", :lastname "Gillenkirch", :department "Department of Finance, Accounting and Taxes", :institution "Georg-August-University of Göttingen", :country "Germany", :sessions (121)}, 9736 {:firstname "Rachid", :lastname "Chelouah", :department "95011", :institution "EISTI ", :country "France", :sessions (229)}, 9758 {:firstname "Lino", :lastname "Costa", :department "ALGORITMI Research Centre", :institution "University of Minho", :country "Portugal", :sessions (101 106)}, 9821 {:firstname "Frank", :lastname "Hennig", :department "Department of Industrial Economics and Technology Management", :institution "Norwegian University of Science and Technology", :country "Norway", :sessions (211)}, 9841 {:firstname "Teofilo", :lastname "Valdes", :department "Statistics and Operations Research", :institution "Complutense University of Madrid", :country "Spain", :sessions (230)}, 9921 {:firstname "Maria Teresa", :lastname "Vespucci", :department "Department of Management, Information and Production Engineering", :institution "University of Bergamo", :country "Italy", :sessions (163)}, 9925 {:firstname "Elisabetta", :lastname "Allevi", :department "Department of Economics and Management", :institution "University of Brescia", :country "Italy", :sessions (70)}, 10000 {:firstname "Laura", :lastname "Palagi", :department "Dipartimento di Ingegneria  informatica automatica e gestionale", :institution "La Sapienza Università di Roma ", :country "Italy", :sessions (79)}, 10025 {:firstname "Steven", :lastname "Prestwich", :department "Computer Science", :institution "Insight Centre for Data Analytics", :country "Ireland", :sessions (138)}, 10054 {:firstname "Mario", :lastname "Innorta", :department "", :institution "University of Bergamo", :country "Italy", :sessions (163)}, 10057 {:firstname "Brigitte", :lastname "Werners", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (37 157 162 278)}, 10087 {:firstname "Oliver", :lastname "Bastert", :department "", :institution "FICO", :country "Germany", :sessions (43)}, 10162 {:firstname "Silja", :lastname "Meyer-Nieberg", :department "Department of Computer Science", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (126)}, 10255 {:firstname "Raik", :lastname "Stolletz", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (159)}, 10297 {:firstname "Ovidiu", :lastname "Listes", :department "", :institution "AIMMS", :country "Netherlands", :sessions (104)}, 10323 {:firstname "Gad", :lastname "Rabinowitz", :department "Department of Industrial Engineering and Management", :institution "Ben Gurion University of the Negev", :country "Israel", :sessions (159)}, 10347 {:firstname "Apostolos", :lastname "Kotsialos", :department "School of Engineering and Computing Sciences", :institution "Durham University", :country "United Kingdom", :sessions (202)}, 10496 {:firstname "Nadia", :lastname "Maïzi", :department "Center for Applied mathematics", :institution "MINES ParisTech", :country "France", :sessions (178)}, 10504 {:firstname "Gilles", :lastname "Guerassimoff", :department "Centre for Applied Mathematics", :institution "Mines ParisTech", :country "France", :sessions (178)}, 10538 {:firstname "Richard", :lastname "Hartl", :department "Business Admin", :institution "University of Vienna", :country "Austria", :sessions (28)}, 10542 {:firstname "Michael", :lastname "Bussieck", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (91)}, 10620 {:firstname "Anna", :lastname "Khmelnitskaya", :department "Faculty of Applied Mathematics", :institution "St.Petersburg State University", :country "Russian Federation", :sessions (193 188)}, 10744 {:firstname "Mohsen", :lastname "Elhafsi", :department "School of Business Administration", :institution "University of California", :country "United States", :sessions (111)}, 10785 {:firstname "Edward", :lastname "Gimadi", :department "Discrete Optimization in Operations Research", :institution "Sobolev Institute of Mathematics", :country "Russian Federation", :sessions (213)}, 10803 {:firstname "Kevin", :lastname "Glazebrook", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (116)}, 10811 {:firstname "Cristinca", :lastname "Fulga", :department "Department of Applied Mathematics", :institution "The Bucharest University of Economic Studies", :country "Romania", :sessions (74)}, 10871 {:firstname "Diethard", :lastname "Klatte", :department "IBW", :institution "Universität Zürich", :country "Switzerland", :sessions (63)}, 10929 {:firstname "Frans", :lastname "de Rooij", :department "", :institution "AIMMS", :country "Netherlands", :sessions (104 258 29)}, 10957 {:firstname "Pakize", :lastname "Taylan", :department "Mathematics", :institution "Dicle University", :country "Turkey", :sessions (31 29)}, 11028 {:firstname "Sureyya", :lastname "Ozogur-Akyuz", :department "Department of Mathematics Engineering", :institution "Bahcesehir University", :country "Turkey", :sessions (231)}, 11072 {:firstname "Basak", :lastname "Akteke-Ozturk", :department "Department of Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (29)}, 11105 {:firstname "Giovanni", :lastname "Sechi", :department "Dept. of Land Engineering", :institution "University of Cagliari", :country "Italy", :sessions (40 133)}, 11148 {:firstname "Wolfgang", :lastname "Polasek", :department "Economics and Finance", :institution "IHS Wien", :country "Austria", :sessions (206)}, 11448 {:firstname "Tobias", :lastname "Buer", :department "Logistics, Tourism and Service Management", :institution "GUtech", :country "Oman", :sessions (209)}, 11624 {:firstname "Wolfgang", :lastname "Bein", :department "Department of Computer Science", :institution "University of Nevada, Las Vegas", :country "United States", :sessions (179 271)}, 11732 {:firstname "Erwin", :lastname "Hans", :department "School of Management and Governance", :institution "University of Twente", :country "Netherlands", :sessions (267)}, 11750 {:firstname "Seyda", :lastname "Serdar Asan", :department "Industrial Engineering", :institution "Istanbul Technical University", :country "Turkey", :sessions (118)}, 11762 {:firstname "Josep", :lastname "Freixas", :department "Matemàtiques", :institution "Universitat Politècnica de Catalunya", :country "Spain", :sessions (188)}, 11783 {:firstname "Vito", :lastname "Fragnelli", :department "", :institution "Università del Piemonte Orientale", :country "Italy", :sessions (193)}, 11799 {:firstname "David", :lastname "Pisinger", :department "DTU Management", :institution "Technical University of Denmark", :country "Denmark", :sessions (49)}, 11875 {:firstname "Tatiana", :lastname "Romanova", :department "Department of Mathematical Modeling and Optimal Design", :institution "Institute for Mechanical Engineering Problems of the National Academy of Sciences of Ukraine", :country "Ukraine", :sessions (100)}, 12179 {:firstname "Mark", :lastname "Körner", :department "Mathematik", :institution "Institut für Numerische und Angewandte Mathematik", :country "Germany", :sessions (100)}, 12245 {:firstname "H.A.", :lastname "Eiselt", :department "", :institution "University of New Brunswick", :country "Canada", :sessions (131)}, 12264 {:firstname "Erik", :lastname "Kropat", :department "Department of Computer Science", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (23 135 32)}, 12412 {:firstname "Maria João", :lastname "Alves", :department "", :institution "Faculty of Economics of University of Coimbra / INESC - Coimbra", :country "Portugal", :sessions (106)}, 12453 {:firstname "Florian", :lastname "Jaehn", :department "Management Science and Operations Research", :institution "Helmut-Schmidt-University - University of the Federal Armed Forces Hamburg", :country "Germany", :sessions (207)}, 12477 {:firstname "Sirma Zeynep", :lastname "Alparslan Gok", :department "Mathematics", :institution "Faculty of Arts and Sciences, Suleyman Demirel University", :country "Turkey", :sessions (16 32)}, 12659 {:firstname "Theodorus S.H. ", :lastname "Driessen", :department "Department of Applied Mathematics ", :institution "University of Twente", :country "Netherlands", :sessions (193 188)}, 12666 {:firstname "Stefan", :lastname "Ruzika", :department "Mathematik", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (217 219 214 225)}, 12718 {:firstname "Katja", :lastname "Poser", :department "Faculty of Business and Economics", :institution "University of Jena", :country "Germany", :sessions (139)}, 12756 {:firstname "João Paulo", :lastname "Costa", :department "", :institution "Faculty of Economics, University of Coimbra / INESC-Coimbra", :country "Portugal", :sessions (106)}, 12769 {:firstname "Eleni", :lastname "Pratsini", :department "", :institution "IBM Zurich Research Lab", :country "Switzerland", :sessions (138)}, 12787 {:firstname "Fabián", :lastname "Flores-Bazán", :department "Departamento de Ingeniería Matemática", :institution "Universidad de Concepción", :country "Chile", :sessions (194)}, 12922 {:firstname "Susanne", :lastname "Lind-Braucher", :department "", :institution "TU Graz", :country "Austria", :sessions (142)}, 12952 {:firstname "Dirk Christian", :lastname "Mattfeld", :department "Business Information Systems", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (50 227)}, 13058 {:firstname "Andreas", :lastname "Bley", :department "Mathematics", :institution "Uni Kassel", :country "Germany", :sessions (214)}, 13201 {:firstname "Tomomi", :lastname "Matsui", :department "Department of Social Engineering", :institution "Tokyo Institute of Technology", :country "Japan", :sessions (220 194 221)}, 13264 {:firstname "Stephan", :lastname "Meisel", :department "Carl-Friedrich Gauss Department", :institution "University of Braunschweig", :country "Germany", :sessions (50 227)}, 13273 {:firstname "Franco", :lastname "Robledo", :department "Operations Research Department", :institution "Universidad de la República", :country "Uruguay", :sessions (218)}, 13364 {:firstname "Matthias", :lastname "Amen", :department "Chair for Quantitative Accounting & Financial Reporting", :institution "Bielefeld University", :country "Germany", :sessions (261 122)}, 13503 {:firstname "Thomas", :lastname "Volling", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (120 110 112 166 160)}, 13531 {:firstname "Maria Pilar", :lastname "Martinez-Garcia", :department "Metodos Cuantitativos para la Economia", :institution "Universidad de Murcia", :country "Spain", :sessions (102)}, 13680 {:firstname "Tim", :lastname "Hultberg", :department "", :institution "EUMETSAT", :country "Germany", :sessions (91)}, 13837 {:firstname "Uwe T.", :lastname "Zimmermann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (145 274 211)}, 13857 {:firstname "Aleksey", :lastname "Glebov", :department "Discrete Analysis and Operations Research", :institution "Sobolev Instititute of Mathematics", :country "Russian Federation", :sessions (213)}, 13866 {:firstname "Florian", :lastname "Sahling", :department "Chair of Production Management", :institution "University of Kaiserslautern", :country "Germany", :sessions (274 161)}, 13887 {:firstname "Thorsten", :lastname "Poddig", :department "Faculty 7: Business Studies & Economics; Department of Finance", :institution "University of Bremen", :country "Germany", :sessions (189)}, 13893 {:firstname "Nikolay", :lastname "Kosarev", :department "R&D", :institution "DELMIA Quintiq, Dassault Systemes B.V.", :country "Netherlands", :sessions (221)}, 14155 {:firstname "John J.", :lastname "Kanet", :department "Operations Management - Niehaus Chair in Operations Management", :institution "University of Dayton", :country "United States", :sessions (152)}, 14225 {:firstname "Lars", :lastname "Moench", :department "", :institution "FernUniversität in Hagen", :country "Germany", :sessions (126)}, 14267 {:firstname "Fernando", :lastname "Ramos", :department "LAC", :institution "INPE", :country "Brazil", :sessions (100)}, 14307 {:firstname "Beatriz", :lastname "Abdul-Jalbar", :department "", :institution "Universidad de La Laguna", :country "Spain", :sessions (119)}, 14545 {:firstname "Roland", :lastname "Mestel", :department "Banking and Finance", :institution "University of Graz", :country "Austria", :sessions (142)}, 14587 {:firstname "Pradyumn Kumar", :lastname "Shukla", :department "", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (76)}, 14609 {:firstname "Alexander", :lastname "Brauneis", :department "", :institution "University of Klagenfurt", :country "Austria", :sessions (142)}, 14661 {:firstname "Andreas", :lastname "Schoppmeyer", :department "Fachgebiet Operations Research und Wirtschaftsinformatik", :institution "Technische Universität Dortmund", :country "Germany", :sessions (209)}, 14704 {:firstname "Felix", :lastname "Hahne", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (209)}, 14705 {:firstname "Curt", :lastname "Nowak", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (209)}, 14707 {:firstname "Christian", :lastname "Bierwirth", :department "", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (138)}, 14715 {:firstname "Alf", :lastname "Kimms", :department "Mercator School of Management", :institution "University of Duisburg-Essen, Campus Duisburg", :country "Germany", :sessions (92 199)}, 14736 {:firstname "Benjamin", :lastname "Hiller", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (274 212)}, 14742 {:firstname "Sigrid", :lastname "Knust", :department "Institute of Computer Science", :institution "University of Osnabrück", :country "Germany", :sessions (146 148)}, 14775 {:firstname "Katsuaki", :lastname "Tanaka", :department "Faculty of Business Administration", :institution "Setsunan University", :country "Japan", :sessions (99 95)}, 14777 {:firstname "Sven", :lastname "de Vries", :department "FB IV - Mathematik", :institution "Uni Trier", :country "Germany", :sessions (222)}, 14778 {:firstname "Jan-Hendrik", :lastname "Jagla", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (104)}, 14796 {:firstname "Andreas", :lastname "Tuchscherer", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (212)}, 14800 {:firstname "Stefan", :lastname "Bock", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (227 152)}, 14803 {:firstname "Klaus ", :lastname "Ambrosi", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "Universität Hildesheim", :country "Germany", :sessions (209)}, 14810 {:firstname "Ursula", :lastname "Walther", :department "FB 1", :institution "Berlin School of Economics and Law", :country "Germany", :sessions (74)}, 14817 {:firstname "Ralph", :lastname "Grothmann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (228 85 163 95)}, 14818 {:firstname "Hans Georg", :lastname "Zimmermann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (164 228 85 162 95)}, 14840 {:firstname "Pavel", :lastname "Borisovsky", :department "Applied mathematics and information systems", :institution "Omsk State Technical University", :country "Russian Federation", :sessions (221)}, 14847 {:firstname "Andreas", :lastname "Klose", :department "Department of Mathematics", :institution "Aarhus University", :country "Denmark", :sessions (47)}, 14853 {:firstname "Franz", :lastname "Nelissen", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (104)}, 14856 {:firstname "Francesco", :lastname "Ferrucci", :department "WINFOR (Business Computing and Operations Research)", :institution "University of Wuppertal", :country "Germany", :sessions (227)}, 14863 {:firstname "Alexander", :lastname "Richter", :department "Business Administration and Production Management", :institution "Ruhr University Bochum", :country "Germany", :sessions (157)}, 14865 {:firstname "Marion", :lastname "Steven", :department "Business Administration and Production Management", :institution "Ruhr-University Bochum", :country "Germany", :sessions (156)}, 14869 {:firstname "Martin", :lastname "Albrecht", :department "Process and Information Management", :institution "Paul Hartmann AG", :country "Germany", :sessions (113)}, 14876 {:firstname "Dominik", :lastname "Möst", :department "Chair of Energy Economics", :institution "Technische Universität Dresden", :country "Germany", :sessions (163)}, 14887 {:firstname "Ralf", :lastname "Stecking", :department "Fakultät II - Institut für VWL und Statistik", :institution "Universität Oldenburg", :country "Germany", :sessions (125)}, 14890 {:firstname "Andreas", :lastname "Kleine", :department "Operations Research", :institution "FernUniversität in Hagen (University of Hagen)", :country "Germany", :sessions (234)}, 14898 {:firstname "Lutz", :lastname "Westermann", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (104)}, 14909 {:firstname "Karl", :lastname "Nachtigall", :department "Faculty of Transport and Traffic Sciences, Institut for Logistics and Aviation", :institution "Technical University of Dresden", :country "Germany", :sessions (206)}, 14923 {:firstname "Ralf", :lastname "Borndörfer", :department "Optimization", :institution "Zuse-Institute Berlin", :country "Germany", :sessions (208 202)}, 14946 {:firstname "Christoph", :lastname "Tietz", :department "Corporate Technology, CT IC 4", :institution "Siemens AG", :country "Germany", :sessions (228 85 95)}, 14965 {:firstname "Anton", :lastname "Eremeev", :department "Discrete Optimization", :institution "Sobolev Institute of Mathematics SB RAS, Omsk Branch", :country "Russian Federation", :sessions (221)}, 14966 {:firstname "Sergey", :lastname "Klokov", :department "", :institution "Sobolev Institute of Mathematics SB RAS, Omsk Branch", :country "Russian Federation", :sessions (221)}, 14969 {:firstname "Marco", :lastname "Lübbecke", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (220 211 212)}, 14973 {:firstname "Michael", :lastname "Drexl", :department "", :institution ".", :country "Germany", :sessions (200)}, 15051 {:firstname "Eugenio", :lastname "Mijangos", :department "Applied Mathematics and Statistics and Operations Research", :institution "UPV/EHU", :country "Spain", :sessions (99)}, 15059 {:firstname "Marika", :lastname "Neumann", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (202)}, 15060 {:firstname "Jens", :lastname "Brunner", :department "Chair of Health Care Operations/Health Information Management", :institution "Faculty of Business and Economics, University of Augsburg", :country "Germany", :sessions (111 37)}, 15080 {:firstname "Susanna", :lastname "Reiss", :department "Fakultät für Mathematik", :institution "TU Chemnitz", :country "Germany", :sessions (222)}, 15127 {:firstname "Thomas", :lastname "Bousonville", :department "Business and Administration", :institution "Hochschule für Technik und Wirtschaft des Saarlandes", :country "Germany", :sessions (201)}, 15150 {:firstname "Christian", :lastname "Viergutz", :department "Institut für Informatik", :institution "Universität Osnabrück", :country "Germany", :sessions (245)}, 15153 {:firstname "Soeren", :lastname "Koch", :department "Management Science", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (205)}, 15154 {:firstname "Joachim R.", :lastname "Daduna", :department "", :institution "Hochschule für Wirtschaft und Recht Berlin Berlin", :country "Germany", :sessions (200)}, 15178 {:firstname "Kerstin", :lastname "Schmidt", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (112)}, 15182 {:firstname "Urs", :lastname "Pietschmann", :department "Faculty of Management and Economics", :institution "Ruhr-University Bochum", :country "Germany", :sessions (157)}, 15195 {:firstname "Harald", :lastname "Uhlemair", :department "Chair of Production and Logistics", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (134)}, 15205 {:firstname "Saad", :lastname "Hasson", :department "Computer Sciences", :institution "IRAQ / Faculty of sciences / University of Babylon", :country "Iraq", :sessions (130 181)}, 15277 {:firstname "Herbert", :lastname "Kopfer", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (50 197 201)}, 15313 {:firstname "Erdal", :lastname "Emel", :department "Industrial Engineering Department", :institution "Uludag University", :country "Turkey", :sessions (196)}, 15321 {:firstname "Marco", :lastname "Schuler", :department "Fakultät für Informatik", :institution "Universität der Bundeswehr", :country "Germany", :sessions (178)}, 15322 {:firstname "Alkin", :lastname "Yurtkuran", :department "Industrial Engineering Department", :institution "Uludag University", :country "Turkey", :sessions (196)}, 15375 {:firstname "Ronny", :lastname "Hansmann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (203 211)}, 15381 {:firstname "Andreas", :lastname "Thümmel", :department "FB MN", :institution "Hochschule Darmstadt", :country "Germany", :sessions (166)}, 15383 {:firstname "Verena", :lastname "Gondek", :department "Department of Mathematics", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (145)}, 15390 {:firstname "Kai", :lastname "Wittek", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (110)}, 15398 {:firstname "Stefan", :lastname "Schmidt", :department "Institute of Management", :institution "Ruhr-University Bochum", :country "Germany", :sessions (162)}, 15432 {:firstname "Oliver", :lastname "Grasl", :department "", :institution "transentis management consulting GmbH & Co. KG", :country "Germany", :sessions (169)}, 15433 {:firstname "Karl-Heinz", :lastname "Küfer", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (175)}, 15579 {:firstname "Edson Tadeu", :lastname "Bez", :department "", :institution "Univali", :country "Afghanistan", :sessions (23)}, 15580 {:firstname "Yogesh", :lastname "Agarwal", :department "Decision Sciences Group", :institution "Indian Institue of Management, Lucknow", :country "India", :sessions (218)}, 15586 {:firstname "Antonio G.N.", :lastname "Novaes", :department "Industrial Engineering", :institution "Federal University of Santa Catarina", :country "Brazil", :sessions (43)}, 15665 {:firstname "Mangesh", :lastname "Gharote", :department "SJM School of Management", :institution "Indian Institute of Technology, Bombay", :country "India", :sessions (147)}, 15802 {:firstname "Verena", :lastname "Schmid", :department "Supply Chain Management", :institution "Europa-Universität Viadrina", :country "Germany", :sessions (50)}, 15827 {:firstname "Vera", :lastname "Hemmelmayr", :department "", :institution "Vienna University of Economics and Business (WU)", :country "Austria", :sessions (28)}, 15857 {:firstname "Johannes", :lastname "Ruhland", :department "University of Jena", :institution "Faculty of Business and Economics", :country "Germany", :sessions (124 139 225)}, 15858 {:firstname "Peter", :lastname "Vojtas", :department "Software Engineering", :institution "Charles University", :country "Czech Republic", :sessions (234)}, 15915 {:firstname "Lionel", :lastname "Amodeo", :department "Charles Delaunay Institute", :institution "University of Technology of Troyes", :country "France", :sessions (152)}, 16003 {:firstname "Farouk", :lastname "Yalaoui", :department "Institut Charles Delaunay, ICD LOSI", :institution "University of Technology of Troyes", :country "France", :sessions (152)}, 16259 {:firstname "Stéphane", :lastname "Dauzere-Peres", :department "Manufacturing Sciences and Logistics", :institution "Ecole des Mines de Saint-Etienne - LIMOS", :country "France", :sessions (115)}, 16305 {:firstname "Claudius", :lastname "Steinhardt", :department "Chair of Business Analytics & Management Science", :institution "Bundeswehr University Munich (UniBw)", :country "Germany", :sessions (92 94)}, 16562 {:firstname "Daniel", :lastname "Ziegler", :department "Chair for Management Sciences and Energy Economics", :institution "University Duisburg-Essen", :country "Germany", :sessions (162)}, 16606 {:firstname "Jörg", :lastname "Rambau", :department "Fakultät für Mathematik, Physik und Informatik", :institution "LS Wirtschaftsmathematik", :country "Germany", :sessions (217)}, 16672 {:firstname "Stefan", :lastname "Theussl", :department "Raiffeisen RESEARCH", :institution "Raiffeisen Bank International AG", :country "Austria", :sessions (228)}, 16717 {:firstname "Cornelius", :lastname "Schwarz", :department "Chair of Business Mathematics", :institution "University of Bayreuth", :country "Germany", :sessions (217)}, 16785 {:firstname "Aleksandra", :lastname "Marcikic", :department "", :institution "University of Novi Sad, Faculty of Economics Subotica", :country "Serbia", :sessions (163)}, 16852 {:firstname "Marco", :lastname "Schutten", :department "MB / OMPL", :institution "University of Twente", :country "Netherlands", :sessions (205)}, 16870 {:firstname "Katja", :lastname "Schimmelpfeng", :department "Lehrstuhl für Beschaffung und Produktion", :institution "Universität Hohenheim", :country "Germany", :sessions (37 161)}, 16877 {:firstname "Philipp", :lastname "Melchiors", :department "Lehrstuhl für technische Dienstleistungen und Operations Management", :institution "Technische Universität München: Fakultät für Wirtschaftswissenschaften", :country "Germany", :sessions (245)}, 16924 {:firstname "Marcus", :lastname "Schröter", :department "Industry and Service Innovations", :institution "Fraunhofer Institut for Systems and Innovation Research", :country "Germany", :sessions (169)}, 16938 {:firstname "Victor", :lastname "Izhutkin", :department "Applied Mathematik", :institution "National Research University Moscow Power  Engineering Institute", :country "Russian Federation", :sessions (86)}, 16971 {:firstname "Lars", :lastname "Hackstein", :department "Transportation Logistics", :institution "Fraunhofer Institute for Material Flow and Logistics", :country "Germany", :sessions (43 210)}, 16988 {:firstname "Frank", :lastname "Fischer", :department "Mathematics and Natural Sciences", :institution "University of Kassel", :country "Germany", :sessions (207)}, 17006 {:firstname "Christoph", :lastname "Helmberg", :department "Fakultät für Mathematik", :institution "Technische Universität Chemnitz", :country "Germany", :sessions (105 207 160 222)}, 17038 {:firstname "Michael", :lastname "Römer", :department "Juristische und Wirtschaftswissenschaftliche Fakultät", :institution "Martin-Luther-Universität Halle-Wittenberg", :country "Germany", :sessions (206)}, 17043 {:firstname "Werner", :lastname "Heid", :department "", :institution "PTV AG", :country "Germany", :sessions (196)}, 17049 {:firstname "Isabel", :lastname "Espírito Santo", :department "ALGORITMI Research Centre", :institution "University of Minho", :country "Portugal", :sessions (106)}, 17075 {:firstname "Hans", :lastname "Daduna", :department "Department of Mathematics", :institution "University of Hamburg", :country "Germany", :sessions (129 130)}, 17090 {:firstname "Marcus", :lastname "Schweitzer", :department "Fachbereich 5", :institution "University of Siegen", :country "Germany", :sessions (160)}, 17093 {:firstname "Angela", :lastname "Herrmann", :department "Department of Business Administration", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (138)}, 17103 {:firstname "Christian", :lastname "Lerch", :department "Industrial and Service Innovations", :institution "Fraunhofer Institute for Systems and Innovation Research", :country "Germany", :sessions (44 169)}, 17112 {:firstname "Ralf", :lastname "Sprenger", :department "Chair of Enterprise-wide Software Systems", :institution "University of Hagen", :country "Germany", :sessions (126)}, 17120 {:firstname "Lars", :lastname "Petersen", :department "Business Management", :institution "Alanus University of Arts and Social Sciences", :country "Germany", :sessions (160)}, 17127 {:firstname "Marco", :lastname "Laumanns", :department "", :institution "Bestmile SA", :country "Switzerland", :sessions (138)}, 17130 {:firstname "Matthias Gerhard", :lastname "Wichmann", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (160)}, 17134 {:firstname "Felix G.", :lastname "König", :department "", :institution "TomTom International B.V.", :country "Germany", :sessions (216 118)}, 17140 {:firstname "Stephan", :lastname "Wagner", :department "Department of Management, Technology, and Economics", :institution "Swiss Federal Institute of Technology Zurich (ETH Zurich)", :country "Switzerland", :sessions (109)}, 17141 {:firstname "Kurt", :lastname "Hornik", :department "Department of Statistics and Mathematics", :institution "Wirtschaftsuniversitaet Wien", :country "Austria", :sessions (228)}, 17152 {:firstname "Alexander", :lastname "Bordetsky", :department "Information Sciences", :institution "NPS Monterey", :country "United States", :sessions (127)}, 17158 {:firstname "Gerald", :lastname "Lach", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (220)}, 17174 {:firstname "Motohiro", :lastname "Hagiwara", :department "School of Commerce", :institution "Meiji University", :country "Japan", :sessions (95)}, 17284 {:firstname "Björn", :lastname "Görder", :department "Institut für Mathematik", :institution "TU Clausthal", :country "Germany", :sessions (168)}, 17331 {:firstname "Christian", :lastname "Rathjen", :department "", :institution "Dassault Systèmes", :country "Germany", :sessions (152)}, 17344 {:firstname "Hideki", :lastname "Katsuda", :department "Schoolo of Business Admninistration", :institution "Kinki University", :country "Japan", :sessions (95)}, 17358 {:firstname "Sebastian", :lastname "Rachuba", :department "Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (37)}, 17364 {:firstname "Karsten", :lastname "Kieckhäfer", :department "Chair of Business Administration, esp. Resource Management", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (43 166)}, 17366 {:firstname "Demet", :lastname "Cetiner", :department "", :institution "Mercator School of Management, University of Duisburg-Essen ", :country "Germany", :sessions (92)}, 17396 {:firstname "Hassan", :lastname "Salehi Fathabadi", :department "School of Mathematics,Statistics and Computer science", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (219)}, 17401 {:firstname "Seyed Amir Hooman", :lastname "Hasani Farmand", :department "", :institution "Department of Industrial Engineering, University of Tehran", :country "Iran, Islamic Republic of", :sessions (156)}, 17428 {:firstname "Stefan", :lastname "Helber", :department "Inst. f. Produktionswirtschaft", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (37 161)}, 17495 {:firstname "Sadi", :lastname "Fadda", :department "Faculty of Business Administration", :institution "International University of Sarajevo", :country "Bosnia and Herzegovina", :sessions (230)}, 17524 {:firstname "Xin", :lastname "Wang", :department "Business Studies & Economics, University of Bremen", :institution "Chair of Logistics", :country "Germany", :sessions (197 201)}, 17686 {:firstname "Uli", :lastname "Suppa", :department "Institut für Wirtschaftsinformatik", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (50)}, 17774 {:firstname "Anne", :lastname "Meyer", :department "", :institution "TU Dortmund University", :country "Germany", :sessions (201)}, 17910 {:firstname "Mariana Rodica", :lastname "Branzei", :department "Faculty of Computer Science ", :institution "\"Alexandru Ioan Cuza'' University", :country "Romania", :sessions (16)}, 18215 {:firstname "Annette", :lastname "Hohenberger", :department "", :institution "Middle East Technical University (METU)", :country "Turkey", :sessions (22)}, 18385 {:firstname "Carlotta", :lastname "Orsenigo", :department "Management, Economics and Industrial Engineering", :institution "Politecnico di Milano", :country "Italy", :sessions (78)}, 18428 {:firstname "Nikolai", :lastname "Chernov", :department "Department of Mathematics", :institution "University of Alabama at Birmingham", :country "United States", :sessions (100)}, 18430 {:firstname "Hanife", :lastname "Akar", :department "Department of Educational Sciences", :institution "Middle East Technical University", :country "Turkey", :sessions (135)}, 18460 {:firstname "Georg", :lastname "Peters", :department "", :institution "Munich University of Applied Sciences & Australian Catholic University", :country "Germany", :sessions (125)}, 18508 {:firstname "Angela", :lastname "Testi", :department "Department of Economics and Quantitative Methods (DIEM)", :institution "University of Genova", :country "Italy", :sessions (65)}, 18528 {:firstname "Steffen", :lastname "Marx", :department "", :institution "Luftverkehrsoptimierung.de", :country "Germany", :sessions (206)}, 18553 {:firstname "Tobias", :lastname "Scheffel", :department "", :institution "TU München", :country "Germany", :sessions (193)}, 18630 {:firstname "Simon", :lastname "Poon", :department "School of Information Technologies", :institution "University of Sydney", :country "Australia", :sessions (125)}, 18767 {:firstname "Georg", :lastname "Ziegler", :department "IBIS, Informatics, TU München", :institution "", :country "Germany", :sessions (193)}, 18846 {:firstname "Ilya", :lastname "Katsev", :department "", :institution "National Research University Higher School of Economics, St. Petersburg, Russian Federation", :country "Russian Federation", :sessions (193)}, 18872 {:firstname "Joern", :lastname "Meissner", :department "", :institution "Kuehne Logistics University", :country "Germany", :sessions (116)}, 18947 {:firstname "Cor", :lastname "van Dijkum", :department "Methodology and Statistics", :institution "Utrecht University", :country "Netherlands", :sessions (22 135)}, 18948 {:firstname "Niek", :lastname "Lam", :department "Methodology and Statistics", :institution "utrecht university", :country "Netherlands", :sessions (22 135)}, 18961 {:firstname "Tim ", :lastname "Hoheisel", :department "Institute of Mathematics", :institution "University of Würzburg", :country "Germany", :sessions (63)}, 19030 {:firstname "Xu", :lastname "Chaojun", :department "Corporate Research Germany", :institution "ABB AG", :country "Germany", :sessions (213)}, 19032 {:firstname "Kiyoshi", :lastname "Sawada", :department "Department of Economic Information", :institution "University of Marketing and Distribution Sciences", :country "Japan", :sessions (225)}, 19059 {:firstname "Jochen", :lastname "Gorski", :department "Department of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (222)}, 19076 {:firstname "Jens", :lastname "Poppenborg", :department "Institute of Applied Stochastics and Operations Research", :institution "Clausthal University of Technology", :country "Germany", :sessions (148)}, 19080 {:firstname "Hans-Jörg", :lastname "von Mettenheim", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (78 85)}, 19092 {:firstname "Marc", :lastname "Klages", :department "Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (85)}, 19095 {:firstname "Deniz", :lastname "Türsel Eliiyi", :department "Industrial Engineering", :institution "Yasar University", :country "Turkey", :sessions (160)}, 19100 {:firstname "Michael H.", :lastname "Breitner", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (78 85)}, 19122 {:firstname "Martin", :lastname "Mevissen", :department "", :institution "IBM Research - Ireland", :country "Ireland", :sessions (84)}, 19188 {:firstname "Nadjib", :lastname "Brahimi", :department "Industrial Engineering and Management", :institution "University of Sharjah", :country "United Arab Emirates", :sessions (115)}, 19268 {:firstname "Boris", :lastname "Krostitz", :department "'Verkehrsmodelle und Simulation' (GSU 1)", :institution "Deutsche Bahn AG, Konzernentwicklung", :country "Germany", :sessions (207)}, 19309 {:firstname "M. Murat", :lastname "Albayrakoglu", :department "Business Informatics Program", :institution "Istanbul Bilgi University", :country "Turkey", :sessions (76)}, 19320 {:firstname "Michael", :lastname "Schneider", :department "Deutsche Post Chair of Optimization of Distribution Networks", :institution "RWTH Aachen", :country "Germany", :sessions (196)}, 19332 {:firstname "Guido", :lastname "Diepen", :department "", :institution "AIMMS", :country "Netherlands", :sessions (104 207)}, 19340 {:firstname "Francesco", :lastname "Rinaldi", :department "Dipartimento Informatica e Sistemistica", :institution "Sapienza", :country "Italy", :sessions (79)}, 19462 {:firstname "Sleman", :lastname "Saliba", :department "Power Generation", :institution "ABB AG", :country "Germany", :sessions (220 221 213)}, 19474 {:firstname "Neele", :lastname "Hansen", :department "", :institution "ITWM Fraunhofer ", :country "Germany", :sessions (213)}, 19525 {:firstname "Vadim", :lastname "Strijov", :department "", :institution "Russian Academy of Sciences, FRC Computer Science and Control", :country "Russian Federation", :sessions (86)}, 19532 {:firstname "Klaus-Christian", :lastname "Maassen", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (199)}, 19553 {:firstname "Anna", :lastname "von Heusinger", :department "Institute of Mathematics", :institution "University of Würzburg", :country "Germany", :sessions (84)}, 19559 {:firstname "Denis", :lastname "Karlow", :department "Wirtschaftsinformatik", :institution "Frankfurt School of Finance & Management", :country "Germany", :sessions (228)}, 19565 {:firstname "Peter", :lastname "Rossbach", :department "Wirtschaftsinformatik", :institution "Frankfurt School of Finance & Management", :country "Germany", :sessions (228)}, 19571 {:firstname "Christoph", :lastname "Nolden", :department "Institute for Industrial Production (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (163)}, 19575 {:firstname "Roswitha", :lastname "Bultmann", :department "Institute for Mathematical Methods in Economics (IWM), Research Unit for Operations Research and Control Systems (ORCOS)", :institution "Vienna University of Technology", :country "Austria", :sessions (181)}, 19620 {:firstname "Bronislovas", :lastname "Kaulakys", :department "", :institution "Institute of Theoretical Physics and Astronomy , Vilnius University", :country "Lithuania", :sessions (97)}, 19699 {:firstname "Lale", :lastname "Ozbakir", :department "Industrial Engineering", :institution "Erciyes University", :country "Turkey", :sessions (158)}, 19815 {:firstname "Xavier", :lastname "Molinero", :department "Mathematics", :institution "Universitat Politècnica de Catalunya · BarcelonaTech", :country "Spain", :sessions (188)}, 19833 {:firstname "José María", :lastname "Alonso_meijide", :department "Statistics and Operations Research", :institution "Universidade de Santiago", :country "Spain", :sessions (188)}, 19902 {:firstname "Taieb", :lastname "Mellouli", :department "Business Information Systems and Operations Research", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (229 211)}, 19917 {:firstname "Susumu", :lastname "Saito", :department "Faculty of Economics", :institution "Sophia University", :country "Japan", :sessions (95)}, 19977 {:firstname "Vlad", :lastname "Kucher", :department "", :institution "Frankfurt Institute for Advanced Studies, Goethe University Frankfurt am Main", :country "Germany", :sessions (166)}, 19999 {:firstname "Michael", :lastname "Schwind", :department "IT-based Logistics", :institution "Goethe University Frankfurt", :country "Germany", :sessions (196)}, 20155 {:firstname "Dolgor", :lastname "Zambalaeva", :department "Discrete Analysis and Operations Research", :institution "Sobolev Instititute of Mathematics", :country "Russian Federation", :sessions (213)}, 20167 {:firstname "Oliver", :lastname "Kleine", :department "Industry and Service Innovations", :institution "Fraunhofer Institut for Systems and Innovation Research", :country "Germany", :sessions (44 169)}, 20232 {:firstname "Erkan", :lastname "Kalayci", :department "METU", :institution "Institute of Applied Mathematics", :country "Turkey", :sessions (23)}, 20288 {:firstname "Leo", :lastname "Kroon", :department "Rotterdam School of Management", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (198)}, 20420 {:firstname "Rolf", :lastname "Möhring", :department "", :institution "Beijing Institute for Scientific and Engineering Computing", :country "China", :sessions (212)}, 20485 {:firstname "Ayse", :lastname "Özmen", :department "Mathematics and Statistics", :institution "University of Calgary", :country "Canada", :sessions (23)}, 20599 {:firstname "Rafael", :lastname "Diaz", :department "Virginia Modeling, Analysis, & Simulation Center ", :institution "Old Dominion University", :country "United States", :sessions (116 161)}, 20607 {:firstname "Vladimir", :lastname "Shikhman", :department "", :institution "TU Chemnitz", :country "Germany", :sessions (63 84)}, 20714 {:firstname "İlknur", :lastname "Atasever Güvenç", :department "Department of Mathematics", :institution "Anadolu University", :country "Turkey", :sessions (103)}, 20715 {:firstname "Mahide", :lastname "Kucuk", :department "Department of Mathematics", :institution "Anadolu University", :country "Turkey", :sessions (103)}, 20717 {:firstname "Yalcin", :lastname "Kucuk", :department "Department of Mathematics", :institution "Anadolu University", :country "Turkey", :sessions (103)}, 20723 {:firstname "Marco", :lastname "Sciandrone", :department "Dipartimento di Ingegneria dell'Informazione", :institution "Universita' di Firenze", :country "Italy", :sessions (79)}, 20852 {:firstname "Hongying", :lastname "Fei", :department "Production and Operations Management", :institution "FUCAM (Catholic University of Mons)", :country "Belgium", :sessions (207)}, 20933 {:firstname "Rina Manuela ", :lastname "Contini", :department "Literature, Arts and Social Sciences", :institution "University of Chieti-Pescara", :country "Italy", :sessions (28)}, 20937 {:firstname "Kathrin", :lastname "Fischer", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology (TUHH)", :country "Germany", :sessions (93 198)}, 20942 {:firstname "Antonio", :lastname "Maturo", :department "Social Sciences", :institution "University of Chieti - Pescara", :country "Italy", :sessions (28)}, 20972 {:firstname "Bo", :lastname "Hu", :department "Department of Management", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (82 7 88)}, 21056 {:firstname "Eren", :lastname "Özceylan", :department "Industrial Engineering", :institution "Natural and Applied Sciences", :country "Turkey", :sessions (23)}, 21077 {:firstname "Andrei", :lastname "DMITRUK", :department "CEMI ", :institution "Russian Academy of Sciences", :country "Russian Federation", :sessions (106)}, 21117 {:firstname "Peter", :lastname "Scholz", :department "Banking & Finance", :institution "Hamburg School of Business Administration", :country "Germany", :sessions (181)}, 21140 {:firstname "Stephan", :lastname "Buetikofer", :department "Institute of Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (63)}, 21496 {:firstname "Amirhossein", :lastname "Sadoghi", :department "Finance Department", :institution "Frankfurt School of Finance & Management", :country "Germany", :sessions (231)}, 21574 {:firstname "Susanne", :lastname "Heipcke", :department "Xpress Optimization", :institution "FICO", :country "France", :sessions (206)}, 21992 {:firstname "Erfan", :lastname "Younesi", :department "Bioinformatics", :institution "Fraunhofer SCAI", :country "Germany", :sessions (25)}, 22108 {:firstname "Markus", :lastname "Siegle", :department "Computer Science", :institution "Universitaet der Bundeswehr Muenchen", :country "Germany", :sessions (132 172 241 269)}, 22109 {:firstname "Tino", :lastname "Krug", :department "Inf1", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (19 27)}, 22122 {:firstname "Fred", :lastname "Wenstøp", :department "Strategy and Logistics", :institution "BI Norwegian Business School", :country "Norway", :sessions (26 135)}, 22145 {:firstname "Dolores", :lastname "Romero Morales", :department "", :institution "Copenhagen Business School", :country "Denmark", :sessions (48)}, 22180 {:firstname "Daniel", :lastname "Roesch", :department "", :institution "Universität Regensburg", :country "Germany", :sessions (262)}, 22274 {:firstname "Israel", :lastname "Tirkel", :department "Industrial Engineering & Management", :institution "Ben-Gurion University", :country "Israel", :sessions (159)}, 22306 {:firstname "Karl", :lastname "Morasch", :department "Wirtschafts- und Organisationswissenschaften", :institution "Universitaet der Bundeswehr Muenchen", :country "Germany", :sessions (236 192 259 195 272)}, 22309 {:firstname "Zuzana", :lastname "Oplatkova", :department "Dept. of Applied Informatics", :institution "Tomas Bata University in Zlin", :country "Czech Republic", :sessions (31 23)}, 22383 {:firstname "Alexander", :lastname "Gouberman", :department "Institut für Technische Informatik", :institution "ITIS e.V. an der Universität der Bundeswehr München", :country "Germany", :sessions (132)}, 22442 {:firstname "Fatma", :lastname "Yerlikaya Özkurt", :department "Industrial Engineering", :institution "Atılım University", :country "Turkey", :sessions (29)}, 22466 {:firstname "Johann", :lastname "Schuster", :department "Informatik 3", :institution "University of the Federal Armed Forces Munich", :country "Germany", :sessions (131)}, 22515 {:firstname "Khaled", :lastname "Sellami", :department "LMA Laboratory", :institution "Bejaia University", :country "Algeria", :sessions (229)}, 22533 {:firstname "Lynda", :lastname "Sellami", :department "Sciences de Gestion", :institution "Université de Bejaia", :country "Algeria", :sessions (229)}, 22534 {:firstname "Mohamed", :lastname "Ahmed-Nacer", :department "USTHB", :institution "Laboratoire des systèmes informatique", :country "Algeria", :sessions (229)}, 22544 {:firstname "Boris", :lastname "Hu", :department "", :institution "", :country "Germany", :sessions (18)}, 22603 {:firstname "Annette", :lastname "Kluge", :department "Business Psychology", :institution "University of Duisburg-Essen", :country "Germany", :sessions (30)}, 22670 {:firstname "Mahdi", :lastname "Shadalooee", :department "Industrial Engineering", :institution "Islamic Azad University, South Tehran Branch, Iran", :country "Iran, Islamic Republic of", :sessions (86)}, 22691 {:firstname "Alexander", :lastname "Hübner", :department "Supply and Value Chain Management", :institution "Technical University Munich", :country "Germany", :sessions (116)}, 22744 {:firstname "Roberto", :lastname "Burlando", :department "Economics", :institution "University of Turin", :country "Italy", :sessions (28)}, 22814 {:firstname "Martin", :lastname "Skutella", :department "Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (217 199)}, 22850 {:firstname "Yuri", :lastname "Skiba", :department "Mathematical Modelling of Atmospheric Processes", :institution "Centro de Ciencias de la Atmósfera, Universidad Nacional Autónoma de México", :country "Mexico", :sessions (173 133)}, 22897 {:firstname "Bettina", :lastname "Berning", :department "Decision Support Systems", :institution "Fraunhofer SCS", :country "Germany", :sessions (205)}, 22934 {:firstname "LABADI", :lastname "Nacima", :department "ROSAS", :institution "University of Technology of Troyes", :country "France", :sessions (178)}, 22941 {:firstname "Neele", :lastname "Hansen", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (216)}, 22954 {:firstname "Wolf", :lastname "Fichtner", :department "Chair of Energy Economics", :institution "KIT", :country "Germany", :sessions (163)}, 22964 {:firstname "Francesc", :lastname "Carreras", :department "Applied Mathematics II", :institution "Technical University of Catalonia", :country "Spain", :sessions (188)}, 22994 {:firstname "Jochen", :lastname "Gönsch", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (92 93)}, 23007 {:firstname "Shu Wo", :lastname "Lai", :department "", :institution "The Chinese University of Hong Kong", :country "Hong Kong", :sessions (220)}, 23097 {:firstname "Khaoula", :lastname "HAMDI", :department "ROSAS", :institution "UTT", :country "France", :sessions (178)}, 23121 {:firstname "Janos D.", :lastname "Pinter", :department "Industrial and Systems Engineering", :institution "Lehigh University, USA and PCS Inc., Canada.", :country "United States", :sessions (148)}, 23143 {:firstname "Shaghayegh", :lastname "Rezaei", :department "Textile Engineering", :institution ", Islamic Azad University, Science and Research Branch", :country "Iran, Islamic Republic of", :sessions (213)}, 23189 {:firstname "Franz", :lastname "Rendl", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (105)}, 23205 {:firstname "Ali", :lastname "Mert", :department "Statistics", :institution "Ege University", :country "Turkey", :sessions (199)}, 23268 {:firstname "Greet", :lastname "Vanden Berghe", :department "Computer Science", :institution "KU Leuven", :country "Belgium", :sessions (179)}, 23271 {:firstname "Johannes", :lastname "Siebert", :department "Business Administration ", :institution "University of Bayreuth", :country "Germany", :sessions (234)}, 23282 {:firstname "Michael", :lastname "Schilde", :department "Department of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (227)}, 23389 {:firstname "Bernhard", :lastname "Ertl", :department "", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (33)}, 23417 {:firstname "Maria Franca", :lastname "Norese", :department "Dipartimento di Ingegneria Gestionale e della Produzione - DIGEP", :institution "Politecnico di Torino", :country "Italy", :sessions (180)}, 23449 {:firstname "Stefan Markus", :lastname "Giebel", :department "Faculty of Right and Economy", :institution "University of Luxembourg", :country "Germany", :sessions (16 125)}, 23455 {:firstname "Alexandra", :lastname "Hartmann", :department "Business School", :institution "University of Applied Sciences, Saarland", :country "Germany", :sessions (201)}, 23456 {:firstname "Florian", :lastname "Potra", :department "Mathematics & Statistics", :institution "University of Maryland, Baltimore County", :country "United States", :sessions (70)}, 23479 {:firstname "CAO Y", :lastname "NGUYEN", :department "Civil and Environmental System Engineering", :institution "Nagaoka University of Technology", :country "Japan", :sessions (197)}, 23499 {:firstname "Dalila", :lastname "Fontes", :department "", :institution "LIAAD, INESC TEC, Faculdade de Economia do Porto, Universidade do Porto", :country "Portugal", :sessions (221)}, 23511 {:firstname "Jenny", :lastname "Nossack", :department "Institute of Information Systems", :institution "University of Siegen", :country "Germany", :sessions (201)}, 23531 {:firstname "Louis", :lastname "Caccetta", :department "Mathematics and Statistics", :institution "Curtin University of Technology", :country "Australia", :sessions (94)}, 23543 {:firstname "Serhan", :lastname "Duran", :department "Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (94)}, 23560 {:firstname "Chiara", :lastname "Novello", :department "DISPEA", :institution "Politecnico di Torino", :country "Italy", :sessions (180)}, 23582 {:firstname "David", :lastname "Alderson", :department "Operations Research Dept.", :institution "Naval Postgraduate School", :country "United States", :sessions (195)}, 23601 {:firstname "Mercedes ", :lastname "Bustos", :department "Lima", :institution "Volcan Cia. Minera SAA", :country "Peru", :sessions (22)}, 23674 {:firstname "MEHMET", :lastname "SARIOGLAN", :department "Tourism", :institution "Social Science", :country "Turkey", :sessions (117)}, 23689 {:firstname "Alice", :lastname "Yalaoui", :department "ROSAS", :institution "UTT", :country "France", :sessions (178)}, 23717 {:firstname "Jan", :lastname "Pelikan", :department "Econometrics", :institution "University of Economics Prague", :country "Czech Republic", :sessions (145)}, 23719 {:firstname "Gennady", :lastname "Zabudsky", :department "Laboratory of Discrete Optimization", :institution "Omsk Branch of Sobolev Institute of Mathematics Siberian Branch of Russian Academy of Sciences", :country "Russian Federation", :sessions (214)}, 23886 {:firstname "Jannes", :lastname "Verstichel", :department "Computer Science", :institution "KU Leuven Technology Campus Ghent", :country "Belgium", :sessions (179)}, 23959 {:firstname "Ceren", :lastname "Erdin Gundogdu", :department "Business Administration", :institution "Yildiz Technical Univercity", :country "Turkey", :sessions (197)}, 23961 {:firstname "Mehmet", :lastname "Can", :department "", :institution "", :country "Bosnia and Herzegovina", :sessions (97)}, 23978 {:firstname "Alexander", :lastname "Vasin", :department "The Department of Operations Research", :institution "Moscow State University - Faculty of Computational Mathematics and Cybernetics", :country "Russian Federation", :sessions (86)}, 23985 {:firstname "Guanwei", :lastname "Jang", :department "Logistics Management", :institution "National Defense University", :country "Taiwan, Province of China", :sessions (43)}, 24007 {:firstname "Vladimir", :lastname "Bulavsky", :department "Experimental Economics", :institution "Central Economics and Mathematics Institute (CEMI)", :country "Russian Federation", :sessions (192)}, 24015 {:firstname "Francesca", :lastname "Maggioni", :department "Department of Management, Economics and Quantitative Methods", :institution "University of  Bergamo", :country "Italy", :sessions (70)}, 24048 {:firstname "Ron", :lastname "Adany", :department "Computer Science", :institution "Bar-Ilan University", :country "Israel", :sessions (179)}, 24144 {:firstname "Viacheslav", :lastname "Kalashnikov", :department "School of Engineering and Sciences (EIC)", :institution "ITESM, Campus Monterrey", :country "Mexico", :sessions (192)}, 24151 {:firstname "Daniel", :lastname "Tuyttens", :department "Mathematics and Operations Research", :institution "University of Mons", :country "Belgium", :sessions (207)}, 24175 {:firstname "Lucian", :lastname "Ionescu", :department "Department of Information Systems", :institution "Freie Universität Berlin", :country "Germany", :sessions (198)}, 24311 {:firstname "Laura", :lastname "Marí", :department "Statistics and Operations Research", :institution "Univ. Politecnica de Catalunya", :country "Spain", :sessions (162)}, 24314 {:firstname "Narcis", :lastname "Nabona", :department "Statistics and Operations Research", :institution "Univ. Politecnica de Catalunya", :country "Spain", :sessions (162)}, 24325 {:firstname "Gürkan", :lastname "Üstünkar", :department "Industrial Engineering", :institution "Gediz University", :country "Turkey", :sessions (231)}, 24377 {:firstname "Sarit", :lastname "Kraus", :department "", :institution "Bar-Ilan University", :country "Israel", :sessions (179)}, 24508 {:firstname "Maryam", :lastname "Asadiyan", :department "", :institution "", :country "Iran, Islamic Republic of", :sessions (231)}, 24510 {:firstname "Vahid", :lastname "Taslimi", :department "", :institution "", :country "Iran, Islamic Republic of", :sessions (231)}, 24583 {:firstname "Oliver", :lastname "Wendt", :department "Business Research & Economics", :institution "University of Kaiserslautern", :country "Germany", :sessions (126)}, 24622 {:firstname "Jutta", :lastname "Geldermann", :department "Chair of Business Administration and Production Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (134)}, 24676 {:firstname "Ahmad", :lastname "Tanekar", :department "Graduate School of Management and Economics ", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (76)}, 24717 {:firstname "Luminita", :lastname "Duta", :department "Automation and Computer Science", :institution "Valahia University Romania", :country "Romania", :sessions (39)}, 24762 {:firstname "Apostolos", :lastname "Fertis", :department "IFOR, D-MATH", :institution "ETH Zürich", :country "Switzerland", :sessions (77)}, 24773 {:firstname "Christoph", :lastname "Weber", :department "", :institution "University Duisburg-Essen", :country "Germany", :sessions (162)}, 24823 {:firstname "Helmut", :lastname "Niessner", :department "", :institution "Simplan Optimizations e.U.", :country "Austria", :sessions (65)}, 24840 {:firstname "Vladimir", :lastname "Soloviev", :department "Department of Applied Mathematics", :institution "Institute for Humanities and Information Technology, Moscow, Russia", :country "Russian Federation", :sessions (192)}, 24892 {:firstname "Sarah ", :lastname "Behbahaninezhad", :department "Industrial Management Department ", :institution "Persian Gulf University", :country "Iran, Islamic Republic of", :sessions (137)}, 24902 {:firstname "Daniele", :lastname "Vigo", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (196 28)}, 24910 {:firstname "S.G.R.", :lastname "Jalali-Naini", :department "Industrial Engineering", :institution "Iran University of Science and Technology", :country "Iran, Islamic Republic of", :sessions (155)}, 24916 {:firstname "Constantin-Bala", :lastname "Zamfirescu", :department "Automation", :institution "Lucian Blaga University of Sibiu", :country "Romania", :sessions (39)}, 24921 {:firstname "Kostja", :lastname "Siefen", :department "DS&OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (197)}, 24924 {:firstname "Antonio", :lastname "Sassano", :department "", :institution "Università di Roma \"La Sapienza\"", :country "Italy", :sessions (79)}, 24975 {:firstname "Sven", :lastname "Spieckermann", :department "Management Board", :institution "SimPlan AG", :country "Germany", :sessions (68)}, 24983 {:firstname "Artem", :lastname "Lagzdin", :department "Laboratory of Discrete Optimization", :institution "Omsk Branch of Sobolev Institute of Mathematics Siberian Branch of Russian Academy of Sciences", :country "Russian Federation", :sessions (214)}, 25005 {:firstname "Thomas", :lastname "Fischer", :department "Faculty of Business and Economics", :institution "University of Jena", :country "Germany", :sessions (124)}, 25028 {:firstname "Andreas", :lastname "Stenger", :department "IT-based Logistics", :institution "Goethe University Frankfurt", :country "Germany", :sessions (196)}, 25095 {:firstname "Hassan", :lastname "Javanshir", :department "", :institution "Islamic Azad University", :country "Iran, Islamic Republic of", :sessions (86)}, 25150 {:firstname "Milad", :lastname "Nozari", :department "Graduate school of management and economics (GSME)", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (97)}, 25312 {:firstname "Volker", :lastname "Engels", :department "", :institution "Fraunhofer IML", :country "Germany", :sessions (173 133)}, 25320 {:firstname "Friederike", :lastname "Wall", :department "Dept. for Controlling and Strategic Management", :institution "Alpen-Adria-Universitaet Klagenfurt", :country "Austria", :sessions (122 168)}, 25350 {:firstname "Jesco", :lastname "Humpola", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (155)}, 25356 {:firstname "Yoshitaka", :lastname "Takahashi", :department "Faculty of Commerce", :institution "Waseda University", :country "Japan", :sessions (130 132)}, 25363 {:firstname "Andreas", :lastname "Frey", :department "Faculty of Business Management and Social Sciences", :institution "University of Applied Sciences Osnabrueck", :country "Germany", :sessions (132)}, 25364 {:firstname "Yoshiaki", :lastname "Shikata", :department "Faculty of Informatics for Arts", :institution "Shobi University", :country "Japan", :sessions (130 132)}, 25442 {:firstname "Elmar", :lastname "Reucher", :department "Quantitative Methoden und Wirtschaftsmathematik", :institution "FernUniversität in Hagen", :country "Germany", :sessions (65)}, 25563 {:firstname "Christian", :lastname "Doppstadt", :department "Logistics and Supply Chain Management", :institution "Goethe University Frankfurt", :country "Germany", :sessions (196)}, 25631 {:firstname "Selcuk", :lastname "Karakaya", :department "Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (112)}, 25650 {:firstname "Faiz", :lastname "Hamid", :department "Information Technology & Decision Sciences", :institution "Indian Institute of Management, Lucknow, India", :country "India", :sessions (218)}, 25674 {:firstname "Wolfgang", :lastname "Achtziger", :department "Department of Mathematics", :institution "Friedrich-Alexander University Erlangen-Nürnberg", :country "Germany", :sessions (265)}, 25676 {:firstname "Christiane", :lastname "Barz", :department "Institute of Business Administration", :institution "University of Zurich", :country "Switzerland", :sessions (149 245)}, 25742 {:firstname "Aline", :lastname "Soterroni", :department "Applied Computing", :institution "National Institute for Space Research (INPE)", :country "Brazil", :sessions (100)}, 25783 {:firstname "Aysen", :lastname "Apaydin", :department "", :institution "Ankara University", :country "Turkey", :sessions (230)}, 25791 {:firstname "Michael", :lastname "Hiete", :department "Institute for Industrial Production (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (40)}, 25812 {:firstname "Roberto Luiz", :lastname "Galski", :department "Satellite Tracking and Control Center", :institution "National Institute for Space Research (INPE)", :country "Brazil", :sessions (100)}, 25933 {:firstname "Jochen", :lastname "Schurr", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (116)}, 25943 {:firstname "Selim ", :lastname "Mankai", :department "Economics", :institution "University of Paris Ouest Nanterre la Défense", :country "France", :sessions (142)}, 25958 {:firstname "Juan Carlos", :lastname "Matallin-Saez", :department "Finance and Accounting", :institution "Universitat Jaume I", :country "Spain", :sessions (142)}, 25972 {:firstname "Pelin", :lastname "Yasar", :department "industial engineering", :institution "Kadir Has University", :country "Turkey", :sessions (133)}, 25975 {:firstname "David", :lastname "Parra Guevara", :department "", :institution "Centro de Ciencias de la Atmósfera, UNAM", :country "Mexico", :sessions (133)}, 26056 {:firstname "Anja", :lastname "Egbers", :department "Business Administration and Production Management", :institution "Ruhr-University Bochum", :country "Germany", :sessions (156)}, 26058 {:firstname "Joachim", :lastname "Gwinner", :department "Aerospace Department", :institution "Universitaet der Bundeswehr Muenchen", :country "Germany", :sessions (87)}, 26117 {:firstname "Stephan", :lastname "Leitner", :department "Department of Controlling and Strategic Management", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (168)}, 26119 {:firstname "Jedrzej", :lastname "Musial", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (93)}, 26121 {:firstname "Marco", :lastname "Schulze", :department "Operations Research Group", :institution "Clausthal University of Technology", :country "Germany", :sessions (179)}, 26151 {:firstname "Stephanie", :lastname "Vogelgesang", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University Magdeburg", :country "Germany", :sessions (111)}, 26155 {:firstname "Hauke", :lastname "Bartusch", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (167)}, 26156 {:firstname "Feray", :lastname "Odman Çelikçapa", :department "Business Administration", :institution "Uludag University", :country "Turkey", :sessions (128)}, 26158 {:firstname "Katherina", :lastname "Brink", :department "Business Adminstration & Economics", :institution "Bielefeld University", :country "Germany", :sessions (121)}, 26159 {:firstname "Anja", :lastname "Wolter", :department "Institut für Produktionswirtschaft", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (159)}, 26166 {:firstname "Serdar", :lastname "Gunal", :department "Business Administration", :institution "Uludag University", :country "Turkey", :sessions (128)}, 26167 {:firstname "Jonathan", :lastname "Ott", :department "Institute for Stochastics", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (70)}, 26172 {:firstname "Karl H.", :lastname "Mueller", :department "", :institution "WISDOM", :country "Austria", :sessions (167)}, 26176 {:firstname "Gagik", :lastname "Kirakossian", :department "Computing Sciences", :institution "State Engineering University of Armenia", :country "Armenia", :sessions (155)}, 26178 {:firstname "Ruben", :lastname "Kirakossian", :department "Computing Sciences", :institution "State Engineering University of Armenia", :country "Armenia", :sessions (155)}, 26180 {:firstname "Marko", :lastname "Hofmann", :department "", :institution "ITIS", :country "Germany", :sessions (175 168)}, 26181 {:firstname "Kei", :lastname "Takahashi", :department "Center for Mathematics and Data Science", :institution "Gunma University", :country "Japan", :sessions (74 226)}, 26182 {:firstname "Peter", :lastname "Grundke", :department "", :institution "University of Osnabrueck", :country "Germany", :sessions (98)}, 26184 {:firstname "Mario", :lastname "Straßberger", :department "", :institution "Hochschule Zittau/Görlitz", :country "Germany", :sessions (98)}, 26188 {:firstname "Elisabeth", :lastname "Schumacher", :department "", :institution "University of Osnabrück", :country "Germany", :sessions (146)}, 26190 {:firstname "Li", :lastname "Luo", :department "Lehrstuhl für Mathematische Optimierung ", :institution "Heinrich-Heine-Universität, Düsseldorf", :country "Germany", :sessions (175)}, 26191 {:firstname "Tabea", :lastname "Grebe", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (175)}, 26194 {:firstname "Thomas", :lastname "Krieger", :department "", :institution "ITIS GmbH", :country "Germany", :sessions (129 195 194)}, 26197 {:firstname "Christian", :lastname "Schwede", :department "", :institution "Fraunhofer IML", :country "Germany", :sessions (113)}, 26199 {:firstname "Simone", :lastname "D'Alessandro", :department "Scienze Economiche", :institution "University of Pisa", :country "Italy", :sessions (134)}, 26205 {:firstname "Polina", :lastname "Kononova", :department "Operation Research", :institution "Sobolev Institute of Mathematics of SBRAS", :country "Russian Federation", :sessions (145)}, 26207 {:firstname "Sowmya", :lastname "Somanath", :department "Electronics and Communication", :institution "PES Institute of Technology", :country "India", :sessions (212)}, 26210 {:firstname "Robert", :lastname "Rieg", :department "Faculty of Business", :institution "Aalen University", :country "Germany", :sessions (44)}, 26211 {:firstname "Sarah", :lastname "Schuelke", :department "", :institution "FernUniversitaet in Hagen", :country "Germany", :sessions (43)}, 26217 {:firstname "Sigifredo", :lastname "Laengle", :department "Department of Management Control", :institution "University of Chile", :country "Chile", :sessions (194)}, 26218 {:firstname "Pietro", :lastname "Piazzolla", :department "Computer Sciences", :institution "University of Torino", :country "Italy", :sessions (172)}, 26221 {:firstname "Anastasiya", :lastname "Gordeeva", :department "", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (213)}, 26222 {:firstname "Eugeniya", :lastname "Ivonina", :department "Mechanics and Mathematics Department", :institution "Novosibirsk State University", :country "Russian Federation", :sessions (213)}, 26224 {:firstname "Jayashree", :lastname "D", :department "Information Science", :institution "PES Institute of Technology", :country "India", :sessions (147)}, 26250 {:firstname "Martin", :lastname "Groß", :department "Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (219)}, 26251 {:firstname "Tibor", :lastname "Dulai", :department "Department of Electrical Engineering and Information Systems", :institution "University of Pannonia", :country "Hungary", :sessions (196)}, 26252 {:firstname "Abel", :lastname "Solera", :department "Hidráulica y Medio Ambiente", :institution "Universidad Politénica de Valencia", :country "Spain", :sessions (40)}, 26253 {:firstname "Javier", :lastname "Paredes", :department "", :institution "Universidad Politécnica de Valencia", :country "Spain", :sessions (40)}, 26254 {:firstname "Joaquín", :lastname "Andreu", :department "", :institution "Universidad Politécnica de Valencia", :country "Spain", :sessions (40)}, 26255 {:firstname "Víctor M.", :lastname "Arqued", :department "Oficina de Planificación Hidrológica", :institution "Confederación Hidrográfica del Duero", :country "Spain", :sessions (40)}, 26257 {:firstname "Enisha", :lastname "Eshwar", :department "Information Science & Engineering", :institution "PES Institute of Technology", :country "India", :sessions (212)}, 26259 {:firstname "Rudolf", :lastname "Avenhaus", :department "Fakultät für Informatik", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (188 194)}, 26261 {:firstname "Florian", :lastname "Bartholomae", :department "", :institution "Universitaet der Bundeswehr Muenchen", :country "Germany", :sessions (192 195)}, 26263 {:firstname "Yike", :lastname "Hu", :department "Business Information Systems and Operations Research", :institution "University of  Kaiserslautern", :country "Germany", :sessions (126)}, 26264 {:firstname "Katharina", :lastname "Amann", :department "Chair of Production and Logistics", :institution "Georg-August-University Goettingen", :country "Germany", :sessions (178)}, 26266 {:firstname "Paulo Alexandre", :lastname "Silva Pereira", :department "Mathematics and Applications", :institution "University of Minho", :country "Portugal", :sessions (221)}, 26269 {:firstname "Kellyn", :lastname "Rein", :department "", :institution "Fraunhofer FKIE", :country "Germany", :sessions (229)}, 26270 {:firstname "Ulrich", :lastname "Schade", :department "", :institution "Fraunhofer FKIE", :country "Germany", :sessions (229)}, 26272 {:firstname "Margarete", :lastname "Donovang-Kuhlisch", :department "EMEA PS CTO Team", :institution "IBM Deutschland GmbH", :country "Germany", :sessions (229 118)}, 26273 {:firstname "Stefanie", :lastname "Schlutter", :department "Optimization", :institution "Fraunhofer SCS", :country "Germany", :sessions (216)}, 26274 {:firstname "Harald", :lastname "Kinateder", :department "", :institution "Universität Passau", :country "Germany", :sessions (97)}, 26275 {:firstname "Niklas", :lastname "Wagner", :department "", :institution "Passau University", :country "Germany", :sessions (97)}, 26280 {:firstname "Atilla", :lastname "Yalcin", :department "DS&OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (109)}, 26281 {:firstname "Jennifer", :lastname "Mylosz", :department "Department of Mathematics", :institution "University of Hamburg", :country "Germany", :sessions (129)}, 26282 {:firstname "Jacint", :lastname "Szabo", :department "Business Optimization", :institution "IBM Research Lab, Zurich", :country "Switzerland", :sessions (155)}, 26285 {:firstname "Thomas", :lastname "Loy", :department "", :institution "Bielefeld University", :country "Germany", :sessions (122)}, 26286 {:firstname "Friedhelm", :lastname "Kulmann", :department "Quantitative Methoden und Wirtschaftsmathematik", :institution "FernUniversität in Hagen", :country "Germany", :sessions (88)}, 26288 {:firstname "Kathrin", :lastname "Armborst", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (175)}, 26291 {:firstname "Elena", :lastname "Pervukhina", :department "Information Systems", :institution "Sevastopol State University", :country "Russian Federation", :sessions (107)}, 26292 {:firstname "Wolfgang A.", :lastname "Welz", :department "Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (217)}, 26293 {:firstname "Ágnes", :lastname "Stark-Werner", :department "Department of Electrical Engineering and Information Systems", :institution "University of Pannonia", :country "Hungary", :sessions (196)}, 26296 {:firstname "Frank", :lastname "Sartorius", :department "Institute for Organic Chemistry and Biochemistry", :institution "Albert Ludwig University Freiburg", :country "Germany", :sessions (65)}, 26300 {:firstname "Yuko", :lastname "Moriyama", :department "Department of Information and System Engineering", :institution "Chuo University", :country "Japan", :sessions (220)}, 26301 {:firstname "Ryo", :lastname "Nakatsubo", :department "Department of Information and System Engineering", :institution "Chuo University", :country "Japan", :sessions (221)}, 26302 {:firstname "Christian", :lastname "Wolf", :department "Decision Support & OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (91)}, 26303 {:firstname "Katrin", :lastname "Schmitz", :department "Chair for Management Sciences and Energy Economics", :institution "University Duisburg-Essen", :country "Germany", :sessions (162)}, 26304 {:firstname "Andreas", :lastname "Rathgeber", :department "Human and Economic Sciences", :institution "UMIT", :country "Austria", :sessions (154)}, 26305 {:firstname "Pei", :lastname "Wang", :department "College of Information System and Management", :institution "National University of Defense Technology", :country "China", :sessions (146)}, 26311 {:firstname "Dominic", :lastname "Brenner", :department "Quantitative Methoden und Wirtschaftsmathematik", :institution "FernUniversität in Hagen", :country "Germany", :sessions (88)}, 26312 {:firstname "Iuliana", :lastname "Iatan", :department "Mathematics and Computer Science", :institution "Technical University of Civil Engineering", :country "Romania", :sessions (125)}, 26313 {:firstname "Sog Yee", :lastname "Mok", :department "", :institution "UniBw", :country "Germany", :sessions (33)}, 26315 {:firstname "Felix", :lastname "Brandt", :department "Information Process Engineering", :institution "FZI Research Center for Information Technology", :country "Germany", :sessions (196)}, 26316 {:firstname "Alexander", :lastname "Kleff", :department "", :institution "PTV AG", :country "Germany", :sessions (196)}, 26317 {:firstname "Josephine", :lastname "Clemens", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University Magdeburg", :country "Germany", :sessions (112)}, 26320 {:firstname "Nicole", :lastname "Wittmann", :department "Bereich Operations Research", :institution "Zentrum für Transformation Bw", :country "Germany", :sessions (170)}, 26321 {:firstname "Thordis Anna", :lastname "Oddsdottir", :department "", :institution "Technical University of Denmark", :country "Denmark", :sessions (110)}, 26322 {:firstname "Kai", :lastname "Furmans", :department "Institut für Fördertechnik und Logistiksysteme", :institution " KIT", :country "Germany", :sessions (201)}, 26323 {:firstname "Nezam", :lastname "Mahdavi-Amiri", :department "Mathematical Sciences", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (105)}, 26325 {:firstname "Torsten", :lastname "Klug", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (212)}, 26326 {:firstname "Andreas", :lastname "Igl", :department "Department of Statistics", :institution "University of Regensburg", :country "Germany", :sessions (96)}, 26327 {:firstname "Alberto", :lastname "Messina", :department "", :institution "RAI - Centre for Research and Technological Innovation", :country "Italy", :sessions (172)}, 26328 {:firstname "Alfred ", :lastname "Hamerle", :department "Department of Statistics", :institution "University of Regensburg", :country "Germany", :sessions (96)}, 26330 {:firstname "Mohammad Reza", :lastname "Ansari", :department "Mathematical Sciences", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (105)}, 26331 {:firstname "Christopher", :lastname "Priberny", :department "Dep. of Finance", :institution "University of Regensburg", :country "Germany", :sessions (96)}, 26332 {:firstname "Kai", :lastname "Neumann", :department "", :institution "Consideo GmbH", :country "Germany", :sessions (167)}, 26334 {:firstname "Christian A.", :lastname "Hochmuth", :department "Industrial Engineering", :institution "Bosch Rexroth AG", :country "Germany", :sessions (213)}, 26336 {:firstname "Anssi", :lastname "Käki", :department "Systems Analysis Laboratory", :institution "Aalto University School of Science and Technology", :country "Finland", :sessions (109)}, 26338 {:firstname "Shuang", :lastname "Liu", :department "", :institution "CSIRO", :country "Australia", :sessions (133 234)}, 26339 {:firstname "Andrea", :lastname "Hammermann", :department "", :institution "Cologne Institute for Economic Research", :country "Germany", :sessions (189)}, 26342 {:firstname "Polina", :lastname "Günther", :department "", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (201)}, 26343 {:firstname "Thomas", :lastname "Siebers", :department "DS&OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (113)}, 26345 {:firstname "Joachim", :lastname "Hertzberg", :department "", :institution "University of Osnabrück", :country "Germany", :sessions (148)}, 26346 {:firstname "Silvia", :lastname "Villa", :department "DIMA", :institution "Universita' di Genova", :country "Italy", :sessions (139)}, 26347 {:firstname "Wendy", :lastname "Proctor", :department "", :institution "CSIRO", :country "Australia", :sessions (234)}, 26348 {:firstname "Andy", :lastname "Sheppard", :department "", :institution "CSIRO", :country "Australia", :sessions (133)}, 26349 {:firstname "Darren", :lastname "Kriticos", :department "", :institution "CSIRO", :country "Australia", :sessions (133)}, 26351 {:firstname "Axel", :lastname "Buchner", :department "Department of Financial Management and Capital Markets ", :institution "Technical University of Munich", :country "Germany", :sessions (74)}, 26352 {:firstname "A.", :lastname "Moeller", :department "", :institution "Weierstrass Institute for Applied Analysis and Stochastics", :country "Germany", :sessions (70)}, 26353 {:firstname "Sebastian", :lastname "Sterzik", :department "Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (197)}, 26355 {:firstname "Jose A.", :lastname "Salinas-Pérez", :department "Management and Quantitative Methods", :institution "ETEA, Business Administration Faculty", :country "Spain", :sessions (139)}, 26356 {:firstname "Luis ", :lastname "Salvador-Carulla", :department "", :institution "PSICOST", :country "Spain", :sessions (139)}, 26357 {:firstname "Frank", :lastname "Schiller", :department "CoC Direct Insurance", :institution "MunichRe", :country "Germany", :sessions (154)}, 26358 {:firstname "Roland", :lastname "Stamm", :department "Risk Management & Control", :institution "DEPFA BANK plc", :country "Germany", :sessions (154)}, 26359 {:firstname "Annett", :lastname "Schädlich", :department "Fakultät für Wirtschaftswissenschaft", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (199)}, 26360 {:firstname "Pierre", :lastname "Joos", :department "Chief Risk Officer", :institution "Allianz Deutschland AG", :country "Germany", :sessions (77)}, 26361 {:firstname "Dominik", :lastname "Dorsch", :department "Dept. Mathematics", :institution "RWTH Aachen University", :country "Germany", :sessions (84)}, 26362 {:firstname "Maciej", :lastname "Machowiak", :department "", :institution "Poznan University of Technology", :country "Poland", :sessions (146)}, 26365 {:firstname "Jan-Philipp", :lastname "Kappmeier", :department "Combinatorial Optimization & Graph Algorithms", :institution "Technische Universität Berlin", :country "Germany", :sessions (219)}, 26367 {:firstname "Daniel", :lastname "Dressler", :department "Mathematics", :institution "TU Berlin", :country "Germany", :sessions (199)}, 26368 {:firstname "Martin", :lastname "Grunewald", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (120)}, 26371 {:firstname "Paula Camelia ", :lastname "Trandafir", :department "Estadistica e Investigación Operativa", :institution "University of Valladolid", :country "Spain", :sessions (214)}, 26372 {:firstname "Anna", :lastname "Storm", :department "Interaktionszentrum Entrepreneurship", :institution "Otto-von-Guericke Universität Magdeburg", :country "Germany", :sessions (137)}, 26373 {:firstname "Jesus ", :lastname "Saez Aguado", :department "Estadistica e Investigación Operativa", :institution "University of Valladolid", :country "Spain", :sessions (214)}, 26378 {:firstname "Elham", :lastname "Mardaneh", :department "Mathematics and Statistics", :institution "Curtin University of Technology", :country "Australia", :sessions (94)}, 26379 {:firstname "Kazutoshi", :lastname "Kumagai", :department "Dept. of Ind. & Manage. Systems Eng.", :institution "Graduate school of  Waseda University", :country "Japan", :sessions (74)}, 26381 {:firstname "Nobuaki", :lastname "Nagamine", :department "Marketing Communication Laboratory", :institution "Daiko Advertising INC.", :country "Japan", :sessions (99)}, 26382 {:firstname "Sartra", :lastname "Wongthanavasu", :department "Computer Science", :institution "Khon Kaen University", :country "Thailand", :sessions (135 231)}, 26384 {:firstname "Shuji", :lastname "Kijima", :department "Department of Informatics, Graduate School of ISEE", :institution "Kyushu University", :country "Japan", :sessions (221)}, 26386 {:firstname "Gunnar", :lastname "Flötteröd", :department "ENAC TRANSP-OR", :institution "EPFL", :country "Switzerland", :sessions (199)}, 26387 {:firstname "Thomas", :lastname "Rieger", :department "Institute for Mathematical Optimization ", :institution "Technical University Braunschweig", :country "Germany", :sessions (145)}, 26388 {:firstname "Corinna", :lastname "Semling", :department "", :institution "IABG mbH", :country "Germany", :sessions (180 170)}, 26389 {:firstname "Mauro", :lastname "Iacono", :department "Dipartimento di studi Europei e Mediterranei", :institution "Seconda Università degli Studi di Napoli", :country "Italy", :sessions (132)}, 26390 {:firstname "Andreas", :lastname "Popp", :department "Operations Management", :institution "Catholic University of Eichstätt-Ingolstadt", :country "Germany", :sessions (115)}, 26392 {:firstname "Gregor", :lastname "Lämmel", :department "", :institution "TU Berlin", :country "Germany", :sessions (199)}, 26397 {:firstname "Vygintas", :lastname "Gontis", :department "", :institution "Institute of Theoretical Physics and Astronomy, Vilnius University", :country "Lithuania", :sessions (97)}, 26398 {:firstname "Bernd", :lastname "Hellingrath", :department "Chair for Information Systems and Supply Chain Management", :institution "University of Münster", :country "Germany", :sessions (113)}, 26399 {:firstname "Stefan", :lastname "Stöckl", :department "FIM Research Center Finance & Information Management", :institution "University of Augsburg", :country "Germany", :sessions (154)}, 26401 {:firstname "Kai", :lastname "Nagel", :department "", :institution "TU Berlin", :country "Germany", :sessions (199)}, 26402 {:firstname "Cornelius", :lastname "Köpp", :department "", :institution "edicos Group", :country "Germany", :sessions (85)}, 26404 {:firstname "Takahiro", :lastname "Ohno", :department "Dept. of Ind. & Manage. Systems Eng.", :institution "Waseda University", :country "Japan", :sessions (74)}, 26410 {:firstname "Hans-Rolf", :lastname "Vetter", :department "", :institution "UniBw München", :country "Germany", :sessions (88)}, 26411 {:firstname "Andreas", :lastname "Varwig", :department "Department of Finance", :institution "University of Bremen", :country "Germany", :sessions (189)}, 26412 {:firstname "Carola", :lastname "Hammer", :department "Lehrstuhl für BWL - Controlling", :institution "Technische Universität München", :country "Germany", :sessions (134)}, 26413 {:firstname "Mohamed", :lastname "Mahaboob", :department "Management Science", :institution "McMaster University", :country "Canada", :sessions (93)}, 26417 {:firstname "Ulrike", :lastname "Baumoel", :department "", :institution "FernUniversitaet Hagen", :country "Germany", :sessions (43)}, 26423 {:firstname "Heiner", :lastname "Micko", :department "Geografie + Artificial Intelligence", :institution "Uni Wien", :country "Austria", :sessions (170)}, 26428 {:firstname "Stefano", :lastname "Marrone", :department "Dipartimento di Matematica", :institution "Seconda Università degli Studi di Napoli", :country "Italy", :sessions (132)}, 26429 {:firstname "Riccardo", :lastname "Vannetti", :department "Dipartimento di Sistemi e Informatica", :institution "Università di Firenze", :country "Italy", :sessions (79)}, 26431 {:firstname "Katharina", :lastname "Gerhardt", :department "Mathematics", :institution "TU Kaiserslautern", :country "Germany", :sessions (218 219)}, 26434 {:firstname "Sérgio Adriano", :lastname "Loureiro", :department "LALT", :institution "Unicamp", :country "Brazil", :sessions (43 44)}, 26436 {:firstname "Christoph", :lastname "Bode", :department "Department of Management, Technology, and Economics", :institution "Swiss Federal Institute of Technology Zurich (ETH Zurich)", :country "Switzerland", :sessions (109)}, 26438 {:firstname "Juan Carlos", :lastname "Salazar-Acosta", :department "", :institution "Universidad Autonoma de Nuevo Leon", :country "Mexico", :sessions (221)}, 26439 {:firstname "Yu", :lastname "Nonaka", :department "", :institution "Graduate School of Fundamental Science and Engineering, Waseda University", :country "Japan", :sessions (130)}, 26442 {:firstname "Lara", :lastname "Turner", :department "Department of Mathematics", :institution "Technical University of Kaiserslautern", :country "Germany", :sessions (224 217)}, 26443 {:firstname "Friedrich-Wilhelm", :lastname "Gundlach", :department "", :institution "Volkswagen AG", :country "Germany", :sessions (110)}, 26451 {:firstname "Christoph", :lastname "Zanker", :department "Industrial and Service Innovations", :institution "Fraunhofer Institute for Systems and Innovation Research", :country "Germany", :sessions (44)}, 26452 {:firstname "Alessandro", :lastname "Antonucci", :department "", :institution "IDSIA", :country "Switzerland", :sessions (225)}, 26453 {:firstname "Saša", :lastname "Žiković", :department "Finance and Banking", :institution "Faculty of Economics Rijeka", :country "Croatia", :sessions (163)}, 26457 {:firstname "Claudio", :lastname "Risso", :department "Instituto de Computación", :institution "Facultad de Ingeniería - Universidad de al República.", :country "Uruguay", :sessions (218)}, 26458 {:firstname "Mohammad", :lastname "AlDurgam", :department "Systems Engineering", :institution "KFUPM", :country "Saudi Arabia", :sessions (159)}, 26461 {:firstname "Moustafa ", :lastname "Elshafei", :department "Systems Engineering", :institution "KFUPM", :country "Saudi Arabia", :sessions (159)}, 26466 {:firstname "Öyküm Esra", :lastname "Yiğit", :department "Statistics", :institution "Ege University", :country "Turkey", :sessions (199)}, 26467 {:firstname "Steffi", :lastname "Höse", :department "", :institution "TU Dresden", :country "Germany", :sessions (96)}, 26468 {:firstname "Stefan", :lastname "Huschens", :department "", :institution "TU Dresden", :country "Germany", :sessions (96)}, 26469 {:firstname "Oliver", :lastname "Pucker", :department "Corporate Finance Department", :institution "University of Cologne", :country "Germany", :sessions (228)}, 26470 {:firstname "Lukas", :lastname "Abegg", :department "Mathematics", :institution "ETH Zürich", :country "Switzerland", :sessions (77)}, 26471 {:firstname "Anja", :lastname "Fischer", :department "", :institution "TU Dortmund", :country "Germany", :sessions (160)}, 26480 {:firstname "Nicole", :lastname "Rösch", :department "", :institution "Chemnitz University of Technology", :country "Germany", :sessions (160)}, 26483 {:firstname "Miroslav", :lastname "Velev", :department "", :institution "Aries Design Automation", :country "United States", :sessions (216)}, 26485 {:firstname "Kentaro", :lastname "Hoshi", :department "Media Network Center", :institution "Waseda University", :country "Japan", :sessions (130)}, 26487 {:firstname "Ping", :lastname "Gao", :department "", :institution "Aries Design Automation", :country "United States", :sessions (216)}, 26488 {:firstname "Nela", :lastname "Vlahinić-Dizdarević", :department "Economics", :institution "Faculty of Economics University of Rijeka", :country "Croatia", :sessions (163)}, 26489 {:firstname "Beate", :lastname "Rottkemper", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology", :country "Germany", :sessions (198)}, 26490 {:firstname "Sebastian", :lastname "Zurheide", :department "Institute for Operations Research and Information Systems", :institution "Hamburg University of Technology (TUHH)", :country "Germany", :sessions (93)}, 26491 {:firstname "Thomas", :lastname "Ponsignon", :department "Corporate Supply Chain", :institution "Infineon Technologies AG", :country "Germany", :sessions (120)}, 26495 {:firstname "Christian", :lastname "Schiller", :department "Corporate Supply Chain", :institution "Infineon Technologies AG", :country "Germany", :sessions (120)}, 26496 {:firstname "Amparo", :lastname "Soler-Dominguez", :department "", :institution "Universitat Jaume I", :country "Spain", :sessions (142)}, 26497 {:firstname "Marek", :lastname "Opuszko", :department "Department of Business Informatics", :institution "Friedrich-Schiller-University of Jena", :country "Germany", :sessions (225)}, 26499 {:firstname "Dietmar", :lastname "Graeber", :department "Qunatitative Methoden", :institution "Universität Hohenheim", :country "Germany", :sessions (85)}, 26501 {:firstname "Timo", :lastname "Lohmann", :department "", :institution "TU Braunschweig", :country "Germany", :sessions (91)}, 26505 {:firstname "shahram", :lastname "mahmoudi", :department "", :institution "mapna", :country "Iran, Islamic Republic of", :sessions (156)}, 26507 {:firstname "Sameh", :lastname "Haneyah", :department "", :institution "TBA", :country "Netherlands", :sessions (205)}, 26508 {:firstname "Jannik", :lastname "Matuschke", :department "TUM School of Management, Lehrstuhl für Operations Research", :institution "Technische Universität München", :country "Germany", :sessions (216 118)}, 26509 {:firstname "Jan-Andre", :lastname "König", :department "Department of Mathematics (ST)", :institution "University of Hamburg", :country "Germany", :sessions (129)}, 26514 {:firstname "Paul", :lastname "Hofmarcher", :department "Department of Finance, Accounting and Statistics", :institution "Institute for Statistics and Mathematics", :country "Austria", :sessions (228)}, 26515 {:firstname "Mustafa", :lastname "Soyertem", :department "Mathematics", :institution "Uşak University", :country "Turkey", :sessions (103)}, 26517 {:firstname "Vincent", :lastname "Bakker", :department "EEMCS", :institution "University of Twente", :country "Netherlands", :sessions (162)}, 26518 {:firstname "Tobias", :lastname "Harks", :department "Institut für Mathematik", :institution "Universität Augsburg", :country "Germany", :sessions (216 118)}, 26519 {:firstname "Maurice", :lastname "Bosman", :department "", :institution "University of Twente", :country "Netherlands", :sessions (162)}, 26520 {:firstname "Albert", :lastname "Molderink", :department "", :institution "University of Twente", :country "Netherlands", :sessions (162)}, 26521 {:firstname "Gerard", :lastname "Smit", :department "", :institution "University of Twente", :country "Netherlands", :sessions (162)}, 26526 {:firstname "Natalia", :lastname "Iliina", :department "", :institution "State University of Management", :country "Russian Federation", :sessions (192)}, 26527 {:firstname "Pavel", :lastname "Kurochkin", :department "", :institution "State University of Management", :country "Russian Federation", :sessions (192)}, 26529 {:firstname "Hagen", :lastname "Salewski", :department "Business Information Systems and Operations Research", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (157)}, 26530 {:firstname "Christoph", :lastname "Danne", :department "Business Computing, esp. CIM", :institution "University of Paderborn", :country "Germany", :sessions (198)}, 26531 {:firstname "Alan", :lastname "Eckhardt", :department "Department of Software Engineering", :institution "Charles University in Prague", :country "Czech Republic", :sessions (234)}, 26532 {:firstname "Yassine", :lastname "Ouazene", :department "ICD-OSI", :institution "University of Technology of Troyes", :country "France", :sessions (144 152)}, 26534 {:firstname "Mandar", :lastname "Tulpule", :department "Virginia Modeling, Analysis, & Simulation Center ", :institution "Old Dominion University", :country "United States", :sessions (116)}, 26540 {:firstname "Marco", :lastname "Beccuti", :department "", :institution "Università degli Studi di Torino", :country "Italy", :sessions (131 139)}, 26541 {:firstname "Giuliana", :lastname "Franceschinis", :department "", :institution "Università del Piemonte Orientale", :country "Italy", :sessions (131 139)}, 26544 {:firstname "Mirco", :lastname "Tribastone", :department "Institut für Informatik", :institution "Ludwig-Maximilians-Universität München", :country "Germany", :sessions (131)}, 26545 {:firstname "Stephen", :lastname "Gilmore", :department "School of Informatics", :institution "The University of Edinburgh", :country "United Kingdom", :sessions (131)}, 26546 {:firstname "Naohisa", :lastname "Komatsu", :department "Faculty of Science and Engineering", :institution "Waseda University", :country "Japan", :sessions (130)}, 26550 {:firstname "Hans", :lastname "Ehm", :department "Supply Chain", :institution "Infineon", :country "Germany", :sessions (120)}, 26551 {:firstname "Orlando", :lastname "Fontes Lima", :department "LALT Logistics and Transports", :institution "UNICAMP", :country "Brazil", :sessions (43 44)}, 26552 {:firstname "Janaina", :lastname "Antonino Pinto", :department "LALT Logistics and Transports", :institution "UNICAMP", :country "Brazil", :sessions (44)}, 26553 {:firstname "Gergely", :lastname "Treplan", :department "Faculty of Information Technology", :institution "Peter Pazmany Catholic University", :country "Hungary", :sessions (148)}, 26554 {:firstname "Hans", :lastname "Corsten", :department "Business Administration and Production Management", :institution "University of Kaiserslautern", :country "Germany", :sessions (157)}, 26555 {:firstname "Raheel", :lastname "Javed", :department "Computer Science", :institution "Linköping University", :country "Sweden", :sessions (231)}, 26556 {:firstname "Mike", :lastname "Small", :department "Software Group", :institution "IBM", :country "United Kingdom", :sessions (118)}, 26557 {:firstname "Mathias", :lastname "Walther", :department "Business Information Systems and Operations Research", :institution "University of Halle", :country "Germany", :sessions (229)}, 26559 {:firstname "Panos", :lastname "Seferlis", :department "", :institution "Aristotle University of Thessaloniki and Chemical Process Engineering Research Institute", :country "Greece", :sessions (94)}, 26560 {:firstname "Furkan", :lastname "Baser", :department "Department of Computer Applications Education", :institution "Gazi University", :country "Turkey", :sessions (230)}, 26561 {:firstname "vahid", :lastname "saadi", :department "management and economics", :institution "sharif university of technology", :country "Iran, Islamic Republic of", :sessions (97)}, 26563 {:firstname "Turkan ", :lastname "Erbay Dalkilic", :department "Department of Statistics and Computer Sciences", :institution "Karadeniz Technical University", :country "Turkey", :sessions (230)}, 26565 {:firstname "Kamile", :lastname "Sanli Kula", :department "Department of Mathematics", :institution "Ahi Evran University", :country "Turkey", :sessions (230)}, 26566 {:firstname "Karsten", :lastname "Helbig", :department "Lehrstuhl für Wirtschaftsinformatik und Operations Research", :institution "Martin Luther Universität", :country "Germany", :sessions (137)}, 26568 {:firstname "Vania", :lastname "Nannola", :department "Management, Economics and Industrial Engineering", :institution "Politecnico di Milano", :country "Italy", :sessions (78)}, 26570 {:firstname "Silvia", :lastname "Canale", :department "Department of Computer and System Sciences", :institution "University of Rome \"La Sapienza\"", :country "Italy", :sessions (79)}, 26571 {:firstname "Gondia Sokhna", :lastname "Seck", :department "Center for applied mathematics", :institution "MINES Paristech", :country "France", :sessions (178)}, 26572 {:firstname "Odileno", :lastname "Lehmkuhl", :department "CIÊNCIA DA COMPUTAÇÃO", :institution "UNIVALI", :country "Brazil", :sessions (23)}, 26574 {:firstname "Dan", :lastname "Adelman", :department "", :institution "University of Chicago Booth School of Business", :country "United States", :sessions (245)}, 26575 {:firstname "Erika", :lastname "Murguia Blumenkranz", :department "School of Computing, Informatics and Decision Systems Engineering", :institution "Arizona State University", :country "United States", :sessions (158)}, 26576 {:firstname "Dieter", :lastname "Armbruster", :department "", :institution "Arizona State University", :country "United States", :sessions (158)}, 26578 {:firstname "Belgin", :lastname "Kayhan", :department "Scientific Computing", :institution "Applied Mathematics", :country "Turkey", :sessions (29)}, 26583 {:firstname "Michael", :lastname "Wagner", :department "Business Process Management", :institution "Paul Hartmann AG", :country "Germany", :sessions (113)}, 26584 {:firstname "Ertan", :lastname "Yakici", :department "Industrial Engineering", :institution "National Defense University, Turkish Naval Academy", :country "Turkey", :sessions (94)}, 26585 {:firstname "Bernhard", :lastname "Hirsch", :department "Institut für Controlling, Finanz- und Risikomanagement", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (193 195)}, 26588 {:firstname "Yuan", :lastname "Tian", :department "", :institution "Tokyo Metropolitan University", :country "Japan", :sessions (98)}, 26589 {:firstname "Martina", :lastname "Volnhals", :department "", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (193)}, 26591 {:firstname "Roman", :lastname "Denysiuk", :department "", :institution "Algoritmi R&D Center", :country "Portugal", :sessions (106)}, 26595 {:firstname "Kalman", :lastname "Tornai", :department "Faculty of Information Technology and Bionics", :institution "Pazmany Peter Catholic University", :country "Hungary", :sessions (148)}, 26596 {:firstname "Dennis", :lastname "Bergmann", :department "", :institution "Hochschule Darmstadt", :country "Germany", :sessions (166)}, 26597 {:firstname "Michael", :lastname "Kunisch", :department "", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (96)}, 26598 {:firstname "Sachin", :lastname "Lodha", :department "Applied Algorithms and Optimization Group", :institution "Tata Consultancy Services", :country "India", :sessions (147)}, 26604 {:firstname "Gianfranco", :lastname "Balbo", :department "", :institution "Università degli Studi di Torino", :country "Italy", :sessions (131)}, 26605 {:firstname "Massimiliano", :lastname "De Pierro", :department "", :institution "Università degli Studi di Torino", :country "Italy", :sessions (131)}, 26606 {:firstname "Peter N", :lastname "Posch", :department "Institute of Finance", :institution "University of Ulm", :country "Germany", :sessions (96)}, 26607 {:firstname "Alexander", :lastname "Blecken", :department "Business Computing, esp. CIM", :institution "University of Paderborn", :country "Germany", :sessions (198)}, 26608 {:firstname "Endre", :lastname "László", :department "", :institution "Pazmany Peter Catholic University - The Faculty of Information Technology", :country "Hungary", :sessions (148)}, 26609 {:firstname "Philippe", :lastname "Luginbuehl", :department "", :institution "Armasuisse", :country "Switzerland", :sessions (225)}, 26611 {:firstname "Alain", :lastname "Hita", :department "", :institution "EDF R&D", :country "France", :sessions (178)}, 26612 {:firstname "Paul", :lastname "Koerbitz", :department "Research training group 1100", :institution "Ulm University", :country "Germany", :sessions (77)}, 26613 {:firstname "Ralf", :lastname "Gössinger", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (157)}, 26614 {:firstname "Jens", :lastname "Ludwig", :department "Institute for Industrial Production (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (40)}, 26617 {:firstname "Mostafa", :lastname "Barzegar", :department "", :institution "Isalamic Azad University- branch of Ghods", :country "Iran, Islamic Republic of", :sessions (110)}, 26618 {:firstname "Haleh", :lastname "Dolati", :department "", :institution "Municipality of Tehran", :country "Iran, Islamic Republic of", :sessions (231)}, 26619 {:firstname "Jenny", :lastname "Nossack", :department "Institute of Information Systems", :institution "University of Siegen", :country "Germany", :sessions (201)}, 26621 {:firstname "Mirjana", :lastname "Lach", :department "Department of Mathematics", :institution "TU Berlin", :country "Germany", :sessions (220)}, 26622 {:firstname "Hans Georg", :lastname "Seedig", :department "", :institution "TU München", :country "Germany", :sessions (219)}, 26623 {:firstname "seyed mohammad javad", :lastname "mirzapour al e hashem", :department "Industrial Engineering", :institution "Iran university of Science and Technology", :country "Iran, Islamic Republic of", :sessions (161)}, 26627 {:firstname "Hans-Georg", :lastname "Konert", :department "Owner/ CEO", :institution "Konekta Consulting GmbH", :country "Germany", :sessions (170)}, 26629 {:firstname "Elisabeth", :lastname "Lübbecke", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (212)}, 26632 {:firstname "Frank", :lastname "Schulz", :department "SAP Research", :institution "SAP AG", :country "Germany", :sessions (157)}, 26633 {:firstname "Paolo", :lastname "Petta", :department "Austrian Research Institute for Artificial Intelligence", :institution "Austrian Society for Cybernetic Studies", :country "Austria", :sessions (170)}, 26634 {:firstname "Sebastian", :lastname "Schiffels", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (111)}, 26637 {:firstname "Ali", :lastname "Bozorgi-Amiri", :department "Industrial Engineering", :institution "Iran University of Science and Technology", :country "Iran, Islamic Republic of", :sessions (155 138)}, 26640 {:firstname "Maryam", :lastname "Karimian", :department "", :institution "Islamic Azad University, Babol Branch", :country "Iran, Islamic Republic of", :sessions (138)}, 26641 {:firstname "Vinicius Jacques", :lastname "Garcia", :department "", :institution "Federal University of Pampa", :country "Brazil", :sessions (211 200)}, 26642 {:firstname "Daniel", :lastname "Bernardon", :department "", :institution "Federal University of Pampa", :country "Brazil", :sessions (200)}, 26643 {:firstname "Mauricio ", :lastname "Sperandio", :department "", :institution "Federal University of Pampa", :country "Brazil", :sessions (200)}, 26651 {:firstname "Lars", :lastname "Nöbel", :department "", :institution "IFU Halle", :country "Germany", :sessions (229)}, 26654 {:firstname "Harald", :lastname "Schaub", :department "U Bamberg", :institution "IABG", :country "Germany", :sessions (167)}, 26655 {:firstname "Erhard", :lastname "Zorn", :department "Department of Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (220)}, 26656 {:firstname "Onur", :lastname "YILMAZ", :department "INDUSTRIAL ENGINEERING", :institution "YILDIZ TECHNICAL UNIVERSITY", :country "Turkey", :sessions (158 76)}, 26657 {:firstname "Uwe", :lastname "Clausen", :department "Director", :institution "Fraunhofer-Institute for Materialflow and Logistics (IML)", :country "Germany", :sessions (133)}, 26658 {:firstname "Ali Fuat", :lastname "Guneri", :department "", :institution "Yildiz Technical University", :country "Turkey", :sessions (158 76)}, 26659 {:firstname "Markus", :lastname "Reimer", :department "", :institution "quin-akademie", :country "Germany", :sessions (88)}, 26660 {:firstname "Şenim", :lastname "Özgüler", :department "Department of Industrial Engineering", :institution "Yildiz Technical University", :country "Turkey", :sessions (158 76)}, 26661 {:firstname "Karl", :lastname "Dvorsky", :department "", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (87)}, 26662 {:firstname "Riccardo", :lastname "Zucca", :department "DIT - Department of Territory Engineering", :institution "University of Cagliari", :country "Italy", :sessions (40)}, 26667 {:firstname "Izhar", :lastname "Ahmad", :department "Mathematics and Statistics", :institution "King Fahd University of Petroleum and Minerals", :country "Saudi Arabia", :sessions (87)}, 26671 {:firstname "Michael", :lastname "Marty", :department "Strategic Studies", :institution "Swiss Armed Forces College", :country "Switzerland", :sessions (108)}, 26672 {:firstname "Yoshinori", :lastname "Matano", :department "Account Management Division", :institution "AD DENTSU OSAKA INC.", :country "Japan", :sessions (95)}, 26673 {:firstname "Günther", :lastname "Edenharter", :department "Klinikum Rechts der Isar", :institution "Klinik für Anästhesiologie", :country "Germany", :sessions (37)}, 26677 {:firstname "Mohammad Taghi ", :lastname "Isaai", :department "Graduate School of Management and Economics ", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (76)}, 26679 {:firstname "Goran", :lastname "Mihelcic", :department "", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (178 180)}, 26680 {:firstname "Alexander", :lastname "Keßler", :department "Business Information Systems & Operations Research", :institution "University of Technology, Kaiserslautern", :country "Germany", :sessions (126)}, 26682 {:firstname "Iiro", :lastname "Harjunkoski", :department "", :institution "ABB Corporate Research", :country "Germany", :sessions (213)}, 26683 {:firstname "Matteo", :lastname "Biondi", :department "", :institution "ABB Corporate Research", :country "Germany", :sessions (213)}, 26684 {:firstname "Mauro", :lastname "Mantovani", :department "Strategische Studien", :institution "Militärakademie an der ETH Zürich", :country "Switzerland", :sessions (108)}, 26685 {:firstname "methaq", :lastname "katta", :department "Computer Science ", :institution "Al-Mustansiriyah University/ Baghdad- IRAQ", :country "Iraq", :sessions (181)}, 26690 {:firstname "Peter T.", :lastname "Baltes", :department "Militaeroekonomie", :institution "Militaerakademie an der ETH Zuerich", :country "Switzerland", :sessions (108)}, 26694 {:firstname "Marijn", :lastname "Jongerden", :department "", :institution "University of Twente", :country "Netherlands", :sessions (172)}, 26702 {:firstname "Gerald", :lastname "Brown", :department "", :institution "Naval Postgraduate School", :country "United States", :sessions (195 210)}, 26728 {:firstname "Turan", :lastname "Paksoy", :department "Industrial Engineering", :institution "Selçuk University", :country "Turkey", :sessions (23)}, 26729 {:firstname "Arnold", :lastname "Dupuy", :department "", :institution "Bundeswehr University, Munich", :country "United States", :sessions (135)}, 26739 {:firstname "Joerg", :lastname "Wellbrink", :department "M II / IT Staff 4", :institution "German Ministry of Defense", :country "Germany", :sessions (127)}, 26744 {:firstname "Boudewijn", :lastname "Haverkort", :department "", :institution "Embedded Systems Institute", :country "Netherlands", :sessions (172 269)}, 26746 {:firstname "farhaneh", :lastname "golozari", :department "Industrial Engineering (master of science)", :institution "University of Science and Culture (USC)", :country "Iran, Islamic Republic of", :sessions (128)}, 26748 {:firstname "Silvia", :lastname "Ulli-Beer", :department "General Energy", :institution "Paul Scherrer Institut", :country "Switzerland", :sessions (169)}, 26750 {:firstname "Dirk", :lastname "Hartmann", :department "Corporate Technology", :institution "Siemens AG", :country "Germany", :sessions (166)}, 26751 {:firstname "Wolfram", :lastname "Klein", :department "", :institution "Siemens AG", :country "Germany", :sessions (166)}, 26752 {:firstname "Gerta", :lastname "Köster", :department "Computer Science and Mathematics", :institution "University of Applied Sciences - Munich", :country "Germany", :sessions (166)}, 26755 {:firstname "Kevin", :lastname "Wood", :department "Operations Research Dept.", :institution "Naval Postgraduate School", :country "United States", :sessions (218 195)}, 26758 {:firstname "Christopher", :lastname "Cullenbine", :department "Economics & Business", :institution "Colorado School of Mines", :country "United States", :sessions (218)}, 26762 {:firstname "James", :lastname "Ferguson", :department "Quality, Production, and Logistics", :institution "Naval Undersea Warfare Center Division Newport", :country "United States", :sessions (128)}, 26763 {:firstname "Brian", :lastname "Mckeon", :department "Torpedo systems dept", :institution "Naval Undersea Warfare Center", :country "United States", :sessions (172)}, 26768 {:firstname "Ozlem", :lastname "Defterli", :department "Department of Mathematics and Computer Science", :institution "Cankaya University, Ankara, Turkey & Saginaw Valley State University, College of Science, Engineering and Technology, MI, USA (currently as PostDoc)", :country "United States", :sessions (32)}, 26774 {:firstname "Stephan", :lastname "Theiss", :department "", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (137)}, 26775 {:firstname "Franziska", :lastname "Guenzel", :department "Interaktionszentrum Entrepreneurship", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (137)}, 26790 {:firstname "Azizollah", :lastname "Jafari", :department "Industrial Engineering", :institution "University of Science and Culture(USC)", :country "Iran, Islamic Republic of", :sessions (128)}, 26791 {:firstname "Daniela", :lastname "Hosser", :department "Institute for Psychology, EPF", :institution "Technical University Braunschweig", :country "Germany", :sessions (16)}, 26842 {:firstname "Katinka", :lastname "Wolter", :department "Computer Science", :institution "Freie Universität Berlin", :country "Germany", :sessions (132)}, 26848 {:firstname "David", :lastname "Haro Monteagudo", :department "Ingeniería Hidráulica y Medio Ambiente", :institution "Universidad Politécnica de Valencia", :country "Spain", :sessions (40)}, 26861 {:firstname "Romana", :lastname "Tschiedel", :department "Operations Research, Computer Science", :institution "Universität der Bundeswehr München", :country "Austria", :sessions (226)}, 26862 {:firstname "Zafer-Korcan", :lastname "Görgülü", :department "", :institution "Uinversität der Bundeswehr München", :country "Germany", :sessions (226)}, 26864 {:firstname "Tim", :lastname "McKay", :department "JOD", :institution "DSTO", :country "Australia", :sessions (180)}, 26865 {:firstname "Seyed Mohammad", :lastname "Asadzadeh", :department "Industrial Engineering", :institution "University of Tehran", :country "Iran, Islamic Republic of", :sessions (156)}, 26871 {:firstname "Simone", :lastname "Dieckmann", :department "Economics Chair of Banking and Finance ", :institution "Universität Osnabrück", :country "Germany", :sessions (98)}, 26874 {:firstname "Solmaz", :lastname "Hosseinioon", :department "Risk Mangement", :institution "IIEES", :country "Iran, Islamic Republic of", :sessions (28)}, 26879 {:firstname "Johann", :lastname "Mayer", :department "Lehrstuhl für Elektrische Antriebstechnik und Aktorik", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (179)}, 26897 {:firstname "Dirk", :lastname "Taubner", :department "", :institution "msg systems ag", :country "Germany", :sessions (241)}, 26906 {:firstname "Bastian", :lastname "Sand", :department "", :institution "University of Kaiserslautern", :country "Germany", :sessions (196)}, 26923 {:firstname "Martin", :lastname "Krynitz", :department "", :institution "Swedish Space Corporation", :country "Sweden", :sessions (127)}, 26948 {:firstname "Stefan", :lastname "Hahler", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (257)}, 26949 {:firstname "Rainer", :lastname "Hoffmann", :department "Department of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (257)}, 26950 {:firstname "Max", :lastname "Klimm", :department "Wirtschaftswissenschaftliche Fakultät", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (257)}, 26951 {:firstname "Abdolkarim", :lastname "Sadrieh", :department "Faculty of Economics and Management", :institution "Universität Magedburg", :country "Germany", :sessions (259 189)}, 26955 {:firstname "Shiva", :lastname "Zamani", :department "GSME", :institution "Sharif University of Technology", :country "Iran, Islamic Republic of", :sessions (97)}, 26956 {:firstname "Winfried", :lastname "Matthes", :department "", :institution "BU Wuppertal", :country "Germany", :sessions (261)}, 26957 {:firstname "Benninga", :lastname "Simon", :department "", :institution "Tel Aviv U and Wharton", :country "Israel", :sessions (262)}, 26958 {:firstname "Menachem", :lastname "Abudy", :department "", :institution "Tel Aviv U", :country "Israel", :sessions (262)}, 26969 {:firstname "Debora", :lastname "Mahlke", :department "", :institution "BASF SE", :country "Germany", :sessions (274)}, 26995 {:firstname "Laura Marina", :lastname "Valencia Niño", :department "Engenharia de Produção", :institution "Universidade Federal do Rio de Janeiro", :country "Brazil", :sessions (181)}, 27025 {:firstname "Björn", :lastname "Scheuermann", :department "Computer Science", :institution "Heinrich Heine University, Düsseldorf", :country "Germany", :sessions (175)}, 27195 {:firstname "Torben", :lastname "Schramme", :department "DS&OR Lab Paderborn", :institution "University of Paderborn", :country "Germany", :sessions (198)}, 29382 {:firstname "faicel", :lastname "hnaien", :department "LOSI", :institution "University of Technology of Troyes", :country "France", :sessions (152)}, 30804 {:firstname "Elise", :lastname "del Rosario", :department "", :institution "OSSFFI", :country "Philippines", :sessions (23)}, 33285 {:firstname "Sascha", :lastname "Herrmann", :department "", :institution "zooplus AG", :country "Germany", :sessions (138)}, 33615 {:firstname "Catalin Stefan", :lastname "Tiseanu", :department "", :institution "University of Maryland", :country "United States", :sessions (138)}, 33678 {:firstname "Birgit", :lastname "Mayer", :department "", :institution "TU Dresden", :country "Germany", :sessions (273)}, 38189 {:firstname "Marco", :lastname "Gribaudo", :department "Dipartimento di Elettronica ed informazione", :institution "Politecnico di Milano", :country "Italy", :sessions (172)}, 41043 {:firstname "Guruprasad", :lastname "Nagaraj", :department "Computer Science", :institution "CMR Institute of Technology", :country "India", :sessions (147 212)}, 50162 {:firstname "Leroy", :lastname "White", :department "", :institution "University of Warwick", :country "United Kingdom", :sessions (23)}, 51147 {:firstname "Gülser", :lastname "Köksal", :department "Industrial Engineering", :institution "Middle East Technical University", :country "Turkey", :sessions (29)}, 53427 {:firstname "Andreas", :lastname "Fügener", :department "", :institution "Universität Köln", :country "Germany", :sessions (111)}, 55333 {:firstname "Martin", :lastname "Bichler", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (193)}, 56196 {:firstname "Maren", :lastname "Martens", :department "", :institution "Landshut University", :country "Germany", :sessions (214)}, 58410 {:firstname "José María", :lastname "Alonso-Meijide", :department "", :institution "Universidade de santiago de Compostela", :country "Spain", :sessions (188)}, 59787 {:firstname "Maximilian", :lastname "Hartl", :department "", :institution "Universität Stuttgart", :country "Germany", :sessions (56)}}}