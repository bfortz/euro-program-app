{:timeslots {1 {:schedule "Wednesday, 9:00-10:30", :day "W", :time "A", :sessions (199965)}, 2 {:schedule "Wednesday, 10:50-12:20", :day "W", :time "B", :sessions (199910 30 42 199896 90 199909 199888 7 60 199833 199873 15 199892 199930 28 199848 86813 26 91 97 199980)}, 3 {:schedule "Wednesday, 13:10-14:40", :day "W", :time "C", :sessions (199897 67 199876 199916 89 8 4 199837 199872 46 199891 45 199961 199944 32 199884 199865 199845 10 199981)}, 4 {:schedule "Wednesday, 15:00-15:45", :day "W", :time "D", :sessions (199972 199971 199973 199979)}, 5 {:schedule "Wednesday, 16:05-17:35", :day "W", :time "E", :sessions (199948 199886 199880 93 199881 199919 39 199958 199836 199869 105 83 199946 37 25 5 199852 76 199982)}, 6 {:schedule " Wednesday, 17:45-18:45", :day "W", :time "F", :sessions (199983)}, 7 {:schedule "Thursday, 8:15-9:45", :day "T", :time "A", :sessions (199918 199885 199878 199899 68 199914 58 199932 24 199874 47 54 199890 94 199964 199858 199945 44 96 27 199941 98)}, 8 {:schedule "Thursday, 10:15-11:00", :day "T", :time "B", :sessions (199968 199974 199975)}, 9 {:schedule "Thursday, 11:25-12:55", :day "T", :time "C", :sessions (199903 199834 71 199911 199882 199905 19 199927 87 199871 199830 77 86 61 51 199862 199942 199849 199883 50 199856 199832)}, 10 {:schedule "Thursday, 13:45-14:30", :day "T", :time "D", :sessions (199969 199977 199978)}, 11 {:schedule "Thursday, 15:00-16:30", :day "T", :time "E", :sessions (199949 199835 199877 199898 63 199900 33 75 55 199842 95 199831 199938 85 99 199860 199939 199851 81652 199864 199920 101)}, 12 {:schedule "Friday, 8:15-9:45", :day "F", :time "A", :sessions (199913 92 199875 106 199931 199894 199889 199959 65 199841 102 199937 199929 199963 199859 199947 199854 79 199957 199847 199926)}, 13 {:schedule "Friday, 10:10-10:55", :day "F", :time "B", :sessions (199976 199970 199967)}, 14 {:schedule "Friday, 11:20-12:50", :day "F", :time "C", :sessions (199912 199840 69 199917 199934 81 199887 199960 199933 199893 199870 199867 199936 73 199928 199863 199943 199846 89890 199955 199940 100)}, 15 {:schedule "Friday, 13:00-14:15", :day "F", :time "D", :sessions (199966)}}, :streams {1 {:name "Algorithmic Game Theory", :sessions (30 199888 67 8 199886 39 199885 58 19 33 92 199889 199887)}, 2 {:name "Artificial Intelligence, Big Data, and Data Mining ", :sessions (15 105 199867)}, 3 {:name "Continuous and Non-linear Optimization", :sessions (7 4 199958 75 199959 199960)}, 4 {:name "Discrete and Combinatorial Optimization, Graphs and Networks ", :sessions (199910 199896 199909 199897 199916 89 93 199919 199918 199899 199914 199903 199911 199905 199898 199900 199913 106 199894 199912 199917 81)}, 5 {:name "Heuristics, Metaheuristics, and Matheuristics ", :sessions (46 47 199830 199831)}, 6 {:name "Decision Theory and Multi-Criteria Optimization ", :sessions (199833 199837 199836 24 199834 87 199835 199842 199841 199840 199893)}, 7 {:name "Statistics and Forecasting", :sessions (199892 199891 83 199890 86 85 73)}, 8 {:name "Robust and Stochastic Optimization ", :sessions (42 90 199880 199881 199878 54 199882 199877 69)}, 9 {:name "Software Applications and Modelling Systems", :sessions (86813 199884 96 199883 81652 79 89890)}, 10 {:name "Energy and Environment ", :sessions (60 199930 45 68 199932 94 199927 61 63 55 99 199931 65 199929 199934 199933 199928)}, 11 {:name "Finance, Banking, Insurance, and Accounting", :sessions (199961 199964 51 199963)}, 12 {:name "Health Care Management", :sessions (77 199938 199937 199936)}, 13 {:name "Logistics and Inventory ", :sessions (26 199865 25 5 27 50 199864 199957 199955)}, 14 {:name "Pricing, Revenue Management, and Smart Markets", :sessions (97 10 76 98 199832 101 199926 100)}, 15 {:name "Production and Operations Management ", :sessions (199848 91 32 199845 37 199852 44 199849 199856 199851 199854 199847 199846)}, 16 {:name "Project Management and Scheduling", :sessions (199873 199876 199872 199869 199874 71 199871 95 199875 102 199870)}, 17 {:name "Supply Chain Management", :sessions (199858 199862 199860 199859 199863)}, 18 {:name "Traffic and Transportation ", :sessions (28 199944 199946 199945 199941 199942 199939 199920 199947 199943 199940)}, 19 {:name "Invited Presentations and Ceremonies", :sessions (199965 199972 199971 199973 199968 199974 199975 199969 199977 199978 199976 199970 199967 199966)}, 20 {:name "Awards Sessions", :sessions (199979 199948 199949)}, 21 {:name "Business Day", :sessions (199980 199981 199982 199983)}}, :sessions {4 {:name "Nonlinear Optimization I", :stream 3, :chairs (29675 35685), :timeslot 3, :papers (119 920), :track 9}, 5 {:name "Vehicle Routing with Intermediate Facilities", :stream 13, :chairs (19320), :timeslot 5, :papers (447 685 731), :track 22}, 7 {:name "Variational Inequalities and Related Topics I", :stream 3, :chairs (35439), :timeslot 2, :papers (83 325 462), :track 9}, 8 {:name "Congestion Games", :stream 1, :chairs (26950), :timeslot 3, :papers (148 522 581 582), :track 8}, 10 {:name "Smart Electricity Markets", :stream 14, :chairs (39546), :timeslot 3, :papers (134 139 171), :track 24}, 15 {:name "Fuzzy Expert Systems/Fuzzy Expertensysteme", :stream 2, :chairs (2651 15349), :timeslot 2, :papers (25 439 687), :track 13}, 19 {:name "Allocation under Preferences", :stream 1, :chairs (41376), :timeslot 9, :papers (537 630), :track 8}, 24 {:name "Applications of Data Analysis and Data Envelopment Analysis", :stream 6, :chairs (29686), :timeslot 7, :papers (926 819 891), :track 11}, 25 {:name "Distribution & Inventory Management", :stream 13, :chairs (26657), :timeslot 5, :papers (117 663 251), :track 21}, 26 {:name "Transport Network Planning & Operation", :stream 13, :chairs (44839), :timeslot 2, :papers (100 753 811), :track 22}, 27 {:name "Applications of combined Simulation & Optimization Methods in Logistics", :stream 13, :chairs (33419), :timeslot 7, :papers (92 101 899), :track 22}, 28 {:name "Staff Scheduling and Rostering", :stream 18, :chairs (23505), :timeslot 2, :papers (499 229 619), :track 19}, 30 {:name "Computational Social Choice", :stream 1, :chairs (33211), :timeslot 2, :papers (214 497 415), :track 3}, 32 {:name "Robust Production and Distribution Planning", :stream 15, :chairs (23451), :timeslot 3, :papers (190 272 296), :track 20}, 33 {:name "Mechanism Design I", :stream 1, :chairs (41942), :timeslot 11, :papers (452 851 871), :track 8}, 37 {:name "Supply Chain Design", :stream 15, :chairs (27254), :timeslot 5, :papers (27 32 50 107), :track 20}, 39 {:name "Network Creation", :stream 1, :chairs (42734), :timeslot 5, :papers (678 601 250), :track 8}, 42 {:name "Robust knapsack problems", :stream 8, :chairs (29733), :timeslot 2, :papers (533 223 571), :track 4}, 44 {:name "Modeling and Analysis of Complex Manufacturing Systems", :stream 15, :chairs (26491), :timeslot 7, :papers (379 305 184), :track 20}, 45 {:name "Optimal Design and Operation of Pipeline Networks", :stream 10, :chairs (19441), :timeslot 3, :papers (57 94 176 280), :track 16}, 46 {:name "Matheuristics", :stream 5, :chairs (5931), :timeslot 3, :papers (43 457), :track 13}, 47 {:name "Metaheuristics in Production and Logistics", :stream 5, :chairs (32377), :timeslot 7, :papers (897 154 518), :track 13}, 50 {:name "Robust Vehicle Routing Problems under Uncertainty", :stream 13, :chairs (24074 26657), :timeslot 9, :papers (442 553 662), :track 22}, 51 {:name "Optimization and Statistics", :stream 11, :chairs (12736), :timeslot 9, :papers (718 763 773), :track 17}, 54 {:name "Robust and stochastic optimization in transportation", :stream 8, :chairs (19182), :specialroom "SFo10", :timeslot 7, :papers (274 716 856), :track 14}, 55 {:name "Uncertainties in Energy Markets and Stochastic Models for Energy Economics", :stream 10, :chairs (25688), :timeslot 11, :papers (406 658 850), :track 10}, 58 {:name "Computing Equilibria", :stream 1, :chairs (44261), :timeslot 7, :papers (99 178 834), :track 8}, 60 {:name "Sustainable Transport", :stream 10, :chairs (17364), :timeslot 2, :papers (170 210 735), :track 10}, 61 {:name "Sustainable Supply Chains", :stream 10, :chairs (2650 30997), :timeslot 9, :papers (397 383 389), :track 16}, 63 {:name "Sustainable Production Planning", :stream 10, :chairs (27800), :timeslot 11, :papers (589 611 736), :track 6}, 65 {:name "Agent-based Simulation and Experimental Economics", :stream 10, :chairs (19100), :timeslot 12, :papers (411 671 683), :track 10}, 67 {:name "Computational Social Choice", :stream 1, :chairs (44437), :timeslot 3, :papers (482 484 738), :track 3}, 68 {:name "Optimization Methods for Energy and Environment", :stream 10, :chairs (19331), :timeslot 7, :papers (283 627 293), :track 6}, 69 {:name "Advanced techniques in robust optimization", :stream 8, :chairs (33453 45195), :timeslot 14, :papers (538 745 784), :track 4}, 71 {:name "Logistics Scheduling", :stream 16, :chairs (5934), :timeslot 9, :papers (303 304 346), :track 4}, 73 {:name "Advances in credit scoring methodology II", :stream 7, :chairs (44795), :timeslot 14, :papers (74 772), :track 15}, 75 {:name "Applications of linear and nonlinear optimization II", :stream 3, :chairs (20793 29675), :timeslot 11, :papers (498 804 113), :track 9}, 76 {:name "Auction Theory ", :stream 14, :chairs (41718), :timeslot 5, :papers (188 576 419), :track 24}, 77 {:name "Health Care Operations Management ", :stream 12, :chairs (16870), :timeslot 9, :papers (260 647 502), :track 14}, 79 {:name "Math Programming Solvers", :stream 9, :chairs (16880), :timeslot 12, :papers (90 440 124), :track 21}, 81 {:name "New effective approaches in combinatorial optimization", :stream 4, :chairs (14713), :timeslot 14, :papers (164 350 709 782), :track 7}, 83 {:name "Forecasting Applications for Quantitative Trading and Investing", :stream 7, :chairs (19080), :timeslot 5, :papers (774 128 780), :track 15}, 85 {:name "Forecasting with Computational Intelligence", :stream 7, :chairs (6752), :timeslot 11, :papers (366 922), :track 15}, 86 {:name "Forecasting for Business Analytics II", :stream 7, :chairs (6752), :timeslot 9, :papers (205 265 700), :track 15}, 87 {:name "Vector and Set Optimization I", :stream 6, :chairs (19168 44697), :timeslot 9, :papers (310 759 665), :track 11}, 89 {:name "Logic-Based Benders Decomposition", :stream 4, :chairs (29246), :timeslot 3, :papers (219 245), :track 7}, 90 {:name "Recent Developments in Stochastic Programming", :stream 8, :chairs (31940), :timeslot 2, :papers (175 398 725), :track 6}, 91 {:name "Service Analytics and Optimization", :stream 15, :chairs (44986 44987), :timeslot 2, :papers (145 144 146 147), :track 23}, 92 {:name "Network Games", :stream 1, :chairs (26518), :timeslot 12, :papers (228 575 715), :track 3}, 93 {:name "Combinatorial & Polyhedral Aspects of Scheduling ", :stream 4, :chairs (1019), :timeslot 5, :papers (465 377 746), :track 5}, 94 {:name "Energy Systems Engineering: Methods and Real-Life Applications", :stream 10, :chairs (25633 45065), :timeslot 7, :papers (635 642 688 741), :track 16}, 95 {:name "Airport Operations Scheduling II", :stream 16, :chairs (829), :timeslot 11, :papers (866 252 906), :track 12}, 96 {:name "Optimization Modeling II", :stream 9, :chairs (3753), :timeslot 7, :papers (508 268 613), :track 21}, 97 {:name "Combinatorial Auctions ", :stream 14, :chairs (55333), :timeslot 2, :papers (220 290 187), :track 24}, 98 {:name "Revenue Management and Flexible Products", :stream 14, :chairs (16305), :timeslot 7, :papers (108 84 364), :track 24}, 99 {:name "Modelling Material and Energy Flows", :stream 10, :chairs (17130), :timeslot 11, :papers (514 825 540), :track 16}, 100 {:name "Combinatorial Clock Auctions", :stream 14, :chairs (44978), :timeslot 14, :papers (48 267 597), :track 24}, 101 {:name "Non-Airline Applications of Revenue Management", :stream 14, :chairs (22994), :timeslot 11, :papers (686 758 722 375), :track 24}, 102 {:name "Project Scheduling: Stochastic And Game Theoretic Aspects", :stream 16, :chairs (41246), :timeslot 12, :papers (914 915 916), :track 12}, 105 {:name "Analytics", :stream 2, :chairs (14817 22994 43180), :timeslot 5, :papers (693 696 174), :track 13}, 106 {:name "Optimization in Engineering Science", :stream 4, :chairs (39554), :timeslot 12, :papers (555 561 682), :track 5}, 81652 {:name "Distributed and Remote MIP Solving II", :stream 9, :chairs (3843), :timeslot 11, :papers (227 905), :track 21}, 86813 {:name "Optimization Software I", :stream 9, :chairs (40907), :timeslot 2, :papers (202 734 546), :track 21}, 89890 {:name "Optimization Software II", :stream 9, :chairs (14853), :timeslot 14, :papers (568 460 605), :track 21}, 199830 {:name "Metaheuristics for Assignment Problems", :stream 5, :chairs (19902), :timeslot 9, :papers (672 837), :track 13}, 199831 {:name "Applications of Metaheuristics", :stream 5, :chairs (45046), :timeslot 11, :papers (204 797), :track 13}, 199832 {:name "Combinatorial Markets and Pricing", :stream 14, :chairs (30379), :timeslot 9, :papers (135 259 623), :track 24}, 199833 {:name "Data Envelopment Analyis", :stream 6, :chairs (485), :timeslot 2, :papers (86 775 531), :track 11}, 199834 {:name "Multi-objective Integer Programming I", :stream 6, :chairs (33154), :timeslot 9, :papers (9 590 603), :track 3}, 199835 {:name "Multi-objective Integer Programming II", :stream 6, :chairs (12756), :timeslot 11, :papers (10 61 713), :track 3}, 199836 {:name "Decision Making and Game Theory", :stream 6, :chairs (13262), :timeslot 5, :papers (584 711), :track 11}, 199837 {:name "Multi-objective Optimization", :stream 6, :chairs (45215), :timeslot 3, :papers (771 632 664), :track 11}, 199840 {:name "Multi-criteria Decision Making Methods", :stream 6, :chairs (33450), :timeslot 14, :papers (631 521 382), :track 3}, 199841 {:name "Group Decision Making and Cooperation", :stream 6, :chairs (20840), :timeslot 12, :papers (512 620 369), :track 11}, 199842 {:name "Decision Making in Practice", :stream 6, :chairs (45262), :timeslot 11, :papers (737 56 701), :track 11}, 199845 {:name "Stochastic Flow Lines: Analysis and Optimization", :stream 15, :chairs (29197), :timeslot 3, :papers (524 503 483), :track 23}, 199846 {:name "Flow Lines: Line Balancing and Scheduling", :stream 15, :chairs (44772), :timeslot 14, :papers (617 615 71), :track 20}, 199847 {:name "Lotsizing and Product Returns", :stream 15, :chairs (25632), :timeslot 12, :papers (399 513 786), :track 23}, 199848 {:name "Integrating Lotsizing and Scheduling", :stream 15, :chairs (29814), :timeslot 2, :papers (450 831 707), :track 20}, 199849 {:name "Production Planning and Order Acceptance", :stream 15, :chairs (45153), :timeslot 9, :papers (629 902 536), :track 20}, 199851 {:name "Manufacturing Applications", :stream 15, :chairs (29239), :timeslot 11, :papers (614 473 829), :track 20}, 199852 {:name "Energy, Heat and Steel Production", :stream 15, :chairs (45255), :timeslot 5, :papers (913 341 823), :track 23}, 199854 {:name "Analytics in the Automotive Sector", :stream 15, :chairs (3578), :timeslot 12, :papers (653 769 874), :track 20}, 199856 {:name "Performance Evaluation", :stream 15, :chairs (35215), :timeslot 9, :papers (358 583), :track 23}, 199858 {:name "Supply Chain Design and Collaboration", :stream 17, :chairs (14715), :timeslot 7, :papers (694 588 844), :track 18}, 199859 {:name "Supply Chain Planning", :stream 17, :chairs (22691), :timeslot 12, :papers (104 726 516), :track 18}, 199860 {:name "Information Asymmetry and Risk", :stream 17, :chairs (33414), :timeslot 11, :papers (764 923 527), :track 18}, 199862 {:name "Contracts and Pricing", :stream 17, :chairs (22994), :timeslot 9, :papers (67 307 365), :track 18}, 199863 {:name "Uncertainty", :stream 17, :chairs (29534), :timeslot 14, :papers (151 165 297), :track 18}, 199864 {:name "Attended Home Deliveries", :stream 13, :chairs (19709), :timeslot 11, :papers (273 884), :track 22}, 199865 {:name "Vehicle Routing and Scheduling with Column Generation", :stream 13, :chairs (829), :timeslot 3, :papers (828 755 860), :track 22}, 199867 {:name "Machine Learning and Data Mining", :stream 2, :chairs (26200), :timeslot 14, :papers (372 491 900), :track 13}, 199869 {:name "Resource-Constrained Project Scheduling: Efficient Solution Procedures", :stream 16, :chairs (13330 45367), :timeslot 5, :papers (418 321 896), :track 12}, 199870 {:name "New Models in Project Scheduling", :stream 16, :chairs (14742), :timeslot 14, :papers (599 921 105), :track 12}, 199871 {:name "Applications and Models in Project Scheduling", :stream 16, :chairs (5965), :timeslot 9, :papers (790 534 488), :track 12}, 199872 {:name "Airport Operations Scheduling I", :stream 16, :chairs (41246), :timeslot 3, :papers (451 677 510), :track 12}, 199873 {:name "Flow Shop Scheduling", :stream 16, :chairs (14742), :timeslot 2, :papers (254 276), :track 12}, 199874 {:name "Scheduling on multiple machines", :stream 16, :chairs (29226), :timeslot 7, :papers (494 525 191), :track 12}, 199875 {:name "Applications in Scheduling", :stream 16, :chairs (1244), :timeslot 12, :papers (230 727 792), :track 4}, 199876 {:name "Complex Scheduling", :stream 16, :chairs (14800), :timeslot 3, :papers (445 504 595), :track 4}, 199877 {:name "Multistage Stochastic Programming", :stream 8, :chairs (39554), :timeslot 11, :papers (349 53 577), :track 4}, 199878 {:name "Approximation Algorithms in Robust Optimization", :stream 8, :chairs (6886), :timeslot 7, :papers (592 628 275), :track 4}, 199880 {:name "Scheduling with Uncertainties", :stream 8, :chairs (17092), :timeslot 5, :papers (351 253 443), :track 4}, 199881 {:name "Robustness Issues", :stream 8, :chairs (37090), :timeslot 5, :papers (394 309), :track 6}, 199882 {:name "Stochastic Programming Concepts and Models", :stream 8, :chairs (9512), :timeslot 9, :papers (347 820 859), :track 6}, 199883 {:name "Distributed and Remote MIP Solving I", :stream 9, :chairs (3843), :timeslot 9, :papers (327 849 612), :track 21}, 199884 {:name "Optimization Modeling I", :stream 9, :chairs (45074), :timeslot 3, :papers (490 861 598), :track 21}, 199885 {:name "Network Design", :stream 1, :chairs (19047), :timeslot 7, :papers (594 286 767), :track 3}, 199886 {:name "Security and Inspection Games", :stream 1, :chairs (16887), :timeslot 5, :papers (318 585 705 824), :track 3}, 199887 {:name "Resource Allocation Games", :stream 1, :chairs (23024), :timeslot 14, :papers (714 720 864), :track 8}, 199888 {:name "Cooperative Games", :stream 1, :chairs (33565), :timeslot 2, :papers (426 644 757), :track 8}, 199889 {:name "Mechanism Design II", :stream 1, :chairs (44543), :timeslot 12, :papers (62 691 788), :track 8}, 199890 {:name "Advances in credit scoring methodology I", :stream 7, :chairs (44795), :timeslot 7, :papers (359 879), :track 15}, 199891 {:name "Forecasting for Business Analytics I", :stream 7, :chairs (16621), :timeslot 3, :papers (554 739 766), :track 15}, 199892 {:name "Forecasting Stream Keynote", :stream 7, :chairs (6752), :timeslot 2, :papers (357), :track 15}, 199893 {:name "Vector and Set Optimization II", :stream 6, :chairs (19168 44697), :timeslot 14, :papers (301 430), :track 11}, 199894 {:name "Packing", :stream 4, :chairs (42140), :timeslot 12, :papers (414 509 441), :track 7}, 199896 {:name "Polyhedra", :stream 4, :chairs (12046), :timeslot 2, :papers (385 952 572), :track 5}, 199897 {:name "Online-Optimization", :stream 4, :chairs (45258), :timeslot 3, :papers (429 587 747), :track 2}, 199898 {:name "Traffic", :stream 4, :chairs (44995), :timeslot 11, :papers (76 654 698), :track 5}, 199899 {:name "Transportation", :stream 4, :chairs (33333), :timeslot 7, :papers (535 44 464), :track 5}, 199900 {:name "Location", :stream 4, :chairs (33657), :timeslot 11, :papers (345 618 892), :track 7}, 199903 {:name "Coloring", :stream 4, :chairs (44056), :timeslot 9, :papers (762 903 501), :track 2}, 199905 {:name "Algorithm Engineering", :stream 4, :chairs (27643), :timeslot 9, :papers (904 814 752), :track 7}, 199909 {:name "Branch-and-Price/Branch-and-Cut", :stream 4, :chairs (13058), :timeslot 2, :papers (530 836), :track 7}, 199910 {:name "Mixed Integer Linear Programming", :stream 4, :chairs (13046), :timeslot 2, :papers (5 231 373), :track 2}, 199911 {:name "Network Design", :stream 4, :chairs (16988), :timeslot 9, :papers (236 262 748), :track 5}, 199912 {:name "Complexity", :stream 4, :chairs (39552), :timeslot 14, :papers (257 288 391), :track 2}, 199913 {:name "Matching", :stream 4, :chairs (38193), :timeslot 12, :papers (387 493 692), :track 2}, 199914 {:name "Routing", :stream 4, :chairs (25677), :timeslot 7, :papers (695 781 338), :track 7}, 199916 {:name "Combinatorial Algorithms", :stream 4, :chairs (9255), :timeslot 3, :papers (177 660 127), :track 5}, 199917 {:name "Approximation Algorithms", :stream 4, :chairs (1019), :timeslot 14, :papers (684 893 616), :track 5}, 199918 {:name "Modeling", :stream 4, :chairs (1560), :timeslot 7, :papers (846 432 708 787), :track 2}, 199919 {:name "Column Generation", :stream 4, :chairs (19441), :timeslot 5, :papers (487 827 302), :track 7}, 199920 {:name "Electric and Hybrid Vehicles", :stream 18, :chairs (21108), :timeslot 11, :papers (596 179 730), :track 23}, 199926 {:name "Revenue Management", :stream 14, :chairs (39402), :timeslot 12, :papers (109 199), :track 24}, 199927 {:name "Combined Heat and Power", :stream 10, :chairs (39420), :timeslot 9, :papers (438 563), :track 10}, 199928 {:name "Energy Markets", :stream 10, :chairs (44851), :timeslot 14, :papers (485 559 740), :track 16}, 199929 {:name "Location of Renewable Energy Sources", :stream 10, :chairs (31952), :timeslot 12, :papers (224 680 702), :track 16}, 199930 {:name "Optimization in Regional Energy Systems", :stream 10, :chairs (41926), :timeslot 2, :papers (908 845 865), :track 16}, 199931 {:name "Planning of Energy Availability", :stream 10, :chairs (44991), :timeslot 12, :papers (141 209 248), :track 6}, 199932 {:name "Planning of Local Generation and Consumption", :stream 10, :chairs (39469), :timeslot 7, :papers (203 492 564), :track 10}, 199933 {:name "Recycling and Electrical Vehicles", :stream 10, :chairs (44380), :timeslot 14, :papers (340 657 867), :track 10}, 199934 {:name "Sustainable Energy Supply Networks", :stream 10, :chairs (32283), :timeslot 14, :papers (604 639 760), :track 6}, 199936 {:name "Planning Emergency Medical Services", :stream 12, :chairs (33571), :timeslot 14, :papers (557 681 728), :track 14}, 199937 {:name "Operating Room Planning & Scheduling", :stream 12, :chairs (41246), :timeslot 12, :papers (374 528 838), :track 14}, 199938 {:name "Transportation in Health Care", :stream 12, :chairs (1256), :timeslot 11, :papers (87 376), :track 14}, 199939 {:name "Train Path Assignment", :stream 18, :chairs (33323), :timeslot 11, :papers (263 264 331), :track 19}, 199940 {:name "Airline Applications", :stream 18, :chairs (45357), :timeslot 14, :papers (676 912), :track 23}, 199941 {:name "Public Transport", :stream 18, :chairs (29288), :timeslot 7, :papers (380 520), :track 23}, 199942 {:name "Collaborative Aspects in Routing and Scheduling", :stream 18, :chairs (45069), :timeslot 9, :papers (858 481 243), :track 19}, 199943 {:name "Rail Freight Transportation", :stream 18, :chairs (35097), :timeslot 14, :papers (401 541 732), :track 19}, 199944 {:name "Rail Transportation", :stream 18, :chairs (45116), :timeslot 3, :papers (444 573 817), :track 19}, 199945 {:name "Routing and Vehicle Logistics", :stream 18, :chairs (45154), :timeslot 7, :papers (478 743), :track 19}, 199946 {:name "Routing", :stream 18, :chairs (45437), :timeslot 5, :papers (670 765 925), :track 19}, 199947 {:name "Routing: Pickup-and-Delivery", :stream 18, :chairs (21140), :timeslot 12, :papers (703 712 852), :track 19}, 199948 {:name "GOR Masterthesis Award", :stream 20, :chairs (1560), :timeslot 5, :papers (929 934 930), :track 2}, 199949 {:name "GOR Dissertation Award", :stream 20, :chairs (14715), :timeslot 11, :papers (927 931 932 933), :track 2}, 199955 {:name "Inventory Management", :stream 13, :chairs (12938), :timeslot 14, :papers (158 237 821), :track 22}, 199957 {:name "Vehicle Routing and Scheduling and Pickup and Delivery", :stream 13, :chairs (3614), :timeslot 12, :papers (423 924 277 466), :track 22}, 199958 {:name "Applications of linear and nonlinear optimization I", :stream 3, :chairs (20793 29675), :timeslot 5, :papers (77 542 574), :track 9}, 199959 {:name "Nonlinear Optimization II", :stream 3, :chairs (42723), :timeslot 12, :papers (453 500 749 160), :track 9}, 199960 {:name "Variational Inequalities and Related Topics II", :stream 3, :chairs (35439), :timeslot 14, :papers (14 655 841), :track 9}, 199961 {:name "Risk and Uncertainty", :stream 11, :chairs (33522), :timeslot 3, :papers (40 368 887), :track 17}, 199963 {:name "Financial Modeling", :stream 11, :chairs (45240), :timeslot 12, :papers (511 549 651), :track 17}, 199964 {:name "Accounting", :stream 11, :chairs (45228), :timeslot 7, :papers (371 448 704), :track 17}, 199965 {:name "Opening Ceremony", :stream 19, :chairs (14969), :timeslot 1, :papers (935), :track 1}, 199966 {:name "Closing Ceremony", :stream 19, :chairs (14969), :timeslot 15, :papers (936), :track 1}, 199967 {:name "Semiplenary Barber", :stream 19, :chairs (19297), :timeslot 13, :papers (941), :track 4}, 199968 {:name "Semiplenary Ben-Tal", :stream 19, :chairs (9512), :timeslot 8, :papers (939), :track 1}, 199969 {:name "Semiplenary Boyd", :stream 19, :chairs (20793), :timeslot 10, :papers (942), :track 1}, 199970 {:name "Semiplenary Dörner", :stream 19, :chairs (5931), :timeslot 13, :papers (949), :track 2}, 199971 {:name "Semiplenary Fransoo", :stream 19, :chairs (14573), :timeslot 4, :papers (946), :track 2}, 199972 {:name "Semiplenary Gritzmann", :stream 19, :chairs (13046), :timeslot 4, :papers (945), :track 1}, 199973 {:name "Semiplenary Lee", :stream 19, :chairs (1256), :timeslot 4, :papers (951), :track 5}, 199974 {:name "Semiplenary Marschner", :stream 19, :chairs (8504), :timeslot 8, :papers (950), :track 2}, 199975 {:name "Semiplenary McLay", :stream 19, :chairs (41246), :timeslot 8, :papers (944), :track 4}, 199976 {:name "Semiplenary Puget", :stream 19, :chairs (12177), :timeslot 13, :papers (947), :track 1}, 199977 {:name "Semiplenary Rönnqvist", :stream 19, :chairs (2650), :timeslot 10, :papers (940), :track 2}, 199978 {:name "Semiplenary Vohra", :stream 19, :chairs (26518), :timeslot 10, :papers (943), :track 4}, 199979 {:name "Company Award", :stream 20, :chairs (1141), :timeslot 4, :papers (960), :track 25}, 199980 {:name "OR Success Stories I", :stream 21, :chairs (24366), :timeslot 2, :papers (937 953 938 954), :track 25}, 199981 {:name "OR Success Stories II", :stream 21, :chairs (45699), :timeslot 3, :papers (956 958 959 963), :track 25}, 199982 {:name "OR Success Stories III", :stream 21, :chairs (3843), :timeslot 5, :papers (948 957 961 962), :track 25}, 199983 {:name "Business Panel Discussion", :stream 21, :chairs (30476), :timeslot 6, :papers (955), :track 25}}, :rooms {1 {:room "Fo1"}, 2 {:room "Fo2"}, 3 {:room "Fo3"}, 4 {:room "Fo4"}, 5 {:room "Fo5"}, 6 {:room "Fo6"}, 7 {:room "Fo7"}, 8 {:room "Fo8"}, 9 {:room "SFo1"}, 10 {:room "SFo2"}, 11 {:room "SFo3"}, 12 {:room "SFo4"}, 13 {:room "SFo9"}, 14 {:room "SFo10"}, 15 {:room "SFo11"}, 16 {:room "SFo14"}, 17 {:room "001"}, 18 {:room "004"}, 19 {:room "I"}, 20 {:room "II"}, 21 {:room "III"}, 22 {:room "IV"}, 23 {:room "V"}, 24 {:room "AS"}, 25 {:room "AachenMuenchener Halle (Aula)"}}, :keywords {2 {:name "Airline Applications", :sessions (28 199872 199982 98 199830 199898 95 81 199940)}, 5 {:name "Artificial Intelligence", :sessions (199892 199877 199831 85 199854)}, 6 {:name "Auctions / Competitive Bidding", :sessions (97 10 76 199862 199832 33 100)}, 7 {:name "Capacity Planning", :sessions (199980 32 83 199982 199899 94 199911 199927 63 199939 199859)}, 8 {:name "Combinatorial Optimization", :sessions (42 199896 199873 199848 199897 199876 199916 199865 199972 199948 93 199919 5 199852 199918 199878 199899 68 199941 199903 199834 199911 19 50 199832 199978 199949 199877 199898 199900 95 199913 92 199875 106 199931 199894 199959 199912 69 199917 81 199943)}, 12 {:name "Computational Biology", :sessions (199919)}, 13 {:name "Convex Optimization", :sessions (199958 199969 199842 81 199960)}, 14 {:name "Continuous Optimization", :sessions (199910 4 199958 199836 199959 199960)}, 16 {:name "Cutting and Packing", :sessions (199916 199894)}, 17 {:name "Data Envelopment Analysis", :sessions (199833 24 199856 199842)}, 18 {:name "Decision Support Systems", :sessions (15 28 86813 199891 199944 10 199886 105 37 199874 44 77 50 199842 81652 199841 199937 199854 199847 199840 199934 199933 199867)}, 19 {:name "Decision Theory and Analysis", :sessions (30 199833 67 199886 199869 24 199964 61 199862 199842 199889 199841 199840)}, 22 {:name "Disaster and Crisis Management", :sessions (199874 199975 199830 199877)}, 23 {:name "Dynamical Systems", :sessions (199892 199932 85)}, 25 {:name "Economic Modeling", :sessions (199833 76 199932 51 199862 33 75 199847 199926 199960 199933 199928)}, 27 {:name "Education and Distance Learning", :sessions (199884 199856 89890)}, 28 {:name "Electrical Markets", :sessions (199930 10 199981 199932 55 65 199934 199928)}, 29 {:name "Energy Policy and Planning", :sessions (60 199930 45 10 199981 199852 68 199932 24 94 199903 199927 61 63 55 99 199875 199931 65 199929 199934 199928)}, 30 {:name "Enterprise Resource Planning Systems", :sessions (44)}, 31 {:name "Environmental Management", :sessions (61 199977 99 65 199934 199933)}, 32 {:name "Expert Systems and Neural Networks", :sessions (83)}, 33 {:name "Facilities Planning and Design", :sessions (199918 199858 199911)}, 34 {:name "Finance and Banking", :sessions (199833 199961 51 199963 73)}, 35 {:name "Financial Modelling", :sessions (199837 199961 199958 83 199890 51 199929 199963 199912)}, 36 {:name "Flexible Manufacturing Systems", :sessions (199851)}, 37 {:name "Forecasting", :sessions (199930 86813 91 199891 83 86 85 199931)}, 39 {:name "Fuzzy Sets and Systems", :sessions (15 199837 199852 199871 63)}, 40 {:name "Game Theory", :sessions (30 199888 7 67 8 45 199948 199886 39 199836 76 199885 58 19 199942 199832 199978 33 199842 199860 92 199889 199887 100)}, 41 {:name "Global Optimization", :sessions (199910 47 199835 75)}, 42 {:name "Graphs and Networks", :sessions (30 199896 199888 15 86813 26 97 199980 199916 199880 39 199885 199899 199914 199903 199882 199942 199900 33 199913 92 106 199894 199912 199840 199867)}, 44 {:name "Group Decision Making and Negotiation", :sessions (26 199964 199860 199841 199840)}, 45 {:name "Health Care", :sessions (199973 37 199858 199975 77 199938 199937 199936)}, 47 {:name "Human Resources Management", :sessions (199842)}, 48 {:name "Industrial Optimization", :sessions (91 199836 25 199852 199982 199927 199871 99 199851 199959 199929 199846)}, 49 {:name "Interior Point Methods", :sessions (199958)}, 52 {:name "Knowledge Engineering and Management", :sessions (199967)}, 53 {:name "Large Scale Optimization", :sessions (94 199905 199969 199959 79 199976 199943)}, 54 {:name "Location", :sessions (199916 37 199858 199911 199898 199900 199920 199840 199936 199940)}, 56 {:name "Marketing", :sessions (105 24 86 33 75)}, 57 {:name "Mathematical Programming", :sessions (199896 7 28 199980 45 199884 199845 199973 199903 199883 63 33 199938 81652 79 199893 199928)}, 59 {:name "Metaheuristics", :sessions (199848 91 46 199948 199869 199946 5 47 199830 63 199831 199875 199870 199846)}, 60 {:name "Military Operations Research", :sessions (199872 85)}, 61 {:name "Modeling Systems and Languages", :sessions (86813 199884 199869 44 96 199883 199851 81652)}, 63 {:name "Multi-Objective Decision Making", :sessions (199888 199833 199897 199837 199869 199964 199941 98 199834 199841 199840 199934)}, 65 {:name "Network Design", :sessions (199909 39 37 199918 199885 68 199914 27 199911 199898 199900 69 199933 199940)}, 66 {:name "Non-smooth Optimization", :sessions (7 199905)}, 67 {:name "Optimization in Financial Mathematics", :sessions (199837 199961 51 199893)}, 72 {:name "OR in Sports", :sessions (199965 199889)}, 73 {:name "OR/MS and the Public Sector", :sessions (199918 199964 77 199856)}, 74 {:name "Parallel Algorithms and Implementation", :sessions (199883)}, 75 {:name "Production and Inventory Systems", :sessions (199848 32 199845 199981 199982 44 199849 99 199851 199875 199854 199847 199863 199846 199955)}, 86 {:name "Project Management and Scheduling", :sessions (15 199872 199869 199871 102 199870 89890)}, 88 {:name "Queuing Systems", :sessions (199891 199845)}, 89 {:name "Reliability", :sessions (199891 54 199849 199842 199867)}, 91 {:name "Revenue Management and Pricing", :sessions (105 199852 98 199832 199831 199864 101 199926)}, 92 {:name "Reverse Logistics / Remanufacturing", :sessions (47 61 199862 99 101 199847 199926 199933)}, 93 {:name "Risk Analysis and Management", :sessions (199961 199886 199881 199890 199882 199842 199860 199841 199963 199893)}, 94 {:name "Robust Optimization", :sessions (42 89 45 199961 32 199880 199881 199958 199852 199878 54 199968 87 199883 199977 199949 199877 199898 199931 69)}, 95 {:name "Routing", :sessions (199909 26 199916 8 199872 199865 199946 5 199914 54 199942 50 199949 199938 199864 199947 199957 199936)}, 96 {:name "Scheduling", :sessions (199873 28 91 199897 199876 89 199872 199944 199880 93 199946 25 199852 199878 68 199874 44 71 199871 77 199942 199898 63 95 199851 101 199875 199937 199854 199957 199847 199917 81 199943 199846 89890)}, 97 {:name "Simulation", :sessions (60 199930 91 199845 199979 199982 199918 199858 27 199927 61 199849 199877 99 199851 199854 199957 199936 199863)}, 98 {:name "Software for OR/MS Analysis", :sessions (86813 199884 199881 96 199883 81652 79 89890)}, 99 {:name "Stochastic Models", :sessions (30 199930 86813 32 199845 199958 25 47 54 199964 199945 199882 199856 55 199917 199863 199955)}, 100 {:name "Strategic Planning and Management", :sessions (199945 199927 61 199931)}, 101 {:name "Supply Chain Management", :sessions (97 4 32 199981 199971 37 24 199874 199858 44 27 199968 61 199862 199849 199831 199860 199920 199859 199854 199933 199863 199955)}, 102 {:name "Sustainable Development", :sessions (60 61 99 199920 199840 199934 199933 199863)}, 103 {:name "System Dynamics and Theory", :sessions (60 61)}, 104 {:name "Telecommunications", :sessions (97 199837 105 199918 199914 199911 199949 199898 199900)}, 105 {:name "Timetabling", :sessions (89 54 199939)}, 108 {:name "Variational Problems", :sessions (199959)}, 109 {:name "Warehouse Design, Planning, and Control", :sessions (199851 199957)}, 115 {:name "Problem Structuring Methods", :sessions (86813)}, 120 {:name "Data Mining", :sessions (15 24 86 199959 199854 199867)}, 121 {:name "Rostering", :sessions (28 199938)}, 124 {:name "Machine Learning", :sessions (10 199958 199968 199905 86 199931 199967 199867 73)}, 126 {:name "Optimal Control", :sessions (7 68 199890 94 75 106)}, 127 {:name "Agent Systems", :sessions (60 199930 67 10 199918 65 199934 199887)}, 133 {:name "Engineering Optimization", :sessions (45 94 63 75 199831 199920 106 199931 69 81)}, 134 {:name "Equilibria", :sessions (30 8 39 199836 199885 58 19 33 92 199889 199887 199960)}, 138 {:name "Ethics", :sessions (199886)}, 140 {:name "Accounting", :sessions (199964 199849)}, 141 {:name "Managerial Accounting", :sessions (199964 199860)}, 142 {:name "Auditing", :sessions (65)}, 143 {:name "Universities", :sessions (199856)}, 144 {:name "Public Institutions", :sessions (199948)}, 145 {:name "Corporate Social Responsibility", :sessions (105)}, 149 {:name "Business Analytics", :sessions (86813 91 199891 105 83 25 199983 27 51 85 199976 73 199966)}, 150 {:name "Decomposition Methods", :sessions (199965 199909 199848 199876 89 199872 94 199858 199949 95 101 199870)}, 151 {:name "Approximation Algorithms", :sessions (199888 199873 199897 8 199880 199878 58 199945 19 199949 199877 199900 199957 199912 199917)}, 152 {:name "Statistics", :sessions (199891 199961 199886 199890 51 199929 73)}, 153 {:name "Computational Experiments", :sessions (42 199884 47 199905 199942 199851 81652 73 199846)}, 154 {:name "Computational Complexity", :sessions (30 42 199873 67 8 199874 71 199911 199912 199917 199887)}, 155 {:name "Constraint Programming", :sessions (7 199869)}, 156 {:name "Dynamic Programming", :sessions (97 199916 199961 199944 199836 105 199890 199834 71 199882 77 199864 101 199928 199955)}, 157 {:name "Integer Programming", :sessions (199965 199910 199896 199909 199876 89 199865 199948 93 199919 199918 199899 199914 199903 199834 199905 199849 199832 199949 199835 199898 75 199931 199929 199957 69 81 199867)}, 158 {:name "Mixed-Integer Programming", :sessions (199910 7 199848 4 199872 46 45 199944 32 199884 199886 199919 199946 25 5 199852 68 199932 199874 94 199858 199945 199911 199905 51 199883 199832 199835 199898 75 199939 199913 106 199894 199937 199947 79 199840 199934 199870 199943 199846 199940)}, 159 {:name "Linear Programming", :sessions (199910 199848 32 58 94 96 87 199835 199860 79 199912)}, 160 {:name "Duality", :sessions (199958 199913 199893)}, 161 {:name "Multi-Objective Programming", :sessions (199837 199834 87 199835 199960)}, 162 {:name "Nonlinear Programming", :sessions (7 4 45 63 75 106 199959 79 199960)}, 163 {:name "Quadratic Programming", :sessions (68 199949 199929)}, 164 {:name "Semidefinite Programming", :sessions (90 199918 81)}, 165 {:name "Stochastic Programming", :sessions (90 45 199845 199880 199882 199849 50 199835 199877 55 199926)}, 166 {:name "Descripte Analytics", :sessions (105)}, 167 {:name "Predictive Analytics", :sessions (10 83 73)}, 169 {:name "Advanced Analytics", :sessions (91 10 199918 86 199864 199929)}, 170 {:name "Matheuristics", :sessions (199848 46 199834 95 199970)}, 171 {:name "Big Data", :sessions (199972 199919 86 199959 199976 199966)}, 172 {:name "Social Networks", :sessions (199910 199903 19)}, 173 {:name "Algorithm Analysis", :sessions (42 199888 86813 199897 199972 93 68 58 199900 92)}, 174 {:name "Logistics", :sessions (26 91 199980 46 199944 199865 199881 199946 37 25 5 24 47 27 199974 71 50 199977 199864 199920 199913 199859 199947 199854 199957 69 199863 199943 89890)}, 175 {:name "Transportation", :sessions (199896 60 28 26 199980 199944 199981 199948 199881 5 199899 68 47 54 199945 199941 71 199942 50 199949 199939 199920 92 199859 199947 199936 199943 199940)}, 176 {:name "Polyhedral Combinatorics", :sessions (199896 199886 93 199949 81)}, 178 {:name "Econometric Models", :sessions (101)}, 179 {:name "Time Series Analysis", :sessions (55 85 199931)}, 181 {:name "Forecasting algorithms", :sessions (199892)}, 182 {:name "Forecasting applications", :sessions (83 199932 86 199963 199859)}, 183 {:name "Statistics with Big Data", :sessions (105 199859)}}, :papers {5 {:keyword1 158, :keyword3 14, :abstract "We introduce computable a-priori and a-posteriori error bounds \r\nfor optimality and feasibility of a point generated as the rounding \r\nof an optimal point of the LP relaxation of a mixed integer linear \r\noptimization problem. Treating the mesh size of integer vectors as \r\na parameter allows us to study the effect of different `granularities' \r\nin the discrete variables on the error bounds. Our analysis mainly bases \r\non the construction of a so-called grid relaxation retract. Relations to \r\nproximity results and the integer rounding property are highlighted.", :title "Error bounds for mixed integer linear optimization problems", :keyword2 159, :authors (2795), :session 199910}, 9 {:keyword1 8, :keyword3 157, :abstract "In this paper, we treat the  binary combinatorial optimisation problems by focusing  on bi- objective study as was widely done in the  mono-objective case. On the basis of   Julien Gorge's observation  made in his paper, where he proposed  a new approach for reducing  a priori the size of the binary uni-dimensional knapsack problem with multiple objectives; this reduction   allows to fix a priori some components to 0 or 1 in all the efficient solutions, showing  that many variables do not satisfy  the developped properties to reduce the instances size of the bi-objectif Knapsack problem, even if they are regular. To remedy some of these last cases, we propose, however, another way to do so. The approach is based on the determination of the supported extreme solutions and the dominance relation   of the efficiency of   the objectifs objects. A didactic example is presented to illustrate all the stages as well as  some numerical experiments.", :title "New properties to reduce the size of bi-objective knapsack problems", :keyword2 161, :authors (22571), :session 199834}, 10 {:keyword1 165, :keyword3 157, :abstract "In this paper, we study the problem of optimizing a linear function over an integer efficient solution set in the stochastic discrete environment. A new exact technique is proposed however, to provide the best preference to the decision maker among a set of stochastic non dominated solutions. \r\nOnce the problem is converted into a deterministic one by adapting the 2-levels recourse approach, a new pivoting technique is applied to generate an optimal penalized efficient solution without having to enumerate all of them.  The combination of both approaches L-Shaped and the combined method proposed by Chaabane & Pirlot (JIMO 2010) enables us to come up not only with an optimal solution efficient but also with sub-a set of stochastic efficient solution defining the path joining the later. \r\n", :title "A New Algorithme for Optimizing Over Integer Efficient Stochastic Set", :keyword2 161, :authors (26435 22571), :session 199835}, 14 {:keyword1 134, :keyword3 25, :abstract "In this talk we suggest a new framework for constructing mathematical models of market activity. Contrary to the majority of the classical economical models (e.g. Arrow-Debreu, Walras, etc.), we get a characterization of general equilibrium of the market as a saddle point in a convex-concave game. This feature significantly simplifies the proof of existence theorems and construction of the adjustment processes both for producers and consumers. Moreover, we argue that the unique equilibrium prices can be characterized as a unique limiting point of some simple price dynamics. In our model, the equilibrium prices have natural explanation: they minimize the total excessive revenue of the market's participants. Due to convexity, all our adjustment processes have unambiguous behavioral and algorithmic interpretation. From the technical point of view, the most unusual feature of our approach is the absence of the budget constraint in its classical form.", :title "Algorithmic models of market equilibrium", :keyword2 13, :authors (20607 25671), :session 199960}, 25 {:keyword1 39, :keyword3 0, :abstract "Gerade im ökonomischen Kontext sind häufig Sachverhalte anzutreffen, deren Wesen nur unscharf beschrieben werden kann. Eine Basis für die Modellierung solcher Sachverhalte in Form von unscharf definierten Begriffen und Zusammenhängen stellt die von Lofti Zadeh begründete Fuzzy-Mengentheorie dar. War es in der frühen Phase Experten vorbehalten, unscharfes Wissen in Form von Systemen zu beschreiben, die auf der Fuzzy-Mengentheorie beruhen, wurde im Zuge der fortschreitenden Entwicklung eine Vielzahl von Verfahren entwickelt, mit deren Hilfe unscharfe Strukturen direkt aus vorhandenen Daten extrahiert werden können. Eine Grundeigenschaft der meisten dieser Verfahren besteht allerdings in der ausschließlichen Behandlung von Daten auf kardinalem Skalenniveau. Eine Berücksichtigung von Daten auf ordinalem oder nominalem Skalenniveau und speziell von Daten auf unterschiedlichen Skalenniveaus, die gerade im Hinblick auf Analysen im ökonomischen Bereich interessant erscheint, fand und findet nur in Ansätzen statt. Im Rahmen dieses Vortrages soll beschrieben werden, wie Daten auf unterschiedlichen Skaleniveaus einer Analyse mit Methoden der Fuzzy-Datenanalyse zugänglich gemacht werden können. Nach der Motivierung des Themas und der Einführung in die Problemstellung soll gezeigt werden, wie ausgewählte bereits existierende Verfahren der Fuzzy-Datenanalyse durch geeignete Modifikationen bzw. Erweiterungen für eine Analyse von Daten auf unterschiedlichen Skalenniveaus eingesetzt werden können. Abschließend soll anhand von exemplarisch ausgewählten Datensätzen die Geeignetheit der vorgestellten Verfahren zur Analyse von Daten auf unterschiedlichen Skalenniveaus aufgezeigt werden.", :title "Methoden der Fuzzy-Datenanalyse für gemischt-skalierte Daten", :keyword2 120, :authors (33402), :session 15}, 27 {:keyword1 65, :keyword3 101, :abstract "Companies all over the world are confronted with designing and redesigning the supply chain of their businesses. A typical supply chain consists of the following levels: suppliers, plants, distribution centers and customer markets. The location of distribution centers is, for example, an expensive and a difficult to reverse long-term, strategic decision that can be tackled with supply chain network design. However, tactical and operational level decisions are often taken into account when addressing supply chain network design issues: the inventory flows and order policies between consecutive supply chain stages depend on the network design. The importance of integrating these decision levels can hardly be overestimated. \r\nThe aim of this literature review is twofold. We provide an updated overview on integrated supply chain network design and we study the issues for the design of a supply chain network for a peculiar pharmaceutical product: vaccines. Vaccines are not ordinary commodities and concern the human race. They reduce the worldwide disease burden of many infectious diseases. The methods of distribution are country dependent and affected by national vaccination policies. This complicates the demand forecasting of vaccines. The total lead time of vaccines varies between 9 and 22 months which makes it even more difficult to match supply and demand. These long lead times are due to the permanent quality control and quality assurance. The perishability of vaccines requires cold chain management to ensure a safe vaccination for the entire world population. Furthermore, the high inventory value and the short shelf-life of the vaccines complicate the inventory management.\r\n", :title "Integrated supply chain design models for vaccines: A literature review", :keyword2 45, :authors (40456 27395 27254), :session 37}, 32 {:keyword1 54, :keyword3 174, :abstract "Our research is inspired by the real-life case of a leading European glass manufacturer, with around 500 customers throughout Europe. The case concerns its reverse logistics network, and the idea of accumulating folded empty trestles in regional depots, to return them to factories in trucks that are better utilized. Consequently, in this problem, inventory management decisions such as the shipment size play a central role, and have to be integrated with the location-allocation decisions. Inspired by this practical case, we study the location of intermediary facilities in a three-level network (reverse or forward), where factories and customers have fixed locations. The cost function covers transportation and facility fixed costs as well as inventory holding and handling costs, and thus underlines the important trade-off between these costs. We allow for direct flows between factories and customers and consider capacitated vehicles. In order to be able to analyze large real-life problems, we develop a continuous optimization formulation (and avoid using integer variables). The latter is shown to decompose when the flows through the DCs are fixed. In this case, the inventory decisions can be computed from a closed-form equation and the location-allocation decisions follow from solving a linear program. Based on this, we propose an iterative heuristic which, at each iteration, estimates the DC flows, solves a linear program, and then improves the DC flow estimations. In order to assess its efficiency, the heuristic is tested on many different configurations. It shows to be able to design large supply chains and to uncover benefits from inventory decisions. Finally, we illustrate the application of our approach on the inspiring practical case.", :title "A location-inventory model and heuristic to design large supply chains", :keyword2 101, :authors (24964 25059 25052), :session 37}, 40 {:keyword1 93, :keyword3 0, :abstract "Time unit invariance is introduced as an additional requirement for multiperiod risk measures: for a constant portfolio under an iid risk factor process, the multiperiod risk should equal the one period risk of the aggregated loss, for an appropriate choice of parameters and independent of the portfolio. Multiperiod maximum loss over a sequence of Kullback-Leibler balls is time unit invariant, whereas multiperiod Value at Risk is not.", :title "Multiperiod Maximum Loss Is Time Unit Invariant", :keyword2 156, :authors (29408 18480), :session 199961}, 43 {:keyword1 170, :keyword3 59, :abstract "The Berth Allocation Problem aims at assigning and scheduling incoming vessels to berthing positions along the quay of a container terminal. This problem is a well-known optimization problem within maritime shipping. In order to address it, we propose two POPMUSIC (Partial Optimization Metaheuristic Under Special Intensification\r\nConditions) approaches that incorporate an existing mathematical programming formulation for solving it. POPMUSIC is an efficient metaheuristic that may serve as blueprint for matheuristics approaches once\r\nhybridized with mathematical programming. In this regard, the use of exact methods for solving the sub-problems defined in the POPMUSIC template highlight an interoperation between metaheuristics and mathematical programming techniques, which provide a new type of Approach for this problem. Computational experiments reveal excellent results outperforming best approaches known to date.", :title "A Matheuristic Approach for the Berth Allocation Problem ", :keyword2 174, :authors (5931 36160), :session 46}, 44 {:keyword1 175, :keyword3 0, :abstract "Lagrange's four-square theorem states that every natural number can be represented by the sum of at most four square numbers. The theorem is generalized to transportation problems with two factories (capacities a1, a2) and two customers (demands b1, b2). \r\n\r\nWhen all four parameters are natural numbers, there exists a transportation plan where the amounts can be represented by altogether eleven squares or less. There exist examples where eleven squares are necessary. \r\n\r\nHere is an example where ten squares are needed: a1=7, a2=113, b1=b2=60. Examples which require eleven squares are much more complicated. Numerical simulations seem to indicate that for (asymptotically) almost all instances eight squares are enough.\r\n\r\nThis is joint work with Katharina Collatz, Robert Hesse, and Anne Hilbert. ", :title "On the Representation of Transportation Plans by Sums of Squares", :keyword2 8, :authors (39159), :session 199899}, 48 {:keyword1 6, :keyword3 0, :abstract "The Combinatorial Clock Auction (CCA) is an important recent innovation in auction design that has been utilised for many spectrum auctions worldwide. While the theoretical foundations of the CCA are described in a growing literature, many of the practical implementation choices are omitted. In this paper, we review and discuss the most critical practical decisions for a regulator implementing the CCA. The list of topics includes: incorporation of competition policy objectives, implementation of reserve prices, activity rules, price incrementing policy, and accommodation of technological choice. We illustrate our discussion with examples from recent CCAs, including UK and Ireland spectrum auctions.", :title "A Practical Guide to the Combinatorial Clock Auction", :keyword2 0, :authors (44011 44036), :session 100}, 50 {:keyword1 18, :keyword3 0, :abstract "Sustainability goes far beyond the inclusion of emissions. We present a five-step framework where supply chain modelling is embedded in a broader contextual setting to preserve sustainability in all its aspects: stakeholder analysis, key performance setup, model construction and scenario building, scenario ranking and final design choice. This contribution focusses on the first and second step. The stakeholder analysis provides insight in the number, type and interrelationships between the various stakeholders. We cover internal and external, supply and demand type of stakeholders. From this analysis a concise set of key performance indicators is derived. In this process we preserve the inclusion of different types of KPI’s, which we classify as technical, economical and value based. It is along these types we balance the sustainability aims of the supply chain: technological sustainability from the viewpoint of products, services and supply systems; economical sustainability in term of the financial continuation of the system and the sustainability based on the human values contain, user and customer values as well as ecological, social and ethical aspects. We will illustrate the approach with real-life industrial evidence. ", :title "A stakeholder perspective as a basis for sustainable supply chain design", :keyword2 0, :authors (27395 27254 40456), :session 37}, 53 {:keyword1 165, :keyword3 94, :abstract "We review the notion of nested distance for filtered stochastic processes as a basis for approximation results in multistage stochastic programming. \r\n\r\nThis notion is used in scenario tree generation, bounding techniques and in ambiguity models. \r\n\r\nThe talk reviews some results contained in the forthcoming Sprnger book \"Multistage Stochastic Programming\" by G. Pflug and A. Pichler.  \r\n", :title "Multistage stochastic programs: metrics, approximations, ambiguity", :keyword2 151, :authors (3122), :session 199877}, 56 {:keyword1 19, :keyword3 89, :abstract "We investigate the concept of system survivability under attack. This concept is particularly important nowadays given the intelligent threats the world is confronting including terrorism, rebellions, civil wars, and so on. We discuss the discrete and continuous cases as well as network systems. We display results for some classical configurations including series-parallel, parallel-series, and k-out-of-n systems. We also discuss the case of repetitive attacks. Moreover, we will briefly outline defensive and offensive planning resources through the expected number of attacks for each system configuration. This gives rise to a game problem between the defender and the attacker where the first player seeks preserving system functionality while the second considers the best attack strategies to force disabling the targeted system.", :title "System Survivability under Attack: Concept and preliminary results ", :keyword2 40, :authors (44404 44403), :session 199842}, 57 {:keyword1 29, :keyword3 57, :abstract "Transmission system operators are faced with the task of routing natural gas through a network of pipelines. The friction in the pipelines lead to pressure loss, that must be compensated by compressor machines to enable transportation along far distances. In addition to compressors, active components such as valves and regulators are used to control the flow of gas and sustain feasible operation within technical and contractual limits. The operators may also request to change the supply distribution at entries through contractual means. For example, the supply at one entry might be reduced, but then another entry has his supply increased to retain a balanced nomination of flow. The suppliers then react in the manner of a Stackelberg game and can choose the supply nodes used for rebalancing. This game is modeled as a bilevel optimization problem, extending an MINLP formulation of the feasibility problem for stationary gas transport. We study the impact of these contractual means on the transport capacity of the networks under different scenarios of opponent behavior. Preliminary computational results are presented.", :title "Increased Capacity in Pipeline Transport through Flexibility in Supply Distribution", :keyword2 40, :authors (33505 14736 24343), :session 45}, 61 {:keyword1 159, :keyword3 157, :abstract "We propose an exact method allowing the generation of Choquet- optimal solutions of a multiple objective Integer linear programming problem (MOILP). A Choquet-optimal solution is a solution that optimizes the Choquet integral for certain values of its parameters and is Pareto optimal. The method is based on optimization of a Choquet integral and it obviously remains valid for MOLP problems in which case it is no longer preferable because of its complexity compared to the weighted sum for example, which in this case generates the same set of Pareto-optimal solutions. For MOILP problems, the main contribution of the proposed method here is the ability to generate some unsupported solutions stuck in concave portions of the efficient frontier.", :title "Optimization of a Choquet integral in a multiple objective integer linear programming problem", :keyword2 161, :authors (44516 22571), :session 199835}, 62 {:keyword1 40, :keyword3 134, :abstract "It is consensus in different fields of practical relevance that the introduction of taxes might affect somehow the playing behavior of actors. Think of e.g. a financial transaction tax, taxes on betting- or poker-platforms, winning taxes in casinos, etc. However, it is not that clear what the effects might really look like. \r\nHere, a game-theoretic-model is considered that concentrates on taxation-effects on transferred monetary volume. For matrix games it is asked: How do taxes on profits change the behavior of players and the expected transacted volume? Analyzing this basic research model clearly shows: one has to be careful in considering taxes as panacea to confine aggressive playing behavior! Taxes might encourage increased expected transfers!  ", :title "Effects of Profit-Taxation in Matrix Games", :keyword2 19, :authors (44543), :session 199889}, 67 {:keyword1 101, :keyword3 0, :abstract "Analyzing the newsvendor context in laboratory experiments gives new insights into the behavioral aspects of\r\ndecision makers. However, a valid question is whether the results of experimental studies can be transferred\r\nto real world decisions. We test this by analyzing the decisions of real decision makers. We derive normative\r\nbenchmarks for the profit maximizing behavior and compare these to actual data. Our findings indicate that\r\nreal decision makers show similar decision biases as students in laboratory environments. Being the first to\r\nanalyze a multi product setting we find a new decision bias, as our decision maker is aggregating costs.", :title "Empirical Newsvendor Decisions under a Service Level Contract", :keyword2 19, :authors (19894), :session 199862}, 71 {:keyword1 96, :keyword3 48, :abstract "Splitting of a number of jobs consisting of several identical items into consistent sublots with sublot-attached setups is studied. Processing is conducted in an overlapping way on at least two successive machines in a permutation flow shop environment, known as lot streaming. \r\nThe minimization of the total time deviation from due windows under the assumption of several due windows per job is considered, including earliness and tardiness penalties. Lot streaming research has focused little attention on due date objective functions in general, and the research question of due date vectors per job in particular has not been addressed before. However, it is important if several identical items have to be produced and delivered to customers in various time slots. \r\nA decomposition based solution heuristic is presented and sublots are allowed to hold items between 1 and the maximum items of the job. In the first step priority rules are used to assign sublots to so-called dispatching positions, in which each position holds exactly one sublot and vice versa. In the second step, a mixed integer linear programming model obtains the sublot number, sublot sizes and scheduling plan simultaneously. \r\nTo improve the solution quality, a simple genetic algorithm is presented to enhance the position allocation in the first step while the decomposition approach is iteratively re-run until a stopping criterion is fulfilled. First numerical results are provided proving the model’s effectiveness. The allocation of sublots to due dates and vice versa is analyzed as well as the influence of the number of sublot positions and the setup durations.", :title "Permutation Flow Shop Scheduling using Lot Streaming for Job-specific Due Date Vectors minimizing Due Date Deviation", :keyword2 158, :authors (44772 247), :session 199846}, 74 {:keyword1 149, :keyword3 152, :abstract "Credit scorecards estimate risk - or probability of default. For many years, credit grantors used score (with policy rules) as a 1-dimensional scale for decision making. This gave better operational control and reduced losses. Credit granting strategy largely reduced to fixing a scorecard cutoff.\r\n\r\nOver time, cutoffs became more sophisticated, taking into account loss levels, revenue, customer lifetime value and most recently capital requirements. However, PD is not profit. There will be many credit applicants below the scorecard cutoff who would be profitable - and many accepted applicants who have little chance of ever turning a profit. \r\n\r\nThis has led to lenders switching dimensions, to look at profit rather than risk. But profit is largely driven by lending  margins - in other words, price. What is the \"correct\" price for each customer? Each customer should be offered an individualised price which gives the lender an acceptable return on capital - taking risk into account.\r\n\r\nBut there are(important) complications:\r\n\r\n- Organisation: whose budget is responsible for the trade-offs involved in RORAC based decisions? How should  the performance of different functions be measured?\r\n- Stability: revenue and profit estimates are less stable than estimates of PD. What happens when real life departs from the models?\r\n- Price Sensitivity: in many markets, customers are increasing ly sensitive to price. If the price is too high, only customers who can’t get credit elsewhere will take the offer. Their risk and revenue performance may be very different from what was assumed.\r\nRecent experience - especially during the financial crisis - has tested some of the assumptions. But there are enough open questions to keep credit analysts in work for years to come!", :title "Do we need scorecard cut-offs?  From matching accept rates to maximising return on capital", :keyword2 34, :authors (44819), :session 73}, 76 {:keyword1 54, :keyword3 8, :abstract "In the host situations, a public service system is designed so that the total disutility, like social costs, is minimized. The social costs are often proportional to the total distance travelled by all users to the nearest service center. Mathematical models of such public service system design are often related to the weighted p-median problem, where the numbers of served users and possible service center locations take the value of several thousands. The number of possible center locations impacts the computational time for solving the associated mathematical programming problem. The necessity to solve large instances of the weighted p-median problem has led to the approximate approach based on a radial formulation, which enables to solve bigger instances in admissible time making use of a universal IP-solver. This approach pays for shorter computational time or smaller demanded computer memory by a loss of accuracy. The accuracy can be improved by more suitable determination of dividing points, which define homogenous set of radii for each user. The above objective denoted as min-sum criterion often causes such situation that the total social cost is minimal, but disutility of the worst situated user is extremely high, what is considered as unfair design. A fair approach to the public service system design consists in the process, when the disutility of the worst situated users is minimized first and then disutility of better located users is optimized subject to the disutility of the worst situated users does not worsen, what is called lexicographical minimization. In this contribution we present an approximate approach based on radial formulation of the problem with homogenous system of radii given by dividing points applied to fair public service system design.", :title "Homogenous Radial Approach to Fair Public Service System Design", :keyword2 157, :authors (29393 29390), :session 199898}, 77 {:keyword1 14, :keyword3 35, :abstract "We contribute to the hybrid, e.g., mixed continuous-discrete dynamics of stochastic differential equations with jumps or Markov-switching models, and to its optimal control. Those systems allow the representation of random regime switches and are of growing importance in economics, finance, science and engineering. We introduce two new approaches to this area of stochastic optimal control: one is based on the finding of closed-form solutions, the other one on a discrete-time numerical approximation scheme. The presentation ends with a conclusion and an outlook to future studies.", :title "Continuous-Discrete Optimal Control of Markov Swicthing Models and Stochastic Hybrid Systems with Jumps", :keyword2 99, :authors (3524 35072 15115 13500 26187 22741), :session 199958}, 83 {:keyword1 158, :keyword3 0, :abstract "Mathematical programs with cardinality constraints are constrained optimization problems, where only a given number of the variables is allowed to be nonzero. We consider a reformulation of the cardinality constraint using binary variables, more precisely a relaxation of this reformulation, which leads to a mathematical program in continuous variables with a complementarity-type of constraints. In this talk, we discuss the relation between the local and global solutions of the original and the relaxed problem. Additionally, we analyze the theoretical properties of the relaxed problem, which differ from those known for general mathematical programs with complementarity constraints. Finally, we suggest a regularization method for the solution of the relaxed problem and present some preliminary numerical results.", :title "A Reformulation of Mathematical Programs with Cardinality Constraints using a Complementarity-type Condition", :keyword2 155, :authors (44863 13084 20908), :session 7}, 84 {:keyword1 91, :keyword3 0, :abstract "Opaque selling refers to a price discrimination practice in which a seller conceals some attributes of the product from the customers and reveals them only after a non-refundable purchase has been made. This selling strategy gives sellers degrees of freedom in assigning customers to a specific product (e.g., a product with excess capacity or distressed inventory) and can thus enable them to increase revenues under consideration of capacity constraints. By offering customers a choice involving uncertainty, the opaque product serves the seller as a mean to induce customers to reveal their idiosyncratic preferences. Customers with weak product preferences are motivated to choose the discounted opaque product, whereas customers exhibiting strong preferences are less likely to opt for the uncertain option. The application and optimal design of opaque mechanisms requires a thorough understanding of the drivers of buyer behavior in such settings. Further, understanding customers’ decision-making is a prerequisite for integrating opaque selling successfully into revenue management. In a series of experiments, we thus aim to identify the causality and strength of factors that drive customer behavior in opaque selling markets. In particular, we study how customers’ product choice and willingness-to-pay for the opaque product is influenced by factors such as strength of preferences, attitude towards risk, ambiguity and the source of uncertainty as well as the choice-elicitation interface to reduce opaqueness.", :title "Experimental Analysis of Buyer Behavior in Opaque Selling Markets", :keyword2 0, :authors (44864 44865), :session 98}, 86 {:keyword1 17, :keyword3 34, :abstract "The Luenberger productivity indicator applies directional distance functions which allow to specifying in what direction (i.e. direction of measurement) the operating units will be evaluated. In the presence of a change in the direction of measurement, the standard components of the existing Luenberger productivity indicator may provide values which are not compatible with reality. In order to eliminate this pitfall, the so-called bottoms-up approach is used to revisit the definition of the indicator and its components. We start with a list of selected sources of productivity change, namely efficiency change, technical change and direction change, then examine the best possible way of measuring each of the sources and combine them to derive a new measure of productivity change. The proposed indicator will be illustrated by means of an empirical application to a panel of 417 German saving banks over the time period 2006-2012. The example explains how the proposed approach is able to properly measure efficiency change, technical change and direction change. The results also provide conclusive evidence about the effect of the change in direction of measurement on the results of the productivity over time in a centralized management scenario.", :title "Luenberger Indicator and Directions of Measurement: A Bottoms-up Approach with an Empirical Illustration to German Saving Banks", :keyword2 25, :authors (13000 1610), :session 199833}, 87 {:keyword1 45, :keyword3 0, :abstract "In this study, epidemiological modeling is used to evaluate different ordering policies for vaccine requirements for an anticipated smallpox attack. Based on a compartmental model for the dispersion of smallpox virus, we consider vaccination as the main control policy in addition to hospitalization and quarantine. Solution to a set of ordinary differential equations is used to estimate the need for vaccines for two different population sizes. Assuming zero initial stock level for smallpox vaccines, we discuss several supply strategies and evaluate their effect on stopping the dispersion of epidemic. In order to guarantee sufficient supply of vaccine, mathematical programming is used to solve the single commodity multi-supplier procurement model under time varying demand rate.", :title "Vaccine Supply Strategies in case of a Smallpox Epidemic", :keyword2 57, :authors (14291), :session 199938}, 90 {:keyword1 98, :keyword3 53, :abstract "The LocalSolver project (http://www.localsolver.com) aims at providing a mathematical programming solver for large-scale mixed-variable non-convex optimization. To scale, LocalSolver is based on variable neighborhood search as global search. Its architecture can be viewed as hybrid, tending to integrate all optimization techniques appropriate to explore from small to large neighborhoods: local and direct search, constraint propagation and inference, mixed-integer linear programming techniques, nonlinear programming techniques, etc. The functional and technical novelties coming with LocalSolver 5.0 will be presented. Then, some benchmarks and practical applications will be detailed to assess the performance and the relevance of LocalSolver for solving large-scale real-life optimization problems. ", :title "LocalSolver: a new kind of math programming solver", :keyword2 57, :authors (22803 22910 18585 22911 31711), :session 79}, 92 {:keyword1 97, :keyword3 0, :abstract "Simulation, especially the discrete, event based approach is widely accepted as a decision support technology for the analysis of manufacturing systems. In practice, simulation studies aim either at the comparison of competitive system designs, the identification the best simulation model’s parameter configuration or both. Combinations of simulation and optimization heuristics support the user in automatically finding optimal solutions, but typically result in long computation times. This often prohibits the practical application of these techniques. Therefore, this paper evaluates different heuristics for the simulation-based optimization approach, in order to derive a fast converging procedure. Results are derived with a scalable material flow model and analytical mathematical functions. The implementation additionally includes an interactive analysis of simulation runs and an early-exit-strategy.", :title "Performance Evaluation of Metaheuristics for the Simulation-based Optimization of Material Flow Models", :keyword2 0, :authors (38534), :session 27}, 94 {:keyword1 158, :keyword3 0, :abstract "Routing a pipe through a power plant is a difficult task as one has many possibilities for a given discretization of the design space following the ground structure approach. The problem combines discrete aspects and nonlinear constraints that model the physics of the pipe. To cope with real world technical restrictions we propose an approach based on a second-order cone model that relaxes these restrictions and a decomposition procedure that is able to handle them explicitly.\r\n\r\nIn the past time the wide field of truss design with linear elasticity has been discussed from a mostly nonlinear optimization point of view. In our case conventional truss topology optimization methods are not directly applicable due to discrete constraints that force the pipe to form a path or even a Steiner tree. In addition to the self-weight we consider the placement of hangers that provide support for the pipe.\r\nStarting from a rough outline of the admissible region and inlet and outlet points we derive a discretized set of potential pipe elements that are modeled as Timoshenko beams. The problem now consists of finding the optimal routing of the pipe, considering also operational costs, while complying with technical restrictions.\r\nThe former can be modeled with the use of an extended graph, while the latter are either relaxed to obtain a binary SOCP model. Explicitly including the technical restrictions on the other hand leads to non-convexities which can be addressed via a decomposition algorithm.\r\nWe also provide hardness results of the occurring problems and show how special tailored cutting planes can be used to accelerate the solving process. Numerical results for academic and real world test instances are presented.", :title "Discrete Optimization Methods for Pipe Routing", :keyword2 133, :authors (29261 19441), :session 45}, 99 {:keyword1 159, :keyword3 0, :abstract "The simplex method is a well-studied and widely-used pivoting method for solving linear programs. When Dantzig originally formulated the simplex method, he gave a natural pivot rule that pivots into the basis a variable with the most violated reduced cost. In their seminal work, Klee and Minty showed that this pivot rule takes exponential time in the worst case. We prove two main results on the simplex method. Firstly, we show that it is PSPACE-complete to find the solution that is computed by the simplex method using Dantzig's pivot rule. Secondly, we prove that deciding whether Dantzig's rule ever chooses a specific variable to enter the basis is PSPACE-complete. We use the known connection between Markov decision processes (MDPs) and linear programming, and an equivalence between Dantzig's pivot rule and a natural variant of policy iteration for average-reward MDPs. We construct MDPs and show PSPACE-completeness results for single-switch policy iteration, which in turn imply our main results for the simplex method.", :title "The Complexity of the Simplex Method", :keyword2 0, :authors (44869 44897), :session 58}, 100 {:keyword1 175, :keyword3 174, :abstract "Real-world transportation often uses hub-based transport networks: Shipments from different sources are bundled, send to a hub, reclassified and send to other hubs or their respective sinks. The economies of scale lower the transport costs but additional costs for building and maintaining hubs come into play. To balance costs and gains, one has to overcome the simplified view on economies of scale often present in literature: Use linear costs and discount them on hub-hub-connections by a fixed factor. \r\n\r\nIf we measure transport costs as concave or step function, we get more realistic models, but MIP methods cannot solve the resulting problems. We present a way to write down hub location problems in a suitable way for neighbourhood search. Furthermore, we develop a Simulated Annealing procedure to attack such general hub location problems. An important and often overlooked problem is the calibration of heuristics. We present a method using the F-Race approach of M. Birattari adapted for our purposes. ", :title "Modelling and Solving Realistic Hub Location Problems", :keyword2 42, :authors (33419 26657), :session 26}, 101 {:keyword1 174, :keyword3 97, :abstract "Transport service providers aim to improve efficiency. They bundle shipments in consolidation centres called hubs, before reaching other hubs or their respective destinations and try to reduce the number of connections in transport networks. Thereby, two different kinds of costs are recognizable: first the costs for buildings and maintaining hubs which are mainly strategic and can be well approximated long before. Further are the stochastic transport costs which depend on the actual transport volume that arises in the future.\r\n\r\nMost hub location models ignore the dependence of transport costs on stochastic factors (e.g., the number and size of the shipments) to avoid computationally demanding models. \r\nA bad solution of a realistic model might be worse in practise than a good solution of simplified model. Therefore it is not a priori clear which is the best model to receive adequate results in limited computation time. One cannot put every model into practise and evaluate it, but there is a good surrogate: Event-based computer simulations allow us to consider much more complicated models compared to those applicable in optimization algorithms. Furthermore, they are reasonably fast to be run hundreds or thousands of times to give a good estimate of the stochastic nature of the problem. \r\n\r\nFollowing our well-established heuristic algorithm for complicated hub location problems, we introduce the \"stochasticity\" as a parameter into the model: Having a detailed model of the stochastic behaviour, we consider weaker and stronger integration of this behaviour into the model for the optimization algorithm. The results of the optimization algorithm can subsequently be evaluated by a detailed event-based simulation, both for average results and the variance in costs.\r\n", :title "Investigation of strategic and stochastic Aspects in Hub Location Problems using Simulation", :keyword2 65, :authors (44911 33419 26516 26657), :session 27}, 104 {:keyword1 101, :keyword3 0, :abstract "ERP-based (Enterprise Resource Planning) advanced planning systems use Operations Research methods for solving planning tasks within ERP-systems as optimal as possible. The companies using such planning systems mostly make quite diverse demands on them. Still in most cases it is possible to find a number of common demands for a group of companies which operate in the same industry sector.\r\n\r\nThe presentation analyzes how the planning tasks of the Supply Chain Matrix can be modeled for such a planning system taking into account the specific demands of the machine building industry. The focus lies on the required variables, the constraints and the interaction of the various optimization models.\r\n\r\nThe outcome should be a model of a planning system consisting of particular relevant planning modules and a definition of the information flow between the modules (=branch-wokflow) that can be used by developers for developing specific solutions for suppliers of the machine building industry.", :title "Designing a planning system for suppliers of the machine building industry", :keyword2 7, :authors (40884 2448), :session 199859}, 105 {:keyword1 86, :keyword3 0, :abstract "In this talk we present a tabu search algorithm for the resource-constrained project scheduling problem (RCPSP) with transfer times. Solutions are represented by resource flows extending the disjunctive graph model for shop scheduling problems. Neighborhoods are defined by parallel and serial modifications as suggested in Fortemps and Hapke [1997]. This approach is evaluated from a theoretical and practical point of view.\r\n Besides studying the connectivity of different neighborhoods, computational  results are presented for benchmark instances with and without transfer times.\r\n", :title "A Flow-Based Tabu Search Algorithm for the RCPSP with Transfer Times", :keyword2 0, :authors (14742 19076), :session 199870}, 107 {:keyword1 101, :keyword3 0, :abstract "Product platforms hold the promise for companies to deliver a large product variety to their customers in a cost efficient way. Our study presents a model to support companies in making product platform decisions based on the overall supply chain costs. By quantifying the supply chain costs that correspond to a set of platform choices on the one hand and end product requirements on the other, the model is able to evaluate (1) whether introducing platforms is beneficial, (2) how many and which platforms should be developed, and (3) which products should be derived from which platforms. The costs impacted by the strategic platform decisions, and considered in the model, origin from the various supply chain activities within the company, namely development, ordering, purchasing, inventory management and customisation. We find that the most cost-efficient product platform decision depends on the trade-off between the costs related to the platforms, such as the investments in the initial platform development, and the costs to derive product variants from those platforms, such as the customisation cost. Another trade-off influencing the platform decision is the one between development costs and other costs. The existence of these trade-offs makes the evaluation of product platform decisions a complex problem and confirms the need for an integrated cost model. The relevance of our platform evaluation model is shown through the application to a real business example at a global technology company specialised in the development and production of medical screens.", :title "Facilitating product platform decisions based on total supply chain costs", :keyword2 0, :authors (41201), :session 37}, 108 {:keyword1 91, :keyword3 0, :abstract "During the airline revenue management process demand is forecasted for whole flight networks. The forecasting methods represent the recent development and historical bookings. The whole process incorporates numerous uncertainties and risks. A relative new approach providing the possibility to overcome these uncertainties is the concept of flexible products. They give traditional network carriers the opportunity to induce new customer markets and generate more revenue while improving the utilization of fixed capacities.  \r\nIn the last years the amount of strategic customers is increasing and presents new challenges for airlines in the field of revenue management. Beside the pure revenue maximization it seems to be economically reasonable to integrate the customer satisfaction into decision making process. An increasing flexibility in airline revenue management process means an extension of subsequent adaptabilities which can have effects on customer satisfaction in different dimensions.\r\nThis talk will present opportunities for network carriers to integrate Flexible Products in their portfolio and outline possible impacts on customer satisfaction. We formulate an analytical approach to represent dependencies between the amount of flexibility and customer value within the revenue management process. With practical experiments we show the reliability of this model and calculate first numerical results. In our talk we present these results and outline shortcomings and possible future research directions.", :title "A long-term view on Flexible Products in Airline Revenue Management", :keyword2 63, :authors (39834 19297 1194), :session 98}, 109 {:keyword1 91, :keyword3 0, :abstract "A classic assumption in airline revenue management (ARM) is that a capacity will be fixed for the entire booking horizon. I.e., the number of seats is supposed to be constant for the whole revenue management process. However, execution difficulties can lead to an unexpected change of capacity, and thus the number of potential tickets for sale can be altered. This situation can arise, e.g., due to aircraft on ground, or technical issues, crew planning, special sales, or weather conditions. It involves the danger of a non-optimal revenue management inventory control as the system will optimize via incorrect input parameters. \r\n\r\nThe possibility of deliberately altering the final capacity of a flight – to better match the arrived demand to date – has already been analyzed extensively. In literature, established approaches are i.a. known under the name of demand driven dispatch, dynamic capacity management, or demand driven swapping. Here, a capacity change is internally motivated, i.e. by revenue management itself, while the major problem of external capacity changes is that revenue management systems are not able to consider these changes yet. Neither their appearance, nor their impact has been sufficiently explored. \r\n\r\nThis talk introduces a formalization of the problem and will highlight how an integration of external capacity changes in ARM forecast and optimization could look like. It will present a simulation model for analyzing the effects of capacity changes and their integration in ARM. \r\n", :title "Capacity Uncertainty in Airline Revenue Management", :keyword2 165, :authors (35608 19297 1194), :session 199926}, 113 {:keyword1 126, :keyword3 25, :abstract "Dynamic sales models in marketing widely rely on the assumption that the attraction rate of new customers for a given product is critically dependent upon advertising effort. These models fail to take into account the role of sales price in the evolution of the number of potential customers. In addition, they disregard the existence of spontaneous word of mouth regarding the product, which may be crucial independently from advertising effort. These two important omissions may lead to produce misleading marketing policies, specifically for the management of word of mouth effectiveness. A primary goal of the paper is to analyze the optimal tradeoff between sales price and advertising effort and its implications for word of mouth effectiveness. To address this issue, an optimal control problem is formulated where the attraction of new customers depends both on spontaneous and advertising-based word of mouth and sales price adjustments are costly. ", :title "On the Interaction Between Price and Advertising in a Gould Contagion Model", :keyword2 56, :authors (39239 3821 23372 10538 23254 23254), :session 75}, 117 {:keyword1 99, :keyword3 0, :abstract "We consider a segment of a supply chain comprising an inventory and a transportation system that cooperate in the fulfillment of stochastic customer orders. The inventory is operated under a discrete time (r,s,q) policy with backorders.\r\nThe transportation system consists of an in-house transportation capacity which can be extended by costly external transportation capacity (such as a third-party logistics provider).\r\n\r\nWe show that in a system of this kind stock-outs and the resulting accumulation of inventory backorders introduces volatility in the workload of the transportation process. Geunes and Zeng(2001) have shown for a base-stock system, that backordering decreases the variability of transportation orders.\r\nOur findings show, that in inventory systems with order cycles longer than one period the opposite is true. In both cases, however, inventory decisions and transportation decision must be taken simultaneously. \r\n\r\nWe present a procedure to compute the probability distribution of the number of transportation orders and the resulting excess transportation requirements or rather transportation costs. We show that the increase of transportation costs resulting from a safety stock reduction may offset the change of the inventory costs. This effect may have a significant impact on general optimality statements for multi-echelon inventory systems.", :title "Integrated Optimization of Safety Stock and Transportation Capacity", :keyword2 0, :authors (4889 17398), :session 25}, 119 {:keyword1 162, :keyword3 0, :abstract "There is a wide range of applications where the derivative\r\nmatrices of the corresponding minimization problems are of rather small \r\nsize but dense. Examples for such a setting are Periodic Adsorption\r\nProcesses (PAPs). Here, the purity of the product or the energy\r\nconsumption serve as target function. Additionaly, the state of the\r\nsystem is described by general nonlinear equality constraints. As a\r\nconsequence, when using well-established techniques the run-time\r\nneeded for the optimization process may be dominated \r\nsignificantly by the computation of the dense Jacobian and its factorization.\r\n\r\nThis talk presents an alternative approach, namely an inexact\r\ntrust-region SQP algorithm. The proposed method does not require the\r\nexact evaluation of the \r\nconstraint Jacobian or an iterative solution of a linear system with a\r\nsystem matrix that involves the constraint Jacobian. \r\nInstead, only an approximation of the constraint Jacobian is required.\r\nFurthermore, it is assumed that an exact representation of the nullspace\r\nof the constraint Jacobian at the current iterate can be evaluated in\r\na fixed finite number of steps if necessary.\r\nCorresponding accuracy requirements for the presented first-order global\r\nconvergence result can be verified easily during the optimization\r\nprocess to adjust the approximation quality of the constraint Jacobian\r\nand its nullspace representation. First numerical results for this new approach are discussed.", :title "An inexact trust-region algorithm for nonlinear programming  problems with dense constraint Jacobians", :keyword2 0, :authors (32839 12639), :session 4}, 124 {:keyword1 158, :keyword3 162, :abstract "In this presentation, we will discuss improvements in the linear, mixed integer and nonlinear solvers in the latest release of the FICO Xpress Optimization Suite version 7.7. This includes a multi-start heuristic for nonlinear programming, the detection of nearly parallel objective functions for MIP, solving and modelling capabilities for robust optimization, and an innovative method for parallelizing the dual simplex algorithm (parallelization across multiple iterations).\r\n", :title "Recent enhancements of the FICO Xpress Optimizer", :keyword2 159, :authors (16880), :session 79}, 127 {:keyword1 16, :keyword3 8, :abstract "In this study we discuss a version of the classical one dimensional bin-packing problem (BPP), where the objective is to minimize the total cost of heterogeneous bins needed to store a given set of items, each with some space requirement. The bins are grouped by categories where each category is distinguished by its cost and capacity. In our study we consider the conflicts constraints where some of the items are pairwise incompatible and consequently cannot be packed together. This variant of the problem occurs in a number of businesses, industrial and transportation contexts within a supply chain where generally we prospect to ask the best transfer cost of diverse available products. We propose a pseudo-polynomial time algorithm for the Variable Sized BPP with Conflicts in the case where the size of the items is at least equal to one third of the largest bin capacity. The latter considered have the lowest unit cost. Our algorithm is described as follows: after assigning each three compatible items with size equal to one third of the largest bin to the same largest bin, the algorithm solves the problem as a minimum-weight matching problem in the weighted compatibility graph where nodes are the items and adjacent items are mutually compatible. The weight of a given edge is obtained by calculus of the minimum cost for packing the corresponding two items either in the same or in separate bins.", :title "Solving the Variable Sized Bin Packing Problem with incompatibility and cardinality constraints", :keyword2 42, :authors (9255 31595 5360), :session 199916}, 128 {:keyword1 35, :keyword3 37, :abstract "We decompose financial return series via wavelets into different time scales to analyze their information\r\ncontent regarding the volatility of the returns. Moreover, we investigate the information of\r\neach scale and discuss the decomposition of daily Value-at-Risk (VaR) forecasts.\r\nBy an extensive empirical analysis, we analyze financial assets in calm and turmoil market times\r\nand show that daily VaR forecasts are mainly driven by the volatility which is captured by the\r\nscales comprising the short-run information. Further, we apply Extreme-Value-Theory to each time\r\nscale and illustrate that the information which is stored by the short-run scales linked via copulas\r\noutperforms classical parametric VaR approaches which incorporate all information available.", :title "On the Information Content of Decomposed Financial Return Series: A Wavelet Approach", :keyword2 182, :authors (33591), :session 83}, 134 {:keyword1 6, :keyword3 169, :abstract "What happens to electricity supply if a tree hits a major electricity transmission line, or a power plant has to force shut down immediately? The brief answer is nothing – previously idle operating reserves jump in to take over. However, with a growing share of unpredictable and uncontrollable renewable generation sources entering the electricity market, the need for operating reserves will increase in the future. We explore the possibility of using the storage capacity of large fleets of electric vehicles (EV) as short term (secondary) operating reserves. We approach the problem from a carsharing fleet owner perspective by designing and evaluating an automated decision support system to manage the virtual power plant of EVs. The system decides for the carsharing owner on a real time basis whether to 1) rent an EV at a specific location to consumers, 2) rent out the battery of this EV as operating reserve to generate electricity (positive reserve), or 3) rent it out as operating reserve to consume (charge) energy (negative reserve). In contrast to previous studies we incorporate explicit opportunity costs for non-availability of EVs during rental to operating reserves (and while recharging afterwards). We find that market design for secondary operating reserves has to change to a more flexible design in order for storage to participate in and add value to the market. The system is evaluated on the basis of a case study of 500 Car2Go EVs in Stuttgart, Germany over a period of 3 months. With decreasing battery depreciation costs and an increasing need for balancing capacity we show that carshared operating reserves are commercially beneficial for both the carsharing owner and the institution in charge of the operating reserves. ", :title "Electric Vehicles as Virtual Power Plants", :keyword2 127, :authors (44744 39546 11802), :session 10}, 135 {:keyword1 6, :keyword3 0, :abstract "We analyze incentives to offer combinatorial auctions in a competing environment with asymmetric information with respect to bidders' preferences. Two sellers each offer the same heterogeneous items. Sellers choose to either use two single-item second-price auctions, a single-bundle second-price auction, or a combinatorial Vickrey auction. We find that if bidders are sufficiently heterogenous in their demand, sellers might prefer not to offer the combinatorial auction. In equilibrium, one seller offers two single-unit auctions and attracts those bidders who want a single item and the other seller offers a single-bundle auction and attracts the remaining bidders.", :title "Competing Combinatorial Auctions", :keyword2 40, :authors (44978 41718 44992), :session 199832}, 139 {:keyword1 167, :keyword3 124, :abstract "Information systems that make autonomous decisions based on consumers’ preferences will play an important role in the smart retail markets of the future. We present a nonparametric Bayesian preference model that learns unobtrusively from limited data collected from many concurrent users, and that quantifies the certainty of its own predictions as input to autonomous decision-making tasks. We make use of recent advances in probabilistic inference for structured Gaussian process models to improve the scalability of our model, and we evaluate its performance on real-world electricity tariff choice data collected through a commercial crowdsourcing platform.", :title "A Probabilistic Preference Model with Applications to Electricity Tariff Choice", :keyword2 28, :authors (44985 39546), :session 10}, 141 {:keyword1 179, :keyword3 37, :abstract "The nuclear phase-out and the increased share of renewable distributed generation implicate new challenges for transforming the electric power system into an environmentally sustainable, reliable and cost-efficient system. \r\nIn particular, the process of control reserve and balancing power to cover power plant or prognosis faults has to be adapted to today's complex decentralized structure. On the one hand the main influencing parameters had changed and are no longer statistically uncorrelated and on the other hand the base value given by the loss of load probability (LOLP) is originated from power plant blackouts, what implies that the provided reserve power is oversized in the majority of cases. Whereas in the past the activation of reserve energy was caused by random failures, today the demand and activation is related to the actual state of generation and supply, the current network characteristics and also generation and load forecasts. Even the influence of business management reasons could be accessed in the recent past. The aim of this work is to use these dependencies (patterns) to be learned with methods of computational intelligence (k-nearest-neighbours) and then use the trained model for predicting future demand. For this purpose a dynamic method with various bidding periods and various tendering quantities is aimed at to be designed and evaluated. The design should not longer be exclusively based on ex-post data but should also factor in ex-ante values like wind, solar or load prognosis. Furthermore it is aimed to examine how a-priori data can reduce the present statically provision of operating reserve.\r\n", :title "Dynamic Strategies for Amount and Reliability of Control Reserve in Future Smart Grids", :keyword2 124, :authors (44991), :session 199931}, 144 {:keyword1 149, :keyword3 96, :abstract "The provision of services hinges considerably on the contribution of the provider and the customer and – if present – on their involved networks. \r\nIn this talk we focus on incident management – a service domain that is highly relevant for all kinds of industries and is described from a provider internal perspective in the ITIL documentation. In previously conducted studies, we have derived result influencing factor classes based on qualitatively and textual analyzed service incident tickets from a worldwide operating IT service provider. We have proven the customer induced contribution to the service generation and aggregated a customer contribution factor (ccf). By complementing these provider-centric service processes with that factor, we are able to use information about the customer's ability to contribute, that was not able to process before. \r\nIn the talk, we address the question: How can the customer's potential to contribute be used to organize the queuing in service incident management in a customer-oriented way? We present a mathematical formulation for assigning tickets to servers and discuss first results of a discrete event simulation. We use this simulation to test basic assignment rules based on the ticket complexity and the servers' level of experience. We also study the impact of the ccf in a small example.", :title "Towards a Customer-oriented Queuing in Service Incident Management", :keyword2 97, :authors (44986 33694), :session 91}, 145 {:keyword1 149, :keyword3 0, :abstract "In the past decades, companies in several industries transformed their business from selling single products to selling individualized and integrated products and services. This shift dramatically impacts the selling approach of the sales force: planning long term relationships with the client become more and more important and the sales force needs to be organized in sales teams rather than ‘lone-wolf’ sellers.\r\n\r\nSales Force Modeling, in particular sales territory design, has been a subject of research for more than 40 years. Sales territory design models assign customer accounts or geographic units to sales representatives and calculate coverage, disruption, and profit impact of alternative assignments. These models are usually integer programming models that maximize coverage, minimize disruption, or maximize profit. However, little attention is given to the changing selling approach and the impact on sales territory design. We study a novel sales territory design model for assigning sales teams to customer accounts to sales teams for maximizing sales revenue based upon individual sales potential for individual products and services. We consider constraints such as workload and geographical distance in our model. We first present a deterministic formulation of the sales territory design model and then formulate a stochastic program. Using real data, the solution of both models are evaluated.", :title "Deterministic and stochastic sales territory design models for sales teams", :keyword2 0, :authors (44996 33694 44987), :session 91}, 146 {:keyword1 48, :keyword3 59, :abstract "The area-wide supply of service parts remains a big planning and logistical challenge for many companies, particularly when the customer requirements for parts availability are high, the demand per part is low and the individual parts are expensive. A common approach is the overnight delivery of service parts to so-called picking points. Often the home addresses of technicians are used as picking points (e.g. garage or van kit). While this approach has obvious advantages for the technicians, it is in general not cost optimal. On the one hand this is due to the fact that the technician residences are usually not optimally located with respect to the repair locations, on the other hand because there are typically more technician locations than the number of locations necessary for the required maintenance and repair service. Consequently the delivery to and the inventory costs of those picking points tend to be too high. The optimal choice of the number of picking points, their geographical locations, as well as the optimal allocation of customers to the picking points, considering maximum travel times, is an NP-complete optimization problem. In the lecture, an optimization system is presented which solves this problem using the Threshold Accepting method (a metaheuristic optimization method similar to Simulated Annealing). Based on real life examples, typical total logistics costs savings will be demonstrated and the sensitivity of the optimal solution with respect to the maximum allowable travel time will be discussed.", :title "Optimization of \"Picking Points\" for the area-wide supply of service parts", :keyword2 174, :authors (44997), :session 91}, 147 {:keyword1 37, :keyword3 0, :abstract "Cash flow forecasts play a pivotal role in corporate planning as for instance liquidity and foreign-exchange risk management are typically based on these forecasts. Unfortunately, expert judgment and prediction are typically biased, but empirical work from other domains employing comparably small datasets suggest that biases can often be partially removed using statistical correction techniques in order to increase forecast accuracy. Although accurate forecasting of financial figures is vital for today's corporations, the quantitative impact of statistical correction of enterprise financial forecasts in general and cash flow prediction in particular has not yet been empirically analyzed. Accordingly, we analyze correction of cash flow forecasts generated by experts from various subsidiaries and business divisions of a multinational company. Employing a unique set of forecasts with different horizons delivered by numerous subsidiaries over a period of over five years, we find that forecasts accuracy can be increased significantly using correction techniques based on linear models. We compare techniques based on ordinary least squares (used for instance in Theil's method) and least absolute deviation regression. The results show that forecast accuracy can be improved significantly using statistical correction techniques. In addition, results indicate a higher robustness of the latter technique against outliers. Furthermore, we find that the usage of geometrically descending weights of recent observations fosters accuracy in the majority of cases.", :title "Statistical Correction of Cash-Flow Forecasts", :keyword2 169, :authors (44998 43180), :session 91}, 148 {:keyword1 151, :keyword3 154, :abstract "Among other solution concepts, the notion of the pure Nash equilibrium plays a central role in Game Theory. Pure Nash equilibria in a game characterize situations with non-cooperative deterministic players in which no player has any incentive to unilaterally deviate from the current situation in order to achieve a higher payoff. Unfortunately, it is well known that there are games that do not have pure Nash equilibria. Furthermore, even in games where the existence of equilibria is guaranteed, their computation can be a computationally hard task. Such negative results significantly question the importance of pure Nash equilibria as solution concepts that characterize the behavior of rational players. Approximate pure Nash equilibria, which characterize situations where no player can significantly improve her payoff by unilaterally deviating from her current strategy, could serve as alternative solution concepts provided that they exist and can be computed efficiently.  We discuss recent positive algorithmic results for approximate pure Nash equilibria in unweighted and weighted congestion games. ", :title "Computing Approximate Pure Nash Equilibria", :keyword2 40, :authors (44469), :session 8}, 151 {:keyword1 101, :keyword3 102, :abstract "\r\nUncertainty of demand is usually modelled in stochastic and multi-stage tour planning algorithms. Optimization in this context looks out for minima of costs and travel distances (and therefore also carbon footprint size). As an example algorithm the contribution explains a 2-stage depot-store last mile distribution based on a metaheuristic method modelling stochastic demand. As a further enhancement, a robustification with an alternative objective function is outlined and discussed. The idea of modification is to compute a solution, which remains optimal and unchanged even if unknown but bounded disturbances occur at runtime. To this end, costs are not exclusively assigned to travel distances, but also to switches in the solution structure. This is applied in order to further broaden the methodological basis of the model and therefore also the width of practical usefulness in business applications.\r\nPractical implications are discussed further by relating the results to the green bullwhip effect concept, assuming additionally increased order and safety stock levels in supply chains when green measures such as slow steaming, electric cars or load optimization are applied. Since robustness compensates for the decreased flexibility in league with these measures but might lead to an increase in the travel distances, the approach represents a calculation model for the increased costs of green measures by flexibility reduction. Real costs increase as modeled in a second stage delivery to satisfy all uncertain demand (realistic for most B2C industries like fashion, food and electronics shops) represents therefore the trigger and motivation for logistics managers to increase order and safety stock levels in all upstream sections from last mile delivery.\r\n", :title "Robustification of 2-stage last mile delivery tour planning for stochastic demand", :keyword2 99, :authors (45001 35215 24846 7857), :session 199863}, 154 {:keyword1 59, :keyword3 99, :abstract "One of the reasons that Stochastic Combinatorial Optimization Problems (SCOPs) are interesting is because of their modeling power regarding certain quantities or events. For example, some problems include travel times which can vary due to unpredictable factors such as unexpected traffic or weather conditions. In these cases, SCOPs offer a better approximation than their deterministic counterparts. However, modeling the problem to be solved as a SCOP introduces intricacies that do not exist in the deterministic versions. One of the most important difficulties present in SCOPs is that often computing the objective function can be a hard problem or in our case computationally expensive.\r\nTo mitigate this problem, the objective function can be approximated instead of being computed exactly. To obtain a reasonable approximation, in a way that is both fast and does not affect the quality of solutions found by a metaheuristic, we use Monte Carlo sampling. Metaheuristics using Monte Carlo Sampling in the objective function have become state-of-the-art approaches for many SCOPs such as the Probabilistic Traveling Salesman Problem with Deadlines (PTSPD) and recently the Orienteering Problem with Stochastic Travel and Service Times (OPSTS). However, we have observed that using Monte Carlo Sampling in problems with deadlines such as the OPSTS causes large errors in the nodes where the deadline is likely to occur. These can mislead metaheuristics in reaching suboptimal solutions. In this presentation, we study different methods for computing the objective function with the purpose of creating faster objective functions than the exact or the pure Monte Carlo sampling based one, while minimizing the error and keeping the quality of the solutions found by the metaheuristic, the same.", :title "Hybrid sampling-based metaheuristics for the Orienteeering Problem with Stochastic Travel and Service Times", :keyword2 174, :authors (17336 38782 518), :session 47}, 158 {:keyword1 99, :keyword3 0, :abstract "Unknown customer demand patterns are a significant challenge for many firms. This is particularly true for seasonal products which oftentimes do not only suffer from an uncertain demand scale, but also from an uncertain demand timing. To ensure a product’s profitability in such adverse market environments, firms have to coordinate a product’s inventory scale with the inventory timing. Motivated by this commonly observed challenge, we address the following question: for a seasonal product, when and how much inventory should a firm stock to best satisfy uncertain customer demand over an uncertain selling season? Our analysis reveals that for an efficient inventory strategy, the firm has to actively manage a tradeoff between the product’s market potential and the product’s costly market time. We also find that the timing uncertainty has more severe repercussions on a product’s profitability than an unknown demand scale. We discuss important managerial implications arising from these findings.", :title "Selling over an Uncertain Season: Scale and Timing of Inventory Availability", :keyword2 0, :authors (39314 4229), :session 199955}, 160 {:keyword1 14, :keyword3 0, :abstract "Part feeding processes at automotive assembly plants deal with the timely supply of parts to designated stations at the assembly line. This is accomplished by means of an internal shuttle system which supplies various stations with needed parts. To specify the production processes by models based on partial differential equations, kinetic equations are derived to model the production flow on assembly lines. \r\nOf interest is a mathematical description able to be used for long-term planning of e.g. workforce capacities, storage capacities and workload predictions. Due to the high volume assembly lines a discrete mathematical model as given by discrete event simulators is challenging to compute for large time periods. \r\nCompared to contemporary literature the underlying particle dynamic is more complicated due to different hyperbolic closure relations to derive the macroscopic hyperbolic models. The transport coefficients in the resulting equations are also computed explicitly and include the statistical information available from the manufacturing plant. In addition numerical studies on the macroscopic equations are presented. \r\n", :title "Kinetic Models for Assembly Lines in Automotive Industries", :keyword2 0, :authors (42723), :session 199959}, 164 {:keyword1 157, :keyword3 133, :abstract "The Multiple Constant Multiplication problem is an important problem\r\nin the field of digital signal processing, that is investigated since decades by engineers.\r\nThere are many applications, such as the implementation of digital filters and linear transforms,\r\nwhere a variable (input signal) has to be multiplied with a set of constants.\r\nIn hardware, this is realized using addition/subtraction and bit shift \r\noperations. The problem is to find a circuit that realizes the multiplications \r\nwith a minimum number of additions/subtractions (bit shifts are assumed to be without costs).\r\nThe Multiple Constant Multiplication Problem can be described as Steiner tree problem in\r\ndirected hypergraphs. \r\n\r\nWe present different ILP and MILP formulations of the problem. \r\nFinally we discuss different extensions of the Multiple Constant Multiplication Problem.", :title "ILP Formulations for the Multiple Constant Multiplication Problem", :keyword2 8, :authors (12969 45013), :session 81}, 165 {:keyword1 101, :keyword3 0, :abstract "Supply chain management (SCM) is the management of flows (products, capital and information) among the stages of the supply chain, aiming to maximize the total expected profitability. Inventory control plays an important role in supply chain management. Properly controlled inventory can satisfy customers’ demands, smooth the production plans, and reduce the operation costs. One alternative, stock policy is the Vendor Managed Inventory, where a single decision maker, the supplier, have the decision rights on all echelons in the supply chain. \r\nIn this study, the system under consideration consists of three stages, a Distribution Center (DC), a wholesaler and a retailer. The wholesaler follows a continuous review (s, S) policy and as a Vendor Manager of the Retailer’s inventory level. Retailer faces Poisson demand and the excess demand is lost. The lead times are exponentially distributed. We model this supply chain network as a continuous Markov process with discrete states. The transition matrices have a blocked structure due to the fact that the system’s flows constitute a QBD or left skip-free process. A computational algorithm is developed in order to generate the performance measures for different values of the system’s characteristics. The major task is to compare the current VMI results, with the results of the same supply chain network, where both wholesaler and retailer are following continues review installation policies.\r\n", :title "Vendor Managed Inventory vs installation stock replenishment policy in a 3-stage supply chain under demand and supply uncertainty", :keyword2 174, :authors (45010), :session 199863}, 170 {:keyword1 103, :keyword3 102, :abstract "Alternative powertrain technologies have the potential to reduce local GHG-emissions of passenger cars significantly. Critical for the customer adoption of these technologies are not only competitive prices but also similar or better technical characteristics compared to conventional vehicles with internal combustion engines (ICE). Regarding the operating range, plug-in hybrid electric vehicles (PHEV) and fuel cell electric vehicles (FCEV) can be considered as promising alternatives to ICEs. However, the development of such powertrains involves considerable risk on the manufacturers’ side due to high investments and uncertain customer acceptance. To support the manufacturers in deriving successful market introduction strategies for PHEVs and FCEVs, this paper proposes a System Dynamics approach to model the interactions between manufacturers and customers. Subject of the model is a generic car market with two competing manufacturers, each introducing alternatively powered car models according to exogenously defined strategies comprising the times of market introduction, target market shares and target profit margins. The market penetration of new technologies is based on a Bass diffusion model in combination with a multinomial logit model to account for particular vehicle types in the customers’ buying decision. Furthermore, the model considers the interdependencies with a complementary filling station infrastructure as well as fuel and energy prices. Experience curves and spillover effects between the manufacturers are also included for electric batteries and fuel cells. The model is applied to an exemplary dataset in order to derive general strategy patterns that are most likely suitable for a successful market introduction of alternative powertrain technologies.", :title "Simulation-based analysis of market introduction strategies for alternative powertrain technologies in long-range passenger cars", :keyword2 175, :authors (44916 17364 2651), :session 60}, 171 {:keyword1 127, :keyword3 29, :abstract "The ongoing conversion of our energy supply experiences great interest from many different market players that were originally working in other industries. As a consequence, a vast amount of proprietary solutions for “smart” energy applications is flooding the market. This turns out to be rather a problem than part of the solution for the systematic development of future energy grids. Additionally, the absence of necessary unifications and standards block further developments that would enable the creation of novel market-driven and hybrid control solutions for various types of technical systems. To overcome these problems, we present our notion and definition of a unified autonomous software entity called energy agent. Based on the energy conservation law and a derivative option and action model therefrom, we claim that our energy agent approach has the capabilities to enable cross domain interactions between different types of energy systems and networks. Therefore, we present here the foundation for the energy agent approach by means of a generalized energy option model that gives an agent the needed understanding and economical assessment options regarding the underlying technical system. In this context we present and discuss two exemplary use cases for the option model that illustrate the applicability of this approach for hybrid energy systems. Further, we present and discuss first combinatorial evaluation strategies and experiences that were determined in the course of our work. Overall we believe that our approach is a good but also necessary base for the development of the future IT-enriched and hybrid energy grid.", :title "Hybrid Energy Option Models for Unified Energy Agents", :keyword2 18, :authors (45016 45017), :session 10}, 174 {:keyword1 145, :keyword3 156, :abstract "The aim of the present study is to offer a validated decision model for casino enterprises. The model enables those users to perform early detection of problem gamblers and fulfill their ethical duty of social cost minimization. To this end, the interpretation of casino customers’ nonverbal communication is understood as a signal-processing problem. Indicators of problem gambling recommended by Delfabbro et al. (2007) are combined with Viterbi algorithm into an interdisciplinary model that helps decoding signals emitted by casino customers. Model output consists of a historical path of mental states and cumulated social costs associated with a particular client. Groups of problem and non-problem gamblers were simulated to investigate the model’s diagnostic capability and its cost minimization ability. Each group consisted of 26 subjects and was subsequently enlarged to 100 subjects. In approximately 95 percent of the cases, mental states were correctly decoded for problem gamblers. Statistical analysis using planned contrasts revealed that the model is relatively robust to the suppression of signals performed by casino clientele facing gambling problems as well as to misjudgments made by staff regarding the clients’ mental states. Only if the last mentioned source of error occurs in a very pronounced manner, i.e. judgment is extremely faulty, cumulated social costs might be distorted.", :title "Decoding problem gamblers’ signals – a decision model for casino enterprises", :keyword2 18, :authors (45018), :session 105}, 175 {:keyword1 165, :keyword3 0, :abstract "We derive a convex approximation for two-stage mixed-integer recourse models and we show that the error of this approximation vanishes as all total variations of the probability density functions of the random variables in the model decrease to zero. To prove this result we use asymptotic periodicity of the mixed-integer value function and error bounds on the expectation of periodic functions.", :title "A convex approximation for two-stage mixed-integer recourse models", :keyword2 0, :authors (44993 9512 11413 9542), :session 90}, 176 {:keyword1 165, :keyword3 29, :abstract "Gas transmission networks are complex structures that consist of passive pipes and active, controllable elements such as valves and compressors. Today's gas markets demand more flexibility from the network operators which in turn have to invest into their network infrastructure. As these investments are very cost-intensive and long-living, network extensions should not only focus on one bottleneck scenario, but should increase the flexibility to fulfill different demand scenarios. Thereby we consider several ways of extending the network: by new pipes between points without a prior direct connection, by building a pipe next to an existing pipe, or by adding active elements to the network. In this presentation, we formulate a model for the network extension problem for multiple demand scenarios and propose two solution strategies. First, we decompose along the scenarios and coordinate the search by a Branch&Bound procedure. We solve MINLP single-scenario subproblems and obtain valid bounds even without solving them to optimality. Second, Dantzig-Wolfe decomposition is used to decouple the scenarios.", :title "Decomposition in Gas Network Planning Under Uncertainty", :keyword2 94, :authors (30768), :session 45}, 177 {:keyword1 156, :keyword3 95, :abstract "In this presentation, we consider a variant of the traveling salesman problem with time windows (TSPTW), called minimum tour duration problem (MTDP), where the objective is the minimization of the tour duration. We present a new effective dynamic programming (DP) approach to solve the MTDP. It is motivated by the DP-based solution approach of Baldacci et al. (2011), who successfully solve the TSPTW with a DP-based algorithm. For dealing with tour duration minimization, we will follow ideas presented in (Irnich 2008) to define consistent resource extension functions in order to apply effective dominance and bounding procedures. This is a non-trivial task because in the MTDP at least two resources will depend on each other in a non-additive and non-linear way. Using relaxations to obtain lower bounds is common practice in routing problems, e.g., using a state-space relaxation (Christofides et al. 1981). We present two new relaxation for the MTDP with two respectively one resource, which are attractive due to their low computational complexity. This and other relaxations can be combined with the ng-tour relaxation and the ngL-tour relaxation (Baldacci et al. 2011). To improve the lower bounds, we use two methods: First, we adapt a penalty method, first suggested by Christofides et al. (1981) for solving a TSPTW with the objective of makespan minimization. Second, we generate the neighborhoods for the ng-tour and ngL-tour relaxations dynamically, a technique successfully applied for solving different routing problems (Bode and Irnich 2012). To our knowledge, we present the first exact algorithm for the MTDP and provide computational results with optimal solutions on many known benchmark instances for the TSPTW.", :title "Dynamic Programming for the Minimum Tour Duration Problem", :keyword2 8, :authors (39408 4161), :session 199916}, 178 {:keyword1 134, :keyword3 151, :abstract "In this talk we study the potential function in congestion games. We consider both games with non-decreasing cost functions as well as games with non-increasing utility functions. We show that the value of the potential function of any outcome s of a congestion game approximates the optimum potential value by a factor which only depends on the set of cost/utility functions, and an additive term which is bounded by the sum of the total possible improvements of the players in the outcome s.\r\n\r\nTo achieve this result we introduce a transition graph, which is defined on a pair of outcomes s, s* and captures how to transform s into s*. On this graph we define an ordered path-cycle decomposition. We upper bound the change in the potential for every path and cycle in the decomposition, and lower bound their contribution to the potential. The result then follows by summing up over all paths and cycles.\r\n \r\nThe significance of this result is twofold. On the one hand it provides Price-of-Anarchy-like results with respect to the potential function. On the other hand, we show that these approximations can be used to compute approximate pure Nash equilibria for congestion games with non-decreasing cost functions with the method of Caragiannis et al. [FOCS 2011]. Our technique significantly improves the approximation for polynomial cost functions. Moreover, our analysis suggests and identifies large and practically relevant classes of cost functions for which approximate equilibria with small approximation factors can be computed in polynomial time. For example, in games where resources have a certain cost offset, e.g., traffic networks, the approximation factor drastically decreases with the increase of offsets or coefficients in delay functions.", :title "Bounding the Potential Function in Congestion Games and Approximate Pure Nash Equilibria", :keyword2 40, :authors (44822 44836 44469), :session 58}, 179 {:keyword1 54, :keyword3 0, :abstract "We derive the distribution of the deviation distance to visit an alternative fuel station. The deviation distance is defined as the sum of the distances from origin to the station and from the station to destination. Since refueling demand decreases with the deviation distance, the distribution is useful to estimate the number of vehicles refueled at the station. Distance is measured as the Euclidean distance. Origins and destinations are assumed to be uniformly distributed. Not only the deviation distance but also the vehicle range is significant for alternative fuel vehicles. We then focus on whether the vehicle can make the round trip between origin and destination. The analytical expression for the distribution demonstrates how the vehicle range, the trip length, and the refueling availability at origin and destination affect the deviation distance.", :title "Distribution of deviation distance to alternative fuel stations", :keyword2 0, :authors (9293), :session 199920}, 184 {:keyword1 101, :keyword3 30, :abstract "This paper deals with integration problems between planning, scheduling and execution processes that arise in semiconductor supply chains on the example of Infineon Technologies AG. Over the last decades, semiconductor manufacturing evolved to complex production networks with facilities dispersed all over the globe. Each step of the value chain can be processed in multiple parallel sites. The decision where and when to produce which products is taken in the enterprise-wide Master Planning from which weekly production targets are derived for all fabrication sites. A high level of aggregation and a mid-term horizon are considered. Later, the execution of the master plan is detailed in a daily production schedule within the scope of each facility. In this paper, we investigate inconsistencies that may occur between decisions taken at the corporate and local level. Among others, local scheduling approaches may not be able to cope with short-term supply disruptions from other sites. Also, different disaggregation procedures may lead to misaligned local production schedules. We first perform an as-is analysis. Infineon’s planning landscape is compared to a reference model from the literature, namely IEC 62264 international standard. We show that Infineon lacks an intermediate process to link up planning with scheduling activities. We suggest improvement approaches for an enhanced vertical architecture that incorporates all relevant planning, scheduling and execution processes. Finally, we sketch the long-term company vision of supply chain integration.", :title "Supply Chain Integration and Practical Problems in Semiconductor Manufacturing", :keyword2 75, :authors (26491 26495), :session 44}, 187 {:keyword1 6, :keyword3 0, :abstract "Every year, mobile network operators (MNOs) around the world spend billions of dollars expanding their mobile networks, to cope with the exponentially increasing demand for 3G and 4G bandwidth. Cellular capacity is particularly scarce in inner-city locations during particular times-of-day. At the same time, the majority of wireless access points (residential and commercial) are largely idle most of the time, i.e., the cheap Internet bandwidth provided by Internet Service Providers (ISPs) remains largely unused. This gives rise to opportunities for trade, where some of the peak-time cellular traffic from the MNOs is offloaded via wireless access points, in exchange for payments from the MNOs to the ISPs. However, determining an optimal allocation and prices is a challenging problem, in particular because MNOs have complex, combinatorial preferences: their need and their value for offloading traffic vary by location and by time-of-day.\r\nIn this paper, we propose a market design solution for this problem, where an intermediary sets up a smart market platform that automatically establishes trades between sellers and buyers. We first describe how the preferences of the sellers and buyers in this domain can be modeled succinctly. Then we introduce a combinatorial allocation mechanism that computes an optimal allocation, i.e., which MNOs get to offload how much of their traffic in which of their cell sectors and at what time of the day. Finally, we show how to use core-selecting combinatorial auctions in this domain to computes prices for each MNO, while minimizing the incentives for the MNOs to misreport their values. We conclude by discussing a number of challenges (e.g., thin markets and non-scarcity) that arise in fielding this mechanism in practice.\r\n", :title "Designing a Combinatorial Market for Offloading Cellular Traffic via Wireless Access Points", :keyword2 104, :authors (45022), :session 97}, 188 {:keyword1 40, :keyword3 0, :abstract "The Winner's Curse is a highly relevant phenomenon for auction practitioners and researchers alike. Even if bidders adopt the Bayesian-Nash equilibrium bidding strategy resulting in non-negative expected profits, they can experience the Winner's Curse in individual realizations. This is specifically relevant for auctions in practice, as their success and acceptance will not only be judged on averages, but also on individual realizations and outcomes. Hence, the frequency and the magnitude of the Winner's Curse experienced in individual realizations, plays an important role. These indicators, however, can significantly differ between auction formats even when bidders use the equilibrium strategy.\r\n \r\nWithin an interdependent values framework, we compare different auction formats with respect to the probability and the magnitude with which the Winner’s Curse occurs in the respective symmetric equilibrium. We show that there is no clear ranking between the first- and the second-price sealed-bid auction which depends both on the number of bidders as well as on the distribution of value signals.\r\n\r\nFurthermore, we present a theoretical model for sealed-bid auctions with symmetric interdependent values in which bidders exhibit loss aversion. Herein, we treat the ex-post realized value of the good as the reference point of each bidder. We derive an implicit characterization of the symmetric equilibrium bidding functions. For the special case of common value goods and beta distributed signals, we present explicit equilibrium bidding functions and show how the expected auction revenue differs within first- and second-price auctions dependent on the number of bidders, the signal distribution and the probability and magnitude of the occurrence of the Winner’s Curse.\r\n", :title "How does the Winner’s Curse affect bidding behavior in sealed-bid auctions?", :keyword2 25, :authors (45021 44894), :session 76}, 190 {:keyword1 7, :keyword3 159, :abstract "The issue of contract manufacturing has grown in importance due to the increasing trend of companies that reduce internal value added or even deliberately focus on their core competencies out-side of the operations and manufacturing domain. We study contract manufacturing at the strategic-tactical level and approach the topic from a multi-criteria decision-making perspective since this topic involves service, cost, quality, and especially more long-term value-related aspects. Value-related aspects can include, among others, intellectual property concerns, reputational risks, in-house expertise retention or legal requirements etc.\r\nTo arrive at a well-balanced outsourcing decision with respect to the aforementioned multiple dimensions, we apply a scenario-based approach at the strategic level and make use of two types of Key Performance Indicators (KPIs): model-based KPIs and KPIs that are derived in an independent assessment from multiple stakeholders. A linear programming approach is applied at the strategic level to solve the multi-criteria multi-stakeholder decision problem.\r\nThe model-based KPIs are handled through the tactical model which manages the trade-off be-tween service and cost. For this purpose, we apply an Aggregate Production Planning model to coordinate internal operations with external contract manufacturing. A queuing network-based approach is integrated to anticipate the stochastic and dynamic behavior of the internal shop floor environment. This gives us the opportunity to balance aggregated customer order lead times vs. total costs of operations when deciding on volume and mix of internal vs. external production. A numerical case example involving different outsourcing scenarios is applied to highlight the benefits of the approach.", :title "A multi-criteria approach to outsourcing decision-making in stochastic manufacturing systems", :keyword2 99, :authors (23451 27395 45026 27254), :session 32}, 191 {:keyword1 18, :keyword3 0, :abstract "Natural disasters, such as earthquakes, tsunamis and hurricanes, cause tremendous harm each year. In order to reduce casualties and economic losses during the response phase, rescue units must be allocated and scheduled efficiently. This problem is one of the key issues in emergency response and has been addressed only rarely in the literature. We suggest a binary, quadratic decision support model that minimizes the sum of completion times of incidents weighted by their severity. The presented problem is a generalization of the parallel-machine scheduling problem with unrelated machines, non-batch sequence-dependent setup times and a weighted sum of completion times – thus, it is NP-hard. Using literature on scheduling and routing, we propose and computationally compare several heuristics, including a Monte Carlo-based heuristic, the joint application of 8 construction heuristics and 5 improvement heuristics, and GRASP metaheuristics. Our results show that problem instances (with up to 40 incidents and 40 rescue units) can be solved in less than a second, with results being at most 10.9% up to 33.9% higher than optimal values. Compared to current best practice solutions, the overall harm can be reduced by up to 81.8%.", :title "Emergency Response in Natural Disaster Management: Allocation and Scheduling of Rescue Units ", :keyword2 22, :authors (45027 45029), :session 199874}, 199 {:keyword1 92, :keyword3 0, :abstract "Remanufacturing is one of the product recovery options where the quality of used products (cores) is upgraded to “as-good-as-new” conditions. In this paper, we consider a monopolist firm selling new and remanufactured products to primary and secondary customers, respectively, with one-way substitution, i.e. primary customers may substitute new products by remanufactured products while secondary customers never consider buying new products. We develop economic models under two scenarios – when the supply of cores is unconstrained and when manufacturers have to procure cores at an acquisition price. The major observations of the paper are as follows. A firm is better off when there is no constraint on the supply of cores. Even when cores have to be acquired at an acquisition price, the profitability is higher than that when the firm does not engage in remanufacturing activities. When a larger number of primary customers replace new products with remanufactured products, there is partial cannibalization of new product sales; however, the combined market share and profitability of the firm increase. When core supply is constrained and customers are less sensitive to core prices, the limited supply of cores may render remanufacturing an infeasible option for the firm. Therefore, firms should not only generate awareness among primary customers to buy remanufactured products, but also step up efforts to ensure a steady supply of cores. We conclude the paper with managerial implications and directions for future research.", :title "Optimal Pricing and Core Acquisition Strategy for a Hybrid Manufacturing/Remanufacturing System", :keyword2 25, :authors (39402), :session 199926}, 202 {:keyword1 173, :keyword3 99, :abstract "Cluster nodes' load analysis is widely used to detect potential problems and optimize cluster performance in solving control problems when clusters are combined in Grid systems, which become increasingly popular due to the growing number of cluster systems. The system is studied under general assumptions about its functionality. Description of the system operating in continuous time is given as follows. A cluster is a set of independent nodes. Tasks enter the system at random time moments, the time intervals between the moments are mutually independent and have the same distribution. Number of requested computation nodes to perform a task is an integer random variable. If there is sufficient number of available nodes, the task is accepted for execution. Otherwise, the task is performed on a group of clusters that can exchange tasks. Task performance duration is some continuous random variable. The number of nodes becoming available after a task is performed is a limited integer random variable. Cluster load analysis is associated with the study of a random process that describes the cluster state at the current time moment. This process can be interpreted as a semi-Markov process with spontaneous changes, the study of which is reduced to the investigation of semi-Markov process with two-dimensional states. The results obtained characterize in sufficient detail the studied system: the distribution of availability of computational cluster nodes can be used to predict changes in the number of nodes available over time; stationary distribution can be used to optimize a number of parameters; non-stationary feature of the considered system - task execution time without a queue - made it possible to estimate the average number of tasks performed within this time interval.", :title "Cluster Task Flow Execution Analysis Model", :keyword2 37, :authors (19977 32654), :session 86813}, 203 {:keyword1 158, :keyword3 0, :abstract "In this talk we present a mixed integer linear program that is used to optimally distribute the release calls for grid services on the multiple generator units of a virtual power plant in real time. \r\n\r\nA virtual power plant is a union of multiple power generator units, power storage devices and power consumption units that are controlled by a central server. This setting allows the pooling of small renewable power plants, in order to achieve an overall capacity that is sufficient for participation in the electricity market. Comparable fast load ramps make renewable generation units well suited for the provision of grid services. This is why the direct marketing of renewable power is becoming increasingly attractive.\r\n\r\nCentral servers provide the integration of virtual power plants into electricity markets. They receive overall set points and distribute them in real-time to individual power production units. Moreover, the central servers provide information management for the planning, reporting and accounting of the plant operation. The required control algorithms for virtual power plants need to consider specific plant properties, such as production limits, ramp times and storage capacities for each generation unit. The presented mixed integer linear program considers the plant properties in the form of constraints and objectives and solves the control task in real-time. The mathematical program does not only obtain a feasible plant operation, but does result in the operation of the virtual power plants at the optimal point.\r\n\r\nFinally, we present an installation of the mathematical program at a large-scale virtual power plant providing secondary balancing power and minute reserve for all four German grid areas. ", :title "Real-Time Optimization of Virtual Power Plants providing Grid Services", :keyword2 28, :authors (19462 25804 45036), :session 199932}, 204 {:keyword1 91, :keyword3 0, :abstract "This research examines the problem of determining an optimal discount schedule where the supplier decides how much (if any) discount should be given to each customer in each period, aiming to maximize his profit. The customers get benefits from accepting discounts since the resulting price reduction exceeds their increase in inventory and order costs. The demand for each customer varies from period to period and is independent of the discount offered. Therefore, the total demand for the supplier is constant and he can only influence when the customers place their orders by offering sufficient discounts in these periods. The type of discount studied is a simple price reduction. The customers are heterogeneous in their demand, holding and order costs. \r\nThe initial solution is received by application of a series of Wagner-Whitin algorithms to the situation without discounts. The neighbouring solutions for finding the best production schedule for the supplier are created by increasing or reducing the number of set-ups. The production periods are spread in such a way that total customers' demand in-between two set-ups is roughly equal. To calculate the objective value for the new production pattern of the supplier, a second neighbourhood search is performed for each customer to determine the best order pattern that minimizes the discount offered and the inventory cost for the supplier. The neighbourhood structure for this heuristic is based on the observation that customers can order an integer number of times between two set-ups of the supplier. These orders are evenly spaced between the set-up periods. This performs a role of a fitness function to compare the quality of solutions. Optimal discounts are determined while the best order pattern for customers is obtained. \r\n", :title "Local search for determining the supplier's optimal discount schedule", :keyword2 101, :authors (37489), :session 199831}, 205 {:keyword1 56, :keyword3 0, :abstract "Designing new products and forecasting their market success is crucial for companies. Nowadays, several different types of conjoint choice models are established to design new products and predict choice shares for given competitive market situations. Therefore, in-depth knowledge of model characteristics is important to select a context-specific adequate conjoint choice model and to assess choice shares of new products right. Generally, the Multinomial Logit (MNL) Model is applied, which is known to suffer from the popular Independence of Irrelevant Alternatives (IIA) property. This property may lead to biased model estimates. While the Multinomial Probit (MNP) Model is known to overcome the IIA property, it is still often stated in the modeling literature, that its restricted form,  the Independent Probit (IP) Model, still exhibits the IIA property. We confute this common belief empirically and illustrate the true properties of the IP Model. Like the MNL Model, the IP Model assumes independence between utilities of alternatives. This independence assumption also leads to biased choice share predictions, when different pairwise similarities of competitive products are present. However, the IIA property and the independence assumptions do not build interchangeable constructs.  Considering this is important, when choosing an adequate model. Otherwise, implications on the market launch of new products may be based on a misleading basis. ", :title "A Note on the Properties of the Independent Probit Model", :keyword2 37, :authors (29040 18006), :session 86}, 209 {:keyword1 29, :keyword3 94, :abstract "Increasing energy prices present a challenging task for small and medium-sized enterprises (SMEs). Since the availability of energy plays a crucial role in running the day-to-day business, this paper focuses on energy procurement of SMEs. Due to limited financial and human resources, SMEs find it difficult to implement measures to reduce energy costs. It is shown that a sustainable reduction of energy purchase prices can be achieved by choosing an appropriate procurement strategy. We develop a quantitative optimisation model that takes into account specific needs of SMEs. The aim of the model is to minimise energy purchase costs while assuring that demand is fulfilled at all times. Uncertainty regarding future energy prices and consumption is modelled by considering different scenarios for the evolution of uncertain parameters. A minimax regret approach is used to determine a robust selection of purchase contracts. For strategic decision support, a robust optimisation model is particularly well-suited to choose a risk-averse procurement strategy. In an exemplary case study, different procurement strategies are compared. Computational results show that a structured energy procurement concept has a high potential to significantly reduce energy costs if SMEs are willing to take over volume and price risk.", :title "Optimising energy procurement for small and medium-sized enterprises", :keyword2 100, :authors (45044 10057), :session 199931}, 210 {:keyword1 127, :keyword3 175, :abstract "Induced by the threat of climate change political decision makers around the world have set up regulations to limit the CO2 emissions from passenger cars (e.g. Regulation (EC) No 443/2009 in the European Union). As a result, automobile manufacturers are currently adding electric vehicles to their portfolio. Up to now these innovative vehicles do not make up a considerable part of the new car sales. This, however, would be a prerequisite for automobile manufacturers to effectively lower their average fleet CO2 emissions and thus adhere to the regulation. \r\nIn this contribution we explore how automobile manufacturers can actively support the market success of electric vehicles by making use of the two main drivers of the diffusion of an innovation: marketing and word of mouth. To do so we extend an existing hybrid simulation model of the automobile market. In this model, system dynamics serves to illustrate the aggregated system structures such as the development of the employed powertrain technologies and the corresponding infrastructure availability. To enable a more detailed examination of specific parts of the aggregated system an agent-based simulation model is integrated. With this, the individual automobile purchasing decision of heterogeneous consumers is depicted. We extend this approach to also include interaction between the consumers to account for the effects of word of mouth and marketing. \r\nWe apply the model to the German automobile market to analyze different structures of consumer interaction and their effect on the vehicles’ market share developments. From this we derive recommendations for automobile manufacturers on how to successfully promote alternatively powered vehicles and thereby lower their average fleet CO2 emissions.", :title "Reducing fleet CO2 emissions through successfully promoting the market diffusion of electric vehicles – a manufacturer’s leverage", :keyword2 103, :authors (44851 17364 2651), :session 60}, 214 {:keyword1 99, :keyword3 0, :abstract "Tournament solutions constitute an important class of social choice functions that only depend on the pairwise majority comparisons between alternatives. Recent analytical results have shown that several concepts with appealing axiomatic properties such as the Banks set or the minimal covering set tend to not discriminate at all when the tournaments are chosen from the uniform distribution. This is in sharp contrast to empirical studies which have found that real-world preference profiles often exhibit Condorcet winners, i.e. alternatives \r\nthat all tournament solutions select as the unique winner. In this work, we aim to fill the gap between these extremes by examining the distribution of the number of alternatives returned by common tournament solutions for empirical data as well as data generated according to stochastic preference models such as impartial culture, impartial anonymous culture, Mallows mixtures, spatial models, and Polya-Eggenberger urn models.", :title "On the Discriminative Power of Tournament Solutions", :keyword2 19, :authors (26622 45047), :session 30}, 219 {:keyword1 150, :keyword3 94, :abstract "We study project scheduling at a large IT services delivery center in which there are unpredictable delays. We apply robust optimization to minimize tardiness while informing the customer of a reasonable worst-case completion time. Due to the impracticality of quantifying joint probability distributions for delay times, we follow the recent practice of using empirically determined uncertainty sets, which to our knowledge have not been applied to service scheduling. To solve instances of a realistic size, we introduce a new solution method based on logic-based Benders decomposition. We show that when the uncertainty set is polyhedral, convexity properties of the problem allow us to simplify the decomposition substantially, leading to a model of tractable size that is suitable for a distributed computing environment. Preliminary computational experience indicates that this approach is superior to a conventional mathematical programming model solved by state-of-the-art software.", :title "Robust Scheduling with Logic-Based Benders Decomposition", :keyword2 96, :authors (42664 42667 24607 3557), :session 89}, 220 {:keyword1 6, :keyword3 42, :abstract "Combinatorial auctions allow bidders to better express their preferences compared to the traditional auction formats, increasing economic efficiency when complementarities or substitution effects are present. We investigate the problem setting where we have an auction of similar goods that can be arranged on rows. An application of this is the selling of tickets for seats in a grandstand or stadium. Another application is selling pieces of land. Bidders are allowed to submit one bid on any subset of the goods (seats, land, ...)  that is connected. The objective is a traditional one: to compute the subset of bids that maximize auction revenue. Of course every good can only be sold once.  We describe a dynamic programming algorithm which, for a fixed number of rows and for a particular class of bids, solves the winner determination problem optimally in polynomial time. We also study a number of extensions for which we can modify the algorithm.\r\n", :title "Dynamic programming for combinatorial auctions with items arranged on rows", :keyword2 156, :authors (44955 9583 6251), :session 97}, 223 {:keyword1 94, :keyword3 8, :abstract "In this talk we present a recoverable robust knapsack problem, where the uncertainty of the item weights follows the approach of Bertsimas and Sim.\r\nIn contrast to the classical robust setting, a limited recovery action is allowed, i.e., up to k  items may be removed when the actual weights are known. We will introduce several algorithms based on a compact integer linear programming formulation, different robustness cuts and robust extended cover inequalities and compare their run-time w.r.t. the recovery action and the scenario set.\r\n", :title "Algorithms for the Recoverable Robust Knapsack Problem", :keyword2 153, :authors (17092 45055 12177 39493), :session 42}, 224 {:keyword1 169, :keyword3 29, :abstract "The purpose of this study is to investigate factors on the very local level (households, addresses) that determine whether or not photovoltaic systems - solar cell systems to generate electricity - are to be installed on buildings. We consider a case study of Germany. We aim to identify if the decision of households to install photovoltaics can be explained by peer effects measured by pre-existing proximate installations (also known as the installed base). Since our analysis is based on individual decisions of households, we employ a discrete choice model with panel data in order to model the decisions whether to install in a certain period or not. We employ a geocoded data set of 21 million addresses and the grid-connected photovoltaic systems set up in Germany through 2010 (we consider 11 periods). In total, our data set used for analysis comprises nearly 210 million observations. Our analysis reveals a positive influence of previously installed systems located nearby on the decision to install a photovoltaic system. However, this effect decreases in time. We present an outlook on how our model can be used for forcasting purposes and locational decision making. Finally, a concept is proposed how Google Trends data can be used within our model.", :title "Diffusion of Photovoltaic Installations in Germany", :keyword2 152, :authors (16639), :session 199929}, 227 {:keyword1 61, :keyword3 18, :abstract "CMPL (<Coliop|Coin> Mathematical Programming Language) is a mathematical programming language and a system for mathematical programming and optimisation of linear optimisation problems. CMPL can be used with the CMPLServer which is an XML-RPC-based web service for distributed optimisation. After an overview of the main functionality, the XML-based file formats (CmplInstance, CmplSolutions, CmplMessages, CmplInfo) for the communication between a CMPLServer and its clients are described. \r\nSince a CMPL model can be solved on a CMPLServer synchronously and asynchronously both modes are explained in the next step. All these distributed optimisation procedures require a one to one connection between a CMPLServer and the client. Furthermore, it will be discussed how CMPLServers from several locations can be coupled to one “virtual CMPLServer”, how a client can connect with it and how optimisation jobs are coordinated within the CMPLServer grid. At the end an analysis about the positive effects of shipping optimisation problems into a grid of CMPLServers versus the corresponding network traffic will be discussed.", :title "CmplServer - An open source approach for distributed and grid optimization", :keyword2 57, :authors (30964), :session 81652}, 228 {:keyword1 175, :keyword3 42, :abstract "Fare evasion in public transit systems causes significant losses to society. In order to decrease evasion rates and minimize these losses, transportation companies conduct fare inspections to check traveling passengers for a valid ticket. We discuss new models for optimizing the distribution of fare inspections within the network based on bilevel programming. In the first level, the leader (the network operator) determines probabilities for inspecting passengers at different locations, while in the second level, the followers (the fare-evading passengers) respond by optimizing their routes given the inspection probabilities and travel times. \r\n\r\nTo model the followers' behavior we study both a non-adaptive variant, in which passengers select a path a priori and continue along it throughout their journey, and an adaptive variant, in which they gain information along the way and use it to update their route. For these problems, which are interesting in their own right, we design exact and approximation algorithms. We also prove a tight bound of 3/4 on the ratio of the optimal cost between adaptive and non-adaptive strategies.\r\n\r\nFor the leader's optimization problem, we study a fixed-fare and a flexible-fare variant, where ticket prices may or may not be set at the operator's will. For the latter variant, we design an LP based approximation algorithm. For all variants of the problem, we devise a local search procedure that shifts inspection probabilities within an initially determined support set. We finally present the results of an extensive computational study on instances of the Dutch railway and the Amsterdam subway network. This study reveals that our solutions are within 95% of theoretical upper bounds drawn from the LP relaxation.", :title "Fare Evasion in Transit Networks", :keyword2 40, :authors (26508 45062 26518 45052), :session 92}, 229 {:keyword1 2, :keyword3 0, :abstract "Airport ground staff scheduling has been long known as one of the most challenging and successful application of operations research, in particular column generation method. In this presentation, we will concentrate on one type of rostering known as cyclic roster (equivalently shift pattern or rotating schedules) which represent sequences of consecutive shifts and days-off designed for a group of employees, rotating from one week to the next. Numerous aspects required in practice have to be taken into account, amongst others crew qualification, work locations and the travel time between each location, government regulations and labour agreements, etc. INFORM's branch-and-price solution approach covers all of these aspects and is in use on many airports world-wide. \r\nCyclic Rosters are usually considered as 'fair by construction'. Nevertheless, one of our customers missed several fairness aspects in the generated plans. In this case study we will discuss why the customer  find the resulting rosters unfair. We show which new fairness requirements are needed. We present a fast local search post-processing step that transforms a cost optimal shift plan from our branch-and-price solver into a fair cyclic shift plan with the same costs. The transformed plans are highly accepted and are in operational use.  \r\nBased in Aachen, INFORM ´s Aviation Division is a team of raised-in-industry ICT professionals who research, develop and deliver cutting-edge software solutions to improve airport and ground handling logistics operations and provide consulting services. INFORM products are used by over 75 organizations in more than 165 airports worldwide.", :title "Fair Cyclic Roster Planning – A Case Study for a Large European Airport", :keyword2 121, :authors (29388), :session 28}, 230 {:keyword1 96, :keyword3 0, :abstract "We study several variants of the single machine capacitated lot sizing problem with sequence-dependent setup costs and product-dependent inventory costs. Here we are given one machine and k types of products that need to be scheduled, each associated with a constant demand rate, production rate p(i) and inventory costs per unit. When the machine switches from producing product i to product j, setup costs c(i,j) are incurred. The goal is to find a schedule such that demand is met at all times and the average per-time-unit costs are minimized. This can be seen as lifting a conventional scheduling problem to its more general high-multiplicity counterpart where there are only a few job types, but each with a high multiplicity. This severely increases the complexity of the problem.\r\n\r\nWe distinguish three cases. In the continuous case the machine can switch products at any time and it can produce at most p(i) units of product i. In the discrete case the machine can only switch products at the end of every unit of time (e.g. a day) and it can produce at most p(i) units of product i. In the fixed case the machine can only switch products at the end of every unit of time and if it produces product i during that unit of time, it has to produce exactly p(i) units.\r\n\r\nWe characterize feasible instances and solve the three cases for k=1 product, where the fixed case is already non-trivial. We prove the decision variants of these cases are in P and we provide an algorithm which outputs a polynomial-sized representation of an optimal schedule. We also solve the continuous k=2 case by proving results on the structure of the schedule. Future work includes the discrete and fixed case with k=2 and the problem with any fixed value of k.", :title "High Multiplicity Scheduling with Switching Costs for few Products", :keyword2 8, :authors (45060 31710 24270 45052), :session 199875}, 231 {:keyword1 157, :keyword3 41, :abstract "When reformulating a given mixed integer program by the use of classical Dantzig-Wolfe decomposition, a subset of the constraints is\r\npartially convexified, which corresponds to implicitly adding all valid inequalities for the associated integer hull. Since these inequalities are not known, a solution of the original linear \r\nprogramming (LP) relaxation which is obtained by transferring an optimal basic solution of the reformulated LP relaxation is in general not basic. In order to obtain an optimal basic solution we would have to explicitly add valid inequalities for the integer hull associated with the partially convexified constraints such that the considered solution becomes basic. Hence, cutting planes which are separated using a basis \r\nlike Gomory mixed integer cuts or strong Chvatal-Gomory cuts are usually not directly applicable when separating such a solution in the original problem.\r\nNevertheless, we can use some crossover method in order to obtain a basic solution which is nearby the considered non-basic solution and separate this auxiliary solution by applying all separators including those using a basis. The generated cutting planes might not only cut off the auxiliary solution, but also the solution we originally wanted to separate.\r\nSo far, this problem was only considered extensively by Range, who proposed the previously described approach including a particular crossover method to find such a nearby basic solution. We present a modified crossover method and extend this procedure by considering additional valid inequalities strengthening the original LP relaxation. Furthermore, we provide the first full implementation of a separator like this and tested it on instances of several problem classes.", :title "Separation of Generic Cutting Planes in Branch-and-Price Using a  Basis", :keyword2 159, :authors (42315 14969), :session 199910}, 236 {:keyword1 33, :keyword3 54, :abstract "The spatial design and operation of public service systems, such as emergency health-care stations, police or fire departments, require to estimate the size of demand, its spatial distribution, possible locations of service centers and the travelling times. Thus, to design and operate these systems efficiently a lot of data need to be collected and properly utilized. In recent years, the availability of open data is rapidly growing and new possibilities, how to build better and more detailed data models, emerge. Remarkable example is the OpenStreetMap (OSM) portal providing detailed geographical information. Here, we use OSM data to extract the road network and to identify customers' locations. When estimating the demand for services, we consider as customers all inhabitants and therefore, we use available population grids. We calculate and compare efficient designs corresponding to two demand profiles, night time demand profile, when the majority of inhabitants rests at home and the demand profile derived from the 24hours average of the population density. We draw conclusions on how affected is the efficient design of service systems by the used population grid.", :title "Demand Distribution Effects on the Critical Service Systems Design", :keyword2 65, :authors (36698), :session 199911}, 237 {:keyword1 75, :keyword3 156, :abstract "We consider a single item periodic-review inventory system with lost sales having iid demand and lead times. Customers receive periodic order updates including updated delivery information from the vendor. With advancement in information technologies, the availability of information systems and the ability to share, transmit and access information has increased. Based on our interaction with sourcing professionals in the industry, information access is not an issue anymore and information is readily available. The problem lies in knowing how to use information updates for better decision making. In this paper, we demonstrate how updated supply delivery information can drive better inventory decisions.  \r\nWe use dynamic programming based optimization and simulation to investigate improved inventory policies under such a system which uses updated delivery information. It is seen that such policies perform significantly better as compared to the classical base-stock order up to inventory policies. We demonstrate conditions under which such updated delivery information could be useful and the value of such information.\r\n", :title "Inventory policies for systems with updated supplier delivery information", :keyword2 101, :authors (39527 39528), :session 199955}, 243 {:keyword1 96, :keyword3 42, :abstract "Due to the ever increasing volume of international container freight, the operational planning of modern seaport container terminals has received plenty of attention in the academic literature. One of the many well-known decision problems in this field of research deals with the scheduling of automated stacking cranes in block storage yards that serve as an intermediate buffer between the seaside operations and the hinterland.\r\nThis planning task typically comprises the assignment of jobs to cranes, the sequencing of jobs per crane and the scheduling of job executions. For the latter scheduling problem Briskorn et. al [D. Briskorn, P. Angeloudis, M. Bell. (2013). Scheduling co-operating stacking cranes with predetermined container sequences. Submitted for publication.] recently proposed a graphical representation and strongly polynomial algorithms for make-span minimization of typical crane settings. In practical applications however, the block storage needs to timely serve the succeeding stage of the logistic chain (e.g. seaside quay cranes), so that the compliance of jobs with given time windows becomes a primary concern. Therefore allowing for release dates and minimizing delay is essential. In this work we generalize and extend the results of Briskorn et al. and develop strongly polynomial time algorithms that observe time windows and weakly polynomial algorithms that minimize maximum delay.", :title "Scheduling co-operating stacking cranes with time windows", :keyword2 175, :authors (45069 40497), :session 199942}, 245 {:keyword1 157, :keyword3 150, :abstract "In the university course timetabling problem the goal is to find rooms and\r\ntimeslots for courses according to certain criteria (e.g., avoiding overlaps in\r\nstudent curricula, make good use of room capacity, etc.). Traditionally this\r\nproblem has been approached by many heuristic solutions but more recently also\r\nexact procedures have been proposed that are able to deal with large scale\r\ninstances. In [G. Lach, M.E. Lübbecke (2008)] an exact approach is shown that\r\nassigns timeslots and rooms independently, thereby gaining a large benefit in\r\nefficiency, while ensuring feasibility for both problems using Halls Marriage\r\nTheorem. A drawback of this approach is, that it fails to properly deal with\r\nroom stability constraints. We show how these constraints can be modeled using\r\nhypergraph matchings and describe a two stage procedure, similar to the\r\naforementioned one, that can solve such instances. To do so we use logical\r\nBenders cuts to coordinate the two problem stages. The generated cuts are \r\nderived from a modification of Halls Marriage Theorem that is applicable for \r\nhypergraphs. The approach is demonstrated on various problem instances, \r\nincluding some drawn from an applied timetabling project at RWTH Aachen \r\nUniversity.", :title "Curriculum based timetabling with room stability constraints using Logical Benders Cuts", :keyword2 105, :authors (29246 14969), :session 89}, 248 {:keyword1 157, :keyword3 133, :abstract "The unit commitment problem is to determine the schedule of power generating units and the generating level of each unit. The decisions involve which units to commit at each time period and at what level to generate power to meet the electricity demand. The objective is to minimize the operational cost which is given by the sum of the fuel cost and the start-up cost. The problem is a typical scheduling problem in an electric power system. This problem is formulated as a multi-stage nonlinear integer programming problem because the fuel cost function is assumed to be a convex quadratic function. In this paper, we propose a new algorithm that is based on the Dantzig-Wolfe reformulation and column generation to solve the unit commitment problem. The column generation method has not been applied frequently to solve the unit commitment problem. Several applications of column generation such as crew scheduling or other scheduling problems suggest that the column generation approach is encouraging. The only research that uses a column generation technique is a paper by Shiina and Birge (2004). They used the column generation approach in which each column corresponds to the start-stop schedule and output level. Since power output is a continuous quantity, it takes time to generate the required column efficiently. In our new approach, the problem to be solved is not a simple set partitioning problem because the columns generated contain only a schedule specified by 0-1 value. We present a new solution algorithm based on the column generation.  It is shown that the new approach is effective to solve the problem.", :title "Unit Commitment by Column Generation", :keyword2 8, :authors (39349 45107 39400 45108), :session 199931}, 250 {:keyword1 42, :keyword3 0, :abstract "The adversary model is one of the first network formation models to explicitly consider robustness aspects. It supposes that exactly one link in the built network will be destroyed by an adversary, according to a known probability distribution. The cost of a player is the expected number of other players to which connection will be lost. Despite its simplicity, this model poses a challenge when it comes to the price of anarchy.\r\n\r\nIn this presentation, I will give an overview over the results obtained so far for the price of anarchy in this model for Nash equilibrium, pairwise Nash equilibrium, and pairwise stability. Some of the graph-theoretic techniques used in the proofs will be sketched.", :title "Price of Anarchy in the Network Formation Adversary Model", :keyword2 134, :authors (45071), :session 39}, 251 {:keyword1 174, :keyword3 0, :abstract "Storage unloading and premarshalling problems occur in container terminals, tram and bus depots and steel slab warehousing where items are stored in stacks and need to be retrieved out of a storage area. Due to the arrangement in stacks, only the topmost item of each stack is accessible directly. If an item below has to be retrieved, reshuffling is necessary. Since reshuffling is very time-consuming, most problems try to minimize the number of reshuffling moves. \r\n\r\nA common problem is that, given a retrieval sequence of items, one has to find a relocation pattern with a minimum number of reshuffling moves which satisfies the sequence. If on the one hand, this problem is considered as an unloading one, a current target item is retrieved as soon as it is the topmost item of any stack, i.e. the storage area gets emptier during unloading. If on the other hand, this problem is considered as a premarshalling one, all items have to be sorted such that afterwards no reshuffling is necessary to retrieve the sequence. In particular, no item leaves the storage area during premarshalling. \r\n\r\nIn some practical applications (e.g. storage of wooden plates), items occur in types. Several items belong to the same type if they share the same properties. In this case, a retrieval request does not ask for a specific item but for any item of a specific type which means that one item has to be chosen among several possible items. \r\n\r\nIn this talk, we will present solution algorithms for unloading and premarshalling problems with types.  We will discuss and compare them to existing algorithms for similar problems. Moreover, we will give an overview of further problem variants.", :title "Solution algorithms for storage unloading and premarshalling problems with types", :keyword2 96, :authors (35383), :session 25}, 252 {:keyword1 2, :keyword3 150, :abstract "Outbound baggage handling at international airports concerns baggage which has to be transfered from the terminal or transfer flights to the departing airplane. In the planning flights have to be assigned to handling facilities and the baggage handling has to be scheduled. The latter involves settting the start of the baggage handling and the start of the depletion of the central baggage storage. Moreover, to load the incoming baggage into bulk containers at the handling facilities workers have to be staffed to the flights. We propose a model formulation to plan the outbound baggage handling including the staffing of the workers. We present a Dantzig-Wolfe and Benders reformulation. An algorithm based on column and row generation is applied to find a feasible assignment and schedule for the baggage handling and to staff the workers at the handling facilities. In a computational study we test the performance of the procedure with real-world instances based on Terminal 2 of Munich Airport. The results show that the algorithm is capable of giving a feasible solution in a reasonable amount of time.", :title "Disruption Management for Outbound Baggage Handling with Work Group Pairings", :keyword2 96, :authors (44845 45073 829 14969), :session 95}, 253 {:keyword1 96, :keyword3 151, :abstract "We are given a set of jobs which are to be processed on a single machine. For each job three parameters, namely a processing time, a due date, and a weight, are specified. Each schedule is represented as a permutation of the jobs.  A job is late in a schedule if its completion time in this schedule exceeds its due date. We seek a schedule minimizing the weighted number of late jobs. This problem is known to be NP-hard. However, special cases with unit weights or unit job processing times are polynomially solvable. In this paper, we assume that all the job parameters may be imprecise. \r\nWe model this uncertainty by specifying a scenario set containing all vectors of   the job parameters (called scenarios) which may occur. We use the min-max criterion to compute a solution, which is the most popular criterion in robust optimization. In this paper, we extend and strengthen the results which have been recently obtained \r\nfor the problem in the literature. \r\nNamely, we show that if the number of processing time scenarios is a part of the input, then the problem is strongly NP-hard even when all job weights are equal to 1 and all  jobs have a common deterministic due date. \r\nWe also show that when the number of due date scenarios is a part of the input, then the problem is not approximable within any constant factor. \r\nThis assertion remains true even if there are two distinct values of the due-dates in scenarios and all job weights \r\nare equal to 1. Finally, we show some positive approximation results for the problem with unit processing times, uncertain due dates and uncertain weights. This approximation results can be extended to a more general problem, in which the maximum is replaced with the OWA operator.", :title "Robust single machine scheduling problem with weighted number of late jobs criterion", :keyword2 94, :authors (6882 6886), :session 199880}, 254 {:keyword1 96, :keyword3 0, :abstract "In this talk we discuss flow shop problems with synchronous movement which are a variant of a non-preemptive permutation flow shop. Jobs have to be moved from one machine to the next by an unpaced synchronous transportation system, which implies that the processing is organized in synchronized cycles. This means that in each cycle the current jobs start at the same time on the corresponding machines and after processing have to wait until the last job is finished. Afterwards, all jobs are moved to the next machine simultaneously.\r\n\r\nBesides the general situation we also investigate special cases involving machine dominance which means that the processing times of all jobs on a dominating machine are at least as large as the processing times of all jobs on the other machines. Especially, we discuss flow shops with synchronous movement for a small number of dominating machines (one or two) and different objective functions. ", :title "Flow Shops with Synchronous Movement", :keyword2 8, :authors (35382 14742), :session 199873}, 257 {:keyword1 8, :keyword3 159, :abstract "Palletizers are widely used in delivery industry. We consider a large palletizer where each stacker crane grabs a bin from one of k conveyors and position it onto a pallet located at one of p stack-up places. All bins have the same size. Each pallet is destined for one customer. A completely stacked pallet will be removed automatically and a new empty pallet is placed at the palletizer. The FIFO Stack-up problem is to decide whether the bins can be palletized by using at most p stack-up places.  Since the FIFO stack-up problem is computational intractable in general, we study the fixed-parameter tractability of this problem. The idea behind fixed-parameter tractability is to try to separate out the complexity into two pieces - some piece that depends purely on the size of the input, and some piece that depends on some parameter of the problem that tends to be small in practice. We introduce a digraph and a linear programming model for the problem. Based on these characterizations we give algorithms to show that the number n of bins, the number m of pallets, and k to the power of m can be chosen as a parameter such that the problem is fixed parameter tractable. Thus for a lot of small parameter values we obtain efficient solutions for the FIFO stack-up problem. We also discuss approximation results for the problem.", :title "Algorithms for Controlling Palletizers", :keyword2 42, :authors (39566 39552 39563), :session 199912}, 259 {:keyword1 6, :keyword3 157, :abstract "In a seminal paper, Lavi and Swamy (2011) propose a general framework\r\nto obtain approximation mechanisms that are truthful in expectation.\r\nThe ellipsoid method is pivotal in this framework and alongside an\r\napproximation algorithm is used to find an integral convex\r\ndecomposition for the fractional solution to the linear program\r\nrelaxation.  Although its worst-case runtime is polynomial, the\r\nellipsoid method is notoriously known to be inefficient in practice.\r\nIn this paper, we propose a more efficient method for finding convex\r\ndecompositions that eliminates the use of the ellipsoid method.  Our\r\nmethod requires only a quadratic number of invocations of the\r\ngap-verifying approximation algorithm.  The number of invocations is\r\nquadratic in terms of the number of dimensions with positive entries\r\nin the fractional solution.  Our method describes a practical way to\r\nfind integral convex decompositions in order to transform various\r\napproximation algorithms of the packing problems into\r\ntruthful-in-expectation approximation mechanisms.\r\n", :title "Efficient convex decomposition for truthful-in-expectation approximation mechanisms", :keyword2 40, :authors (39348 45075 55333), :session 199832}, 260 {:keyword1 45, :keyword3 0, :abstract "The transportation processes for patients, personnel, and material in large and complex maximum-care hospitals with many departments can consume significant resources and thus induce substantial logistics costs. These costs are largely determined by the allocation of the different departments and wards in possibly multiple connected hospital buildings. We develop a hierarchical layout planning approach based on an analysis of organizational and operational data from the Hannover Medical School, a large and complex university hospital in Hannover, Germany. The purpose of this approach is to propose locations for departments and wards for a given system of buildings such that the consumption of resources due to those transportation processes is minimized. We apply the approach to this real-world organizational and operational dataset as well as to a fictitious hospital building and analyze the algorithmic behavior and resulting layout. ", :title "A hierarchical facility layout planning approach for large and complex hospitals", :keyword2 0, :authors (17428 29814 29197), :session 77}, 262 {:keyword1 65, :keyword3 7, :abstract "Recent advances in communication technology allow to compress data streams in communication networks by deploying physical devices (caches) at routers, yielding a more efficient usage of link capacities. This gives rise to the network design problem with compression (NDPC), a generalization of the classical network design problem. In this paper, we compare both problems, focusing on the computational complexity and analyzing the differences induced by the compression aspect. \r\n\r\nWe show that the subproblem of adding compression, i.e., the compressor placement problem (CPP), is already weakly NP-hard, even on instances where Network Design alone is easy. We conclude with a pseudopolynomial algorithm for tree instances and a restricted polynomial case.", :title "Complexity Results for Network Design with Compression", :keyword2 154, :authors (42054 12177), :session 199911}, 263 {:keyword1 175, :keyword3 7, :abstract "The train path assignment’s optimization algorithm generates an optimal solution for freight train path applications by connecting available slots between several construction nodes without conflicts. This method is not only used for a real timetable e.g. for the following year but also for timetable-based development of railway infrastructure in long-term scenarios. However, for infrastructure development the actual slot connections are not the main concern in this planning step. The railway infrastructure company rather wants to detect bottlenecks in the infrastructure and needs to get evidence for necessary developments of its railway network. By presenting results of a real world German railway network’s test case, this paper shows which bottlenecks can be derived from an optimized slot assignment and which measures (in timetable and infrastructure) could eliminate the detected bottlenecks. Necessary key figures for discovering bottlenecks will be introduced, too. It is shown that shadow prices of the developed column generation method are a good indicator for the identification of bottlenecks. For the first time with the comparison of different assignments’ key numbers one can deliver a clear monetary benefit for the removal of a single bottleneck, e.g. the revenue advantage of an additional track for buffering freight trains. Hence, using the developed optimization algorithm for train path assignment leads to new useful insights for a railway infrastructure company to develop its railway network. ", :title "New insights using optimized train path`s assignment for the development of railway infrastructure", :keyword2 105, :authors (33365 45038), :session 199939}, 264 {:keyword1 175, :keyword3 105, :abstract "In today’s timetabling process for railway freight transportation, train paths are constructed individually on the base of concrete train path applications. In contrast, an industrialized timetable for rail freight transport is based on the separation of train path and the train itself. This means that in the first step train paths are constructed between predefined locations in the railway network (construction nodes) with parameters representing many trains. These train paths are called slots and correspond to the available capacity for freight trains in the railway network. After the train path applications have been received at a fixed date, suitable train paths will be searched simultaneously for all applications and their complete routes. In this step the railway infrastructure company has to make sure that each slot is used by only one application and that the slots are connected with no conflicts in the construction nodes.  This paper discusses the necessity of an optimization algorithm for the outlined slot’s assignment for industrialized timetabling of a railway infrastructure company. Therefore the potential for optimization in comparison to a greedy heuristic approach is shown in an example of the German railway network’s long-term timetabling scenario. It becomes apparent that the developed column generation approach generates good solutions for real-world use cases in an acceptable runtime.", :title "Why does a railway infrastructure company need an optimized train path`s assignment for industrialized timetabling?", :keyword2 7, :authors (45038 33365), :session 199939}, 265 {:keyword1 169, :keyword3 182, :abstract "We introduce concise, multi-dimensional metrics to characterize the revision behavior found in cash flow forecasting processes and use these metrics to predict  forecast accuracy, entropy, as well as the direction of a forecast error. Accuracy of cash flow forecasts is important in corporate reporting and planning systems, and corporate financial controllers require techniques to assess and improve the quality of the forecast data. However, vast amounts of cash flow forecasts with forecast horizons of up to 12 months are generated and revised regularly by local financial managers working for different subsidiaries in different regions and business divisions, and corporate financial controllers need decision support tools to analyze, assess, and improve the forecast data. Employing a large, multi-year dataset of real-world cash flow forecasts provided by a large multinational company, we show empirically that novel measures such as the (geometric) revisioning center in combinations with the type and strength of a principal revision pattern  -- assigned based on the similarity of an individual revision pattern and empirical orthogonal patterns -- provide predictive value over established quality indicators such as weak planning efficiency, or the determination of biases potentially introduced by 'anchoring and adjustment' or 'running down a forecast'. \r\n", :title "Predictive Value of Geometric Measures for Revisioning Pattern in Corporate Cash Flow Forecasting", :keyword2 37, :authors (45076 43180), :session 86}, 267 {:keyword1 6, :keyword3 0, :abstract "Combinatorial clock auctions (CCAs) have recently been used around the globe to allocate mobile telecom licenses. The CCA is presented to national authorities as a superior auction model that, because of its second-price rule, eliminates the scope for strategic bidding or “gaming” (see, e.g., Cramton, 2012)  so that bidders can “simply bid their valuations”. The bidding behaviour of firms in many of the recent real-world auctions are difficult to rationalize by bidders bidding value. \r\nThis article analyzes the properties of the CCA in case bidders have a spite motive in that ceteris paribus they prefer outcomes where rivals pay more for their winning allocation. We show that if firms have a lexicographic spite motive, the Vickrey-Clark-Groves (VCG) mechanism underlying the CCA does not have a (weakly) dominant strategy.  Nevertheless, under additional conditions, the CCA, unlike the VCG mechanism, can be solved using iterative elimination of (weakly) dominated strategies.  In the resulting equilibrium, bidders express aggressive bids above value on some packages, and they may even bid on packages without intrinsic value.  Bidding truthfully is an iteratively dominated strategy.  We show that bidders in the clock phase strategically expand their demand, while a former result on strategic demand reduction only holds true when there are 2 bidders.\r\nThe spite motive also interacts in a complicated way with budget constraints. A budget constraint implies that bidders cannot pay more than a certain exogenously determined amount.  Paradoxically (maybe), in a CCA this does not mean that (in the supplementary round) a bidder cannot bid more than its budget. We discuss some results showing that there always will be at least one bidder who bids above budget.\r\n\r\n", :title "Strategic Spiteful Bidding in Combinatorial Clock Auctions", :keyword2 0, :authors (45078), :session 100}, 268 {:keyword1 61, :keyword3 0, :abstract "Modeling languages for formulating and analyzing optimization problems are essentially declarative, in that they are founded on a symbolic description of a model’s objective function and constraints rather than a procedural specification of how a problem instance is to be generated and solved.  Yet successful optimization modeling languages have come to offer many of the same facilities as procedural, high-level programming languages, in two ways: by extension of their syntax to interpreted scripting languages, and by exposure of their functions through application programming interfaces (APIs).  How can scripting and APIs benefit the user of a declarative language, and what do they offer in comparison to modeling exclusively in a general-purpose language?  This presentation suggests a variety of answers, through examples that make use of advanced AMPL scripting features and the new AMPL APIs for Java, MATLAB, and other platforms.", :title "Alternatives for Programming in Conjunction with an Algebraic Modeling Language for Optimization", :keyword2 0, :authors (3753), :session 96}, 272 {:keyword1 94, :keyword3 158, :abstract "Suppliers in the automotive industry currently face two major requirements from their customers: (i) increasing flexibility to deal with fluctuating demand volumes while following a leveled production approach according to the lean philosophy, and (ii) prearranged cost saving targets over product life-time due to a more competitive business environment. Automotive suppliers thus have started to organize themselves in manufacturing networks to better balance demand with capacity supply across locations and to realize cost savings from economies of scale. However, OEMs require approval of each production line before production starts which is costly, involves several months of lead time, and is time-bound if a minimum production quantity is not met. Consequently, planning complexity increases which requires appropriate decision support systems for tactical supply chain planning.\r\nWe present a corresponding robust decision model for tactical supply chain planning of an automotive supplier. The approach is capable of flexibly dealing with demand fluctuations while following a stable and cost-efficient production plan. For this purpose, we make use of two-stage stochastic programming and integrate corresponding robust planning methods. Since the forecast delivery schedule of the OEM typically involves substantial uncertainty, we also investigate on the issue of information robustness to find plans that are sufficiently insensitive to the level and quality of forecast information. A scaled-down industry example is used to evaluate the presented approach.", :title "Robust Tactical Planning in Automotive Supplier Networks", :keyword2 101, :authors (23451 45083 45082), :session 32}, 273 {:keyword1 169, :keyword3 91, :abstract "The increase in online retailing has caused a boom in attended home deliveries: For example, when fresh groceries are delivered to the customer’s door, this has to happen at a time when someone is at home to receive them. As delivery fees cannot fully compensate the costs of delivery in tight delivery time windows, we propose a novel, value-based approach to demand fulfilment. The idea is that to be profitable, businesses should not only minimize the costs of delivery, but should also maximize the overall value of fulfilled orders.\r\nWe present an iterative solution approach: First, we approximate the transport capacity based on forecasts of expected delivery requests and a cost-minimizing routing. Subsequently, we decide on the acceptance of actual delivery requests given the objective of maximizing the overall value of orders given a fixed transport capacity. Based on the set of accepted requests, we update the routing solution to minimize costs of delivery. The solution combines well-known techniques from revenue management and time-dependent vehicle routing. In a computational study, the potential and the limits of this approach are investigated for a German metropolitan area. This study particularly considers the sensitivity of our approach regarding forecast accuracy and demand composition.\r\n", :title "Improving Order Acceptance through Revenue Management Techniques for Attended Home Deliveries in Metropolitan Areas", :keyword2 174, :authors (19297 16919), :session 199864}, 274 {:keyword1 175, :keyword3 89, :abstract "In practice, the execution of delivery routes often differs from plans due to a variety of influences such as traffic jams, weather, customer availability, etc. These influences may cost the driver to miss customer time windows. While the predictability of some of these factors is nearly impossible, it is often possible to derive travel time distributions based on historical traffic data. This idea is the foundation the vehicle routing problem with time windows and stochastic travel times (SVRPTW).\r\nIn this work, we propose a fairly straightforward way to guarantee a given service level at all customers by ensuring a certain probability of arrival before the end of each customer's time window. We particularly consider how arrival time distributions should properly be propagated throughout a route given the presence of time windows. Our chance-constrained approach carefully considers how to estimate the arrival time distributions at each customer on the route, which enables us to verify if the given service level is maintained at individual customers.\r\nOur ideas can be “plugged” into any algorithm for the SVRPTW and thus be used to solve large problems fairly quickly in the form of a feasibility check. We exemplarily show how to implement them in a tabu search solution approach. Computational experiments based on Solomon instances demonstrate how the solutions change for different levels of customer service across two probability distributions and several parameter settings. Results show that it is possible to achieve a certain level of service at almost no additional cost for some types of instances, while others require up to 33% more vehicles and 22% more working time to make delivery routes virtually free of lateness.", :title "A Chance-Constrained Approach for Lateness Avoidance in Routing Problems with Time Windows and Stochastic Travel Times", :keyword2 95, :authors (16919 27111 45084), :session 54}, 275 {:keyword1 151, :keyword3 94, :abstract "A finite set of elements and a set of feasible solutions composed of some subsets of the element set are given.  In the deterministic case, each element has a nonnegative cost and we seek a feasible solution whose total cost is minimal. In this paper, we assume that the element costs are not precisely known and we model this uncertainty by specifying a scenario set containing a finite number of cost scenarios. In order to choose a solution a popular robust approach is typically used. In the robust approach, we compute a solution which minimize the cost in a worst case, which leads to the min-max (or min-max regret) criteria. This approach has, however, some known drawbacks. It assumes that decision makers are very pessimistic or risk averse. Furthermore, they have no additional knowledge about which scenarios are more likely to occur. In 1988 the Ordered Weighted Averaging aggregation operator was introduced by Yager. This operator allows decision makers to take their attitude towards the risk into account. It contains the maximum and the arithmetic mean as special cases. The class of discrete optimization problems with the OWA criterion has been recently discussed in a number of papers. In this work we propose to use a more general criterion, namely the Weighted OWA operator (shortly WOWA) introduced by Torra in 1996. In the WOWA operator an additional vector of weighs is specified which can be interpreted as scenarios subjective probabilities. The WOWA operator contains the OWA and the weighted mean (the expected value) as special cases. In this paper, we  construct an approximation algorithm for the considered problem, with some guaranteed worst case ratio. This algorithm is general and requires only that the underlying deterministic problem is polynomially solvable.", :title "Robust discrete optimization problems with the WOWA criterion", :keyword2 8, :authors (6886 6882), :session 199878}, 276 {:keyword1 96, :keyword3 151, :abstract "We study the fundamental problem of scheduling bidirectional traffic along a path composed of multiple segments. The main feature of the problem is that jobs traveling in the same direction can be scheduled in quick succession on a segment, while jobs in opposing directions cannot cross a segment at the same time. We show that this tradeoff makes the problem significantly harder than the related flow shop problem, by showing that it is NP-hard even for identical jobs. We give polynomial algorithms for a single segment and any constant number of segments, respectively. In contrast, we show the problem to be NP-hard on a single segment and with identical jobs if some pairs of jobs traveling in different directions are allowed to cross the segment concurrently. Finally, we give a PTAS for scheduling bidirectional traffic on a path composed of a constant number of segments.", :title " Scheduling Bidirectional Traffic on a Path", :keyword2 154, :authors (26629 45087 26950), :session 199873}, 277 {:keyword1 95, :keyword3 157, :abstract " Optimization of vehicle routes with delivery and pickup for a rental industry is considered. The company delivers to or picks up from customers rented products. Several types of products exist, and customers rent the specified number of products of the specific type. Time windows exist for delivery and pickup. There exist two sizes of vehicles, and their trips start from and end at depot and vehicles can make several trips during a day. Delivery must precede pickup on any trip of a vehicle. Capacity of vehicles depends on product type and also on how products are loaded on vehicles, i.e., whether products are loaded in a fold form or in an unfold or assembled form. Depending on order quantity, split deliveries/pickups may be necessary. The company wants to minimize the total transportation cost.\r\n Based on the fact that the total number of distinct trips is rather small due to limited capacity of the vehicles, our solution strategy first enumerates all possible trips. Routes (i.e., collection of trips) are obtained by assigning trips to vehicles so that the total cost is minimized subject to constraints on demand, an upper limit on the number of trips per vehicle, and time compatibility of trips assigned to a specific vehicle.  Since there exist many time compatibility constraints, the problem is first solved without them, we then check the compatibility and if necessary add compatibility constraints, and the problem is solved again until all routes become time compatible.\r\nThe computational performance of the proposed solution approach and goodness of the generated routes are evaluated based on several sets of real data. Routes obtained in 30-60 minutes of CPU time were found to be 4-10% lower in cost than actual routes produced manually by the planning personnel.", :title "Optimization of Vehicle Routes with Delivery and Pickup for a Rental Business: A Case Study", :keyword2 96, :authors (39400 45086 45089 45085), :session 199957}, 280 {:keyword1 158, :keyword3 133, :abstract "When considering cost-optimal operation of gas transport networks, compressor stations play the most important role. However, modeling of these stations lead to complicated mixed-integer nonlinear and nonconvex optimization or feasibility problems. In this talk, MINLP and GDP models as well as continuous reformulations of an isothermal and stationary variant of the problem are discussed. The applicability and importance of different model formulations, especially those without discrete variables is demonstrated by an extensive computational study on real-world instances.", :title "Continuous Reformulation Techniques for Mixed-Integer Nonlinear Optimization of Gas Compressor Stations", :keyword2 162, :authors (23956 45090 13054 24559), :session 45}, 283 {:keyword1 8, :keyword3 158, :abstract "In this talk we give insight into the mathematical properties of two different linearized power flow models. We compare the well known DC approximation with a formulation which also approximates reactive flows. We analyze these two linearizations in terms of solvability and discuss how good they approximate the nonlinear power flow equations. The need of linearized power flow equations is based on the power grid design problem, as using the nonlinear power flow equations would yield a non-convex MINLP. By considering linearized equations we gain an MILP, which is preferred for many reasons. We therefore analyze the two linearizations' corresponding power grid design problems and show whether the more complex approximation is suitable for practical use. Finally, we consider the fact if the optimal design for the linearized power flow models is feasible for the nonlinear power flow equations.", :title "Practical Use of Different Linearized Power Flows", :keyword2 65, :authors (39273 12177), :session 68}, 286 {:keyword1 65, :keyword3 40, :abstract "Network creation games (NCG) aim to model the evolution and outcome of networks created by selfish nodes. In these games, nodes can decide individually which edges they want to buy in order to minimize their private costs, i.e., the costs of the bought edges plus costs for communicating with other nodes. Each node v can buy a set of edges, each for a price alpha. Its goal is to minimize its private costs, i.e., the sum (SUM-game) or maximum (MAX-game) of the distances from v to all other nodes  in the network plus the costs of the bought edges. Since all decisions are taken individually and only with respect to optimize their private costs, analyzing the resulting network by comparing it to an overall good structure constitutes the central aspect in the study of NCGs. This task was formalized as analyzing the price of anarchy and was first discussed by Fabrikant et al. (PODC '03) for the SUM-game and by Demaine et al. (PODC '07) for the MAX-game. These papers inspired to a series of subsequent work.\r\nWe extend these models by incorporating quality-of-service aspects: Each edge can not only be bought at a fixed quality (edge length one) at a fixed price alpha. Instead, we assume that quality levels (i.e., edge lengths) are varying in a fixed interval. A node now can not only choose which edge to buy, but can also choose its quality x, at the price p(x), for a given price function p. For both games and all price functions, we show that Nash equilibria exist and that the price of stability is either constant or depends only on the interval size of available edge lengths. Our main results are bounds for the price of anarchy. In case of the SUM-game, we show that they are tight if price functions decrease sufficiently fast.", :title "Quality of Service in Network Creation Games", :keyword2 134, :authors (45088 45091 45092), :session 199885}, 288 {:keyword1 8, :keyword3 151, :abstract "Sensor networks offer exciting new possibilities for achieving sensory omnipresence. The main trouble is that the used sensors are inherently limited and individually incapable of estimating the state of a target, and that the measurements provided by these sensors are strongly corrupted by noise. We consider the problem of assigning sensors to track targets so as to minimize the error cost in the resulting estimation for target locations. More in particular, 2n sensors are located on a straight line, and need to be assigned in disjoint pairs to n targets, which are somewhere in the plane. This so-called Focus of Attention problem is a special case of a three index assignment problem. \r\n\r\nWe provide a complete complexity and approximability analysis of the Focus Of Attention problem. We establish strong NP-hardness, and we construct a polynomial time approximation scheme. Furthermore, we describe error cost functions for which a polynomial time algorithm exists. Finally, we discuss the setting where the sensors are at unit distances from each other, and prove that even in this special case strong NP-hardness still applies.", :title "The Focus of Attention Problem", :keyword2 154, :authors (9583 6251 12598 55926), :session 199912}, 290 {:keyword1 6, :keyword3 0, :abstract "We introduce an auction design framework for large markets with hundreds of items and complex bidder preferences. Such markets typically lead to computationally hard allocation problems. Our new framework consists of compact bid languages for sealed-bid auctions and methods to compute second-price rules such as the Vickrey-Clarke-Groves or bidder-optimal, core-selecting payment rules when the optimality of the allocation problem cannot be guaranteed. \r\nTo demonstrate the efficacy of the approach for a specific, complex market, we introduce a compact bidding language for TV advertising markets and investigate the resulting winner-determination problem and the computation of core payments. For realistic instances of the respective winner determination problems, very good solutions with a small integrality gap can be found quickly, though closing the integrality gap to find marginally better solutions or prove optimality can take a prohibitively large amount of time. Our subsequent adaptation of a constraint-generation technique for the computation of bidder-optimal core payments to this environment is a practically viable paradigm by which core-selecting auction designs can be applied to large markets with potentially hundreds of items. Such auction designs allow bidders to express their preferences with a low number of parameters, while at the same time providing incentives for truthful bidding. We complement our computational experiments in the context of TV ad markets with additional results for volume discount auctions in procurement in order to illustrate the applicability of the approach in different types of large markets.", :title "Compact bid languages and core-pricing in large multi-item auctions", :keyword2 101, :authors (45000 55333), :session 97}, 293 {:keyword1 29, :keyword3 175, :abstract "Because of circumstances, this is a combination of two talks.\r\n\r\n1.\r\nDesigning electrical power network grids is a challenging and complex issue. We investigate two different problems: connecting a new point to an existing electrical grid based on Euclidean distances in a non-uniform weighted space and choosing the cost-optimum design for a new electrical network in which we are given information about the producers, the consumers and the possible connections between points in the network.\r\n\r\nFor the first problem we show that Dijkstra’s algorithm combined with a point sampling approach can be used to find an approximate solution. \r\n\r\nThe second problem is modeled as a maximum network flow problem for which connections do not only have a cost for each unit of flow sent, but also a fixed cost, which has to be paid if the connection is used in the network. We propose two different approaches for solving this problem: a branch-and-bound (BB) algorithm and a cost-function slope (CFS) heuristic. \r\n\r\n2. The best way to reduce air pollution by public transport is to use only electric vehicles. However, at this moment this is not a cost-efficient solution. We will discuss environment-friendly vehicle scheduling using a fleet with multiple types of buses, where we focus on reducing air pollution on the global level and on ‘black spots’, for example city centres which are already heavily polluted. We also look for a balance between operational cost and pollution. We will illustrate this with a real-life case.", :title "1. Automatic planning for power system design/2. Environmental friendly vehicle scheduling", :keyword2 173, :authors (19331 45095 39371 24135 45097), :session 68}, 296 {:keyword1 101, :keyword3 75, :abstract "Measurements of the actual lead times in production systems show a non-linear\r\nrelationship between the workload and the output of these systems which can be\r\nmodeled by queuing models (see e.g. publications by Missbauer and Uzsoy (in 2002\r\nand in 2011)). Competition between jobs for bottleneck stations cause a network\r\nof queuing models (discussed e.g. by Haskose in 2002). Due to their complexity,\r\nseveral authors (e.g. Asmundsson in 2009) recommend clearing\r\nfunctions (CFs) as an alternative.\r\nSeveral usages of CFs are proposed in recent research. One is the control of the\r\norder release within the operative hierarchical production planning and control (see\r\ne.g. Kacar in 2012 or Missbauer in 2011). For this, Ravindran introduced in 2011\r\na single product planning model to estimate order releases. The CF is used as limitation\r\nof the capacity and determines the output of a production system depending\r\non its workload. A predetermined alpha service level, which denotes the probability of\r\nno stockout within an order cycle, has to be fulfilled. The demands are normally\r\ndistributed and the mean values as well as the standard deviation values vary over\r\ntime, which cause (additional) uncertainty.\r\nIn this contribution we extend the order release planning model of Ravindran\r\nto deal with multiple products as well as with product specific CFs. We introduce\r\na simulation-based method to derive product specific CFs for a specific production\r\nsystem. As test problem we use a scaled down production system based on\r\nan electrical parts manufacturer in Germany. To analyze the extended order release\r\nplanning model we perform long term simulation experiments in a rolling and overlapping\r\nplanning environment. The results outperform a basestock policy as an alternative\r\nprocedure.", :title "Order release within operative hierarchical production planning and control using product specific clearing functions", :keyword2 94, :authors (31192 45098 6751), :session 32}, 297 {:keyword1 75, :keyword3 101, :abstract "This work investigates multi-stage stochastic manufacturing and inventory systems in the semi-conductor industry. The systems use reorder point replenishment policies and face supply variability, demand variability and shared capacities among other business constraints. In this context the customer service level for the end product might follow a multi-modal distribution. This phenomenon challenges the usage of low-order moments for planning and analyzing the customer service level. We show the causes of this multi-modal behavior as well as a feasible approach to detect and mitigate these situations.", :title "Multi-modal service level distributions in stochastic production networks", :keyword2 97, :authors (29534 11111), :session 199863}, 301 {:keyword1 57, :keyword3 0, :abstract "We consider a set-valued optimization problem where a set-valued objective mapping is minimized over a feasible set given by a closed convex set. In this talk the notion of optimality introduced by Kuroiwa is regarded. The images of the set-valued mapping are assumed to be compact and convex whereas the mapping is not convex. Such kind of optimization problem may be interpreted as a bilevel optimization problem with a convex lower level problem possessing a compact feasible set. \r\nAfter introducing a special set difference, we define a directional derivative and a subdifferential for set-valued mappings and investigate properties of these tools. We derive new optimality conditions for unrestricted set-valued optimization problems using both directional derivative and subdifferential. In addition, we also present optimality conditions for restricted problems with the aid of the tangent cone (Bouligand cone) to the feasible set and the directional derivative. \r\n", :title "Optimality conditions in set-valued programming", :keyword2 0, :authors (29132), :session 199893}, 302 {:keyword1 158, :keyword3 0, :abstract "We discuss the solution of large MINLP using hierachical MILP relaxations. The MILP relaxiations are derived using piecewise-linear relaxations of the underlying nonlinear constraints. The main focus of our talk is to discuss how we can adaptively refine the relaxations.\r\nWe show the applicability of this technique on examples from gas network optimzation.", :title "Solving MINLP using  hierarchical MILP relaxations", :keyword2 0, :authors (19441), :session 199919}, 303 {:keyword1 174, :keyword3 156, :abstract "This talk treats the twin robot scheduling problem where two moving robots execute storage and retrieval moves in parallel along a shared pathway. The depots are located at both ends of the line and a dedicated robot is assigned to each of them. While moving goods between their respective depots and some storage locations on the line, non-crossing constraints among robots need to be considered. This problem setting is, for instance, relevant in container yards of large ports, where two identical gantry cranes (robots) store and retrieve containers from sea- and landside in parallel. We present an efficient decomposition heuristic, which solves even large problem instances with hundreds of jobs close to optimality in a couple of minutes.", :title "A heuristic decomposition procedure for the twin robot scheduling problem on a line", :keyword2 96, :authors (5934 5838 29815), :session 71}, 304 {:keyword1 174, :keyword3 175, :abstract "With an ongoing containerization of the global trade, optimizing routes of container ships received plenty attention within the recent years. Most of the models developed in this context are adaptions of the well-known vehicle routing problem, which, however, in some scenarios seems needlessly complex. For instance in short-sea shipping, most satellite ports visited by feeder ships to exchange containers with a central hub port lie on a straight line along some coastline or river. This paper investigates ship routing where all ports are located along a shoreline and introduces problem versions solvable in polynomial time. Other problem settings are shown to be NP-hard, so that heuristic solution procedures are developed. A comprehensive computational study investigates the efficiency of different routing policies.\r\n", :title "Routing feeder ships along a coastline", :keyword2 96, :authors (45099 29815 5934), :session 71}, 305 {:keyword1 101, :keyword3 61, :abstract "Many activities happen in the daily innovation of supply chain and thus complexity is generated. One typical problem from high-tech industry is that when a new alternative solution for a technology emerges with cost saving but adding complexity, it is not obvious whether the company should adopt it or not. Therefore it is important to evaluate the complexity and then identify which complexity is value-added and which is not. Current research on qualitative measurement is mainly for the strategic analysis; some quantitative methods are also available but most of them still lack practicability and tools. To support decision making, we are interested in the implementation details, such as, formal indicators and structural measurement. This paper focuses on the quantitative analysis of the complexity. The complex problem can be viewed as a system consisting of elements and various relationships based on the PROS (process, role, object, state) approach. Our hypothesis of complexity measurement analyses the static and dynamic parts separately. The static part can be measured using statistics of the elements and their unchanged relationships by calculating the weights of attributes. And the dynamic part tracks the interactions of elements and their changeable relationships in a holistic system. However, how to transfer this part to a numeric value is still under investigation. This idea was partly verified in an internal workshop for complexity management, where 4 different topics in the semiconductor industry from a specific technical problem to the general data management were discussed by around 50 audiences. The first step of quantitative measurement was tested by process and role analysis. It shows that this methodology has a potential to be applied in a broad area.", :title "Complexity Measurement in the Semiconductor Supply Chain", :keyword2 18, :authors (45061 26550 45100 45101), :session 44}, 307 {:keyword1 101, :keyword3 6, :abstract "In some dynamic markets, like electronics, the cost of some components can change from one quarter to the next. Thus, some buyers might be interested in awarding regular short-term contracts to follow the best market price. However, when suppliers can invest in improving their production cost, such short-term contracts can deter suppliers from investing since they have no guarantee about future business. In this paper, we investigate this issue through a two-period model in which the buyer decides whether to auction off one contract at the beginning of each period or (to auction off) a single contract for both periods, depending on the size of its supply base. We assume that only the supplier that wins the first-period auction can invest to improve its second-period cost. We first characterize the endogenous optimal investment under both settings. Then we determine the equilibrium bidding strategy of the suppliers, as well as the optimal mechanism that the buyer should propose to its potential suppliers. Finally, we realize some numerical analysis to illustrate our results. Our results show that suppliers always make a greater investment when there is only one second-price auction that is organized. Further, we find that the optimal mechanism for the buyer depends on the cost improvement curve and on the supply base size. Indeed, the buyer tends to prefer a single auction when there are few suppliers competing, to take advantage of a greater investment, and two auctions when suppliers are numerous, to benefit from an enhanced competition. Finally, we also find that suppliers are always better off in the two-auction context.", :title "Optimal contract length in dynamic markets", :keyword2 25, :authors (44900 35390), :session 199862}, 309 {:keyword1 174, :keyword3 175, :abstract "Freight forwarding companies in the less-than-truckload (LTL) industry are under strong competitive pressure. Due to this pressure companies are trying to gain a competitive advantage by systematically optimizing the processes and the implementation of logistics innovations. We want to investigate LTL terminals, which are the hubs of the LTL transportation networks and operate as distribution centers with collection and distribution function of goods, e.g. cross docking. The task of a LTL terminal is the accurate and in time handling of shipments between vehicles on short-distance traffic and transport vehicles on long-distance traffic. The performance of a LTL terminal is largely determined by the proper use of the gates. However, many uncertain factors influence the planning. Fluctuations can occur in both, the arrival times of vehicles as well as in the processing times. Even failures of resources within the logistical system can affect the quality of the solution. A gate assignment plan should also be stable for late arrivals and other uncertain influences. Thus it is reasonable to use robust (stochastic) optimization to create a gate assignment plan which can handle the occurring uncertainties. We present our optimization model for the assignment of the trucks to the gates, taking into account the processes inside the terminal, e.g. the movements of the goods from gate to gate. In addition to this, we also show which uncertainties need to be considered to get a robust gate assignment plan and how to include these uncertainties in our model using robust (stochastic) optimization.", :title "Robust gate assignment in less-than-truckload terminals", :keyword2 94, :authors (37090 26657), :session 199881}, 310 {:keyword1 161, :keyword3 0, :abstract "We propose a parametric simplex algorithm for solving linear vector optimization problems (LVOPs). It is a generalization of the parametric self-dual simplex algorithm, which originally is designed for solving single objective linear optimization problems, and capable of solving two objective LVOPs whenever the ordering cone is the positive orthant. Our algorithm works for any dimension, and it is possible to extent it to any polyhedral ordering cone C. In each iteration, the algorithm provides a set of inequalities, which define the current partition of the parameter space and correspond to a vertex of the upper image. In addition to the usual simplex arguments, one needs to eliminate the redundant inequalities from that set. This extra step is similar to the vertex enumeration procedure, which is used in most of the objective space based LVOP algorithms. Different from those, this algorithm doesn’t require to solve a scalar linear program in each iteration.", :title "Parametric Simplex Algorithm for Linear Vector Optimization Problems", :keyword2 159, :authors (14206 29603 45103), :session 87}, 318 {:keyword1 40, :keyword3 152, :abstract "\r\n\r\nWe consider a class of stochastic positional games that extend deterministic positional games and discrete Markov decision processes. A special class of these games is formulated and studied using a certain game-theoretical concept for finite state space Markov decision processes with an average and expected total discounted optimization criteria [1,2]. Now, we assume that a finite space Markov  process may be controlled by several players as follows: \r\n\r\nThe set of states is divided into several disjoint subsets which we regard as the position sets of the corresponding players. Each player has to determine which action should be taken in each state of his position set in order to minimize his own average cost per transition or the expected total discounted cost. The cost of system’s transition from one state to another in a Markov process is given for each player separately. In addition the set of actions, the transition probability functions and the starting state are known. We assume that in the considered  games the players use stationary strategies: we  are seeking for a Nash equilibrium. \r\n\r\nOur main results are concerned with the existence and characterization of Nash equilibria for stochastic positional games and an application of the algorithms for determining the optimal stationary strategies of the players.\r\n\r\nReferences\r\n\r\n1. Lozovanu D. \r\nThe game-theoretical approach to Markov decision problems and determining Nash equilibria for stochastic positional games. Int. J. Mathematical Modelling and Numerical Optimization, \r\n2 (2), 162-164 , 2011\r\n\r\n2. Lozovanu D., Pickl S., Kropat E. \r\nMarkov decision processes and determining Nash equilibria for st", :title "Algorithms in Stochastic Positional Games for Determining Nash Equilibria", :keyword2 18, :authors (9694 4796), :session 199886}, 321 {:keyword1 86, :keyword3 0, :abstract "Project management is a complex decision making process involving the unrelenting pressures of risk, time and cost. A project management problem typically consists of planning and scheduling decisions. (Gonçalves, Mendes, 2008)\r\nThe resource-constrained project scheduling problem (RCPSP) consists of activities that must be scheduled subject to precedence and resource constraints such that the makespan is minimized. (Hartmann, Briskorn,2010). It is  is an NP-hard (Non-Deterministic Polynomial-Time Hard) problem which contains a number of complicated problems in scheduling like job shop, flow shop and assembly line balancing. As the problem is NP-hard the performance is limited and can only solve small-sized project networks. Genetic algorithms (GA) adapt to dynamic factors such as changes to the project plan and aims to find near-optimal solutions. Also overcomes the poor performance of the exact procedures for large-sized project networks.\r\n This study  presents a literature review about genetic algorithm for the resource constrained project scheduling problems and aims to show the advantages of using a genetic algorithm (GA) as a heuristic method in RCPSP. \r\n", :title "Review of The Literature About Genetic Algorithms On The Resource-Constrained Project Scheduling Problems", :keyword2 59, :authors (45118 45119 45120), :session 199869}, 325 {:keyword1 162, :keyword3 0, :abstract "We consider an NLP formulation of the optimization problems with cardinality constraints which arise, e.g. in sparse portfolio selection. Similarly to mathematical programs with complementarity constraints, we introduce concepts of S- and M-stationarity. We show that both are optimality conditions for cardinality constrained problems under certain problem-tailored constraint qualifications. For a parameterized version of the problem we analyze qualitative stability of solutions to the respective M-stationarity conditions.", :title "Optimality conditions for optimization problems with cardinality constraints", :keyword2 57, :authors (11953 44863 13084), :session 7}, 327 {:keyword1 57, :keyword3 74, :abstract "In this presentation, we will introduce the robust optimization framework and the distributed computation feature of the FICO Xpress Optimization Suite 7.7. The first part of the talk will present the design principles and incremental modelling feature of the robust optimization framework, and will be continued by a description of the distributed computation engine and the new cloud-based optimization service.", :title "Robust optimization and distributed computation features of the FICO Xpress Optimization Suite", :keyword2 94, :authors (42895 31389 32575 21574 39525), :session 199883}, 331 {:keyword1 175, :keyword3 0, :abstract "We introduce a binary linear model for solving the train path assignment\r\nproblem. For each train request a train path  has to be constructed from a \r\nset of predefined path parts within a time-space network.   \r\nFor each possible path we use a binary decision variable to indicate,\r\nwhether the path is used by the train request. Track and halting \r\ncapacity constraints are taken into account. We discuss different \r\nobjective functions, like maximizing revenue or maximizing total train \r\npath quality. The problem is solved by using column generation\r\nwithin a  branch and price approach. This talk gives some modeling\r\nand implementation details and presents computational results from real world instances. ", :title "Modelling and Solving a Train Path Assignment Model", :keyword2 158, :authors (33323), :session 199939}, 338 {:keyword1 42, :keyword3 0, :abstract "A \"`Spontaneous Postman Problem\"' is a routing problem in which a postman selects subsequent\r\nstreets of his tour by a nilly-willy strategy. This spontaneous choice leads to the basic question how\r\nto partition a network into different subdistricts such that it can be guaranteed, that each district is\r\nserved if the postman is “`spontaneous”’. The structural problems of the network that arise within this\r\nframework are closely related to the investigation of local traces and maximum edge-disjoint cycle\r\npackings in graphs. A \"`min-max-theorem\"' can be proved if the graph is Eulerian.", :title "Spontaneous Postmen Problems and edge-disjoint cycle packings in graphs ", :keyword2 95, :authors (25677), :session 199914}, 340 {:keyword1 102, :keyword3 0, :abstract "Electric mobility enables a sustainable climate and environmental friendly mobility to manage globally discussed topics like the reduction of CO2 emissions, the reduction of total energy consumption, and the efficient use of available resources. For example, the German government gives a clear sign for the principal role of electric vehicles in the near future with the goal of one million electric vehicles on German roads by 2020. But, the range of an electric vehicle is currently limited by battery cost and weight. It must be the goal of each driver to use the given energy as good as possible. Compared to conventional cars, where the driving behavior is a pivotal factor for fuel consumption, there are a lot more influences which have a significant influence on power consumption while driving electric vehicles. For example, the use of auxiliary equipment (e.g. interior heating) has a high influence and results in a significant range reduction. The missing understanding of the cause and effect laws for environmental (e.g. weather, route) and additional (e.g. number of car passengers) factors on power consumption of an electric vehicle induces uncertainty and range anxiety, i.e. the fear of not reaching the desired destination. We describe a model which explains these interdependencies and a cause and effect model. The applied model provides assistance for the driver: it quantifies the interaction between the factors which influence the power consumption. To validate the model, test cycles with real time data are conducted. The test cycles show exemplary different effects on the power consumption by varying the identified influence factors. ", :title "A Quantitative Model of Electric Vehicles’ Energy Consumption ", :keyword2 0, :authors (43053 19100), :session 199933}, 341 {:keyword1 94, :keyword3 158, :abstract "Unit commitment (UC) is one of the most important problems in electric power system operations. It seeks an economic operating policy to a system of generating units over a multi-period finite horizon T. This policy determines the periodical power output of each unit, implying which units to commit (operate) in order to meet the demand subject to equipment and physical constraints. We consider the profit UC (PUC) problem of a generator operating in a deregulated market wishing to maximize its profit under uncertain demand and renewable energy output.\r\nElectricity is inefficiently stored, which poses an additional challenge.\r\nWe employ the Robust Optimization (RO) methodology to solve the PUC model. The RO is a large-scale distribution-free methodology designed for uncertain problems. It provides a feasible solution for any realization bounded within an uncertainty set, and its value is a guaranteed bound on the objective function value over this set.\r\nFor a given trajectories of the uncertain parameters the problem is casted as a mixed integer linear program (MILP) with O(T) constraints. Since these uncertainties affects the objective function only, its robust counterpart (RC) includes the same O(T) mixed integer linear constraints as in the deterministic problem, yet its objective function is bilinear. Although such a problem is generally NP-hard, we utilize the uncertainty set structure to optimality solve it via enumeration. Essentially, the resulting RC model is a MILP with O(T) constraints as the deterministic model. Numerical experiments show that the RC policy is significantly superior to the NOM policy, i.e., the solution to the problem given specific nominal trajectories of the uncertain parameters.\r\n", :title "Robust Optimization for the Multi-Period Unit Commitment Problem", :keyword2 29, :authors (42750 11838 3746), :session 199852}, 345 {:keyword1 151, :keyword3 42, :abstract "We propose a new approximative approach to the discrete facility location problem that provides solutions close to the lexicographic minimax optimum. The lexicographic minimax optimum is a concept that allows to find equitable location of facilities. Our main contribution is the approximation approach which is based on rules which allow; (i) to take into account the multiplicities assigned to different customers; (ii) to detect whether for a given distance active customers can reach higher, equal or smaller distance to the closest located facility; and (iii) to use methods customized for solving the p-median problem. Customized methods can handle larger problems than up to date general purpose integer programming solvers. We use the resulting algorithm to perform an extensive study using the well-known benchmarks, and using benchmarks derived from the real-world road network data. We demonstrate that our algorithm allows to solve larger problems than existing algorithms and provides high-quality solutions. The algorithm found an optimal solution for all tested benchmarks where we could compare the results with the exact algorithm.", :title "An Approximative Lexicographic Min-Max Approach to the Discrete Facility Location Problem", :keyword2 54, :authors (29160 29548 29390), :session 199900}, 346 {:keyword1 175, :keyword3 154, :abstract "In public transportation, tariff planning is an important decision problem, which considerably influences the profit of operators and the customer satisfaction of passengers. In this talk we investigate a tariff design problem, which maximizes the profit while considering the customers’ willingness to pay in different tariff systems, such as unit, distance- or zone-based tariffs. In the latter case, the transportation network is subdivided into disjoint zones and the customers’ fare depends on the traversed zones. For this tariff system, several zoning and pricing strategies are presented and evaluated. Since these problems turn out being NP-hard even if the network structure of transportation network is very simple, efficient heuristic solution approaches are introduced.", :title "Zone-based tariff design in public transportation", :keyword2 174, :authors (45125 5934), :session 71}, 347 {:keyword1 156, :keyword3 0, :abstract "Preventive maintenance of technical systems strives at increasing the reliability or performance of the system. We consider modular monotonic multi-state systems consisting of several components (modularity), where the maintenance of a component does not impair the performance of the system (monotonicity) and every component may evolve in (possibly infinitely many) different states. A structure function maps the component states to the system performance. We assume that the structure function, the stochastic wearing processes of the single components, the available maintenance budget, and the (opportunity) cost for the deterioration of the system performance are known. We seek a component-specific maintenance strategy that allocates the budget in such a way that the total opportunity cost in the planning horizon is minimized. We address this optimization problem using the concept of (approximative) dynamic programming. ", :title "Maintenance strategies for modular monotone multi-state systems", :keyword2 165, :authors (28739), :session 199882}, 349 {:keyword1 22, :keyword3 165, :abstract "We formulate the disaster preparedness and short-term response planning problem through a multistage stochastic optimization model. To account for risk, we also add chance constraints which ensure that the budget limits will not be exceeded with high probability.  These chance constraints, however, are replaced by some coherent risk measures and are then added to the objective function. We assume that both the demands and the road capacities have known but continuous distributions, which implies an infinite number of scenarios for the problem. Then, we discretize these continuous distributions using different sampling techniques, and build scenario trees which contain a big number of scenarios. To cope with the computationally untractable multi-dimensional integrations, we estimate the expectations by their Sample Average Approximations. Under some assumptions, we solve the resulting problems through the Stochastic Dual Dynamic Programming algorithm. We numerically derive useful insights for the applications of the algorithm. ", :title "Stochastic Dynamic Programming Solution of a Risk-Adjusted Disaster Preparedness and Relief Distribution Problem", :keyword2 97, :authors (29330), :session 199877}, 350 {:keyword1 164, :keyword3 0, :abstract "For (undirected) graphs, the bandwidth problem is the problem of labeling the vertices of a given graph with distinct integers such that the maximum difference between the labels of adjacent vertices is minimal. \r\nIn this talk we present two new semidefinite programming bounds of the problem; one is suitable for graphs with symmetry, and the other one applicable to any graph of moderate size. In order to evaluate the lower bounds, we also compute upper bounds. Consequently, we are able to determine an optimal labeling \r\nfor several graphs under consideration.", :title "On bounding the bandwidth of graphs", :keyword2 13, :authors (8638 45130 23189), :session 81}, 351 {:keyword1 151, :keyword3 94, :abstract "We propose a natural model for two-stage scheduling in which reserving a time unit for processing jobs incurs some cost. This cost depends on the time at which the reservation is made: a priori decisions, based only on distributional information, are much cheaper than on-demand decisions made when the actual scheduling scenario is known. Such a model captures e.g. the resource provisioning problem that users of cloud computing services face.\r\n\r\nWe consider both the stochastic and the robust version of this problem. We investigate scheduling on unrelated machines in the two-stage scheduling model with reservation cost. Our main contribution is an (8 + epsilon)-approximation algorithm, for both the stochastic and the robust version with a polynomial number of scenarios. It relies on a generalized time-indexed LP-formulation, a rounding strategy that balances first-stage reservation and fractional scheduling cost, and the concept of alpha-points. The key ingredient is a separation of jobs and time slots to be considered in either the first or the second stage only. At the expense of another epsilon our result holds for any arbitrary scenario distribution given by means of a black-box in the two-stage stochastic problem.", :title "Two-Stage Scheduling on Unrelated Machines", :keyword2 165, :authors (39743 45131 14975 45132), :session 199880}, 357 {:keyword1 181, :keyword3 23, :abstract "The forecasting of high dimensional nonlinear systems is obviously a non-trivial challenging task, both regarding identification, analysis and model specification. Artificial neural networks have been proven to be universal approximators but this still leaves the identification task a hard one.  To do it efficiently, we have to violate some of the rules of classical regression theory. Furthermore we should focus on the interpretation of the resulting model to overcome its black box character. Of special interest are complex dynamical system in the form of state space models realized as recurrent neural networks. After the introduction of small open dynamical systems we will study dynamical systems on manifolds. Here manifold and dynamics have to be identified in parallel. We will move on to large closed dynamical systems with hundreds of state variables and will compare causal versus retro-causal models of the observations.  The combination of these models will lead us to an implicit description of dynamical systems on manifolds. Finally we will discuss the quantification of uncertainty in forecasting. In our framework the uncertainty appears as a consequence of principally unidentifiable hidden variables in the description of large systems. The value of the different principles will be shown on real world principal in Supply Chain Management, Finance, Load Forecasting, Renewable Energy, Process Control and Process Surveillance.\r\n", :title "Forecasting of Complex Dynamical Systems with Neural Networks", :keyword2 5, :authors (14818), :session 199892}, 358 {:keyword1 73, :keyword3 0, :abstract "Since decades the public sector seems incapable to not incur new debt or even save money to overcome the omnipresent stressed financial situation. This grievance does not only exist on a certain level of public sector administration but is rather pervasive over several levels of public bodies including municipalities, federal states as well as entire nations. This maladjustment is further accompanied by calls for an increase in public service provision efficiency to improve the financial situation of public institutions. In our contribution, we test whether and how local public service provision efficiency (differentiated in productive- and cost-efficiency) changes over time identifying if the stressed financial situation is counteracted over time. We therefore identify if a possible municipal service provision efficiency change over time is due to an overall ability change, namely a shift of the production function or individual effects. We deploy Stochastic Frontier Analysis to build an efficient frontier based on a novel panel of German municipalities. On the one hand our results suggest that for both, productive- and cost-efficiency a negative structural trend holds. On the other hand, for productive-efficiency individual effects increase public service delivery efficiency over time. Therefore, an efficiency increase on the cost level might be rejected but on the productive level mixed results occur.", :title "Structural versus individual time effects on local governments’ service provision efficiency: A comparison of productive- and cost-efficiency", :keyword2 99, :authors (45104 45135), :session 199856}, 359 {:keyword1 35, :keyword3 0, :abstract "Quantifying credit risk with default probabilities is a standard technique for financial institutes, investors or rating agencies. To get a higher precision of default probabilities, one idea is the aggregation of different available ratings (i.e. default probabilities) to a so called 'consensus rating'. But does the concept of 'consensus rating' really make sense? What is a 'real' consensus rating? This paper tries to clarify under which conditions a consensus rating exits. Therefore, the term of 'consensus information' is used. This leads to a concept that deals with the precision of aggregated rating characteristics. Within this framework the problem of misinformation resp. contradictory information is addressed. It is shown that consensus information is not necessarily more informative than individual information. Furthermore, the aggregation aspects are discussed from a statistical perspective.", :title "Consensus Information and Consensus Rating - A Note on Methodological Problems of Rating Aggregation", :keyword2 93, :authors (44954 45133), :session 199890}, 364 {:keyword1 91, :keyword3 0, :abstract "A major benefit of flexible products is that they allow for supply-side substitution even after they have been sold. This helps improve capacity utilization and increase the overall revenue in a stochastic environment. As several authors have shown, flexible products can be incorporated into the well-known deterministic linear program (DLP) of revenue management’s capacity control. In this talk, we show that flexible products have an additional “value of flexibility” due to their supply-side substitution possibilities, which can be captured monetarily. However, the DLP-based approaches proposed so far fail to capture this value and, thus, steadily undervalue flexible products, resulting in lower overall revenues. To take the full potential of flexible products into account, we propose a new approach that systematically increases the revenues of flexible products when solving the DLP and performing capacity control. A mathematical function of variables available during the booking horizon represents this artificial markup and adapts dynamically to the current situation. We determine the function’s parameters using a standard simulation-based optimization method. Numerical experiments show that the benefits of the new approach are biggest when low value demand arrives early. Revenues are improved by up to 5% in many settings.", :title "On the application of DLP-based approaches for revenue management with flexible products", :keyword2 2, :authors (16305 22994 32076), :session 98}, 365 {:keyword1 92, :keyword3 0, :abstract "Product reclamation is a critical process in remanufacturing. It is generally assumed in the literature that customers simply want to get rid of their used products without expecting any compensation for them. Some authors have only recently started looking into firms that offer a posted (fixed) price for them. Following recent reports suggesting that customers are increasingly open to bargaining, we compare using a posted price and bargaining to obtain used products. In our analysis, we consider an original manufacturer acting as a monopolist as well as a manufacturer and an independent remanufacturer acting in a duopoly. We analytically show that bargaining is always beneficial to the monopoly manufacturer. In the duopoly case, we distinguish a Cournot competition and a market with the manufacturer as Stackelberg leader. The results of a numerical study show that both firms will use posted pricing in the Cournot competition, especially if bargaining is not costless. By contrast, the remanufacturer can significantly increase his profit by using negotiations if he is the Stackelberg follower.", :title "Buying used products for remanufacturing: Negotiating or posted pricing", :keyword2 0, :authors (22994), :session 199862}, 366 {:keyword1 5, :keyword3 149, :abstract "The liberalization of the German energy market in 2002 along with the deregulation of neighbouring European energy markets in recent years has created several needs for energy companies, public services, energy brokers and large scale energy consumers. Innovative procurement concepts must be developed in order to make use of market chances, to minimize risks or to leverage energy resources efficiently.\r\n\r\nIn this context, energy price forecasting is probably one of the most demanding tasks for market oriented energy procurement. Since the primary energy markets are highly interrelated, an isolated analysis of a single domestic energy market is questionable. What is required is a joint modelling of all interrelated energy and commodity markets. \r\n\r\nWe present an approach of coherent market modeling to forecast energy prices, which is based on large time-delay recurrent neural networks (LRNN). These nonlinear state space models combine different operations of small neural networks into only one shared state transition matrix. We use unfolding in time to transfer the network equations into a spatial architecture. The training is done with error backpropagation through time. Unlikely to small networks and standard econometric techniques, overfitting and the associated loss of generalization abilities is not a major problem in large networks due to the self-created eigen-noise of the systems.\r\n\r\nWe exemplify our approach of market modeling by forecasting the long- and short-term development EEX base future prices.", :title "Forecasting Energy Prices with Neural Networks", :keyword2 23, :authors (14817 14818), :session 85}, 368 {:keyword1 35, :keyword3 152, :abstract "Credit risk modeling is generally based on a stochastic framework, with implicit assumptions about the applied model, stochastic variables and parameters. The loss of a portfolio is often described as a random variable, and credit risk is expressed by appropriate risk measures. However, estimating the model parameters induces estimation errors, leading to errors in risk measures. These estimation errors are generally treated as random variables, even though this is equivalent to being neutral to uncertainty in the sense of Knight (1921). Thus, given the large estimation errors in credit risk, and empirical evidence which shows that agents are actually not neutral to uncertainty (Ellsberg, 1961), we present a framework on how parameter uncertainty can be considered in any credit risk model.\r\n \r\nFollowing Garlappi (2007), we model non-neutrality to uncertainty using an optimization problem subject to specified confidence intervals around the parameter estimates. In an empirical study we use default data from S&P’s and Moody’s from 1970 to 2012 to assess how the inclusion of parameter uncertainty impact real-world applications.\r\n\r\nWe demonstrate that many published alternative approaches that deal with parameter uncertainty are also covered by our approach. In addition, we observe that previous approaches inadvertently model investors as affine to uncertainty. Our analysis of historic default data shows that portfolios with particularly high ratings are more affected by parameter uncertainty than portfolios with lower ratings. In conclusion, our framework (1) has a solid axiomatic foundation, (2) can be applied to any credit risk model, (3) uses the full information included in available datasets, and (4) can quantify and compare the degree of uncertainty aversion.", :title "Credit Decisions under Risk and Uncertainty", :keyword2 94, :authors (33649 22180), :session 199961}, 369 {:keyword1 63, :keyword3 0, :abstract "As a definition, the logistics industry can be described as the well worth winning in the field of engineering and widely used in human systems, which tends to grow every day in changing and evolving world economy. The logistics industry services in line with people's expectations and requests, such as product needs to be provided at any time which is embraced like an idea, while performing activities with the effects of globalization are faced with various risks. Known as a negative concept, risk and its reflection for the situation to be resolved is a paramount importance for companies. Incorporating human factors for the logistics industry is also important to reduce risks thoughts. In this study, the risks that logistics sector firms can be encountered analyzed by one of the Multi-Criteria Decision Making techniques, Decision Making Trial and Evaluation Laboratory (DEMATEL) method. The method has considered four main criteria (Financial Risks, Strategic Risks, Physical Risks, Operational Risks) and twelve sub-criteria’s (Liquidity Management, Contracts, Credibility Management, Political Risks, Customer Satisfaction, E commerce Logistics, Weather Conditions & Climate, Cargo Security, Dependence  to Key Area, Fleet Management, Employee Suitability, Asset Utilization and Management). At last the result obtained from method is presented. ", :title "THE RISK FACTORS ANALYSIS THAT CAN BE FACED IN LOGISTICS SECTOR WITH DEMATEL METHOD", :keyword2 93, :authors (20840 20833), :session 199841}, 371 {:keyword1 73, :keyword3 99, :abstract "The stressed financial situation in the public sector and the continuous aspiration for austerity in western governments and public bodies is omnipresent. As one core element in the New Public Management shift, Germany, like many other countries, has experienced significant reforms in public sector accounting and reporting in the last decade. We analyse the effect of new accounting and budgeting regimes. We therefore analyse public service provisions’ cost-efficiency of German local governments in the state of North Rhine-Westphalia applying a stochastic frontier approach. This study presents evidence for an efficiency boost of municipalities due to the adoption of accrual accounting. Furthermore, we show that adopting accrual accounting leads to an increase in efficiency over time.", :title "Local governments in the wake of new financial management: Evidence from Germany", :keyword2 140, :authors (45135 45104), :session 199964}, 372 {:keyword1 124, :keyword3 0, :abstract "Ranking problem is a problem of learning a ranking function from the data set of n objects each of which is endowed with an attribute vector of m dimension and a ranking label chosen from the ordered set of labels. Attribute vectors of objects are separated by hyperplanes which share a common normal vector, then each object is given a label according to the layer it is located in. The problem is to find the normal vector as well as the thresholds of each layer that best fit the input data. What distinguishes the problem from the conventional multi-class classification problems is that the identical normal vector should be shared by all the separating hyperplanes.\r\nWe propose to apply the dual representation of the normal vector to the formulation based on the fixed margin strategy by Shashua and Levin for the ranking problem. We keep the original constraints and replace the objective function by a quadratic function of the dual representation. The problem thus obtained has the drawback that it has n of variables as well as n of constrains, however, the fact that it enables the application of kernel technique outweighs the drawback. The key idea is twofold: the dimension m of the attribute vectors is usually much smaller than the number n of objects, hence we need a small number of attribute vectors for the dual representation, and it is very likely that most of the constraints are redundant at the optimal solution. Then we propose a row and column generation algorithm. Namely, we start the algorithm with a sub-problem which is much smaller than the master problem in both variables and constraints, and then increment both of them as the computation goes on. Some computational results will be reported at the site.", :title "Row and Column Generation Algorithm for Maximization of Minimum Margin for Ranking Problem", :keyword2 120, :authors (45033 45138 19907 29260), :session 199867}, 373 {:keyword1 157, :keyword3 0, :abstract "The modularity proposed by Newman and Girvan is one of the most common measures when the nodes of a graph are grouped into communities consisting of tightly connected nodes. Due to the NP-hardness of the problem, few exact algorithms have been proposed.\r\nAloise et al. formulated the problem as a set partitioning problem, which has to take into account all, exponentially many, nonempty subsets of the node set, and makes it difficult to secure the computational resource when the number of nodes is large. Their algorithm is based on the linear programming relaxation, LP relaxation for short, and uses the column generation technique. Although it provides a tight upper bound of the optimal value, it can suffer a high degeneracy due to the set partitioning constraints.\r\nIn this study, we propose an algorithm based on the Lagrangian relaxation. We relax the set partitioning constraints and add them to the objective function as a penalty with Lagrangian multipliers, and obtain the Lagrangian relaxation problem with only the binary variable constraints. For a given Lagrangian multiplier vector, an optimal solution of the Lagrangian relaxation problem can be obtained by checking the sign of coefficients, but it is hard to compute all the coefficients of variables. Then we propose to use the column generation technique in order to alleviate the computational burden. Namely, we start the algorithm with a small number of variables and gradually add variables as the computation goes on. We also propose some methods to accelerate the convergence.", :title "A Lagrangian Relaxation Algorithm for Modularity Maximization Problem", :keyword2 172, :authors (45034 45033 29260), :session 199910}, 374 {:keyword1 45, :keyword3 0, :abstract "Operating rooms (OR) are a hospital’s most important and expensive resources. Thus hospitals strive to operate ORs at high utilization without jeopardizing patient service. In this context, one of the main challenges is to cope with the natural uncertainty in surgery durations. We consider the problem of scheduling types of elective procedures to ORs over a mid-term planning horizon (Master Surgical Scheduling). The resulting OR-planning model is stochastic and allows to control overtime. We present different linearization approaches of the non-linear base model and indicate further extensions.", :title "Master Surgical Scheduling with stochastic surgery durations", :keyword2 0, :authors (39298 16870), :session 199937}, 375 {:keyword1 91, :keyword3 0, :abstract "In a regenerate-to-order environment used products owned by the customers are sent to service providers to restore the products’ functionality for another life cycle. Regeneration service providers have to decide whether to accept or to reject incoming regeneration orders. The reason is that they have only scarce short-run capacities. \r\nThe used products have individual conditions which are not known with certainty in advance. Different regeneration modes can be applied in order to regenerate used goods. Besides the possibility of repairing damaged parts of the product, there exists the option to replace those parts by inventory parts. Taking these characteristics into account, we present a bid-price-based approach to capacity control. We develop a randomized linear program with network capacities. The beneficial effect of the flexibility arising from different modes is shown by numerical studies. ", :title "Order Acceptance Control in a Regenerate-To-Order Environment with Different Regeneration Modes", :keyword2 92, :authors (39320), :session 101}, 376 {:keyword1 45, :keyword3 95, :abstract "The global demographic change leads to an increasing number of elderly people and therefore people in need of care. One possibility to support these people is home health care, where clients stay at their homes and receive services from home health care providers. To plan the different services for a given time period, the providers have to perform a complex routing and scheduling task. The home health care problem from literature combines the well-known vehicle routing problem and nurse rostering problem to achieve the daily routes and duty schedules for the nurses. These classical problems are extended by some specific extensions such as skill requirements and personal preferences of clients to be applicable in the home health care context. \r\nThe routing part of the home health care problem is the object of many publications. In contrast, usually working regulations for the nurses are not considered, although they are widely used in the nurse rostering problem for hospitals. We adapt relevant regulations, such as shift rotations and break rules, and bring them to the home health care problem in order to respect personal preferences and legal requirements. Numerical results from a mixed-integer formulation solved by a commercial solver show that these tend to be noncompetitive with respect to computing time due to the integration of two NP-hard problems. Therefore we present a heuristic approach based on a large neighborhood search to cope with the complexity of the problem and get solutions in a reasonable computing time.", :title "A heuristic approach to the home health care problem with working regulations", :keyword2 121, :authors (45137 1141), :session 199938}, 377 {:keyword1 96, :keyword3 0, :abstract "The power consumption rate of computing devices has seen an enormous increase over the last decades. Therefore computer systems must make a trade-off between performance and energy usage. This observation has led to speed scaling, a technique that adapts the speed of the system to balance energy and performance. Fundamentally, when implementing speed scaling, an algorithm must make two decisions at each time: (i) a scheduling policy decides which jobs to serve, and (ii) a speed scaler decides how fast to run.\r\n\r\nIn this presentation we introduce a preemptive single machine scheduling problem where the machine speed is externally given and depends on the number of jobs that is available for processing. A job is available for processing when it is released but not yet completed. The objective is to minimize the sum of weighted completion times. \r\n\r\nWhen the machine speed is constant over time, it is well known that the Smith's rule yields an optimal schedule. Unfortunately this gives arbitrary bad results for the problem under consideration. We introduce a greedy algorithm that solves the problem to optimality when all weights are equal. With only small changes we can alter this algorithm to work when weights are arbitrary and we have unit processing times. \r\n\r\nFor arbitrary weights and processing times our algorithm finds an optimal schedule when we restrict ourselves to a certain order of job completions. However, we do not know which is an optimal order of job completions. The WSPT-order, which is optimal when machine speed is fixed, can even give arbitrary bad results.\r\n", :title "Scheduling with job dependent machine speed", :keyword2 173, :authors (45115 29203), :session 93}, 379 {:keyword1 96, :keyword3 0, :abstract "Scheduling is one of the most important problems in industrial production planning. Unfortunately, in general this problem is NP-complete which makes it a computationally hard problem to solve. Various methods such as SAT-Solving, Dynamic Programming, state-based search, have been applied on scheduling since the late 1940s. In order to handle the diversity and dynamics of different scheduling domains more general problem representations such as Mixed Integer Programming or Constraint Satisfaction have proven to be successful.\r\nMore recent approaches build on the paradigm of Answer Set Programming (ASP) which is a pure declarative approach based on a subset of first order logic. Due to the success of Constraint Programming (CP) techniques hybrid approaches combining ASP and CP have been developed. Currently, there are two types of such Constraint ASP approaches. First, there are solvers providing an extended input language in order to have special constructs for expressing constraints concurrently to ASP constructs. Second, a more lightweight combination of combining Constraint Programming and ASP is to use ASP as a specification language for Constraint Satisfaction Problems (CSPs) such that the solution (answer set) of an ASP program encodes a CSP which is then used by a CP/CSP solver as an input.\r\nIn the proposed article we compare such ASP based approaches with regard to their suitability for scheduling problems. Our analysis and exemplifications are done on the basis of a production scheduling problem of Infineon Technologies Austria AG. The Infineon production scheduling problem incorporates the notions of workflows, priorities, due time, tardiness, change over times, planned and unplanned downtimes of devices and furthermore.", :title "Representing production scheduling problems with answer set programming approaches", :keyword2 61, :authors (45028 45148 45145 45144 45064 45147 45142), :session 44}, 380 {:keyword1 175, :keyword3 63, :abstract "In depot management for public transport, disposition is the process of assigning vehicles to tracks or to parking spaces, as well as journeys to vehicles and/or depot positions. The problem usually involves a lot of constraints and criteria. Constraints can be hard (e.g. a certain track needs to be cleared by a certain time) or soft (only use a certain vehicle if you really need to), and they can be both explicit and implicit. The criteria can be of different priorities and are often contradicting. Furthermore, as anyone who has used public transport can tell, there is a great degree of uncertainty. On top of that complexity, in a real-time system we have strict time constraints for computation. Any decision must be taken within a few seconds.\r\n\r\nPSI Transcom’s depot management software provides all of this in a highly configurable way. Constraints and criteria can be dynamically added and modified, thus adapting the system to the special needs of individual customers without changing existing code. The choice of the preferred solution among a set of feasible alternatives given multiple criteria is based on fuzzy logic, implemented in the Qualicision® kernel supplied by Fuzzy Logik Systeme.\r\n\r\nIn this talk, I will first give a short overview of the general optimization process in our software. Then I will provide some examples where standard combinatorial optimization problems, such as shortest path, maximum flow and maximum matching, play a key role within this process. They occur as subproblems of the global optimization problem and need to be solved in order to evaluate individual constraints and criteria.", :title "Aspects of Combinatorial Optimization in Depot Management for Public Transport", :keyword2 8, :authors (29288), :session 199941}, 382 {:keyword1 19, :keyword3 18, :abstract "Outranking-methods as a specific application of Multi-Criteria Decision Analysis (MCDA) are applied to structure complex decision problems as well as to elicitate of the decision makers’ preferences. Therefore, a consideration of behavioral effects within outranking-methods seems to be meaningful. Several behavioral effects and biases have been identified in previous studies, however, only few approaches exist to consider such behavioral issues within the application of MCDA-methods explicitly. \r\nThe prospect theory developed by Kahneman and Tversky (1979) represents one of the most prominent theories from behavioral decision theory. Their findings concerning the decision behavior of humans, e.g. loss aversion or reference dependency, are broadly supported and confirmed through a variety of empirical research. Hence, the aim this paper is to integrate these elements from prospect theory within the outranking approach PROMETHEE. For that purpose, an additional discrete reference alternative is incorporated. \r\nA case study concerning the sustainable usage of biomass for energy conversion illustrates the new developed method. \r\n", :title "Integration of Prospect Theory into the outranking approach PROMETHEE ", :keyword2 102, :authors (33450), :session 199840}, 383 {:keyword1 29, :keyword3 97, :abstract "Resource intensive industries are still responsible for a large part of greenhouse gas (GHG) emissions in Germany. While some political stakeholders call for a more restrictive climate policy to force further reductions of GHG emissions, the exceptions made for these industries increase. Currently, there exist financial reliefs of about eight billion Euros due to different taxations and free allocation of certificates to guarantee the global competitiveness of German industries. The question rises how a more restrictive climate policy would affect industrial GHG emissions and the economic situation. Contrary to many other approaches in the field of policy evaluation, the underlying actor-oriented approach of the project DECARBONISE (funded by the BMBF) focuses on the simulation of plant-specific investment decisions as well as the calculation of plant specific costs and revenues. Therefor a detailed database of the internal material and energy flows of all relevant plants together with the currently available efficiency increasing measures is developed. In the subsequent simulation, the plants, modelled as actors, decide on the implementation of these measures dependent on the GHG reduction potentials as well as on the overall economic and political conditions which can be varied in scenarios. The approach focuses on the iron and steel and the aluminum sector, whose GHG emissions represent about 7% of German's overall GHG emissions. The results show, that there are only minor reduction potentials of these industries due to already realized high efficiency standards. Thus, more restrictive climate policies only show slight additional GHG emission reductions of the German metal production but go along with a significant cost increase influencing global competitiveness.", :title "An actor-oriented approach to evaluate climate policies with regard to resource intensive industries", :keyword2 31, :authors (32246 8713 2675), :session 61}, 385 {:keyword1 8, :keyword3 157, :abstract "Given three sets, each with cardinality of n elements, and a cost function defined on triples with one element each from these sets, the axial 3-index assignment problem asks for a set of n disjoint triples such that the total cost is minimised. it is well-known that this problem is strongly NP-hard. In this work we extend the study of facial structure of the axial 3-index assignment polytope (3AP). In particular we answer a question asked in Qi, L., D. Sun (2000). By giving a new class of facet defining inequalities with right hand side 2, called wall inequalities. We obtain our results using a geometric interpretation of a valid inequality of 3AP by relating it to vertices and axes of a three-dimensional cube. We also give a polynomial time separation algorithm for the wall inequalities.\r\n", :title "Facets of the axial Three-Index Assignment Polytope", :keyword2 57, :authors (21665 6251), :session 199896}, 387 {:keyword1 8, :keyword3 160, :abstract "We investigate the class of balanced hypergraphs, a common generalization of bipartite graphs due to Berge. Based on coloring properties of these hypergraphs we present a new min-max theorem for an optimization problem closely connected to matchings and vertex covers. The result generalizes König's Theorem and Hall's Theorem for balanced hypergraphs.", :title "The Duality between Matchings and Vertex Covers in Balanced Hypergraphs", :keyword2 42, :authors (45139 45192), :session 199913}, 389 {:keyword1 103, :keyword3 101, :abstract "The link between sustainable supply chain management and dynamic capabilities has been conceptualized by Beske (2012) and operationalized by adequate policies in various industries (Beske 2013, Beske et al. 2013). In a first step, the approach of the proposed paper is to develop a causal diagram from the conceptual framework and related literature. Based on graph theory approaches, the different constructs are analyzed with regard to their importance for the coherence and interplay in sustainable supply chains. In a second step, a system dynamics model is developed from this causal diagram to assess the behavior of supply chains with regard to triggers and performance outcomes of sustainability. The system dynamics model is suitable to reflect the high complexity of different constructs and their dynamic interplay, to validate conceptual frameworks and to substantiate conclusions drawn from empirical findings. Faced with different demand fluctuations like pulses, steps and random fluctuations, preeminent loops have been detected for each scenario. These main regulation mechanisms are insuring a stable and sustainable supply chain management. At the theoretical side, this means that the model can tell us which dynamic capabilities are more suitable for different market fluctuations.\r\n\r\nBeske P (2012): Dynamic capabilities and sustainable supply chain management. IJPDLM 42 (4): 372-387.\r\nBeske P (2013): Dynamic Capabilities in Sustainable Supply Chain Management. Kassel University Press, Kassel.\r\nBeske P, Land A, Seuring S (2014): Sustainable supply chain management practices and dynamic capabilities in the food industry: A critical analysis of the literature. IJPE http://dx.doi.org/10.1016/j.ijpe.2013.12.026i\r\n", :title "Dynamic capabilities and sustainability practices in supply chain management – a causal diagram and a system dynamics model", :keyword2 102, :authors (47085 43371 43375), :session 61}, 391 {:keyword1 8, :keyword3 154, :abstract "A fundamental financial problem is budgeting. A firm is given a set of financial instruments X over a number of time periods. Every instrument has a return and for every time period a price. Further for every time period there is budget. The task is to choose a portfolio X' from X such that for every time period the prices of the portfolio do not exceed the budged and the return of the portfolio is maximized. Since the capital budgeting problem is computational intractable and is defined on inputs of various informations, we study the fixed-parameter tractability of the problem. The idea behind fixed-parameter tractability is to split the complexity into two parts - one part that depends purely on the size of the input, and one part that depends on some parameter of the problem that tends to be small in practice. We show that for the multi-period problem the number of instruments and the sum of all budgets can be chosen as a parameter such that the problem is fixed-parameter tractable. For the single-period problem additionally the threshold value of the return can be chosen as a parameter. Thus for a lot of small parameter values we obtain efficient solutions for the capital budgeting problem. We also consider the connection between these parameterized problems and approximation and pseudopolynomial algorithms.", :title "Capital Budgeting Problems: A parameterized point of view", :keyword2 35, :authors (39552 39566 45122), :session 199912}, 394 {:keyword1 94, :keyword3 98, :abstract "Linear optimization problems are investigated that have random parameters in their m constraints. In constructing a robust solution x in d-space, we control\r\nthe risk arising from violations of the constraints. This risk is measured by set-valued risk measures, which extend the usual univariate coherent distortion (= spectral) risk measures to the multivariate case. To obtain a robust solution in d variables, the linear goal function is optimized under the restrictions holding uniformly for all parameters in a d-variate uncertainty set. This set is built from uncertainty sets of the single constraints, each of which is a weighted-mean trimmed region in d-space and can be efficiently calculated. Furthermore, a possible substitution of violations between different constraints is investigated by means of the admissable set of the multivariate risk measure. In the case of no substitution, we give an exact\r\ngeometric algorithm, which possesses a worst-case polynomial complexity. We extend\r\nthe algorithm to the general substitutability case, that is, to robust polyhedral optimization. The consistency of the approach is shown for generally distributed parameters. Finally, applications of the model, especially to supervised machine learning, are discussed.", :title "A general solution for robust linear programs with distortion risk constraints", :keyword2 93, :authors (26116 22996), :session 199881}, 397 {:keyword1 92, :keyword3 100, :abstract "Current research on strategic issues in Closed-Loop Supply Chain Management typically assumes that consumers are characterized by a heterogeneous willingness to pay (WTP) for a new product which is often modeled by using a uniform distribution. In contrast to this, the value that customers assign to a remanufactured product is determined by discounting the new product price with a common factor. Thus, any heterogeneity in consumers' WTP for remanufactured products solely stems from a differing WTP for the new product. This approach typically leads to linear price/quantity relationships enhancing tractability of the resulting stylized models. However, recent empirical work indicates that consumers are quite different in their relative assessment of the quality of a remanufactured product. Our research aims at (1) assessing the impact of the assumption that consumers homogenously discount the value of remanufactured goods on the price/quantity decisions of a monopolistic producer offering both, new and remanufactured products, (2) identifying important drivers of the heterogeneity, and (3) providing a compelling model based on individual utility that can explain important drivers of the heterogeneity observed and fit the corresponding modeling parameters in an experimental study.", :title "Sources and Effects of Heterogeneous Willingness to Pay for Remanufactured Products", :keyword2 19, :authors (17039 45143 33414), :session 61}, 398 {:keyword1 165, :keyword3 0, :abstract "Introducing stochastic dominance constraints when handling risk aversion in linear programming under stochastic uncertainty leads to optimization problems with uncountably many chance constraints. Metric regularity of the constraint function is the key to stability of the optimal solution sets subject to perturbations of the underlying  probability measure. The talk is on identifying verifiable sufficient conditions for metric regularity via a local linear growth condition. ", :title "A representation of a class of stochastic dominance constraints enabling Lipschitzian properties and stability", :keyword2 0, :authors (44979 9512), :session 90}, 399 {:keyword1 75, :keyword3 0, :abstract "Based on various requirements for different horizons in production planning and control, a three-level mathematical model for lot sizing and scheduling has been developed. The requirements originate from practical problems and challenges in production control, found in small and medium enterprises in the metalworking industry. The idea is to divide the planning horizon into three different planning scopes, to cope with the requirements on an adequate level. Each scope is implemented by a suitable model based on the literature. A short-term scope includes the next few days and maps the production control of the scope to a “proportional lot sizing and scheduling” model. The medium-term scope covers several days up to more than a week and differs from the short-term scope by a larger period size and minor level of detail. It is modeled by a “continuous setup lot sizing problem”. Different from the two previous models, the long-term scope is based on a model which is not simultaneously building lot sizes and a sequence. The model extends the “capacitated lot sizing problem” using periods, the size of a whole week. The three models are combined into one major model, using the inventory constraints as synchronization. This way, consistency of already produced items and demanded items can be guaranteed. First results will be discussed in the talk.", :title "A three-level capacitated lot sizing model for production control", :keyword2 96, :authors (45009 1141), :session 199847}, 401 {:keyword1 175, :keyword3 8, :abstract "Based on a real world problem we optimize efficiency in railway transportation. \r\nGiven a set of shipment requests and predefined train schedules we assign shipments to trains in an efficient way. For our industrial partner, the Kombiverkehr GmbH & Co KG (KV), we formulate a MIP model that minimizes the number of train changes for single loading units. In a feasible transportation plan every shipment has a delivery due date that needs to be met. To be able to handle the tremendous model size for realistic instances, we combine the usage of state-of-the-art MIP solvers with tailor made techniques from the field of Combinatorial Optimization and a custom-built preprocessing. The KV provides us with real world data for that problem.\r\nAs a next step, we consider energy efficiency as well. For that purpose, the power consumption of a train between two terminals is estimated as a function of transported weight, covered distance and difference in altitude. \r\nIn cooperation with our other industrial partner, the Deutsche Bahn Mobility Logistics AG, we are working on a further extension where the predefined train schedules are not fixed anymore but train departure and arrival times can be varied within certain time intervals.\r\nThe project is part of the BMBF-supported joint research project “e-motion”.\r\n", :title "Efficient Rail Freight Transport", :keyword2 53, :authors (40519 13837), :session 199943}, 406 {:keyword1 99, :keyword3 179, :abstract "The increasing impact of electricity generation from renewable energy sources (RES-E) on energy markets in Europe and beyond, makes it more and more important to study their generation characteristics in detail. Therefore, in order to design an energy system or to make investment decisions, it is crucial to thoroughly explore the fluctuating and uncertain properties of RES-E generation.\r\n\r\nThe fluctuating character of RES-E feed-in can adequately be expressed by time series with a high temporal resolution (e.g. hours or 1/4 hours). Since there is few data on a high spatial and temporal resolution available on a European scale, many energy system analysts use historical meteorological data for their analysis and convert it to RES-E generation. However, when investigating the fluctuating character of RES-E feed-in and the linked need for flexible backup capacity, this data base might not be sufficient to draw robust conclusions. Therefore, in this work we pursue a methodology to generate an infinite volume of realistic photovoltaic feed-in data. This aims at enabling energy systems analysts to base their modelling approaches on a larger set of realistic data and thus reaching more robust and reliable results.\r\n\r\nThe purpose of this paper is to explore the possibilities of modeling the solar radiation through a stochastic process. After reviewing several stochastic models from literature, a modeling approach for solar radiation is formulated and calibrated using historical meteorological data. The generated radiation data is converted to electricity generation using a photovoltaic power plant model. Both the modeled radiation and electricity generation are evaluated and discussed with regard to their ability to simulate the RES-E’s uncertain and fluctuating character.", :title "Stochastic simulation of solar radiation in order to generate time series of photovoltaic electricity feed-in", :keyword2 165, :authors (45037 39482 33470 22954), :session 55}, 411 {:keyword1 31, :keyword3 0, :abstract "Since the seminal work of Rosen/Lazear (1981), many studies on tournaments have been conducted. We refer to the extension of Gilpatric (2005) that allows agents in tournaments to cheat (and thus to possibly gain higher payoffs) and implements incomplete monitoring. For the agents the dominant strategy is to cheat if audit probability falls below a certain value and not to cheat if audit probability is higher than another value. Based on the work of Evans (2008), who experimentally investigates how agents react to imperfect monitoring, we create an environmental framework for participants in a lab experiment: cheating is called “do not undertake necessary environmental protection measurements”. Participants are informed that doing so will harm other participants in the lab by reducing their payoffs. One third of the participants acts as principals and chooses the audit probability while the other participants are agents in a tournament and decide whether to cheat after they are informed about their principals’ decisions. We create another experiment without the tournament structure. While keeping the eco-framework and having financial incentives as identical as possible, we just remove the tournament. Agents still decide whether to cheat given an audit probability, but they do not act in a competitive environment as in the tournament. We find that principals choose significantly higher audit probabilities in the absence of the tournament structure. Furthermore, for given audit probabilities, agents decide to cheat less without the tournament. It seems that within a competitive structure such as tournaments agents less respect the environment. In addition, principals monitor more intensively, leading to smaller payoffs.", :title "The effect of competition on environmental behavior- Evidence from the lab", :keyword2 142, :authors (44984 9886), :session 65}, 414 {:keyword1 8, :keyword3 158, :abstract "We consider a generalization of the multidimensional Strip Packing Problem (SPP). In a standard d-dimensional SPP (SPP-d), a given set of boxes has to be scheduled within a strip with fixed sizes in the first d-1 dimensions and variable size in dimension d without rotating any box. The latter size is commonly denoted as height of the strip and has to be minimized such that the boxes can still be packed pairwise disjointly within the strip.\r\n \r\nIn a packing that is feasible with respect to SPP-d each scheduled box is represented as a product of d one-dimensional intervals of corresponding width. Additionally, for a given subset S of dimensions, these intervals are required to be non-overlapping in the problem considered in this talk. We also introduce some variants with further special constraints. For example, we add constraints related to gravity or related to the orientation of boxes with respect to S.\r\n\r\nFor all considered variants we derive the computational complexity, we introduce preprocessing methods based on conservative scales, i.e. on a modification of the widths of the boxes, and we present exact solution methods. For the latter, we use the concept of packing classes well known for standard SPP-d. Finally, we discuss some computational results for our implementation of the exact solution methods.", :title "Multidimensional Strip Packing with partially non-overlapping intervals", :keyword2 42, :authors (26387 13837), :session 199894}, 415 {:keyword1 40, :keyword3 0, :abstract "We consider algorithmic aspects of the classical mechanism design problem of implementing social choice functions. We show how an adaption of the well-known negative cycle criterion for weak implementability can be used to decide the question of implementability in the strong sense when one restricts to incentive compatible direct revelation mechanisms. We derive an efficient combinatorial algorithm that computes the payments of an incentive compatible direct revelation mechanism that strongly implements a given social choice function in dominant strategies or decides that none exist.\r\n  \r\nOur result complements the results obtained in the companion paper of Krumke and Thielen, where a nondeterministic polynomial time algorithm for the more general problem of deciding of strong implementability via indirect mechanisms is given. This more general problem is expected to be NP-complete.", :title "A Combinatorial Algorithm for Strong Implementation of Social Choice Functions", :keyword2 42, :authors (36955 33211), :session 30}, 418 {:keyword1 86, :keyword3 61, :abstract "The aim of resource-constrained project scheduling (RCPS) is to assign starting times to a number of jobs subject to precedence and resource constraints such that a project related objective is optimized. We present a new exact approach for the multi-mode RCPS problem (MRCPSP) with generalized precedence relations (GPR) and the objective of makespan minimization. State-of-the-art exact algorithms for the single-mode RCPSP integrate techniques from Constraint Programming (CP) and Boolean Satisfiability (SAT) solving in a Branch-and-Bound search framework. In our talk, we show how these techniques  can be generalized to the MRCPSP with GPRs. For the generalization, we implemented two new constraint handlers for the optimization framework SCIP. The latter capture constraint propagation rules for precedence and renewable resource constraints. Moreover, they process valid clauses deduced from the processed domain reductions to the SCIP-intern SAT mechanism. We introduce three mathematical models in SCIP for the MRCPSP with GPRs which integrate our new constraint handlers. The different formulations are tested with 30-, 50- and 100-job instances from the literature.\r\nOur computational experiments show, that our exact algorithm, i.e. the solution of our models with SCIP outperforms the state-of-the-art exact approach from the literature. Finally, we conclude that our approach is easily usable via SCIP and can also be applied to generalizations of the MRCPSP containing more general objective functions and resource constraints.", :title "On the efficient modeling of the multi-mode resource-constrained project scheduling problem with generalized precedence relations in the  optimization framework SCIP", :keyword2 155, :authors (31297 10538), :session 199869}, 419 {:keyword1 6, :keyword3 25, :abstract "Much research in auction design was devoted to combinatorial or package auctions, which allow for bids on packages of objects. Arguably, the first-price sealed-bid auction is the most wide-spread package auction format. However, the characterization of Bayesian Nash equilibrium strategies in the incomplete information game turned out to be hard. Initial attempts focus on a market where two local bidders compete against a global bidder. The resulting free-rider problem makes it hard for the local bidders to coordinate assuming quasi-linear utility functions. Quasi-linearity might not be the right assumption in many real-world markets. We analyze value bidders who receive their budget for certain packages from a principal, but this budget is considered sunk cost. This model describes utility functions as they can be found in ad markets or in spectrum auctions.  With value bidders coordination becomes trivial for the local and single-minded bidders. In this paper we analyze a different market with two multi-minded bidders both interested in one or two units of a single good, where the split outcome is efficient. Interestingly, the results are the opposite. We show that in a Bayesian Nash equilibrium value bidders do not coordinate and this result is independent of distributions or risk aversion. In contrast, bidders with quasi-linear utility functions coordinate to the efficient split outcome in equilibrium. ", :title "When Bidders Fail to Coordinate: First-Price Sealed-Bid Package Auctions with  Quasi-Linear and Value Bidders", :keyword2 40, :authors (45152 55333), :session 76}, 423 {:keyword1 174, :keyword3 151, :abstract "2D Rail Mounted Vehicle Scheduling with Non-Crossing Constraints\r\n\r\nIn many logistics applications several rail-mounted vehicles are used to organize a warehouse, a shipyard or a storage of goods. It is crucial for an efficient production environment to find conflict-free tours - every vehicle limits the other due to its position along the rail - minimizing the total execution time. We consider a vehicle scheduling problem (called 2DVS), where n items need to be transported on the plane using k identical vehicles. Throughout the whole process, all vehicles need to stay in their initial order along the x-axis.\r\n\r\nThe aim is to find a solution where all jobs are transported, the tours do not cross along the x-axis and the makespan is minimized. As a generalization that fits well with the practical circumstances,\r\n we consider a safety distance that has to be kept between the vehicles. \r\n\r\nOur main contribution is a model for 2DVS and some nearby variations. More specifically, we show that 2DVS is NP-hard even if we know the optimal starting times of all jobs. Both the starting times and the \r\nassignment of each job can be treated as a solution to the problem.\r\n\r\nInterestingly, the problem can be seen as k-Stacker Crane Problem (k-SCP) in a grid graph with a maximum metric as distance. We combine some well known approximation algorithms for the k-SCP to get a better approximation for the special distance function.", :title "2D Rail Mounted Vehicle Scheduling with Non-Crossing Constraints", :keyword2 109, :authors (29468), :session 199957}, 426 {:keyword1 151, :keyword3 42, :abstract "Matching and coalition formation are fundamental problems in a variety of scenarios where agents join efforts to perform tasks, such as, e.g., in scientific publishing. To allocate credit or profit stemming from a joint project, different communities use different crediting schemes in practice. A natural and widely used approach to profit distribution is equal sharing, where every member receives the same credit for a joint work. This scheme captures a natural egalitarian fairness condition when each member of a coalition is critical for success. Unfortunately, when coalitions are formed by rational agents, equal sharing can lead to high inefficiency of the resulting stable states. In this paper, we study the impact of changing profit sharing schemes in order to obtain good stable states in matching and coalition formation games. We generalize equal sharing to sharing schemes where for each coalition each player is guaranteed to receive at least an alpha-share. This way the coalition formation can stabilize on more efficient outcomes. In particular, we show a direct trade-off between efficiency and equal treatment.\r\n\r\nIf k denotes the size of the largest possible coalition, we prove an asymptotically tight bound of k^2 alpha on prices of anarchy and stability. This result extends to polynomial-time algorithms to compute good sharing schemes. Further, we show improved results for a novel class of matching problems that covers many well-studied cases, including two-sided matching and instances with integrality gap 1.", :title "Designing Profit Shares in Matching and Coalition Formation Games", :keyword2 40, :authors (41376 45057), :session 199888}, 429 {:keyword1 8, :keyword3 63, :abstract "In online optimization, an algorithm has to make decisions based on a sequence of incoming bits of information without knowledge of future inputs. The performance of an online algorithm is commonly evaluated by comparing its objective value to the optimal offline solution, also referred to as competitive analysis. Thus far, the notion of online algorithms and competitive analysis is only known for single-objective optimization problems. We transfer the concept to multiple objectives and introduce competitive analysis for multi-objective optimization problems. Due to the shift from a single optimal solution in a single-objective optimization problem to a set of efficient solutions in a multi-objective optimization problem, the transformation of the concept of competitive analysis to multiple objectives is not straightforward. \r\nIn this talk, the novel definition of multi-objective online optimization is introduced and then applied to the ski rental problem which is an analogy for the classic rent or buy problem. Imagine you are about to go skiing for the first time in your life and you are faced with the question of whether to buy skis or to rent them. If you knew how often you would go skiing in the future, the optimal decision could be calculated based on the rental and the buying costs. By the definition of a second cost component related to the comfort of buying or renting skis, the bi-objective ski rental problem is introduced. We present an optimal bi-objective online algorithm with respect to multi-objective competitive analysis.", :title "The Bi-Objective Ski Rental Problem", :keyword2 173, :authors (36513), :session 199897}, 430 {:keyword1 67, :keyword3 160, :abstract "Set-valued risk measures have been recently used to quantify risk in multi-asset financial markets with transaction costs or other frictions. In this work, it is assumed that there is an individual utility function for every asset and the set-valued shortfall risk measures are studied based on these utility functions. The value of a shortfall risk measure at a fixed random vector is defined as the solution of a certain convex set optimization problem. Using a recent Lagrange duality for set optimization, the corresponding dual problem is obtained, which gives rise to divergence risk measures - another new class of convex set-valued risk measures. The value of a divergence risk measure can be interpreted as a \"partially scalarized\" set optimization problem where one of the dual variables coming from Lagrange duality has the role of a scalarizing vector. It is shown that a shortfall risk measure can be written as an intersection, that is, a set-valued supremum, over a family of divergence risk measures. Examples of these risk measures include the set-valued versions of the entropic risk measure and average value at risk.", :title "Set-valued shortfall risk measures via Lagrange duality", :keyword2 93, :authors (45023), :session 199893}, 432 {:keyword1 164, :keyword3 33, :abstract "Given a set of machines the Double-Row Facility Layout Problem (DRFLP) asks for an arrangement of the machines along both sides of a path. The aim is to minimize the sum of the weighted transports between the machines. In contrast to the Single-Row Facility Layout Problem there may be spaces between neighboring machines in the same row. We consider here the special case of DRFLP with all machines having the same size. After a short literature review we present two different models, which are based on the idea of introducing additional dummy machines in order to model the spaces between the machines in the arrangement. The number of these additional machines is chosen such that at least one of the original optimal solutions is preserved.  Our integer linear programming model uses betweenness variables combined with variables modeling the overlap of the machines. A quadratic program in ordering variables is the basis for a semidefinite programming model, whose relaxation is solved with a spectral bundle method. Computational tests show that for medium- to large-sized instances the SDP approach clearly beats the ILP approach regarding the strength of the lower bounds after one hour of computing time.  ", :title "Models for the Double-Row Equidistant Facility Layout Problem", :keyword2 8, :authors (26471 3287 30955), :session 199918}, 438 {:keyword1 7, :keyword3 97, :abstract "Combined heat and power (CHP) plants generate heat and power simultaneously leading to a higher efficiency than an isolated production. CHP unit commitment requires a complex operation planning, since power is consumed in the moment of generation. The integration of heat storage might be efficient, as heat generation is decoupled from demand. This allows a partially power price oriented plant operation, where power is generated especially in times of high market prices. Therefore, the short-term development of the power market has to be anticipated. Consequently, an efficient plant operation depends to a great extent on the accuracy of the anticipated power prices and the flexibility due to the respective storage capacity. \r\nThis contribution analyzes the effects of short-term uncertainties in the power price on the CHP unit commitment for different heat storage capacities. An extensive Monte Carlo Simulation is run in order to determine the financial consequences of inaccurate power price anticipation. The study shows that the storage capacity affects the sensitivity of the solution due to stochastic influences. Since a higher storage capacity increases the flexibility in the unit commitment, the CHP plant operation is able to react faster on inaccurately anticipated power prices. Thus, high storage capacities go along with robust solutions concerning the financial consequences due to uncertain power prices. The consideration of only long-term uncertainties might result in an underestimation of heat storage capacity. It is recommended to additionally integrate short-term uncertainties in models for strategic planning of heat storage capacity.\r\n", :title "Impact of heat storage capacity on CHP unit commitment under power price uncertainties", :keyword2 29, :authors (39462 10057), :session 199927}, 439 {:keyword1 39, :keyword3 86, :abstract "In the scientific literature no comprehensive approach can be found for scheduling in project management that takes into account vagueness of non-stochastic origin, which means that no approach exists starting with modeling, proceeding with scheduling, and finishing with evaluating and interpreting the results taking into account in a systematic way the effects of vagueness of non-stochastic origin. The aim of the PhD-thesis of the author, which is currently in progress, is to show that such a comprehensive approach is feasible, and more importantly, the usefulness of such an approach for handling real-life problems will be demonstrated by means of a realistic practical example. In this talk we will present the starting point, the goals, and the methods of this work. To a large extent the methods are based on Fuzzy Theory, whose main aim is to handle vagueness in a mathematically precise way.", :title "Vagueness-enabled Scheduling in project management", :keyword2 18, :authors (5454), :session 15}, 440 {:keyword1 57, :keyword3 162, :abstract "We present the new features and performance improvements included in the latest release of the SCIP Optimization Suite. The Optimization Suite consists of the constraint integer programming toolkit SCIP and ships with the LP solver SoPlex and the modeling language ZIMPL. It also contains the parallelization framework UG and the column generation extension GCG.\r\n\r\nWe report on our new interfaces to Python and Java and also on our rewritten internal interface between SCIP and SoPlex, which allows for better control over the LP solver.\r\n\r\nMore information and downloadable libraries, binaries as well as source code packages can be found at scip.zib.de.", :title "SCIP Optimization Suite 3.1", :keyword2 158, :authors (32758), :session 79}, 441 {:keyword1 16, :keyword3 0, :abstract "We present an algorithm for the two-dimensional SPP that improves the packing of the FFDH heuristic and state theoretical results of this algorithm. We also present an implementation of the FFDH heuristic\r\nfor the three-dimensional case, which is used to construct a new\r\nalgorithm\r\nwith absolute performance ratio of at most 5.\r\nBased on this algorithm,\r\nwe prove a general upper bound\r\nfor the optimal height,\r\nwhich depends on the continuous lower bound and the maximum height lower bound, and show that the combination of both lower bounds also has an absolute worst case performance ratio of at most 5.", :title "Upper Bounds for Heuristic Approaches to the Strip Packing Problem", :keyword2 0, :authors (42140 16923), :session 199894}, 442 {:keyword1 18, :keyword3 175, :abstract "Resulting from an increase of shipment quantities many logistics facilities such as terminals and distribution centers often reach the limit of their performance ability and thus become a bottleneck in supply-chains. Our research focuses on less than truckload (LTL) forwarding companies providing a pick-up and delivery service within a local area. Whereas delivery orders are already known before tour start, about 50% of daily pick-up orders will be added during the day, at the time the trucks are on tour. This dynamic vehicle route planning has a large impact on the internal processes of the transshipment facility and thus to in-house resource requirements. The daily decisions about which trucks to use, which vehicle routing to plan and how to organize the transshipment in the terminal reach their limits with static methods since the freight forwarding business becomes more dynamic and unknown customer orders are not considered. The objectives of our research are the development of robust route planning methods, unknown customer orders, the dynamic dispatching of incoming pick ups, the integration of varying driving times as well as testing our methods on real world data. Based on expected pick ups a variety of feasible, probable scenarios are generated. Subsequently an initial heuristic is used for our tours and an evolutionary algorithm improves each solution. The parallel computed solutions are then combined to achieve an efficient and robust solution. On the basis of real data sets with about 100 vehicles and 1,000 stops per day the portability will be shown on usual problem instances.", :title "Robust vehicle routing as an impact on LTL terminals", :keyword2 174, :authors (26516 26657 37090), :session 50}, 443 {:keyword1 94, :keyword3 42, :abstract "We investigate a special case of the job shop problem where there is uncertainty about whether an operation actually occurs and needs to be scheduled. Specifically, we model a job shop problem with perfect information about all processing times, precedence relations, and resource consumption but with a set of operations that might or might not occur - so called variable operations. The total number of variable operations that will indeed occur is limited by a parameter K. This type of problem arises in a simplified environment of a hospital patient scheduling problem. \r\nKnowing that at most K variable operations will occur, one wants to come up with a stable schedule. We propose a recoverable robust model with two stages: in a first stage we fix the order of operations sharing the same machine. After the occurrence of at most K variable operations, we compute in a second phase the start times of each operation. Since we want to minimize the sum of the worst-case completion times, this sums up to a nonlinear min-max-min optimization problem. \r\nIn this talk, we present a branch and bound algorithm to solve this recoverable robust scheduling problem. Upper bounds on the nodes and branching rules are based on an budgeted max cost flow problem on acyclic graphs.", :title "Robust job shop scheduling problem with uncertain operations", :keyword2 96, :authors (39494 17092 29344), :session 199880}, 444 {:keyword1 175, :keyword3 18, :abstract "The railway system is vulnerable to external disturbances which interrupt the regular operation and cause delays. These delays can propagate through a larger part of the railway network if a train dispatcher does not quickly reschedule the operation. Train dispatching is currently performed by hand. Most dispatchers rely on their experience and simple dispatching rules when they deal with disturbances. The usage of optimization methods could result in a significant reduction of delays and energy consumption. This paper presents OptDis, a novel method for solving the important dispatching problem of detecting and resolving occupation conflicts. These conflicts arise when two trains attempt to occupy the same infrastructure at the same time. OptDis assists dispatchers by resolving conflicts using a mixed-integer linear programming approach. The real-world feasibility of the solutions found by OptDis is ensured by a detailed consideration of minimum running times and of the interlocking system. The newly developed simulation tool LUKS-D is used to evaluate OptDis. This tool performs simulations which are much closer to the real-world operation than previous approaches. An experiment is presented which simulates the region around Bern, a real-world dispatching area from Switzerland.", :title "Real-Time Train Dispatching Using Mixed-Integer Linear Programming", :keyword2 158, :authors (31977), :session 199944}, 445 {:keyword1 96, :keyword3 157, :abstract "The Job-Shop Scheduling Problem is widely studied for the makespan objective. In recent years there has also been research on exact solution approaches and lower bounds to the job shop problem with min-sum criteria (e.g. Lancia et al., 2011; Baptiste et al., 2008). We propose a new solution approach for the job shop problem minimizing the sum of completion times. In our approach we bring together several ideas of recent research. First we adapt the arc-time indexed formulation of Pessoa et al. (2010) to the jobshop problem. In this formulation a machine schedule is represented by a path through a network. Therefore we have a flow formulation with side constraints. We solve this problem with row and column generation (e.g. Sadykov and Vanderbeck, 2011). That means we generate machine schedules for a single machine in the pricing procedure and add the corresponding arcs to the arc time indexed master problem formulation. This approach has the advantage that machine schedules can be recombined in the masterproblem and we need to solve potentially less pricing problems. The proposed formulation can be further strengthened by adding precedence cuts (Christofides et al., 1987). First computational tests yield promising results in terms of lower bounds and running times.", :title "Row-and-Column Generation for the Jobshop Scheduling Problem with min-sum Objective", :keyword2 150, :authors (29344 45158 14969), :session 199876}, 447 {:keyword1 174, :keyword3 158, :abstract "We study a generalization of the vehicle routing problem with time windows: Instead of vehicles with a conventional combustion engine we consider electric vehicles which usually have a strictly limited range. We assume, that these vehicles might not be able to complete their tour with a single battery charge and thus would have to visit one or more recharging stations.\r\nGiven is a graph with a depot, a set of clients, and a set of recharging stations. Each client has a strictly positive demand and a time window in which it has to be visited. The vehicles are able to recharge their battery's state of charge (SOC) by a fixed amount of energy per time unit. A network arc is defined by its travel cost and time. Further, a vehicle consumes a particular amount of energy on each arc which depends on the arc length, its empty weight and linearly on the weight of the currently loaded goods. This amount can be negative if the vehicle is able to recover energy on a downward slope. The fleet is homogeneous with fixed load and SOC limits.\r\nThe objective is to find a set of routes with minimal total costs such that each route starts and ends at the depot, each client is visited exactly once within its time window, the total demand of all clients on a route must not exceed the load capacity, and the SOC stays within its limits. Recharging stations may be visited as often and as long as necessary.\r\nSchneider et al. (2012) introduced a variant of this problem with strictly positive and load independent energy consumption per arc. At a recharging station the SOC of a vehicle is always recovered to its maximum. We consider the more practical setting defined above and present mixed integer linear programming formulations and corresponding branch-and-cut methods to solve them.", :title "The Electric Vehicle Routing Problem with Time Windows and Load-Dependent Energy Consumption", :keyword2 8, :authors (26409 22160 5319), :session 5}, 448 {:keyword1 44, :keyword3 141, :abstract "This paper addresses the question of the effect of fair / unfair promotion on the willingness to cooperate within a group, using an extended version of the classic dictator game. To investigate the research question at hand, a laboratory experiment is conducted. A 2x2 research design is used. During the experiment, the two members of each group will be assigned the role of a superior (promoted group member) and a subordinate (responder). We manipulate two factors: Fair and unfair promotion as well as the possibility for the subordinate to punish her superior. The promotion depends on the result of a real effort task. In the unfair setting, subjects with a higher score in the task get the less favorable position in the dictator game, the role of the responder. In consequence, the unfair promotion should not be attributed to the superior. It is analyzed how fairness of the promotion influences the heights of the offer. In addition to the dictator game we enable the responder to react to the offer by punishing the superior. \r\nThe treatments with fair promotion rules (including punishment or not) are supposed to serve as the basis for comparison. The results are compared to the unfair promotion treatments. Because of indirect reciprocity concerns, we expect the superior to make higher offers in comparison to the control treatment. On the other hand, subordinates punish more when they believe that they would have “earned” the position of the superior if unfairness is not “compensated” by the superior. The results have implications for promotion decisions and the subsequent interaction within hierarchical groups.\r\n", :title "Favoritism and indirect Reciprocity in Hierarchical Relationships", :keyword2 19, :authors (45159 41267 1658), :session 199964}, 450 {:keyword1 59, :keyword3 0, :abstract "The production of perishable products such as dairy products includes several specific aspects concerning product durability and production procedures. The production of different dairy goods within a plant requires coordination of the product flow across different production levels (e.g., soaking, heating, fermentation, cooling, filling). Usually the lot-sizing problem and the detailed sequencing and scheduling problem are treated separately in the production planning process. By considering these two problems simultaneously in a realistic model formulation we aim to improve the overall performance of the entire production process. For this purpose we extended the Position-Based Model introduced by Lütke-Entrup et al. (2005). The extensions include explicit product transfers via product pipes (i.e., pipes are used to transfer products between aggregates; no two transfers can be performed at the same time), product-dependent durability during the production process (e.g., after fermentation the product has to be chilled within a certain time limit), cleaning and sterilization pipes which prevent simultaneous treatment of specific aggregates, maximum and minimum capacity of aggregates, sequence-dependent setup times, product loss caused by transfers, a product specific production speed for each aggregate, and cleaning intervals (i.e., the time between two consecutive cleaning procedures is limited). Based on a set of real-world production data, we used our model to determine exact solutions to very small problem settings. As even for small instances the time required for obtaining exact solutions is too long for practical use cases, we developed an innovative metaheuristic solution approach based on the concept of adaptive large neighborhood search for this problem.", :title "A metaheuristic solution approach for a rich lot-sizing and scheduling model", :keyword2 8, :authors (23282 45160 45068 2769), :session 199848}, 451 {:keyword1 2, :keyword3 0, :abstract "This paper presents a two-stage mixed integer programming approach for optimizing the skill mix and training schedule at an aircraft maintenance company. In this study, we only focus on the line maintenance which takes place at the gate or parking ramp between the arrival and departure of an aircraft. Since different aircraft have different features and can show different problems, only adequately skilled workers should be assigned to maintain certain flights. Hence, a good personnel schedule should make sure that all flights can be maintained in time with the available workers and their respective skills.\r\n\r\nWhile a higher skilled workforce increases flexibility and can lead to cheaper schedules, the required training can become very expensive. The first step is therefore to make a trade-off between cheaper rosters that require higher skilled workers and the training costs to obtain this higher skilled workforce. The second step is to design an optimal training schedule to obtain the optimal skill mix with minimal costs. This second model determines the exact timing of the training for each worker and takes into account that a worker is unavailable to work during his training periods.\r\n\r\nWe illustrate our approach with a computational experiment based on real life data of Sabena Technics, a large aircraft maintenance company located at Brussels Airport in Belgium. Experiments first demonstrate that our models succeed in finding low cost schedules in reasonable time. Second, we illustrate the benefits of training by comparing a scenario without training to a scenario with training. The results show how our approach can make a good trade-off between cheaper rosters that require higher skilled workers and the training costs to obtain this higher skilled workforce.\r\n", :title "A two-stage mixed integer programming approach for optimizing the skill mix and training schedules for aircraft maintenance", :keyword2 158, :authors (43680 2987 36408 41246), :session 199872}, 452 {:keyword1 134, :keyword3 0, :abstract "The price of anarchy measures the costs to society due to the selfishness of players. More formally, it is a lower bound on the quality of any Nash equilibrium relative to the quality of the global optimum. However, in particular games some Nash equilibria are not realistic, therefore the price of anarchy gives an overly pessimistic view. Instead of assuming that all players choose their strategies simultaneously, we consider games where players choose their strategies sequentially. The sequential price of anarchy is then a lower bound on the quality of any subgame perfect equilibrium of such a game relative to the quality of the global optimum.\r\n This idea was introduced in a recent paper by Paes Leme, Syrgkanis, and Tardos, where they indeed give examples where sequential decision making leads to better equilibria. We review some of their results, touch upon our own results for a throughput scheduling problem, and discuss some of our ongoing work on linear congestion games.\r\n", :title "The Sequential Price of Anarchy", :keyword2 40, :authors (45162 1019), :session 33}, 453 {:keyword1 8, :keyword3 53, :abstract "Wir betrachten in diesem Vortrag nicht-lineare kontinuierlich Funktionen, die auf strukturierten Gittern definiert sind. Zur Auswertung der Jacobi-Matrix solcher Funktionen werden üblicherweise Techniken verwendet, die auf Graphmodellen und deren diskreten Optimierung basieren. Der Vortrag skizziert neue Techniken aus diesem Umfeld.", :title "Neue Entwicklungen zur Auswertung von Jacobi-Matrizen auf Gittern", :keyword2 14, :authors (45163), :session 199959}, 457 {:keyword1 158, :keyword3 0, :abstract "In various industrial applications, one is encountered with a multi-stage optimization problem. This is in particular the case when a problem is formulated over a time horizon - as, e.g., lot sizing problems or resource allocation problems.\r\n\r\nWhen such a problem is formulated as a MIP, its coefficient matrix then has a so-called staircase structure, i.e. it breaks down into subsequent, pairwise connected blocks. In the recent past, we have managed to find a staircase structure in an arbitrary MIP - even if it is not a priori known to be a multi-stage problem.\r\n\r\nBesides exact algorithms, heuristic algorithms have been devised for multi-stage problems. Such heuristics are e.g. the rolling horizon or the fix-and-relax heuristic.\r\n\r\nWe apply generic versions of these heuristics on general MIPs from the MIPLIB2010 library as well as on instances of multi-stage problems from the literature. In particular, we compare them against classical generic MIP heuristics and investigate whether the knowledge of a structure is of any advantage when searching for feasible solutions.\r\n\r\nOn the other hand, we also exploit staircase structures in generic MIP heuristics, in particular diving heuristics. Diving heuristics iteratively branch on a variable and solve the resulting LP. In our diving heuristics, the blocks of the MIP (which, depending on the problem, may be interpreted as time steps) are taken into account when selecting variables. We give a comparison between block-wise diving heuristics and classical ones.\r\n\r\nPreliminary results show that our heuristics are successful on multi-stage problems from the literature as well as on generic MIPs.", :title "Primal Heuristics for Multi-Stage Mixed Integer Programs", :keyword2 0, :authors (29257 14969), :session 46}, 460 {:keyword1 27, :keyword3 174, :abstract "The Logistics Algorithms Visualization and Education Software (LAVES) is an open source project at the University of Siegen, aiming at supporting non-mathematics and non-informatics (bachelor-level) students in understanding the basic concepts of algorithms that are applied to solve problems arising in Operations Research, especially in logistics, by means of visualization. It allows students to create problem instances click-by-click with direct graphical feedback, offers a set of algorithm related controls, presents execution-table views as used by the students when manually processing algorithms, depicts and highlights related pseudocode (including LaTeX formulas), and includes an exercise-mode. LAVES is accompanied by a Development Kit (LAVES-DK) that allows instructors (with Java knowledge) to implement course-specific algorithm visualizations (called plugins) to be used with LAVES. The DK is generic and provides a broad range of tools. We will present the basic features of LAVES and LAVES-DK and report on first classroom experiences and student feedback.", :title "LAVES: A(nother) Software for Supporting Students by Visualizing Algorithms", :keyword2 98, :authors (29563 45167), :session 89890}, 462 {:keyword1 66, :keyword3 126, :abstract "We study a semismooth Newton method for differential\r\nvariational inequalities (DVIs). Such problems comprise the solution of\r\n an ODE and a variational inequality (VI) and have \r\nvarious applications e.g. as differental games in economic sciences.\r\nThe method we propose is based on a suitable time discretization \r\nscheme of the underlying ODE and a reformulation of the resulting\r\nfinite dimensional problem as a system of nonlinear, nonsmooth equations. \r\nWe will theoretically analyze the resulting method \r\n and finish with some numerical results.", :title "Newton-type methods for Differential Variational Inequalities", :keyword2 40, :authors (35439), :session 7}, 464 {:keyword1 42, :keyword3 0, :abstract "The baggage handling system at Frankfurt Airport distributes up to 110.000 bags per day using its over 80 km long rail tracks. During the last years the baggage handling system has been extended and new requirements have been implemented, e.g. robust routing in case of disturbances and balancing constraints for the early baggage storage system based on prognosis data. This talk describes how OR helped us to succeed in this complex project focussing on the technical details.", :title "How OR Improves The Baggage Handling System At Frankfurt Airport - The Technical Details", :keyword2 7, :authors (33333 45168), :session 199899}, 465 {:keyword1 176, :keyword3 0, :abstract "Given an n-vector p of processing times of jobs, the single machine scheduling polytope C arises as the convex hull of completion times of jobs when these are scheduled without idle time on a single machine. Given a point x in C, Carathéodory's theorem implies that x can be written as convex combination of at most n vertices of C. We show that this convex combination can be computed from x and p in time O(n^2), which is linear in the naive encoding of the output. We obtain this result using essentially two ingredients. First, we build on the fact that the scheduling polytope is a zonotope. Therefore, all of its faces are centrally symmetric. Second, instead of C, we consider the polytope Q of half times and its barycentric subdivision. We show that the subpolytopes of this barycentric subdivison of Q have a simple, linear description. The final decomposition algorithm is in fact an implementation of an algorithm proposed by Grötschel, Lovász, and Schrijver applied to one of these subpolytopes.", :title "Decomposition Algorithm for the Single Machine Scheduling Polytope", :keyword2 96, :authors (29289 1019), :session 93}, 466 {:keyword1 157, :keyword3 0, :abstract "Pickup and delivery problems (PDP) are an important class of VRP and it aims to find good tours for vehicles both pickup and delivery operations. PDP can be classified into 3 groups, basically. 1-1 (one to one), M-M (many to many) and 1-M-1 (one to many to one). 1-1 means each commodity has only one supply and one demand point. M-M means there can be more than one supply and demand points for any commodity. 1-M-1 means some commodities at depot are delivered to demand points and some commodities at customers are delivered to depot. Additionally, it can be defined a new problem that more than one supply and demand points for each commodity occur and every node in the network acts like a depot. Since these problems are NP-hard, obtaining an optimal solution in a reasonable time is not easy. In this study, integer models are offered for 1-1 and 1-M-1 type PDP so as to energy minimizing and it is shown on small scale test instances that the models can find the optimal solution. Additionally, a new problem for PDP is defined and its model is discussed.", :title "A New Approach for Pickup and Delivery Problem", :keyword2 174, :authors (3614 45501), :session 199957}, 473 {:keyword1 61, :keyword3 48, :abstract "Laser cutting is a thermal separation process widely used in shaping and contour cutting applications. It has the advantage over conventional cutting techniques that it is a very fast and at the same time very accurate technology with the optical tool laser not being exposed to any wear. There are, however, gaps in understanding the dynamics of the process, especially with regard to issues related to cut quality. Modeling and simulation of the laser cutting process -although quite demanding in computational resources- has shown to improve that understanding without the need for executing a lot of experiments in the real world.  \r\nThe simulation itself is characterized by a high dimensional input parameter set. Each parameter has its own range, and thus they are together forming the parameter domain space. The quality criteria, which are predicted with the numerical model, are analyzed together with the parameter domain space and are thus used to optimize the process. However, simulation results can only help in the build-up of process understanding, if they can be presented in their entirety and together with their origin in the parameter domain. \r\nIn this paper an approach is shown for the support of experts in the special application field of laser cutting. Furthermore, the approach’s basic principles can be transferred to any application domain, in which process maps can be useful to gather process knowledge. The paper describes feasible and suitable methods for this purpose. It also presents the validation of these methods with the help of a web application.  This web application considers the integration of simulation data as well as their suitable visualization.  The paper discusses the current approach and gives an outlook for the future work.", :title "Virtual Production Intelligence Providing Analytics in Laser Cutting ", :keyword2 153, :authors (45058 45170 45171), :session 199851}, 478 {:keyword1 175, :keyword3 100, :abstract "According to the International Organization of Motor Vehicle Manufacturers (OICA), more than 15 million new vehicles were sold or registered in Europe in 2013. The majority of these vehicles needs to be transported from plant to dealership,which imposes large logistic challenges for the manufacturers. We introduce two transportation problems that arise in the area of finished vehicle logistics and propose algorithms how to solve them.\r\n\r\nOn a strategic level, a manufacturer needs to negotiate contracts both for transportation and yard services. Any selection of contracts must consider capacity constraints as well as constraints on minimal usage and mutual exclusion of contracts. The selected contracts will usually be used as the default transport network for  most of the vehicles for at least the next year. Due to the large amount of transported vehicles, possible savings from optimized networks are huge.\r\n\r\nOn an tactical level, a detailed routing for the next weeks needs to be computed based on the default network. However, time tables of vessels and trains as well as unexpected disruptions of the transport network can result in bottlenecks that render the regular transport paths invalid. Among a set of alternative routes,  a cost effective alternative that still delivers the vehicles in time has to be computed. \r\n\r\nWe present similar exact approaches for these problems that were developed at INFORM and are used successfully by large manufacturers. We also emphasize on how changing requirements can be considered in the development of such algorithms, a key requirement in a modern software development process.", :title "Network Design and Transport Planning in Finished Vehicle Logistics", :keyword2 158, :authors (45156), :session 199945}, 481 {:keyword1 175, :keyword3 153, :abstract "Nowadays, freight carriers are often confronted with customers demanding for quick execution of their transportation requests. Depending on this need, some new transportation requests could appear during the current planning interval. Especially for Small and Mid-size Carriers (SMCs), it is difficult to deal with the uncertainness pertinent to dynamic situations. In this context, SMCs may find a possibility to increase their transportation efficiency by joining or even establishing a horizontal collaboration within a carrier coalition for freight exchange. For such coalitions, mechanisms of the Dynamic Collaborative Transportation Planning Problems (DCTPP) have to be developed in order to conquer the uncertainness of dynamic situations in collaborative scenarios. In this paper a new heuristic approach, using an Adaptive Large Neighborhood Search, for a multi-vehicle version of the DCTPP is introduced. This framework organizes the collaboration process of some independent SMCs by a stepwise request exchange mechanism. All dynamic aspects are viewed by a periodic re-optimization strategy within a rolling horizon planning. One of the main barriers for the establishment of collaborations is the carrier-fear for abandoning their independence. To guarantee a still existing autonomy in our framework, each coalition member decides on its own which of its requests are offered for freight exchange. In a computational study it is analyzed which heuristic strategies are most suitable for selecting those collaborative requests.", :title "Pre-selection Strategies for Dynamic Collaborative Transportation Planning Problems", :keyword2 95, :authors (45165 15277), :session 199942}, 482 {:keyword1 19, :keyword3 0, :abstract "A central theme in computational social choice is to study the extent to which voting systems computationally resist manipulative attacks seeking to influence the outcome of elections, such as manipulation (i.e., strategic voting), control, and bribery.\r\nBucklin and fallback voting are among the voting systems with the broadest resistance (i.e., NP-hardness) to control attacks. However, only little is known about their behavior regarding manipulation and bribery attacks. We comprehensively investigate the computational resistance of Bucklin and fallback voting for many of the common manipulation and bribery scenarios; we also complement our discussion by considering several campaign management problems for Bucklin and fallback and by giving a survey of known results for Schulze, cup, and Copeland. \r\n\r\nRelatedly, the margin of victory is a critical measure for the robustness of voting systems in terms of changing election outcomes due to errors in the ballots or fraud in using electronic voting machines. Applications include risk-limiting post-election audits so as to restore the trust in the correctness of election outcomes.\r\nContinuing the work of Xia, we show that the margin of victory problem is NP-complete for Schulze and cup elections. We also consider the exact variant of this problem, which we show to be complete for DP, the second level of the boolean hierarchy over NP, in Schulze, cup, and Copeland elections.\r\n\r\nThis paper is based on the work presented in the extended abstract that is to appear in the proceedings of the Thirteenth International Conference on Autonomous Agents and Multiagent Systems, May 2014, and on as yet unpublished results by the authors.", :title "The Complexity of Manipulation, Bribery, Campaign Management, and Margin of Victory in Schulze, Copeland, Cup, Bucklin, and Fallback Voting", :keyword2 154, :authors (44437 45186 45199 45175), :session 67}, 483 {:keyword1 88, :keyword3 0, :abstract "We present a method to determine the exact  inter-departure, inter-start and cycle time of closed queueing networks that can be modeled as Continuous-Time Markov Chains with finite state space. The method is based on extending the state space to determine the transitions that lead to a departure or an arrival of a part on a station. Once these transitions are identified and represented in an indicator matrix, a first passage time analysis is utilized to determine the exact distributions of the inter-departure, inter-\r\nstart, and cycle time. In order to illustrate the methodology, we consider closed-loop production lines with\r\nphase-type service time distributions and finite buffers. We discuss the methodology to generate the state space and to obtain the transition rate matrices for the considered distributions automatically. We use the proposed method to analyze the effects of system parameters on the inter-departure, inter-start time, and cycle time distributions numerically for various cases. The generality of the methodology allows an analysis of the inter-departure, inter-start, and cycle time distributions of a wide range of production systems including open queueing networks that can be modeled as Continuous-Time Markov Chains in a unified way.", :title "Inter-departure, Inter-start, and Cycle Time Distribution of Closed Queueing Networks", :keyword2 99, :authors (29197 2832), :session 199845}, 484 {:keyword1 40, :keyword3 0, :abstract "Path-disruption games, introduced by Bachrach and Porat, are coalitional games played on graphs where one or multiple adversaries each seeks to reach a given target vertex from a given source vertex, while a coalition of agents seeks to prevent that from happening by blocking every path from the source to the target for each adversary.  Inspired by bribery in voting, we introduce the notion of bribery for path-disruption games.  Here, the adversary breaks into the setting and tries to change the outcome to her advantage by paying a certain amount of money, without exceeding a given budget.  Now that the agents collaborate while, at the same time, they want to win against their adversary who can actively interfere with the situation in order to achieve her individual goals in opposition to the agents, the game combines aspects of both cooperative and noncooperative game theory.  We analyze the complexity of the problem of whether the adversaries can bribe some of the agents such that no coalition will form that prevents the adversaries from reaching their targets.  We show that this problem is NP-complete for a single adversary and complete for the second level of the polynomial hierarchy for the case of multiple adversaries.  Furthermore, we expand the model of path-disruption game by allowing uncertainty about the target vertices.  The agents do not know for sure where the adversary is heading to and which paths to block.  Rather, every vertex is a potential target the adversary seeks to reach with a certain given probability.  We study the complexity of problems related to common solution concepts and other properties of such games.", :title "Path-Disruption Games: Bribery and a Probabilistic Model", :keyword2 154, :authors (45176 44437 45326), :session 67}, 485 {:keyword1 28, :keyword3 57, :abstract "In Germany, the aggressive expansion of wind and solar power is decreasing power prices and eroding the viability of conventional electricity generation units of established utilities. The intermittency of renewables and insufficient transmission capacity from the windy north to the energy-intensive south has increased the need for grid congestion management (BMWi (2012)). Low operating hours have lead to threats to decommission fast-adjusting conventional plants, which poses risks for the security of supply and grid stability. As a response, the transmission system operator, TenneT, and the Federal Network Agency, Bundesnetzagentur, have agreed to compensate costs of two plants in Bavaria (Tennet (2013)).\r\n\r\nAs a long-term solution, BMWi (2013) has proposed a central capacity market. We build a complementarity model to investigate this market and to determine optimal compensations to conventional generators. Specifically, we recast the sequential model in Kunz (2013) as a bi-level optimisation model in which the day-ahead market decision are taken at the upper level and congestion management decisions at the lower level, guided by the upper level compensation decisions that the regulator takes in order to minimize the total generation costs.\r\n\r\nWe calibrate the model to the German power system and identify the congested parts of the transmission network: this gives insights about the geographical distribution of capacity payments under different demand and renewable energy scenarios. We also extend the model to multiple time periods to show how capacity payments create incentives to dispatch flexible units and thus mitigate the impacts of intermittent renewables. Our framework can be modified to study the impacts of other policy measures such as higher CO2 prices.", :title "How Much is Enough? Optimal Capacity Payments in a Renewable-Rich Power System", :keyword2 29, :authors (45177 32222 2268), :session 199928}, 487 {:keyword1 171, :keyword3 12, :abstract "A Loss of Heterozygosity (LOH) event occurs when, by the laws of Mendelian inheritance, an individual should be heterozygote at a given site but, due to a deletion polymorphism, is not. Deletions play an important role in human disease and their detection could provide fundamental insights for the development of new diagnostics and treatments. In this article we investigate the Parsimonious Loss of Heterozygosity Problem (PLOHP), i.e., the problem of partitioning suspected polymorphisms from a set of individuals into a minimum number of deletion areas. \r\n\r\nWe focused our attention in the article [1] that provide a state-of-the art integer programming formulation able to solve instances of the PLOHP containing up to 9000 individuals and 3000 SNPs.\r\n\r\nIn the article [1], the authors show that the PLOHP can be formulated as a specific version of the clique partition problem in a particular class of graphs called undirected catch-point interval graphs and they prove its general NP-hardness. \r\n\r\nIn order to tackle this problem, we investigate the possibility to use column generation techniques, together with the use of graph decomposition methods and divide and conquer techniques in order to improve the solution time of one of the model provided in [1].\r\n\r\nAs first result of our experiment we can say that column generation techniques and preprocessing methods provided a considerable reduction of the computational demand to solve the problem. In particular no branches are necessary in the column generation process for the analysed datasets.\r\n\r\n[1] An Integer Programming Formulation of the Parsimonious Loss of Heterozygosity Problem. Daniele Catanzaro, Martine Labbé, and Bjarni Halldorsson, IEEE/ACM Trans Comput Biol Bioinform, 2012", :title "A column generation approach to the Parsimonious Loss of Heterozygosity Problem", :keyword2 8, :authors (26549), :session 199919}, 488 {:keyword1 48, :keyword3 0, :abstract "We consider a German potash underground mine where crude salt is mined using a room and pillar mining method. The excavation is based on conventional drilling and blasting techniques. This kind of underground mining is characterized by different consecutive production steps (operations) such as filling blast holes with explosive substance or loading broken material. Each production step requires one trackless machine (from a set of heterogeneous machines) and a mine worker who has the corresponding skill.\r\nThe daily workforce scheduling problem forms the bottom level of a hierarchical planning approach. In order to generate reasonable shift schedules, the overlying planning levels provide input data concerning which amount has to be mined per shift/day and which parts of the mine should be excavated with higher priority. Therefore, our problem consists of specifying the assignment and scheduling of the planned operations to the resources, i.e., miners and machines that are available in the respective shift. \r\nDue to a variety of practical requirements, even small instances could not be solved to optimality within reasonable computation time. For this reason, we develop a problem specific construction heuristic that is already embedded into the IT structure of our industrial partner. We exemplify our solution approach by scheduling a real-world shift.", :title "Combined staff and machine shift scheduling in a German potash underground mine", :keyword2 86, :authors (26121 5965), :session 199871}, 490 {:keyword1 158, :keyword3 98, :abstract "Log files for optimization solvers can sometimes be confusing: columns of numbers, some increasing and some decreasing, with few words to explain their meanings. We will show you how to pull useful information out of a Gurobi log file.  We'll talk about what is happening behind the scenes and provide hints on how a Gurobi log file can help you to improve solver performance.\r\n\r\nExamining log files often leads to useful parameter changes.  Default parameter values are chosen to be efficient on average. They work well across a broad set of models, but not on all models. We will present some examples where analyzing the solver output and changing a small number of parameters helped to reduce the solving time significantly. Additionally, we give a brief introduction to Gurobi’s Tuning Tool and explain the meanings of the different parameter changes it suggests.", :title "What you can learn from a Gurobi log file", :keyword2 153, :authors (45074), :session 199884}, 491 {:keyword1 124, :keyword3 0, :abstract "Bayesian networks (BNs) represent relations of conditional independence between random variables. Learning BNs from data (big or otherwise) is an important task that is known to be NP-hard in general. By casting BN learning as constrained optimisation, (constraint) integer programming (CIP) has been used to attack the problem - in our own work via the SCIP framework. In this talk I will talk on what has been achieved by taking this approach and what remains to be done.\r\n\r\nAn important advantage of using CIP is that it facilitates a 'declarative' approach to machine learning where the user need only declare the data and prior knowledge and the solver/developer has the job of finding an optimal BN given that information. I will discuss recent work where this has been exploited to find optimal sets of related BNs.", :title "Bayesian network learning using integer programming", :keyword2 157, :authors (45185), :session 199867}, 492 {:keyword1 23, :keyword3 25, :abstract "Heat pumps provide the possibility to use renewable electricity for heating purposes and at the same time offer flexibility for the usage of intermittent renewable supply through thermal storage. Yet the economically optimized operation in a smart grid environment has so far not been investigated in detail. On the one hand, heat pump owners may operate it at substantially decreased costs by making use of periods of low market prices for electricity. On the other hand, grid operators may benefit from such type of operation through shaving off the demand peaks or avoiding grid overloads due to the fluctuating supply of electricity from renewable sources.\r\nThis contribution analyzes the optimal control strategy for a heat pump including thermal storage. It notably investigates the heat costs saving potential of a typical household being heated by a standard air-water heat pump. The thermodynamic system is modelled by a simplified system of 5 differential equations. The control algorithm for the operation of the heat pump is based on the principles of model predictive control and applies a combined COP and market price optimization based on a one-day-look-ahead algorithm for heat demand and electricity prices - both being implemented in MATLAB. The algorithm is designed as to be easily implementable in machine code. \r\nThe method is assessed using actual meteorological data and market prices and simulating the operation of an optimized, a non-optimized and a partly-optimized system. These results provide an exemplary insight into the annual cost savings by using the smart grid environment. The last part of this contribution then gives an outlook on the evaluation method of the advantageousness of such operation for the grid operator in an agent based simulation.\r\n", :title "Economically optimized operation of heat pumps in a smart grid environment", :keyword2 182, :authors (44999 33364 24773), :session 199932}, 493 {:keyword1 8, :keyword3 0, :abstract "We investigate a sufficient and necessary condition for the existence of a perfect matching in normal hypergraphs. The class of normal hypergraphs strictly contains all balanced hypergraphs for which Conforti et. al. proved a Hall-type condition for the existence of a perfect matching. We show that this condition can be generalized to normal hypergraphs by multiplying vertices and give a tight upper bound on the number of times a vertex has to be multiplied.", :title "A Hall condition for normal hypergraphs", :keyword2 42, :authors (45072 14923), :session 199913}, 494 {:keyword1 96, :keyword3 0, :abstract "We consider the scheduling problem of a manufacturer that has to process a set of jobs on identical parallel machines where jobs can only be delivered at a given number of delivery dates and the total tardiness is to be minimized. Such settings are frequently found in industry, for example when a manufacturer relies on a logistics provider that picks up completed jobs twice a day. The scheduling problem with fixed delivery dates where the delivery dates are considered as an exogenously given parameter for the manufacturer’ scheduling decisions can be solved by various optimal and heuristic solution procedures. Here, we consider a variant of this problem where only the number of delivery dates is fixed. For example, the manufacturer may be entitled to assign the logistics provider two pick-up times per day. Then, the machine schedule and the delivery dates can be determined simultaneously which may significantly improve adherence to due dates. We discuss a mathematical programming formulation and a heuristic solution approach for the resulting parallel machine production and distribution scheduling problem. The findings can provide valuable input when it comes to evaluating and selecting distribution strategies that offer a different extent of flexibility regarding the delivery dates.   ", :title "Scheduling identical parallel machines with a fixed number of delivery dates", :keyword2 101, :authors (29263), :session 199874}, 497 {:keyword1 154, :keyword3 134, :abstract "We consider the classical mechanism design problem of strongly implementing social choice functions in a setting where monetary transfers are allowed. In contrast to weak implementation, where only one equilibrium of a mechanism needs to\r\nyield the desired outcomes given by the social choice function, strong implementation (also known as full implementation) means that a mechanism is sought in which all equilibria yield the desired outcomes. For strong implementation, one cannot restrict attention\r\n  to incentive compatible direct revelation mechanisms via the Revelation Principle, so the question whether a given social\r\n  choice function is strongly implementable cannot be answered as easily as for weak implementation. When considering Bayes Nash equilibria, the Augmented Revelation Principle states that it suffices to consider mechanisms in which the set of types of each agent is a subset of the set of her possible bids. Moreover, given some additional data, such a mechanism can be constructed\r\n  by an iterative procedure via selective elimination of undesired equilibria in finitely (but possible exponentially)\r\n  many steps. For dominant strategies as the equilibrium concept, however, no such results have been known so far.\r\n  We close this gap by showing a variant of the Augmented Revelation Principle for dominant strategies and a selective elimination procedure for constructing the desired mechanisms in polynomially many steps.  Using these results, we then show that strong implementability in dominant strategies can be decided in nondeterministic polynomial time.", :title "Complexity of Strong Implementation of Social Choice Functions in Dominant Strategies", :keyword2 40, :authors (19477 36955), :session 30}, 498 {:keyword1 41, :keyword3 133, :abstract "Many separation tasks in Chemical Engineering are based on\r\ndistillation. The determination of an optimal design for such\r\nseparation processes often requires solving a mixed-integer non-convex   \r\noptimization problem to global optimality, and, is, hence, very\r\nchallenging, in general. \r\nIn this work, we present, for a certain class of distillation processes, a bound-tightening strategy that exploits the\r\nproblem-specific structure. The bound-tightening strategy is used to\r\ndefine a MINLP relaxation of the original problem. The relaxed MINLP\r\nforms the basis of a modified branch-and-bound algorithm, which is\r\nused to solve the original problem to global optimality. The\r\nperformance of the algorithm is demonstrated on a series of test\r\ninstances. \r\n\r\nThis is a joint work with Martin Ballerstein, Achim Kienle, Christian Kunde und Robert Weismantel", :title "A Bound-tightening technique for the global optimization of distillation-based separation processes.", :keyword2 158, :authors (45188), :session 75}, 499 {:keyword1 121, :keyword3 57, :abstract "Numerous dynamic, interdependent processes exist at an airport. These processes are highly affected by uncertain events as changing flight schedules, delays, or weather conditions. Naturally a flexible workforce management is needed to support such operation. Airlines, airports, and ground handlers provide the necessary workforce to meet this demand. But legal requirements, union agreements and company policies define the flexibility of workforce planning and utilization in practice. Nevertheless a valid (monthly) roster matching the supply with demand under all these requirements has to be prepared usually several weeks before the day of operation.\r\n\r\nIn this talk we discuss the optimization challenges to create monthly rosters for ground personnel at an airport. We give examples of typical (legal/union/company) constraints, point out the characteristics of different work areas at an airport, and how this affects the rostering. Further we present how rostering is solved by our branch-and-price solution methodology in practice. Using this approach, we report on our real-life experience with optimized rostering in airport ground handling.", :title "An Insight to Aviation: Rostering Ground Personnel in Practice", :keyword2 2, :authors (45121), :session 28}, 500 {:keyword1 162, :keyword3 14, :abstract "In this talk, we first recall a basic theorem on calmness of the intersection of calm multifunctions, cf. Klatte, Kummer: Nonsmooth Equations in Optimization, Kluwer 2002. Then we show how to apply this to calmness conditions for the optimal solution set mapping of a (finite and semi-infinite) optimization problem under data perturbations. A main result says the argmin mapping of a convex semi-infinite program is calm if an auxiliary inequality system has this property, while the opposite direction may fail in the general case. The results are obtained in collaboration with Bernd Kummer (Humboldt University Berlin).", :title "Intersection of calm multifunctions and its application to the argmin mapping", :keyword2 108, :authors (10871), :session 199959}, 501 {:keyword1 172, :keyword3 42, :abstract "Much on behavior by energy consumers can be learned from what they tell each other in online discussion fora. Hence, we perform a longitudinal case study on the discussion platform www.energiesparhaus.at.  Specifically, we visualize the yearly changes in the communication network among consumers, along with content dimensions and their effects on declared adoption, about a popular subtopic: Rika Memo, a pellet-fired stove (www.rika.at/en/memo/).\r\nFirst, we look at the evolution of this thread between its start in Oct 2007, and Oct 2012, by time intervals of a year, which summarizes the data in 6 graphs. All discussion board members who contributed to the topic at any time during our total study period (except for the thread’s initiator) are pictured as nodes in each graph. If members communicated with each other in the thread before or during a certain year, this is visualized with a link between them in that year’s graph. Cumulative number of posts exchanged is reflected in the strength of a link. Next, we construct similar series of graphs for each of some relevant content dimensions: social and informational exchange (Harmsen - van Hout et al. EJOR 2013), where the latter is subdivided in the traditional 4 elements of the marketing mix, as well as positive and negative exchange. Finally, by coloring the nodes in all graphs we investigate the effects of (dimensions of) communication on adoption of the respective heating system.\r\nBy such semi-dynamic visualization we add to the literature on social network visualization (e.g., Trier ISR 2008) to gain new insights into the dynamic characteristics of online consumer discussion fora as well as the topic of energy consumer behavior and how this can be affected by low-cost online communication platforms.", :title "Online discussion among energy consumers: A semi-dynamic social network visualization", :keyword2 29, :authors (44056 21108 45189), :session 199903}, 502 {:keyword1 45, :keyword3 156, :abstract "Nursing homes provide long-term care for elderly people who are too frail or sick to live autonomously anymore. The majority of nursing home residents require assistance with activities of daily living such as bathing, grooming, eating meals and taking medication. Each task requires a specific level of qualification of the respective care worker and has to be performed within a small time window around the point in time requested by the resident. Since care workers cause the largest share of operational costs, there is a lot of pressure on management of such facilities to appoint as little workers as possible while maintaining a high quality of service.\r\nWe present a mixed-integer program (MIP) and a dynamic programming (DP) approach that generate optimal task schedules in terms of waiting times of the residents for a given workforce composition. To solve large problem instances, we develop heuristic solution approaches to speed up the DP approach. Using data from practice, we evaluate the computational performance of our solution approaches. Furthermore, we perform a sensitivity analysis to show how waiting times or workforce expenditures can be reduced by increasing the flexibility of the workforce (i.e., allowing workers with high qualification to perform task with lower qualification requirements) and by increasing the scale of the schedule (i.e., creating a common schedule for two neighboring departments of a facility).\r\n", :title "Operational scheduling of care workers in long-term care facilities", :keyword2 96, :authors (29046 39406 10255 1082), :session 77}, 503 {:keyword1 75, :keyword3 99, :abstract "Traditional Kanban systems are designed to work in a static operating environment. Recent works suggest to change the number of Kanban cards based on the current inventory level to account for stochasticity in the system.   We provide a systematic overview of the existing approaches. Based on that, a new mechanism for the Kanban card setting under stochastic and moreover non-stationary operating environments is introduced. This operating environment occurs for example during production ramp-ups. In contrast to existing approaches, the proposed approach uses information about the future development of the system to proactively change the number of Kanban cards.  We discusses objectives and preliminary results of the new card setting approach and outline similarities to the buffer allocation problem. ", :title "Setting Kanban cards for production systems under non-stationary and stochastic operating environments", :keyword2 165, :authors (33462 10255), :session 199845}, 504 {:keyword1 96, :keyword3 0, :abstract "In the last years, job shop scheduling problems that are more complex - but also of wider applicability - than the classical Job Shop (JS) have found increasing interest, a prototypical example of such a Complex Job Shop problem (CJS) being the Blocking Job Shop (BJS). While several methods have been developed for various CJS, most of them consider as objective makespan minimization and very few address other objectives related for instance to due dates or flow time, that are equally relevant in practice.\r\n\r\nThis talk addresses CJS problems with arbitrary regular objective. Building on previous work of the authors on CJS problems with makespan objective, the problem is formulated in a disjunctive graph and a local search method using a neighborhood based on job-insertion is proposed. A key feature is the ability to consistently and efficiently generate feasible neighbor solutions, typically by moving a critical operation together with other operations whose moves are “implied”.\r\n\r\nNumerical results are presented for the Job Shop (JS), the Job Shop with Setup Times (JSS), and the Blocking Job Shop (BJS) with the following four objectives: makespan, maximum tardiness, total weighted flow time, total weighted tardiness.\r\n\r\nThe results support the validity of the proposed method. Specifically, the results are competitive with current benchmarks in the JS and JSS, they substantially improve the current benchmarks in the BJS with makespan objective and establish first benchmarks in the BJS with the other three objectives.", :title "Complex Job Shop Scheduling with Regular Objective", :keyword2 8, :authors (19271 19607), :session 199876}, 508 {:keyword1 61, :keyword3 0, :abstract "In this presentation, we will illustrate how the modeling script that is central to your application, is able to extend itself based on data supplied by the end user, using the model query and model edit functions offered by AIMMS. The presentation will discuss a repetitive modeling pattern. Such a pattern can be coded once, generating script upon execution, thereby reducing the application's maintenance costs. Furthermore, it will delve into the use of formulas as data. Formulas, such as \"blending rules\" and \"pricing rules\", are the intellectual property of the end user, and such formulas are only made available while the end user is running its application. By treating these formulas as data, they can be used inside optimization models.", :title "Letting Your Application do the Modeling", :keyword2 0, :authors (45161), :session 96}, 509 {:keyword1 16, :keyword3 0, :abstract "We investigate a heuristic for the two-dimensional rectangular strip packing problem (2DSPP) that constructs a feasible two-dimensional packing by placing one-dimensional cutting patterns obtained by solving the horizontal one-dimensional bar relaxation (1DHBR). To represent a solution of 2DSPP, a 1DHBR solution has to satisfy, among others, the vertical contiguous condition. That means that there must exist such an ordering of cutting patterns that all items representing one rectangle are located in consecutive patterns. To strengthen the 1DHBR with respect to that vertical contiguity new inequalities were formulated and numerically analyzed.", :title "New inequalities for one-dimensional relaxations of the two-dimensional strip packing problem", :keyword2 0, :authors (42755 16923), :session 199894}, 510 {:keyword1 60, :keyword3 150, :abstract "We introduce a military aircraft mission planning problem where a given fleet of aircraft should attack a number of ground targets. Due to the nature of the attack, two aircraft need to rendezvous at the target, that is, they need to be synchronized in both space and time. At the attack, one aircraft is launching a guided weapon, while the other is illuminating the target. Each target is associated with multiple attack and illumination options. For each attack option the expected effect on the target is given. Further, there may be precedence constraints between targets, limiting the order of the attacks. The objective is to maximize the outcome of the entire attack, while also minimizing the mission timespan. The problem is formulated as a mixed integer linear programming (MILP) model and can be characterized as a generalized vehicle routing problem with synchronization and precedence side constraints. Finding optimal solutions through direct application of a general MIP solver is only practical for scenarios of moderate sizes. Even for problem instances including only five targets, it takes CPLEX several hours to verify optimality, although it is able to find feasible and near-optimal solutions much earlier. Therefore, we propose a Dantzig-Wolfe decomposition and solve the resulting problem by a column generation approach. A column represents a predefined sequence of targets and tasks for one aircraft with the corresponding time periods in which the targets are visited. To generate columns we solve longest path subproblems with capacity and precedence side constraints. We compare the column generation approach with a direct application of CPLEX on the MILP formulation.", :title "Military aircraft mission planning: a column-generation approach", :keyword2 95, :authors (36408 29723 25562 2987), :session 199872}, 511 {:keyword1 35, :keyword3 34, :abstract "Holding funds have become increasingly popular for asset classes such as real estate, hedge funds or mixed-assets funds over the last years. This second level of funds is plausible if there are some practical limitations on the first level that hinder diversification. The European Union regional policy with its European Urban Development Funds creates such limited investment universes.\r\n\r\nIn a first step, our paper analyses the theoretical reasons for the benefits of a second fund level. In a second step, we employ mathematical modelling techniques to quantitatively evaluate its diversification effects. Therefore, we use a Monte Carlo method to simulate the development of Polish projects within possible credit portfolios. Geometric Brownian motion processes help to determine the cash flows of these Polish projects by allowing for stochastic deviations from a given drift rate. As an interim result of this application, we obtain the discrete probability density of investors’ terminal wealth generated by the respective credit funds. Finally, an assessment of the utility (CRRA) of an investment measured through the terminal wealth in either one of the Urban Development Funds (first level) or the Holding Fund (second level) reveals that the diversification benefits through the latter exceed the additional transaction costs for a wide range of investors’ risk preferences.\r\n\r\nOur paper contributes to the scarce research on urban development investments within multi-level fund structures. To the best of our knowledge, we are the first to quantify the benefits from the second level of such funds on the one hand and to consider volatile cash flows of projects suitable for Urban Development Funds on the other hand.", :title "Advantages of Multi-level Fund Structures for Urban Development Investments", :keyword2 93, :authors (45187 14628 45190), :session 199963}, 512 {:keyword1 18, :keyword3 44, :abstract "In the past research work, we have introduced a generic iterative hybrid procedure for quantitative group multi-criteria decision analysis that consolidates an autonomous aggregation-disaggregation mechanism with a moderated Delphi process. By applying a universal framework for the assessment of group decision-making methods and systems, we have shown that the aggregation-disaggregation analysis and the Delphi method can be synergistically combined although they are based on different core principles.\r\nIn this paper, we operationalize all steps of the hybrid procedure by defining appropriate algorithms, operators and metrics. We focus on initial preference specification, preference aggregation, analysis of (dis)agreements, sensitivity/robustness analysis, communication, adjustment of holistic decisions and preferential parameters, preference disaggregation, and relaxation of constraints. Introduced operators and metrics assess the majority opinion, compute deviations, determine the direction of the group, identify the most discordant decision-makers, and determine the robustness of opinions. Proposed algorithms adjust preferential parameters of the most opposing group members with the purpose to iteratively, convergently and efficiently unify opinions. Derived algorithms, operators and metrics are applied to both most relevant decision-making problematics: ranking of alternatives and sorting of alternatives into arbitrary many ordered categories.", :title "A hybrid Delphi and aggregation-disaggregation procedure for group decision-making: algorithms, operators and metrics", :keyword2 19, :authors (29689), :session 199841}, 513 {:keyword1 92, :keyword3 0, :abstract "We present a new model formulation for a multi-product capacitated lot sizing problem with remanufacturing. We assume that the returned products possess different quality levels. The process of (re)manufacturing is located on multiple machines.  The returned products with a given quality level can be remanufactured to the next better or a higher quality level. External demands for new products as well as for remanufactured products depending on the quality are considered. The demand of remanufactured products of a given quality level can also be satisfied by any remanufactured product with a higher quality level or in addition by a new product. However, this substitution is not allowed in the other direction. Furthermore, a solution approach based on mathematical programming is proposed.", :title "Capacitated lot sizing with quality-dependent remanufacturing ", :keyword2 0, :authors (36077 13866), :session 199847}, 514 {:keyword1 48, :keyword3 92, :abstract "With a total of 1.6 billion tons of crude steel in 2013 worldwide steel production has reached its highest level to date. Therefore it is necessary to deal with large amounts of by-products. An essential group of by-products in the iron and steel industry are slags. Slags perform important metallurgical tasks and are inevitable for iron and steel production processes. Although slag production is inevitable, slags are not considered waste and can be used as secondary resources. For example, slags are recycled to produce road construction material, cements and fertilizers. In order to recycle slags there is a variety of alternative recycling measures. The potential of a recycling measure strongly depends on a multitude of technical, economic and ecological variables. Due to the concurrence of these variables a general statement concerning the advantage of one specific recycling measure cannot be given. In short term production planning this leads to the question how slags are to be recycled. A planning approach taking into account all relevant variables is not known. This contribution introduces a production planning approach for slag recycling considering technical, economic and ecological variables. The planning approach comprises a quantity and a value structure. The quantity structure is based on an activity analysis focusing operating points of possible recycling processes. In order to determine relevant operating points, recycling processes are modeled by means of flowsheet simulation. The information provided by the quantity structure is evaluated in the value structure based on management accounting. Subsequently, the quantity and value structure are incorporated into a formal mathematical model. The application of the model is illustrated in a case study.", :title "Operative planning of recycling measures for iron and steel slags", :keyword2 75, :authors (39469 17130 2651), :session 99}, 516 {:keyword1 101, :keyword3 175, :abstract "On a tactical level retailers face the problem to determine on which weekdays stores should be delivered and to set a frame for short term vehicle routing. Especially in grocery retail weekly repetitive delivery patterns are applied to increase planning stability for the stores and to balance picking workload at the distribution center. A delivery pattern is defined as a store-specific combination of weekdays on which a delivery takes place.\r\n\r\nAs several processes in the logistics subsystems distribution center, transportation and instore logistics of the retail supply chain are influenced by the delivery pattern decision, an integrated approach is necessary to solve the problem. Therefore we propose an IP model that considers the decision relevant costs and capacities at the distribution center, in transportation and instore. We especially focus on instore handling aspects, bundling issues in transportation and associated interrelations.\r\n\r\nTo solve the trade-off between the different cost components which are aligned to the delivery pattern decision, we propose a simultaneous and a sequential solution approach. We show significant cost saving potentials by applying the model and approaches proposed using a case from a major European grocery retailer. An extensive sensitivity analysis gives further insights into cost and capacity effects.", :title "Selecting delivery patterns for grocery chains", :keyword2 174, :authors (45184 25668 22691), :session 199859}, 518 {:keyword1 59, :keyword3 153, :abstract "Meta-heuristic search procedures incorporate several strategies for evolving one or several search trajectories through a search space that represents the set of feasible solutions of a combinatorial optimization problem. In the context of vehicle routing, a lot of basic operators have been invented in order to find distance minimal route sets that fulfill given sets of often complicated constraints. Typically, several types of constraints are distinguished. Constructive constraints must be fulfilled in order to ensure that the proposed solution is a set of routes but loading constraints coordinate the assignment of requests to vehicles. Scheduling constraints are imposed in order to determine feasible operation starting times. While intra-route scheduling constraints have implications for the scheduling of operations in the route of one vehicle, inter-route scheduling constraints are imposed in order to achieve a coordination of the starting times of operations executed by different vehicles. If all given inter-route scheduling constraints are fulfilled then the vehicles are called synchronized. Recently, synchronization constraints have entered the arena of vehicle routing research. We report about experiences from the development of a meta-heuristic that incorporates different operators as well as hill climbing procedures with the goal to solve a pickup and delivery problem with synchronization constraints. Typical search concepts reported for the pickup and delivery problem fail to achieve synchronized operations. We start with a report on these failures. Next, we derive countermeasures to overcome this shortcoming. Finally, we demonstrate the effectiveness of the proposed new operators and neighborhoods within comprehensive computational experiments.", :title "Strategies for achieving synchronized operation times of several vehicles in a meta-heuristic search procedure", :keyword2 175, :authors (32377), :session 47}, 520 {:keyword1 175, :keyword3 0, :abstract "We study the problem of finding an optimal itinerary to travel from a starting location to a destination location using public transport, where we allow travelers to alternate rides with (short) walks. The main difference with previous research is that we take all possible walks that a traveler can make into consideration. This large number of possible walks poses a potential computational difficulty. However, in this study we derive theorems for identifying a small subset of walks that only need to be considered. These results are embedded in a solution algorithm, which is tested in a real-life setting for bus transportation in Groningen, a medium sized city in the northern part of the Netherlands. An extensive numerical study leads to encouraging results. First, only one per cent of all possible walks needs to be considered, so that the optimal itinerary can be determined very efficiently. Second, allowing walks has considerable benefits; reducing the travel time in about 6 per cent of all randomly generated examples by more than 10 per cent on average.", :title "Optimizing Itineraries in Public Transportation with Walks between Rides", :keyword2 0, :authors (37356 35181), :session 199941}, 521 {:keyword1 18, :keyword3 158, :abstract "An increasing environmental awareness, rising energy costs, progressing urbanization, and shortage of space cause to rethink individual mobility behavior and personal car ownership in cities. Car sharing is a sustainable mobility concept that allows individuals to satisfy their mobility needs without owning a car and addresses modern mobility. Car sharing is particularly suitable to cover medium-range distances and can be linked to the public transport of major cities (intermodal mobility). Within this context, the integration of electric vehicles represents an opportunity to further protect the environment and potentially save energy costs.\r\nIn order to create an efficient car sharing transportation network, the location of stations, the number of vehicles and the availability of electric fast charging stations are critical success factors. Based on an existing optimization approach for fossil car sharing, we provide a decision support system (DSS) to plan and optimize car sharing stations for electric vehicles. Within design-oriented research, we refine and evaluate research artefacts. An optimization model and the DSS OptCarShare 1.1 enable to optimize stations and visualize results. Parameters, such as the annual lease payment for charging station, the expected travel time of consumer, the charging time of electric vehicle dependent on available charging stations, affect the decision variables such as the number of car sharing stations, vehicles and fast charging stations. \r\nOn the basis of evaluations and benchmarks for the cities of Hanover and Zurich, we establish generalizations for the parameters of the model. The results show a high impact of the fast charging stations (half an hour to fill 80% of the battery) on the current model and the optimal solution.", :title "A Decision Support System to Optimize Car Sharing Stations with Electric Vehicles", :keyword2 54, :authors (45014 30218 19100), :session 199840}, 522 {:keyword1 40, :keyword3 95, :abstract "During the last decade, the quantification of the inefficiency of game-theoretic equilibria has been a popular and successful line of research. The two most widely adopted measures for this inefficiency are the Price of Anarchy (PoA) and the Price of Stability (PoS). In this talk I will summarise recent results on the PoS in congestion games. ", :title "Price of Stability in Congestion Games", :keyword2 134, :authors (44836 42850), :session 8}, 524 {:keyword1 57, :keyword3 0, :abstract "The Buffer Allocation Problem (BAP) can be modeled as a mixed integer program by sampling the effective processing times. Recently, a Benders Decomposition approach has been proposed for the BAP. The computation times of this procedure can be further reduced by the generation of lower bounds based on the optimization of subsystems. We improve the computation time by generating additional lower bounds for each individual buffer. Additionally, the choice of the next evaluated buffer allocation is not under control using a standard solver for the master problem in the existing Benders Decomposition approach. We investigate the performance of approaches to systematically generate new candidate solutions in the master problem.", :title "Accelerating sample-based optimization methods of buffer allocations in flow lines", :keyword2 97, :authors (37015 10255), :session 199845}, 525 {:keyword1 96, :keyword3 158, :abstract "A problem of multi-product scheduling on dedicated machines is considered. Each product can be produced by a family of alternative multi-machine technologies. Multi-machine technologies require more than one machine at the same time. A sequence dependent setup time is needed between different technologies. The criterion is to minimize the makespan. The problem is motivated by the real-life scheduling applications in chemical industry.\r\nPreemptive and non-preemptive versions of the problem are studied. Mixed integer linear programming models, based on a continuous time representation, are formulated for both versions. Using these models, the polynomially solvable cases of the problem, in which the number of technologies is a given constant, are found. \r\nWe analyze computational complexity and approximation complexity of the problem. In particular, it is proved that the problem without setup times in the case, when there is only one technology for each product and each machine may be used for processing only two technologies, is NP-hard in the strong sense. Moreover, the problem cannot be approximated within a practically relevant factor of the optimum in polynomial time, if not P=NP.\r\nThis research has been supported by the RFFI Grant 12-01-00122.\r\n", :title "On Complexity of Scheduling Problem with Technology Based Machines Grouping", :keyword2 154, :authors (33399 14965), :session 199874}, 527 {:keyword1 101, :keyword3 141, :abstract "We consider a decentralized organization. A principal hires an agent to be head of a profit center. The agent’s only task is to choose the periodic order quantity for a single selling season in the presence of uncertain demand. One out of two possible demand distributions materializes. By assumption the agent knows which distribution is present, but the principal does not. The principal aims at maximizing long term firm value while the agent maximizes short run profit. Given this setting an adverse selection problem is present. We show that the principal can offer a compensation scheme that results in zero agency costs and fully efficient outcomes.", :title "The role of service level based compensation in a profit center organization with demand uncertainty", :keyword2 40, :authors (33414 39363), :session 199860}, 528 {:keyword1 45, :keyword3 96, :abstract "In most hospitals there are patients who receive surgery later than medically advised. In one of Belgium’s largest hospitals, UZ Leuven, this is the case for approximately every third patient. Patients could be served in a timelier manner if the hospital would increase its capacities, i.e., opening a new operating room and hiring the necessary additional personnel. Unfortunately, this is not an option. Another way to improve the amount of patients served in time is to improve the way they are scheduled. Surgeons do their scheduling themselves and do not use algorithms to support their decision. As a consequence, we analyzed scheduling mechanisms that are easy to apply manually.\r\nWe checked three mechanisms. Firstly, we checked whether it is beneficial to allow different groups of patients to be served one day after it was decided that they need surgery. Secondly, we checked whether it is beneficial to allow some group of patients to be served on a FCFS basis. Thirdly and lastly, we investigated the effects of pushing low urgency patients more into the future in order to serve high urgency patients quicker.\r\nWe will show extensive computational results to demonstrate the impact that combinations of the different scheduling mechanisms have on various patient related performance measures. Additionally, we also identify those combinations that best match the hospital data.\r\n", :title "How to schedule patients to operating rooms when simulation results suggest FCFS to perform best", :keyword2 18, :authors (37465 41246 43026), :session 199937}, 530 {:keyword1 150, :keyword3 0, :abstract "In our talk, we consider the optimization problem of re-arranging the rows and columns of a matrix (especially matrices arising from mixed integer programs) into singly-bordered block-diagonal form for a given number of blocks such that the total number of border rows is minimized.\r\n\r\nA singly-bordered block-diagonal form is beneficial not only because it can be exploited for computing an LU- and QR-factorization, but also when solving mixed integer programs, e.g. by applying Dantzig-Wolfe decomposition.\r\n\r\nIn the literature numerous heuristic approaches have been proposed, but only one exact algorithm.\r\n\r\nWe present a new IP-formulation that is solved by a branch-and-price algorithm. In this formulation every binary variable corresponds to a subset of rows forming one particular block. \r\n\r\nThe pricing problem can be solved by several heuristics (e.g. hill climbing and simulated annealing). Moreover, we introduce two exact approaches: the first one is by integer programming and the second is based on Lagrangean relaxation exploiting the combinatorial structure of the pricing problem such that the Lagrangean subproblem can be solved efficiently by computing a minimum s-t cut.\r\n\r\nFurthermore, we suggest a branching scheme working on (aggregated) sums of variables whose branching decisions are respected in easily adapted pricing algorithms. Moreover, we  introduce a (randomized) primal heuristic that uses fractional solutions to provide good integer solutions even in the root node.\r\n\r\nIn our computational study we will examine the impact of the above techniques and compare the performance with the existing exact algorithm. Preliminary results suggest that our approach particularly performs well for a higher (>4) number of blocks and thus complements the existing approach.", :title "A Branch-and-Price Algorithm for Minimizing the Border in Bordered Block-Diagonal Matrices", :keyword2 157, :authors (33581 29178 19709 14969), :session 199909}, 531 {:keyword1 17, :keyword3 0, :abstract "We present an application of data envelopment analysis for the assessment of the quality of treatment plans for radiation therapy of prostate cancer. Because commercial radiotherapy treatment planning systems require treatment planners to iteratively adjust the plan parameters in order to find a satisfactory plan, the quality of a plan may not be the best achievable one. We propose a quality assessment method based on Data Envelopment Analysis (DEA) to address this inefficiency. This method compares a plan of interest to a set of past delivered plans and searches for evidence of potential further improvement. With the assistance of DEA, planners will be able to make informed decisions on whether further planning is required and ensure that a plan is only accepted when the plan quality is close to the best attainable one. We demonstrate the potential of the DEA method on a set of 37 clinically acceptable prostate cancer treatment plans.  ", :title "Quality assessment for external radiotherapy planning based on data envelopment analysis", :keyword2 63, :authors (485 41433 45268 13797 45266), :session 199833}, 533 {:keyword1 94, :keyword3 154, :abstract "We study the problem of packing a knapsack without knowing its capacity. Whenever we attempt to pack an item that does not fit, the item is discarded; if the item fits, we have to include it in the packing. We show that there is always a policy that packs a value within factor 2 of the optimum packing, irrespective of the actual capacity. If all items have unit density, we achieve a factor equal to the golden ratio 1.618. Both factors are shown to be best possible.\r\nIn fact, we obtain the above factors using packing policies that are universal in the sense that they fix a particular order of the items and try to pack the items in this order, independent of the observations made while packing. We give efficient algorithms computing these policies. On the other hand, we show that, for any alpha > 1, the problem of deciding whether a given universal policy achieves a factor of alpha is coNP-complete. If alphe is part of the input, the same problem is shown to be coNP-complete for items with unit densities. Finally, we show that it is coNP-hard to decide, for given alpha, whether a set of items admits a universal policy with factor alpha, even if all items have unit densities.", :title "Packing a Knapsack of Unknown Capacity", :keyword2 173, :authors (45087 26950 14975 33453), :session 42}, 534 {:keyword1 96, :keyword3 0, :abstract "Jobs scheduled in the classical resource-constrained project scheduling problem (RCPSP) consume renewable resources during their execution. Thereby, it is often assumed that each of these resources has a constant capacity throughout the planning horizon, which must not be exceeded. In practice, the usage of additional capacity can be part of the decision problem. For that reason, we extend the classical RCPSP by a decision on the usage of overtime with associated penalty costs (RCPSP-OC).\r\n\r\nIn order to solve problem instances of practically relevant size, we develop a heuristic solution method. Studies from literature show that the most powerful heuristics for the RCPSP contain the serial schedule generation scheme (SSGS) at their core. Accordingly, a heuristic for the RCPSP-OC based on the SSGS seems to be promising. Due to the fact that additional capacities are not considered, however, the SSGS in its basic form is not suitable for solving the RCPSP-OC. Therefore, we present a modified version of the SSGS embedded in a genetic algorithm. Additionally, we evaluate further approaches for solving the RCPSP-OC by choosing different representations in a genetic algorithm.", :title "Resource-constrained project scheduling with overtime", :keyword2 0, :authors (45146 17387), :session 199871}, 535 {:keyword1 8, :keyword3 175, :abstract "We introduce a hypergraph based combinatorial optimization problem -\r\nthe Cycle Embedding Problem (CEP). The CEP is a subproblem of the Rolling Stock\r\nRotation Problem and can be described as follows.  Given are two hypergraphs,\r\ni.e., on a fine and a coarse layer, a corresponding projection from fine to\r\ncoarse, and a set of cycles covering all nodes of the coarse layer. The goal is\r\nto embed these coarse cycles, i.e., to find cycles in the fine layer such that\r\ntheir projection are the coarse cycles. We develop an integer programming\r\nformulation for this combinatorial problem and provide a complete description\r\nfor standard graphs. For hypergraphs we prove that the problem is NP-hard.\r\nFinally, we present computational results of CEPs deduced from problem instances\r\nof DB Fernverkehr AG. The layers for the rolling stock rotation planning problem\r\nare motivated by aspects of vehicle orientations. Neglecting the orientation of\r\nvehicles leads to a coarse hypergraph layer without considering necessary turn\r\naround trips. The CEPs coming from our coarse-to-fine approach are usually\r\nfeasible and tractable for optimization. Hence, in general, the planning of turn\r\naround trips can be done subsequently after solving a coarse variant of the\r\nrolling stock rotation problem.", :title "The Cycle Embedding Problem", :keyword2 157, :authors (21211 14923 45197 45198 14771), :session 199899}, 536 {:keyword1 75, :keyword3 97, :abstract "The amount of data produced by any kind of electronic device increases continuously. With more and more data available, more and more processes and decisions are based on such data. But with an increasing amount of data available, there is little said about the data quality. A lot of research has been done to define measures for data quality. We do know how to measure different aspects of data quality. But we know little about the effects. With more and more decisions based on an increasing amount of data, it remains open to investigate the impact of poor data quality. Depending on the process using certain data, the effects may be harmful. The knowledge about effects of using data with low quality is mandatory. Gaining such knowledge, we may find a way to avoid negative effects. It is necessary to keep in mind, that poor data quality is not equivalent to data uncertainty. Understanding data quality as usefulness of data, uncertainty is neither a prerequisite nor an outcome of poor quality. In fact, poor data quality may come along with very certain and specific information. Thus, it is not advisable to reduce data quality to data uncertainty.\r\nIn this paper, we are going to define a production model. This model will be used to solve a cost minimization problem. We use this model to compute different solutions, enriched with different kinds of low data quality aspects. For each quality aspect, we investigate the negative effects, correlated to the input data. Afterwards, we are going to combine different kinds of low data quality aspects. We present the gained information. Additionally, we use the computed information for a business process improvement. We aim on a general approach to reduce negative effects of using data with low quality in processes.", :title "Data Quality and Production Planning", :keyword2 140, :authors (45153 1658), :session 199849}, 537 {:keyword1 151, :keyword3 8, :abstract "We consider the problem of computing a large stable matching in a bipartite graph G = (A \\cup B, E) where each vertex u \\in A \\cup B ranks its neighbors in an order of preference, perhaps involving ties. A matching M is said to be stable if there is no edge (a,b) such that a is unmatched or prefers b to M(a) and similarly, b is unmatched or prefers a to M(b). While a stable matching in G can be easily computed in linear time by the Gale-Shapley algorithm, it is known that computing a maximum size stable matching is APX-hard.\r\n\r\nIn this paper we consider the case when the preference lists of vertices in A are strict while the preference lists of vertices in B may include ties. This case is also APX-hard and the current best approximation ratio known here is 25/17 \\approx 1.4706 which relies on solving an LP. We improve this ratio to 22/15 \\approx 1.4667 by a simple linear time algorithm.\r\n\r\nWe first compute a half-integral stable matching in \\{0,0.5,1\\}^{|E|} and round it to an integral stable matching M. The ratio |\\opt|/{|M|} is bounded via a payment scheme that charges other components in \\opt \\oplus M to cover the costs of length-5 augmenting paths. There will be no length-3 augmenting paths here.\r\n\r\nWe also consider the following special case of two-sided ties, where every tie length is 2. This case is known to be UGC-hard to approximate to within 4/3. We show a 10/7 \\approx 1.4286 approximation algorithm here that runs in linear time.", :title "An Improved Approximation Algorithm for the Stable Marriage Problem with One-Sided Ties", :keyword2 40, :authors (45150), :session 19}, 538 {:keyword1 94, :keyword3 157, :abstract "We seek to design optimal robust client-server networks: Suppose that we want to transfer a single commodity (e.g., data) among the nodes in a network. Each node has a minimum and a maximum balance limiting how much of the unique commodity the node can supply or demand. Our aim is to find minimum cost integer capacities for the network's links such that all possible realizations of supplies and demands can be routed through the network. This gives us a worst-case robust model with polyhedral uncertainties. Applications for the model lie in networks where all servers can answer the client's requests which is, for instance, true for movie streaming networks.\r\n\r\nWe build on previous work by Buchheim, Liers and Sanità (INOC 2011) and a previous joint work by authors (ISCO 2012) with Álvarez, Dorneth and Parriani to develop a branch-and-cut algorithm for the problem. It uses a capacity based linear program to obtain lower bounds for the objective value and derives upper bounds with problem specific rounding heuristics. To solve the linear program, we give a separation algorithm and tighten our formulation with 3-partition inequalities. Finally, we evaluate the algorithm experimentally.", :title "Single-Commodity Robust Network Design with Simple Polyhedral Uncertainty", :keyword2 65, :authors (28033 22920 14728 14713 662), :session 69}, 540 {:keyword1 29, :keyword3 0, :abstract "Today the energetic layout of buildings is increasingly shaped by climate change and limited fossil resources. New loads, local power generation, and energy storages rapidly gain influence. Various technologies appeared on the market, each with specific effects on the energetic footprint of a building. New energy supply technologies are, e.g., photovoltaic (PV) and solar thermal systems, heat pumps, or combined heat and power (CHP) micro systems. For the energy demand additionally new loads such as electric vehicles arise. The specific conditions of a building play a crucial role besides energy storages. Important parameters are, e.g., the energy usage of the building (private, commercial or industrial) or the specific location characteristics (ambient temperature, solar radiation, etc.). Cause-and-effect-laws of each technology today are well-studied for most instances. But, the complexity of mutual relations increases with combining different technologies under various conditions caused by the plurality of influencing factors. This trend progressively complicates the simulation of energy flows and the determination of specific energetic-optimal layouts. Here a quantitative model of the holistic energy flows in buildings is presented. This model takes into account building- and location-specific requirements and their influence on energy demand and supply. Furthermore it involves both the possible usage of different technologies and their combination. It is shown that the model helps to comprehend the complexity of cause-and-effect-laws regarding the energy flows in buildings. Results provide a basis for energetic-optimal planning.", :title "A Quantitative Model for the Simulation and Optimization of Energy Flows in Buildings", :keyword2 97, :authors (45200 33485 19100), :session 99}, 541 {:keyword1 174, :keyword3 175, :abstract "A hub-and-spoke railway system is an efficient way of handling freight transport by land. A modern rail-rail train yard consists of huge gantry cranes that move the containers between the trains. In this context, we can consider a rail-rail transshipment yard scheduling problem (TYSP) where the containers arrive to the hub and need to be placed on a train that will deliver them to their destination. In the literature the problem is decomposed hierarchically into five sub problems, which are solved separately. First, we have to group the trains into bundles, in which the trains visit the yard and are processed at the same time. Next, we assign tracks to trains within these groups, namely parking positions. Then we have to find final positions for the containers on trains. Next we generate container moves that needs to be performed to repack the trains. Finally, we have to assign those moves to the cranes for processing.\r\n\r\nWe propose a model which will solve TYSP as a single problem. A mathematical formulation has been proposed, which enables us to define more robust and complex objective functions which includes the key characteristics from each of the sub problems. A batch of computational experiments has been conducted and compared to the results from the literature. The conclusions from the performed experiments is that the transshipment yard scheduling problem can be solved without the use of decomposition techniques.", :title "On the rail-rail transshipment yard scheduling problem", :keyword2 158, :authors (31551 5390 4224 10954 14844), :session 199943}, 542 {:keyword1 94, :keyword3 49, :abstract "The modeling and prediction of regulatory networks is of considerable importance in many different areas such as finance, environmental protection, education, systems biology, medicine and life sciences. Modern statistical learning, data mining and estimation theory has provided many regression approaches. In particular, Multivariate Adaptive Regression Spline (MARS) is an important non-parametric regression methodology. However, after the recent financial crisis, it has been realized that the known statistical methods, which suppose that the input data are exactly known and equal to some nominal values in developing models, may give untrustworthy results. This introduces a kind of weakness to the methods since, in real-life, both output and input data include uncertainty in the form of noise. Therefore, robustification has started to draw more attention in many fields, especially, the financial sector where regulatory networks appear naturally and the corresponding regression problems usually depend on complex data bases that are affected by noise and uncertainty.\r\n\r\nIn our study, we investigate how the concept of robust optimization can provide a modeling framework for the analysis of complex regulatory systems under data uncertainty. Supported by Robust Optimization, we analyze time-discrete target-environment regulatory systems under polyhedral uncertainty by using Robust MARS (RMARS) and Robust Conic MARS (RCMARS), which is more model-based and employs continuous, well-structured convex optimization that enables the applying of Interior Point Methods and their codes, e.g., MOSEK. We demonstrate the performance of RMARS and RCMARS with a numerical study and compare their results.  \r\n", :title "ROBUST COUNTERPARTS FOR TWO-MODAL COMPLEX REGULATORY NETWORKS: RMARS AND RCMARS", :keyword2 124, :authors (20485 12264 3524), :session 199958}, 546 {:keyword1 98, :keyword3 18, :abstract "Business decision makers require optimized plans and schedules to be robust.  This means plans and schedules must be resilient to change, as well as have the ability to quickly recover from shocks or changes to the system.  At the same time, many decision makers who use optimization technology consider data as being certain when creating plans and schedules.  However, when the data changes, their plans and schedules often break down, leading to decision instability and distrust in optimization technology.  \r\nIn this talk, we present a unified framework and toolkit for robust decision-making under uncertainty.  The goal of this approach is to improve the resilience of plans and schedules, as well as trust in optimization technology.  This toolkit guides operations research practioners in modeling business problems under uncertainty, including a methodology for soliciting the uncertainty characterization and information to automatically construct robust and stochastic models, based on a given deterministic model.  It also guides business decision makers in leveraging various optimization-based approaches, such as robust and stochastic optimization, to create multiple plans and compare their performance across multiple scenarios and KPIs.  We demonstrate the use of the toolkit for a case study involving demand fulfillment.", :title "A Unified Framework and Toolkit for Decision-Making under Uncertainty", :keyword2 149, :authors (40907), :session 86813}, 549 {:keyword1 35, :keyword3 34, :abstract "The research  is motivated by the practical internet exchange platform in the multibank system.   The model of the capital relocation was considered for the currency exchange transactions in the multibank environment. \r\nThe paper  is focused in the capital distribution in the bank exchange system due to the revenue maximization according to the demand forecast.  The practical application simulation model with transaction emulation has been developed. Several capital distribution models were evaluated and compared. The model assumed the initial capital distribution between banks and capital transfers during the transactions time periods.  The transfer time depends on the bank and the currency. Several algorithms of the capital relocation have been  proposed and analyzed their  effectiveness in the several conditions. The simulation experiments have been performed.  The profit calculation algorithms have been proposed and evaluated calculating the possible pair matching coefficient.\r\n\r\n", :title "Capital distribution in the bank currency exchange system", :keyword2 182, :authors (4224 31551), :session 199963}, 553 {:keyword1 174, :keyword3 165, :abstract "In the present talk we will introduce an integer L-shaped algorithm for a stochastic extension of the vehicle routing problem with simultaneous delivery and pickup. We assume that the quantities to be delivered are fixed, whereas the quantities to be picked up are not known in advance. For the stochastic pickup data, we contemplate a finite discrete probability distribution. Due to possible route failures, i.e. arriving at a customer with insufficient vehicle capacity, compensation strategies or corrective actions need to be considered. Unserved pickup quantities are collected by an additional vehicle, starting from the depot only after complete information on the unserved pickup amounts has become available. \r\nFor the single vehicle case, the stochastic model is formulated as a two-stage stochastic program with recourse and solved by means of the integer L-shaped method. Lower bounding functionals (LBFs) are used to improve the efficiency of this algorithm by strengthening the lower bound on the recourse cost associated to partial routes encountered throughout the solution process. The concept of general partial routes is adapted from Jabali, Rei, Gendreau and Laporte.", :title "Route planning under uncertainty", :keyword2 95, :authors (33865 9512 2189), :session 50}, 554 {:keyword1 149, :keyword3 18, :abstract "We propose a method for forecasting intermittent demand with generalized state-space model using time series data. Forecasting intermittent demand exactly is important for manufacturers, transport businesses and retailer, because of diversification of consumer preference and small lot production of many products by the diversification. There are many models for forecasting intermittent demand. Croston's model is one of the most popular one for intermittent demand forecasting, which has many variant models, log-Croston, modified Croston and other models. However, Croston's model has inconsistency on its assumptions pointed out by Shenstone and Hyndman (2005). Additionally, Croston's model generally needs round-up approximation on the inter-arrival time for estimating parameters from discrete time-series data. We employ non-Gaussian nonlinear state space models to forecast intermittent demand. Specifically, we employ mixture of zero and Poisson distributions, because occurrence of intermittent phenomenon implies low average demand. As well as in DECOMP (Kitagawa, 1986), time series are broken down into steady, seasonal, autoregression and external terms in our model. Therefore, with ordinal maximum likelihood estimators, we cannot obtain parameters because the number of parameters excesses the number of data owing to non-stationary assumptions on parameters. Then, we adopt Beyes framework, which is similar to DECOMP. However, we employ particle filter for filtering method instead of Kalman filter in DECOMP owing to non-Gaussianness on the system and observation noises and nonlinearity in these models. To show the superiority of ours to other typical intermittent demand forecasting method, we will conduct comparison analysis using actual data in the grocery store.", :title "Forecasting intermittent demand with generalized state-space model", :keyword2 37, :authors (26181 45207 45208 45209 45210), :session 199891}, 555 {:keyword1 42, :keyword3 126, :abstract "Analytical or experimental methods can only find an optimal control strategy for technical systems with a fixed setup. To find the overall optimum, it is necassary to find the optimal control strategy for a wide variety of setups, not all of which might be obvious even to an experienced designer. We present an approach that allows one to find the optimal topology with an optimal feedback control system as a whole. This mixed-integer formulation considers and compares numerous discrete topological and continuous control options.\r\n \r\nOne example for a system with different topological and control strategy options is a filling level application: Pumps can either be used or not and they can be connected in series or in parallel. To attain different filling levels, the rotational speed of the used pumps has to be controlled. The optimum needs to balance energy efficiency against short actuation times between the load cases.\r\n \r\nWe developed an abstract model of the filling level application as a control circuit with optional elements. To accurately optimize a feedback control system one needs to account for the time-dependent behavior of its components: P (proportional), I (integration) and D (derivation), PT1, PT2 (delay of first or second order) or PTt (dead-time). We discretized the time dependence and obtained a mixed-integer formulation based on a time-expanded flow network. This allows one to include combinatorial decisions such as variation of the network topology. We are able to appraise feasible solutions using the global optimality gap. ", :title "Designing a Feedback Control System via Mixed-Integer Programming", :keyword2 158, :authors (39553 41756 41758 39554 42187), :session 106}, 557 {:keyword1 45, :keyword3 175, :abstract "In Germany, the federal states have sovereignty over the Emergency Medical Service (EMS) system. Therefore, each state has its own EMS law including different rules and specific definitions of the provided services. Each state is then divided into smaller EMS regions with a rescue coordination center being responsible for the allocation and organization of the services.\r\nEMS systems in Germany are not only responsible for emergency services but also for the transport of patients if the attendance of an emergency medical assistant is necessary. Even if many of the transportation tasks are known in advance, trips are usually not planned at present, especially not automatically. \r\nOne of the main problems in practice are the waiting times for the patients when ambulances arrive too late, but also the waiting times for the staff, if patients are not ready at the hospital when they are supposed to be picked up. \r\nWe want to show that by modeling it as a dial-a-ride problem and solving it with (online) heuristics to include short-term demands, scheduling the patient transports can be reasonable in practice. Due to cost increases and cost pressure which are typical for the healthcare sector efficient planning methods become more and more important.\r\nWe present a mathematical model and an algorithm for solving the patient transportation problem. We test these using data from a rescue coordination center located in the south of Germany.\r\nThe long-term goal is to build a platform that connects the EMS regions within a federal state. It integrates the ability to schedule patient transports between different regions to avoid empty trips on the way back.", :title "Planning the Patient Transport as Part of the German EMS System", :keyword2 95, :authors (33694 5078), :session 199936}, 559 {:keyword1 28, :keyword3 29, :abstract "With increasing shares of renewable generation, reserve power markets are expected to gain in importance. Competitively organized markets like in Germany are characterized by high prices with considerable fluctuations. Analytical investigations in a partial equilibrium framework reveal however that capacity prices should be rather low if reserve power is auctioned on an hourly basis. Numerical analyses are then used to quantify in a large European electricity market model the impact of different specifications of the reserve power products.", :title "Equilibrium pricing of reserve power", :keyword2 25, :authors (41876 24773), :session 199928}, 561 {:keyword1 133, :keyword3 42, :abstract "System Synthesis is the process of finding a combination of various components such that the resulting technical system fulfills a given purpose. Typically, the workflow is divided into two consecutive stages: first, a set-up is found by an experienced engineer or by heuristic methods. Secondly, optimization techniques are used to compute an optimal usage strategy. This usually results in an optimal operating of a suboptimal system topology. \r\n\r\nIn contrast, we apply Operations Research methods to find an optimal solution for both stages simultaneously, i.e. we find the best topology to enable the best possible usage. The composite solution is an energy-optimal or cost-optimal system.\r\n\r\nWe test our approach with a practical test case: a  booster station which is used to guarantee the water supply in multistory buildings. The system essentially consists of a combination of pumps and pressure accumulators. For a given flow and pressure demand, we are able to synthesize the best booster station, i.e. we find an optimal combination of available components and an optimal control for the used components. \r\n\r\nWith this example, we address a ubiquitous problem of Operations Research methods: Despite being able to find a provable optimal solution to a model, the modeling error often cannot be quantified. We have validated the quality of our test case model with an experimental set-up.  Thereto, we consider several load cases and compare our computational results with measurements on a test rig. \r\n", :title "Experimental Validation of an Enhanced System Synthesis Approach", :keyword2 158, :authors (41758 39553 39554 42187 41756), :session 106}, 563 {:keyword1 29, :keyword3 100, :abstract "The provision of balancing power offers additional revenue potential, especially for energy companies with a combined heat and power (CHP) plant and a heat storage. Balancing power is needed to ensure a reliable power supply as nominal frequency has to be maintained despite of unscheduled power plant outages and a volatile feed-in of renewable energies. In Germany the transmission system operator is responsible for the provision of sufficient balancing power. On the German balancing market the demand for three types of balancing power is procured in a request for proposal process. The assignment takes place on the basis of work and achievement costs. \r\nIn order to participate on the balancing market for minute reserve, municipal energy companies have to submit a bid for each hour of the following day that comprises a price and the amount of electricity at which power generation can be increased or decreased. If the bid price is lower or equal to the market clearing price, the contract is awarded to the energy company. In this case the energy company has to ensure that the needed capacity is available considering the own uncertain heat and power demand. Therefore, unit commitment of a CHP plant and a heat storage as well as capacity allocation for the balancing energy market are simultaneously optimized in our approach to support energy companies planning their bids. ", :title "Optimal operation of a CHP plant for the energy balancing market", :keyword2 48, :authors (39420 45245 10057), :session 199927}, 564 {:keyword1 28, :keyword3 0, :abstract "Since 2012, the operators of renewable energy systems in Germany can chose between different trading mechanisms. The electricity produced by renewable energies can be reimbursed according to the Renewable Energy Law (EEG). Otherwise, the new trading mechanism of direct marketing (“Direktvermarktung”) can be chosen. Direct marketing offers further possibilities for commercialization e.g. to wind park operators, as for example taking part in reserve power markets or selling the produced energy at the electricity stock exchange. The combination of a wind farm with a battery storage is particularly interesting for the direct marketing case, as an integrated wind-battery system can be scheduled in a more balanced way, alleviating natural wind power fluctuations.\r\n\r\nWe present a mathematical model that optimizes the contribution margin for two direct marketing options. We analyze a system that consists of a wind farm and a battery storage and consider the system to take part in the electricity stock exchange. We discuss adaptions of the model when additional participation at the tertiary control market is possible. As a reference for determining the profitability of investing in a storage we take an average fixed EEG compensation for wind energy. We construct a test instance for the models based on 2013 prices of the European Power Exchange and the German reserve power market as well as wind data of the transmission system operator 50Hertz. We then compare the optimal solutions to the reference case. We evaluate if the gain of an integrated wind and storage system exceeds the fixed EEG compensation such that the yearly costs for the storage can be compensated. \r\n", :title "Dispatch of a wind farm with a battery storage", :keyword2 29, :authors (41926 33694 45212 31230 22954), :session 199932}, 568 {:keyword1 98, :keyword3 86, :abstract "The Java Framework for Resource Scheduling (JFORS) is designed to support scientists to develop, implement, enhance, and evaluate solution methods (optimization algorithms) tackling Resource Scheduling Problems (RSPs). The application domain RSP includes different kinds of scheduling problems (e.g., single machine scheduling or flow-shops), lot-sizing problems, or resource constraint project scheduling problems. Basic purpose of JFORS is to enable the scientist to concentrate on the development and (performance) analysis of solution methods. Therefore, JFORS provides a comprehensive data model for all kind of RSPs, problem instances, solution methods and their parameter, objective functions and their parameter, key figures, experiments, schedules, evaluation settings, and execution settings. All these information are saved persistently in a relational database (MySQL) by the object-relational mapping framework Hibernate. JFORS itself is divided into four software components: The first component comprises basic functionalities regarding problem specification, algorithm configuration, and key figure definition. The second component provides possibilities to import and manipulate problem instances and to define experiments. The third component offers functionalities to execute experiments on the local workstation in a single or multiple threads (by using the Parallel Java Library), or remotely on a computing grid (by using the JPPF framework). Functionalities to evaluate the performance of an algorithm and to export and process the results are bundled in the fourth component. All four components provide a comprehensive user interfaces to simplify tasks like solver configuration, experiment design, or result analysis (e.g., concerning objective values, schedules, or key fig", :title "A new Java Framework for Resource Scheduling Problems", :keyword2 96, :authors (27800), :session 89890}, 571 {:keyword1 94, :keyword3 8, :abstract "In this talk, we consider knapsack problems with uncertain item weights. We are allowed to query an item to find its exact weight, where the number of such queries is bounded by a given parameter. After these queries are made, we need to pack the items robustly, i.e., so that the choice of items is feasible for every remaining possible scenario of item weights.\r\n\r\nThe central question that we consider is: Which items should be queried in order to gain maximum profit? We introduce the notion of query competitiveness to evaluate the quality of an algorithm for this problem, and obtain lower and upper bounds on this competitiveness for interval-based uncertainty. Similar to the study of online algorithms, we study the competitiveness under different frameworks, namely we analyze the worst-case query competitiveness for deterministic algorithms, and the expected query competitiveness for randomized algorithms.\r\n\r\nWe also extend this approach to Gamma-restricted uncertainties as introduced by Bertsimas and Sim. Furthermore, we present heuristic algorithms for the problem. In computational experiments considering both the interval-based and the Gamma-restricted uncertainty, we evaluate their empirical performance. While the usage of a Gamma-restricted uncertainty improves the nominal performance of a solution (as expected), we find that the query competitiveness gets worse.", :title "The Robust Knapsack Problem with Queries", :keyword2 173, :authors (29733 45216 31388 1601 45217), :session 42}, 572 {:keyword1 57, :keyword3 8, :abstract "We consider the diameter constrained minimum spanning tree problem (DMSTP) on a graph. Given an edge-weighted undirected graph, the objective is to find a minimum-weight spanning tree such that the number of edges on the path between any two nodes does not exceed a given diameter D. Several integer programming models as well as exact and heuristic solution approaches for the DMSTP have been discussed in the literature. The current state-of-the-art approach has been proposed by Gouveia, Simonetti and Uchoa in 2011 who reformulated the DMSTP as a Steiner tree problem on a layered graph. The authors showed that the layered graph approach outperformed all previous integer programming based approaches both in theory and practice. Surprisingly not much is known, however, with respect to the polyhedral structure of the DMSTP. In this work, we aim to close this gap by studying formulations in the natural space of variables, i.e, in the space of undirected edge design variables. We introduce new classes of facet-defining inequalities that are based on so-called jump inequalities. Finally, some results from computational experiments are given.", :title "A polyhedral study of the diameter constrained minimum spanning tree problem", :keyword2 42, :authors (12046 5319 22042), :session 199896}, 573 {:keyword1 156, :keyword3 0, :abstract "Rail-road transshipment yard is an important entity of intermodal transportation system. In the yard gantry cranes are used to move containers, e.g. from trains to trucks and vice versa. In practice, we often assign a fixed work area for each crane to avoid crane interferences. We aim to determine the size of the work areas to balance the workloads for all cranes, so as to minimize the makespan. To evaluate the workloads accurately it's necessary to consider the move sequence of containers, so it's required to solve a sequencing problem with setup times. Also consider arrival and departure time of trucks, we formulate this sequencing problem as ATSP with time windows and precedence relations. A exact solution procedure is provided to solve the both problems together, i.e. determining fixed crane areas and obtaining move sequences for each crane. We also generate random instances, which simulate real-world transshipment yards, to test our method. In the end, our experimental results are reported and compared to another crane area solution, which is obtained by an algorithm without considering the crane move sequences, to show the acceleration effect of our method.", :title "Crane areas and move sequences in rail-road transshipment yards", :keyword2 96, :authors (38898 35097 10954), :session 199944}, 574 {:keyword1 14, :keyword3 160, :abstract "We deliver formulae for the biconjugate functions of some infimal functions, that hold provided the fulfillment of certain regularity conditions. Moreover, we rediscover or extend different results from the literature.\r\n\r\n", :title "On biconjugates of infimal functions", :keyword2 13, :authors (20665 26152), :session 199958}, 575 {:keyword1 134, :keyword3 0, :abstract "Comparative statics is a well established research field where one\r\nanalyzes how marginal changes in parameters of a strategic game\r\naffect the resulting equilibria. While classic comparative statics is\r\nmainly concerned with qualitative approaches we aim at quantifying\r\nthe possible extend of such an effect.  We apply our quantitative\r\napproach to a multimarket oligopoly model\r\nand consider price shocks as parameter change.\r\n\r\nWe quantify the worst case profit reduction for multimarket oligopolies\r\nwith an arbitrary number of markets exhibiting arbitrary positive price shocks.\r\nFor markets with affine price functions and firms with convex cost technologies,\r\nwe show that the relative loss of any firm is at most 25% no matter\r\nhow many firms compete in the oligopoly. We further investigate the impact\r\nof positive price shocks on total profit of all firms as well as on\r\nconsumer surplus. We find tight bounds also for these measures\r\nshowing that total profit and consumer surplus decreases by at\r\nmost 25% and 16,6%, respectively. ", :title "Quantitative Comparative Statics for a Multimarket Paradox", :keyword2 40, :authors (26518 34468), :session 92}, 576 {:keyword1 6, :keyword3 40, :abstract "Loss-averse bidders face different sensations as the price clock proceeds in single-unit ascending or descending auctions. We investigate equilibrium bidding behavior of bidders with independent private values and reference-dependent preferences, applying the Köszegi and Rabin (2006) model.\r\nBidders' stochastic reference points are endogenous, and are determined by their strategy and their beliefs about the other bidders. Utility functions reflect that bidders anticipate changes in their reference point due to updated beliefs, e.g. about the own winning probability, during the course of the auction. An optimal bidding strategy can be reduced to a series of optimal binary decisions at each price (approve or quit in the EA and wait or bid in the DA).We solve for personal equilibrium (PE) profiles, which contain for each bidder a bidding strategy that is optimal given the others' bidding strategies and the reference point induced by the own and others' strategies.\r\nThere exists a range of belief-free PE profiles in the EA and a range of symmetric PE profiles in the DA under different existence conditions. The highest expected revenue in a PE profile of the DA is higher than in the EA, but the highest expected revenue in a PE profile of the EA may exceed the lowest expected revenue in the DA. The difference is mainly driven by the aversion to losing the item in the DA.", :title "Reference-Dependent Bidding in Dynamic Auctions", :keyword2 25, :authors (44894 41718), :session 76}, 577 {:keyword1 8, :keyword3 5, :abstract "Quantified linear integer programs (QIPs) are linear integer programs (IPs)\r\nwith variables being either existentially or universally quantified. They can be interpreted as\r\ntwo-person zero-sum games between an existential and a universal\r\nplayer on the one side, or multistage optimization problems under uncertainty on the\r\nother side. Solutions of feasible QIPs are so called winning strategies\r\nfor the existential player that specify how to react on moves – certain\r\nfixations of universally quantified variables – of the universal player to\r\ncertainly win the game. In order to solve the QIP optimization problem, where the task is to find an especially attractive winning strategy,\r\nwe examine the problem’s hybrid nature and combine linear programming\r\ntechniques with solution techniques from game-tree search.\r\n\r\nHere, we present the algorithmic framework of our basic solver 'Yasol', which is based upon a mixture of Alphabeta-algorithm, cutting plane techniques and boolean constraint propagation.", :title "Multistage Optimization with the help of Quantified Linear Programming", :keyword2 94, :authors (39554), :session 199877}, 581 {:keyword1 40, :keyword3 95, :abstract "We study the existence of approximate pure Nash equilibria in weighted congestion games. We develop techniques to obtain approximate potential functions that prove the existence of alpha-approximate pure Nash equilibria and the convergence of alpha-improvement steps. We show how to obtain upper bounds for approximation factor alpha for a given class of cost functions.\r\nWe demonstrate our techniques and establish the existence of approximate equilibria for specific classes of cost functions. For example for concave cost functions the factor is at most 3/2, for quadratic cost functions 4/3, and for polynomial cost functions of maximal degree d it is at at most d + 1. For games with two players we obtain tight bounds which are as small as for example 1.054 in the case of quadratic cost functions.", :title "Approximate pure Nash equilibria in weighted congestion games", :keyword2 134, :authors (45219 44469 26950), :session 8}, 582 {:keyword1 40, :keyword3 95, :abstract "We initiate the study of congestion games with variable demands in which the players strategically choose both a non- negative demand and a subset of resources. The players’ incentives to use higher demands are stimulated by nondecreas- ing and concave utility functions. The payoff for a player is defined as the difference between the utility of the demand and the associated cost on the used resources. Although this class of non-cooperative games captures many elements of real-world applications, it has not been studied in this generality in the past. Specifically, we study the fundamental problem of the existence of pure Nash equilibria, PNE for short. We call a set of cost functions C consistent if every congestion game with variable demands and cost functions in C possesses a PNE. We say that C is universally approximately consistent if every such game has the rho-Finite Improvement Property for every rho > 0. Our results provide a complete characterization of consistency and universally approximately consistency revealing that only affine and homogeneous exponential functions are consistent. En route, we obtain novel characterizations of consistency for congestion games with fixed but resource-dependent demands.", :title "Congestion Games with Variable Demands", :keyword2 134, :authors (26950 26518), :session 8}, 583 {:keyword1 143, :keyword3 17, :abstract "University production processes are hard to analyze and to simulate due to the high complexity of inputs and outputs. For example outputs can be in very different areas like teaching (graduates), research (publications, third party funding) or third mission (co-operations, transfer of knowledge). Therefore usually for an efficiency analysis, methods such as the data envelopment analysis (DEA) are used in order to adhere to the multitude of inputs and outputs. This contribution will discuss in a first step a DEA calculation for 86 German universities and universities of applied sciences with the inputs budget or number of professors and the outputs PhD, MA and BA graduates, third party funding in the science areas social/humanities, life sciences (including medicine), natural sciences and engineering (data by Statistisches Bundesamt and DFG, 2009-2012). The analysis is then in a second step used to suggest a production function model for simulation purposes. This is accomplished by including the DEA efficiency values into a regression model calculated with “R” as a dependent variable and testing several independent variables as possible explanating factors. The successfully reviewed factors in this procedure will be included in a draft for a production function for universities in order to allow for simulation of production process results in universities. Finally, the simulation results are backtested with the existing DEA dataset and therefore evaluated for their prognostic power compared to the real input and output values of the 86 listed German universities.", :title "DEA calculation for production simulation modeling with universities", :keyword2 27, :authors (35215), :session 199856}, 584 {:keyword1 156, :keyword3 40, :abstract "In this study, we propose a model of advertising competition under uncertainty of advertising effect in order to measure the influence that its effect gives in the strategies of the firm. Advertising competition is one of the dynamic marketing problems. In markets, a firm needs to take care of its own and competitors’ advertising strategies in order to maintain or improve its own market share, sales and profit. Over the past few decades, considerable studies, for example, introduced in Huang et al. (2012) have been conducted on advertising competition. In some of these studies, advertising competition is formulated as differential game models. However, advertising effect is assumed to be deterministic. In other words, it is assumed that state variables change by the actions of a firm and the competitors and do not change in other factors. \r\n\r\nPrasad and Sethi (2004) proposed the extended Vidal-Wolfe model under uncertainty of market share. However, they did not consider the uncertainty of advertising effect. Jorgensen and Zaccour (2004) mentioned the need in consideration of the uncertainty of advertising effect. It is clear that the advertising effect has uncertainty by an audience rating in the television commercial.\r\n\r\nThis paper proposes Closed-loop Nash equilibria (Markovian Nash equilibria) in a Lanchester differential game of advertising competition with uncertainty of advertising effect. In this study, we formulate that advertising effect changes over time stochastically. In addition, Closed-loop equilibira in stochastic games are satisfied with Hamilton-Jacobi-Bellman equations.\r\n\r\nIn the numerical experiments, the advertising cost and profit in our strategy are compared to those of actual data and Open-loop Nash equilibria strategy.", :title "Closed-Loop Nash Equilibria Strategy under Uncertainty of Advertising Effect in Advertising Competition", :keyword2 134, :authors (39226 26181 26404), :session 199836}, 585 {:keyword1 158, :keyword3 176, :abstract "Stackelberg Games confront contenders with opposed objectives sequentially. The Leader acts first and the Follower reacts to the Leader's strategy. The objective of the game is for the Leader to commit to a reward-maximizing strategy anticipating the Follower's best response.\r\n\r\nIn a Bayesian Stackelberg Game, which is NP-hard, the Leader faces\r\none out of a group of Followers, otherwise the game is called a Singletype-of-Follower Stackelberg Game, which is polynomial (Conitzer and Sandholm, 2006). Moreover, games in which the respective strategies of the Leader and Follower consist in covering and attacking targets are called Stackelberg Security Games.\r\n\r\nWe present novel tight formulations for the Single-type-of-Follower\r\nStackelberg Game and for the Single-type-of-Attacker Stackelberg Security Game, significantly improving the current formulations present in the literature (Paruchuri et al., 2008), (Kiekintveld et al., 2009). Further, we show that both formulations provide a complete linear description of the convex hull of the sets of feasible solutions of the corresponding problems and show that one formulation is the projection of the other on the appropriate space. The formulations presented for the Bayesian case improve the continuous relaxations of existing formulations. Computational experiments are carried out to compare our formulations with those in the literature.", :title "Novel Formulations for Stackelberg Security Games", :keyword2 40, :authors (41203 1 5426 6813), :session 199886}, 587 {:keyword1 8, :keyword3 0, :abstract "In the interval scheduling problem we are given a set of jobs (intervals), where every interval is given by a release date and a processing requirement. If an interval is accepted, it must be started at its release date. The task is to accept a maximum number of non-overlapping intervals.\r\n\r\nWe consider the following online variant of this problem. An online algorithm knows the set of intervals. However, up to k of these intervals can fail, i.e., they cannot be accepted, and an online algorithm only learns that an interval fails at the time when it is released. An optimal offline algorithm knows all failing intervals beforehand and can compute an optimal solution for the remaining intervals.\r\n\r\nWe analyze this setting by means of competitive analysis. We present competitive algorithms and provide lower bounds on the competitive ratio that can be achieved by deterministic and randomized online algorithms.", :title "Interval Scheduling with Online Failure of Jobs", :keyword2 96, :authors (36737 36955 33211), :session 199897}, 588 {:keyword1 97, :keyword3 0, :abstract "The health care supply chain, especially in developed countries, is facing 2 major challenges: First, it is a substantial cost driver in an industry under permanent cost-pressure. Second, successful supply chain practices from other industries, like retail, have not been broadly applied in health care leading to a gap in operational performance. \r\nThe application of supply chain management methods like collaborative forecasting and planning could overcome both challenges. A comprehensive model quantifying the impact of such an application is missing for the health care sector with its specific characteristics, like very high service level requirements and perishable products with limited lifetime. This paper therefore aims to quantify the impact of the application of collaborative forecasting and planning on supply chain performance in health care and to provide guidelines for a successful application in this multi-stakeholder environment. The study is based on a model simulating a 3-tier supply chain from pharmaceutical manufacturers to hospital patients. The model is fed with real-world patient demand data for multiple pharmaceuticals with different demand patterns.\r\nFurther studies aim to find mechanisms to balance the benefits of collaborative forecasting and planning between the partners of the health care supply chain.\r\n", :title "Coordinating the Health Care Supply Chain - Saving costs and improving service level through joint Forecasting and Planning", :keyword2 45, :authors (45214), :session 199858}, 589 {:keyword1 96, :keyword3 59, :abstract "As the producing industry is one of the main energy consumers, increasing energy efficiency in production processes turns out to be a key factor in the energy transition. An analysis of planning approaches for industrial energy supply systems (ESSs) shows that fixed energy demand patterns are an essential planning assumption. This assumption of fixed and unchangeable demand patterns is not necessarily valid for production processes. Instead, we assume that these demand patterns are directly related to the production schedule and thus, can be influenced by production planning. In consequence, adjusting the demand patterns offers the possibility to design and operate ESSs better and in consequence, to increase energy supply’s efficiency. The study at hand transfers potentials to increase the efficiency of ESSs into aspects (e.g., objectives or constraints) which can be integrated into short-term production planning in order to take advantage of the energy-saving potentials of ESSs. In detail, an exemplary short-term production planning approach that tackles the problem of minimizing the difference between the minimum and maximum cumulated energy demand is presented. The resulting energy demand patterns have a reduced range (defined by the minimum and maximum cumulated energy demand) and thus, the energy efficiency of the ESS can be improved. Here, we consider a scheduling problem that is defined by a parallel machine environment, whereby production orders are characterized by energy demand profiles. Because it can be shown that the problem is NP complete, we propose (beside a mixed integer linear program) an iterated greedy local search heuristic for the new scheduling problem. The solution quality of this heuristic is measured with regard to several test instances. ", :title "Improving energy efficiency by integrating energy aspects into short-term production planning", :keyword2 57, :authors (39419 27800), :session 63}, 590 {:keyword1 161, :keyword3 0, :abstract "We consider constrained combinatorial optimization problems and relax one or several of the constraints. In this way, we formulate associated multiple objective optimization problems. This allows us to analyze the trade-off between constraint satisfaction on one hand and original objective value on the other hand.\r\nAs a concrete example problem, we consider bidimensional knapsack problems (i.e., one objective and two knapsack constraints) and their associated biobjective, single-constraint knapsack problems. A dynamic programming based solution approach is adapted to compute the nondominated set of the transformed problem or a subset of it. It is shown that a representation of the nondominated set is obtained at little extra cost as compared to the solution of the original problem. In this context we discuss strategies for bound computation and for handling negative cost coefficients, which occur through the transformation.", :title "Transforming Constraints into Objectives:A  Biobjective Solution Method for Solving Bidimensional Knapsack Problems", :keyword2 156, :authors (45220 8883 1560 53033), :session 199834}, 592 {:keyword1 96, :keyword3 151, :abstract "In this paper, we investigate two robust makespan scheduling problems. In a considered robust approach we are given a scenario set which contains a constant number of distinct cost vectors which describes possible realizations of each element cost. The objective is to find a solution that minimizes the cost under the worst possible scenario, called Min-Max cryterion. The first considered problem is a Min-Max Makespan Scheduling Problem (Min-Max Pm||Cmax) in which the task is to partition the jobs into m subsets, each of which is scheduled on one machine. The objective is to minimize the biggest completion time under worst case scenario (makespan). The problem is equivalent to the know Vector Scheduling Problem. In the latter one, Min-Max Flow Shop Scheduling Problem (Min-Max Fm||Cmax), each job consists of m operations each of which is processed sequentially by a different machine. The problem consists in finding a permutation of jobs. The objective is once again the worst scenario makespan. In this paper we prove that a simple merging rule can reduce the number of jobs in any instance of the both considered problems to a constant depending only on \\eps. Additionaly we prove that the optimal solution of a reduced instance does not differ from the original one by more than a 1 + O(\\eps) factor. As a consequence we provide a Polynomial Time Approximation Scheme for both problems. The running time of the algorithm is linear in the number of jobs which improves the best known result. The second result of the paper is the Competitive Ratio Approximation Scheme for the online counterpart of the considered problems. Such a scheme algorithmically constructs an online algorithm with a competitive ratio arbitrarily close to the best possible competitive ratio for a given problem.", :title "Approximation Schemes for Robust Makespan Scheduling Problems", :keyword2 94, :authors (33437), :session 199878}, 594 {:keyword1 65, :keyword3 40, :abstract "Many important networks, most prominently the Internet, are not designed and administrated by a central authority. Instead, such networks have evolved over time by (repeated) uncoordinated interaction of selfish agents which control and modify parts of the network.  The Network Creation Game [Fabrikant et al. PODC'03] and its variants attempt to model this scenario. In these games, agents correspond to nodes in a network and each agent may create costly links to other nodes. The goal of each agent is to obtain a connected network having maximum service quality, i.e. small distances to all other agents, at low cost.\r\n\r\nThe key questions are: How do the equilibrium networks of these games look like and how can selfish agents actually find them? For the latter, recent results on the dynamic properties of the sequential version of these games will be surveyed. For the former, ongoing work focussing on structural properties is presented.", :title "Selfish Network Creation - Dynamics and Structure", :keyword2 42, :authors (42734), :session 199885}, 595 {:keyword1 96, :keyword3 8, :abstract "The policy of low inventories along the automative supply chain leads from the viewpoint of an automative supplier to a high number of customer demands and material supplies from his suppliers. The huge amount of possible car configurations results at the suppliers stage in a high product variety for one functional component. In order to fulfill customer demands and to cope with the variety of the own product portfolio the need for efficient production scheduling arises. We consider the case that the variations of the component are assembled on a single machine with sequence-dependent setup times. Moreover the components can only be produced if enough materials are available. The objective is high production efficiency, measured by a schedules' total weighted completion time. In order to obtain lower bounds on the objective, the problem is decomposed into a master problem and several subproblems. The decomposition exploits the presence of precedence chains among the jobs and yields a partition of the job set. For every set of jobs out of this partition a subproblem is defined. In this talk we present different possibilities to define the subproblems as well as several classes of valid inequalities for the master problem. Therefore, a set of lower bounds can be obtained by applying a column generation approach on different compatible combinations of master and subproblem formulations. These bounds are tested on a variety of test instances and first computational results are presented.", :title "Lower Bounds based on decompositions for a single machine scheduling problem with sequence-dependent setup times and inventory constraints", :keyword2 150, :authors (29640 14800), :session 199876}, 596 {:keyword1 175, :keyword3 101, :abstract "Electric drivetrain technologies play an important role for delivery fleets in light of constantly rising fuel prices and steadily tightening CO2 emission and urban air quality legislations. \r\nIn this study, we assess the total cost of ownership (TCO) of electrifying a delivery fleet in inner city districts over a ten-year operating life. For the electrification, two battery technologies (ZEBRA, Li-Ion) are used that differ, among others, in capacity and thus coverage, price, and durability. Along with direct vehicle costs, we also consider indirect vehicle costs, such as installation and operating expenses of the charging infrastructure, and environmental costs (life-cycle analysis, LCA). Empirical data are taken from a field trial of Deutsche Post DHL in Bonn, where delivery is characterized in particular by a high number of stopovers and stop-and-go traffic. TCO of the electric delivery fleet are compared with that of a diesel-powered delivery fleet.\r\nEvidently, the results vary according to battery technology. TCO of the electric drives are found to be 190-210% higher than those of a diesel-powered fleet. However, intelligent battery charging strategies, smart charging networks, charging algorithms that prolong battery durability, and vehicle-to-grid (V2G) technologies reduce TCO of electric drives by 8-9%. Sensitivity analyses of factors with the strongest causalities reveal at which point cost efficiency is attained. In fact, only under the premises of falling manufacturing and battery costs, rising diesel prices, and the adoption of V2G models, electric delivery vehicles will become economically viable. Advancement of battery technologies and battery size optimization will improve economic efficiency further.\r\n", :title "Electrification of Postal Delivery Fleets: A Cost-based Analysis of Competing Battery Technologies and Charging Strategies", :keyword2 174, :authors (44928 21108), :session 199920}, 597 {:keyword1 6, :keyword3 0, :abstract "This paper characterizes the complete set of full-information Nash equilibria of a class of sealed-bid combinatorial auctions. This class contains the Vickrey auction, bidder-optimal core-selecting auctions, and the pay-as-bid auction as well as any other core-selecting auction. The characterizations for particular auctions are simple and intuitive, and allow for straightforward comparisons between auctions. All of the Nash equilibria of the pay-as-bid auction are Nash equilibria of every bidder-optimal core-selecting auction, and all of the latter's equilibria are also equilibria of the Vickrey auction. This paper also analyzes the possible equilibrium outcomes - assignments, payments, and payoffs - of these auctions. Any assignment and payments that generate individually rational payoffs are the result of some Nash equilibrium of the Vickrey auction and of every bidder-optimal core-selecting auction. We provide a necessary and sufficient condition for an outcome to result from an equilibrium of the pay-as-bid auction. This condition is stricter than individual rationality but still allows payoffs outside of the core. We consider extensions of the auction games to address the seller's incentives, the impact of budget constraints, and the implementation of the tie-breaking rule.", :title "Nash Equilibria of Sealed-Bid Combinatorial Auctions", :keyword2 40, :authors (41718 41719), :session 100}, 598 {:keyword1 61, :keyword3 0, :abstract "For more than two years, the Karlsruhe Institute of Technology and the University of Augsburg have been teaching a course on modeling with ILOG CPLEX Optimization Studio in cooperation with IBM. The course complements existing theoretical bachelor courses on mathematical programming. In the course, students get a detailed introduction into the elements of OPL and learn how to efficiently model, implement and solve real-world optimization problems. \r\n\r\nThis course is now being rolled out to other universities and complemented by a textbook. The textbook will cover the content of the course, and will also serve as a tutorial on optimization programming with the Optimization Programming Language (OPL). \r\n\r\nIn the talk, we give an overview of the content of the textbook and show how the course can successfully be included into existing study programs. Furthermore, we give details on the official certification process, through which successfull students can get an IBM certificate.", :title "Modeling with IBM ILOG CPLEX - An IBM-certified course and textbook", :keyword2 27, :authors (33695 5078 16305 33694), :session 199884}, 599 {:keyword1 158, :keyword3 150, :abstract "The capital-constrained net present value problem consists of scheduling several project activities subject to completion-start precedence and capital constraints such that the net present value of the cash flows of the activities is maximized. Doersch and Patterson (1977) discuss a mixed-integer linear programming formulation (MILP). Despite improvements in optimization software and computer hardware, nowadays such formulations are applicable to small-sized problem instances only.\r\n\r\nWe present a heuristic method that combines mixed-integer linear programming with a network-based decomposition. The heuristic consists of two phases: In the first phase, the project network is decomposed into subsets of activities. In the second phase, these subsets of activities are iteratively added to the partial schedule, applying an exact MILP formulation. Thereby, we do not fix the starting times of the activities which have already been scheduled, but we allow a time window in which the activities can be shifted when inserting new activities to the partial schedule. A major advantage of such MILP-based heuristics is the flexibility to account for additional constraints or modified planning objectives. Our computational results indicate that the heuristic is able to devise optimal solutions to non-trivial problem instances, and outperforms the MILP of Doersch and Patterson (1977).", :title "An MILP-based Heuristic for the Capital-Constrained Net Present Value Problem", :keyword2 86, :authors (45211 125), :session 199870}, 601 {:keyword1 40, :keyword3 0, :abstract "Network creation games have been extensively studied, both from economists and computer scientists, due to their versatility in modeling individual-based community formation processes, which in turn are the theoretical counterpart of several economics, social, and computational applications on the Internet.\r\nHowever, the generally adopted assumption is that players have a common and complete information about the ongoing network, which is quite unrealistic in practice. We consider a more compelling scenario in which players have only limited information about the network they are embedded in. More precisely, we define a suitable equilibrium concept and we explore the game theoretic and computational implications of assuming that players have a defective view of the network.", :title "Network Creation Games with Incomplete Information", :keyword2 42, :authors (45224), :session 39}, 603 {:keyword1 170, :keyword3 0, :abstract "Beam search is a tree search procedure where, at each level of the tree, at most W nodes are kept. That results in a meta-heuristic whose solving time is polynomial in both W and the number of variables as long as node selection is decided in polynomial time.\r\n\r\nAlthough popular for solving single-objective problems (mostly scheduling-related ones), beam search has been studied for multi-objective optimization by two teams so far. The approaches have three fundamental components in common: branching scheme, variable selection and node pruning. Authors do not analyze influence of the branching scheme on solution quality. Regarding the decision rule for selecting the variable to branch on at each tree-node, they notice a strong influence on the quality. Pruning the nodes in polynomial time is made in various ways. Our work studies those three components and explains their influence. Relying on theoretical grounds, we advice their design and show that specificities due to the multiplicity of objectives must be regarded. In particular, we clearly divide the node pruning process into two phases, respectively node quality evaluation and node selection, whose desirable properties are identified and refined individually through empirical processes.\r\n\r\nAt last, those versatile considerations are applied to the bi-objective Knapsack Problem and the bi-objective Traveling Salesman Problem with Profits. Thus, the benefits from our guidelines are shown component by component. The so-obtained Knapsack solver outperforms the previous dedicated beam search of literature. The TSP results will allow authors for future comparisons.", :title "Beam Search for integer multi-objective optimization", :keyword2 63, :authors (33154 20539 19001 10538), :session 199834}, 604 {:keyword1 102, :keyword3 29, :abstract "The rising energy demand of rapidly developing countries, such as China, has to be met with a fast expansion in electricity generation capacity. As electricity generation from fossil fuels is linked to environmental pollution, capacity expansion is increasingly governed by the paradigm of sustainability. Small hydropower plants (SHPs) cater to the principle of sustainable development by beneficial effects such as poverty alleviation in underdeveloped rural regions resulting from the provision of affordable electricity or the associated reductions in greenhouse gas emissions. Impacts both on the environment and the society nearby, however, are adversely connoted in sustainability considerations.\r\n\r\nDecision making on design, location and management issues of SHPs, with a view to increase the sustainability of projects, poses a multi-dimensional problem, to which many scholars apply methods from operations research, in particular multi-criteria analysis. A review of the pertinent literature yields two insights. First, sustainability lacks a clear-cut definition giving room to a plethora of approaches and virtuous sets of criteria. Second, authors focus either on existing SHPs, or on planning new SHPs. Yet an assessment for sustainability of SHPs needs to grasp all relevant impacts in an integrated manner. Therefore, this contribution draws up a methodology applicable to ex-ante as well as ex-post assessments of SHPs based on a review of existing applications and methods and it derives a catalogue of sustainability criteria for evaluating SHPs.\r\n", :title "Sustainability Assessment of Hydropower Plants: A Review of Applications and Methods", :keyword2 18, :authors (45202 33421 45225 45226), :session 199934}, 605 {:keyword1 98, :keyword3 0, :abstract "Optimization is a small but essential element of many applications. Thus the capability to interact with other systems is a key design principle of GAMS - not just a superficial check on the feature list. With its open architecture, powerful modeling language and integrated state-of-the-art solvers, GAMS provides you the best tools to develop and seamlessly integrate optimization models into various environments without locking you into a particular solution. During this workshop we will illustrate these design principles in GAMS and show how they contribute to the success of several commercial and academic applications.", :title "Design Principles that make the Difference", :keyword2 0, :authors (14853), :session 89890}, 611 {:keyword1 39, :keyword3 0, :abstract "Over the last decade, the installed peak power of PV-plants in Germany has significantly increased from 1 GW in 2004 to over 36 GW in 2014. The majority of photovoltaic plants are connected to the distribution grid. Photovoltaics are subject to large fluctuations in their power generation because of changing weather conditions. Therefore, distribution system operators (DSOs) are confronted with greater problems to prevent the overload of grid components and to keep the voltage range within admissible constraints. In recent years, DSOs normally reacted to those new challenges with conventional grid expansion by increasing cable cross-sections, laying parallel cables and increasing the power capacity of transformers. This may result in expensive and inefficient grid expansion. A solution might be the integration of solar energy storages in private households and the active peak power reduction at the grid connection point of the household. By using conventional operating strategies, solar energy storages are often fully charged when the power generation from photovoltaics is at its maximum at midday. Therefore, peak shaving is not possible and the PV-plant wattage has to be controlled. By optimizing the charge/discharge mode of solar energy storages with a fuzzy control system, the peak power generation from photovoltaics and therefore, the required grid expansion on the low voltage level can be reduced. In this study, the design and implementation of a fuzzy control system is developed considering the current power generation, the charging level of the battery and the solar forecast. First high-resolution simulations on a 1-min time scale show the high potential of the fuzzy control system to minimize the feed-in management.", :title "The Integration of Solar Energy Storages in Distribution Grids Using a Fuzzy Control Algorithm", :keyword2 29, :authors (42979 24622), :session 63}, 612 {:keyword1 61, :keyword3 57, :abstract "The IT industry is currently undergoing a major shift, away from traditional standalone applications, to new platforms such as servers, clouds, tablets, and mobile phones. We will demonstrate a new server-based version of the MPL OptiMax Component Library, that makes implementing real-world optimization applications a relatively quick and easy process. We will take you through all the steps of implementing optimization projects, including formulating the model, integrating it seamlessly with data in different formats, and then finally deploying the project on a server for servicing both web and mobile clients, using standard programming languages, such as CSharp, Visual Basic, Java, C/C++, or Python.", :title "Deploying MPL Optimization Models Online on Servers and Mobile Platforms", :keyword2 98, :authors (3843), :session 199883}, 613 {:keyword1 61, :keyword3 159, :abstract "MPL is a modeling system that allows the model developer to efficiently formulate complicated optimization models. We will demonstrate some real-world MPL models that have been formulated as web-based applications using the MPL OptiMax Component Library. A Portfolio Optimization model will be explored and shown how it can be iterated to produce a trade-off curve (Efficient Frontier) between the Return and Risk. A Vehicle Routing application with multiple vehicles and depots. We will also demonstrate a Nurse Rostering application with multiple contract rules and objective criterias.", :title "Real-world Optimization Models Formulated and Deployed as Applications using MPL OptiMax", :keyword2 98, :authors (11248), :session 96}, 614 {:keyword1 36, :keyword3 109, :abstract "The evolution of 3D-printing and its applications in sectors such as medicine, culture, manufacture etc. Leads to notable changes in our daily life. 3D-printing and its implications at production chain, is the main research question of this study. As known, production chain is the procedure of transforming raw materials into goods. Planning, manufacturing, selling, are some of the main steps in this chain. Recently, the above steps are being restructured. Products are designed and then are just printed and sold. Storage cost or cost from unsold products is eliminated. 3D-printing is a rapid, customized and low cost production. The speed and the low cost are also associated with the sense of reproduction. After designing the prototype of a product, is easy to reprint it in small or big quantities. The problem of suppling small markets is solved by 3D-printing, as these markets could be served without enabling manufacture companies to warehouse or produce goods with large cost. The customized production is associated with the ability to make small or big changes into product’s prototype i.e. In color, in size, in scheme without cost, and satisfy customers’ needs in a more efficient way. The goal of this study is to examine how the production chain is being transformed, which steps are changing, which steps are being replaced and which new steps are being added. Managing incoming orders, mapping the production procedure, redefining the suppliers, reconsidering the selling points (how the consumers receive the products), pricing these new products, are some issues under examination in this paper.", :title "\"3d-printing\" redesigns the procedure of planning,  manufacturing and selling goods", :keyword2 75, :authors (19731), :session 199851}, 615 {:keyword1 96, :keyword3 153, :abstract "This paper discusses a re-entrant permutation slow shop scheduling problem with missing operations. The two considered objective functions are makespan and total throughput time. Re-entrant flows are characterized by the multiple processing of jobs on one or more machines. The reasons for a re-entry of a job can be, e.g., rework or process-related. Each re-entry is starting the job on a new production level. After giving an overview on recent literature on re-entrant scheduling problems, we introduce two possibilities to represent the job sequence for a re-entrant permutation flow shop problem with missing operations. Because the problem is NP-hard, we propose a heuristic for solving the problem. We chose the Variable Neighborhood Search (VNS), since there have been promising approaches in literature on other scheduling problems. This meta-heuristic framework combines the advantages of local search algorithms and tries to avoid getting stuck in local optima. The initial solution for the VNS is obtained by a dispatching rule. A hill climbing algorithm has been implemented as the integrated local search method of the VNS. The VNS is compared to a MIP formulation from literature and one from earlier work of us. The computational results show, that the VNS delivers better objective values for larger problems, if the computation time for the solution methods is limited to one hour. As well we show for what problem sizes the VNS is applicable and what measures could be taken to make it applicable to even larger problem sizes. ", :title "A Variable Neighborhood Search for a Re-entrant Permutation Flow Shop Scheduling Problem", :keyword2 59, :authors (36412 37980), :session 199846}, 616 {:keyword1 8, :keyword3 99, :abstract "Two important characteristics encountered in many real-world scheduling problems are heterogeneous processors and a certain degree of uncertainty about the sizes of jobs. In this paper we address both, and study for the first time a scheduling problem that combines the classical unrelated machine scheduling model with stochastic processing times of jobs. Here, the processing time of jobs on machines is governed by independent random variables, and their realization become known only upon job completion. We study the objective to minimize the expected total weighted completion time. By means of a novel time-indexed linear programming relaxation, we compute in polynomial time a non-anticipatory scheduling policy with performance guarantee arbitrarily close to 3/2+D/2. Here, D is an upper bound on the squared coefficient of variation of the processing times. When jobs also have individual release dates, our bound is 2+D. We also show that the dependence of the performance guarantees on D is tight. Notably, via D=0 the currently best known bounds for deterministic scheduling on unrelated machines, 3/2 and 2 respectively, are contained as a special case.", :title "Unrelated Machine Scheduling with Stochastic Processing Times", :keyword2 96, :authors (1019 22814 1835), :session 199917}, 617 {:keyword1 48, :keyword3 75, :abstract "This paper draws attention to assembly line balancing problem in which workers have been assigned to teams in advance inspiring from the assembly lines with multi-manned work stations differing from conventional ones. Team-oriented assembly line balancing is the problem to assign tasks to multi-manned workstations while satisfying some constraints. Most researches about the team-oriented assembly line balancing problems are focused on the conventional industrial measures that minimizing total worker, number of multi-manned workstations or both. But in real life problems, workload density has an  important role for the ergonomic measures. So, a mathematical model that combines the minimization of multi-manned stations and difference of physical workload of workers is proposed. ", :title "A New Design Team-Oriented Assembly Line Balancing Problem", :keyword2 96, :authors (36725 45230), :session 199846}, 618 {:keyword1 173, :keyword3 8, :abstract "The facility location problem involves locating facilities in potential sites, and determining the best strategy for communications between facilities and clients. The objective of the facility location problem is to open a subset of facilities, and assign service from facilities to each client such that the total sum of setup cost and connection cost is minimized. During the past decades, there has been a considerable amount of research on the facility location problem and its variations in the operations research community. \r\n\r\nTo cope with real-world applications in which constraints and requirement of the facility location problem appear in different scenarios, the problem can be formulated in various ways. A facility cannot often afford all kinds of service due to complexity and cost, especially in a large-scale network. Moreover, each client may have different types of demand requirement. In this study, we investigate the multiservice facility location problem, which finds applications to distribution network design. Each facility has the ability to provide at most p kinds of distinct service for clients, while each client is associated with different demand requirement from the p services. The goal is to select a subset of facilities and to identify its corresponding service assignment to clients such that the demand requirement of each client can be satisfied, and the total cost, including the facility setup cost, service cost and connection cost which is usually measured by the metric distance between facilities and clients, is minimized. Note that the optimal placement of such distinct but cooperative facilities is very different from that of identical facilities. We attempt to explore approximation hardness and develop algorithms for solving the problem.\r\n", :title "The Multi-service Facility Location Problem", :keyword2 151, :authors (45227 45258 45223), :session 199900}, 619 {:keyword1 96, :keyword3 18, :abstract "Railway crew scheduling deals with generating duties for train drivers to cover all train movements of a given timetable. The common objective is to minimize the overall costs associated with a crew schedule, such as workforce costs, hotel costs, etc. \r\n\r\nIn reality, a cost minimal schedule often shows an uneven distribution of unpopular duties among crew districts. As an example, overnight rests, which are typically unpopular among drivers, might be assigned to one crew district only. This situation is commonly perceived as unfair and corresponding crew schedules are only badly accepted among employees.\r\n\r\nTransferring results from stationary contexts, we define and measure unpopularity and (un)fairness in a railway crew scheduling context. We show how to best integrate fairness conditions into a column generation based solution algorithm. Our method has been applied to real-world test instances from a large European freight railway carrier. For our test scenarios, we could significantly improve schedule fairness, while schedule cost and solution runtime were only marginally affected.\r\n", :title "Fairness considerations in railway crew scheduling", :keyword2 175, :authors (23505 45329 14573), :session 28}, 620 {:keyword1 44, :keyword3 0, :abstract "A multicriteria group choice problem is considered, it includes: a set of feasible decisions; a vector criterion reflecting general goals of group of decision makers (DMs); asymmetric binary relations of decision makers (DM), which reflect individual preferences. Individual preferences are given by “quanta” of information, which indicate compromise between two components of vector criterion: for the sake of getting profit on one component of criteria (more important) the DM is ready to lose some value on other component (less important). Each DM’s preference relation is a cone relation, and is characterized by convex pointed cone, which contains nonnegative orthant and does not contain the origin. The majority preference relation is considered: one decision majority dominates another if for at least half group of DMs the first decision is preferred to another (by the DM’s preference relation). It is proved that such majority relation is a cone relation, and its cone, in general, is not convex. The property of convex is equivalent to transitivity of corresponding relation. The goal is to construct a convex part of the majority preference relation cone, and it gives the transitive part of this relation. The case of group of three DMs and three components of criteria is considered. It is given such information: 1) for DM1 first criterion is more important than the second, and the second criterion is more important than the third; 2) for DM2 the second is more important than the third, and the third is more important than the first; 3) for DM3 the third is more important than the first, and the first is more important than the second. It is shown how to specify the convex part of majority preference relation cone, and construct the set of nondominated vectors.", :title "Multicriteria group choice using the majority preference relation based on cone individual preference relations", :keyword2 63, :authors (45067), :session 199841}, 623 {:keyword1 91, :keyword3 158, :abstract "Consider a network where there are two types of arcs: a subset of arcs is owned by a company imposing tolls for using them, and a subset of remaining arcs which are toll-free. Furthermore, toll arcs are connected such that they constitute a single path, as it occurs for instance in a highway network. The company is willing to maximize the revenue from tolls, whilst users seek for their minimum cost path between their origin and destination. This problem is strongly NP-hard and can be modeled as a bilevel program.\r\n\r\nWe propose a Dantzig-Wolfe reformulation for this problem, and show that the linear relaxation is stronger than the MILP formulation proposed in the literature. The subproblem is non linear but easily solvable.\r\nMore advanced techniques have been included in our column generation algorithm, as initialization alternatives, stabilization of dual variables values and early stopping criteria.\r\nFurthermore, we propose a full Branch-and-Price scheme to solve the integer problem, with an ad-hoc branching algorithm using pseudo-costs to guide the choices. An SOS branching scheme has also been proposed. Some rounding heuristics have been investigated to improve the primal bound during the branching.\r\nFinally the framework has been extended to a branch-and-cut-and-price, including some efficient valid inequalities from the literature.\r\nNumerical experiments have been run under the SCIP framework.", :title "A Branch-and-Cut-and-Price Algorithm for the Network Pricing Problem with Connected Toll Arcs", :keyword2 8, :authors (30379 1 5426), :session 199832}, 627 {:keyword1 163, :keyword3 96, :abstract "Within power grids, supply and demand need to be matched at all times. This is traditionally done by using flexibility in supply to match demand. However, this methodology is less viable in future power girds due to an increasing share of inflexible generation from renewable sources such as wind and sun. Thus flexibility to match supply and demand needs to be sought elsewhere. \r\nIt is expected that in the future an increasing amount of flexibility is available on the demand side of electricity, mainly in the form of appliances that store energy in some form or manner. Examples of such appliances are electrical vehicles, heat pumps combined with heat buffers and fridges. Demand Side Management (DSM) methodologies often attempt to schedule these appliances locally based on a steering signal send by a global controller. The local controllers use these steering signals to determine an optimal schedule for their appliances.\r\n The local schedule generated by the local controller is thus an important step within the realization and analysis of DSM methodologies. To this end we study a two-fold steering signal consisting of both a time-varying price and a target profile. We model the local minimization objective as a weighted sum of the total cost of the consumed energy and the squared deviation from the target profile. The minimization is done subject to local constraints implied by the appliance. We study the structure of the derived optimization problems and use them to obtain efficient algorithms that solve the optimization problems to optimality.  ", :title "Local device scheduling for demand side management using two types of steering signals", :keyword2 126, :authors (39330 8513 39404), :session 68}, 628 {:keyword1 94, :keyword3 8, :abstract "Minmax regret optimization aims at finding robust solutions that perform best in the worst-case, compared to the respective optimum objective value in each scenario. Even for simple uncertainty sets like boxes, most polynomially solvable optimization problems have strongly NP-hard minmax regret counterparts. Thus, heuristics with performance guarantees can potentially be of great value, but only few such guarantees exist.\r\nA very easy but effective approximation technique is to compute the midpoint solution of the original optimization problem, which aims at optimizing the average regret, and also the average nominal objective. It is a well-known result that the regret of the midpoint solution is at most 2 times the optimal regret. Besides some academic instances showing that this bound is tight, most instances reveal a way better approximation ratio.\r\nIn this talk we consider a new lower bound for the optimal value of the minmax regret problem. Using this lower bound we state an algorithm that gives an instance dependent performance guarantee of the midpoint solution for combinatorial problems that is at most 2. The computational complexity of the algorithm depends on the minmax regret problem under consideration;  we show that the sharpened guarantee can be computed in polynomial time for several classes of combinatorial optimization problems.", :title "Minmax Regret: Improved Analysis for the Midpoint Solution", :keyword2 151, :authors (42017 29733), :session 199878}, 629 {:keyword1 75, :keyword3 101, :abstract "We consider a tactical planning problem which integrates production planning decisions together with order acceptance decisions, while taking into account the dependency between workload and lead times. \r\nThe planner needs to decide which orders to accept and the period in which each accepted order should be produced. If an order is accepted, it generates revenue, incurs production and inventory costs, and affects the production lead time. The more orders are accepted, the higher is the workload and production lead time resulting in the possibility of missing due dates. If an order is rejected, a lost sale cost occurs. \r\nThe problem is formulated as a mixed integer linear program and solved using an efficient Lagrangian relaxation heuristic that is based on decomposing the problem into efficiently solvable sub-problems. Numerical results show that the proposed Lagrangian heuristic outperforms a relax-and-fix heuristic and a state-of-the-art solver, providing very small gaps between the obtained lower and upper bounds within reasonable CPU times.\r\n", :title "Production Planning with Order Acceptance and Load Dependent Lead Time", :keyword2 157, :authors (45231 19188 4565), :session 199849}, 630 {:keyword1 40, :keyword3 134, :abstract "We study matching games and stable matchings with different forms of local constraints. In our model, each player is a node in a fixed matching network and strives to be matched to another player. Each player has a complete preference list over all other players it can be matched with but depending on the constraints and the current state of the game not all potential matching partners are available at all times. For the constraints we concentrate on the well studied cases of locally stable matching and friendship matching as well as considerate stable matching and socially stable matching, but additionally give results for a way broader class of matching games with local constraints in the case of correlated preferences. We focus on convergence of dynamics to stable states (regarding the local constraints) but also give insights on the relationships between the different types of constraints. Further we analyze maximum stable matchings and prove that unlike for the setting without constraints for all our settings computing the size of a maximum stable matching is NP-hard and further hard to approximate within a factor of 1.5-epsilon.", :title "Uncoordinated Matching Markets with Local Constraints", :keyword2 172, :authors (45057 41376), :session 19}, 631 {:keyword1 44, :keyword3 42, :abstract "In several multiobjective decision problems Pairwise Comparison Matrices (PCM) are applied to evaluate the decision variants. The problem that arises very often is inconsistency of given PCM. In such\r\na situation it is important to approximate the PCM with a consistent one. The most common way is to minimize the Euclidean distance between the matrices. In the paper we consider minimization of the maximum distance. After applying the logarithmic transformation we are able to formulate obtained subproblem as Shortest Path Problem\r\nand solve it more efficiently. We analyze and completely characterize the form of the set of optimal solutions and provide an algorithm that results in a unique optimum regardless the initial conditions.", :title "Deriving Priorities From Inconsistent PCM using the Network Algorithms", :keyword2 63, :authors (30400), :session 199840}, 632 {:keyword1 104, :keyword3 63, :abstract "The purpose of this study is to propose a mathematical model that has ability of solving a multi-objective optimization problem for a telecommunications bandwidth broker who acquires and sells bandwidth under uncertain market environment. The model seeks for two important goals: maximizing expected profit and minimizing expected loss capacity with some constraints such as backbones' capacity and the Quality of Service (QoS) expectations of end-users’. The presence of vagueness and randomness of information makes applying the fuzzy set theory and stochastic programming techniques more convenient to deal with the non-deterministic nature of telecommunication network setting. The proposed model simultaneously considers the randomness in demand and determines the allocation of end-users' bandwidth requests into acquired capacity. In the solution phase of the model, max-min, weighted additive and weighted max-min fuzzy operators are used in order to solve resulting probabilistic linear programming model. To evaluate the effectiveness of suggested model, well-known measure of uncertainty effect, the value of the stochastic solution is modified and used. Randomly generated test scenarios are tested and results are obtained to provide managerial insights to decision makers. It is observed that proposed model provides more profit, satisfaction ratio and less capacity loss compared to deterministic methodology. It is shown that increasing uncertainties (increasing number of scenarios and variance) makes fuzzy stochastic approach more attractive for decision makers over deterministic approach. Moreover, it is concluded by extensive computational experiments that solution qualities in terms of satisfaction ratio, profit and capacity loss varies under different fuzzy operators", :title "A Stochastic Multi-objective Backbone Selection and Capacity Allocation Problem under Different Fuzzy Operators", :keyword2 39, :authors (45233 19359), :session 199837}, 635 {:keyword1 53, :keyword3 29, :abstract "In order to achieve the climate protection targets of the European Commission increased use of renewable energy sources (RES) is vital. As these exhibit an unsteady availability, future power systems will require technologies able to shift the available energy either in space or time. Such technologies include demand-side-management (DSM), transmission systems and electricity storages while in times of low renewable feed-in flexible power plants such as gas turbines and combined cycle power plants are required. \r\nTo analyse such aspects in scenarios for the time horizon 2050 with high shares of RES, we have established a combined dispatch and investment model determining required storage and exchange capacities as well as capacities of thermal power plants at minimum economic costs. This linear optimization problem (LP) is constrained to meet the energy demand in each country and every hour of the year. Furthermore, it has to comply with the technology specific restrictions.\r\nGenerally, wind and solar energy as well as energy from run-of-river are taken into account as an hourly time series for each country. These time series are generated in an exogenous step based on detailed geographical and meteorological data and (together with the scenario assumptions for energy demand and DSM) they yield the residual load.\r\nSensitivities examined include two different RES mixes, delayed grid expansion, increased costs for CO2-emissions and a reduced utilization of DSM.\r\nThe scenario with reduced DSM utilization results in the highest storage demand for Germany while in the other scenarios energy supply is mainly ensured just as well by capacity expansions of combined cycle power plants and gas turbines by extensions on cross-border interconnectors.", :title "A European Dispatch and Investment Model for Determining Cost Minimal Power Systems with High Shares of Renewable Energy", :keyword2 7, :authors (45234 45340), :session 94}, 639 {:keyword1 18, :keyword3 31, :abstract "In the future, the usage of fossil fuels must be reduced in order to ensure supply security as well as projected emission savings within the transportation sector. One option for achieving these targets is the substitution of fossil fuels by biofuels. When using biofuels the occurrence of negative social side-effects has to be observed. Those social side-effects include the competition of biofuels with the food/fodder production as well as the appearance of land use change (direct/indirect). To avoid land use change the minimization of life cycle emissions of the fuel sector is not sufficient, as the emissions polluted by the biofuel production (especially from the 2nd generation) are still below those of fossil fuels including land use change emissions. Thus, we develop a three-objective, multi-period optimization model, considering cultivation of biomass, production of biofuels, import of biofuels and biomass, as well as blending of fuels. Our aim is to identify Pareto-efficient solutions and to derive trade-off relations for political decision makers regarding profit maximization, emission minimization, and land use change minimization.\r\nTo calculate the efficient frontier of the three-objective MILP we use the augmented epsilon-constraint approach. To estimate the optimal solutions of existing political regulations according to ecological, economic and social targets lexicographical ordering is used. The model is applied to a case study of the German (bio)diesel market and the existing political regulations are analyzed to derive implications and recommendations for political decision makers.", :title "Developing a decision support framework to regulate the fuel / bio-fuel sector under consideration of economical, ecological and social objectives", :keyword2 63, :authors (32283 2650), :session 199934}, 642 {:keyword1 133, :keyword3 0, :abstract "A methodology is presented for the design of distributed energy supply systems exploiting the near-optimal solution space. Distributed energy supply systems are integrated systems incorporating a multitude of technical units. The design of these systems is intrinsically complex and challenging. For this reason, the design should best be addressed by mathematical optimization. Usually, optimization-based design methods aim at generating the mathematically optimal solution for a given problem. However, the mathematical models employed never perfectly represent the real world. Thus, the optimal solution also only approximates the optimal real-world solution. For this reason, the optimum alone is of limited use to the design engineer in practice.\r\n\r\nIn this paper, a design approach is presented, which supports the engineer through the generation of a set of near-optimal solution alternatives. These alternatives can be evaluated in more detail a posteriori. The near-optimal solutions are generated systematically by sequentially solving a series of optimization models, each extended by an integer-cut constraint to exclude already known solutions.\r\n\r\nAnalyzing a real-world problem at the industrial scale, we reveal a rich near-optimal solution space with structurally very different solutions that exhibit similar objective function values. Considering the many constraints and uncertainties arising in practice, it is practically impossible to rank the generated solutions strictly based on a single objective function value. Instead, the near-optimal solutions should be employed to support the design process by emphasizing the “must-haves” and the differences of the generated solutions, i.e., the rational choices.", :title "Design of distributed energy supply systems  through analysis of near-optimal solutions", :keyword2 158, :authors (45235 45242 45065), :session 94}, 644 {:keyword1 40, :keyword3 173, :abstract "This talk is about computing the Shapley value in matching games.\r\nMatching games constitute a fundamental class of cooperative games which help understand and model auctions and assignments. In a matching game, the value of a coalition of vertices is the weight of the maximum size matching in the subgraph induced by the coalition. The Shapley value is one of the most important solution concepts in cooperative game theory. \r\nAfter establishing some general insights, we show that the Shapley value of matching games can be computed in polynomial time for some special cases: graphs with maximum degree two, and graphs that have a small modular decomposition into cliques or cocliques (complete k-partite graphs are a notable special case of this). The latter result extends to various other well-known classes of graph-based cooperative games.\r\nWe continue by showing that computing the Shapley value of unweighted matching games is #P-complete in general. Finally, a fully polynomial-time randomized approximation scheme (FPRAS) is presented. This FPRAS can be considered the best positive result conceivable, in view of the #P-completeness result.", :title "Shapley meets Shapley", :keyword2 151, :authors (45236), :session 199888}, 647 {:keyword1 18, :keyword3 73, :abstract "Demographic change as well as the introduction of a new compensation system based on diagnostic related groups lead to a demand shift for hospital inpatient care in Germany. Thus, hospital capacity has to be adapted for hospital sites and medical specialties to adapt to these new conditions. In Germany, strategic planning of inpatient care lies within the responsibility of the federal states, and is often executed with a limited regional scope in a rather hands-on approach by planning committees staffed with representatives of health insurances and hospital operators.\r\n\r\nAgainst this background, a strategic planning approach is developed to increase the effectiveness and efficiency of hospital planning for the four medical specialties of inpatient primary healthcare. For this purpose, we develop an ILP, which simultaneously determines the location and number of hospitals, the medical specialties offered by each hospital, and the capacity per medical specialty (expressed by the number of beds). Furthermore, the model ensures the accessibility of inpatient primary healthcare for the entire population, while minimizing the overall number of hospitals and medical departments within a region.\r\n\r\nWe apply our model to the case study of North Rhine-Westphalia where the federal government has recently enacted a new legislative framework indicating a reduction of the overall number of hospital beds by over 12 % (excluding psychiatry and geriatrics).", :title "Strategic planning of coverage for inpatient primary healthcare", :keyword2 45, :authors (45141 2650), :session 77}, 651 {:keyword1 34, :keyword3 35, :abstract "After the financial crisis 2007-2009, supervisory authorities endorsed more comprehensive stress testing frameworks. For many risk types, usually, model-based stress tests are carried out by banks. Taking credit risk as an example, the scenario of a severe macroeconomic downturn has to be translated into the corresponding changes of credit risk parameters. These stressed risk parameters are needed for computing the regulatory and economic capital requirements in the assumed stress scenario.\r\nAs the results of other quantitative risk management tools, stress test results are prone to model and estimation risk. Surprisingly, the discussion of these issues in the context of stress tests is relatively sparse in the literature. This paper contributes to this discussion in the specific field of credit risk stress tests.\r\nBased on the credit portfolio model CreditPortfolioView, we show how model and estimation risk can influence the stressed default probabilities and, hence, the regulatory economic capital requirements. Starting from a base case model, we analyze, among others, the impact of the usage of different methods for making the data stationary, lagged variables in the regression equation for the macroeconomic index and different time series models for the explaining risk factors. Furthermore, we show how degrees of freedom with respect to the choice of the stress scenario can influence the results.\r\nAlthough the analyzed specifications satisfy all statistical and econometrical demands, we find that stressed default probabilities and regulatory capital requirements can vary significantly. This shows the vulnerability of the employed stress test to model and estimation risk and calls for extensive robustness checks of stress test results.", :title "Model and estimation risk in quantitative credit risk stress tests", :keyword2 93, :authors (45240 26182 45248), :session 199963}, 653 {:keyword1 75, :keyword3 174, :abstract "Innerhalb der Wochenprogrammfüllung, einem Teilprozess der Wochenprogrammplanung in der Automobilindustrie, werden Aufträge der jeweils aktuellen Planungswoche so zugeordnet, dass die Werkskapazitäten bezogen auf Auftragsvolumen möglichst ausgelastet werden. Hierbei ist eine Vielzahl von Restriktionen, wie z.B. die verfügbaren Kapazitäten für Montage oder der Lieferanten zu berücksichtigen. Die zugrundeliegende Aufgabe ist ein ganzzahliges Optimierungsproblem, bei dem Aufträge unter Berücksichtigung der genannten Restriktionen und Zielen gewählt werden müssen. In der Praxis sind die Ziele meist nicht allein durch die geschickte Auswahl der Aufträge zu erreichen. Deshalb wird in einem aufwendigen Abstimmungsprozess zwischen Logistik und Vertrieb versucht, notwendige Restriktionsanpassungen zu ermitteln und umzusetzen.\r\nIn diesem Betrag wird ein „Programm-Füllungs-Assistenzsystem“ vorgestellt, dass für einen deutschen Automobilhersteller entwickelt wurde. Das Logistische Assistenzsystem ermöglicht es die Einplanung zu simulieren und die notwendigen Restriktionsanpassungen zu bestimmen. Auf dieser Basis unterstützt das Assistenzsystem den iterativen Prozess der Wochenprogrammfüllung zwischen den beteiligten Bereichen. Die eingesetzte Heuristik nutzt für die Einplanung eine Bewertung der Aufträge auf Basis der durch lineare Extrapolation prognostizierten verfügbaren Kapazitäten. Dieses Vorgehen mindert die Gefahr, dass Restriktionen frühzeitig kritisch werden. Restriktionen werden automatisch angepasst, falls dies notwendig und erlaubt ist. Durch dieses Vorgehen sinkt der Planungsaufwand deutlich, während die Ergebnisqualität steigt. Das vorliegende Paper stellt das Assistenzsystem, die Heuristik und Ergebnisse aus der Praxis vor.", :title "Programm-Füllungs-Assistenzsystem", :keyword2 96, :authors (45241 45246 45247), :session 199854}, 654 {:keyword1 104, :keyword3 65, :abstract "With the increasing demand for Internet and cloud computing services, the need for large scale data centers has become paramount. In these data centers, switched Ethernet networks are becoming popular, because of the way they effectively manage traffic. Their topology must be cycle-free, to avoid broadcast radiation. Therefore, Ethernet networks only activate, at a given time, a subset of the existing links that must verify the IEEE 802.1d standard, which defines the topology of the sub-network as a spanning tree. \r\nOne of the drawbacks of this protocol is that the network only ends up using a small  number of the existing links. To overcome this, Ethernet networks began using the Multiple Spanning Tree Protocol, which\r\nmaintains a set of spanning trees that are used for routing the traffic demands in the network. This is highly advantageous for the traffic performances of Ethernet networks, as the traffic can be spread throughout a bigger number of links. We present different mixed integer programming models for the Traffic Engineering problem of optimally designing a network implementing the Multiple Spanning Tree Protocol, such that link utilization is minimized. Although some variants of this problem have been treated in the literature, this is the first approach that focuses on using exact methods. We present tests in order to compare the formulations, in terms of linear relaxation strength and computing time. We also propose a binary search algorithm that has proven to be efficient in obtaining quasi-optimal solutions for this problem.", :title "Models for traffic engineering with multiple spanning tree protocols", :keyword2 158, :authors (40500 1 5319), :session 199898}, 655 {:keyword1 14, :keyword3 0, :abstract "We state necessary conditions for coercivity of a multivariate \r\npolynomial involving the vertex set of its Newton polytope. We also \r\ndiscuss the issues around proving the sufficiency of these conditions.", :title "Coercivity of Multivariate Polynomials in Terms of Their Newton Polytopes", :keyword2 162, :authors (31866 2795), :session 199960}, 657 {:keyword1 92, :keyword3 18, :abstract "The energy production of renewable energy sources is an essential mean to stop the consequences of climate change. In Germany, the installed capacity of photovoltaic (PV) steeply increased over the last years due to subsidies provided by the government. Considering the lifetime of PV modules of 25 – 30 years, the related amount of PV waste will increase during the next decades. Thus, PV modules have been integrated into the WEEE directive in the year 2012. In order to fulfil the WEEE recycling and recovery quotas, it will be sufficient to recover the fractions with the highest mass, i.e. glass and frame. However, it could be reasonable to recover other rare materials, like silver, copper, tellurium or indium, due to evolving scarcity of certain resources and limited availability of primary resources in Germany. The necessary technologies are still in the development or pilot stage. \r\nAgainst this background, the aim is to develop a strategic planning approach in order to analyse the early installation of appropriate collection and recycling infrastructures with special focus on future resource criticalities. In order to do so, a multi-periodic MILP is developed regarding capacity, technology and location decisions for collection and recycling of PV modules. Decisions are evaluated with regard to economic aspects. Additionally, information on resource criticalities derived from criticality indicators is integrated. By using resource price scenarios and subjective probabilities for the scenarios, the model evaluates the effects of resource criticality for economic decisions in recycling network planning. A case study illustrates the approach and its results.\r\n", :title "Strategic network planning of recycling of photovoltaic modules", :keyword2 65, :authors (45239 2650), :session 199933}, 658 {:keyword1 28, :keyword3 0, :abstract "Overview\r\nThis presentation deals with uncertainties in electricity markets, especially on the balancing markets. Thereby, forecasting quality plays an important role in this context, as shorter lead time leads to better forecasts. Shorter contract durations on the balancing market would reduce the costs for providing balancing energy and would lower barriers for market entry. To measure the efficiency gain of shorter contract duration in balancing markets, an optimization model is applied to the German electricity system. Thereby, day-ahead and markets for balancing energy are modelled in detail.\r\nMethods\r\nA Stochastic mixed integer linear optimization model minimizing total system costs is applied. Uncertain parameters are the renewable feed-in. The time series are generated with an ARMA and/or SARIMA approach. Under these uncertainties the balancing commitment are optimized. Based on these commitments a second model is used, where the need of control energy is modelled as stochastic component. With this two-stage model approach, the influence of different balancing market design options are analysed concerning effectivity.\r\nResults\r\nWith shorter contract duration time \r\na)\tcosts for providing balancing energy decrease,\r\nb)\tnumber of market participants increase significantly and\r\nc)\trenewable energy sources have an incentive to participate in the markets for balancing energy.\r\nHigher volatility of day-ahead market prices intensifies the above mentioned effects.", :title "UNCERTAINTIES IN THE BALANCING MARKETS FOR ELECTRICITY - BARRIERS FOR RENEWABLE ENERGY SOURCES ", :keyword2 165, :authors (45164 14876), :session 55}, 660 {:keyword1 42, :keyword3 0, :abstract "This paper considers the k-sink location problem in dynamic path networks. In our model, a dynamic path network consists of an undirected path with positive edge lengths, uniform edge capacity, and positive vertex supplies. Here, each vertex supply corresponds to a set of evacuees. Then, the problem requires to find the optimal location of k sinks in a given path so that each evacuee is sent to one of k sinks. Under the optimal evacuation for a given k-sink location, there exist k-1 vertices such that each one represents the boundary dividing all evacuees between adjacent two sinks into two groups, i.e., all supplies in one group evacuate to the left sink and all supplies in the other group evacuate to the right sink. We call such k-1 vertices (k-1)-divider. Therefore, the goal is to find k-sink location and (k-1)-divider which minimize the maximum evacuation time or the total evacuation time for all supplies, which are denoted by the minimax problem and the minisum problem, respectively. We study the k-sink location problem in dynamic path networks with continuous model, and prove that the minimax problem can be solved in O(kn) time and the minisum problem can be solved in O(n^2 min{k, 2^{{logkloglogn}^(0.5)}}) time, where n is the number of vertices in the given network. Note that these improve the previous results by Y. Higashikawa, M. J. Golin, and N. Katoh, ``Multiple Sink Location Problems in Dynamic Path Networks’’, Proc. AAIM 2014 (to appear).", :title "Improved Results on Multiple Sink Location Problems in Dynamic Path Networks", :keyword2 54, :authors (45244 45256 3297), :session 199916}, 662 {:keyword1 95, :keyword3 174, :abstract "This paper studies a variant of the Vehicle Routing Problem with Soft Time Windows (VRPSTW) inspired by real world distribution problems. Soft time windows constraints are\r\nvery common in the distribution industry, but quantifying the trade-off between routing cost and customer inconvenience is a hard task for practitioners. There is not consensus among scientists on how to model time windows violations and on how to weight time windows violations and routing costs. We therefore develop an alternative interpretation of soft time\r\nwindows constraints. \r\nIn our model, practitioners impose a minimum routing cost saving (to be achieved with respect to the hard time windows solutions) and to minimize solely the customer inconvenience. We propose two exact algorithms based on branch-and-cut-and-price method. The first algorithm is based on standard branch-and-cut-and-price and uses an embedded relaxation procedure. The second algorithm uses concepts of bi-objective optimization and is based on a bisection algorithm.\r\nOur computational experience provides\r\nan extensive comparison among the results obtained with our variants and those obtained by imposing hard and soft time windows constraints. The performance of the algorithm is also discussed.", :title "Exact algorithms for the vehicle routing problem with soft time windows", :keyword2 8, :authors (19625 24917 518), :session 50}, 663 {:keyword1 149, :keyword3 48, :abstract "In the automotive industry, managing inventory is both critically important and highly complex. The cost associated with keeping a sufficient number of vehicles in inventory is significant. At the same time, depending on vehicle segment and geographical market, a sizable share of the customer base expects to be able to purchase a vehicle without having to wait for it to be built. Not having the right vehicles in inventory can also be costly.\r\n\r\nA complicating factor in inventory management is the fact that the typical product complexity (in terms of uniquely different buildable configurations) is measured in the billions or even many orders of magnitude higher. In other words, it is physically impossible to keep every possible configuration of a given vehicle model in inventory.\r\n\r\nIn this presentation we will present a few recent topics in inventory management at Ford of Europe, where mixed-integer optimization techniques were employed to improve the overall inventory management. Particular emphasis will also be on the challenges that one often encounters in practical business applications: production constraints, organizational and timing constraints, data fusion from different sources, communication with non-mathematically minded business partners, confounding factors in the evaluation of final results, etc.\r\n", :title "Inventory Optimization at Ford of Europe", :keyword2 158, :authors (45140 45253), :session 25}, 664 {:keyword1 161, :keyword3 0, :abstract "Given a set N of feasible points of a multi-objective optimization (MOO) problem, the search region corresponds to the part of the objective space containing all the points that are not dominated by any point of N. We consider an alternative representation of the search region by a set of tight local upper bounds (in the minimization case) that can be derived from the points of N. Determining efficiently such local upper bounds is a crucial issue when designing methods for generating or approximating the nondominated set. We present several equivalent definitions of local upper bounds and show their usefulness in MOO. The existence of local upper bounds is supported by a first incremental approach which eliminates redundancies among local upper bounds. We also study some properties of local upper bounds, especially concerning the issue of redundant local upper bound, that give rise to an incremental approach which avoids such redundancies. Finally, we bound the worst case number of local upper bounds and discuss computational experiments that compare the practical efficiency of the presented approaches. ", :title "On the representation of the search region in multiple objective optimization", :keyword2 0, :authors (45215 1560 2279), :session 199837}, 665 {:keyword1 94, :keyword3 0, :abstract "Robust optimization incorporates uncertainties in the formulation of optimization models and hedges against these uncertainties by minimizing the worst case of all possible outcomes. Different concepts of what is seen as robustness are presented in the literature.\r\nMulti-objective optimization, on the other hand, considers multiple objectives and investigates solution techniques for calculating efficient solutions, i.e., solutions whose objective vector is not dominated in the objective space.\r\nSince handling uncertainties and multiple objectives is necessary for many real world applications, combining robust and multi-objective optimization is of high practical and theoretical interest.\r\n\r\nIn this talk, we present several concepts of robustness for uncertain multi-objective optimization problems, some of which are extensions of classical concepts of robustness for single objective optimization problems while others are new concepts developed specifically for the multi-objective setting.\r\n\r\nNamely, we present the concepts of minmax, highly, flimsily, and lightly robust efficiency as well as the concept of lower set less ordered efficiency.\r\nWe motivate the different concepts by pointing out which strategy a decision maker follows by choosing each of the respective concepts.\r\n\r\nFurthermore, we investigate relationships between the concepts and shortly present algorithms for calculating robust efficient solutions.\r\nMost of these algorithms are based on well-known solutions techniques for calculating efficient solutions to deterministic multi-objective optimization problems, such as the weighted sum scalarization and epsilon-constraint method.\r\n\r\nFinally, we illustrate the concepts on a practical example.", :title "Robustness concepts for uncertain multi-objective optimization problems", :keyword2 161, :authors (31388 1601), :session 87}, 670 {:keyword1 95, :keyword3 59, :abstract "Districting is the problem of grouping small geographic areas, called basic areas, into larger geographic clusters, called districts, subject to a number of relevant planning criteria. \r\n\r\nIn this talk we will focus on practical problems in the context of sales districting. In this application a basic area corresponds to a customer location and a district corresponds to the area of responsibility for one sales person. Three important planning criteria are balance, compactness and contiguity. Balance describes the requirement for districts to have approximately the same size with respect to the workload or sales potential. A district is said to be geographically compact if it is closely and firmly packed together. Compact districts reduce the sales persons’ unproductive travel time. Contiguity means that it is possible to travel between the basic areas of a district without having to leave the district.\r\n\r\nThe main idea of our solution approach is to recursively subdivide the problem geometrically into smaller and smaller subproblems until an elementary level is reached, at which point we can efficiently solve the problem. To subdivide a problem into two subproblems, we first determine two parallel lines L1 and L2, such that the set of all basic areas to the left (right) of L1 (L2) already comprises a balanced subproblem. In order to obtain compact districts, we then assign sequentially each basic area between these lines to its closest subproblem. In that way, we are also able to consider network distances, although we use a geometric approach. Tests on real-world data confirm the efficiency of this approach and the quality of the solutions obtained. \r\n", :title "Geometric Approaches for Districting Problems", :keyword2 174, :authors (39383 12140 5078), :session 199946}, 671 {:keyword1 127, :keyword3 0, :abstract "Investments decisions in electricity markets are complex problems. With technical\r\nlifetimes of power plants that extend over 30 years, long time periods have to be\r\nregarded when determining the value of an investment. Naturally, this value is subject to\r\nuncertainty – which is one of the characteristics of a real investment. Besides\r\nuncertainty, two other aspects characterize real investments: Investments are not or only\r\npartially reversible and the time for an investment decision is to some extent flexible.\r\nLiterature suggests treating real investments like American-style call options, whose\r\nvalue can be determined via the Black-Scholes model. In the field of energy economics\r\nthere exists a broad application of real-option models, e.g. Fleten (2007) or Kumbaroğlua\r\n(2008). While many models focus on stochastic processes such as Brownian motions to\r\nmodel the electricity prices, in this paper an approach is presented where hourly prices\r\nare forecasted based on existing power plants and expected future investments.\r\nTo analyze investments in electricity markets an agent-based model for the German\r\nmarket area is chosen, where the generation companies represented by supply agents,\r\ndetermine individually if and when to build a new power plant. Each supply agent\r\nforecasts fundamental based hourly day-ahead market prices for the year a new power\r\nplant could be operated for the first time. To account for uncertainties underlying the\r\ninvestment such as fuel prices, a recombining tree for each investment option is created.\r\nEach node of the tree contains for each year the expected hourly profit margins based\r\nthe volatility of the margins of past of the years.", :title "An agent-based model for investment decision in electricity markets", :keyword2 28, :authors (45250 25688 9973 22954), :session 65}, 672 {:keyword1 22, :keyword3 0, :abstract "One of the main problems relief teams face after a natural or man-made disaster is how to plan rural road repair work tasks to take maximum advantage of the limited available financial and human resources. Previous research focused on speeding up repair work or on selecting the location of health centers to minimize transport times for injured citizens. In spite of the good results, this research does not take into account another key factor: survivor accessibility to resources.\r\n\r\nIn this paper we account for the accessibility issue, that is, we maximize the number of survivors that reach the nearest regional center (cities where economic and social activity is concentrated) in a minimum time by planning which rural roads should be repaired given the available financial and human resources. This is a combinatorial problem since the number of connections between cities and regional centers grows exponentially with the problem size, and exact methods are no good for achieving an optimum solution. \r\n\r\nIn order to solve the problem we propose using an Ant Colony System adaptation, which is based on ants' foraging behavior. Ants stochastically build minimal paths to regional centers and decide if damaged roads are repaired on the basis of pheromone levels, accessibility heuristic information and the available budget. \r\n\r\nThe proposed algorithm is illustrated by means of an example regarding the 2010 Haiti earthquake, and its performance is compared with another metaheuristic, GRASP.", :title "An Ant Colony System adaptation to deal with accessibility issues after a disaster", :keyword2 59, :authors (4413 2529 45252), :session 199830}, 676 {:keyword1 54, :keyword3 65, :abstract "Recently, lots of low-cost carrier(LCC) company have founded and get popularization as new airline style.  In Japan \"Peach Co.\" started business as LCC in 2012. However, it is true that some companies is suffering from a slump in business. To found new LCC company, considering airline networks is the most important to success. Therefore, in this research, we propose a mathematical model to optimize both airline network, number of flights, and the number of airplanes for maximize new LCC's profit supposing hub-spoke system. To calculate the solution, we incorporate the real data of LCC's revenue and cost to calculate profit. We consider freight and incidental business revenue for revenue. Next, airport setting-up expense, sales administrative expense, expense for holding airplanes, fuel expense, employment expense, and some other expense are contained in cost. There are also some constraint; the significant one is flight time restriction. \r\nWe used the \"record of transportation\" which Ministry of Land, Infrastructure, Transport and Tourism published. In addition, for calculating each cost, we used actual airline's profit-and-loss statement because particular cost item is written on there. \r\nIn this research, Narita Airport and other top 15 airports are set as proposed airports. Out of these 16 airports, top 6Airport which include Narita and Kansai International will become hub airport. \r\nWe use Wolfram Mathematica9 for calculating optimization problem. First, we calculated the case of single-hub problem. The result is that the profit became maximum when Narita is set as hub airport.  Next, we considered the case of 2-hub problem. There are 15 pairs of hub airport. As a result, Narita-Kansai International pair became maximum. Top four pairs were related to Narita Airport", :title "Optimal Airline Networks, Flight Volumes, and the Number of Crafts for New Low-cost Carrier in Japan", :keyword2 175, :authors (43221 9690), :session 199940}, 677 {:keyword1 86, :keyword3 96, :abstract "Classical project scheduling is based on the assumption of a fixed project structure. However, since this assumption is too strict for many practical applications, several models have been introduced to cope with flexibility in project networks. Against this background we present a different approach which has been motivated by aircraft maintenance. Here the extensive maintenance procedure of an aircraft (especially of the aircraft engines) can be regarded as a project. A special feature of aircraft maintenance is given by the possibility to exchange components between different aircrafts. In this way additional working time caused by faulty components can be transferred between different aircrafts, making it possible to reduce ground time of aircrafts. In a first step towards capturing this situation we define so called \"insertion networks\": Here the nodes are partitioned in several classes only one of which corresponds to a set of \"normal\" activities. Each of the other ones, say class i, represents positions on which a certain number of activities of type i have to be inserted. The objective is to find an insertion of the activities which minimizes the makespan of the network. At first we study the case without resource constraints. In contrast to critical path method, our problem turns out to be strongly NP-hard even after dropping the resource constraints. However, for a special case we present a polynomial time algorithm based on computing maximum Sperner families. In a second step we include resource constraints and discuss how to adapt RCPSP algorithms to our problem.", :title "Flexible project scheduling motivated by aircraft maintenance", :keyword2 2, :authors (45169), :session 199872}, 678 {:keyword1 42, :keyword3 65, :abstract "In the network creation game with n vertices, every vertex (a player) buys a set of adjacent edges, each at a fixed amount C. It has been conjectured that for C more or equal n, every Nash equilibrium is a tree, and has been confirmed for every C more than 273*n. We improve upon this bound and show that this is true for every C at least 65*n. To show this, we provide new and improved results on the local structure of Nash equilibria. Technically, we show that if there is a cycle in a Nash equilibrium, then C has to be smaller than 65*n. Proving this, we only consider relatively simple strategy changes of the players involved in the cycle. We further show that this simple approach cannot be used to show the conjectured upper bound \"C is less than n if a cycle may exist in Nash equilibrium\", but conjecture that a slightly worse bound \"C less than 1.3*n\" can be achieved with this approach. Towards this conjecture, we show that if a Nash equilibrium has a cycle of length at most 10, then indeed C is less than 1.3*n. We further provide experimental evidence suggesting that when the girth of a Nash equilibrium is increasing, the upper bound on C obtained by the simple strategy changes is not increasing. To the end, we investigate the approach for a coalitional variant of Nash equilibrium, where coalitions of two players cannot collectively improve, and show that if C is at least 41*n, then every such Nash equilibrium is a tree.", :title "Tree Nash Equilibria in the Network Creation Game", :keyword2 40, :authors (45254 19047 45257), :session 39}, 680 {:keyword1 29, :keyword3 157, :abstract "The task of planning photovoltaic (PV) power plants is very challenging, due to several degrees of freedom and constraints. The decision makers have to consider the local weather conditions, the area topography, the physical behavior of the technical components and many more complex aspects. Currently, engineers often make decisions only based on their personal experience and with rules of thumb. But the problem is far too complex to be solved with simple rules. Hence, in most cases this process results in suboptimal solutions.\r\n\r\nWe present an approach for optimizing one variant of the way routing problem for PV plants. These ways are needed for site access during construction and maintenance and must be placed under certain restrictions. Mathematically, our problem is: Given the area polygon and the ways’ angle (orientation), choose feasible positions for the ways by placing corresponding parallel stripes, so that the space available for placing PV tables in the polygon is maximized. This space is given by certain parallelograms in the polygon between the ways.\r\n\r\nIn our solution concept, we discretize the problem and regard the angle of the ways as fixed. Then we formulate the problem as an Integer Program (IP) which can be solved by standard solvers. In addition, we reformulate the IP as a maximum independent set problem on interval graphs. This graph-theoretic problem can be solved in polynomial time. Using the latter approach, we are able to generate a variety of solutions with different angles for the ways with little effort of time. This enables us to also analyze the effect of different angles.\r\n\r\nSummarizing, we present a time efficient, exact solution approach for dealing with a complex problem which is motivated by an industrial optimization task.  ", :title "Optimized Pattern Design for Photovoltaic Power Stations", :keyword2 48, :authors (31952 45292 15433 16873 33487), :session 199929}, 681 {:keyword1 45, :keyword3 0, :abstract "Providing high quality emergency medical services (EMS) and ensuring accessibility to these services for the general public is a key task for health care systems. Given a limited budget, available resources, e.g., ambulances, have to be used economically in order to ensure a high quality coverage. Demographic changes, increased traffic volume and structural modifications in the urban infrastructure lead to permanent changes in EMS demand. In particular, the developments in the urban infrastructure include modifications of the road-network, the provision of developing areas and the incorporation of neighboring cities including the centralization of EMS. An appropriate EMS infrastructure (number and positions of stations) and configuration of the EMS system (number, positions and relocations of ambulances) is needed to ensure an adequate coverage and high service quality. Most approaches in literature dealing with strategic location and resource planning neglect the consideration of the initial state of EMS systems and possible future structural changes. In contrast, the presented approach identifies an optimal adaptation process, i.e., an enhancement of the existing EMS system to meet future requirements. This adjustment takes into account the existing EMS infrastructure and future developments in a dynamic manner, while respecting the EMS quality criteria. Tactical decisions are included into strategic planning and are combined with strategic decisions in order to stabilize the EMS system advancement against environmental changes. A linear multi-criteria program is developed and solved using a weighted sum approach. It supports EMS decision makers to dynamically improve an existing with respect to multiple requirements during a strategic time horizon.", :title "Optimal adaptation process of Emergency Medical Services systems in a changing environment", :keyword2 54, :authors (32309), :session 199936}, 682 {:keyword1 8, :keyword3 0, :abstract "Checking the feasibility of bookings belongs to the key tasks in gas pipeline operation. The customer orders a booking, that means a maximal in- or output of gas, at a node on the underlying gas network. The gas transportation company has to decide whether to agree to the booking or not. In its most basic form, they have to be able to sent all balanced nominations within the bookings on the exits and entries through the network.\r\nA vector of gas input at entries and output at exits together with allowed pressure intervals for all nodes is called a nomination.\r\nDue to special agreements with customers it is possible that the nomination consists of power intervals at some exits or entries.\r\nIn this talk a method is presented to generate nominations for given bookings to decide whether the booking is feasible or not.", :title "Building Nominations for Real World Gas Transportation Problems", :keyword2 162, :authors (24343 14736 33505), :session 106}, 683 {:keyword1 127, :keyword3 29, :abstract "The progress of the transformation of the German energy system is connected with challenges in the mobility, warmth and electricity sector.\r\nEspecially the volatile production of renewable electricity from windmills and photovoltaic systems leads to new obstacles regarding to grid stability. The two obvious alternatives are balancing electricity supply and demand with storage and conversion technologies or compensating local peaks with an expanded grid. Both options lead to high investments and cause rising electricity prices. This, and the environmental destruction of grid expansion lower the acceptance of additional renewable energy generation capacities.\r\n\r\nThis impact can be reduced through a better geographical and temporal link between electricity demand and renewable energy generation. This objective can be achieved by regional electricity markets as steering mechanism between independent producing and consuming agents. \r\n\r\nThe demand side of this regional market consists of perfectly price inelastic agents (e.g. TV, illumination) and price elastic agents (e.g. electric vehicle, wash-dryer, heat generation and battery). As well the supply side consists out of perfectly inelastic agents (e.g. photovoltaic systems and windmills) and elastic agents (e.g. cogeneration units, batteries).\r\n\r\nThis paper describes a model of rational agent behavior based on marginal costs and game theory. The presented approach leads to a market equilibrium suiting to the challenge of grid stability. \r\n\r\nThe presented research allows to develop and evaluate business models for (partial-) off grid systems and the prediction of economic rational agent behavior within them.\r\n\r\n", :title "Steering of Small Scale Electricity Consumer and Producer Behavior using Regional Electricity Markets – A Quantitative Model", :keyword2 28, :authors (19100 45218), :session 65}, 684 {:keyword1 151, :keyword3 0, :abstract "We discuss precedence constrained knapsack problems (PCKP) and some extensions which are of high theoretical and practical interest for example in portfolio optimization. Let us consider the following portfolio optimization problem: We are given a fixed budget and a set of assets which may be included in the portfolio. Each asset has a cost and an arbitrary, non-negative utility, for example projected profits, associated. The optimization problem seeks for a portfolio, that is, a set of assets, with maximal utility such that the budget constraint is met. In the presence of precedence constraints, some assets may only be included in the portfolio if a set of preceding assets was also selected.\r\nThe additional restriction of precedence constraints often appears in practice, for example in real estate markets. Buying a single object may be expensive at low projected profit, however, buying an entire street block might enable us to design highly profitable building complexes. An intuitive extension of this problem has to ensure multiple budget constraints which might arise for legal reasons.\r\nWe present the first approximation algorithms for PCKP in the presence of arbitrary precedence constraints for both, single and multiple budget constraints. In either case, the result is tight in the sense that the approximation algorithm may in fact output a solution meeting our approximation guarantee, which, interestingly, is independent of the number of budget constraints. The approximation algorithm uses a novel linear programming relaxation of PCKP which exploits the structure of the underlying precedence constraints and hence might be of independent interest. Finally, we show that there is no polynomial-time approximation scheme for PCKP under standard complexity assumptions.", :title "Primal-Dual Algorithms for Precedence Constrained Covering Problems", :keyword2 0, :authors (45232 45195 6626), :session 199917}, 685 {:keyword1 174, :keyword3 175, :abstract "In this paper we study a variant of the vehicle routing problem with time windows (VRPTW) in which the fleet consists of battery electric vehicles (BEVs). Because of the limited range of BEVs and a low-developed infrastructure of charging stations the energetic feasibility of vehicle routes must be focused in models and algorithms. This includes the state of charge as well as possible mid-tour recharging stops. This contribution contains a branch-and-price approach where the subproblem consists of an elementary shortest path problem with resource constraints (ESPPRC). The ESPPRC is characterized by the common resource constraints (cost, time, load, customer visits) and is extended by energy feasible paths. Therefore possible recharging stops along a path are included in a labeling algorithm which is used to solve the subproblem. We present several aspects concerning our approach, discuss results and outline further work.", :title "A branch-and-price approach for a vehicle routing problem with optional mid-tour recharging stops", :keyword2 95, :authors (33557 33284 14909), :session 5}, 686 {:keyword1 91, :keyword3 0, :abstract "In this talk, we consider order acceptance and scheduling decisions in a multi-stage assemble-to-order production system facing stochastic demand. We take a revenue management approach based on bid prices to make these decisions. Revenue management applications in production systems commonly take an aggregated view of capacity. We investigate the appropriateness of this approach. The resulting production plans are evaluated using a detailed simulation model of the production system. We propose an approach that computes bid prices based on a detailed multi-stage production model. Additionally, parameters are updated using data from the simulation.", :title "Revenue management in a  multi-stage ATO production environment", :keyword2 96, :authors (37762 4229 10255 14225), :session 101}, 687 {:keyword1 39, :keyword3 18, :abstract "So far path-dependency in interfirm-networks haven't been covered in literature in depth and we lack in the evaluation with real-options in this field of interest both in an uncertain and in a fuzzy environment at all.\r\nBy regarding networks as sequence of single investments, in financial theory well known option-pricing theory can be applied to this type of organization. For the determination of change in value of a network-entrance by emerging path-dependency, a fuzzy approach will be used for evaluation and thus giving decision support. For this purpose, a fuzzy version of the Datar-Mathews evaluation model will be applied to interfirm-networks, once with and once without considering path-dependent processes. The use of the Datar-Mathews approach first relaxes the stringent assumption of evaluation via an escapist riskless market interest rate. Instead, according to network-specific characteristics and in relation to the exercise date of the examined options, differentiated interest rates are used for a more realistic evaluation. In addition, the effects of arising path-dependency on the payoff distribution and, hence, the corresponding realoption-value of a project, here the network entrance, can be examined by applying a fuzzy methodology. Thereto, we can use fuzzy numbers and intervals on the one hand, linguistic variables on the other hand. Fuzzy numbers and intervals are employed for arithmetical calculation, linguistic variables for rule-based determination of the respective option-value. Whereat, the corresponding fuzzy factors can refer to all determinants of the option-value (e.g. cashflows, scenario probabilities).\r\n", :title "Evaluating path-dependency in networks – a fuzzy realoption approach", :keyword2 42, :authors (42931 2651), :session 15}, 688 {:keyword1 29, :keyword3 0, :abstract "In order to reduce greenhouse gas emissions, the expansion of renewable energy sources in the European power system is strongly promoted. Especially the intermittent feed-in of wind power and photovoltaic plants increases significantly and will result in high temporary surpluses of electrical energy. Thus, short- and long-term energy storages are required in the future power system. A promising option for long-term storage is the transformation of electrical energy into hydrogen or methane using Power-to-Gas technology (PtG). The produced gas can then be stored in the natural gas infrastructure. This way PtG couples the power with the natural gas system and an evaluation of the impact of PtG requires a combined simulation of both systems. \r\nIn this paper, a simulation method for the European power and natural gas system based on an optimization approach is introduced. The mathematical formulation of the problem represents a minimization of total costs subject to the coverage of demand and reserve requirements as well as the observance of technical constraints. Due to the problem complexity, especially because of binary decisions and non-linearities resulting from restrictions of thermal power and PtG plants, a closed-loop optimization is not practicable. Therefore, the introduced method consists of a multi-stage optimization with the use of Lagrangian Relaxation and decomposition techniques. After the presentation of the mathematical model and the technical implementation, exemplarily results for a future scenario of the European power and natural gas systems are shown in this paper. The following evaluation of the results focusses on the robustness of the developed method as well as the computational time. Finally, an outlook on future method enhancements is given.", :title "Simulation of the System-Wide Impact of Power-to-Gas  Energy Storages by Multi-Stage Optimization", :keyword2 150, :authors (45077 45261 25633), :session 94}, 691 {:keyword1 72, :keyword3 0, :abstract "Modern professional sports tournaments grew up to a huge economy factor. Sports contests consist of many games, usually between two players. The outcomes of these pairwise comparisons are, with respect to the rules, relevant for the quantitative and qualitative results of the whole tournament. Models for sports contests are also applicable to multilevel economic competitions.\r\nThe outcome of a game depends on the effort of both players as well as a random component. The probability of a win increases with higher own effort und decreases with higher opponent’s effort. This effort fluctuates over the season. Besides random-based variations the players can control their effort inputs in a strategic way. After some games with the highest input, there is no chance to stay on this level. A wise and sustainable input of the player’s effort resources is necessary. The individual aims and the different opponent’s strengths influence the optimal effort input of a player. If all players are optimizing their inputs, there are huge effects on the tournament itself. Economic factors, especially a permanent high audience interest, play a major role.\r\nA model describing the input of effort resources in sports tournaments with pairwise comparisons and under certain real world conditions is developed. Main issues are the analysis of the optimal input from the player’s point of view and the input allocation of all players in a game theoretical approach. Existence, uniqueness and special properties of the resulting Nash equilibrium are discussed. Further issues are the effects on the tournament as a whole and the applicability to the reality including real specific phenomena.", :title "Optimal Effort in Sports Tournaments", :keyword2 40, :authors (45181), :session 199889}, 692 {:keyword1 174, :keyword3 0, :abstract "We introduce and analyze the Partitioning Min-Max Weighted Matching (PMMWM) Problem. PMMWM combines the problem of partitioning a set of vertices into disjoint subsets of restricted size and the the strongly NP-hard Min-Max Weighted Matching (MMWM) Problem, that has recently been introduced in the literature. In contrast to PMMWM, the latter problem assumes the partitioning to be given. Potential applications arise in the field of container transshipment in rail-road terminals. We propose a MILP formulation for PMMWM and prove that the problem is NP-hard in the strong sense. Two heuristic frameworks are presented. Both of them outperform standard optimization software. Our extensive computational study proves that the algorithms provide high quality solutions within reasonable time.", :title "The Partitioning Min-Max Weighted Matching Problem", :keyword2 158, :authors (38193 29563 10954), :session 199913}, 693 {:keyword1 149, :keyword3 104, :abstract "Targeting the customers most prone to respond to a marketing campaign, such as product advertisements, is a key task in direct marketing. Typically, targets are preselected using segmentation techniques, which divide the customer base into groups of customers with similar characteristics and hopefully comparable response probabilities to marketing activities.\r\nToday, segmentation is often based on customer attributes such as recency, frequency and monetary value of purchases (RFM approach); in some cases also ownership of a certain product is used. However, in several studies it has been shown that a more detailed modeling of a customer's purchase history has additional predictive value, for example to estimate the probability of next purchase. The major challenge with sequence modeling is the combinatorial growth of possible sequences and the resulting small groups of customers for each sequence (Empty Space Phenomenon). \r\nWe present a method to learn a user-defined number of customer segments, where member count in each segment is significantly increased compared to a grouping based on raw purchase sequences. In our approach, we first preprocess each customer’s purchase history by assigning each bought product a geometrically decreasing weight depending on the recency of it acquisition. Thereby the focus is more on recent buying behavior while still considering older purchase history depending on the discount factor used. The resulting weighted purchase vectors are then projected into product space and distance-based clustering is used for the segmentation.\r\nExperimental results based on data provided by a large telecommunications company show high discriminative power of the derived segments for predicting next purchases.\r\n", :title "Customer Segmentation Using Concise Representation of Purchasing Sequences", :keyword2 56, :authors (43231 43180), :session 105}, 694 {:keyword1 101, :keyword3 54, :abstract "There are lots of factors to evaluate the performance of the supply chains such as customer service,quality, lead time, cost etc. But due to the environmental requirements (social responsibilities, Kyoto Protocol,government agencies etc.) an increasing attention has to be given to develop environmental strategies. If the aforementioned environmental applications are considered in the management of supply chains, then a new paradigm called green supply chain management (GrSCM) can be achieved.In this paper, the design of a closed loop supply chain network is studied which includes multiple plants, collection centers, demand markets and products. The proposed model is able to integrate the forward and reverse network design decisions to avoid the sub-optimality leads from separated and sequential designs. To this aim, a mixed-integer linear programming model is proposed that minimizes the total cost. Besides, a test problem is examined. Also we offer an exploratory study of modified facility location. Because of leading the environmental disasters, the global climate alteration has been one of the most important controversial issues in decades. The greenhouse gas emissions(co2, methane, nitric oxide, ozone etc.) begin with the industrial revolution. After this significant event, the global warming is getting worst as long as the energy demands are met by the fossil fuels. Thus, model is extended to consider environmental factors byε-constraint method. Our results indicate that it may be desirable to open more or different facilities than optimal from a narrow economic perspective to reduce the carbon dioxide emissions.", :title "A GREEN FACILITY LOCATION FOR A CLOSED-LOOP SUPPLY CHAIN NETWORK DESIGN", :keyword2 33, :authors (30896 31871 45221 45671), :session 199858}, 695 {:keyword1 42, :keyword3 104, :abstract "Future mobile networks will implement concepts of Software Defined Networking (SDN) and Network Function Virtualization (NFV). These concepts facilitate the “slicing” of a mobile network infrastructure into several virtual mobile networks.\r\nIn this contribution we address the problem of optimal embedding of virtual network slices into a given mobile network infrastructure with virtualized core network and service functions that are executed within datacenters of a cloud. Here the virtual core network functions comprise both data and control plane entities. The target is to determine for each network slice the optimum number and locations of the virtual functions and the routing of the traffic flows traversing these virtual functions (service chaining) so as to minimize the consumption of physical resources while guaranteeing a certain quality of service level. Physical resources are processing, storage, switching and transmission capacity. This problem can be formulated using an extended virtual network embedding approach allowing virtual network elements to be split on multiple physical nodes. However, this approach turns out to be not scalable for realistic problem sizes. Therefore we developed a new integer program optimization formulation. Our model also provides the basis for algorithmic optimization approaches.\r\n", :title "An Optimization Model for Software-defined Mobile Networks with virtualized Network and Service Functions", :keyword2 65, :authors (45238 39388), :session 199914}, 696 {:keyword1 166, :keyword3 91, :abstract "Similar customer behaviour should lead to clusters in the data they leave behind. When such clusters overlap, standard algorithms might lead to uninterpretable results. We performed standard and sparse principal component analysis in order to explain the heterogeneity in revenue management data. Our results identify typical customer behavior and some first new insight into dependencies between our variables. ", :title "Sparse principal component analysis in revenue management data", :keyword2 183, :authors (23312 19297), :session 105}, 698 {:keyword1 96, :keyword3 2, :abstract "Considering Air Traffic Management (ATM), the runway system is the main element that combines airside and groundside of the ATM System. To achieve an efficient planning, exact models are required. First of all, we model the runway scheduling problem in two different ways. One of them decides the ordering of the aircraft together with the landing time. The second uses a time discretization. It is an assignment problem with side constraints that computes for every discretized point in time whether an aircraft is scheduled and if so, which one is. Furthermore, security distances are respected. For randomly generated instances and different values of aircraft, the results for both exact models are evaluated with respect to optimality and computational run time. Different preprocessing rules have been derived and are evaluated for each model. In reality, we have to face disturbances and uncertainties in the aircraft flight times that usually lead to deviations from the actual plan or schedule. Using robust optimization, we protect the model against data uncertainties in order to avoid expensive or even infeasible solutions for the disturbed problem. Robust optimization concepts are transferred to the runway scheduling problem and are incorporated into the exact models. They are tested within a simulation for a planning horizon up to two hours before landing. Using random initial data for each aircraft and for the uncertainties in the earliest and latest landing or departure times, the robust models are compared to the nominal ones. The comparison is done with respect to stability of a plan, the number of necessary reschedulings and the number of served aircraft. In presence of uncertainty, the preliminary computations yield promising results for improved schedules.", :title "Exact Approaches for Runway Schedules in Air Traffic Management: Nominal and Robust Solutions", :keyword2 94, :authors (44995 45267 14713 13046), :session 199898}, 700 {:keyword1 171, :keyword3 124, :abstract "This paper represents result from our ongoing research project in the foresight area. The goal of\r\nour project is to develop web based tools which automatically detect potential real world events and associate them with a real location. This knowledge can be used to enable companies to adapt their capacities accordingly.\r\nAs for now we analyze the world wide web in more than 60 languages and can use a scalable amount of sources which we assign to one of over 100 national states.\r\nTo reach this goal we utilize the big search engines as their core competence is to determine the\r\nrelevance of a document regarding the search query. The search engines allow us a slicing of the\r\nresults by language and country.\r\nIn the next step we download some of the proposed documents for analysis. Because of the\r\namount of information required we reach the field of Big Data. Therefore an extra effort is made\r\nto ensure scalability of the application. As data storage we chose a NoSQL database which scales\r\nlinear with the number of nodes and promises fault tolerance.\r\nTo finally detect events in the data we use data mining methods which allow us to be independent\r\nfrom the language of a document. As input for these methods serve the downloaded documents,\r\nan specially prepared index structure containing meta data and various other information which\r\naccumulate during the collection of the documents.\r\nWe show that we can detect current events with a high impact and their corresponding locality and discuss future research.", :title "Detection and localization of Current Events using Web Data", :keyword2 120, :authors (44966), :session 86}, 701 {:keyword1 93, :keyword3 0, :abstract "The importance of information security is constantly increasing with technology becoming more pervasive every day. As a result, the necessity and demand for practical methods to evaluate and improve information security is particularly high. The aim of this paper is to apply mathematical optimization techniques to improve information security. According to the identified problem structure, a combinatorial optimization model is established. The objective of the presented approach is to maximize system security by choosing the best combination of security controls limited by available budget. In addition, by performing a What-if analysis and systematic budget variations, the decision maker can get improved insights and thus determine an ideal budget proposition yielding the highest benefit among all possible control configurations. An exemplary case study demonstrates how this approach can be used as a tool within the risk management process of an organization.", :title "Optimizing information security investments with limited budget", :keyword2 18, :authors (45262 10057), :session 199842}, 702 {:keyword1 29, :keyword3 163, :abstract "In this paper financial portfolio theory is applied in order to obtain optimal locations for renewable power plants. A geographically dispersed set of wind farms and solar power plants provide a more stable energy than the energy provided in the case the renewable energy plants are concentrated in a small area.  Two single period portfolio selection models for optimal location of renewable energy power plants are presented. The models belong to the class of mean-variance models. One of them is a minimum risk model and the other one is a maximum expected return model.\r\nDecisions of investment in renewable energy power plants are connected with land use decisions and the development of the grid infrastructure. In our models a renewable power plant is a wind farm or a solar power plant. A wind farm is a set of wind turbines and a solar power plant is a set of solar panels. A portfolio is a vector with integer components which show how many wind turbines or solar panels should be installed at various locations. Some of the variables of the models are non-negative integers and others are binary variables. Input data in the models are represented by wind data sets (mean wind speed and velocity variances) and solar data set (which establishes the site's irradiance and weather variability) collected from sites geographically dispersed. \r\n", :title "Mean-variance models for the location problem of renewable power plants", :keyword2 35, :authors (14957 31304), :session 199929}, 703 {:keyword1 175, :keyword3 174, :abstract "During courier and express providers’ operational dispatching, vehicles are assigned to customer orders. This task is complex, combinatorially comprehensive, and contains facets that defy modeling within reasonable effort, e.g. due to a lack of structured data. Hence, a fully automated solution cannot be achieved. In praxis, human dispatchers often use dialog-oriented decision support systems (DSS). These systems generate recommendations from which the human dispatchers select the most profitable one, additionally taking into account domain-specific knowledge. Solutions that consolidate the freight of multiple customer orders onto a single vehicle are usually particularly favorable. Generally, consolidating leads to a higher degree of vehicle capacity utilization, which in turn increases cost effectiveness, and lowers the resulting environmental burden.\r\nWe present a new recursive heuristic for this scenario based on the well-known savings algorithm. A central parameter of the algorithm limits the number of interdependent single tours. Through the appropriate setting of this parameter, one can control the results’ complexity and ensure their transparency and acceptance by human dispatchers. Using real-world data benchmarks, we prove its effectiveness empirically.\r\n", :title "A New Approach to Freight Consolidation For a Real-World Pickup-and-Delivery Problem", :keyword2 95, :authors (14705 14704 14803), :session 199947}, 704 {:keyword1 141, :keyword3 63, :abstract "We analyse in a parsimonious static model how goal congruence or preference similarity can be obtained when principal and agent are risk sensitive and when a setting is prevailing in which the agent has a shorter time horizon than the principal while intertemporal dependencies in risky cash flows are to be taken into account. \r\n\r\nOur results are as follows. First, we identify preferences that allow for preserving the unique properties of the residual income measure when agent and principal are risk sensitive. Second, we are able to show that in addition to the \r\nidentified preferences constant absolute risk aversion allows for reconciling the agent’s and the principal’s risk attitude. Finally, we find a new relative risk allocation scheme for this setting. It allows for both, (robust) goal congruence and preference similarity when cash flows are normally distributed. We also prove that these results hold for the special case of budget restrictions.\r\n\r\nJEL: M 41, J 33", :title "Goal congruence and preference similarity between principal and agent - setting incentives under risk with differing time horizons", :keyword2 19, :authors (45228 45264), :session 199964}, 705 {:keyword1 40, :keyword3 19, :abstract "In our paper we expand the considerations of Fandel/Trockel (2011) to an analysis of a dynamic trust behavior of the strategic players. The trust parameters that determine the level of the additional payoffs in the case of trust are now time-dependent with respect to the number of repeated rounds of the inspection game. The basis of modelling is a logistic function that describes the trust expansion among the strategic players. Unfortunately there exists the hazard that the inspectee will prey the inspector’s trust if the inspector’s trust level increases and exceeds a threshold. The inspector wants to prevent this situation. This is modelled by a stochastic term which expresses the percentual loss of trust of the inspector that may occur, so that a reasonable boundary of a threatened exploitation is not realized. However if this occurs, the calculated equilibrium in the next round of the repeated game will be the Nash solution without any trust. In the following rounds trust will maybe increase again and develop in a similar way as before.\r\n\r\nBased on a simulated structure of the chronology of the players’ payoffs one can estimate the level of mistrust the inspector should never underbid, so that error-free payoff-series without trust variations occur that dominate the Nash solution in games without trust, but simultaneously decrease the value of hazard the inspector may be exploited by the inspectee.\r\n\r\nReference:\r\nFandel, G., Trockel, J., 2011. Der Einfluss von Vertrauen in einem Inspektionsspiel zwischen Disposition und Controlling, in: Nguyen, T. (Hrsg.): Mensch und Markt – Die ethische Dimension wirtschaftlichen Handelns, Festschrift für Prof. Dr. Dr. h. c. Volker Arnold, Wiesbaden, 451-478.\r\n", :title "The effects of trust variations on the results of inspection procedures", :keyword2 138, :authors (16887 16883), :session 199886}, 707 {:keyword1 75, :keyword3 0, :abstract "We propose an extended model formulation of the Proportional Lot-sizing and Scheduling Prob-lem (PLSP). In this model, setup operations can be carried out period overlapping as well as product order dependent. We merge setup operations with comparable effort to so called setup classes. The implementation of these setup classes leads to a significant reduction of binary variables and therefore to a faster solution time resp. a better solution quality. We finally pre-sent numerical studies which show the effect of the implemented setup classes in comparison to literature-based approaches.", :title "A Proportional Lot-sizing and Scheduling Problem with Setup Classes", :keyword2 158, :authors (29814 17428), :session 199848}, 708 {:keyword1 97, :keyword3 169, :abstract "This work examines the calibration of simulations for business analytics. Complex simulations are increasingly employed to evaluate alternative planning strategies. With the number of model parameters and interdependencies grow challenges regarding the validation and calibration of simulation systems. A major tasks lies in emerging simulation types such as agent-based simulation. Here heterogeneous groups of agents are directly modeled to enable the consideration of agents’ impact on the planning solution and its success. Challenges are that the system’s behavior emerges from agents’ individual decisions and actions, which cannot be fully observed.\r\nTo survey calibration of simulation in business analytics, we present the results of a quantitative literature review. We differentiate stochastic, event-driven and agent-based aspects in simulations and subsume existing calibration approaches. Based on this, we collect specific requirements for calibrating relevant types of simulation. For each aspect, we propose a general formulation of calibration as classical optimization problem. We examine the formulations’ complexities, their advantages and disadvantages and available solving approaches. We particularly consider the quest for an automated calibration approach for agent-based simulations. Based on the view of calibration as optimization problem, this could be used for a wide field of applications in business analytics.", :title "Calibration of Discrete Simulations for Business Analytics - An Optimization Problem and its Prospects", :keyword2 127, :authors (45157), :session 199918}, 709 {:keyword1 8, :keyword3 157, :abstract "The quadratic matching problem (QMP) asks for a matching in a graph that optimizes a quadratic objective in the edge variables. The QMP generalizes the quadratic assignment problem. Applications of the QMP exist in computer vision, when for example a moving person is identified automatically on photos that are taken within a short period of time. More generally, the problem of finding 'highly similar' subgraphs in two given graphs can be solved by determining a QMP.\r\nWhen using branch-and-cut approaches, usually the binary quadratic problems are linearized by introducing additional variables that model the product terms, together with linearization constraints. However, in general LP-relaxations of the linearized IP-formulation yield weak bounds. In our approach, we strengthen the linearized IP-formulation by cutting planes that are derived from facets of the corresponding matching problem where only one quadratic term is assumed in the objective function (QMP1). We present new classes of facets that arise from the well known blossom inequalities of the matching problem. We show that separation of these new inequalities is polynomially solvable. We present different methods to strengthen the new relaxations for the general QMP. Thus, during separation additional cutting planes for the general QMP can be derived from valid inequalities of the QMP1. In particular, we introduce a method based on the linearization-reformulation technique that generates valid inequalities for the QMP from valid inequalities from QMP1. Based on these results, we design and implement an exact branch-and-cut approach and report computational results. ", :title "An Exact Solution Method for the Quadratic Matching Problem: The One-Quadratic Term Approach and Generalizations", :keyword2 176, :authors (45066 14713 36025), :session 81}, 711 {:keyword1 40, :keyword3 14, :abstract "\r\nIn this article I reconsider a   technique for handling  Nash equilibria for additively aggregative games, \r\ni.e.,  games where the  payoff function of a  player depends only on his own strategy and   the sum of all strategies.\r\n\r\nThis technique, developped\r\nby Selten and Szidarovzsky, was  especially succefull  in oligopoly theory.\r\nThe technique consists in transforming the   fixed point problem for \r\nthe best reply correspondence R  into an associated  fixed point problem for a correspondence B.\r\nThe value of the technique consists in the fact that the fixed point problem for\r\nB in general is more simple than that of R$ as the domain\r\n of B typically is a subset of the real numbers. This holds in particular under suitable\r\n  differentiability and concavity assumptions for the  payoff functions of the game.\r\n\r\nIn fact the technique even applies to  \r\ncorrespondences with a special factorisation property and so its setting is not necessarily a    game theoretic one. \r\nA quite general class of correspondences to which it applies recently has been identified. \r\nIn the present article I show that it is possbile to extend this class which makes that the technique can handle more general types of aggregative games.\r\n\r\n\r\n  \r\n", :title "On the Setting for the Selten-Szidarovzsky Method", :keyword2 48, :authors (13262), :session 199836}, 712 {:keyword1 175, :keyword3 0, :abstract "The delivery of goods from a central depot to different customer locations with a given set of vehicles is a well-known and widely studied problem in Operations Research. We extend the so-called Vehicle Routing Problem (VRP) in a way that the fleet of delivery vehicles consists of Hybrid Electric Vehicles (HEVs) having a combustion and an additional electric engine, which is powered by an integrated battery with a given capacity. The resulting problem is introduced as Hybrid Electric Vehicle – Vehicle Routing Problem (HEV-VRP) and supports decision makers to evaluate the acquisition of HEVs for their specific operation.\r\n\r\nWe assume vehicles that are able to use four different modes of operation: pure combustion, pure electric, charging the battery while driving in combustion mode and a boost mode, where the electric and combustion engine are combined. The modes of operation differ in cost and travel time for each arc within the delivery network and we restrict the maximum working hours for the drivers. Moreover, the vehicles have a limited capacity that cannot exceed the given demand of the customers visited.\r\n\r\nAs the HEV-VRP is a generalization of the NP-hard VRP, the HEV-VRP is NP-hard, too. As the complexity of the problem is even increased by the different modes of operation compared to the VRP, practical problem sizes require the usage of heuristics to find solutions in a reasonable time. Therefore, we present a simple heuristic approach, combining modifications on the tour structure and the modes of operation. To test our approach, we generated test instances based on the Solomon benchmark instances for the VRP with Time Windows (VRPTW) and point out the potential savings by using HEVs for delivery tours.\r\n", :title "A simple Heuristic for the Hybrid Electric Vehicle – Vehicle Routing Problem", :keyword2 95, :authors (25563 9272 24902), :session 199947}, 713 {:keyword1 161, :keyword3 41, :abstract "This communication aims to present some computational experiments with Branch & Bound techniques in Multiobjective (mixed) Integer Linear Fractional Programming (MOILFP). The importance and interest of these problems stem from the fact that many real applications involve the optimization of ratios (e.g. the maximization of output per some metric of the dimension of the region), integer variables for modelling several real world issues, and also entail multiple conflicting criteria. One of the most used techniques for computing non-dominated solutions in multiobjective programming problems is the optimization of a weighted sum of the objective functions. This transformation in problems with linear fractional functions leads to the so called sum of ratios problem, one of the most difficult fractional problems encountered so far.\r\nWe have already developed algorithms to compute nondominated solutions for Multiobjective Linear Fractional Programming Problems (MOLFP): Branch & Bound algorithms, which were then improved by introducing cuts into Branch & Cut schemas. We will present some adaptations of these algorithms in order to cope with integer variables. Computational experiments, for testing performance, were carried out and we will report on the obtained results.\r\n", :title "Some experiments with Branch & Bound techniques in MOILFP problems", :keyword2 158, :authors (12756 12412), :session 199835}, 714 {:keyword1 134, :keyword3 154, :abstract "Recent advancements of network technology enabled and simplified outsourcing of processing and storing information to remote facilities. The offering of such services in a competitive environment has become known as cloud computing. The competitive aspect is twofold. On the one hand, customers compete over the allocation of various types of services and resources like bandwidth or computing power. These resources are usually limited in capacity and when the demand exceeds that capacity costumers’ demand can only be satisfied partially. On the other hand, service providers face strategic decisions in the markets which have to take into account the budget of their clients. As long as a client can afford all the desired products, this has no consequence. But once their total costs exceed his budget, he has to split it between them. When deciding to offer a product, a provider therefore has to consider the remaining budgets of the interested clients. We study budget games as strategic games as well as in a variant that takes into account temporal aspect. Strategic games are often analyzed as one-shot games which do not capture situations like a new provider having a disadvantage against those already established. The clients prioritize the products they already know and spend only what is left of their budget on what a new provider offers. As a result, he cannot gain more than what is left of a clients budget. In this approach, called ordered budget games, we take the order of strategy changes into account. Each client has an ordering of the products and its budget is allocated to them in that order. If a player decides to change its strategy, its supply of products changes and new products are moved to the last position in the ordering of the clients in the target group.", :title "Budget-restricted utility games with ordered strategic decisions", :keyword2 40, :authors (45259 44469), :session 199887}, 715 {:keyword1 8, :keyword3 40, :abstract "We study competitive resource allocation problems in which a set of players distribute their demands integrally on a set of resources subject to player-specific submodular capacity constraints. Each player has to pay for each unit demand a cost that is a nondecreasing and convex function of the total allocation of that resource. This general model of resource allocation generalizes both singleton congestion games with integer-splittable demands and matroid congestion games with player-specific costs. As our main result, we give an algorithm computing a pure Nash equilibrium. \r\nThe proof rests on a  structural result on the sensitivity of optimal\r\nsolutions minimizing some linear objective over an integral polymatroid base polyhedron which \r\nis of independent interest.", :title "Resource Competition on Integral Polymatroids", :keyword2 173, :authors (45195 26518 26950), :session 92}, 716 {:keyword1 94, :keyword3 0, :abstract "The objective in timetable information is to find “good” train connections. Besides other criteria like, e.g., the number of transfers, the travel time is an important measure for the quality of a connection. However, fast connections tend to use transfers with small transfer times which are highly endangered to break in case of delays. \r\nRobust timetable information aims at finding connections which are robust against delays. I.e., given an uncertainty set U which specifies all possible delay scenarios, the objective of robust timetable information is to find a connection which has lowest travel time in the worst case (taken over the scenarios from set U).\r\nOne possible approach to robust timetable information would be to consider a connection (consisting of a sequence of stations and the trains taken between these stations) robust, if it can be traveled on as planned in all delay scenarios. This, however, often leads to connections with very high transfer times, since the transfers have to have the capacity to “absorb” all (potential) previously arising delays.\r\nBetter solutions (with respect to both worst-case and non-delayed travel time) can be found if we include the possibility to reroute passengers in case of delays. In this case, a solution to the timetable information problem is a strategy which specifies a connection and indicates how to adapt the chosen connection in case of delays. \r\nSuch a strategy is robust optimal, if it minimizes the worst-case travel time (where the worst-case is taken over the scenarios in the uncertainty set U).  \r\nIn this talk, we present solution algorithms for finite uncertainty sets and discuss how these can be used to find robust optimal strategies also for infinite uncertainty sets.\r\n\r\n", :title "Robust optimal strategies in timetable information", :keyword2 175, :authors (19182 29733 29738 1601), :session 54}, 718 {:keyword1 35, :keyword3 34, :abstract "Uncertainty about the probabilistic modeling of contingent claims is magnified by the uncertainty stemming from the need to adequately parameterize the stochastic dynamics of a given model or family of models. Losses associated with models usage can lead to financial distress for market participants and possibly impose systemic risks spreading throughout the economy attracting special attention from both risk management and regulatory authorities. This paper proposes a new framework based on convex risk measures to provide robust bid and ask pricing functionals. These uncertainty-capturing pricing functionals adjust models calibrated to benchmark instruments for model risk additionally reflecting uncertainty about the true parameters if the solution to model calibration is not unique. Based on these robust risk measures, we introduce the notion of uncertainty premiums for discounted payoffs. This enables us to quantify the degree of uncertainty and derive price uncertainty ratios for contingent claims. Numerical case studies using market information from credit index tranches for multi-name credit payoffs subject to default risk capture the impact of uncertainty about the parameterization of probability (pricing) measures, illustrate the characteristics of parameter uncertainty premiums, and document their evolution over time.", :title "Measuring Parameter Uncertainty in CDO Pricing Models", :keyword2 67, :authors (45273 45276 34348), :session 51}, 720 {:keyword1 40, :keyword3 0, :abstract "In cost sharing games, the existence and efficiency of pure Nash equilibria fundamentally depends on the underlying cost sharing protocol. We consider a general class of resource allocation problems in which a set of resources is used by a heterogeneous set of selfish users. The cost of a resource is a (non-decreasing) function of the set of its users. The set-dependency of the cost functions allows to model different technologies at the resources required by different users, such as machines, bandwidth, personal, etc.\r\n\r\nUnder the assumption that the costs of the resources are shared by uniform cost sharing protocols, i.e., protocols that use only local information of the resource's cost structure and its users to determine the cost shares, we give (asymptotically) tight bounds on the inefficiency of the resulting pure Nash equilibria. Specifically, we show tight bounds on price of stability and anarchy for games with only submodular, only supermodular or arbitrary cost functions, respectively. While all our upper bounds are attained for the well-known Shapley cost sharing protocol, all our lower bounds hold for arbitrary uniform protocols and even for games with anonymous costs, i.e., games in which the cost only depends on the cardinality of the set of its users.", :title "Sharing costs for good equilibria", :keyword2 0, :authors (45274 26950), :session 199887}, 722 {:keyword1 91, :keyword3 0, :abstract "Discounts are often an important selling point for retail, especially for online shops. If the variety of products of a retailer is very large then these calculations can cost a lot of resources. Therefore two algorithms for discount calculation will be introduced. The algorithms are based on econometrics. A multi product model which uses the price elasticity of demand builds the core of the algorithms. To solve the model regression and dynamic programming are used amongst others.\r\nGenerally there is a data pre-processing necessary to apply these algorithms. So the second part is a discussion of how the data available to a retailer can be processed to meet the requirements of the introduced algorithms and allowing so the application. This will include the consideration of seasonality or the price of a competitor.", :title "Automated discount calculation for retail", :keyword2 178, :authors (36925), :session 101}, 725 {:keyword1 165, :keyword3 0, :abstract "This talk addresses unit commitment under uncertainty of load and power infeed from renewables in alternating current (AC) power systems. Beside traditional unit-commitment constraints, the physics of power flow are included. To gain global optimal solutions a recent semidefinite programming approach is used, which leads us to risk averse two-stage stochastic mixed integer semidefinite programs whose structure is analyzed, and for which a decomposition algorithm is presented. ", :title "Two-stage Stochastic Semidefinite Programming for Unit Commitment Under Uncertainty with AC Power Flow Constraints", :keyword2 164, :authors (31940 9512), :session 90}, 726 {:keyword1 183, :keyword3 101, :abstract "Oracle's In-Memory Consumption-Driven Planning(IMCDP) is a new product which offers the step change in performance, scalability, and new functionality needed for forecasting and replenishment planning at a highly granular level.\r\nSupply chain performance, e.g. for consumer products manufacturers, is most effective when forecasting and replenishment planning are done as close to the end customer as possible using demand or consumption data, e.g. daily Point of Sale (POS) data, in order to avoid the bullwhip effect and to enable shelf-connected and collaborative supply chain planning.\r\nHowever, limitations in software and hardware performance have precluded the use of sophisticated planning algorithms in most situations, so many companies plan at distribution center level and week, and using outbound shipments instead of end-customer demand. This approach leads to suboptimal forecasts, service levels,and inventory turns. IMCDP overcomes these limitations and makes daily store-level planning a reality.\r\nIMCDP has the scalability to plan across all of the business and can accommodate planning at different levels in a single system. The level at which a line of business or account will be planned will be tied to the criticality to the business as well as data availability and planning needs. That way one can plan at a granular level for one business process without incurring performance impacts on other business processes such as Sales and Operations Planning.\r\n\r\nIMCDP calculates a time-phased replenishment plan, that combines current on-hand and inventory targets with in-transit, on-order and shipment leadtime to create an order which will meet end-customer demand.", :title "Oracle In-Memory Consumption-Driven Planning: Extreme Performance for the Demand-Driven Value Chain", :keyword2 182, :authors (45229 45277), :session 199859}, 727 {:keyword1 8, :keyword3 75, :abstract "The open-pit mine block sequencing problem (OPBS) models a deposit of ore lying near the earth's surface as a three-dimensional grid of blocks. A solution, in discretized time, identifies a profit-maximizing extraction (mining) schedule for the blocks. Our model variant, a mixed-integer program (MIP), presumes a predetermined destination for each extracted block, namely, processing plant or waste dump. The MIP  incorporates standard constructs, but also (i) adds not-so-standard lower bounds on resource consumption in each time period, and (ii) allows fractional block extraction in a novel fashion while still enforcing pit-wall slope restrictions. A new, flexible ``hierarchical Benders decomposition'' extends nested Benders decomposition to solve the MIP's linear-programming relaxation. Adding constraints aggregated across time to the decomposition's subproblems reduces solution times dramatically. A specialized branch-and-bound heuristic then produces high-quality integer solutions. Medium-sized problems (e.g., 25,000 blocks and 20 time periods) solve to near optimality in minutes. We believe these computational results are the best known for instances of OPBS that enforce lower bounds on resource consumption.", :title "Hierarchical Benders Decomposition for Open-pit Mine Block Sequencing", :keyword2 96, :authors (1244), :session 199875}, 728 {:keyword1 45, :keyword3 0, :abstract "Rescue services are an important part of public health care, offered by the state to the general public. A crucial aspect of rescue service is the first aid of patients provided by local Emergency Medical Services (EMS). The quality of a rescue service system is typically evaluated ex post by the proportion of emergencies reached within the legal time frame. Optimization models in literature consider different variants of demand area coverage, such as single coverage, double coverage and empirical required coverage. Additionally, models with busy fractions and reliability levels serving as a proxy for EMS quality are suggested. All models support the decision maker on the strategic and tactical level of ambulance location planning, but differ regarding the specification of objective functions as well as concerning input parameters and model assumptions. In literature no comparisons of the mentioned models with respect to their influence on the EMS quality are found. In order to evaluate the performance of different optimization models, a detailed simulation study is conducted. We analyze the influence of different objective functions and the resulting positioning of EMS resources on real world outcome measures. Test instances include data sets of a large German city as well as randomly generated samples with different urban structures.", :title "Analysis of ambulance location models using discrete event simulation", :keyword2 97, :authors (33571 32309 39468 10057), :session 199936}, 730 {:keyword1 175, :keyword3 133, :abstract "The present work models the uncertainty of oil, electricity and battery prices in order to find the optimal renewal strategy for transport vehicle fleets in Germany. It presents a comprehensive statistical model of total operating costs for the usage of vehicles in the transport industry. The model takes into consideration current and future power train technologies, such as internal combustion and electric engines. The framework allows for the calculation of sensitivities of the relevant explanatory variables (fuel price, interest rate, inflation rate, economic life-cycle duration, subsidies, taxing policies, and economic environment). The study also contains the calculation and evaluation of relevant diffusion scenarios for commercially used electric vehicles.", :title "Optimal Renewal and Electrification Strategy for Commercial Car Fleets in Germany", :keyword2 102, :authors (21108 45279), :session 199920}, 731 {:keyword1 174, :keyword3 59, :abstract "In recent years, the optimal use of alternative fueled vehicles in transport applications has received increased attention. This has led to several reformulations of existing problems to cover the newly introduced features.\r\n\r\nIn previous work we combined two streams of research to model a fleet sizing problem with battery electric vehicles, time windows and the possibility of recharging on tour at dedicated recharging stations – called the Electric Fleet Size and Mix Vehicle Routing Problem with Time Windows and recharging stations (E-FSMVRPTW). This formulation is limited to a fleet of electric vehicles only, neglecting the real world requirement of considering conventional vehicles as well. Furthermore, by enforcing a strict recharging policy (always recharge to full capacity) past works are restricted to a subset of routing decisions, omitting routes where a recharge to only half of the battery would result in a time-feasible solution.\r\n\r\nIn this work we extend the E-FSMVRPTW formulation by introducing conventional and plug-in hybrid vehicles to the available fleet mix. A new decision set is considered since the engine mode (electricity or conventional fuel) can be switched en route. Furthermore, we enrich the problem by adding other real-world aspects, such as different recharging rates and decidable charging quantities as well as city-center restrictions. These restrictions model so-called 'green zones' where vehicles using conventional engines are prohibited or penalized.\r\n\r\nWe propose a rich electric fleet size and mix problem model and a layered evaluation and improvement approach using local search, dynamic programming-based labeling and greedy policies. We present first computational results on benchmark instances with a focus on the methodological aspects.", :title "A Rich Electric Fleet Size and Mix Problem", :keyword2 175, :authors (39002 22655 22160 10538), :session 5}, 732 {:keyword1 8, :keyword3 96, :abstract "Notwithstanding political initiatives to promote the rail freight transportation, the actual share of freight rail transport is decreasing in EU (from 15% in 1980 to 10% in 2010, EU statistics “Transport in Figures”). In fact, rail logistics fails to make a competitive offer to firms. The actual average speed of freight trains is estimated at about 10 km/h and only a half of freight trains reach their destination with less than a 30 min-delay. A recognized bottleneck in the rail logistics is inefficient operation of the shunting yards.\r\nWe consider a tactical planning task of allocating the classification work within a multiple-sided shunting yard. The inbound freight trains have to be re-assembled, or classified, to form the outbound trains. Thereby the classification tasks can be distributed among several classification units. Rail cars can be transferred between classification units at rather high additional cost. Typically, the hub-yards within the rail network, such as Maschen (Hamburg), represent examples of such multiple-side shunting yards.\r\nIn our paper, we investigate how to allocate the classification tasks within multiple-sided shunting yards in an efficient way. We model the problem as clique partitioning problem with additional constraints. We present a heuristic and an exact solution method.", :title "Allocating classification tasks  at multiple-sided shunting yards", :keyword2 175, :authors (35097 29458 10954), :session 199943}, 734 {:keyword1 61, :keyword3 115, :abstract "Given a generic process or workflow model in YAWL-notation or any other process modelling language like BPMN or WFMC we state that, by using a set of reduction rules as introduced e.g. by Sadiq et al. we are able to generate a hierarchically structured tree of sub graphs of the workflow graph-representation. According to the notation used in La Rosa et al. we call these sub graphs facts. The tree structure of the graph-representation on the one hand and the logical relation between the branches and leafs of the tree on the other can be utilized to create a set of constraints and dependencies between the single facts. La Rosa et al. showed that the nested branches can be associated to (predefined) questions with respect to the configuration of a workflow management system like for instance an ERP-application. They presented an algorithm which dynamically sorts the questions and answers in a maximum efficient configuration path while working through the corresponding questionnaire.\r\nBy combining the different elements as facts, constraints on questions and configuration space we are thus able to 1. Algorithmically generate the efficient structured, interactive questionnaire for the configuration of workflow systems and 2. Algorithmically check the consistency (dead lock free, free of synchronization structural conflict) of the underlying workflow model.\r\nThe concept was tested in the prototype of the interactive questionnaire for configuration of the webservice based ERP-Application Posity.\r\n", :title "Generation of interactive Questionnaires using YAWL-based workflow models", :keyword2 42, :authors (39370), :session 86813}, 735 {:keyword1 97, :keyword3 175, :abstract "Due to the growth of vehicles-per-capita and travel demand in Iceland, greenhouse gas (GHG) emissions from the road transport sector have been increasing rapidly during the past decade. To achieve the Iceland’s long-term goals to reduce the net GHG emissions in the transport sector, a transition to alternative fuel vehicles (AFVs) will be required. \r\nTo explore the transition process toward a low carbon transport, a system-dynamics model of Iceland’s energy systems (UniSyD_IS) is developed. UniSyD_IS is a detailed resource and technology specific model in which equilibrium interactions act across six key markets: electricity, hydrogen, biogas, bioethanol, biodiesel, and vehicle fleets. UnisyD_IS encompasses conventional and alternative fuel supply pathways and the corresponding vehicle powertrains. The whole model structure is divided into four main sectors: 1) fuel supply, 2) fuel prices, 3) infrastructures, and 4) fuel demand. The model provides an endogenous analysis of road transport sector in which the long-term evolutions of light and heavy-duty vehicles are simulated through a vehicle choice algorithm.\r\nIn this paper the structure and the algorithm of energy and transport simulation are described and possible transition pathways toward a low-carbon transport in Iceland are explored. The application of the UniSyD_IS model has potential to provide important policy insights as it enables policy analysis at both supply and demand sides and can simulate the impact of different policy instruments on both fuels and vehicles.\r\n", :title "System Dynamics Modeling of Pathways to a Sustainable Transportation in Iceland", :keyword2 29, :authors (6335), :session 60}, 736 {:keyword1 7, :keyword3 162, :abstract "A multitude of biorefinery concepts is discussed for the usage of various forms of biomass. In any case, a biorefinery is meant to make economically advantageous use of the main and co-products resulting from the corresponding biomass conversion process. Whether the upgrading of potential products can be considered economically advantageous depends on the value of the biorefinery's products and the cost associated with the installation of the required upgrading and/or separation equipment. Based upon the model of a biomass-based synthesis gas biorefinery, other biorefinery concepts based on algae and enzymatic breakdown of cellulose are investigated. These concepts require different assumptions concerning the origin of the input biomass, the struture of logistics cost, viable biorefinery capacities, potential products and required upgrading and separation processes. Accordingly, modeling approaches used for the economic assessment of biorefineries need to be adapted in a suitable manner. In spite of these differences, it is attempted to conduct a comprehensive evaluation of biorefinery concepts to determine which concepts appear to be the most promising from the current state of knowledge and to present an approach to use techno-economic modeling to gain further understanding in this developing key field of biomass conversion.", :title "Optimization as a means of evaluating the respective advantages of biorefinery concepts", :keyword2 133, :authors (28733), :session 63}, 737 {:keyword1 47, :keyword3 13, :abstract "Every year organizations go for campus recruitment of fresh graduates on large scale. Organizations commonly consider college rankings by external agencies to make hiring decisions. The colleges may be highly ranked externally but the realized “utility” of the hired candidates and college rankings from an organization’s perspective, may differ from external rankings. Organizational utility is based on factors such as tenure of the candidates and their performances on the job. Also determining number of students to be recruited from each ranked college is another challenge faced by managers. In this paper, we present ranking schemes for the colleges, using DEA and average ranking, based on past employees data (performance, tenure, attrition etc.) and college data (joining ratio, external college grading etc.), with the organizational utility perspective. The rankings were correlated with expert opinion using measures like Kendall Tau. Based on rankings, a new recruitment allocation model is developed to determine the number of students to be recruited from each college, given an overall target of number of students to be recruited in that year. Our model tries to maximize the expected organizational utility as well as maintain a healthy diversity. For solution, we have modified the standard water-fill algorithm from convex optimization. The results show improved organizational utility of new allocations, assuming the same overall behaviour of hires. We are building an intelligent automated recruitment allocation system to reduce recruitment efforts and enhance organizational utility from the recruited fresh hires. The proposed approach is applicable for other human resource supply chain problems like recruitment of experienced professionals from placement agencies.", :title "Novel approach for effective campus recruitment ", :keyword2 17, :authors (45269 15665 45280), :session 199842}, 738 {:keyword1 154, :keyword3 0, :abstract "Voting scenarios arise whenever the preferences of different parties have to be aggregated to form a joint decision, for example in political elections, group decisions, web site rankings, or multiagent systems. Many voting problems turned out to be NP-hard which can also be a desired property, for example in case of manipulation or bribery. Since voting problems carry many natural parameters such as the number of alternatives or the number of votes and there are real-world scenarios where each of these parameters is small, it is natural to employ parameterized complexity analysis, that is, to measure the computational complexity of a problem as a function of a multitude of input parameters.\r\n \r\nWe discuss a few results from the DFG project \"Parameterized Algorithmics for Voting Systems\" using the problems \"Lobbying\" and \"Shift Bribery\" as examples and show both (fixed-parameter) tractable and intractable parameterizations of the problems.\r\n\r\nIn the Lobbying problem, we are given a binary multi-issue election where voters approve or disapprove multiple issues and an agent (the lobby) may influence up to k voters. The Lobbying problem asks whether the lobby can choose k voters to be influenced so that as a result each issue that is liked by the lobby gets a majority of approvals and each issue that is disliked by the lobby gets a majority of disapprovals.\r\n\r\nIn the Shift Bribery problem, we are given an election (based on preference orders), a preferred candidate p, and a budget. The goal is to ensure that p wins (under some specified voting rule) by shifting p higher in some voters' preference orders. However, each such shift request comes at a price (depending on the voter and on the extent of the shift) and we may not exceed the given budget.", :title "On the Multivariate Complexity of some Bribery Problems", :keyword2 127, :authors (45278), :session 67}, 739 {:keyword1 88, :keyword3 152, :abstract "\"Software aging\" relates to the phenomenon that during operations a software system may show an increasing failure rate that cannot be attributed to changes in the user behavior or the software code. Typically, software aging is due to the accumulation of error states (such as leaked memory) inside the running system. Periodically removing these error states (e.g., via system reboots or application restarts) can help prevent future aging-related failures of the software system, thus increasing its reliability. This proactive technique has been known as \"software rejuvenation\". Since the accumulation of internal error states is often accompanied by progressive software performance degradation, the measured response time of the software system can be used to detect the onset of software aging, and to determine when to trigger software rejuvenation. \r\n\r\nIn this talk, we propose to model the widely-used Apache HTTP server as a finite-server queue with Poisson arrivals and service times that follow a two-stage Erlang distribution. For this queuing model, we first derive the steady-state probabilities, which to the best of our knowledge have not been available in the existing literature. We then obtain closed-form expressions for the response time distribution as well as its moments, using this information to validate our model. Finally, we present a phase-type-distribution approach to calculating the cumulative distribution function of the sample average of response times. The quantiles of this distribution are employed in our distribution-based rejuvenation algorithm (DBRA), which uses the mean of observed response times for deciding when to rejuvenation the system. In simulations, we compare the performance of the DBRA with the one of a previously-suggested algorithm.", :title "A queuing model and its application to software rejuvenation", :keyword2 89, :authors (45191 45281 45283 45284 45286), :session 199891}, 740 {:keyword1 29, :keyword3 156, :abstract "The liberalization of the energy market and the merit-order effects lead to difficulties in the profitable operation of some modern conventional power plants. Although they are highly efficient with state-of-the-art technical properties, these power plants are underutilized or even mothballed. Decisions about further operation or shut-down of these conventional power plants are in most cases characterized by being irreversible, implying uncertainty about future rewards, and being flexible in timing. A relatively new approach for evaluating investment/disinvestment projects with uncertainties has been introduced by the real options approach (ROA) (Dixit and Pindyck, 1994; Schwartz and Trigeorgis, 2001). This valuation technique is based on option pricing methods used in finance and has been developed by Black, Scholes, and Merton (Black and Scholes, 1973; Merton, 1973), who based their valuation on partial differential equations. In last two decades, real options models have been widely applied to analyze especially investment decision under dynamic market conditions. ROA dominates the net present value approach and accounts for flexibility in the decision-making process. Nevertheless, the analysis of disinvestment decisions considering uncertainty of the market has been of high relevance in recent years, but so far it has not been applied to the energy sector. Moreover, disregarding disinvestment options in decision-making processes can lead to incorrect valuations of investment strategies at the firm level. In this paper, we develop a real options model for the disinvestment in conventional power plants. Using the real options approach we aim at determining the optimal timing for shut-down of unprofitable power plants.", :title "A Real Options Model for the Disinvestment in Conventional Power Plants", :keyword2 28, :authors (59838 45289 21108), :session 199928}, 741 {:keyword1 133, :keyword3 126, :abstract "About 15% of the German electricity consumption is used to operate chillers and cooling towers. The mathematical optimisation of the mode of operation of these units is often very time consuming, because the part load behaviour and temperature dependency of both chillers and re-cooling units is non-linear and the interdependencies cannot easily be overseen. Mathematical models often neglect the temperature dependency of the unit performance and take only the part load behaviour at fixed temperatures into consideration. Hence degrees of freedom are neglected, that could lead to significant energy savings. \r\n\r\nIn this paper we present a methodology to model chillers and cooling towers in order to perform a mixed integer linear optimisation. The focus of the presented methodology is the application by energy consultants. Therefore a practical linearization approach is used, that is applicable with data that is available in a non-academic energy system analysis. It is shown how chillers, cooling towers and pumps can be modelled linearly and how an optimization can be done using this linear model. The models consider the part load behaviour for fixed temperatures both for chillers and re-coolers. Furthermore the dependency between outside temperature and re-cooler efficiency of dry cooling towers and between wet bulb temperature and efficiency of wet cooling towers is taken into consideration. The chillers are modelled using a linearized dependency between the temperature of the cooling water and the electricity consumption.\t\r\n\r\nThe methodology is used to optimize a cooling network consisting of 13 chillers and 9 cooling towers with an overall maximum cooling capacity of 27MW. The optimised control uses 15% less electrical energy than the actual implemented control strategy.", :title "Applied MILP Modelling and Optimisation of Cooling Energy Systems", :keyword2 159, :authors (45271 45282 45305 45287 45304), :session 94}, 743 {:keyword1 175, :keyword3 151, :abstract "Carsharing systems offer a new mobility service that allow its users to use cars when they need one, from a fleet of cars scattered in an urban area. Cars are located at different stations that have a fixed number of parking spaces. In this study, we are dealing with one-way carsharing system where users can pick a car from a station and return it to any other station. Available Cars and Free parking space at each station, play a major role in the success of the one-way carsharing systems. Therefore, Carsharing operators recruit employees to relocate cars between the stations to avoid the rejection of users’ demands for picking up cars or returning them into stations. In this paper, we developed a greedy algorithm in order to solve the maximum number of rejected users' demands, using the minimum number of employees. We used mobility data collected in an operational system to build the users’ demand matrices. In a carsharing system which has 20 stations, 150 cars, through 1,374 trips made during one day and 555 expected rejected demands, results show that the algorithm is able to solve 55% of expected rejected demands using 5 employees and more than 80% of these rejected demands using 10 employees. We compared the algorithm with an exact Mixed Integer Linear Programming model using IBM ILOG CPLEX optimizer and made the proof of performance with stochastic input data and different numbers of employees.", :title "A Greedy Algorithm for relocation problem in one-way carsharing", :keyword2 99, :authors (45154), :session 199945}, 745 {:keyword1 8, :keyword3 174, :abstract "We consider routing through hub networks from the perspective of a logistics’ customer. We devise an optimization method to decide on renting hubs and routing several different goods from multiple sources to multiple sinks in a large scale network with realistic transportation costs. As the strategic planning must be completed before the actual demand is known, our solutions are robust optimal, i.e., have lowest cost under the worst-case of a restricted fluctuating demand. \r\nOur case studies are outbound networks of retailers, and the inbound network of an automotive company. Given multi-commodity demands, the goal is to choose cost minimal hubs and subroutes offered by a multitude of transportation companies at an involved system of rates. \r\nTypical rates depend on several properties (usually two: weight and volume). We model the cost on an edge by different, abstract containers, each having fixed cost for buying copies and capacities for each property. In one respect, fluctuating demand makes optimization easier as limits the the benefit of planning for tightly filled containers. Therefore, we allow for buying a fractional number of copies greater than one or no copy. The crucial optimization potential stems from the consolidation of goods with different properties. \r\nWe apply the model of budgeted interval uncertainty as in Bertsimas and Sim, with uncertain demand values. We extend their methodology to obtain a compact MILP formulation for a robust counterpart. Preliminary experiments on a real instance with roughly 400 sources, 20 sinks and 10000 demands indicate that for a small set of hubs (»10) the MILP can be solved close to optimality, while for larger hub sets (»100) a solution to the resulting LP relaxation can be rounded to integrality.", :title "Strategic planning in large-scale logistic networks", :keyword2 94, :authors (33307 33453 33663), :session 69}, 746 {:keyword1 96, :keyword3 8, :abstract "The classical time-indexed 0–1 linear programming formulations for the resource constrained project scheduling problem involve binary variables indicating whether an activity starts precisely at or before a given time period. In the literature, references to less classical “on/off” formulations, that involve binary variables indicating whether an activity is in progress during a time period, can also be found. These formulations were not compared to the classical ones in terms of linear programming (LP) relaxations. In this talk, we show that the previously proposed on/off formulations are weaker than the classical formulations and we obtain a stronger on/off formulation via non singular transformations of the classical formulations. We also remark that additional time-indexed formulations, presented as appealing in the literature, are in fact either weaker or equivalent to the classical ones.", :title "On time-indexed formulations for the resource-constrained project scheduling problem", :keyword2 157, :authors (16865), :session 93}, 747 {:keyword1 8, :keyword3 151, :abstract "     Bin packing is one of oldest classic NP-hard problems in the field of combinatorial optimization. The problem involves assigning a set of n items with positive sizes to bins of equal capacity such that the number of bins required is minimized. In this work, we consider a long-studied generalization of the bin packing problem, in which every item is released one by one and must be packed into a unique bin as soon as the items arrive. The objective of this online bin packing problem is to determine a packing without knowledge of next items to minimize the total number of bins required. \r\n\r\n     There have been many papers on this online packing problem since an elegant online strategy, called the Harmonic algorithm, was presented by Lee and Lee in 1985 [Journal of the ACM, 32(3):562-572, 1985]. After longstanding efforts by a series of the Harmonic algorithm and its variants, Seiden extended the idea and proposed the Super Harmonic algorithm whose asymptotic competitive ratio is the best known result to date [Journal of the ACM, 49(5):640-671, 2002]. This study revisits the properties of this online packing problem and investigates approximation algorithms for solving its multidimensional model.\r\n", :title "The Online Bin Packing Problem Revisited", :keyword2 173, :authors (45258 45227 45223), :session 199897}, 748 {:keyword1 8, :keyword3 158, :abstract "An important task in modern communication networks is the virtualization of network resources. On top of an existing physical substrate network (SN), a virtual network provider implements virtual networks (VN) consisting of processing units connected by links. The processing units are realized in terms of virtual machines on real physical ones, the links are mapped to physical connections. Different virtual machines may be mapped to the same physical machine and links may be realized using several routing and communication lines in the SN.\r\n\r\nThe aim of the Virtual Network Embedding Problem (VNEP) is to map nodes and links of a VN to nodes and paths in the SN. The nodes and links of each VN possess certain demands on resources on the substrate nodes (e.g. computing capacity) and edges (e.g. bandwidth requirements). The task is to embed several VNs so that resource constraints in the substrate nodes and edges are satisfied. Classical approaches typically consider a simultaneous embedding of all VNs in an offline setting or the successive embedding of arriving VNs into the running network in an online setting. In contrast, we regard the problem with additional time restrictions for each VN. For each VN one is given a interval when the VN should be embedded and a duration how long the VN lasts. The task is to find an embedding for each VN and together with this a time slot in which the VN should be embedded, so that the time restrictions are satisfied and for each point in time the capacity restrictions are fulfilled as well. The aim of this talk is to present models for solving the Time Restricted Virtual Network Embedding Problem based on integer programming. We present first computational results to compare the performance of these models on moderately sized instances.", :title "Models for  Virtual Network Embedding Problems with Time Restrictions", :keyword2 104, :authors (16988 13058), :session 199911}, 749 {:keyword1 48, :keyword3 171, :abstract "Hot rolling is the most important metal forming process in terms of production capacity and demand. In this process slabs of cast metal are heated to temperatures up to 1250 degrees C and then formed into metal sheets by reducing their thickness and at the same time increasing their length in several steps or passes. In each pass the slab is deformed via compression between two driven work rolls in a roll stand. To design the schedules for rolling processes the force during each rolling pass is of crucial importance. Typically simplified constitutive modelling equations are used to predict those forces. For precise predictions the equations use typically around 15 material dependent parameters. These parameters are conventionally determined in laboratory scale tests with high efforts and costs. In this paper a concept is detailed that enables the determination of the material model parameters via inverse modelling directly from industrially measured process data. The basic idea is to use the deviation between measured and modelled forces as a quality indicator for the material model parameter precision. To minimize the force deviations the simplified rolling model is embedded into a non-linear optimization loop where the material model parameters serve as input and the objective function is defined as the least squares deviation between measured and modelled force. After successful optimization the resulting parameter set enables the prediction of roll forces in industrial rolling processes with high accuracy without the need for additional material testing. Using these forces it is then possible to lay out optimal process schedules.", :title "Inverse Modelling via Non-Linear Optimization for Precise Force Predictions in Hot Rolling of Steel", :keyword2 120, :authors (45249 45285), :session 199959}, 752 {:keyword1 158, :keyword3 124, :abstract "Performance variability is a phenomenon inherent to all state-of-the-art solver codes in which different representations of a problem instance result in different solver runtimes. In mixed-integer programming (MIP) solvers, simply permuting the rows and/or columns of the A matrix is sufficient to drastically change solver performance. This is, in part, due to imperfect tie-breaking. Several approaches exist to exploit this variability through parallelizing the solving of several representations and choosing the one that looks the most promising. In contrast to these methods, we propose an offline machine learning approach that predicts \"good\" problem instance representations in order to achieve better runtimes, meaning no parallelism is required. Our approach analyzes the structure of instances and permutations of the variables/constraints in a problem in order to predict whether or not a particular instance representation will provide a low runtime.", :title "Exploiting performance variability in MIP solvers using machine learning", :keyword2 157, :authors (27643), :session 199905}, 753 {:keyword1 174, :keyword3 0, :abstract "Automotive Original Equipment Manufacturers (OEM) produce a wide range of cars in their plants in Europe. The plants are supplied with component parts by thousands of suppliers of which a large number is located in Europe as well. Depending on the part type and demand structure different transport types like Full Truck Load or Less Than Full Truck Load are chosen to provide the plants. In addition, various transport modes like road or rail transports are used to benefit from their individual cost structures.  \r\nIn a strategic network optimization the optimal transport types and modes are identified. Afterwards, logistics service providers (LSP) are chosen in a tender process to perform the necessary transports at minimum costs and highest possible quality and service level. The transport network is separated in geographic regions (e.g. Spain, North of France) in order to design logistically relevant and manageable network parts on which the LSP can bid.\r\nThe aim of the tender process is to gather LSP-quotes on the transport regions, modes and types. The quotes are compared and the cost-optimal set of quotes and LSPs is chosen under certain restrictions. For example, the restrictions cover the transport volume per LSP or the maximum number of LSP admitted. Furthermore, it is possible to form bid packages combining several regions. The objective function consists of the transport costs arising out of a feasible set of LSPs serving then network regions and it is often influenced by criteria as, for instance, the implementation effort. \r\n4flow has developed a mathematical model and an optimization tool to support the tender process and assess and compare possible scenarios. In this paper the mathematical model and its application on a real-world problem will be presented.", :title "Tender decisions in European transportation networks for automotive companies", :keyword2 175, :authors (45291 44839), :session 26}, 755 {:keyword1 157, :keyword3 8, :abstract "This study proposes a new formulation and a column generation approach for the black\r\nand white traveling salesman problem. This problem is an extension of the traveling\r\nsalesman problem in which the vertex set is divided into black vertices and white vertices. The number of white vertices visited and the length of the path between two\r\nconsecutive black vertices are constrained. The objective of this problem is to find the\r\nshortest Hamiltonian cycle that covers all vertices satisfying the cardinality and the\r\nlength constraints. We present a new formulation for the undirected version of this\r\nproblem, which is amenable to the Dantzig-Wolfe decomposition. The decomposed\r\nproblem which is defined on a multigraph becomes the traveling salesman problem\r\nwith an extra constraint set in which the variable set is the feasible paths between pairs\r\nof black vertices. In this paper, a column generation algorithm is designed to solve the\r\nlinear programming relaxation of this problem. The resulting pricing subproblem is an elementary shortest path problem with resource constraints, and we employ acceleration\r\nstrategies to solve this subproblem effectively. The linear programming relaxation\r\nbound is strengthened by a cutting plane procedure, and then column generation is\r\nembedded within a branch-and-bound algorithm to compute optimal integer solutions.\r\nThe proposed algorithm is used to solve randomly generated instances with up to 80\r\nvertices.", :title "A New Formulation and Approach for the Black and White Traveling Salesman Problem", :keyword2 174, :authors (16992), :session 199865}, 757 {:keyword1 40, :keyword3 151, :abstract "In this presentation a case of horizontal cooperation with transferable and non-transferable utility is considered. As example, we consider a cooperative traveling salesman problem, where besides the minimization of total costs every player aims to maximize his own utility from assigned orders. The allocation problem is defined as a generalized NTU game with transferable and non-transferable utility. The characteristic set of this game results from the solution of a multi-objective optimization problem. For the determination of the allocation of costs and utilities we present a game-theoretic approach using the NTU core concept. For the computation of NTU core elements an algorithm was developed. The results of the computational study show the performance of the developed algorithm.", :title "An NTU-Based Approach for Allocation Problems in Cooperative Planning defined as a Multi-Objective Optimization Problem", :keyword2 63, :authors (33565 14715), :session 199888}, 758 {:keyword1 91, :keyword3 156, :abstract "We consider the availability control of electric vehicles in station-based car sharing systems (e-car-sharing). In this kind of car sharing system customers are able to flexibly rent vehicles at rental points that are typically located at easily accessible locations within a metropolitan area. Our focus is on station-based car sharing systems with round-trips, i.e., customers are obliged to return the rented vehicles at the start station. We present a novel approach for the availability control in such systems. The proposed availability control accounts for stochastic demand and the strong temporal interdependencies between acceptance decisions that arise from limited battery capacity and long-recharging times. A decomposition approach is presented to approximately solve the model. The result is an acceptance-denial policy that significantly outperforms the first-come-first-served ap-proach currently used in industry. ", :title "Controlling the availability of electric vehicles in station-based car sharing systems with round-trips", :keyword2 150, :authors (45151 45372 15178 2651), :session 101}, 759 {:keyword1 161, :keyword3 0, :abstract "Often, in Linear Vector Optimization Problems, one is confronted with a large number of variables, whereas the dimension of the outcome space is of considerably lower dimension. Taking advantage of this observation, Benson proposed an outcomespace-based outer approximation algorithm. Later, Ehrgott, Löhne and Shao presented a dual variant of this algorithm, and recently, Hamel, Löhne and Rudloff provided further improvements and extensions to Benson's algorithm.\r\nThe aim of the talk is to present an implementation of this algorithm along with several enhancements that were made. Therefore, in the first part we will explain what we consider to be a \"Linear Vector Optimization Problem\" (LVOP) and state an appropriate solution concept. In the second part, we will show how such a solution can be computed by iteratively approximating the so called \"upper image\" of the LVOP, a polyhedron which is defined to be the image of the objective function over the feasible set plus (Minkowski) the ordering cone (an arbitrary pointed solid polyhedral cone). In order to compute the outer approximation polyhedra in each iteration step, we need to solve one linear programm. The solution of this LP defines a \"cutting plane\", which is used to refine the outer approximation. Ascertaining the resulting polyhedron as intersection of the old approximation and the affine halfspace induced by the cutting plane is called \"vertex enumeration\". We will show how the vertex enumeration can be computed efficiently by using adjacence- and incidenceproperties of the polyhedra. Also the reduction of computational expenses for solving the LP's in every iteration step by utilizing the common structure of these LP's (warmstarts) will be considered.\r\nEventually, we will present computational examples.", :title "bensolve -- A tool for solving Linear Vector Optimization Problems", :keyword2 0, :authors (44697 19168), :session 87}, 760 {:keyword1 28, :keyword3 127, :abstract "Electrical power demand and supply fluctuate over time, but have to be balanced in the electrical power net. For the private household sector, further fluctuations of demand are expected to increase with the diffusion of power intense technology like battery electric vehicles (BEVs) and heat pumps. By applying demand side management (DSM), either by incentives or direct control instruments, utilities influence energy demand.\r\nAgainst this background, the aim of this paper is to present a methodology to analyze the impact of DSM on household energy demand. Thus, we develop a two step model, which, first, generates household load profiles and, second, adjusts the load profiles in reaction to the used DSM instrument. The load profile of each household is generated by a bottom-up simulation model due to the complexity and randomness of residential appliance usage. In reaction to DSM, each household may alter its appliance usage, considering both cost minimization against its own comfort of living. Therefore, each household is modeled as a bi-criterial, mixed integer linear program for the second step. The MILP considers both a structural level of the energy infrastructure of the household, and a behavioral level of the resident behavior. By the disaggregated level of modeling different energy carriers, energy storage and transformation are considered for each household. \r\nThe developed model is applied to a case study of a future household sector which includes prospective appliances. Different types of appliances such as BEVs, heat pumps, battery storages and combined heat and power generators are considered. Implications from the utilization of DSM for the households, the utility and the power net are derived by the case study.", :title "Demand side management for the household sector  – case study of prospective household technologies", :keyword2 158, :authors (45134 2650), :session 199934}, 762 {:keyword1 8, :keyword3 157, :abstract "The graph coloring problem corresponds to assigning a minimum number of colors to the vertices of a graph such that no two vertices of an edge get the same color. The problem is used in scheduling, timetabling, and telecommunications networks. However, in real-life problems assignments that are feasible may conflict as a result of unforeseen circumstances (e.g. delays). When we consider unforeseen circumstances, a feasible assignment may still be undesirable. In the robust graph coloring problem, every pair of vertices that can be assigned to the same color has a cost coefficient, representing undesirability of the assignment. The robust graph coloring problem is to create a valid coloring of a graph by minimizing the total cost of the assignment. The problem is used in scheduling where tasks are subject to delays and cost coefficients represent the probability and the effect of delays. In our work, we model the robust graph coloring problem by modifying the asymmetric representatives formulation, originally used for the graph coloring problem. In the formulation, representative vertices are used in order to represent vertices belonging to the same color class. The formulation reduces symmetry in the problem. We present various classes of valid inequalities as well as their separation procedures. We discuss a column generation scheme and present computational results.", :title "A Branch-and-Cut algorithm for robust graph coloring", :keyword2 42, :authors (10362 3558 14274), :session 199903}, 763 {:keyword1 149, :keyword3 152, :abstract "The paper presents the results of an empirical testing of Altman's Z-Score model in transitional economy conditions as are in Serbia today. The authors chose as research sample the enterprises in recycling industry, because these enterprises are not heavily affected by the financial crisis in the period after 2008. Namely, regardless of the consequences of the economic crisis, the recycling industry in Serbia shows an increase in both total assets, as well as in total income of the sector. Also, the percentage of processed municipal and electrical waste in Serbia is still low for EU standards, but is increasing in recent years. These facts indicate growth and development of the recycling industry in Serbia. On the other hand, the recycling industry is particularly affected by problems specific for transitional economies: (1) unregulated supply market and landfills that do not meet the standards for collection and classification of waste, leading to difficulties in continuous supply of recyclers and (2) corruption scandals related to government subsidies and state financing of waste collection and processing, leading to unequal market position of enterprises in this industry. These characteristics of the sample creates a relevant basis for testing reliability of the model just in terms of issues specific for economies in transition, abstracting the impact of financial crisis. The aim of the paper is to test Altman's Z-Score model in terms of its reliability in predicting performance of the enterprises within two years lag period. Predictive value of Z-Score model is going to be statistically tested by investigating the relationship of model's results with profitability in terms of ROA, ROE, Liquidity Ratio and Net Income of enterprises in sample.", :title "Reliability Assessment of Altman’s Z-Score Model to Predict Financial Distress of Enterprises in Transitional Economy", :keyword2 25, :authors (42388 43641 45294), :session 51}, 764 {:keyword1 101, :keyword3 159, :abstract "Today's decision making problems are discrete, multi-criteria and involve multiple decision maker (DM).Organizations use the GDM techniques because of the problem's complexity. One of the key questions in this type of problems is how the preferences of the DMs can be modeled. DMs are able to provide only incomplete information, because of time pressure, lack of knowledge, and their limited expertise related to the problem domain. In these types of situations the DSS should allow modeling of the incomplete preference information. In this study we developed an interactive procedure which uses incomplete information preference information. Main theme underlying the method is every group member wants to compare their partial information with other group members. This procedure reflects the incomplete information as linear range because it can count easily from partial utility information. Range type makes the incomplete information effective and efficient to demonstrate the group members. In addition to this, range type utility information makes easy to compare every group members’ utility information with group’s information and collecting the each group member’s utility information within group’s utility information. To obtain group utility, preference aggregation method is used. Interactive procedure helps to make a consensus of group. The method uses the criterion of realism (Hurwicz) and for this it uses the infinity of knowledge. We used this method for the evaluation of the performance of organization companies as the service suppliers of a pharmaceutical company. The suppliers’ utility information calculated by using optimism coefficient which is determined by the group. The supplier which has the highest utility is selected. ", :title "SUPPLIER SELECTION WITH UTILITY RANGE-BASED INTERACTIVE GROUP DECISION MAKING METHOD", :keyword2 44, :authors (45293 29699), :session 199860}, 765 {:keyword1 95, :keyword3 0, :abstract "Each year millions of tons of hazardous materials are transported across Europe. Hazardous materials are substances, which if released or misused can pose significant impacts to human life and the natural environment. Therefore, the transportation and vehicle routing of hazardous materials must be carefully managed. We consider a practical variant of the vehicle routing problem, where a weighted distance criterion is involved, that results from the risk of hazardous materials passing on road links. Thereby, the risk of a vehicle load on a road link is computed using the risk factors presented in the \"European agreement concerning the international carriage of dangerous goods by road\" (ADR). The problem is modeled as a mixed-integer linear program and small-scale problem instances are solved with CPLEX. In order to solve large-scale instances heuristically, a genetic algorithm is presented that uses a random key representation. Computational experiments are conducted on benchmark problems from the literature in order to evaluate the performances of the proposed solution procedures. ", :title "A new approach for the vehicle routing of hazardous materials", :keyword2 59, :authors (9524 33700 5965), :session 199946}, 766 {:keyword1 88, :keyword3 18, :abstract "Call centre staffing is important as the workforce accounts for 60-70% of the operating cost of a call centre. The staffing procedure involves two distinct but interrelated research areas: a) forecasting the call arrival rates and b) modelling the call centre as queueing system to decide on staffing levels, using the forecast arrival rates.\r\n\r\nWe introduce a geometric discrete time modelling (Geo-DTM) approach and use it with an iterative-staffing algorithm (ISA) to determine staffing levels. Empirical tests show that under perfect knowledge of arrival rates, there are many benefits of using the Geo-DTM+ISA method compared to steady-state staffing methods.\r\n\r\nWith simulated call arrivals data, we evaluate the effects of forecasting errors on call centre performance using various forecasting models and the Geo-DTM+ISA for staffing. The results show that even with a good quality dynamic queueing model (Geo-DTM+ISA), better forecasting accuracy does not necessarily translate into better service levels. The system performance exhibited depends on a combination of factors.\r\n\r\nWe also study the combined effects on call centre performance in the likely practical case where both forecasting and queueing models are suboptimal. Our results show that under a quality driven service regime, stationary models perform similarly to Geo-DTM+ISA. However, under an efficiency driven service regime, the stationary based staffing methods perform much worse than Geo-DTM+ISA, although both are affected by forecasting errors. Insights from the empirical results are used to provide guidance for call centre workforce management. What proves important is the interaction between uncertainty, forecasting accuracy and the call centre planning system. No element should be analysed in isolation.", :title "Sometimes two wrongs can make a right - Combining forecasting and queueing models for call centre staffing", :keyword2 37, :authors (16621 15364 3669), :session 199891}, 767 {:keyword1 42, :keyword3 65, :abstract "In the network design game with n players, every player chooses a path in an edge-weighted graph to connect her pair of terminals, sharing costs of the edges on her path with all other players fairly. We study the price of stability of the game, i.e., the ratio of the social costs of a best Nash equilibrium (with respect to the social cost) and of an optimal play. It has been previously shown that the price of stability of any network design game is at most H(n), the n-th harmonic number. This bound is tight for directed graphs. For undirected graphs, the situation is dramatically different, and tight bounds are not known. It has only recently been shown that the price of stability is at most (1-1/n^4)*H(n), while the worst-case known example has price of stability around 2.25. We improve the upper bound considerably by showing that the price of stability is at most H(n/2) + eps for any value of eps > 0 (starting from some suitable n > n(eps)).", :title "New Bound on the Price of Stability for Network Design Games", :keyword2 40, :authors (19047 45254), :session 199885}, 769 {:keyword1 120, :keyword3 101, :abstract "Continuous changes in product design and market conditions imply that product variants which have been produced in the past may not be valid in the future. Nevertheless, customer order history is an important input for capturing customer buying behavior, required for future planning activities. In order to extrapolate associations among products features and their validity against new product design, we propose a fully automated association rule mining with satisfiability (SAT) framework. Design rules are modeled as SAT problem and generated association rules are filtered by solving an instance for SAT problem. The methodology is demonstrated using an industry size example.\r\n", :title "Integrating satisfiability framework in association rule for better customer buying behavior analysis in mass customization", :keyword2 5, :authors (24063 28300), :session 199854}, 771 {:keyword1 63, :keyword3 67, :abstract "Important efforts contributing to Extreme Value Theory lead to determine (sufficient) statistics that reduce an infinite-dimensional multi-criteria problem to an equivalent problem defined in a finite-dimensional space. Is it possible to address the original problem without calculating statistics for optimizing? Vector Optimization Theory successfully solves infinite-dimensional problems, it however requires preference cones to have a non-empty interior (i.e., the property of solidness), which is not true in some relevant spaces of random variables. Fortunately, a recent theoretical work (still in press) restores the optimization results without requiring solidness property. We apply this work to a portfolio optimization problem in a space of random variables, whose cones do not satisfy solidness. This document presents a summary of the application. We obtain the solution to the original problem without the need of defining statistics. Finally, we propose to deepen our analysis, as it is possible to extend this application to a new scalarization procedure, which requires neither linear spaces nor transitive preferences.", :title "Portfolio optimization without sufficient statistics", :keyword2 35, :authors (26217 12787 45295), :session 199837}, 772 {:keyword1 124, :keyword3 167, :abstract "The mathematical problem of credit scoring is often formulated as a binary classification task. Due to the nature of the problem, defaults rarely occur and the classes are therefore highly imbalanced.\r\nIn contrast to the balanced setting and the many methods available for it,\r\nthis aspect is still underrepresented in research despite its great relevance\r\nfor many business applications, e.g., in response modeling or medical diagnosis.\r\nImbalancy can substantially degrade the performance of a binary classifier - \r\nin the extreme resulting in a trivial majority vote.\r\n\r\nWe have set up a systematic benchmark study for a real world credit scoring classification task\r\nin the open source framework \"Machine Learning in R\" (mlr).\r\nWe will compare popular ways of mitigating the imbalancy problem in this setting.\r\nResults are presented and discussed concerning both the benefit of possible\r\nstrategies as well as the effect of classifier choice and tuning parameters.\r\n", :title "On class imbalancy correction for classification algorithms in credit scoring", :keyword2 153, :authors (45203 44795), :session 73}, 773 {:keyword1 67, :keyword3 34, :abstract "The mean-variance problem introduced by Markowitz in 1952  is a \r\nfundamental model in portfolio optimization up to date. This problem is \r\nparticularly hard to solve when cardinality constraints are added, \r\nbecause the problem  then becomes non-convex and NP-hard. This problem \r\noften includes  transaction level constraints, that is, minimum and \r\nmaximum portions held of an asset, if it is held at all. The existing \r\nexact methods for such problems take a huge amount of time to give \r\nsolutions, which render them practically hard to apply.\r\n\r\nThe aim of this talk is to introduce a method that provides tight lower \r\nand upper bounds to the mean-variance portfolio optimization problem \r\nwith  cardinality  and transaction level constraints. The method \r\ninvolves performing eigendecomposition of the covariance matrix and then \r\nusing only a few of the eigenvectors and eigenvalues to obtain a \r\nrelaxation of the original problem. This relaxation, when solved, gives \r\na lower bound to the optimal value of the original problem. The solution \r\nto the relaxed problem is then used to obtain feasible solutions to the \r\noriginal problem and upper bounds.\r\n\r\nThe obtained upper and lower bounds are tight and the computing time \r\nrequired to obtain them is much less than what state-of-the-art \r\nmixed-integer proramming softwares use.  We test the method on \r\nlarge-scale problems of up to 1,000 assets and the results are not only \r\ngood but can also be obtained in a reasonable amount of time, which \r\nmakes it practically usable.", :title "Tight bounds on the cardinality constrained mean-variance portfolio optimization problem using truncated eigendecomposition", :keyword2 158, :authors (12736 45299 29723), :session 51}, 774 {:keyword1 149, :keyword3 167, :abstract "We investigate the influence of company fundamentals on the mid-term development of a company's stock price. Contribution to the literature is three-fold: 1.) We filter using several fundamental indicators. This reduces the number of potential portfolio candidate. 2.) We specifically consider a mid-term investment of several weeks as opposed to a daily or yearly investment horizon. 3.) We focus on the importance of including debt in the relevant indicators.", :title "Company fundamentals as mid-term predictive indicators", :keyword2 35, :authors (45296 19080), :session 83}, 775 {:keyword1 17, :keyword3 0, :abstract "Data Envelopment Analysis (DEA) is a nonparametric approach to measure the relative efficiency of decision making units (DMUs). One of the most popular DEA approaches is the BCC model by Banker, Charnes and Cooper (1984). It is a well-known result that the sign of the BCC scale variable indicates whether increasing, decreasing or constant returns to scale prevail for a DMU. Moreover Rödder, Kleine and Dellnitz (2012) proof that the scale variable reveals the efficiency change due to a monocentric scaling of inputs and outputs. In this contribution we interpret the value of the scale variable from an additional economic point of view. It is shown that the optimal value of the scale variable corresponds to an hidden output. The idea is illustrated by a balance sheet and a numerical example.", :title "DEA-scale variable from an economic point of view", :keyword2 19, :authors (14890 9874), :session 199833}, 780 {:keyword1 7, :keyword3 167, :abstract "We use high-frequency option data to build a market model of option prices. To this end we train an artificial neural network. The network is retrained on a rolling window basis. The results can be used for real-time option pricing or for short-term forecasting.", :title "Short-Term Market Models for Option Prices", :keyword2 32, :authors (19080 19100), :session 83}, 781 {:keyword1 157, :keyword3 0, :abstract "The Rapid Transit Challenge is a challenge in which participants have to traverse an entire subway network in the shortest possible time. There are two main variations of this challenge:\r\nIn the first the rider is required to cover all lines, i.e. traverse every distinct segment between two station in any direction, while for the second only every station complex needs to be visited.\r\nTo efficiently model those two problems, it is crucial to take directions and changing times between lines and directions into account. The problem then corresponds to a special type of Routing Problem on a directed graph, closely related to the Directed Rural Postman Problem and the Generalized TSP.\r\nIn this context we will present an IP-based branch-and-bound approach using dynamic constraint generation. By exploiting the special structure of the underlying transportation network, we were able to solve the Rapid Transit Challenge for large real-world subway networks, such as Berlin and New York City, very efficiently.", :title "Integer Programming Approaches for the Rapid Transit Challenge", :keyword2 95, :authors (26292), :session 199914}, 782 {:keyword1 176, :keyword3 2, :abstract "Optimization problems abound in air traffic management. A relevant\r\nproblem consists in scheduling the landing and departing airplanes on\r\na runway. In this talk, we consider a single runway. The task is to\r\nassign each airplane a discrete time slot such that the makespan is\r\nminimized. Each time slot can be assigned at most once to either a\r\nlanding or a departing aircraft. The freedom of the ordering is\r\nlimited by precedence constraints that are present between some pairs\r\nof aircraft. In practice, there exists an arrival planner and a\r\ndeparture planner that can assign time slots to aircraft. First, we\r\npresent a mathematical model for the `worst-case' scenario in which\r\nthe arrival planner and the departure planner act as adversaries and\r\nalternatingly assign a certain time slot to some aircraft, together\r\nwith computational results. The model yields an integer program\r\ntogether with quantifier variables. For an instance, it answers the\r\nquestion whether there exists a successful scheduling strategy for the\r\narrival planner, irrespectively of the strategy of the departure\r\nplanner.\r\n\r\nSecondly, we present a model for runway scheduling with precedence\r\nconstraints in which the arrival and the departure planner cooperate\r\nin order to derive improved schedules. The task of determining an\r\noptimum slot assignment for landing and departing airplanes\r\nsimultaneously is modeled as a linear mixed-integer problem. Its\r\npolyhedral structure is analyzed. Furthermore, the complete facial\r\ndescription is derived for the corresponding assignment problem with\r\none additional precedence constraint.", :title "The Assignment Problem with Precedence Constraints and its Application in Air Traffic Management", :keyword2 96, :authors (17115 39553 14713 13046), :session 81}, 784 {:keyword1 94, :keyword3 0, :abstract "Water network optimization can benefit water utilities by improving operations, such as finding lowest-cost pump schedules or determining valve placements and settings that result in minimal leakage. The formulation of such an optimization problem requires modeling the network and the progression of node pressures and water flows over time.  The time discretization step for the resulting differential-algebraic equation must be chosen carefully, because a large time step can result in a solution that is feasible for the discretized model, but not feasible for the physical (continuous) system, whereas small time-steps impact the tractability of the optimization problem at hand.  In the study of water networks, the basic forward Euler method is the universally accepted method of choice, even though its limitations are well-known.  We show that a large time step can result in meaningless numerical results, and we construct an upper bound on the error in the tank pressures found by using a forward Euler scheme for a general network.  This error bound is then used to construct an optimization formulation that is robust to the discretization error. While many classical approaches for robust optimization dealing with uncertainty in the input data have been proposed, robust optimization with respect to uncertainty in the modeling of the system is novel in water network optimization. \r\n \r\nWe provide methods to find an upper bound on the discretization error for a chosen network and to formulate an optimization problem that is robust to the model uncertainty. These methods can be used to optimize water network operation given the error introduced by time discretization. Results are shown for these methods using our test network.", :title "Robustness to Time Discretization Errors in Water Network Optimization", :keyword2 133, :authors (41108), :session 69}, 786 {:keyword1 92, :keyword3 18, :abstract "\r\n \r\nEvery company selling a physical product has to decide on the related warranty issues. One of these issues concerns: what to do with products or parts replaced in the context of a warranty claim?\r\nAn overview is given of a number of potential reasons for taking care of these products or parts, as well as simple mathematical models to estimate the costs and benefits related to each reason individually as well as for combinations of these reasons. Application of the models in practice is briefly discussed and directions for further research are indicated.  \r\n \r\n", :title "On the value of warranty returns", :keyword2 25, :authors (25632), :session 199847}, 787 {:keyword1 8, :keyword3 73, :abstract "Before applying as teacher trainees, students in North Rhine-Westphalia have to complete at least one internship (6 months) at a school. These internships are centrally organised and can be scheduled during the summer or winter term, respectively. A feasible assignment of students to schools must respect subject specific capacity constraints at the schools and at the associated centers for teacher education. Under these constraints the assignment is optimized with respect to individual preferences of students and distances between students and schools.\r\n\r\nThe problem is formulated as a discrete, assignment-like optimization problem that has an interesting structure due to the conjunction of the two majors of every student (e.g., Mathematics and Physics, Biology and English,...) with the subject specific capacities at the schools and at the centers for teacher education. We discuss relations to multi-commodity network flow models and suggest both exact and heuristic solution algorithms. The methods are illustrated at problem instances for students from Wuppertal.", :title "Assigning University Students to Schools for Internships in Teacher Education", :keyword2 65, :authors (1560 45302 21205 9695), :session 199918}, 788 {:keyword1 40, :keyword3 0, :abstract "We consider intertwined optimization problems with multiple autonomous decision makers, which are represented by corresponding agents within a strategic environment. These agents deal with a common set of feasible solutions (contracts). This combined solution space (contract space) is complex since, firstly, even for a single agent the calculation of an optimal solution may constitute an NP-hard problem, and, secondly, one has to cope with self-interested agents with conflicting goals and private information. The problem is to mutually determine a commonly accepted solution as the eventual contract which should account for all agents' individual goals to some degree. Such kinds of coordination problems impose restrictions on the design of possible solution mechanisms, which may be regarded as negotiation procedures. In particular, one cannot presuppose that the involved parties truthfully disclose private information (i.e., their preferences) and honestly observe any conceivable rule. On the contrary, the applicability and effectiveness of a solution mechanism depends on a sensible design of verifiable negotiations rules under consideration of the incentives of the involved agents. After reviewing research on negotiation-based search mechanisms which address these concerns, we adapt and extend general negotiation procedures regarding i) how new contract proposals are generated, ii) which questions are directed at the involved agents, and iii) how iterative decisions are conducted to advance the search process. These concepts are experimentally evaluated for multi-agent sequencing problems under consideration of the incentives of self-interested agents.", :title "Design and evaluation of algorithmic mechanisms for hard multilateral multi-issue negotiation problems", :keyword2 0, :authors (7569 20363), :session 199889}, 790 {:keyword1 86, :keyword3 0, :abstract "Due to a considerable degree of uncertainty, the generation of baseline schedules for the execution of product development projects is a challenging task. In order to cope with unforeseen disruptions during project execution, research efforts have been made in the area of robust project scheduling. There, uncertainty is most often treated by modeling activity durations as random variables with a known distribution. However, due to creative engineering tasks, lack of historical data and vague specifications of product characteristics, it is not trivial to define appropriate distribution functions. Thus, some authors propose the use of fuzzy logic to account for imprecision in the data. When combining fuzzy logic and robust project planning, the challenge lies in evaluating the robustness of the resulting schedule. \r\nIn this context, we examine the suitability of existing robustness measures for the assessment of fuzzy project plans. To this end, we present a basic model formulation of a multi-mode resource-constrained project scheduling problem (RCPSP) with fuzzy activity times and a pre-specified project deadline. Using a numerical example to illustrate the solution structure of fuzzy project plans, the applicability of different robustness measures is discussed. Finally, an outline of a robust scheduling methodology for the presented multi-mode RCPSP with fuzzy activity times is presented. \r\n", :title "A multi-mode RCPSP with fuzzy activity times for robust scheduling of product development projects", :keyword2 39, :authors (45301 15187 2651), :session 199871}, 792 {:keyword1 29, :keyword3 59, :abstract "In this paper, we investigate the problem of scheduling workflow applications on cloud computing infrastructures. The cloud workflow scheduling is a complex optimization problem which requires considering various scheduling criteria. Traditional researches mainly focus on optimizing the time and cost without paying much attention to energy consumption. We propose a new approach based on the hybridization of a CSP with a genetic algorithm heuristic to optimize the scheduling performance by (a) formulating a model for task-resource mapping to minimize the overall energy consumption using the dynamic voltage scaling (DVS) technique; and (b) designing a heuristic that uses hybridization of a CSP with a genetic algorithm to solve task resource mapping based on the proposed model. Our approach is validated by simulating a complex workflow application.", :title "Hybridization of a CSP with a genetic algorithm for workflow scheduling based on energy-aware in cloud computing environment", :keyword2 96, :authors (22515 45303 20786), :session 199875}, 797 {:keyword1 59, :keyword3 5, :abstract "Distributed computing is the next generation of computing environments is called ubiquitous computing. The purpose of ubiquitous computing is to render and allow the computing to being ubiquitous and discreetly accessible to the user at any time and anywher, while integrating technologies and communication in daily life people (person) in a strong way. This information accessibility and flexibility of ubiquitous computing, making it vulnerable to attacks. This requires the detection of security breaches when they occur. Our goal in this article is to explore the possibility of detecting intrusions (attacks) occurred in ubiquitous environments using genetic algorithm approach. ", :title "Intrusion detection system performance in ubiquitous environments using genetic algorithm approach", :keyword2 133, :authors (45046 22533 45572), :session 199831}, 804 {:keyword1 162, :keyword3 157, :abstract "We consider the problem of minimizing a polynomial over the integer lattice, which is an NP hard problem in general. Since it has many applications and interesting special cases, tractable subclasses of the problem need to be identified. Existence of global integer minimizers is related to the leading form of the polynomial, i.e. its highest order terms: A well-known sufficient condition for the existence of continuous and integer minimizers is a leading form that attains positive values only - except at zero. For example, in the univariate case this condition simplifies to an even degree and a positive leading coefficient.\r\n\r\nIf this condition holds, we algorithmically determine a finite box containing an integer minimizer, having smaller box size than boxes known from literature. Once the box is fixed, we may find the minimizer by branch and bound. For an effective bounding, we introduce a new class of underestimators having integer minimizers which can be directly determined. By this method we obtain a lower bound on the value of the integer minimizer of the polynomial. Numerical results show the quality of the lower bound. Since it is possible to compute an optimal underestimator from this class during preprocessing, we omit time-consuming computations at each subproblem. Using results from real algebraic geometry, it is possible to further tighten the lower bound.\r\n\r\nThe resulting branch and bound procedure has been implemented and tested on random instances.", :title "Lower Bounds for Global Polynomial Integer Optimization", :keyword2 41, :authors (45070 29561 1601), :session 75}, 811 {:keyword1 174, :keyword3 44, :abstract "The logistics and transportation sector has undergone fundamental changes in the past decades. Intensified competition on global markets along with heightened customer expectations lead to increased pricing pressure. However, increased efficiency can be achieved if freight carriers collaborate by trading their transportation requests. In the highly competitive shipping and transportation industry, companies need to achieve a maximum level of efficiency in order to stay in business.  Our study is based on an auction based exchange mechanism which has been presented by Berger and Bierwirth [1]. They provide a framework of methods for maximizing the total profit of the network while enabling the carriers to reveal as few as possible private information. Results are compared to those obtained by central planning and to a situation where carriers do not collaborate at all. Investigations are based on three levels of competition according to the geographical composition of customer areas. The integrated tour planning method constitutes the traveling salesman problem with precedence constraints (TSPPD) and is solved by exact algorithms. We replace their exact and thus costly tour planning process by a heuristic approach. Furthermore, we include new carrier strategies and show their effect on the total profit of the collaborative carrier network. Our heuristic based framework shows promising results while we are able to handle problems with an increased number of transportation requests. \r\n[1] Berger, S., Bierwirth, C. (2010). Solutions to the request reassignment problem in collaborative carrier networks. Transportation Research Part E 46: 627-638.\r\n", :title "Improving an auction based exchange mechanism for the collaborative carrier routing problem", :keyword2 95, :authors (39372 45307 10538), :session 26}, 814 {:keyword1 158, :keyword3 0, :abstract "Let F be a frame, which is a spanning set, of a real vector space and let v be a vector in the same space. Our goal is to represent v as a linear combination of elements of F and to use as few elements of F as possible.\r\n\r\nThe problem has applications in image processing, e.g. when a picture is wanted to necessitate as little storage space as possible, and in signal processing, e.g. when a decomposition of a piece of music into the individual acoustic signals of the contributing instruments is required.\r\n\r\nThe NP-completeness of the problem is known.\r\nIn our talk we use a formulation of the problem as an integer linear program [see Jokar and Pfetsch 2008], which requires big-M constraints, where M is an upper bound on all entries of at least one optimal solution of the original problem. Since M depends on the corresponding frame F, we use properties of F in order to decrease M.\r\n\r\nIn particular, we determine the size of M in the integer linear programming formulations for the following two frames:\r\nfirstly the frame consisting of all the vectors of the standard basis together with the columns of the N-dimensional normed Haar matrix and secondly the standard basis vectors together with the transposed rows of the N-dimensional normed Haar matrix.\r\nThe individual structures of both frames are used to obtain big-M constraints which are small enough to allow the application of the integer linear program to vectors of dimension 16 up to 4096. Finally, optimal solutions to the nonlinear problem for each of the two frames are obtained.", :title "Mixed-integer optimization of sparse representations of vectors in frames", :keyword2 153, :authors (45288 1601 45308), :session 199905}, 817 {:keyword1 175, :keyword3 174, :abstract "This paper considers the optimization problem of trains schedule for single track railway. The main motivation for this work is a need of efficient utilization of railway infrastructure available in Australia, thus the mathematical modelling inspired by practical issue is developed.\r\nThe model presented in the paper aims to maximize number of trains that could carry out the route in the given time interval, avoiding deadlocks. Firstly a basic model which allows optimization work is defined, under assumptions regarding time, route, capacities of the stations, intervals between stations and velocity of the trains. Therefore the minimal time consuming model with finite capacities is developed and presented, referring to particular conditions.\r\n\r\n", :title "Single Track Railway Problem", :keyword2 96, :authors (45116 5390 4224 14844), :session 199944}, 819 {:keyword1 17, :keyword3 101, :abstract "This work presents an analysis of the relationship between efficiency and the use of information and communication technologies (ICT) by logistic service providers (LSP) that operate in temperature controlled supply chains. The study was performed using secondary data collected from 2007 to 2013 of the Brazilian cold supply chain market. Technical and scale efficiency scores were determined with DEA (Data Envelopment Analysis) models and multivariate statistical procedures for the selection of input-output variables of the transformation process of inputs into logistic services. The relationship between efficiency scores of LSP and their use of ICT were established with regression models for groups of LSP according the use of exclusively own fleet, exclusively third fleet, as well as own plus third fleet of trucks in their operations. Results show a weak relationship between use of ICT and efficiency scores. Merely groups of LSP that operate with ICT related to third fleet of trucks show higher technical and scale efficiency scores. This indicate that LSP that operate with own fleet tend to reveal lower efficiency scores when compared with the former group. The lack of strong sensitivity of the use of ICT with the observed efficiency of LSP in temperature controlled supply chains seems to indicate that investments in these technologies have no measurable effect on the efficiency, and therefore, on productivity.", :title "On the relationship between efficiency and use of information and communication technologies in cold supply chains", :keyword2 174, :authors (8258 41995 44983), :session 24}, 820 {:keyword1 165, :keyword3 99, :abstract "Stochastic programs are usually formulated with probability distributions that are exogenously given. Modeling and solving models of endogenous uncertainty, where decisions can influence the probabilities, has remained a largely unresolved challenge. In this talk we present a new approach to handle endogenous uncertainty in stochastic programs for the case of decision-dependent probabilities, called distribution shaping. It enables an efficient characterization of decision-dependent probability measures based on the observation that neighboring probability measures in the space of the influencing binary decision variables, linearly related according to Bayes' Rule. Accordingly, we derive a successive polyhedral characterization of probability measures as a function of decisions and reformulate the corresponding nonlinear stochastic programs as mixed-integer programs. We demonstrate the effectiveness of the approach on two example problems. The first example is a pre-disaster planning problem of finding optimal investments to strengthen links in a transportation network, given that the links are subject to stochastic failure. Using the new approach, a recently considered instance of the Istanbul highway network can be solved to optimality within seconds, for which only approximate solutions have been known so far. The second example is a stochastic project planning problem, where individual activities have a risk of exceeding their allocated planned duration. This probability can be reduced by investing additional resources, and our approach allows to find an investment plan to that minimized expected project duration.", :title "Distribution shaping and scenario bundling for stochastic programs with endogenous uncertainty", :keyword2 42, :authors (17127 10025 37741), :session 199882}, 821 {:keyword1 75, :keyword3 0, :abstract "Lead time reduction is one of the main goals when one wants to pursue a concept of a lean and agile modern supply chain. However, many companies that have actively embarked on the projects related to reducing the lead times were, at least in a short run, faced by the fact that their customer service performance suffered. This has forced the customers to search for or stick with the alternative, more reliable, supply channels, through which they would improve the supply process reliability. We study a customer’s perspective of this problem by modelling a periodic review, single stage dual sourcing inventory system with non-stationary stochastic demand, where replenishment can occur either through a regular stochastically capacitated supply channel and/or an alternative uncapacitated supply channel with a longer fixed lead time. While most of the multiple supplier research explores the trade-off between purchasing costs and indirect costs of holding safety inventory to cover against demand and supply variability, our focus lies more in studying the effect of capacity and lead time on supply reliability and the customer’s order allocation decision to suppliers. In addition, we study a situation in which the unreliable supplier provides upfront information on capacity availability, denoted as advance capacity information, to the customer. We derive the optimal dynamic programming formulation and we show some of the properties of the optimal policy by carrying out a numerical analysis. Additionally, our numerical results on the benefits of dual sourcing and the value of sharing advance capacity information reveal several managerial insights.", :title "Dual Sourcing Inventory Model with uncertain Supply and Advance Capacity Information", :keyword2 99, :authors (12938 995), :session 199955}, 823 {:keyword1 8, :keyword3 91, :abstract "District heating networks (DHN) can provide higher efficiencies and better pollution control\r\ncompared to local heat generation. However, there are still many areas, which can be improved\r\nand optimized in these systems. A DHN is a complex distributed system of different customer\r\nsubstations and components such as boilers, accumulators, pipes, and in many cases also turbines for electricity production. How to schedule the components with the objective of maximizing the profit of heat and electricity production over a finite time horizon is receiving increased attention [1-3], and is the problem that has been dealt with in this work. This mixed integer linear programming (MILP) problem has been formulated as a unit commitment problem, which involves finding the most profitable unit dispatch regarding production costs and heat and electricity sell prices, while simultaneously meeting the predicted district heating demands and satisfying network operational constraints. The heating demands within the optimization time horizon are predicted based on season and weather forecasts. In this work, the district heating plant in Uppsala,\r\nSweden, owned by Vattenfall ab, has been considered as a reference plant for modeling and optimization. The optimization model is formulated in python using pyomo modeling language, and\r\n\r\nSolved by the gurobi solver. An hourly-based data of five consecutive days is used as the time horizon. The results demonstrate the fact that with an accurate model of the DHN, it is possible to significantly increase the revenue of the DHN by finding the most economical way to dispatch different production components.", :title "PERFORMANCE IMPROVEMENT OF SHORT-TERM PRODUCTION PLANNING  FOR DISTRICT HEATING SYSTEMS ", :keyword2 158, :authors (45255 29034 45313 45314 45315 45316), :session 199852}, 824 {:keyword1 40, :keyword3 19, :abstract "Since 9/11 terrorist threats are much more present in the European countries’ preventative security and intelligence strategies. However, risk management is still dominated by methods which focus too much on historical frequencies and do not sufficiently account for the terrorists’ motives and for the strategic component of the interaction between offender and defender. One alternative is to cluster the wide field of terrorists’ motives by type and to set up a corresponding defender-offender-game with incomplete information on both sides. The defender is uncertain about the terrorist’s type which we reduce to two exemplified variants, both well established in terrorism research: The fanatic (‘irrational’) terrorist strives to spread maximum damage and fear whereas the subversive terrorist uses attacks as a symbolic and specifically addressed communication device. Additionally also the terrorists face uncertainty with regard to random events which e.g. determine the success of an attack or the amount of collateral damage. In this paper we analyze the difference between these two approaches. We model the classical risk management approach by a specific variant of fictitious play and compare it with the outcome of the sequential game of incomplete information. We find that the latter allows for a more purposeful use of security measures as the defender avoids to get caught in a hare-and-tortoise-trap. We specify the conditions under which the incomplete information-model outperforms fictitious play in the sense that it lowers the cost of defense at a given rate of deterrence. We analyze the robustness of our results and discuss the implications and requirements for practical application.", :title "Strategic Deterrence of Terrorist Attacks", :keyword2 93, :authors (45048 45317 2675), :session 199886}, 825 {:keyword1 31, :keyword3 0, :abstract "The energy- and ressource-efficient design of production processes is nowadays a crucial com-petitive factor for producing companies. Considering the actual discussion along the field of sus-tainability, producing companies strive to improve energy- and resource-efficiency. To achieve this goal, managerial and operational measures (MOM) have to be planned and implemented. A major challenge for the planning of MOMs is the evaluation of their ecological effectiveness. Here three characteristics arise. First, MOMs in general effect multiple ecological index numbers. Sec-ond, there are numerous interdependencies in the flow of materials and energy within a produc-tion system, which are affected by the implementation of an individual managerial or operation-al measure. Third, multiple measures are interdependent as well and thus cannot be cumulated easily. Common approaches in the evaluation of MOMs typically focus on their individual evalua-tion regarding a specific ecologic measure for a specific production process. An evaluation re-garding the whole production system as well as the interdependencies to other managerial or operational measues is missing.\r\nIn this paper, a modell based evaluation approach is developed, which takes interdependencies of the flow of materials and energy as well as interdependencies between MOMs. The evaluation approachis based on a modular multi-layer model of the flow of materials and energy. This mod-el explicitly incorporates all described interdependencies. The modular design of this model allows for a sufficiently accurate and problem adequate modelling of the production system. This approach is the base for the development of a decision support tool for the planning and implementation a bundle of efficient and MOMs.\r\n", :title "Evaluation of managerial and operational measures to improve ressource- and energy-efficience in the automotive industry", :keyword2 102, :authors (45306 17130 2651), :session 99}, 827 {:keyword1 8, :keyword3 0, :abstract "Column generation (CG) models have several advantages over compact formulations, e.g., they provide better LP bounds, may eliminate symmetry, and can hide non-linearities in their subproblems. However, users also encounter drawbacks in the form slow convergency a.k.a. the tailing-off effect and the oscillation of the dual variables. Among different alternatives for stabilizing the CG process, Ben Amor, Desrosiers, and Valério de Carvalho (2006) suggest the use of dual-optimal inequalities in the context of cutting-stock and bin-packing problems. We will generalize their results, provide new classes of (deep) dual-optimal inequalities, and show the applicability to other problems (vertex coloring, bin-packing and cutting-stock problems with conflicts, temporal knapsack problem). We also suggest the dynamic addition of violated dual inequalities in a cutting-plane fashion, and present computational results proving the usefulness of the methods.", :title "Dual Inequalities for Stabilized Column Generation Revisited", :keyword2 157, :authors (4161 29571), :session 199919}, 828 {:keyword1 95, :keyword3 0, :abstract "This paper addresses a technician routing and scheduling problem motivated by the case of a forklift maintenance provider. Technicians are proficient on different skills and pair into teams to serve maintenance tasks. Tasks are skill constrained and have time windows that can span multiple days. The objective is to determine the daily assignment of technicians into teams, teams into tasks, and daily team routes such that the operation costs and the customer waiting are minimized. We propose a mixed integer program and a column generation-based algorithm for the solution of this problem. Using real-world data from a forklift maintenance provider, we present our first numerical results.", :title "Multiperiod Technician Routing and Scheduling", :keyword2 0, :authors (29524 10255), :session 199865}, 829 {:keyword1 97, :keyword3 0, :abstract "It is important to develop practical and effective methods to improve productivity in semiconductor manufacturing fab which involves possibly one of the most complex manufacturing processes ever used. The photolithography process in semiconductor manufacturing is one of the most complex processes and known as the bottleneck process which significantly affects the entire fab productivity. In this research, we consider lot assignment problem in photolithography process in case that there is a limited number of qualified equipment types and main equipment for each photolithography step and apply a simple heuristic approach in order to minimize makespan of the photolithography process.", :title "A Simulation Study on Lot Assignment Problem in Semiconductor Photolithography Process", :keyword2 96, :authors (29239), :session 199851}, 831 {:keyword1 159, :keyword3 150, :abstract "Usually the lot-sizing problem and the detailed sequencing and scheduling problem are treated separately in the production planning process. By considering these two problems simultaneously in a very realistic model formulation we aim to improve the overall performance of the entire production process. For this purpose we extended the Position-Based Model introduced by Lütke-Entrup et al. (2005). The extensions include explicit product transfers via product pipes (i.e., pipes are used to transfer products between aggregates; no two transfers can be performed at the same time), product-dependent durability during the production process (e.g., after fermentation the product has to be chilled within a certain time limit), cleaning and sterilization pipes which prevent simultaneous treatment of specific aggregates, maximum and minimum capacity of aggregates, sequence-dependent setup times, product loss caused by transfers, a product specific production speed for each aggregate, and cleaning intervals (i.e., the time between two consecutive cleaning procedures is limited). Based on a set of real-world production data, we used our model to determine exact solutions to very small problem settings. As even for small instances the time required for obtaining exact solutions is too long in general (even finding a first feasible solution for one product on all available aggregates takes many hours), we first developed a fix-and-optimize inspired construction heuristic to obtain a feasible solution for several products. This means, that the overall problem is first decomposed and iteratively solved while adding one product per iteration. With this as input we created an innovative matheuristic solution approach based on the concept of fix-and-optimize for this problem.", :title "Solving a rich position based model for dairy products", :keyword2 170, :authors (45068 2769 23282), :session 199848}, 834 {:keyword1 40, :keyword3 173, :abstract "We present an algorithm that computes approximate pure Nash equilibria in a broad class of constraint satisfaction games that generalize the well-known cut and party affiliation games. Our results improve previous ones by Bhalgat et al. (EC 10) in terms of the obtained approximation guarantee. More importantly, our algorithm identifies a polynomially-long sequence of improvement moves from any initial state to an approximate equilibrium in these games. The existence of such short sequences is an interesting structural property which, to the best of our knowledge, was not known before. Our techniques adapt and ex- tend our previous work for congestion games (FOCS 11) but the current analysis is considerably simpler.", :title "Short sequences of improvement moves lead to approximate equilibria in constraint satisfaction games", :keyword2 134, :authors (44261 35913 44470), :session 58}, 836 {:keyword1 150, :keyword3 65, :abstract "The Fixed Charge Network Design Problem addresses the problem of simultaneous design and routing, where a fixed cost is paid for opening a link and a linear routing cost is paid for sending traffic flow on a link. The routing decision must be performed such that flows remain bounded by the installed capacities. This problem appears as a particular case of the combined network design and traffic flow routing problem with time-dependent demands developed in this paper. This general problem can be formulated as a multi-period mixed integer optimization problem. A compact formulation based on the aggregation of flows by destination shows that its resolution on realistic instances becomes intractable and unscalable with state-of-the-art solvers due to the weak linear programming bound provided by the formulation. An extended formulation, where flows are decomposed by origin-destination pairs while keeping the requirement of destination-based routing, provide much better linear programming lower bounds. However, as its resolution still suffers from its huge size, solving the linear relaxation becomes intractable as the network size increases. In this paper, we explore different decomposition techniques to overcome this limit. One of them consists in projecting the extended formulation on the space of variables of the base formulation, leading to a Benders decomposition that can be embedded in a branch-and-cut method yielding a candidate for an efficient centralized solving procedure. Moving to a decentralized procedure, requires to design mechanisms to obtain distributed versions of the master problem solved at each node and to exchange information from the subproblems of tractable size by involving only local decisions to the distributed versions of the master problem.", :title "Methods for time-dependent combined network design and routing optimization", :keyword2 95, :authors (32497 1), :session 199909}, 837 {:keyword1 2, :keyword3 0, :abstract "We consider the crew scheduling problem for multi-domicile airlines with irregular flight schedules. Based on capacity-based crew pairing optimization, we develop heuristics for the crew assignment phase taking into account both airline productivity and crew welfare criteria. For crews stationed at several domiciles with several kinds of full and parttime contracts and unevenly distributed times of vacation, off-duty requests and assigned office and simulator duties, it is difficult to assign all pairings into the timely unstructured gaps in-between the prescheduled activities and fixed and requested off-day blocks. \r\nWe propose a three-staged assignment process: The first phase “capacity-based assignment” constructs a first assignment solution based on day-capacities, flight hour goals and lengths of gaps. The optional second phase “inter-domicile balancing” relocates some pairings out of domiciles with capacity deficiencies to correct the assignability of pairings. The third fine-tuning phase “intra-domicile fairness balancing” performs exchange moves between crew members of the same domicile improving the starting solution by minimizing a variance-like evaluation function of fairness criteria based on equal distribution of flight hour goals, nice destinations, crew preferences and granted OFF requests.\r\nWe report on some techniques enhancing the results for real-world data both quantitatively and qualitatively: Scheduling small gaps first and using multi-level moves between several crew members solved hard bottleneck situations. The integration of expert and corporate rules, e.g. schedule pairings directly before/after vacation and off-blocks, prefer early-to-late duty blocks, account for standby-usable days, enhanced the quality of assignment results.\r\n", :title "Heuristics for Multiple Domicile Crew Assignment based on Capacity Calculation and Expert Rules", :keyword2 0, :authors (19902 45335), :session 199830}, 838 {:keyword1 45, :keyword3 18, :abstract "In many hospitals, surgical departments are typically allocated operating rooms and time on given weekdays into which they are able to book elective surgeries. This is the case of the operating theatre of a German hospital where each surgical group informs the operating room (OR) manager of the elective cases that will be performed on the following day. During the surgery day, the OR manager gradually details the OR schedule as time unfolds. Currently, there is the belief that this modus operandi neither maximizes the utilization of the available resources nor minimizes the costs of the operating theatre. Before changing the current practice, the hospital would like to know the potential impact of a number of scenarios. We developed a mixed integer linear programming model that is embedded in a preemptive goal programming framework to create a schedule for next day’s surgeries. The base scenario depicts the current situation of dedicated rooms to surgical groups. In the second scenario, surgeries may be performed in non-preferred rooms and deviations from dedicated rooms are minimized. The third scenario analyses the policy of opening the ORs to all surgical groups. This option would dramatically change the current role of the OR manager. In a second step, each scenario was also considered with the option of performing anaesthesia induction outside the OR, a practice that is currently not followed by the hospital but that could allow a higher utilization of the operating theatre.  All scenarios were evaluated using real data provided by the hospital. We will compare the corresponding OR schedules by means of several performance indicators. Based on the computational study, recommendations for the implementation of a new policy are discussed.", :title "Evaluating different policies on scheduling elective surgical procedures: A case study", :keyword2 158, :authors (1256 45337), :session 199937}, 841 {:keyword1 161, :keyword3 0, :abstract "We consider multiobjective semi-infinite optimization problems which are defined by finitely many objective functions and infinitely many inequality constraints in a finite-dimensional space. We discuss constraint qualifications as well as necessary and sufficient conditions for locally weakly efficient solutions. Furthermore, we generalize two concepts of properly efficient solutions to the semi-infinite setting and present corresponding optimality conditions.", :title "On proper efficiency in multiobjective semi-infinite optimization", :keyword2 0, :authors (39997 12520), :session 199960}, 844 {:keyword1 150, :keyword3 101, :abstract "We consider a special lot-sizing problem in the context of purchasing alliances. We focus on a supply chain which consists of several retailers and one supplier. The retailers are free to cooperate in order to benefit from quantity discounts. In case of a cooperation, transshipments are possible, that is, movement of a product from one retailer to another. A mixed integer programming problem is introduced to cope with the decision problem of who orders when, for whom, how many products and how many products are in stock or being transshipped. Our goal is to minimize the total cost of the system. A Benders Decomposition approach is applied to find a\r\nsolution to this problem.", :title "Benders Decomposition applied to cooperative lot-sizing", :keyword2 158, :authors (45341 14715), :session 199858}, 845 {:keyword1 29, :keyword3 0, :abstract "One potential means to handle non-controllability and limited predictability of photovoltaic (PV) and wind power production is to employ demand-side flexibility, i.e. demand response (DR) resources. In this paper, we take the perspective of a PV or wind power system operator who leverages DR in order to maximize the economic value of the production supplied in short-term power markets. DR is modeled as contractual flexibility, meaning that the PV or wind operator has the freedom to shift a share of some power supply commitment between neighbored delivery slots. \r\nWe formulate two alternative DR operation modes: (1) use DR to maximize relative day-ahead market value, by shifting the supply-demand balance in view of day-ahead prices; (2) use DR in intraday operations to minimize costs incurred when balancing forecast errors. An analytical comparison and some (preliminary) testing with German market data suggest that the intraday operation mode (2) yields a higher value in the vast majority of instances. These findings can be attributed to the greater volatility of intraday prices compared to day-ahead prices, and to the fact that the intraday application of DR allows both shifting supply-demand balances as well as netting them.\r\nUltimately, we combine the intraday DR operation with a bidding model for the balancing of PV or wind power forecast errors in continuous-trade intraday markets. The integrated model proposed directs both the allocation of DR resources and the trading of remaining supply-demand imbalances with the goal of value maximization. In the optimization problem, the stochastic and correlated behavior of the two key variables intraday price and forecast error are accounted for by means of a multi-dimensional binomial lattice and real options analysis.", :title "Day-ahead versus Intraday Valuation of Demand-Side Flexibility for Photovoltaic and Wind Power Systems", :keyword2 99, :authors (45342 21108), :session 199930}, 846 {:keyword1 157, :keyword3 0, :abstract "The wireless network planning problem as considered in this talk comprises two tasks:  The decision which base stations should be deployed and the assignment of traffic nodes to base stations. A predominant problem in these types of networks is interference. A traffic node served by one base station also receives interfering signals from other base stations. A prevalent method to avoid interference is the incorporation of constraints in the formulation of the planning problem which guarantee a minimum so-called signal-to-interference-plus-noise ratio (SINR) per traffic node. However, this type of constraint leads to numerical difficulties as the coefficients in the resulting linear inequality vary significantly in magnitude. \r\nIn this talk, motivated by system models from network engineering, we propose the usage of discrete channel quality indicators to model interference as a building block of an integer linear program. These indicators depend on the SINR and define the quality of a link which affects the amount of bandwidth needed to serve a traffic node. Depending on the base station decision and hence, the emitted interference, not every indicator is feasible for each link. We separate the proposed model inequalities, which are similar to cover inequalities, on the fly to exclude such infeasible base station decision and indicator combinations from the solution space. ", :title "A new approach for interference modulation in wireless networks", :keyword2 104, :authors (45338 12177 45347), :session 199918}, 849 {:keyword1 158, :keyword3 0, :abstract "The two most recent versions of CPLEX have introduced three different ways\r\nto solve (mixed) integer problems with CPLEX in a distributed parallel\r\nfashion:\r\n1. \"Concurrent parallel optimization\" starts MIP solvers with different\r\n   parameter settings on the same problem on a set of (remote) machines.\r\n   The results of all solvers are monitored and search stops if the combined\r\n   primal and dual bounds of all solvers satisfy a termination criterion.\r\n2. \"Concurrent parallel optimization with communication between solvers\" is\r\n   similar to the above but now information found during the search\r\n   (incumbents, cuts, ...) can be communicated between the solvers so as to\r\n   speed up the individual solvers.\r\n3. \"Distributed parallel tree search\" takes the standard MIP tree search\r\n   algorithm to a cluster of distributed machines.\r\nIn this talk we will review and compare the three different strategies\r\nin detail. We will also report on their respective performance.\r\n", :title "Distributed parallel MIP solving with CPLEX", :keyword2 74, :authors (23446), :session 199883}, 850 {:keyword1 29, :keyword3 0, :abstract "Frequently, energy market models focus on the analysis of equilibria and equilibrium development paths. But the history of competitive electricity markets in Europe is more resembling to a sequence of booms and busts - with currently a bust period. A key reason are the long lead times for construction. By investigating the impacts of deviations from an (anticipated) equilibrium, the relevance of various risk factors for profitability is highlighted. This will contribute to improve investment decision making under uncertainty.", :title "The impact of disequilibria in power markets", :keyword2 28, :authors (41874 24773), :session 55}, 851 {:keyword1 6, :keyword3 56, :abstract "We study the problem of finding the profit-maximizing multi-item mechanism in a setting,\r\nwhere bidders hold two-dimensional private information: one for the value of the item being sold, the other one for the added value margin they exhibit in case of exclusive allocation. We require the mechanism to be deterministic, individually rational, and implementable in dominant\r\nstrategies. Our main motivating example comes from online marketing, specifically sales lead generation. Due to the great demand from practitioners for simple and speedy solutions, instead of going for optimality, we focus on heuristics that provide good revenue relative to the optimal mechanism. Notably, we demonstrate that even the simplest mechanisms, such as selling always exclusively or always non-exclusively, produce revenue within a constant factor approximation of the optimal revenue. We identify two different single-dimensional relaxations of the problem, for\r\nwhich we determine the optimal auction using well-known techniques. The relaxations provide revenue bounds that can be used to evaluate the quality of heuristic auctions. We also devise a heuristic mechanism from the class of affine maximizers and demonstrate by means of simulation\r\nthat it yields revenue very close to the upper bounds, and thus very close to optimality.", :title "Multi-item auctions with exclusivity margin", :keyword2 57, :authors (45319 16170 45345), :session 33}, 852 {:keyword1 175, :keyword3 158, :abstract "Over the past decades, many metropolitan areas were facing a continuing increase of their population leading, amongst others, to a higher demand of transport of goods, both by the industry and suppliers, and by households. In addition, various new types of services were developed to deliver goods. \r\nFor delivery companies, short delivery times, low costs and high quality are some of the main targets of a shipment, whereas for public authorities and the society, the minimization of green-house gas emissions is of increasing importance. \r\nTo address some of these requirements, various models to bundle and deliver goods were developed. In an applied research project presented here, a cooperation platform for several logistic companies will be developed, where bundling of goods is a key component. Therefore, an existing pickup and delivery model from Savelsbergh and Sol (1995) was extended. This model is flexible enough for the extensions developed while at the same time covering all essential requirements. A consistent path was developed from the raw data to the parameters of the model. The model was implemented in GAMS and solved with CPLEX.\r\nFurthermore, a methodology was developed to allow for meeting multi-criteria objectives (costs, emissions, etc.) together with the definition of measures to quantify the impact for different scenarios. The scenarios are based on real world data from different shipping companies.\r\nIn this paper, the focus is not on computational aspects related to the size of the problem, but instead on (i) illustrating a consistent methodology for integrating raw data into the model (network layout, costs,...), (ii) the measures to quantify the impact of bundling goods, and (iii) presenting some preliminarily results from tests with real world data.", :title "Extension and application of a general pickup and delivery model for evaluating the impact of bundling goods in an urban environment ", :keyword2 95, :authors (21140 45346), :session 199947}, 856 {:keyword1 99, :keyword3 0, :abstract "We want to determine delay distribution functions analytically from given source delays. For this purpose, we use an activity on arc network. Generally, the calculation of propagated delays requires a topological sorting of arrival and departure events and cannot be applied if the network contains cycles. We use an iterative method to approximate the long-run delay distributions in those cycles. The objective of this talk is to investigate the impact of this approach on the limiting distributions.\r\n\r\nIn a first step we try to find a topological sorting for the events. If successful, we use this order to compute the corresponding delay distribution functions. Otherwise, in cyclic structures, i.e. the strong components of the network, we sort the events using a relaxed version of the topological sorting and approximate the delay distributions functions iteratively. Basically, we just need to apply three mathematical operations to the distribution functions: convolution, multiplication and excess-beyond operation. For studying the convergence behaviour we make use of a result of Loynes who examined the long-run waiting times in a simple queuing model. \r\n\r\nIn this iteration scheme the delay distribution functions of the arrival and departure events converge under certain conditions. But the random variable of the limiting distribution might not be finite. Moreover, the limiting distribution might not be unique, i.e. independent of the sorting used for the events.", :title "Modelling Delay Propagation in Railway Networks", :keyword2 105, :authors (39414), :session 54}, 858 {:keyword1 175, :keyword3 40, :abstract "Dynamic route guidance system, generally provided by a system administrator, aims to provide road users en-route recommendations to avoid traffic congestion. In this study, we consider the problem as a multi-player repeated game in a dynamic multi-agent transportation system. A game-theoretical route guidance (user-optimal routing) strategy based on joint strategy fictitious play (JSFP) is proposed to solve dynamic user-optimal routing problem. Each guided user makes his travel time estimations and local outgoing link decisions based on his historical experiences and received en-route traffic time information. The proposed algorithm incorporates users’ inertia and en-route traffic information when making his local route choice decisions. The en-route traffic information considered in this study consists of periodically updated link travel times and announced travel time delays. The proposed approach is based on individual selfish adaptive online route choice behavior under JSFP strategy with real-time traffic information provision. \r\nThe numerical results demonstrate the convergence of the proposed algorithm to near-Nash equilibrium and travel times and delay reduction in a dynamic congested network. The advantages of the proposed algorithm reside on its distributed and self-guidance aspects. We show that the proposed JSFP strategy can achieve better route guidance performance compared with the existing iterative solution algorithm (Zuurbier, 2010) and the time-dependent shortest path routing method. The computational result in realistic network based on a queue model will be presented. We demonstrate the performance of the proposed algorithm with respect to different compliance rates and to non-recurrent incident situations.  \r\n", :title "Dynamic user-optimal routing based on joint strategy fictitious play", :keyword2 95, :authors (40073), :session 199942}, 859 {:keyword1 165, :keyword3 0, :abstract "The talk addresses modeling and algorithmics in stochastic programming with dominance constraints. With accent on recent developments, mixed-integer models and models involving  PDE constraints will be discussed.", :title "Stochastic Dominance in Stochastic Optimization", :keyword2 93, :authors (9512), :session 199882}, 860 {:keyword1 95, :keyword3 0, :abstract "We present a new extension of the vehicle routing problem (VRP): The VRP with flexible delivery locations (VRPFDL). In the VRPFDL, a job not only corresponds to exactly one location but has to be performed at one out of a set of possible locations. One possible application for the VRPFDL is the hospital-wide therapist routing problem. In the hospital-wide therapist routing problem, therapists are depicted as vehicles and patients are depicted as jobs to be treated at a ward or at a therapy center. In order to solve the VRPFDL we present a mixed integer program. Due to its computational intractability we reformulate the problem as a Dantzig-Wolfe formulation which is solved by means of branch-and-price-and-cut. Based on standard VRP benchmark instances, we generate VRPFDL instances and evaluate the mixed integer program and the Dantzig-Wolfe approach. ", :title "Vehicle Routing with Flexible Delivery Locations", :keyword2 8, :authors (44745 45073 29539 829), :session 199865}, 861 {:keyword1 98, :keyword3 0, :abstract "From the beginning in the 1970s at the World Bank till today, GAMS, the General Algebraic Modeling System, has evolved continuously in response to user requirements, changes in computing environments and advances in the theory and practice of mathematical programing. We will outline several recent enhancements of GAMS supporting efficient and productive development of optimization based decision support applications.", :title "Recent Enhancements in GAMS", :keyword2 57, :authors (14898 10542), :session 199884}, 864 {:keyword1 40, :keyword3 0, :abstract "Assume that a set of agents has to subdivide a set of indivisible items. Preferences over the items may be diverse for different agents. We study the impact of fairness on the efficiency of allocations, looking at different fairness criteria from the theory of fair division. Current research has focused on the case where the number of items is arbitrary. Here we consider situations where the number of items is relatively small, compared to the number of agents, which is relevant in practice and indeed makes a difference.", :title "The price of fairness for a small number of indivisible items", :keyword2 127, :authors (23024), :session 199887}, 865 {:keyword1 127, :keyword3 97, :abstract "Today‘s electricity consumer tend to become small businesses (also referred to as prosumers) as they invest in their own decentralized electricity generation (e.g. photovoltaic, combined heat and power, etc.) and mobile (e.g. electric vehicles) and/or stationary energy storage as well as in information technology (IT) to connect and organize these new devices (e.g. as virtual storage). Furthermore, the installed IT allows them at least technically to establish local markets. The variety of consumers and their characteristics implies numerous ways of how they optimize their individual unit commitment. This paper aims to analyze the impact of the individual consumers’ decisions on a future electricity demand and feed-in on low voltage network level. Therefore, in a first step the different unit commitment problems of the different small businesses have been modeled using mixed-integer linear programming (MILP). In a second step these consumers are modeled as learning agents of a multi-agent system (MAS). The MAS represents a local electricity market in which participants negotiate supply relationships. At each step of the simulation of the MAS the agents will readjust their MILP decision based on newly gained information (e.g. neighbor agent sells electricity cheaper in the evening). Finally, using different synthetic scenarios with different input parameters (e.g. load characteristics) the behavior of the agents and the resulting impact are studied in detail. Amongst others, the simulation’s results show major changes in electricity demand and feed-in for scenarios with high market penetration of storages. Results also show that, electricity demand and supply balance in the local electricity market for certain scenarios and a specific market design.", :title "Impacts of electricity consumers' unit commitment on low voltage networks", :keyword2 28, :authors (45348 31230 22954), :session 199930}, 866 {:keyword1 2, :keyword3 170, :abstract "We consider the planning and scheduling of inbound baggage which leaves the airport through the baggage claim hall. Although, this is a standard process at airports, to the best of our knowledge, there has been no one mathematical model proposed in the literature optimizing the inbound baggage handling process and analyzing its theoretical structure. As the inbound baggage handling problem turns out to be NP-hard, we propose a hybrid heuristic combining greedy randomized adaptive search procedure (GRASP) with a guided fast local search (GFLS) and path-relinking. We demonstrate how we implemented the proposed algorithm into the running system of a major European Airport. In a case study, we compare the results of the MIP with the solution of the GRASP/GFLS heuristic and the solution provided by practice. All computational results are based on real data. ", :title "Inbound Baggage Handling at Airports", :keyword2 8, :authors (45073 45350 829), :session 95}, 867 {:keyword1 31, :keyword3 101, :abstract "In the future, electric mobility will become more important in the traffic sector.  Lithium-ion batteries will power most of the electric vehicles. These batteries used in electric vehicles retain 80% of their capacity even after 7-8 years of use, which is sufficient for alternate use. The research question of this paper is to calculate the value of second life batteries. We also determine the economic (price, profit) and market (demand) consequence of the second life of used electric vehicle batteries. \r\n\r\nWe use a closed loop supply chain (CLSC) framework for electric vehicles, which includes reuse, recycling and disposal of electric vehicle batteries. In our model, we use a generalized Bass diffusion model for demand of electric vehicles. The reuse and recycling of used batteries from electric cars also have a significant effect on the pricing decision and profits of OEMs. We model this effect by optimizing the OEMs profit in the CLSC framework. Another important factor that affects the profit is the return rate of used batteries.\r\n\r\nWe find that the optimal price for electric vehicles is influenced by the economic value of used batteries and can potentially increase the demand for electric vehicles. We show that the profits of OEMs are higher when considering a realistic closed loop supply chain framework for electric vehicles. Since their profit is also affected by the return rate of used batteries, OEMs should incentivize the customers to return the used batteries by applying different return policies.\r\n", :title "Reuse and recycling of batteries from electric cars: Economic and Market consequences", :keyword2 25, :authors (40593 1658 40357), :session 199933}, 871 {:keyword1 25, :keyword3 42, :abstract "We study characterizations of implementable allocation rules when types are multi-dimensional, monetary transfers are allowed, and agents have quasi-linear preferences over outcomes and transfers. Our main characterization theorem implies that allocation rules are implementable if and only if they are implementable on any two-dimensional convex subset of the type set. For finite sets of outcomes, they are implementable if and only if they are implementable on every one-dimensional subset of the type set. Our results complement and extend significantly a characterization result by Saks and Yu (2005), as well as follow-up results thereof. \r\n\r\nOur proofs demonstrate that the linear programming approach to mechanism design, pioneered in Gui et al (2004) and Vohra (2011), can be extended from models with linear valuation functions to arbitrary continuous valuation functions. This provides a deeper understanding of the role of monotonicity and local implementation. In particular, we provide a new, simple proof of the Saks and Yu theorem, and generalizations thereof. Modeling multi-dimensional mechanism design the way we propose it here is of relevance whenever types are given by few parameters, while the set of possible outcomes is large. Examples for such types occur in scheduling problems and combinatorial auctions.\r\n", :title "Characterizing implementable allocation rules in multi-dimensional environments", :keyword2 40, :authors (41942 9411), :session 33}, 874 {:keyword1 18, :keyword3 75, :abstract "This study is done over the planning/scheduling problem of production line of one of the world’s largest automotive wheel suppliers. The production process consists of casting, heat treatment, machining, leveling, leakage testing, brushing and the paint shop. This study specifically focuses on the WIP build-up and solution methods to remedy this WIP build-up on the conveyors starting from machining to the end of the brushing process.  Although more than 300+ models can be manufactured in the plant, daily average number of models in the production, vary between 20 and 25. Especially in machining and leveling, cycle times of products change significantly based on their models. Cycle times range in [103, 240] sec. in machining and [58, 112]sec. in leveling. The conveyor system carrying the products move at a constant speed of 9mt/sec. This situation, along with pressure to make due dates, creates significant WIP build-up and congestion on the conveyor system.\r\nDue to long production line, product variety etc., it is very difficult to model and solve this problem analytically. For these reasons, the production line is modeled in detailed using simulation. The simulation model is verified and validated.  \r\nWe present results of 3 different solution methods and their effects on the system using real-life data. The 3 methods are, use of dispatching decision rules, different layouts and increasing/decreasing numbers of machines and/or operators in a design of experiments.   \r\n", :title "Simulation based Scheduling Using Dispatching and Batching Rules in Due Date Priority Production Planning", :keyword2 97, :authors (3578 45361 45365 45363 45364), :session 199854}, 879 {:keyword1 126, :keyword3 152, :abstract "In this talk we present our recent results on the multi-period portfolio selection problem with exponential utility function. It is assumed that the asset returns depend on predictable variables and that the joint random process of the asset returns and the predictable variables follow a vector autoregressive process. We prove that the optimal portfolio weights depend on the covariance matrices of the next two periods and the conditional mean vector of the next period. The case without predictable variables and the case of independent asset returns are partial cases of our solution. Furthermore, we provide an empirical study where the cumulative empirical distribution function of the investor's wealth is calculated using the exact solution. It is compared with the investment strategy obtained under the additional assumption that the asset returns are independently distributed.", :title "The Exact Solution of Multi-Period Portfolio Choice Problem with Exponential Utility", :keyword2 156, :authors (45358 26007 45359), :session 199890}, 884 {:keyword1 174, :keyword3 156, :abstract "Home service optimization is becoming a key issue in many industrial sectors. For instance, it is common practice for large technology stores in Europe to offer both the delivery of products at home after purchase, and additional professional services like installation and setup.\r\nCrucial decisions must be taken at different levels, like the tactical definition of time slots and the operational scheduling of the operators; different strategies have been developed in the literature, typically trading time slot flexibility with price incentives and discounts. Any approach agree on a common principle: while a service time slot may be negotiated with some flexibility, missing a fixed appointment is perceived as a strong disservice by the customer.\r\nWe tackle the problem of negotiating service time between customers and service providers (a) at an operational level of detail, that is explicitly producing hard time windows, together with a suitable scheduling for an operator to meet them, (b) in an online fashion, that is answering to each customer at his arrival time, without assuming any\r\ndistribution on future customers, and without the possibility of re-negotiating the slots, and (c) with realtime performances, that is with computational methods yielding decision support options in fractions of seconds. \r\nWe formalize a time slot allocation problem, we propose diverse negotiation policies and we design algorithms that are able to cope with issues (a), (b) and (c) simultaneously. We also introduce suitable indicators, highlighting level of service factors as quality measures.\r\nFinally, we perform an experimental campaign, assessing the trade-off between different level of service measures, and proving the overall effectiveness of the negotiation process.", :title "Optimizing time slot allocation in single operator home delivery problems", :keyword2 95, :authors (19709 38567 12569), :session 199864}, 887 {:keyword1 34, :keyword3 93, :abstract "The structure of the age pyramide is constantly shifting due to the demographic change in Germany. The citizens bear higher responsibility for investments and retirement decisions and simultaneously the complexity of the financial markets and the range of available financial products are steadily increasing. Limited financial knowledge and simplified decision rules can be wrong and result in negative effects on future consumption possibilities. The question is how an investor can reduce the discrepancy between complex financial decisions and lack of financial expertise. Intelligent software solutions that support the processes at the portfolio level can relieve the financial advisor enormously. In a software-based portfolio optimization the financial adviser has the key role to bring the resources and restrictions of the bank or financial consulting firm together with the individual needs of an investor. Motivated by these developments, the present work focuses on the evaluation of software-based depot optimization and -monitoring for investment advisory services. For this purpose, the following research question will be answered and discussed: “What are the offered possibilities of different software-based depot optimization and –monitoring tools and how reasonable are the optimization results?” Based on an exemplary portfolio various optimization results of advisory tools are critically evaluated based on scenarios for different risk types. All scenario results are represented graphically in the form of risk-performance charts. The scenario analysis of the two tested tools show, as with all methods and algorithms, the results strongly depend on the entered parameters. Overall, the tools provide according to the settings valid optimization results.", :title "Evaluation of a software-based investment advisor for depot optimization and -monitoring", :keyword2 67, :authors (33522 19100), :session 199961}, 891 {:keyword1 19, :keyword3 120, :abstract "In Japan, the production of vegetables has fallen from the latter half of the 1980's because of decreasing of agriculture workers. On the other hand, the amount of imported vegetable has increased, because the price of imported vegetables is cheap and the stable supply of them is possible. However, in recent years, the consumers have become increasingly aware of problem related to safety of food like chemical levels in imported vegetables, therefore, needs of domestic vegetable have risen. In this study, the consideration of the consumer who relates to the purchase of a domestic vegetable is clarified for giving a useful finding for further promotion of the consumption expansion activity of a domestic vegetable. There also have been some studies on purchasing vegetables in Japan. However, few studies focus on purchasing domestic vegetables of housewives. It limits to a lot of live foods consumed at home and the analysis is advanced in the present study though there is various kinds of such as the live food, the frozen vegetables, and dehydrated vegetables. This study analyzed the consumer awareness that influence the purchasing Japanese domestic vegetables in by structural equation modeling analysis (SEM). The analysis data is the survey data which was collected in the Tokyo metropolitan area for international student of the living in Japan.", :title "Decision Making Process Model with Price Acceptability in Japanese products", :keyword2 56, :authors (29686), :session 24}, 892 {:keyword1 65, :keyword3 151, :abstract "In the connected facility location with buy-at-bulk edge costs\r\nproblem we are given a graph containing clients and potential facilities,\r\na core cable type of infinite capacity, and several access cable types with\r\ndecreasing cost per capacity ratio. The task is to open some facilities,\r\nconnect them by a Steiner tree of core cables, and build a forest network\r\nof access cables such that the edge capacities suffice to route all client\r\ndemands to open facilities. The objective is to minimize the total cost\r\nfor opening facilities and installing core and access cables. We consider\r\na natural model for this problem, and show that its integrality gap is a constant.", :title "On the integrality gap of  the connected facility location with buy-at-bulk edge costs problem", :keyword2 104, :authors (33657 45366), :session 199900}, 893 {:keyword1 8, :keyword3 154, :abstract "We consider the Minimum Biclique Cover and Minimum Biclique Partition problems on bipartite graphs. That is, for a given bipartite graph, we wish to compute a small number of complete bipartite subgraphs (also called bicliques) such that each edge is contained in at least one of them. This problem, besides its correspondence to a well-studied notion of bipartite dimension in graph theory, has applications in many other research areas such as artificial intelligence, computer security, automata theory, electrical engineering, and biology. Since it is NP-hard, past research has focused on approximation algorithms, fixed parameter tractability, and special graph classes that admit polynomial time exact algorithms. For the minimum biclique partition problem, we are interested in a biclique cover that covers each edge exactly once.\r\n\r\nWe revisit the problems from approximation algorithms' perspectives and give nearly tight lower and upper bound results. We first show that both problems are as hard to approximate as the Node Coloring problem. That is, by exploiting properties of graph products, we obtain lower bounds for the approximation guarantee of polynomial-time approximation algorithms, which grow almost linearly in the number of nodes. We thereby raise the best-known lower bound for Minimum Biclique Cover by Gruber and Holzer to a power of 3. The improvement of the lower bound for Minimum Biclique Partition is even more dramatically, where only APX-hardness with a constant slightly above 1 was known before. Furthermore, we show that sub-linear approximation factors can be obtained, which almost closes the remaining gap between upper and lower bounds.\r\n\r\nJoint work with Parinya Chalermsook, Sandy Heydrich, and Eugenia Holm", :title "Almost Tight Approximation Results for Biclique Cover and Partition", :keyword2 151, :authors (29680), :session 199917}, 896 {:keyword1 86, :keyword3 63, :abstract "In this study, we evaluate the efficiency of schedules for a well-known multi-mode projects scheduling problem, discrete time/cost trade-off problem (DTCTP). We aim to investigate different approaches to measure efficiency of solutions using Data Envelopment Analysis (DEA) and compare them in terms of applicability in real life problems. In a previous study (Eryilmaz et al. 2014), robustness was integrated as a criterion for ranking the schedules. However each DEA model (input, output orientation, slack based measure; constant, variable, increasing, and decreasing returns to scale; weight restricted) resulted in different efficiency scores and interpretations. Differently, in this research, we compare the DEA approaches; investigate the domination relations for the set of schedules considering various criteria (cost, time, and robustness). To validate the effectiveness and efficiency of the chosen approach, extensive computational experiments and statistical analysis will be performed.\r\n\r\nReferences\r\nEryilmaz, Utkan, Hazir, Oncu, and Schimdt, Klaus W., A Multi-Criteria Approach for Ranking Schedules for Multi-Mode Projects, Proceedings of the 14th International Conference on Project Management and Scheduling, TUM School of Management, Munich, Germany, (2014), pp. 80–83. ", :title "Efficiency Evaluation of Multi-Mode Project Schedules: Comparison of Different Approaches", :keyword2 19, :authors (45367 13330 12005), :session 199869}, 897 {:keyword1 41, :keyword3 92, :abstract "When different algorithms are used to solve an optimization problem in parallel, a fixed time budget is usually allocated to each one of them. The decision is user-defined and it is based on the inherent characteristics of the problem at hand and the employed algorithms. Typically, all algorithms are allocated equal time budgets, which remain constant throughout the optimization process. However, it is frequently observed that different algorithms perform better than others for different problems or instances of the same problem. Thus, it is reasonable to reward better-performing algorithms with higher time budget during the optimization procedure. However, the selection of the favored algorithms cannot be taken a priori, since it is habitually observed that different algorithms perform better at different stages of the optimization procedure.\r\nThis paper proposes a portfolio of metaheuristic algorithms that operate in parallel and adopt a market trading-based system that orchestrates the allocation of the total available execution time among the constituent algorithms. More specifically, the portfolio dynamically distributes the total available time budget by favoring the best performing algorithms with a higher fraction of the total available time. The core idea of the time allocation mechanism is inspired by trading models and it involves a number of algorithms that act as investors, which buy and sell solutions using time as currency. \r\nThe proposed approach is assessed on a significant problem from the field of Operations Research, namely the production planning in systems with remanufacturing of products. Preliminary experimental evidence renders our approach highly promising. ", :title "Parallel Algorithm Portfolio with Market Trading-based Time Allocation", :keyword2 59, :authors (45356 23824 18726), :session 47}, 899 {:keyword1 97, :keyword3 101, :abstract "The calibration of supply networks considering safety stocks is a problem that has drawn considerable research activities in the last decades. Besides analytical approaches also simulation has gained broader attention recently. The main reason for using simulation is that these models are usually more detailed and thus more realistic than analytical models. ZF Friedrichshafen AG, e.g. uses SimChain as a simulation tool for calibrating and optimizing their safety stocks. The main problem for such simulation-based approaches is the number of parameter settings to be tested for each supply chain. A straight-forward approach is therefore to use an analytical model to gain a good starting solution. However, using analytical models to parameterize safety stocks within the model hardly ever leads to a clear reduction of the number of parameter settings to be tested by simulation in order to obtain satisfactory results. \r\n\r\nAnalyzing the simulation results of various projects and test settings, however, show some significant mathematical relations between results (in terms of average service levels) and parameter settings, e.g. safety stocks, transport times (including the underlying distributions) and also transport schedules. In this paper we present these results and an approach for calibrating safety stocks based on business analytics, which has shown a clear superiority compared to other approaches in the field of simulation-based optimization with respect to the number of parameter settings to be tested.", :title "Combining simulation and business analytics for optimizing safety stocks in supply networks", :keyword2 149, :authors (45362 45360), :session 27}, 900 {:keyword1 18, :keyword3 89, :abstract "Bayesian Networks are established means in various kinds of classification tasks, e.g., technical or medical diagnosis, pattern recognition, as well as air and sea surveillance. In Bayesian Networks, nodes' probability of query states (classification results) are determined based on declarations (finding of features) from different evidence nodes. Conflicts are pieces of such evidence from different sources that carry substantially different, but reliable information on the same object. They can be detected by an adequate conflict measure. In normal operations, conflicts between sources occasionally appear due to rare cases, situations not covered by the underlying Bayesian model, or inaccuracies of sensor measurements. \r\n\r\nFailing sources showing no or same declaration at all times can easily be detected by simple statistic means, whereas systematically deviating or random behavior of defect sources is harder to detect. Our working hypothesis is that these types of failure result into a significantly increased level of conflicts in applications, where the same classification task is repeatedly performed in a large number of cases within a short time frame. We propose an approach to monitor all sources in such a Bayesian Classification Network by evaluating the conflict-ratio levels in a sliding window, covering a certain number of previous classification cases. In a simulated scenario of maritime surveillance with the task of smugglers' detection, the ability of this monitoring approach to detect defect sources is evaluated by determination of typical parameters, which describe underlying diagnostic test's performance of this approach.", :title "Monitoring of Bayesian Network Sources in Repeatedly Performed Classification Tasks", :keyword2 42, :authors (26200), :session 199867}, 902 {:keyword1 89, :keyword3 101, :abstract "In the past decades reaching a high level of on time deliveries became a crucial requirement to ensure customer satisfaction. On the other hand order- and resource-related uncertainty hampers the generation of reliable delivery promises. Therefore the need for planning approaches that generate robust delivery dates arises. In the context of supply chains capable-to-promise approaches are suggested to determine delivery dates with respect to available resources. To enhance solution and planning robustness, the paper aims at analyzing three preventive measures that can be applied to cover order- and resource-related uncertainty: capacity nesting, safety capacity and interactive order promising. Therefore, a two-stage approach is modelled and numerically analyzed. The common way of accepting orders according to customers’ delivery time specifications is applied at the first planning stage. In order to reduce order-related uncertainty, instead of finally rejecting orders whose requested delivery times cannot be met, deviating delivery dates are proposed at the second planning stage considering customers’ response (interactive order promising). At both stages capacity for future lucrative orders (capacity nesting) is reserved to cope with order-related uncertainty and safety capacity is provided to handle resource-related uncertainty. The two-stage planning approach is implemented as a dynamic, stochastic mixed-integer programming model and a numerical analysis based on real-world data of a manufacturer is performed by means of the AIMMS environment. A systematic variation of relevant measure parameters is carried out to identify the impacts of the preventive measures on profit, solution and planning robustness as well as the interactions between the adaptation measures.", :title "How to increase robustness of capable-to-promise? - A numerical analysis of preventive measures", :keyword2 165, :authors (39472 26613), :session 199849}, 903 {:keyword1 42, :keyword3 0, :abstract "In the classical vertex coloring problem one asks if one may color the vertices of a graph G = (V, E) with one of k colors so that no two adjacent vertices are similarly colored; the corresponding optimization problem seeks to find the minimum value k for a graph that admits a legal k coloring. The list coloring problem is a variant of vertex coloring where a vertex may be colored only a permissible color from a prescribed set. Many problems that rely on vertex coloring can be modelled more appropriately using list coloring. For example, exam timetabling is frequently modelled as a vertex coloring problem where graph edges represent subjects that may not be scheduled simultaneously. Other constraints, such as preference for the times an exam may be scheduled, are often considered to be soft constraints. By supplying a list of (in)appropriate hours for each exam one may model the problem more accurately as an instance of list coloring. Similarly, the frequency assignment problem for cellular telephone networks and WLANs may be modelled more accurately by restricting the coloring of vertices (transmitters or routers) to a specified set.\r\n\r\nClearly the list coloring problem is as hard as vertex coloring, for the latter reduces to the former (in polynomial time) through supplying, for every vertex, all colors as its permissible list. However, in spite of its importance few published algorithms exist for list coloring. In this research, we propose a new efficient ILP based algorithm and compare it with the two existing ones we could find in the literature: the greedy, random algorithm k-GL (Greedy List) proposed by Achlioptas and Molloy (1997), and the maximal independent set-based heuristic algorithm LC proposed by Tsouros and Satratzemi (2005).", :title "New Experimental Algorithm for List Coloring Problem", :keyword2 57, :authors (45352), :session 199903}, 904 {:keyword1 53, :keyword3 0, :abstract "The focus of this work is to compare several Lagrangian relaxation approaches for solving the multicommodity capacitated network design problem (FC-MMCF). This problem frequently appears in the real world. In fact,\r\nFC-MMCF problem arises in Logists, Telecommunications and Transportation to model a plenty of applications. On the other hand, the numerical results aim at providing a benchmark for large scale MIP problems, pointing out the strengths and weaknesses of the different Lagrangian approaches.\r\n\r\nIn particular, we consider the Flow and the Knapsack relaxation for FC-MMCF problem and we solve the Lagrangian duals by using different methods coming from the differentiable optimization like (incremental, deflected, projected) subgradient-type methods and (disaggregated, generalized) bundle type methods.\r\n", :title "A computational comparison of approaches to Lagrangian duals: the case study of FC-MMCF", :keyword2 66, :authors (24291 969 5855), :session 199905}, 905 {:keyword1 61, :keyword3 98, :abstract "AIMMS PRO (Publishing and Remote Optimization) platform allows for remote optimization, queuing and prioritizing of the optimization tasks on a central server. We discuss important aspects such as data exchange and messages exchange capabilities offered by the PRO platform. We illustrate these capabilities based on an advanced example where several incumbent solutions of an MIP problem are evaluated remotely on the server using a simulation run. Results are fed back to the client where they serve for sensitivity analysis and visual comparison of a number of feasible solutions.", :title "Distributed computing using server based optimization in AIMMS PRO", :keyword2 153, :authors (10297), :session 81652}, 906 {:keyword1 2, :keyword3 0, :abstract "Ground handling as well as many other personnel scheduling problems require the explicit assignment of shifts and days off to individual employees rather than to a generic workforce. This means that information on skills, availability, and overtime balances must be taken into account. A very flexible component of the shift models used in ground handling is the break regulation. For a large portion of the workforce at AeroGround, a major European groundhandler, the total break duration per shift may be split into sub-breaks, where each sub-break has a minimum and maximum length, and workstretch durations regulate the time between them. We will provide an overview and classification scheme for breaks regulations discussed in literature. Moreover, we will introduce and present a tour scheduling model based on work templates that includes hierarchical skill levels and the possibility to use different break regulations. We analyze different break regulations and show the advantage of using flexible break regulations.\r\n", :title "The Airport Ground Staff Tour Scheduling Problem with Flexible Breaks ", :keyword2 0, :authors (45350 45073 829), :session 95}, 908 {:keyword1 28, :keyword3 37, :abstract "The transformation of the german Energy System and its ambitious aims are a challenging field for strategic decision support tools and the underlying models. The Hanover region has for instance committed itself to the goal of greenhouse gas emissions reduction by 95% until 2050. This aim can only be reached if renewable energy sources will completely substitute fossil fuels. This objective makes it necessary to redesign the energy sector. Including the selection of cost and space effective sources and optimal balancing between energy saving and additional renewable energy production. \r\n\r\nTherefore the dilemma between volatile and rapid price decline of energy collection, storage and conversion technologies and necessary longtime planning in the energy sector has to be solved.\r\n\r\nThis papers model solves this dilemma in two steps. At first the model predicts technology prices by the combination of learning rates and global market size forecasts. Subsequent the resulting learnings curves are used for future actual costs calculations based on annual working costs as well as annuities of renewable energy investments. This investments consist of electricity generation from photovoltaic and wind power, the future prices of different electric, plugin-electric and combustion engines, and the price of electricity storage (batteries) and conversion (power-to-gas). Furthermore the model includes viability calculations for building heating and insulation. In all three sectors a given electricity, mobility and warmth demand must be fulfilled by selection of technology alternatives.\r\nThis papers model can easily be expanded by additional technologies. In further research based on the model a scenario tool for economic viable decision making in the energy sector can be programmed.\r\n", :title "A Quantitative Model for Cost-Efficient Regional Energy System Planning", :keyword2 29, :authors (45218 19100), :session 199930}, 912 {:keyword1 2, :keyword3 158, :abstract "Planning a fuel-efficient flight trajectory connecting the departure and destination is a hard optimization problem. The solution space of a flight trajectory is four-dimensional: a 2D horizontal space on the earth surface, a vertical dimension consisting of a number of discrete altitude levels, and a time dimension controlled by the aircraft speed. In practice, the flight planning problem is solved in two separate phases: a horizontal phase that finds an optimal 2D trajectory consisting of a series of segments; followed by a vertical phase that assigns optimal flight altitude and speed to each segment, and the altitude and speed can only be changed at the beginning of a segment. In this work, we focus on the vertical phase. In general, the higher it flies, the more fuel efficient it is. However, the optimal altitude for each segment also depends on some interconnected and dynamically changing aspects: weight, which decreases as fuel burns; speed, which changes flight time; and weather condition, especially wind, which changes considerably by altitude and time. A time constraint is enforced such that a flight should arrive within a certain time window due to gate availability. Then how to assign altitude and speed for each segment of a flight trajectory while satisfying the arrival time constraint is a challenging optimization problem. We formulate this problem into a mixed integer nonlinear programming model, and apply different acceleration techniques. Besides, general-purposed black-box optimizers and problem-specific heuristics are also applied. Experiments are conducted based on the real-world data provided by our industrial partner Lufthansa Systems. The experimental results confirm the fuel saving potential of the vertical profile optimization in flight planning.", :title "Fuel Efficient Vertical Optimization of Passenger Flight Trajectories", :keyword2 175, :authors (45357 16315 45369 45368), :session 199940}, 913 {:keyword1 48, :keyword3 39, :abstract "A fuzzy linear programming model to scheduling orders in the steelmaking and continuous casting production is developed. The general structure of the production system considers an arbitrary number of machines at each stage, producing orders of several steel grades and types (e.g. slabs and billets). In addition to optimization criteria such as makespan the satisfaction of continuity constraints (between batches), transit time constraints (in process time of liquid steel) and due date satisfaction constraints are of main importance in this problem. But the strict satisfaction of these constraints in a given instance may produce bad solutions, i.e. feasible solutions that satisfy strictly all constraints whitin a high makespan (low productivity), or no feasible solution exists. In practice, aspects such as continuity, maximal transit time and due date satisfaction can be handled in a relative manner: it is possible to allow schedules of casting sequences with small discontinuities and/or small violations of maximal transit times and due dates. The resulting symmetrical model optimizes an overall constraints satisfaction grade of the global decision, i.e., the degree of satisfaction of the fuzzy continuity, transit time and due date satisfaction constraints as the fuzzy makespan aspiration level constraint satisfaction.", :title "Fuzzy Linear Programming Model for Scheduling Steelmaking and Continuous Casting Production", :keyword2 96, :authors (16459), :session 199852}, 914 {:keyword1 86, :keyword3 0, :abstract "Due to the extensive timeframes and the transfer of risk towards the preferred special purpose vehicle, there is more value at stake in public-private partnership projects in relation to traditional public procurement projects. It is in the social interest that public entities select consortia capable of performing the project with outstanding quality, yet at a reasonable price. Usually, detailed and costly project proposals are required from the bidding consortia. These high bidding costs are often seen as an inhibitor for contractors to enter the playing field and governments are currently seeking for mechanisms to increase competition. This paper models the procurement process in a bi-level experimental bidding setting with discrepancies in the bidders’ experience levels. A contractor’s strategy is composed of the pre-tender investment willingness and the targeted mark-up. An approximation algorithm for the determination of the bidding equilibrium at the contractors’ level is presented and relies on the best response heuristic. At the upper-level, the impact of common governmental policies on the bidding equilibrium is investigated. Firstly, the number of bidders invited for tender is a critical factor for the bidding behavior and especially inexperienced bidders need additional incentives to penetrate the market. The introduction of a partial government contribution in the bidding cost is proven to add value. Last but not least, a project pipeline effectively stirs up the enthusiasm of new entrants but results mostly in lower costs for the government and not necessarily in higher quality proposal documents. ", :title "How to abolish the barriers to entry in Public-Private Partnership bidding: A game-theoretical assessment of governmental policies", :keyword2 0, :authors (36770 41246), :session 102}, 915 {:keyword1 86, :keyword3 0, :abstract "In reality projects are executed under high levels of uncertainty. Empirical and theoretical research shows that the consideration of such a factor is crucial for achieving a successful project implementation. We consider an extension of the resource-constrained project scheduling problem (RCPSP), where the duration of the activities are stochastic variables with a known probabilistic distribution and both the precedence and the resource constraints must hold with a given probability. In this paper we present a branch and bound (b&b) algorithm for solving the chance-constrained RCPSP.\r\nGeneral chance-constrained programming (CCP) problems are extremely difficult to solve. In this particular case such complexity is amplified by the inherent difficulty of the (deterministic) RCPSP. Typical approaches for solving CCP problems are based on an extended integer programming (IP) formulation, where the constraints that define the set of feasible solutions of the deterministic counterpart problem are slightly modified and extended in order to obtain the new set of feasible solutions. The efficiency of those approaches is determined by the quality of the linear programming (LP) relaxation of the deterministic counterpart problem.\r\nThe IP formulations for the RCPSP have weak LP relaxations in general. In the literature there are a number of papers that present valid (sometimes facet defining) inequalities that make the different formulations stronger. However, the efficiency gap (in terms of computation time) between methods based on an IP formulation and ad hoc methods (i.e. not based on LP relaxations) is still important.\r\nWe developed a b&b method for solving the chance-constrained RCPSP. It is based on bounds obtained by using an efficient ad hoc method for the RCPSP.", :title "A branch and bound algorithm for the chance-constrained RCPSP with stochastic activity durations", :keyword2 0, :authors (36797 41246), :session 102}, 916 {:keyword1 86, :keyword3 0, :abstract "During the last decade, generating proactive baseline schedules for the RCPSP has been considered many times by different authors. Among the different approaches to construct a baseline schedule, we select the chance constraint programming approach because it has the advantage of being independent from the reactive scheduling approach and shows better performance in comparison with its competitors. \r\nAssuming that a set of supporting realizations (scenarios) exists for the random (stochastic) parameters, the proactive chance-constrained RCPSP can be formulated as a MIP formulation. The goal is to minimize the makespan such that the constraints are satisfied for a certain number (total number of scenarios x (1 - the confidence level)) of selected scenarios.  Lamas and Demeulemeester (2014) solve this MIP formulation using a branch and cut algorithm. Since solving instances with a large (possibly infinite) number of scenarios may be computationally exhaustive, the total number of scenarios can be reduced using the sample average approximation technique. \r\nSelecting a subset of scenarios is equivalent to excluding its complement subset from the set of all scenarios. We construct an undirected graph of conflicting scenarios which cannot be excluded together. Each node represents a scenario and each edge represents a conflict. These conflicts lead to a set of node packing inequalities some of which are lifted to become more stronger. \r\nIn this paper, a polynomial algorithm is devised to construct the node packing constraints. The results are discussed and compared with those provided in (Lamas and Demeulemeester, 2014). \r\n", :title "New inequalities for solving proactive RCPSP with a chance constraint", :keyword2 0, :authors (34431 41246 27231), :session 102}, 920 {:keyword1 14, :keyword3 158, :abstract "We discuss recent advances in the modeling, simulation and optimization\r\nof supply chains. The interest is in macroscopic descriptions of phenomena\r\nrelated to production. Several approaches based on continuous formulation of \r\nthe model and suitable discretization leading to a variety of problems\r\nfrom nonlinear optimization to mixed-integer problems. Recent results\r\nand relations are discussed in this talk. ", :title "Modeling and optimization of supply chains", :keyword2 101, :authors (35685 29675), :session 4}, 921 {:keyword1 86, :keyword3 0, :abstract "We consider a generalization of the resource-constrained project scheduling problem (RCPSP), namely the RCPSP with flexible resource profiles (FRCPSP) in discrete-time periods. In the FRCPSP, only the total required amount of each resource is given for each activity, whereas the activity duration and the resource allocation have to be determined. As the resource allocation of an activity can be adjusted between time periods, the resulting resource profile of the activity is flexible. The FRCPSP, therefore, determines for each activity the start time, the duration, and the resource allocation per time period in order to minimize the project makespan. To solve the FRCPSP, we propose a hybrid metaheuristic that integrates a genetic algorithm and a variable neighborhood search. The genetic algorithm employs a modified parallel schedule generation scheme with a two-step resource allocation heuristic to generate schedules. We then further improve the best-found schedules with a variable neighborhood search by reallocating resources among activities based on critical path calculations. We evaluate the performance of our proposed method and compare the results to those of other heuristic and exact methods.", :title "A Hybrid Metaheuristic for the Resource-Constrained Project Scheduling Problem with Flexible Resource Profiles", :keyword2 59, :authors (45377 35914 829), :session 199870}, 922 {:keyword1 37, :keyword3 60, :abstract "Selecting appropriate forecasting models is of particular importance for artificial Neural Networks (NN), where many candidate models of varying performance can be created. NN offer large degrees of freedom in specifying network architectures, and the weight of each architecture must be randomly initialised multiple times in order to account for local minima in parameterisation. As a result, for a single time series a large number of NN candidate models can be created, out of which one must be selected to generate the actual out-of-sample prediction.\r\n\r\nDespite the inherent importance of model selection for NNs, only limited research has addressed the issue. In statistics, model selection based on Information criteria (IC) is widely accepted (Hyndman, 2010). However, for NNs, QI & Zhang (2001) compare different in-sample information criteria of AIC, BIC etc. and forecast errors and find they fail in selecting models with high out-of-sample performance. Curry and Morgan (2004) raise fundamental theoretical concerns about the adequacy of any ICs for NNs due to the indeterminacy of redundant network weights, and the challenges in determining a network’s actual degrees of freedom. These limitations question the popular use of IC for the selection of NN models, and fundamentally impair the reliable use of NNs in forecasting.\r\n\r\nTo address this gap, this study proposes a novel NN selection criteria of multiple-step ahead out-of-sample trace forecast errors for model selection. We assess its efficacy in a large empirical evaluation on 111 time series of industry data, taken from the popular NN3 competition (Crone et al., 2010), and compare it to popular information criteria of AIC and BIC and error metrics of MSE, MAE, and MAPE for in- and out-of-sample NN model selection. ", :title "Improved Model Selection Criteria for Neural Networks: an empirical evaluation of trace errors in time series prediction", :keyword2 179, :authors (6752), :session 85}, 923 {:keyword1 93, :keyword3 93, :abstract "There are many internal and external factors that affect a supply chain’s success and sustainability. All these factors mean a risk for the supply chain. So risks should be managed carefully and  effectively. The negative effects of potential risks should be minimized for a better supply chain performance. The topic risk management has started to be used more common by academicians in recent years. There are different risk management techniques in literature. Some of these techniques are qualitative and some of them are quantitative. In this study we review quantitative risk minimization models in supply chain. First we introduce the most common risks and then we analyze quantitative risk models and their solution techniques. Finally we give some directions for future research about modeling risks in supply chain.", :title "MODELING RISKS IN SUPPLY CHAIN: AN OVERVIEW TO LITERATURE", :keyword2 101, :authors (33634 26168), :session 199860}, 924 {:keyword1 95, :keyword3 0, :abstract "This paper considers the exploitation of available real-time information in parcel pick-up processes based on a real-world application with a German parcel service provider. In particular, the effects of real-time changes in business customers’ demands are analyzed. During execution of an a priori planned master-schedule, vehicle capacity may be exceeded in the case of unexpectedly increased customer demands. Thanks to new information systems, changes in demand can be monitored in real-time during execution of the schedule. Therefore, it is possible to reschedule before a problem occurs and the remaining tour becomes infeasible. To address this issue, we model the problem as a Vehicle Rescheduling Problem with Time Windows (VSRPTW). A ruin-and-recreate heuristic is presented to allow for real-time rescheduling based on newly available data. Via simulation, the system is evaluated in a computational study. The study shows that exploiting real-time information with the developed method has positive effects on the cost and on the service level of logistics providers.", :title "Real-time rerouting with time windows and ad-hoc demand changes", :keyword2 97, :authors (45379 45381), :session 199957}, 925 {:keyword1 95, :keyword3 158, :abstract "The research deals with a routing and scheduling problem of specialized vessels carrying oil products. The aim is to develop some models for enhancing profits to oil products tankers fleet pools and for reducing shipping costs of oil products tankers to increase their competitiveness. A heterogeneous fleet transports the products from several loading ports to several discharging ports. Time windows are involved on the discharging side due to production and storage plans, and on the loading side as a result of negotiations with customers. Demand may be delivered by more than one vessel. Also a vessel may have both a service related to pick-up of oil products and a delivery of oil products. The routing and scheduling problem is formulated as a mixed-integer programming problem. It includes information and constraints about the supply and demand, but also about the vessels, the vessel routes, and the ports and their restrictions. ", :title "Vessel journey planning for oil products distribution in Vietnam", :keyword2 96, :authors (45437 23980), :session 199946}, 926 {:keyword1 17, :keyword3 0, :abstract "Benchmarking methodologies as Data Envelopment Analysis – DEA, Stochastic Frontier (SFA) and Corrected Ordinary Least Squares has been used by energy regulators around the world as an important part of the regulation process. Some regulators uses benchmarking to reach the total costs (TOTEX) that the companies are allowed to charge in the tariff, while others uses the methodology to measure the efficient operational costs(OPEX). In these models TOTEX or OPEX are used as input while network extension, number of consumers, market, area served, energy distributed disaggregated in high, medium and low voltage, density of the network, maximum demand, among others, are used as outputs. In Brazil, the regulator (ANEEL) started using benchmarking in 2007. During two cycles of tariff review and in 2012, by an anticipation of concessions renewal, the transmission companies were evaluated by DEA. For distribution energy companies the application of a benchmarking methodology started in 2010/2011. Actually the result of the process was an efficiency score taken from the average between the results of two methodologies: COLS, using a Cobb-Douglas function, and DEA, using a non decreasing returns to scale model. A second stage was added to take into account that the environment can affect the costs. In 2014 another revision in this methodology is ongoing.   This paper review the  methodologies applied in the third(3CRTP) and fourth(4CRTP) cycle of tariff review of the distribution companies and proposes an alternative that better suits to the reality of the energy brazilian distributors. ", :title "Benchmarking the Brazilian Distribution Electricity Companies using Data Envelopment Analysys - DEA", :keyword2 29, :authors (31737 45641 45640), :session 24}, 927 {:keyword1 95, :keyword3 150, :abstract "The basic multiple-vehicle arc-routing problem is called Capacitated Arc-Routing Problem (CARP). Applications of the CARP are in waste collection and mail delivery, for example. The goal is to find a cost-minimal set of tours that service all required edges and meet the capacity restriction. In this work, a cut-first branch-and-price second approach is developed. In phase one, cutting planes are generated that are introduced to the master problem in the second phase. The subproblem is a shortest path problem with resource constraints. It is solved in order to generate new columns for the master problem. Integer CARP solutions are guaranteed by a new hierarchical branching scheme. Comprehensive computational results show the effectiveness of the algorithm. Combining location problems with arc-routing problems enables one to model more realistic mail delivery applications. In this work, two mathematical formulations for each park and loop, and park and loop with curbline are introduced. The two models for each problem differ in how they model feasible transfer routes. While the first type of model uses subtour-elimination constraints, the second type uses flow variables and flow conservation constraints. The computational study shows that a MIP-Solver often needs less computation time to solve the latter type of model or results in better lower bounds when reaching the time limit.", :title "On Arc-Routing Problems", :keyword2 157, :authors (29566), :session 199949}, 929 {:keyword1 8, :keyword3 144, :abstract "Political districts are of significant importance in elections to the Bundestag, the German parliament. Each district elects one  representative into parliament ensuring that each part of the country is represented. These elected representatives make up half of the members of the Bundestag. The allocation of electoral districts is subject to legal requirements and needs regular updates due to an ever-changing population distribution. In the author's master's thesis, the problem of dividing a country into electoral districts is defined as a multi-criteria optimization problem in which a node-weighted graph has to be partitioned into a given number of contiguous, weight-restricted subgraphs. In a comprehensive analysis, the NP-hardness of this problem is proven. In addition and to get a more profound understanding of the complexity, the underlying partition problems are investigated on different graph classes. An optimization-based heuristic in accordance with the divide-and-conquer principle is introduced and successfully applied to population data of the latest German census. The computed results show that the presented algorithm allocates electoral districts, which are not only in accordance with the law, but also match the objectives mentioned in the law more closely than the current districting. ", :title "Political Districting for Elections to the German Bundestag", :keyword2 157, :authors (45055), :session 199948}, 930 {:keyword1 175, :keyword3 59, :abstract "We consider an operational process at shunting yards, where freight cars are disassembled and reassembled via a system of tracks and switches to form outbound trains with no restriction on the order of the freight cars. Given are due dates for each outbound train and priority values for its freight cars. Furthermore, the composition and the processing time of each inbound train is part of the input. An outbound train is de ned by a set of freight cars taken from one or many inbound trains. In this context, we try to minimize the weighted tardiness of all outbound trains by the determination of the optimal humping sequence of the inbound trains. We show that this problem is NP-hard and we present a simple mixed integer problem formulation. Besides two heuristic approaches and an implementation in CPLEX, the main focus of our single stage shunting problem is on the development of an exact branch & bound procedure. Therefore, we present powerful precedence constraints and priority rules to reduce the solution space. Further, we compare the runtime and accuracy of the proposed algorithms with the results of CPLEX optimizer in a computational study.  ", :title "Adapting exact and heuristic procedures in solving an NP-hard sequencing problem", :keyword2 157, :authors (45567), :session 199948}, 931 {:keyword1 8, :keyword3 163, :abstract "The quadratic traveling salesman problem (QTSP) is an extension of the traveling salesman problem  (TSP) where the costs do not depend on two but on each three nodes traversed in succession. It can be formulated as an integer program with a quadratic objective function. The QTSP is motivated by an application in bioinformatics. Important special cases are the angular-metric TSP and the TSP with reload costs. We present polyhedral studies for the linearized integer programming formulations in the symmetric and in the asymmetric case. These include the dimension of the associated polytopes as well as three groups of valid inequalities and facets. Some are related to the Boolean quadric polytope and some forbid conflicting configurations. Furthermore, we provide two general approaches that allow to strengthen valid inequalities of TSP in order to get stronger inequalities for QTSP. Applying these approaches to the subtour elimination constraints leads to facets in most cases, but in general facetness is not preserved. In addition, the complexity of the separation problems for several facet classes is studied. Finally, we present some computational results using a branch-and-cut framework. Separating the newly derived cutting planes large instances from biology could be solved to optimality.", :title "A Polyhedral Study of Quadratic Traveling Salesman Problems", :keyword2 176, :authors (26471), :session 199949}, 932 {:keyword1 8, :keyword3 175, :abstract "A system of lines in public transport should usually be connected, i.e., for each two stations there has to be a connecting path that is covered by the lines. We define this problem in a graph theoretical context and call it the Steiner connectivity problem. It is a generalization of the well-known Steiner tree problem. We discuss complexity and approximation algorithms, give a transformation to the directed Steiner tree problem, and show that directed models provide tighter formulations for the Steiner connectivity problem than undirected models, similar as for the Steiner tree problem. Some of these investigations can be used to propose a novel direct connection approach that allows an integrated optimization of line planning and passenger routing. This approach focusses on direct connections. The attractiveness of transfer free connections is increased by introducing a transfer penalty for each non-direct connection. In a project with the Verkehr in Potsdam GmbH to compute the line plan for 2010 we showed that our approach is applicable in practice and can be used to solve real world problems.", :title "Line Planning and Connectivity", :keyword2 151, :authors (45197), :session 199949}, 933 {:keyword1 94, :keyword3 104, :abstract "In this thesis, we consider mathematical optimization under data uncertainty using mixed integer linear programming techniques. Our investigations follow the deterministic paradigm known as robust optimization. We investigate four robustness concepts for robust optimization and describe their parametrization, application, and evaluation. The concepts are gamma-robustness, its generalization multi-band robustness, the novel more general submodular robustness, and the two-stage approach called recoverable robustness.\r\n\r\nFor each concept, we investigate the corresponding robust generalization of the knapsack problem (KP) presenting IP formulations, detailed polyhedral studies including new classes of valid inequalities, and algorithms. In particular, for the submodular KP, we establish a connection to polymatroids and for the recoverable robust KP, we derive a nontrivial compact reformulation. Additionally, the recoverable robust KP is experimentally evaluated in detail.\r\n\r\nFurther, we consider the gamma-robust and multi-band robust generalizations of the capacitated network design problem (NDP) presenting MIP formulations, new detailed polyhedral insights with new classes of valid inequalities, and algorithms. For example, we derive alternative formulations for these robust NDP by generalizing metric inequalities. Furthermore, we present representative computational results for the gamma-robust NDP using real-life measured uncertain data from telecommunication networks based on our work with the German ROBUKOM project.", :title "Robustness Concepts for Knapsack and Network Design Problems under Data Uncertainty", :keyword2 176, :authors (45121), :session 199949}, 934 {:keyword1 40, :keyword3 0, :abstract "Weighted congestion games are a significant and extensively studied class of strategic games, in which players compete for subsets of shared resources in order to minimize their private costs. In this thesis, we introduce congestion games with multi-dimensional demands as a generalization of weighted congestion games. Instead of a one-dimensional demand value each player is associated with a multi-dimensional demand vector and the cost function of a resource is a multi-variable function of the aggregated demand vectors of all players sharing the resource. Such a cost structure is natural when the cost of a resource depends not only on one, but on several properties of the players’ demands, e.g., total weight, total volume, and total number of items. We study the existence of pure Nash equilibria for this new class of games and give a complete characterization of the existence of pure Nash equilibria in terms of the resource cost functions. Specifically, we identify all sets of cost functions that guarantee the existence of a pure Nash equilibrium for every congestion game with multi-dimensional demands. Furthermore, we investigate the equilibrium existence problem for subclasses with restricted strategy spaces, such as singleton or matroid congestion games with multi-dimensional demands.", :title "Congestion Games with Multi-Dimensional Demands", :keyword2 8, :authors (45568), :session 199948}, 935 {:keyword1 72, :keyword3 150, :abstract "Faster computers and algorithms have transformed how sports schedules have been created in practice in a wide range of sports.  Techniques such as Combinatorial Benders Decomposition, Large Scale Neighborhood Search, and Brand-and-Price have greatly increased the range of sports leagues that can use operations research methods to create their schedules.  With this increase in computational and algorithmic power comes the opportunity to create not just playable schedules but more profitable schedules.  Using data mining and other predictive analytics techniques, it is possible to model attendance and other revenue effects of the schedule.  Combining these models with advanced schedule creation approaches leads to schedules that can generate more revenue for teams and leagues.  These concepts are illustrated with experiences in professional and college sports leagues.\r\n", :title "Sports Scheduling meets Business Analytics", :keyword2 157, :authors (2091), :session 199965}, 936 {:keyword1 171, :keyword3 0, :abstract "Cognitive computing systems learn and interact naturally with people to extend what either humans or machine could do on their own. They help human experts make better decisions by penetrating the complexity of Big Data. This talk will provide an overview of cognitive computing, discuss current applications of it, and explore the role operations research can play in extending cognitive computing beyond the domain of language based reasoning.\r\n", :title "Operations Research in the Era of Cognitive Computing", :keyword2 149, :authors (9083), :session 199966}, 937 {:keyword1 175, :keyword3 0, :abstract "In 2008, Netherlands Railways (NS) won the Franz Edelman Award for using the Operations Research (OR) methods to introduce a completely, new timetable in December 2006. This timetable was selected from a set of 10 timetables, all generated with OR models. In addition, rolling stock and crew schedules were constructed with OR tools. Although the general performance of NS has significantly improved since the introduction of the new timetable, NS struggled a lot with winter weather, more specific with snow, during the last couple of years.\r\n\r\n \r\n\r\nIn December 2009, after severe problems in train operations, NS started - together with ProRail (the Dutch railway infrastructure manager) and the Ministry of Infrastructure and the Environment - a Winter program to improve its operations during heavy winter days. The long term goal of the Winter program is to achieve a high performance under all circumstances, so even during heavy winter conditions. This goal can be achieved by improving the assets such that they do not fail during heavy winter conditions, and by having a new process for disruption management. In this process, advanced algorithms to reschedule the timetable, rolling stock and crew in realtime, play a major role. The algorithms for real-time rescheduling of crew have already been used in practice. Experiments since Summer 2013 have shown that crew members can be rescheduled within a few minutes. In this presentation, we will discuss the first results, our implementation strategy and remaining challenges. \r\n", :title "OR at Netherlands Railways: Successes and Challenges", :keyword2 0, :authors (5932), :session 199980}, 938 {:keyword1 42, :keyword3 0, :abstract "The baggage handling system at Frankfurt Airport distributes up to 110.000 bags per day using its over 80 km long rail tracks. During the last years the baggage handling system has been extended and new requirements have been implemented, e.g. robust routing in case of disturbances and balancing constraints for the early baggage storage system based on prognosis data. This talk describes how OR helped us to succeed in this complex project.\r\n\r\nTechnical details will be discussed in an accompanying talk given by Frauke Böckmann on Thursday morning.", :title "How OR Improves The Baggage Handling System At Frankfurt Airport - Project Insights", :keyword2 7, :authors (45168 33333), :session 199980}, 939 {:keyword1 94, :keyword3 101, :abstract "Optimization problems associated with real applications often suffer from difficulties due to a large scale design dimension, or lack of convexity, or the presence of uncertain parameters. We present some meaningful cases where these difficulties were successfully addressed. The examples include applications in Signal Processing, Machine Learning, Supply Chains, and Medical Imaging.\r\n", :title "Tractable solutions of some challenging optimization problems", :keyword2 124, :authors (11838), :session 199968}, 940 {:keyword1 31, :keyword3 94, :abstract "There are several industries connected closely to natural resources, such as forests, minerals and energy. The natural resource sector is fundamental to a strong modern bio-social-economy for many countries. There are some important characteristics which are common for all (or a majority) of the natural resource areas. The underlying value chain for each area is divergent i.e. they start with few raw materials and as these are refined through the value chain the number of products and services increases. These areas are also important for their social impact, energy production/consumption and the environment. There are many stakeholders and decision makers in the natural resources value chains, which often are decoupled, and several objectives are driving the planning processes. Lastly, the logistic operations typically involve large long term investments and very large volumes. Optimizing this set of integrated values which often are conflicting (in terms of how they drive the decisions) is a complex task.  This raises the need for sustainable, robust and integrated long-term and short-term planning. In this presentation, we will address a number of applications arising in different value chains. We discuss their properties, interactions and challenges. The applications include transportation, inventory, routing and distribution planning in the forest and mining industries. We also describe how operations research models and methods have been crucial and used efficiently to develop practical decision support tools for the sector. These tools include collaborative logistics, anticipative and integrative planning, and robust optimization. \r\n", :title "Value chain planning for natural resources", :keyword2 174, :authors (1666), :session 199977}, 941 {:keyword1 124, :keyword3 0, :abstract "Deep Learning is the field of study of hierarchical information processing systems, more historically known as neural networks. Recently the field has been received great attention from academia, industry and the media as new techniques have emerged that have advanced the state of the art in reinforcement learning, natural language modelling, compression and computer vision, amongst others.  I'll give a brief overview of the field,  the techniques involved and aspirations for future intelligent information processing algorithms.\r\n", :title "Deep Learning", :keyword2 52, :authors (45634), :session 199967}, 942 {:keyword1 13, :keyword3 0, :abstract "Convex optimization has emerged as useful tool for applications that include data analysis and model fitting, resource allocation, engineering design, network design and optimization, finance, and control and signal processing. After an overview, the talk will focus on two extremes: real-time embedded convex optimization, and distributed convex optimization.   Code generation can be used to generate extremely efficient and reliable solvers for small problems, that can execute in milliseconds or microseconds, and are ideal for embedding in real-time systems.  At the other extreme, we describe methods for large-scale distributed optimization, which coordinate many solvers to solve enormous problems.", :title "Convex Optimization: From embedded real-time to large-scale distributed", :keyword2 53, :authors (7487), :session 199969}, 943 {:keyword1 8, :keyword3 0, :abstract "The problem of allocating bundles of indivisible objects without transfers arises in the assignment of courses to students, the assignment of computing resources like CPU time, memory and disk space to computing tasks and the assignment of truck loads of food to food banks. In these settings the complementarities in preferences are small compared with the size of the market. We exploit this to design mechanisms satisfying efficiency, envyfreeness and asymptotic strategy-proofness.\r\n\r\n\r\nInformally, we assume that agents do not want bundles that are to large. There will be a parameter k such that the marginal utility of any item relative to a bundle of size k or larger is zero. We call such preferences k-demand preferences. Given this parameter we show how to represent probability shares over bundles as lotteries over approximately deterministic feasible integer allocations. The degree of infeasibility in these integer allocations will be controlled by the parameter k. In particular, ex-post, no good is over allocated by at most k-1 units.\r\n\r\nBased on joint work with Thanh Nguyen and Ahmad Peivandi.", :title "One-Sided Matching with Limited Complementarities", :keyword2 40, :authors (39622), :session 199978}, 944 {:keyword1 22, :keyword3 0, :abstract "Laura McLay will describe her research projects that apply operations research methodologies to emergency medical services.  These projects have resulted in several key insights into optimally using scarce public resources for responding to health emergencies. This talk will include a discussion of issues that affect models for optimally allocating scarce resources for public services (such as emergency medical services) including issues involving performance benchmarks, equity, natural disasters, and modeling human elements in systems. She will also discuss insights obtained from putting the results into practice in a real world setting.\r\n", :title "Delivering emergency medical services: research, application, and outreach", :keyword2 45, :authors (40522), :session 199975}, 945 {:keyword1 171, :keyword3 173, :abstract "Detecting hidden structures in (high-dimensional) data is a general and ubiquitous task. Examples include the assessment of insurance risks and the\r\ncorresponding tariffing, issues of predictive maintenance, supply-chain diversification, medical treatment planning or business demand prediction.\r\n\r\nThere is a wide range of analytical and statistical methods for data analysis and assessment. For instance, in auto insurance, parameter-based tariffing is employed that, in fact, leads to a box-classification of the\r\nparameter space followed by rather involved statistics.\r\n\r\nIn the talk we present a geometric clustering model that provides a shift towards a more sophisticated and data-structure-based dissection of space that allows for much simpler and more reliable subsequent statistics. We show how the model captures the intuition behind good clusterings and leads to efficient algorithms in practice. Also, we report on results for some real-world tasks of the problems mentioned before.\r\n\r\n(Joint work with Andreas Brieden)\r\n", :title "On data segmentation", :keyword2 8, :authors (18841), :session 199972}, 946 {:keyword1 101, :keyword3 0, :abstract "Increasingly, companies are finding that the end of efficiency improvements in operations within company borders have been reached: vehciles routes have been optimized, inventory has been pooled, and manufacturing economies of scale have been reached. A natural next step is to then explore optimization bevond company borders. While vertical collaboration (with suppliers and customers) has received a lot of attention in the literature and in industrial practice in the past 15 years, horizontal collaboration (with competitors or other companies at the same level in the supply chain) is much less studied and practiced.\r\n\r\nIn this talk, I will give an overview of horizontal collaboration across a variety of industries in logistics, manufacturing, and retail. Examples will be given of actual projects, and the requirements on associated models will be discussed. The relationship between important business questions such as the appropriate governance model of the collaboration and the modeling support that operations research can offer will be discussed.\r\n\r\n", :title "Optimizing beyond company borders: Horizontal collaboration in supply chain management", :keyword2 0, :authors (995), :session 199971}, 947 {:keyword1 171, :keyword3 149, :abstract "Big Data is a shortcut for a very interesting phenomenon: we now have data about almost everything.  Managing and using that data can be challenging.  Indeed, data can come in very large volumes.  Data can also come in a large variety of forms (eg audio, video, free text, text feeds, sensor measures, etc).  Data can also by in motion (streamed) as opposed to be at rest.  Each of these Big Data dimensions (volume, variety, velocity) create challenges and opportunities for optimization techniques and applications.  We will review these challenges and explore potential approaches.  We will also provide some actual examples where Big Data and Optimization are used together in new, innovative, applications.\r\n", :title "Optimization in the Big Data age", :keyword2 53, :authors (39533), :session 199976}, 948 {:keyword1 2, :keyword3 97, :abstract "The ORCONOMY GmbH has successfully developed an IT-solution for scenario-based scheduling of flight simulator trainings. The goal was to achieve an optimal capacity allocation of cockpit simulator capacities under consideration of customer requests. An advanced user interface in combination with a powerful optimization core ensured the quality and acceptance of the solution.", :title "An OR-Framework-based solution for optimal flight simulator scheduling", :keyword2 7, :authors (7364), :session 199982}, 949 {:keyword1 170, :keyword3 0, :abstract "Metaheuristic algorithms and frameworks, such as tabu search, genetic algorithms, variable neighborhood search, etc., were in fact usually proposed in years when mixed integer programming (MIP) was seldom a viable option for solving real-world problem instances.\r\n\r\nHowever, research on mathematical programming, and in particular on discrete optimization, has led to a state of the art where MIP solvers or customized mathematical programming codes can be effective even in a heuristic context, both as primary solvers or as subprocedures.\r\n\r\nIn the past years different hybrid variants of  xact and metaheuristic search techniques - also called matheuristics - were developed especially for rich problems in the field of logistics and transportation. In this talk different design concepts of matheuristics will be presented. ", :title "Matheuristic Design Concepts for Rich Problems", :keyword2 0, :authors (2769), :session 199970}, 950 {:keyword1 174, :keyword3 0, :abstract "t.b.a.", :title "Re-Designing a parcel network for growth", :keyword2 0, :authors (19541), :session 199974}, 951 {:keyword1 45, :keyword3 0, :abstract "Almost eight million cancer patients worldwide receive some form of radiation therapy each year. One promising treatment is high-dose-rate brachytherapy, which entails delivering high-dose radiation to the tumor via the temporary implantation of radioactive seeds. This treatment promises to be particularly effective in eradicating tumors, while preserving the organs. Yet, major obstacles to successful treatment remain, especially (1) determining the best seed type, spatial configuration of seeds, and seed dwelling time, and (2) improving the probability that the treatment will eliminate all malignant cells. We developed an advanced planning model to simultaneously address both of these issues. To permit taking advantage of the best available information, our model works with inputs from positron emission tomography. We begin with a multiobjective, nonlinear, mixed-integer programming model that is initially intractable. To solve the model, we introduce an original branch-and-cut and local-search approach that couples new polyhedral cuts with matrix reduction and intelligent geometric heuristics. The result has been accurate solutions, which are obtained rapidly. Clinical trials on cervical cancer treatment at Rush University Medical Center have demonstrated superior medical outcomes. These analytical techniques are applicable not only to cervical cancer, but also to other types of cancer, including breast, lung, and prostate cancer.\r\n", :title "Health Analytics: Personalized Cancer Treatment Planning", :keyword2 57, :authors (3633), :session 199973}, 952 {:keyword1 175, :keyword3 8, :abstract "We present a novel extended formulation for the line planning problem that is based on what we call \"configurations\" of lines and frequencies. Configurations are combinatorial building blocks of primal solutions; they rule out the \"capacity numerics\" and make the problem purely combinatorial. The configuration model is strong in the sense that it implies several facet-defining inequalities for the standard model: set cover, symmetric band and MIR inequalities, and multicover inequalities. These theoretical findings can be confirmed in computations, however, the enormous number of configurations can blow up the formulation for large instances. We propose a mixed model that enriches the standard model by a judiciously chosen subset of configurations that provide a good compromise between model strength and size. Computational results for large-scale line planning problems are presented.", :title "A Configuration Model for the Line Planning Problem", :keyword2 176, :authors (45659 14923 45197), :session 199896}, 953 {:keyword1 175, :keyword3 0, :abstract "The transport planning problem deals with moving goods from one location to another by using the available modes of transport. What makes this problem interesting is that intermodal transport of goods is also allowed.\r\n\r\nThe territory planning problem basically involves partitioning a set of customers into a given number of clusters that are “balanced”, “compact”, and as nonoverlapping as possible.\r\n\r\nWe will briefly talk about and define these problems. Then, we will take a short look at the way we solved them.\r\n\r\n ", :title "Solving two practical problems from the worlds of transport and territory planning", :keyword2 0, :authors (45661), :session 199980}, 954 {:keyword1 174, :keyword3 0, :abstract "Deutsche Post DHL has invested a significant amount in its parcel distribution network over the last 3 years. Different methods and models from Operations Research are used to optimize the distribution network by supporting management decisions concerning the hub location or the sorting capacity of hubs. A linear mathematical programm which optimizes the number and the location of delivery depots will be presented and it will be illustrated how OR has influenced the landscape of delivery depots within the parcel distribution network of Deutsche Post DHL in Germany so far.", :title "Optimizing the delivery depot network of DHL Parcel in Germany", :keyword2 57, :authors (24366 45693), :session 199980}, 955 {:keyword1 149, :keyword3 0, :abstract "This is a panel discussion with business analytics experts from renowned companies. They will discuss whether analytics is different from operations research as we know it, its risks and opportunities, and what perspectives it offers for companies and scientists, theory and practice.", :title "Analytics - Hype or here to stay?", :keyword2 0, :authors (17621 4625 7364 14818), :session 199983}, 956 {:keyword1 175, :keyword3 0, :abstract "Since the beginning of the credit crisis in 2008, many shipping companies have adopted slow-steaming policies. Prior to the credit crisis slow-steaming was a concept virtually unheard of in the industry; primarily due to a shortage of vessel capacity. During our presentation we will introduce some of the dynamics of slow-steaming and the dilemma that this creates for shipping companies. Also, we will discuss speed differentiation that is beyond the scope of the company?s control. \r\n\r\nIn the second half of the presentation we will explore how Integrated Planning Platform help to secure the benefits of the slow steaming opportunity while adhere to other to other constraints. Then we will review how this complex model ? with the help of solvers ? will help to create robust planning scenarios for an example scenario with increased demand. We will conclude by summarizing the benefits for shipping company. \r\n", :title "Time, speed and bunker consumption in tactical and operational planning", :keyword2 0, :authors (45697), :session 199981}, 957 {:keyword1 7, :keyword3 0, :abstract "Being one of the largest manufacturers of automated teller machines (ATMs), it comes naturally to Wincor Nixdorf to offer cash management software and consulting to the end of running a network of ATMs as cost-effectively as possible while maintaining a high service level. Taking the classical inventory optimization problem as a starting point, we will provide an introduction to the additional challenges arising by way of service times, lead times, cash recycling, co-location of ATMs, residual costs and limited transport capacities, amongst others. We will present common pitfalls and successful modelling techniques. If time permits, we will go beyond the realm of retail banking and have a brief look at cash management for central banks.", :title "Optimized Operation of Automated Teller Machines and Vaults", :keyword2 0, :authors (45698), :session 199982}, 958 {:keyword1 29, :keyword3 0, :abstract "TransAlta headquartered in Calgary, Alberta, Canada, has implemented KISTERS’ BelVis\r\nResOpt for optimization of their 800 MW Hydroelectric power plants on the Bow and the North\r\nSaskatchewan River Systems. BelVis ResOpt solves complex optimization problems using\r\nMixed Integer Linear Programming (MILP) with the support of a commercial mathematical\r\nsolver. The application has been setup to automatically provide day-ahead operation schedules to\r\noptimize for maximum benefit over time. Prior to using BelVis ResOpt, the water management\r\nengineers estimated the optimization results with the use of spreadsheets. This process was not\r\nonly time consuming but did not guarantee the best possible solution. By switching to BelVis\r\nResOpt users are now able to focus their attention on higher level tasks like scheduling decisions\r\nto maximize profit and minimize risks while the tool runs different analysis scenarios and\r\nautomatically provides daily operational solutions. \r\n", :title "Optimization for a Canadian hydro-power company", :keyword2 0, :authors (45699), :session 199981}, 959 {:keyword1 28, :keyword3 0, :abstract "Due to the energy transition in Germany the energy sector is affected by massive changes that make\r\nthe planning tasks for the utilities more and more complex. Given the sharp rise in shares of non-\r\npredictable energy supply from renewable energy sources (wind, solar) an intraday market was\r\nestablished, allowing the energy suppliers to respond to changes in demand and supply situations at \r\nvery short notice. Especially the difficult predictability of renewable generation leads to imbalances\r\nin the energy system, which cannot be covered by balancing energy mechanisms only.\r\n\r\nEnergy suppliers now have the challenge to continuously monitor their generation portfolio and \r\ncalculate forecasts for their own renewable infeed and the heat demand of their customers. In \r\naddition, the short-term forecast of prices in the intraday market seems useful. Any new forecast\r\nsituation or any change in the conditions in the market result in a new optimization problem to \r\ndetermine the optimal market behavior and to calculate the optimal operation of the power plants.\r\n\r\nFor about 20 years ProCom GmbH offers planning solutions for the energy sector, helping to optimize \r\nenergy portfolios and forecast prices, energy demand and supply. The underlying platform BoFiT\r\nsupports users starting from the model development for optimization and forecast ending at \r\nautomatically running processes for continuous trading in the energy markets. The optimization \r\nfunctions are based on mixed integer programming and the forecast functions use among other \r\nmethods artificial neural networks.\r\n", :title "Intraday Trading in Energy Markets – a continuous Optimization and Forecasting Challenge", :keyword2 0, :authors (33504), :session 199981}, 960 {:keyword1 97, :keyword3 0, :abstract "Discrete-event simulation is a well-established OR tool to tackle a great variety of (stochastic) optimization problems in different industries like manufacturing and logistics. But the terms simulation and optimization are very often mixed-up or even seen as competitive in these industries. This talk will show some practical applications of discrete-event simulation starting with simulation as \"pure\" evaluation function, as a tool for the simulation expert to , e.g., manually optimize dynamic control rules, and as a complementing companion of mathematical optimization procedures. In addition, some of the challenges which an OR consultant and a company working day to day in that field have to face when simulation comes to practice will be described as well.", :title "Simulation and Optimization - Practical Considerations of competitive Companions", :keyword2 0, :authors (45700), :session 199979}, 961 {:keyword1 75, :keyword3 0, :abstract "A smart and simple solution usable for production optimization must nowadays answer a variety of questions for business operations and long-term planning. As part of this presentation and discussion we give an insight into a customer project . The mission-critical objectives of this project included the improvement of customer orientation by optimizing delivery and response times as well as optimizing the use of capital by reducing bound means. We optimized the production regarding utilization of existing capacity.  Futher goals were the automation of operational processes - for example the creation of delivery plans for major projects or the bundling of contracts - and a simulation of \"what if\" scenarios for optimal decision support.\r\n\r\nThe project was realized using X-INTEGRATE´s solution \"XPO\". Using XPO, you can utilize production facilities better, improve customer service and satisfaction and optimize planning horizons as well as production processes. XPO is ready to use and can flexibly be adapted to individual needs. Because of it´s module-based approach, XPO is suitable for medium-sized companies as well as large enterprises and regional manufacturing companies. \r\n", :title "Planning optimization for multi-site, fast & efficient production processes - customer satisfaction and on-time delivery in focus ", :keyword2 0, :authors (45701), :session 199982}, 962 {:keyword1 48, :keyword3 0, :abstract "The nature of the pick and place process directly implies lot of discrete decisions to take. Somehow the machine setup, the sequence of operations on a machine and the distribution of \r\nworkload within in the machines in a line have to be defined. \r\n\r\nThe same holds on the production planning level. The goal of reducing change over times \r\ndirectly leads to the task of sequencing and clustering products. \r\n\r\nIn this talk, we focus on the interaction of mathematicians and engineers in the development of \r\nmachines and of mathematicians and production planners on the higher planning levels.", :title "Mathematical Optimization in Printed Circuit Board Assembly", :keyword2 0, :authors (45702), :session 199982}, 963 {:keyword1 101, :keyword3 0, :abstract "Air Liquide’s operations management must take into account supply and demand data as well as contractual requirements and market information when planning the day-to-day operations, as well as for long-term strategic planning. Optimization tools have been developed based on complex models of Air Liquide’s industrial activity, reaching from medium-term regional production planning down to real-time operation of individual plant equipment. Based on the integration of real-time operations data as well as multiple market data interactive tools support daily business decision-making such as short-term energy procurement as well as optimized dispatching of production volumes to the plants.\r\n", :title "Industrial Gases Production and Supply Chain Optimization", :keyword2 75, :authors (45703), :session 199981}}, :users {1 {:firstname "Bernard", :lastname "Fortz", :department "Département d'Informatique", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (199909 199886 199832 199898)}, 125 {:firstname "Norbert", :lastname "Trautmann", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (199870)}, 247 {:firstname "Rainer", :lastname "Leisten", :department "Operations Management", :institution "University Duisburg-Essen in Duisburg", :country "Germany", :sessions (199846)}, 485 {:firstname "Matthias", :lastname "Ehrgott", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (199833)}, 518 {:firstname "Luca Maria", :lastname "Gambardella", :department "Istituto Dalle Molle di Studi sull'Intelligenza Artificiale", :institution "IDSIA", :country "Switzerland", :sessions (47 50)}, 662 {:firstname "Andrea", :lastname "Lodi", :department "D.E.I.S.", :institution "University of Bologna", :country "Italy", :sessions (69)}, 829 {:firstname "Rainer", :lastname "Kolisch", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (103 199865 95 199870)}, 969 {:firstname "Antonio", :lastname "Frangioni", :department "Dipartimento di Informatica", :institution "Universita' di Pisa", :country "Italy", :sessions (199905)}, 995 {:firstname "Jan C.", :lastname "Fransoo", :department "Department of Technology Management", :institution "Technische Universiteit Eindhoven", :country "Netherlands", :sessions (199971 199955)}, 1019 {:firstname "Marc", :lastname "Uetz", :department "Applied Mathematics ", :institution "University of Twente ", :country "Netherlands", :sessions (34 93 33 199917)}, 1082 {:firstname "Ger", :lastname "Koole", :department "Mathematics", :institution "Vrije Universiteit Amsterdam", :country "Netherlands", :sessions (77)}, 1141 {:firstname "Leena", :lastname "Suhl", :department "Dept. Business Information Systems", :institution "University of Paderborn", :country "Germany", :sessions (199979 199938 199847)}, 1194 {:firstname "Natalia", :lastname "Kliewer", :department "Information Systems", :institution "Freie Universitaet Berlin", :country "Germany", :sessions (98 199926)}, 1244 {:firstname "Thomas", :lastname "Vossen", :department "Leeds School of Business", :institution "University of Colorado", :country "United States", :sessions (199875)}, 1256 {:firstname "Teresa", :lastname "Melo", :department "Business School", :institution "Saarland University of Applied Sciences", :country "Germany", :sessions (199973 199938 199937)}, 1560 {:firstname "Kathrin", :lastname "Klamroth", :department "Department of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (199837 199948 199918 199834)}, 1601 {:firstname "Anita", :lastname "Schöbel", :department "TU Kaiserslautern", :institution "Fachbereich Mathematik", :country "Germany", :sessions (42 54 87 199905 75)}, 1610 {:firstname "Heinz", :lastname "Ahn", :department "Institut für Controlling und Unternehmensrechnung", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (199833)}, 1658 {:firstname "Peter", :lastname "Letmathe", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (199964 199849 199933)}, 1666 {:firstname "Mikael", :lastname "Rönnqvist", :department "", :institution "Département de génie mécanique", :country "Canada", :sessions (199977)}, 1835 {:firstname "Maxim", :lastname "Sviridenko", :department "", :institution "IBM T. J. Watson Research Center,", :country "United States", :sessions (199917)}, 2091 {:firstname "Michael", :lastname "Trick", :department "Tepper School of Business", :institution "Carnegie Mellon University", :country "United States", :sessions (199965)}, 2189 {:firstname "Michel", :lastname "Gendreau", :department "MAGI and CIRRELT", :institution "Polytechnique Montréal", :country "Canada", :sessions (50)}, 2268 {:firstname "Ahti", :lastname "Salo", :department "Systems Analysis Laboratory", :institution "Aalto University School of Science", :country "Finland", :sessions (199928)}, 2279 {:firstname "Daniel", :lastname "Vanderpooten", :department "", :institution "LAMSADE - Universite Paris Dauphine", :country "France", :sessions (199837)}, 2448 {:firstname "Herbert", :lastname "Meyr", :department "Department of Supply Chain Management", :institution "University of Hohenheim", :country "Germany", :sessions (199859)}, 2529 {:firstname "Antonio", :lastname "Jiménez-Martín", :department "Departamento de Inteligencia Artificial", :institution "Universidad Politécnica de Madrid (UPM)", :country "Spain", :sessions (199830)}, 2650 {:firstname "Grit", :lastname "Walther", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (61 77 199977 199933 199934)}, 2651 {:firstname "Thomas", :lastname "Spengler", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (15 60 199871 99 101)}, 2675 {:firstname "Frank", :lastname "Schultmann", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (199886 61)}, 2769 {:firstname "Karl", :lastname "Doerner", :department "Department of Business Decisions and Analytics", :institution "University of Vienna", :country "Austria", :sessions (199848 199970)}, 2795 {:firstname "Oliver", :lastname "Stein", :department "Institute of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (199910 199960)}, 2832 {:firstname "Baris", :lastname "Tan", :department "College of Administrative Sciences and Economics", :institution "Koç University", :country "Turkey", :sessions (199845)}, 2987 {:firstname "Jeroen", :lastname "Belien", :department "Center for Information Management, Modeling and Simulation", :institution "KU Leuven", :country "Bermuda", :sessions (199872)}, 3122 {:firstname "Georg", :lastname "Pflug", :department "Department of Statistics and Decision Support Systems", :institution "University of Vienna", :country "Austria", :sessions (199877)}, 3287 {:firstname "Miguel F.", :lastname "Anjos", :department "School of Mathematics", :institution "University of Edinburgh", :country "United Kingdom", :sessions (199918)}, 3297 {:firstname "Naoki", :lastname "Katoh", :department "Department of Informatics", :institution "Kwansei Gakuin University", :country "Japan", :sessions (199916)}, 3524 {:firstname "Gerhard-Wilhelm", :lastname "Weber", :department "Faculty of Engineering Management, Chair of Marketing and Economic Engineering", :institution "Poznan University of Technology", :country "Poland", :sessions (199958)}, 3557 {:firstname "Alan", :lastname "Scheller-Wolf", :department "", :institution "Carnegie Mellon University", :country "United States", :sessions (89)}, 3558 {:firstname "Stan", :lastname "van Hoesel", :department "", :institution "University of Maastricht", :country "Netherlands", :sessions (199903)}, 3578 {:firstname "Mahmut Ali", :lastname "Gokce", :department "Industrial Engineering", :institution "Yaşar University", :country "Turkey", :sessions (199854)}, 3614 {:firstname "Aydin", :lastname "Sipahioglu", :department "Industrial Engineering", :institution "Osmangazi University", :country "Turkey", :sessions (199957)}, 3633 {:firstname "Eva", :lastname "Lee", :department "Industrial and Systems Engineering", :institution "Georgia Institute of Technology", :country "United States", :sessions (199973)}, 3669 {:firstname "Dave", :lastname "Worthington", :department "The Management School", :institution "Lancaster University", :country "United Kingdom", :sessions (199891)}, 3746 {:firstname "Boaz", :lastname "Golany", :department "Industrial Engineering & Management", :institution "Technion - Israel Institute of Technology", :country "Israel", :sessions (199852)}, 3753 {:firstname "Robert", :lastname "Fourer", :department "", :institution "AMPL Optimization Inc.", :country "United States", :sessions (96)}, 3821 {:firstname "Fouad", :lastname "El Ouardighi", :department "Operations Management", :institution "ESSEC Business School", :country "France", :sessions (75)}, 3843 {:firstname "Bjarni", :lastname "Kristjansson", :department "", :institution "Maximal Software", :country "Iceland", :sessions (199982 199883 81652)}, 4161 {:firstname "Stefan", :lastname "Irnich", :department "Chair of Logistics Management, Gutenberg School of Management and Economics", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (199916 199919)}, 4224 {:firstname "Grzegorz", :lastname "Pawlak", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (199944 199963 199943)}, 4229 {:firstname "Moritz", :lastname "Fleischmann", :department "Chair of Logistics and Supply Chain Management", :institution "University of Mannheim", :country "Germany", :sessions (101 199955)}, 4413 {:firstname "Alfonso", :lastname "Mateos", :department "Inteligencia Artificial", :institution "Technical University of Madrid", :country "Spain", :sessions (199830)}, 4565 {:firstname "El-Houssaine", :lastname "Aghezzaf", :department "Industrial Management", :institution "Ghent University ", :country "Belgium", :sessions (199849)}, 4625 {:firstname "Gertjan", :lastname "de Lange", :department "SVP Business Analytics", :institution "AIMMS", :country "Netherlands", :sessions (199983)}, 4796 {:firstname "Stefan Wolfgang", :lastname "Pickl", :department "Department of Computer Science", :institution "UBw München COMTESSA", :country "Germany", :sessions (199886)}, 4889 {:firstname "Horst", :lastname "Tempelmeier", :department "Supply Chain  Management and Production", :institution "University of Cologne", :country "Germany", :sessions (25)}, 5078 {:firstname "Stefan", :lastname "Nickel", :department "Institute for Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (199884 199946 199936)}, 5319 {:firstname "Luís", :lastname "Gouveia", :department "DEIO - Departamento de Estatística e Investigação Operacional", :institution "Universidade de Lisboa - Faculdade de Ciências", :country "Portugal", :sessions (199896 5 199898)}, 5360 {:firstname "Mohammed Said", :lastname "Radjef", :department "Operational Research", :institution "University of Bejaia", :country "Algeria", :sessions (199916)}, 5390 {:firstname "Jacek", :lastname "Blazewicz", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (199944 199943)}, 5426 {:firstname "Martine", :lastname "Labbé", :department "computer Science", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (199886 199832)}, 5454 {:firstname "Wolfgang Anthony", :lastname "Eiden", :department "", :institution "", :country "Germany", :sessions (15)}, 5838 {:firstname "Dirk", :lastname "Briskorn", :department "", :institution "University of Wuppertal", :country "Germany", :sessions (71)}, 5855 {:firstname "Bernard", :lastname "Gendron", :department "DIRO/CIRRELT", :institution "Université de Montréal", :country "Canada", :sessions (199905)}, 5931 {:firstname "Stefan", :lastname "Voss", :department "Wirtschaftsinformatik/Information Systems", :institution "University of Hamburg", :country "Germany", :sessions (46 199970)}, 5932 {:firstname "Dennis", :lastname "Huisman", :department "Econometric Institute", :institution "Erasmus University", :country "Netherlands", :sessions (199980)}, 5934 {:firstname "Nils", :lastname "Boysen", :department "Lehrstuhl für ABWL/ Operations Management", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (71)}, 5965 {:firstname "Jürgen", :lastname "Zimmermann", :department "Operations Research", :institution "TU Clausthal", :country "Germany", :sessions (199946 199871)}, 6251 {:firstname "Frits", :lastname "Spieksma", :department "Mathematics and Computer Science", :institution "Eindhoven University of Technology", :country "Netherlands", :sessions (97 199896 199912)}, 6335 {:firstname "Hlynur", :lastname "Stefánsson", :department "School of Science and Engineering", :institution "Reykjavik University", :country "Iceland", :sessions (60)}, 6626 {:firstname "Thomas S.", :lastname "McCormick", :department "", :institution "Sauder School of Business, UBC", :country "Canada", :sessions (199917)}, 6751 {:firstname "Michael", :lastname "Manitz", :department "Technology and Operations Management, Chair of Production and Supply Chain Management", :institution "University of Duisburg/Essen", :country "Germany", :sessions (32)}, 6752 {:firstname "Sven F.", :lastname "Crone", :department "Department of Management Science", :institution "Lancaster University Management School", :country "United Kingdom", :sessions (199892 86 85)}, 6813 {:firstname "Fernando", :lastname "Ordonez", :department "Industrial and Systems Engineering", :institution "University of Southern California", :country "United States", :sessions (199886)}, 6882 {:firstname "Pawel", :lastname "Zielinski", :department "Department of Computer Science", :institution "Wroclaw University of Science and Technology", :country "Poland", :sessions (199880 199878)}, 6886 {:firstname "Adam", :lastname "Kasperski", :department "Wroclaw University of Technology", :institution "Department of Operations Research", :country "Poland", :sessions (199880 199878)}, 7364 {:firstname "Ingmar", :lastname "Steinzen", :department "", :institution "ORCONOMY GmbH", :country "Germany", :sessions (199982 199983)}, 7487 {:firstname "Stephen", :lastname "Boyd", :department "Electrical Engineering", :institution "Stanford University", :country "United States", :sessions (199969)}, 7569 {:firstname "Andreas", :lastname "Fink", :department "Chair of Information Systems", :institution "Helmut-Schmidt-University", :country "Germany", :sessions (199889)}, 7857 {:firstname "Roberto", :lastname "Montemanni", :department "Department of Sciences and Methods for Engineering", :institution "University of Modena and Reggio Emilia", :country "Italy", :sessions (199863)}, 8258 {:firstname "Carlos Ernani", :lastname "Fries", :department "Department of Production and Systems Engineering", :institution "Federal University of Santa Catarina", :country "Brazil", :sessions (24)}, 8504 {:firstname "Hans-Jürgen", :lastname "Sebastian", :department "Deutsche Post Endowed Chair of Optimization of Distribution Networks", :institution "RWTH Aachen University", :country "Germany", :sessions (199974)}, 8513 {:firstname "Johann", :lastname "Hurink", :department "Department of Applied Mathematics", :institution "University of Twente", :country "Netherlands", :sessions (68)}, 8638 {:firstname "Renata", :lastname "Sotirov", :department "Department of Econometrics and Operations Research", :institution "Tilburg University", :country "Netherlands", :sessions (81)}, 8713 {:firstname "Magnus", :lastname "Fröhling", :department "Faculty of Economics", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (61)}, 8883 {:firstname "Luis", :lastname "Paquete", :department "Department of Informatics Engineering", :institution "University of Coimbra", :country "Portugal", :sessions (199834)}, 9083 {:firstname "Brenda", :lastname "Dietrich", :department "Mathematical Sciences", :institution "IBM TJ Watson Research Center", :country "United States", :sessions (199966)}, 9255 {:firstname "Mohamed", :lastname "MAIZA", :department "Laboratoire de Mathématiques Appliquées", :institution "Ecole Militaire Polytechnique", :country "Algeria", :sessions (199916)}, 9272 {:firstname "Achim", :lastname "Koberstein", :department "Information and Operations Management", :institution "European University Viadrina Frankfurt (Oder)", :country "Germany", :sessions (199947)}, 9293 {:firstname "Masashi", :lastname "Miyagawa", :department "Regional Social Management", :institution "University of Yamanashi", :country "Japan", :sessions (199920)}, 9411 {:firstname "Rudolf", :lastname "Müller", :department "Department  of Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (33)}, 9512 {:firstname "Rüdiger", :lastname "Schultz", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (90 199968 199882 50)}, 9524 {:firstname "Julia", :lastname "Rieck", :department "Operations Research Group", :institution "University of Hildesheim", :country "Germany", :sessions (199946)}, 9542 {:firstname "Wim", :lastname "Klein Haneveld", :department "Department of Econometrics", :institution "University of Groningen, Faculty of Economics", :country "Netherlands", :sessions (90)}, 9583 {:firstname "Dries", :lastname "Goossens", :department "Business Informatics and Operations Management", :institution "Ghent University", :country "Belgium", :sessions (97 199912)}, 9690 {:firstname "Yudai", :lastname "Honma", :department "Institute of Industrial Science", :institution "The University of Tokyo", :country "Japan", :sessions (199940)}, 9694 {:firstname "Dmitrii", :lastname "Lozovanu", :department "Institute of Mathematics and Computer Science", :institution "Academy of Sciences of Moldova", :country "Moldova, Republic of", :sessions (199886)}, 9695 {:firstname "Michael", :lastname "Stiglmayr", :department "School of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (199918)}, 9874 {:firstname "Wilhelm", :lastname "Rödder", :department "Operations Research", :institution "University of Hagen", :country "Germany", :sessions (199833)}, 9886 {:firstname "Heike", :lastname "Schenk-Mathes", :department "Institut für Wirtschaftswissenschaft", :institution "Technische Universität Clausthal", :country "Germany", :sessions (65)}, 9973 {:firstname "Massimo", :lastname "Genoese", :department "Institute for Industrial Production", :institution "University of Karlsruhe", :country "Germany", :sessions (65)}, 10025 {:firstname "Steven", :lastname "Prestwich", :department "Computer Science", :institution "Insight Centre for Data Analytics", :country "Ireland", :sessions (199882)}, 10057 {:firstname "Brigitte", :lastname "Werners", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199927 199842 199931 199936)}, 10255 {:firstname "Raik", :lastname "Stolletz", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (199845 199865 77 101)}, 10297 {:firstname "Ovidiu", :lastname "Listes", :department "", :institution "AIMMS", :country "Netherlands", :sessions (81652)}, 10362 {:firstname "Birol", :lastname "Yüceoglu", :department "Information Technologies", :institution "Migros T.A.Ş.", :country "Turkey", :sessions (199903)}, 10538 {:firstname "Richard", :lastname "Hartl", :department "Business Admin", :institution "University of Vienna", :country "Austria", :sessions (26 199869 5 199834 75)}, 10542 {:firstname "Michael", :lastname "Bussieck", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (199884)}, 10871 {:firstname "Diethard", :lastname "Klatte", :department "IBW", :institution "Universität Zürich", :country "Switzerland", :sessions (199959)}, 10954 {:firstname "Erwin", :lastname "Pesch", :department "Faculty III", :institution "University of Siegen", :country "Germany", :sessions (199944 199913 199943)}, 11111 {:firstname "Ulrich", :lastname "Schimpel", :department "Business Optimization", :institution "IBM Research", :country "Switzerland", :sessions (199863)}, 11248 {:firstname "Sandip", :lastname "Pindoria", :department "", :institution "Maximal Software Ltd", :country "United Kingdom", :sessions (96)}, 11413 {:firstname "Maarten H.", :lastname "van der Vlerk", :department "Econometrics & OR", :institution "University of groningen", :country "Netherlands", :sessions (90)}, 11802 {:firstname "Jan", :lastname "van Dalen", :department "Dept. of Decision and Informatiion Sciences", :institution "RSM Erasmus University", :country "Netherlands", :sessions (10)}, 11838 {:firstname "Aharon", :lastname "Ben-Tal", :department "Industrial Engineering and Mangement", :institution "Technion-Israel Institute of Technology", :country "Israel", :sessions (199852 199968)}, 11953 {:firstname "Michal", :lastname "Cervinka", :department "Institute of Information Theory and Automation", :institution "Academy of Sciences of the Czech Republic", :country "Czech Republic", :sessions (7)}, 12005 {:firstname "Klaus", :lastname "Schmidt", :department "Lehrstuhl für Regelungstechnik", :institution "Universität Erlangen-Nürnberg", :country "Germany", :sessions (199869)}, 12046 {:firstname "Markus", :lastname "Leitner", :department "Department of Supply Chain Analytics", :institution "Vrije Universiteit Amsterdam", :country "Netherlands", :sessions (199896)}, 12140 {:firstname "Jörg", :lastname "Kalcsics", :department "School of Mathematics", :institution "University of Edinburgh", :country "United Kingdom", :sessions (199946)}, 12177 {:firstname "Arie", :lastname "Koster", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (42 68 199918 199911 199976)}, 12264 {:firstname "Erik", :lastname "Kropat", :department "Department of Computer Science", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (199958)}, 12412 {:firstname "Maria João", :lastname "Alves", :department "", :institution "Faculty of Economics of University of Coimbra / INESC - Coimbra", :country "Portugal", :sessions (199835)}, 12520 {:firstname "Francisco", :lastname "Guerra-Vázquez", :department "Actuaria y Matematicas", :institution "Fundación Universidad de las Americas Puebla", :country "Mexico", :sessions (199960)}, 12569 {:firstname "Lucas", :lastname "Létocart", :department "LIPN UMR CNRS 7030", :institution "Institut Galilée - Université Paris 13", :country "France", :sessions (199864)}, 12598 {:firstname "Sergey", :lastname "Polyakovskiy", :department "Information Process Engineering (IPE)", :institution "FZI  Forschungszentrum Informatik an der Universität Karlsruhe", :country "Germany", :sessions (199912)}, 12639 {:firstname "Lorenz T.", :lastname "Biegler", :department "", :institution "Carnegie Mellon University", :country "United States", :sessions (4)}, 12736 {:firstname "Elina", :lastname "Rönnberg", :department "Department of Mathematics / Optimization", :institution "Linköping University", :country "Sweden", :sessions (51)}, 12756 {:firstname "João Paulo", :lastname "Costa", :department "", :institution "Faculty of Economics, University of Coimbra / INESC-Coimbra", :country "Portugal", :sessions (199835)}, 12787 {:firstname "Fabián", :lastname "Flores-Bazán", :department "Departamento de Ingeniería Matemática", :institution "Universidad de Concepción", :country "Chile", :sessions (199837)}, 12938 {:firstname "Marko", :lastname "Jaksic", :department "Faculty of Economics", :institution "University of Ljubljana", :country "Slovenia", :sessions (199955)}, 12969 {:firstname "Diana", :lastname "Fanghaenel", :department "Fachbereich Elektrotechnik/Informatik", :institution "Universität Kassel", :country "Germany", :sessions (81)}, 13000 {:firstname "Mohsen", :lastname "Afsharian", :department "Department of Business Sciences", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (199833)}, 13046 {:firstname "Alexander", :lastname "Martin", :department "Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (199910 199972 199898 81)}, 13054 {:firstname "Marc", :lastname "Steinbach", :department "Inst. for Applied Mathematics", :institution "Leibniz University Hannover", :country "Germany", :sessions (45)}, 13058 {:firstname "Andreas", :lastname "Bley", :department "Mathematics", :institution "Uni Kassel", :country "Germany", :sessions (199909 199911)}, 13084 {:firstname "Christian", :lastname "Kanzow", :department "University of Wuerzburg", :institution "Insitute of Mathematics", :country "Germany", :sessions (7)}, 13262 {:firstname "Pierre", :lastname "von Mouche", :department "", :institution "Wageningen Universiteit", :country "Netherlands", :sessions (199836)}, 13330 {:firstname "ONCU", :lastname "HAZIR", :department "", :institution "Rennes School of Business", :country "France", :sessions (199869)}, 13500 {:firstname "Nuno", :lastname "Azevedo", :department "Statistics Department", :institution "Banco de Portugal", :country "Portugal", :sessions (199958)}, 13797 {:firstname "Andrea", :lastname "Raith", :department "Engineering Science", :institution "The University of Auckland", :country "New Zealand", :sessions (199833)}, 13837 {:firstname "Uwe T.", :lastname "Zimmermann", :department "Institute of Mathematical Optimization", :institution "TU Braunschweig", :country "Germany", :sessions (199894 199943)}, 13866 {:firstname "Florian", :lastname "Sahling", :department "Chair of Production Management", :institution "University of Kaiserslautern", :country "Germany", :sessions (199847)}, 14206 {:firstname "Firdevs", :lastname "Ulus", :department "Industrial Engineering", :institution "Bilkent University", :country "Turkey", :sessions (87)}, 14225 {:firstname "Lars", :lastname "Moench", :department "", :institution "FernUniversität in Hagen", :country "Germany", :sessions (101)}, 14274 {:firstname "Guvenc", :lastname "Sahin", :department "Faculty of Engineering and Natural Sciences, Industrial Engineering", :institution "Sabanci University", :country "Turkey", :sessions (199903)}, 14291 {:firstname "Burcu", :lastname "Adivar", :department "Department of Logistics Management", :institution "Izmir University of Economics", :country "Turkey", :sessions (199938)}, 14573 {:firstname "Ulrich", :lastname "Thonemann", :department "Supply Chain Management", :institution "Universtiy of Cologne", :country "Germany", :sessions (28 199971)}, 14628 {:firstname "Wolfgang", :lastname "Breuer", :department "", :institution "RWTH Aachen ", :country "Germany", :sessions (199963)}, 14704 {:firstname "Felix", :lastname "Hahne", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (199947)}, 14705 {:firstname "Curt", :lastname "Nowak", :department "Betriebswirtschaft und Wirtschaftsinformatik", :institution "Stiftung Universität Hildesheim", :country "Germany", :sessions (199947)}, 14713 {:firstname "Frauke", :lastname "Liers", :department "Department Mathematik", :institution "FAU Erlangen-Nuremberg", :country "Germany", :sessions (199898 81 69)}, 14715 {:firstname "Alf", :lastname "Kimms", :department "Mercator School of Management", :institution "University of Duisburg-Essen, Campus Duisburg", :country "Germany", :sessions (199888 199858 199949)}, 14728 {:firstname "Michael", :lastname "Juenger", :department "Institut fuer Informatik", :institution "Universitaet zu Koeln", :country "Germany", :sessions (69)}, 14736 {:firstname "Benjamin", :lastname "Hiller", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (45 106)}, 14742 {:firstname "Sigrid", :lastname "Knust", :department "Institute of Computer Science", :institution "University of Osnabrück", :country "Germany", :sessions (199873 199870)}, 14771 {:firstname "Thomas", :lastname "Schlechte", :department " ", :institution "LBW Optimization GmbH", :country "Germany", :sessions (199899)}, 14800 {:firstname "Stefan", :lastname "Bock", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (199876)}, 14803 {:firstname "Klaus ", :lastname "Ambrosi", :department "Institut für Betriebswirtschaft und Wirtschaftsinformatik", :institution "Universität Hildesheim", :country "Germany", :sessions (199947)}, 14817 {:firstname "Ralph", :lastname "Grothmann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (14 105 85)}, 14818 {:firstname "Hans Georg", :lastname "Zimmermann", :department "Corporate Technology CT RTC BAM", :institution "Siemens AG", :country "Germany", :sessions (199892 199983 85)}, 14844 {:firstname "Gaurav", :lastname "Singh", :department "Mathematics, Informatics & Statistics", :institution "Commonwealth Scientific and Industrial Research Organisation (CSIRO)", :country "Australia", :sessions (199944 199943)}, 14853 {:firstname "Franz", :lastname "Nelissen", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (89890)}, 14876 {:firstname "Dominik", :lastname "Möst", :department "Chair of Energy Economics", :institution "Technische Universität Dresden", :country "Germany", :sessions (55)}, 14890 {:firstname "Andreas", :lastname "Kleine", :department "Operations Research", :institution "FernUniversität in Hagen (University of Hagen)", :country "Germany", :sessions (199833)}, 14898 {:firstname "Lutz", :lastname "Westermann", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (199884)}, 14909 {:firstname "Karl", :lastname "Nachtigall", :department "Faculty of Transport and Traffic Sciences, Institut for Logistics and Aviation", :institution "Technical University of Dresden", :country "Germany", :sessions (5)}, 14923 {:firstname "Ralf", :lastname "Borndörfer", :department "Optimization", :institution "Zuse-Institute Berlin", :country "Germany", :sessions (199896 199899 199913)}, 14957 {:firstname "Marius", :lastname "Radulescu", :department "Mathematical Statistics", :institution "Institute of Mathematical Statistics and Applied Mathematics", :country "Romania", :sessions (199929)}, 14965 {:firstname "Anton", :lastname "Eremeev", :department "Discrete Optimization", :institution "Sobolev Institute of Mathematics SB RAS, Omsk Branch", :country "Russian Federation", :sessions (199874)}, 14969 {:firstname "Marco", :lastname "Lübbecke", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (199965 199909 199910 89 46 199876 95 199966)}, 14975 {:firstname "Nicole", :lastname "Megow", :department "Mathematik/Informatik", :institution "Universität Bremen", :country "Germany", :sessions (104 42 199880)}, 15115 {:firstname "Diogo", :lastname "Pinheiro", :department "Department of Mathematics", :institution "Brooklyn College of the City University of New York", :country "United States", :sessions (199958)}, 15178 {:firstname "Kerstin", :lastname "Schmidt", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (101)}, 15187 {:firstname "Matthias Gerhard", :lastname "Wichmann", :department "Institute of Automotive Management and Industrial Production", :institution "TU Brauschweig", :country "Germany", :sessions (199871)}, 15277 {:firstname "Herbert", :lastname "Kopfer", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (199942)}, 15349 {:firstname "Heinrich", :lastname "Rommelfanger", :department "Economics and Business Administration", :institution "J. W. Goethe University", :country "Germany", :sessions (15)}, 15364 {:firstname "Robert", :lastname "Fildes", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (199891)}, 15433 {:firstname "Karl-Heinz", :lastname "Küfer", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (199929)}, 15665 {:firstname "Mangesh", :lastname "Gharote", :department "SJM School of Management", :institution "Indian Institute of Technology, Bombay", :country "India", :sessions (199842)}, 16170 {:firstname "Hemant", :lastname "Bhargava", :department "Graduate School of Management", :institution "UC Davis", :country "United States", :sessions (33)}, 16305 {:firstname "Claudius", :lastname "Steinhardt", :department "Chair of Business Analytics & Management Science", :institution "Bundeswehr University Munich (UniBw)", :country "Germany", :sessions (199884 98)}, 16315 {:firstname "Armin", :lastname "Fügenschuh", :department "MINT", :institution "Brandenburg Technical University", :country "Germany", :sessions (199940)}, 16459 {:firstname "Eduardo", :lastname "Salazar", :department "Department of Industrial Engineering", :institution "University of Concepción", :country "Chile", :sessions (199852)}, 16621 {:firstname "Xi", :lastname "Chen", :department "Management Science", :institution "Lancaster University Management School", :country "United Kingdom", :sessions (199891)}, 16639 {:firstname "Sven", :lastname "Müller", :department "Transport Business Economics", :institution "Karlsruhe University of Applied Sciences", :country "Germany", :sessions (199929)}, 16865 {:firstname "Christian", :lastname "Artigues", :department "LAAS", :institution "CNRS", :country "France", :sessions (93)}, 16870 {:firstname "Katja", :lastname "Schimmelpfeng", :department "Lehrstuhl für Beschaffung und Produktion", :institution "Universität Hohenheim", :country "Germany", :sessions (77 199937)}, 16873 {:firstname "Ingmar", :lastname "Schüle", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (199929)}, 16880 {:firstname "Timo", :lastname "Berthold", :department "", :institution "Fair Isaac Germany GmbH", :country "Germany", :sessions (79)}, 16883 {:firstname "Guenter", :lastname "Fandel", :department "FernUniversitaet in Hagen, Fakultaet fuer Wirtschaftswissenschaft", :institution "Zentrum fuer Produktionsoekonomie und Entscheidungsmanagement", :country "Germany", :sessions (199886)}, 16887 {:firstname "Jan", :lastname "Trockel", :department "FernUniversität in Hagen", :institution "Center for Production Economics and Decision Support", :country "Germany", :sessions (199886)}, 16919 {:firstname "Jan Fabian", :lastname "Ehmke", :department "Management Science", :institution "Otto-von-Guericke University", :country "Germany", :sessions (54 199864)}, 16923 {:firstname "Guntram", :lastname "Scheithauer", :department "Mathematik", :institution "Technische Universität Dresden", :country "Germany", :sessions (199894)}, 16988 {:firstname "Frank", :lastname "Fischer", :department "Mathematics and Natural Sciences", :institution "University of Kassel", :country "Germany", :sessions (199911)}, 16992 {:firstname "Ibrahim", :lastname "Muter", :department "School of Management", :institution "University of Bath", :country "United Kingdom", :sessions (199865)}, 17039 {:firstname "Rainer", :lastname "Kleber", :department "Faculty of Economics and Management", :institution "Otto-von-Guericke University of Magdeburg", :country "Germany", :sessions (61)}, 17092 {:firstname "Christina", :lastname "Büsing", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (42 199880)}, 17115 {:firstname "Andrea", :lastname "Peter", :department "Department of Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (81)}, 17127 {:firstname "Marco", :lastname "Laumanns", :department "", :institution "Bestmile SA", :country "Switzerland", :sessions (199882)}, 17130 {:firstname "Matthias Gerhard", :lastname "Wichmann", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (64 62 99)}, 17336 {:firstname "Roberto", :lastname "Montemanni", :department "(IDSIA)", :institution "Istituto Dalle Molle di Studi sull'Intelligenza Artificiale", :country "Switzerland", :sessions (47)}, 17364 {:firstname "Karsten", :lastname "Kieckhäfer", :department "Chair of Business Administration, esp. Resource Management", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (60)}, 17387 {:firstname "Carolin", :lastname "Kellenbrink", :department "Institut für Produktionswirtschaft", :institution "Universität Hannover", :country "Germany", :sessions (199871)}, 17398 {:firstname "Oliver", :lastname "Bantel", :department "Supply Chain Management und Produktion", :institution "Universität Köln", :country "Germany", :sessions (25)}, 17428 {:firstname "Stefan", :lastname "Helber", :department "Inst. f. Produktionswirtschaft", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (199848 77)}, 17621 {:firstname "Josef", :lastname "Kallrath", :department "GMC/MS - B 9", :institution "BASF SE", :country "Germany", :sessions (199983)}, 18006 {:firstname "Winfried", :lastname "Steiner", :department "Marketing", :institution "Clausthal University of Technology, Institute of Management and Economics", :country "Germany", :sessions (86)}, 18480 {:firstname "Raimund", :lastname "Kovacevic", :department "DB04 J03", :institution "Institut für Stochastik und Wirtschaftsmathematik, ORCOS", :country "Austria", :sessions (199961)}, 18585 {:firstname "Julien", :lastname "Darlay", :department "", :institution "LocalSolver", :country "France", :sessions (79)}, 18726 {:firstname "Enrique", :lastname "Alba", :department "", :institution "University of Malaga", :country "Spain", :sessions (47)}, 18841 {:firstname "Peter", :lastname "Gritzmann", :department "Mathematics", :institution "TU München", :country "Germany", :sessions (82 199972)}, 19001 {:firstname "Fabien", :lastname "Tricoire", :department "Institute for Production and Logistics Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (199834)}, 19047 {:firstname "Matúš", :lastname "Mihalák", :department "Dept. of Data Science and Knowledge Engineering", :institution "Maastricht University", :country "Netherlands", :sessions (39 199885)}, 19076 {:firstname "Jens", :lastname "Poppenborg", :department "Institute of Applied Stochastics and Operations Research", :institution "Clausthal University of Technology", :country "Germany", :sessions (199870)}, 19080 {:firstname "Hans-Jörg", :lastname "von Mettenheim", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (83)}, 19100 {:firstname "Michael H.", :lastname "Breitner", :department "Leibniz Universität Hannover", :institution "Institut für Wirtschaftsinformatik", :country "Germany", :sessions (199930 199961 83 99 65 199933 199840)}, 19168 {:firstname "Andreas", :lastname "Löhne", :department "Institut für Mathematik", :institution "FSU Jena", :country "Germany", :sessions (87 199893)}, 19182 {:firstname "Marie", :lastname "Schmidt", :department "Rotterdam School of Management", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (54)}, 19188 {:firstname "Nadjib", :lastname "Brahimi", :department "Industrial Engineering and Management", :institution "University of Sharjah", :country "United Arab Emirates", :sessions (199849)}, 19271 {:firstname "Reinhard", :lastname "Bürgy", :department "Dept of Informatics", :institution "University of Fribourg", :country "Switzerland", :sessions (199876)}, 19297 {:firstname "Catherine", :lastname "Cleophas", :department "Service Analytics", :institution "CAU Kiel University", :country "Germany", :sessions (105 98 199864 199926 199967)}, 19320 {:firstname "Michael", :lastname "Schneider", :department "Deutsche Post Chair of Optimization of Distribution Networks", :institution "RWTH Aachen", :country "Germany", :sessions (6 5)}, 19331 {:firstname "J.M.", :lastname "van den Akker", :department "Information and Computing Sciences", :institution "Utrecht University", :country "Netherlands", :sessions (68)}, 19359 {:firstname "Hasan Huseyin", :lastname "TURAN", :department "", :institution "University of Yalova", :country "Turkey", :sessions (199837)}, 19441 {:firstname "Lars", :lastname "Schewe", :department "Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (45 199919)}, 19462 {:firstname "Sleman", :lastname "Saliba", :department "Power Generation", :institution "ABB AG", :country "Germany", :sessions (199932)}, 19477 {:firstname "Sven", :lastname "Krumke", :department "Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (30)}, 19541 {:firstname "Andreas", :lastname "Marschner", :department "", :institution "Deutsche Post AG", :country "Germany", :sessions (199974)}, 19607 {:firstname "Heinz", :lastname "Gröflin", :department "Dept of Informatics", :institution "University of Fribourg", :country "Switzerland", :sessions (199876)}, 19625 {:firstname "Matteo", :lastname "Salani", :department "", :institution "IDSIA - USI/SUPSI", :country "Switzerland", :sessions (50)}, 19709 {:firstname "Alberto", :lastname "Ceselli", :department "Dipartimento di Informatica", :institution "Università degli Studi di Milano", :country "Italy", :sessions (199909 199864)}, 19731 {:firstname "Maria", :lastname "Mavri", :department "Business Administration", :institution "University of the Aegean", :country "Greece", :sessions (199851)}, 19894 {:firstname "Michael", :lastname "Becker-Peth", :department "Technology and Operations Management", :institution "Rotterdam School of Management, Erasmus University", :country "Netherlands", :sessions (199862)}, 19902 {:firstname "Taieb", :lastname "Mellouli", :department "Business Information Systems and Operations Research", :institution "Martin-Luther-University Halle-Wittenberg", :country "Germany", :sessions (199830)}, 19907 {:firstname "Keiji", :lastname "Tatsumi", :department "Division of Electrical, Electronic and Information Engineering", :institution "Osaka University", :country "Japan", :sessions (199867)}, 19977 {:firstname "Vlad", :lastname "Kucher", :department "", :institution "Frankfurt Institute for Advanced Studies, Goethe University Frankfurt am Main", :country "Germany", :sessions (86813)}, 20363 {:firstname "Jörg", :lastname "Homberger", :department "", :institution "", :country "Germany", :sessions (199889)}, 20485 {:firstname "Ayse", :lastname "Özmen", :department "Mathematics and Statistics", :institution "University of Calgary", :country "Canada", :sessions (199958)}, 20539 {:firstname "Sophie", :lastname "Parragh", :department "Institute of Production and Logistics Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (199834)}, 20607 {:firstname "Vladimir", :lastname "Shikhman", :department "", :institution "TU Chemnitz", :country "Germany", :sessions (199960)}, 20665 {:firstname "Sorin-Mihai", :lastname "Grad", :department "Faculty of Mathematics", :institution "University of Vienna", :country "Austria", :sessions (199958)}, 20786 {:firstname "Rabah", :lastname "Kassa", :department "LMA Laboratory", :institution "Universite Bejaia  algerie", :country "Algeria", :sessions (199875)}, 20793 {:firstname "Michael", :lastname "Herty", :department "Fachbereich Mathematik", :institution "RWTH Aachen", :country "Germany", :sessions (199958 199969 75)}, 20833 {:firstname "Metin", :lastname "Dagdeviren", :department "Department of Industrial Engineering", :institution "Engineering Faculty", :country "Turkey", :sessions (199841)}, 20840 {:firstname "Erdem", :lastname "Aksakal", :department "Industrial Engineering", :institution "Ataturk University", :country "Turkey", :sessions (199841)}, 20908 {:firstname "Oleg", :lastname "Burdakov", :department "Department of Mathematics", :institution "Linkoping University", :country "Sweden", :sessions (7)}, 21108 {:firstname "Reinhard", :lastname "Madlener", :department "School of Business and Economics / E.ON Energy Research Center", :institution "RWTH Aachen University", :country "Germany", :sessions (199828 199827 199930 199903 199920 199928)}, 21140 {:firstname "Stephan", :lastname "Buetikofer", :department "Institute of Data Analysis and Process Design", :institution "Zurich University of Applied Sciences", :country "Switzerland", :sessions (199947)}, 21205 {:firstname "Markus", :lastname "Kaiser", :department "Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (199918)}, 21211 {:firstname "Markus", :lastname "Reuther", :department "Optimization", :institution "Zuse-Institut Berlin", :country "Germany", :sessions (199899)}, 21574 {:firstname "Susanne", :lastname "Heipcke", :department "Xpress Optimization", :institution "FICO", :country "France", :sessions (199883)}, 21665 {:firstname "Trivikram", :lastname "Dokka", :department "Management Science Department", :institution "Lancaster University", :country "United Kingdom", :sessions (199896)}, 22042 {:firstname "Ivana", :lastname "Ljubic", :department "IDS", :institution "ESSEC Business School of Paris", :country "France", :sessions (199896)}, 22160 {:firstname "Jakob", :lastname "Puchinger", :department "LGI", :institution "CentraleSupélec, IRT-SystemX", :country "France", :sessions (5)}, 22180 {:firstname "Daniel", :lastname "Roesch", :department "", :institution "Universität Regensburg", :country "Germany", :sessions (199961)}, 22515 {:firstname "Khaled", :lastname "Sellami", :department "LMA Laboratory", :institution "Bejaia University", :country "Algeria", :sessions (199875)}, 22533 {:firstname "Lynda", :lastname "Sellami", :department "Sciences de Gestion", :institution "Université de Bejaia", :country "Algeria", :sessions (199831)}, 22571 {:firstname "chaabane", :lastname "Djamal", :department "Operations Research", :institution "usthb - Algeria -", :country "Algeria", :sessions (199834 199835)}, 22655 {:firstname "Thibaut", :lastname "Vidal", :department "Computer Science", :institution "PUC-Rio - Pontifical Catholic University of Rio de Janeiro", :country "Brazil", :sessions (5)}, 22691 {:firstname "Alexander", :lastname "Hübner", :department "Supply and Value Chain Management", :institution "Technical University Munich", :country "Germany", :sessions (199859)}, 22741 {:firstname "Nadi Serhan", :lastname "Aydin", :department "Institute of Applied Mathematics, Financial Mathematics", :institution "Middle East Technical University", :country "Turkey", :sessions (199958)}, 22803 {:firstname "Frédéric", :lastname "Gardi", :department "", :institution "LocalSolver", :country "France", :sessions (79)}, 22814 {:firstname "Martin", :lastname "Skutella", :department "Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (199917)}, 22910 {:firstname "Thierry", :lastname "Benoist", :department "LocalSolver", :institution "Innovation 24", :country "France", :sessions (79)}, 22911 {:firstname "Bertrand", :lastname "Estellon", :department "", :institution "LIF CNRS UMR 6166 - Faculté des Sciences de Luminy - Université Aix-Marseille II", :country "France", :sessions (79)}, 22920 {:firstname "Valentina", :lastname "Cacchiani", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (69)}, 22954 {:firstname "Wolf", :lastname "Fichtner", :department "Chair of Energy Economics", :institution "KIT", :country "Germany", :sessions (199930 199932 55 65)}, 22994 {:firstname "Jochen", :lastname "Gönsch", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (52 105 98 199862 101)}, 22996 {:firstname "Pavel", :lastname "Bazovkin", :department "Department of Economic and Social Statistics", :institution "University of Cologne", :country "Germany", :sessions (199881)}, 23024 {:firstname "Sascha", :lastname "Kurz", :department "Mathematics, Physics and Computer Science", :institution "University of Bayreuth", :country "Germany", :sessions (199887)}, 23189 {:firstname "Franz", :lastname "Rendl", :department "Mathematics", :institution "Alpen-Adria-Universität Klagenfurt", :country "Austria", :sessions (81)}, 23254 {:firstname "Peter M.", :lastname "Kort", :department "", :institution "University of Tilburg", :country "Netherlands", :sessions (75)}, 23282 {:firstname "Michael", :lastname "Schilde", :department "Department of Business Administration", :institution "University of Vienna", :country "Austria", :sessions (199848)}, 23312 {:firstname "Claus", :lastname "Gwiggner", :department "Operations Research", :institution "University of Hamburg", :country "Germany", :sessions (105)}, 23372 {:firstname "Dieter", :lastname "Grass", :department "", :institution "Vienna University of Technology", :country "Austria", :sessions (75)}, 23446 {:firstname "Daniel", :lastname "Junglas", :department "CPLEX Development", :institution "IBM Deutschland", :country "Germany", :sessions (199883)}, 23451 {:firstname "Gerd J.", :lastname "Hahn", :department "", :institution "German Graduate School of Management and Law", :country "Germany", :sessions (32)}, 23505 {:firstname "Silke", :lastname "Jütte", :department "Department of Supply Chain Management and Management Science", :institution "University of Cologne", :country "Germany", :sessions (28)}, 23824 {:firstname "Konstantinos", :lastname "Parsopoulos", :department "Department of Computer Science & Engineering", :institution "University of Ioannina", :country "Greece", :sessions (47)}, 23956 {:firstname "Martin", :lastname "Schmidt", :department "Department of Mathematics", :institution "Trier University", :country "Germany", :sessions (45)}, 23980 {:firstname "Gerrit K.", :lastname "Janssens", :department "Logistics", :institution "Hasselt University", :country "Belgium", :sessions (199946)}, 24063 {:firstname "Tilak Raj", :lastname "Singh", :department "MFTBC, IT-Big Data and Analytics", :institution "Daimler Trucks Asia- Japan", :country "Japan", :sessions (199854)}, 24074 {:firstname "Jens", :lastname "Baudach", :department "Institute of Transport Logistics", :institution "TU Dortmund University", :country "Germany", :sessions (50)}, 24135 {:firstname "Marcel", :lastname "van Kooten Niekerk", :department "", :institution "Qbuzz", :country "Netherlands", :sessions (68)}, 24270 {:firstname "Alexander", :lastname "Grigoriev", :department "Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (199875)}, 24291 {:firstname "Enrico", :lastname "Gorgone", :department "Département d'Informatique", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (199905)}, 24343 {:firstname "Claudia", :lastname "Gotzes", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (45 106)}, 24366 {:firstname "Christoph", :lastname "Hempsch", :department "", :institution "Deutsche Post DHL", :country "Germany", :sessions (199980)}, 24559 {:firstname "Bernhard", :lastname "Willert", :department "Institute of Applied Mathematics", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (45)}, 24607 {:firstname "John N.", :lastname "Hooker", :department "Tepper School of Business", :institution "Carnegie Mellon University", :country "United States", :sessions (89)}, 24622 {:firstname "Jutta", :lastname "Geldermann", :department "Chair of Business Administration and Production Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (63)}, 24773 {:firstname "Christoph", :lastname "Weber", :department "", :institution "University Duisburg-Essen", :country "Germany", :sessions (199932 55 199928)}, 24846 {:firstname "Nihat Engin", :lastname "Toklu", :department "", :institution "Istituto Dalle Molle di Studi sull'Intelligenza artificiale (IDSIA)", :country "Switzerland", :sessions (199863)}, 24902 {:firstname "Daniele", :lastname "Vigo", :department "DEI", :institution "University of Bologna", :country "Italy", :sessions (199947)}, 24917 {:firstname "Maria", :lastname "Battarra", :department "School of Management", :institution "University of Bath", :country "United Kingdom", :sessions (50)}, 24964 {:firstname "Jean-Sébastien", :lastname "Tancrez", :department "Louvain School of Management", :institution "Université catholique de Louvain", :country "Belgium", :sessions (37)}, 25052 {:firstname "Pierre", :lastname "Semal", :department "Louvain School of Management", :institution "Université caholique de Louvain", :country "Belgium", :sessions (37)}, 25059 {:firstname "Jean-Charles", :lastname "Lange", :department "Information & Production", :institution "UCL", :country "Belgium", :sessions (37)}, 25562 {:firstname "Nils-Hassan", :lastname "Quttineh", :department "", :institution "Department of Mathematics", :country "Sweden", :sessions (199872)}, 25563 {:firstname "Christian", :lastname "Doppstadt", :department "Logistics and Supply Chain Management", :institution "Goethe University Frankfurt", :country "Germany", :sessions (199947)}, 25632 {:firstname "Simme Douwe", :lastname "Flapper", :department "", :institution "Technische Universiteit Eindhoven", :country "Netherlands", :sessions (199847)}, 25633 {:firstname "Albert", :lastname "Moser", :department "", :institution "Institute of Power Systems and Power Economics", :country "Germany", :sessions (94)}, 25668 {:firstname "Michael", :lastname "Sternbeck", :department "Supply Chain Management and Operations", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (199859)}, 25671 {:firstname "Yurii", :lastname "Nesterov", :department "CORE", :institution "Université catholique de Louvain (UCL)", :country "Belgium", :sessions (199960)}, 25677 {:firstname "Peter", :lastname "Recht", :department "OR und Wirtschaftsinformatik", :institution "TU Dortmund", :country "Germany", :sessions (199914)}, 25688 {:firstname "Dogan", :lastname "Keles", :department "", :institution "Institute for Industrial Production (IIP), Karlsruhe Institue for Technology (KIT)", :country "Germany", :sessions (55 65)}, 25804 {:firstname "Rüdiger", :lastname "Franke", :department "", :institution "ABB AG", :country "Germany", :sessions (199932)}, 26007 {:firstname "Taras", :lastname "Bodnar", :department "Department of Statistics", :institution "European University Viadrina", :country "Germany", :sessions (199890)}, 26116 {:firstname "Karl", :lastname "Mosler", :department "Department of Economic and Social Statistics", :institution "University of Cologne", :country "Germany", :sessions (199881)}, 26121 {:firstname "Marco", :lastname "Schulze", :department "Operations Research Group", :institution "Clausthal University of Technology", :country "Germany", :sessions (199871)}, 26152 {:firstname "Gert", :lastname "Wanka", :department "Faculty of Mathematics", :institution "Chemnitz University of Technology", :country "Germany", :sessions (199958)}, 26168 {:firstname "Huseyin", :lastname "Basligil", :department "The Department of Industrial Engineering", :institution "Yildiz Technical University", :country "Turkey", :sessions (199860)}, 26181 {:firstname "Kei", :lastname "Takahashi", :department "Center for Mathematics and Data Science", :institution "Gunma University", :country "Japan", :sessions (199891 199836)}, 26182 {:firstname "Peter", :lastname "Grundke", :department "", :institution "University of Osnabrueck", :country "Germany", :sessions (199963)}, 26187 {:firstname "A. Sevtap", :lastname "Selcuk Kestel", :department "Institute of Applied Mathematics, Actuarial Sciences", :institution "Middle East Technical University", :country "Turkey", :sessions (199958)}, 26200 {:firstname "Max", :lastname "Krueger", :department "Fakultät Wirtschaftsingenieurwesen", :institution "Hochschule Furtwangen", :country "Germany", :sessions (199867)}, 26217 {:firstname "Sigifredo", :lastname "Laengle", :department "Department of Management Control", :institution "University of Chile", :country "Chile", :sessions (199837)}, 26292 {:firstname "Wolfgang A.", :lastname "Welz", :department "Mathematics", :institution "Technische Universität Berlin", :country "Germany", :sessions (199914)}, 26387 {:firstname "Thomas", :lastname "Rieger", :department "Institute for Mathematical Optimization ", :institution "Technical University Braunschweig", :country "Germany", :sessions (199894)}, 26404 {:firstname "Takahiro", :lastname "Ohno", :department "Dept. of Ind. & Manage. Systems Eng.", :institution "Waseda University", :country "Japan", :sessions (199836)}, 26409 {:firstname "Mario", :lastname "Ruthmair", :department "Department of Statistics and Operations Research", :institution "University of Vienna", :country "Austria", :sessions (5)}, 26435 {:firstname "MEBEREK", :lastname "FATMA", :department "MATHEMATIQUE", :institution "USTHB", :country "Algeria", :sessions (199835)}, 26471 {:firstname "Anja", :lastname "Fischer", :department "", :institution "TU Dortmund", :country "Germany", :sessions (199918 199949)}, 26491 {:firstname "Thomas", :lastname "Ponsignon", :department "Corporate Supply Chain", :institution "Infineon Technologies AG", :country "Germany", :sessions (44)}, 26495 {:firstname "Christian", :lastname "Schiller", :department "Corporate Supply Chain", :institution "Infineon Technologies AG", :country "Germany", :sessions (44)}, 26508 {:firstname "Jannik", :lastname "Matuschke", :department "TUM School of Management, Lehrstuhl für Operations Research", :institution "Technische Universität München", :country "Germany", :sessions (92)}, 26516 {:firstname "Christian", :lastname "Tesch", :department "", :institution "Institute of Transport Logistics - TU Dortmund University", :country "Germany", :sessions (27 50)}, 26518 {:firstname "Tobias", :lastname "Harks", :department "Institut für Mathematik", :institution "Universität Augsburg", :country "Germany", :sessions (8 199978 92)}, 26549 {:firstname "Luciano", :lastname "Porretta", :department "GOM", :institution "Universitè Libre de Brusselles", :country "Belgium", :sessions (199919)}, 26550 {:firstname "Hans", :lastname "Ehm", :department "Supply Chain", :institution "Infineon", :country "Germany", :sessions (44)}, 26613 {:firstname "Ralf", :lastname "Gössinger", :department "Business Administration, Production and Logistics", :institution "University of Dortmund", :country "Germany", :sessions (199849)}, 26622 {:firstname "Hans Georg", :lastname "Seedig", :department "", :institution "TU München", :country "Germany", :sessions (30)}, 26629 {:firstname "Elisabeth", :lastname "Lübbecke", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (199873)}, 26657 {:firstname "Uwe", :lastname "Clausen", :department "Director", :institution "Fraunhofer-Institute for Materialflow and Logistics (IML)", :country "Germany", :sessions (26 25 199881 27 50)}, 26950 {:firstname "Max", :lastname "Klimm", :department "Wirtschaftswissenschaftliche Fakultät", :institution "Humboldt-Universität zu Berlin", :country "Germany", :sessions (42 199873 8 92 199887)}, 27111 {:firstname "Ann", :lastname "Campbell", :department "Management Sciences", :institution "The University of Iowa", :country "United States", :sessions (54)}, 27231 {:firstname "Patricio", :lastname "Lamas", :department "Industrial Engineering", :institution "Universidad Andres Bello", :country "Chile", :sessions (102)}, 27254 {:firstname "Nico", :lastname "Vandaele", :department "Operations Management Dept.", :institution "Katholieke Universiteit Leuven", :country "Belgium", :sessions (32 37)}, 27395 {:firstname "Catherine", :lastname "Decouttere", :department "", :institution "Katholieke Universiteit Leuven", :country "Belgium", :sessions (32 37)}, 27643 {:firstname "Lars", :lastname "Beckmann", :department "", :institution "University of Paderborn", :country "Germany", :sessions (199905)}, 27800 {:firstname "Christian", :lastname "Gahm", :department "Chair of Production & Supply Chain Management", :institution "Augsburg University", :country "Germany", :sessions (63 89890)}, 28033 {:firstname "Daniel", :lastname "Schmidt", :department "Institut für Informatik", :institution "Universität zu Köln", :country "Germany", :sessions (69)}, 28300 {:firstname "Narayan", :lastname "Rangaraj", :department "Industrial Engineering and Operations Research", :institution "Indian Institute of Technology Bombay", :country "India", :sessions (199854)}, 28733 {:firstname "Lars-Peter", :lastname "Lauven", :department "", :institution "Chair of Energy Management and Power System Operation, University of Kassel", :country "Germany", :sessions (63)}, 28739 {:firstname "Michael", :lastname "Krause", :department "", :institution "Clausthal University of Technology", :country "Germany", :sessions (199882)}, 29034 {:firstname "Markus", :lastname "Bohlin", :department "", :institution "SICS Swedish ICT", :country "Sweden", :sessions (199852)}, 29040 {:firstname "Friederike", :lastname "Paetz", :department "", :institution "Marketing, Clausthal University of Technology, Institute of Management and Economics", :country "Germany", :sessions (86)}, 29046 {:firstname "Alexander", :lastname "Lieder", :department "Chair of production management", :institution "University of Mannheim", :country "Germany", :sessions (77)}, 29132 {:firstname "Maria", :lastname "Pilecka", :department "", :institution "TU Bergakademie Freiberg", :country "Germany", :sessions (199893)}, 29160 {:firstname "Lubos", :lastname "Buzna", :department "Department of Mathematical Methods and Operations Reserach", :institution "University of Zilina", :country "Slovakia", :sessions (199900)}, 29178 {:firstname "Martin", :lastname "Bergner", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (199909)}, 29197 {:firstname "Svenja", :lastname "Lagershausen", :department "Department of Supply Chain Management and Production", :institution "University of Cologne", :country "Germany", :sessions (199845 77)}, 29203 {:firstname "Tjark", :lastname "Vredeveld", :department "Dept of Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (93)}, 29226 {:firstname "Guido", :lastname "Schryen", :department "", :institution "Universität Regensburg", :country "Germany", :sessions (199874)}, 29239 {:firstname "You-Jin", :lastname "Park", :department "School of Business Administration", :institution "College of Business and Economics, Chung-Ang University", :country "Korea, Republic of", :sessions (199851)}, 29246 {:firstname "Florian", :lastname "Dahms", :department "Operations Research", :institution "RWTH Aachen", :country "Germany", :sessions (89)}, 29257 {:firstname "Christian", :lastname "Puchert", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (46)}, 29260 {:firstname "Yoshitsugu", :lastname "Yamamoto", :department "Graduate School of Systems and Information Engineering", :institution "University of Tsukuba", :country "Japan", :sessions (199910 199867)}, 29261 {:firstname "Jakob", :lastname "Schelbert", :department "Department of Mathematics", :institution "FAU Erlangen-Nürnberg, Discrete Optimization", :country "Germany", :sessions (45)}, 29263 {:firstname "Arne", :lastname "Mensendiek", :department "Business Administration and Economics", :institution "Bielefeld University", :country "Germany", :sessions (199874)}, 29288 {:firstname "Kai-Simon", :lastname "Goetzmann", :department "", :institution "PSI Transcom GmbH", :country "Germany", :sessions (199941)}, 29289 {:firstname "Ruben", :lastname "Hoeksma", :department "", :institution "Universität Bremen", :country "Germany", :sessions (93)}, 29330 {:firstname "Ebru", :lastname "Angun", :department "Industrial Engineering", :institution "Galatasaray University", :country "Turkey", :sessions (199877)}, 29344 {:firstname "Sarah", :lastname "Kirchner", :department "Operations Research", :institution "RWTH Aachen", :country "Germany", :sessions (199876 199880)}, 29388 {:firstname "Torsten", :lastname "Fahle", :department "Airport Systems Division", :institution "Inform GmbH", :country "Germany", :sessions (28)}, 29390 {:firstname "Jaroslav", :lastname "Janacek", :department "Mathematical Methods and Operations Research", :institution "University of Zilina", :country "Slovakia", :sessions (199898 199900)}, 29393 {:firstname "Marek", :lastname "Kvet", :department "", :institution "University of Zilina", :country "Slovakia", :sessions (199898)}, 29408 {:firstname "Thomas", :lastname "Breuer", :department "PPE Research Centre", :institution "FH Vorarlberg", :country "Austria", :sessions (199961)}, 29458 {:firstname "Christian", :lastname "Otto", :department "", :institution "DB Schenker Rail Deutschland AG", :country "Germany", :sessions (199943)}, 29468 {:firstname "Torsten", :lastname "Gellert", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (199957)}, 29524 {:firstname "Emilio", :lastname "Zamorano de Acha", :department "Chair of Production Management", :institution "Univerisity of Mannheim", :country "Germany", :sessions (199865)}, 29534 {:firstname "Stefan", :lastname "Woerner", :department "", :institution "IBM Research", :country "Switzerland", :sessions (199863)}, 29539 {:firstname "Daniel", :lastname "Gartner", :department "TUM School of Management", :institution "Technische Universitaet München", :country "Germany", :sessions (199865)}, 29548 {:firstname "Michal", :lastname "Kohani", :department "Mathematical Methods and Operations Research", :institution "University of Zilina", :country "Slovakia", :sessions (199900)}, 29561 {:firstname "Ruth", :lastname "Hübner", :department "Institut für Numerische und Angewandte Mathematik", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (75)}, 29563 {:firstname "Dominik", :lastname "Kress", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (199913 89890)}, 29566 {:firstname "Claudia", :lastname "Schlebusch", :department "Chair of Logistics Management, Gutenberg School of Management and Economics", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (199949)}, 29571 {:firstname "Timo", :lastname "Gschwind", :department "", :institution "Johannes Gutenberg University Mainz", :country "Germany", :sessions (199919)}, 29603 {:firstname "Birgit", :lastname "Rudloff", :department "", :institution "Princeton University", :country "United States", :sessions (87)}, 29640 {:firstname "Paul", :lastname "Göpfert", :department "WINFOR (Business Computing and Operations Research) Schumpeter School of Business and Economics", :institution "University of Wuppertal", :country "Germany", :sessions (199876)}, 29675 {:firstname "Simone", :lastname "Göttlich", :department "School of Business Informatics and Mathematics", :institution "University of Mannheim", :country "Germany", :sessions (4 199958 75)}, 29680 {:firstname "Andreas", :lastname "Karrenbauer", :department "", :institution "Max Planck Institute for Informatics", :country "Germany", :sessions (199917)}, 29686 {:firstname "Yumi", :lastname "Asahi", :department "Department of engineering, Management of business", :institution "Shizuoka University", :country "Japan", :sessions (24)}, 29689 {:firstname "Andrej", :lastname "Bregar", :department "", :institution "Informatika", :country "Slovenia", :sessions (199841)}, 29699 {:firstname "Murat", :lastname "Ayanoglu", :department "", :institution "Faculty of Economics and Administrative Sciences", :country "Turkey", :sessions (199860)}, 29723 {:firstname "Torbjörn", :lastname "Larsson", :department "Department of Mathematics", :institution "Linköping University", :country "Sweden", :sessions (199872 51)}, 29733 {:firstname "Marc", :lastname "Goerigk", :department "Network and Data Science Management", :institution "University of Siegen", :country "Germany", :sessions (42 199878 54)}, 29738 {:firstname "Matthias", :lastname "Müller-Hannemann", :department "Computer Science", :institution "Martin-Luther Universität Halle-Wittenberg", :country "Germany", :sessions (54)}, 29814 {:firstname "Steffen", :lastname "Kasper", :department "Institute of Production Management", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (199848 77)}, 29815 {:firstname "Simon", :lastname "Emde", :department "Management Science / Operations Research", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (71)}, 30218 {:firstname "Tim A.", :lastname "Rickenberg", :department "Institut für Wirtschaftsinformatik", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (199840)}, 30379 {:firstname "Alessia", :lastname "Violin", :department "Computer Science", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (199832)}, 30400 {:firstname "Marcin", :lastname "Anholcer", :department "Department of Operations Research", :institution "Poznan University of Economics", :country "Poland", :sessions (199840)}, 30476 {:firstname "John", :lastname "Poppelaars", :department "", :institution "NGB (Dutch OR Society)", :country "Netherlands", :sessions (199983)}, 30768 {:firstname "Jonas", :lastname "Schweiger", :department "", :institution "Atesio GmbH", :country "Germany", :sessions (45)}, 30840 {:firstname "Elisabeth", :lastname "Köbis", :department "Department of Mathematics", :institution "University of Erlangen-Nuremberg", :country "Germany", :sessions (23 43)}, 30896 {:firstname "Babak", :lastname "Farhang Moghaddam", :department "", :institution "Institute for Management and Planning Studies", :country "Iran, Islamic Republic of", :sessions (199858)}, 30955 {:firstname "Philipp", :lastname "Hungerländer", :department "Mathematics", :institution "University of Klagenfurt", :country "Austria", :sessions (199918)}, 30964 {:firstname "Mike", :lastname "Steglich", :department "", :institution "Technical University of Applied Sciences Wildau", :country "Germany", :sessions (81652)}, 30997 {:firstname "Jacqueline", :lastname "Bloemhof", :department "Operations Research and Logistics", :institution "Wageningen University", :country "Netherlands", :sessions (61)}, 31192 {:firstname "Frank", :lastname "Herrmann", :department "Innovation and Competence Centre for Production Logistics and Factory Planning", :institution "OTH Regensburg", :country "Germany", :sessions (32)}, 31230 {:firstname "Patrick", :lastname "Jochem", :department "Chair of Energy Economics (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (199930 199932)}, 31297 {:firstname "Alexander", :lastname "Schnell", :department "Business Administration", :institution "University of Vienna", :country "Austria", :sessions (199869)}, 31304 {:firstname "Constanta Zoie", :lastname "Radulescu", :department "Modelling and Simulation", :institution "National Institute for Research and Development in Informatics", :country "Romania", :sessions (199929)}, 31388 {:firstname "Jonas", :lastname "Ide", :department "Fakultät für Mathematik", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (42 87)}, 31389 {:firstname "Yves", :lastname "Colombani", :department "Xpress Optimization", :institution "FICO", :country "France", :sessions (199883)}, 31551 {:firstname "Mateusz", :lastname "Cichenski", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (199963 199943)}, 31595 {:firstname "Sais", :lastname "Lakhdar", :department "Université d’Artois CNRS-UMR8188", :institution "Centre de Recheche en Informatique de Lens", :country "France", :sessions (199916)}, 31710 {:firstname "Michaël", :lastname "Gabay", :department "", :institution "Artelys", :country "France", :sessions (199875)}, 31711 {:firstname "Romain", :lastname "Megel", :department "", :institution "e-lab, Bouygues SA", :country "France", :sessions (79)}, 31737 {:firstname "Ana", :lastname "Lopes", :department "Center for Efficiency, Sustainability and Productivity Analysis, NESP", :institution "Federal University of Minas Gerais - UFMG, Brazil", :country "Brazil", :sessions (24)}, 31866 {:firstname "Tomas", :lastname "Bajbar", :department "Institute of Operations Research", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (199960)}, 31871 {:firstname "Amir Afshin", :lastname "Fatahi", :department "Industrial Engineering", :institution "Islamic Azad University, Parand Branch", :country "Iran, Islamic Republic of", :sessions (199858)}, 31940 {:firstname "Tobias", :lastname "Wollenberg", :department "Mathematics", :institution "University of Duisburg-Essen", :country "Germany", :sessions (90)}, 31952 {:firstname "Kai", :lastname "Plociennik", :department "Optimization", :institution "Fraunhofer ITWM", :country "Germany", :sessions (199929)}, 31977 {:firstname "Frederic", :lastname "Weymann", :department "Institute of Transport Science", :institution "RWTH Aachen University", :country "Germany", :sessions (199944)}, 32076 {:firstname "Sebastian", :lastname "Koch", :department "Chair of Analytics & Optimization", :institution "University of Augsburg", :country "Germany", :sessions (98)}, 32222 {:firstname "Afzal", :lastname "Siddiqui", :department "Computer and Systems Sciences", :institution "Stockholm University", :country "Sweden", :sessions (199928)}, 32246 {:firstname "Patrick", :lastname "Breun", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (61)}, 32283 {:firstname "Laura Elisabeth", :lastname "Hombach", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (199934)}, 32309 {:firstname "Dirk", :lastname "Degel", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199936)}, 32377 {:firstname "Jörn", :lastname "Schönberger", :department "Faculty of Transportation and Traffic Sciences", :institution "Technical University of Dresden", :country "Germany", :sessions (1 47)}, 32497 {:firstname "Dimitri", :lastname "Papadimitriou", :department "Mathematics and Computer Science", :institution "University of Antwerp", :country "Belgium", :sessions (199909)}, 32575 {:firstname "Zsolt", :lastname "Csizmadia", :department "Xpress", :institution "FICO", :country "United Kingdom", :sessions (199883)}, 32654 {:firstname "Zoia", :lastname "Runovska", :department "", :institution "Hochschule Hamm-Lippstadt", :country "Germany", :sessions (86813)}, 32758 {:firstname "Matthias", :lastname "Miltenberger", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (79)}, 32839 {:firstname "Andrea", :lastname "Walther", :department "Institut für Mathematik", :institution "Universität Paderborn", :country "Germany", :sessions (4)}, 33154 {:firstname "Thibaut", :lastname "Barthelemy", :department "Business Administration", :institution "University of Vienna", :country "Austria", :sessions (199834)}, 33211 {:firstname "Stephan", :lastname "Westphal", :department "Institute for Applied Stochastics and Operations Research", :institution "Clausthal University of Technology", :country "Germany", :sessions (30 199897)}, 33284 {:firstname "Henning", :lastname "Preis", :department "Faculty of Traffic and Transportation Sciences, Institute for Logistics and Aviation", :institution "Technical University of Dresden", :country "Germany", :sessions (5)}, 33307 {:firstname "Alexander", :lastname "Richter", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (69)}, 33323 {:firstname "Karl", :lastname "Nachtigall", :department "Faculy of Transportation and Traffic Science", :institution "TU Dresden", :country "Germany", :sessions (199939)}, 33333 {:firstname "Frauke", :lastname "Böckmann", :department "", :institution "Fraport AG", :country "Germany", :sessions (199980 199899)}, 33364 {:firstname "Jessica", :lastname "Raasch", :department "Chair for Management Science and Energy Economics", :institution "University Duisburg-Essen", :country "Germany", :sessions (199932)}, 33365 {:firstname "Daniel", :lastname "Pöhle", :department "Strategisches Fahrplan- und Kapazitätsmanagement", :institution "DB Netz AG", :country "Germany", :sessions (199939)}, 33399 {:firstname "Julia", :lastname "Kovalenko", :department "chair of higher mathematics", :institution "Siberian Automobile and Highway Academy", :country "Russian Federation", :sessions (199874)}, 33402 {:firstname "Joachim", :lastname "Vierling", :department "", :institution "Universität Heidelberg", :country "Germany", :sessions (15)}, 33414 {:firstname "Guido", :lastname "Voigt", :department "Logistics (Supply Chain Management)", :institution "Universität Hamburg", :country "Germany", :sessions (61 199860)}, 33419 {:firstname "J. Fabian", :lastname "Meier", :department "Institut für Transportlogistik", :institution "TU Dortmund", :country "Germany", :sessions (26 27)}, 33421 {:firstname "Simon", :lastname "Hirzel", :department "", :institution "Fraunhofer Institute for Systems and Innovation Research ISI", :country "Germany", :sessions (199934)}, 33437 {:firstname "Adam", :lastname "Kurpisz", :department "Institute of Mathematics and Computer Science", :institution "Wroclaw University of Technology", :country "Poland", :sessions (199878)}, 33450 {:firstname "Nils", :lastname "Lerche", :department "", :institution "Chair of Production and Logistics, Georg-August-Universität Göttingen", :country "Germany", :sessions (199840)}, 33453 {:firstname "Sebastian", :lastname "Stiller", :department "", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (42 69)}, 33462 {:firstname "Justus Arne", :lastname "Schwarz", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (199845)}, 33470 {:firstname "Valentin", :lastname "Bertsch", :department "Department of Energy Systems Analysis", :institution "German Aerospace Center (DLR)", :country "Germany", :sessions (55)}, 33485 {:firstname "Maria-Isabella", :lastname "Eickenjäger", :department "Institut für Wirtschaftsinformatik", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (99)}, 33487 {:firstname "Martin", :lastname "Bischoff", :department "Corporate Technology", :institution "Siemens AG", :country "Germany", :sessions (199929)}, 33504 {:firstname "Olaf", :lastname "Syben", :department "", :institution "ProCom", :country "Germany", :sessions (199981)}, 33505 {:firstname "Robert", :lastname "Schwarz", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (45 106)}, 33522 {:firstname "Rouven", :lastname "Wiegard", :department "", :institution "Institut für Wirtschaftsinformatik, Leibniz Universität Hannover", :country "Germany", :sessions (199961)}, 33557 {:firstname "Stefan", :lastname "Frank", :department "Faculty of Transport and Traffic Sciences, Institute for Logistics and Aviation", :institution "Technical University of Dresden", :country "Germany", :sessions (5)}, 33565 {:firstname "Igor", :lastname "Kozeletskyi", :department "Mercator School of Management", :institution "University of Duisburg-Essen", :country "Germany", :sessions (199888)}, 33571 {:firstname "Pascal", :lastname "Lutter", :department "Fac. of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199936)}, 33581 {:firstname "Michael", :lastname "Bastubbe", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (199909)}, 33591 {:firstname "Theo", :lastname "Berger", :department "Empirical Economics and Applied Statistics", :institution "University of Bremen", :country "Germany", :sessions (83)}, 33634 {:firstname "Betül", :lastname "Özkan", :department "Industrial Engineering", :institution "Yildiz Technical University", :country "Turkey", :sessions (199860)}, 33649 {:firstname "Arndt", :lastname "Claußen", :department "Institut für Banken und Finanzierung", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (199961)}, 33657 {:firstname "Mohsen", :lastname "Rezapour", :department "", :institution "Institute for Mathematics, TU Berlin", :country "Germany", :sessions (199900)}, 33663 {:firstname "Daniel", :lastname "Karch", :department "", :institution "TU Berlin", :country "Germany", :sessions (69)}, 33694 {:firstname "Melanie", :lastname "Reuter-Oppermann", :department "Karlsruhe Service Research Institute", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (91 199884 199932 199936)}, 33695 {:firstname "Hans", :lastname "Schlenker", :department "ILOG Optimization", :institution "IBM Deutschland GmbH, Software Group", :country "Germany", :sessions (199884)}, 33700 {:firstname "Carsten", :lastname "Ehrenberg", :department "Operations Research Group", :institution "Clausthal University of Technology", :country "Germany", :sessions (199946)}, 33865 {:firstname "Nadine", :lastname "Wollenberg", :department "Mathematic", :institution "Universitiy of Duisburg-Essen", :country "Germany", :sessions (50)}, 34348 {:firstname "Stefan", :lastname "Weber", :department "", :institution "Institut für Stochastik", :country "Germany", :sessions (51)}, 34431 {:firstname "Morteza", :lastname "Davari", :department "Research Centre for Operations Management, Campus Brussels", :institution "KU Leuven", :country "Belgium", :sessions (102)}, 34468 {:firstname "Philipp", :lastname "von Falkenhausen", :department "Institut für Mathematik", :institution "Technische Universität Berlin", :country "Germany", :sessions (92)}, 35072 {:firstname "Busra", :lastname "Temocin", :department "", :institution "Middle East Technical University ", :country "Turkey", :sessions (199958)}, 35097 {:firstname "Alena", :lastname "Otto", :department "", :institution "University of Siegen", :country "Germany", :sessions (199944 199943)}, 35181 {:firstname "Ruud", :lastname "Teunter", :department "Operations", :institution "University of Groningen", :country "Netherlands", :sessions (199941)}, 35215 {:firstname "Matthias", :lastname "Klumpp", :department "Institut für Logistik & Dienstleistungsmanagement", :institution "FOM University of Applied Sciences", :country "Germany", :sessions (199856 199863)}, 35382 {:firstname "Stefan", :lastname "Waldherr", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (199873)}, 35383 {:firstname "Jana", :lastname "Lehnfeld", :department "", :institution "University of Osnabrück", :country "Germany", :sessions (25)}, 35390 {:firstname "Aadhaar", :lastname "Chaturvedi", :department "Business Administration", :institution "Université de Namur", :country "Belgium", :sessions (199862)}, 35439 {:firstname "Steffensen", :lastname "Sonja", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (7 199960)}, 35552 {:firstname "laurent", :lastname "gourves", :department "computer science", :institution "CNRS - LAMSADE - universite Paris-Dauphine", :country "France", :sessions (57)}, 35608 {:firstname "Daniel", :lastname "Kadatz", :department "Information Systems", :institution "Freie Universität Berlin", :country "Germany", :sessions (199926)}, 35685 {:firstname "Michael", :lastname "Herty", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (4)}, 35913 {:firstname "Ioannis", :lastname "Caragiannis", :department "Department of Computer Engineering and Informatics", :institution "University of Patras", :country "Greece", :sessions (58)}, 35914 {:firstname "Anulark", :lastname "Naber", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (199870)}, 36025 {:firstname "Laura", :lastname "Klein", :department "Mathematics", :institution "TU Dortmund", :country "Germany", :sessions (81)}, 36077 {:firstname "Kristina", :lastname "Burmeister", :department "Department of Production Management", :institution "Leibniz University Hannover", :country "Germany", :sessions (199847)}, 36160 {:firstname "Eduardo", :lastname "Lalla-Ruiz", :department "Institute of Information Systems", :institution "University of Hamburg", :country "Germany", :sessions (46)}, 36408 {:firstname "Jorne", :lastname "Van den Bergh", :department "", :institution "KU Leuven (campus Brussels)", :country "Belgium", :sessions (199872)}, 36412 {:firstname "Richard", :lastname "Hinze", :department "", :institution "Merseburg University of Applied Sciences", :country "Germany", :sessions (199846)}, 36513 {:firstname "Morten", :lastname "Tiedemann", :department "Institute for Numerical and Applied Mathematics", :institution "Georg-August-University Goettingen", :country "Germany", :sessions (199897)}, 36698 {:firstname "Matej", :lastname "Cebecauer", :department "Department of Transportation Networks", :institution "University of Žilina", :country "Slovakia", :sessions (199911)}, 36725 {:firstname "Hamid", :lastname "Yılmaz", :department "Industrial Engineering", :institution "Ataturk University", :country "Turkey", :sessions (199846)}, 36737 {:firstname "Marco", :lastname "Bender", :department "Institute for Applied Stochastics and Operations Research", :institution "Clausthal University of Technology", :country "Germany", :sessions (199897)}, 36770 {:firstname "Dennis", :lastname "De Clerck", :department "Decision Sciences and Information Management", :institution "KU Leuven", :country "Belgium", :sessions (102)}, 36797 {:firstname "Patricio", :lastname "Lamas", :department "", :institution "KU Leuven", :country "Belgium", :sessions (102)}, 36925 {:firstname "Alexander", :lastname "Börsch", :department "", :institution "TU Chemnitz", :country "Germany", :sessions (101)}, 36955 {:firstname "Clemens", :lastname "Thielen", :department "Department of Mathematics", :institution "University of Kaiserslautern", :country "Germany", :sessions (30 199897)}, 37015 {:firstname "Sophie", :lastname "Weiss", :department "Chair of Production Management", :institution "University of Mannheim", :country "Germany", :sessions (199845)}, 37090 {:firstname "Lars", :lastname "Eufinger", :department "", :institution "Deutsche Bahn AG", :country "Germany", :sessions (199881 50)}, 37356 {:firstname "Bram", :lastname "de Jonge", :department "Operations", :institution "University of Groningen", :country "Netherlands", :sessions (199941)}, 37465 {:firstname "Michael", :lastname "Samudra", :department "Faculty of Economics and Business", :institution "KU Leuven", :country "Belgium", :sessions (199937)}, 37489 {:firstname "Viktoryia", :lastname "Buhayenko", :department "Department of Economics and Business Economics", :institution "Aarhus University", :country "Denmark", :sessions (199831)}, 37741 {:firstname "Ban", :lastname "Kawas", :department "", :institution "IBM Research", :country "United States", :sessions (199882)}, 37762 {:firstname "Hendrik", :lastname "Guhlich", :department "Area Operations Management", :institution "University of Mannheim", :country "Germany", :sessions (101)}, 37980 {:firstname "Dirk", :lastname "Sackmann", :department "", :institution "Merseburg University of Applied Sciences", :country "Germany", :sessions (199846)}, 38193 {:firstname "Sebastian", :lastname "Meiswinkel", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (199913)}, 38534 {:firstname "Christoph", :lastname "Laroque", :department "Heinz Nixdorf Institute", :institution "University of Paderborn", :country "Germany", :sessions (27)}, 38567 {:firstname "Marco", :lastname "Casazza", :department "OptLab", :institution "Università degli Studi di Milano", :country "Italy", :sessions (199864)}, 38782 {:firstname "Vassilis", :lastname "Papapanagiotou", :department "", :institution "IDSIA", :country "Switzerland", :sessions (47)}, 38898 {:firstname "Xiyu", :lastname "Li", :department "", :institution "University of Siegen", :country "Germany", :sessions (199944)}, 39002 {:firstname "Gerhard", :lastname "Hiermann", :department "TUM School of Management", :institution "TU Munich", :country "Germany", :sessions (5)}, 39159 {:firstname "Ingo", :lastname "Althoefer", :department "Mathematics and Computer Science", :institution "FSU Jena", :country "Germany", :sessions (199899)}, 39226 {:firstname "Yasuhiro", :lastname "Iida", :department "Industrial Management", :institution "Waseda University", :country "Japan", :sessions (199836)}, 39239 {:firstname "Gustav", :lastname "Feichtinger", :department "Institute of Statistics and Mathematical Methods in Economics", :institution "Vienna University of Technology", :country "Austria", :sessions (75)}, 39273 {:firstname "Stephan", :lastname "Lemkens", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (68)}, 39298 {:firstname "Alexander", :lastname "Kressner", :department "Procurement and Production", :institution "University of Hohenheim", :country "Germany", :sessions (199937)}, 39314 {:firstname "Jochen", :lastname "Schlapp", :department "Business School", :institution "University of Mannheim", :country "Germany", :sessions (199955)}, 39320 {:firstname "Felix", :lastname "Herde", :department "Institut für Produktionswirtschaft", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (101)}, 39330 {:firstname "Thijs", :lastname "van der Klauw", :department "EEMCS", :institution "University of Twente", :country "Netherlands", :sessions (68)}, 39348 {:firstname "Salman", :lastname "Fadaei", :department "Informatics", :institution "TU München", :country "Germany", :sessions (199832)}, 39349 {:firstname "Takayuki", :lastname "Shiina", :department "Department of Industrial and Management Systems Engineering", :institution "Waseda University", :country "Japan", :sessions (199931)}, 39363 {:firstname "Barbara", :lastname "Schoendube", :department "Accounting and Control", :institution "Otto-von-Guericke University Magdeburg", :country "Germany", :sessions (199860)}, 39370 {:firstname "Raimond", :lastname "Wüst", :department "Institute for Data Analysis and Process Design", :institution "ZHAW", :country "Switzerland", :sessions (86813)}, 39371 {:firstname "Han", :lastname "Hoogeveen", :department "Department of Information and Computer Science", :institution "Utrecht University", :country "Netherlands", :sessions (68)}, 39372 {:firstname "Margaretha", :lastname "Gansterer", :department "", :institution "University of Vienna", :country "Austria", :sessions (26)}, 39383 {:firstname "Alexander", :lastname "Butsch", :department "Institute of Operations Research (IOR)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (199946)}, 39388 {:firstname "Thomas", :lastname "Bauschert", :department "Chair for Communication Networks", :institution "TU Chemnitz", :country "Germany", :sessions (199914)}, 39400 {:firstname "Susumu", :lastname "Morito", :department "Industrial and Management Systems Engineering", :institution "Waseda University", :country "Japan", :sessions (199957 199931)}, 39402 {:firstname "Subrata", :lastname "Mitra", :department "Operations Management", :institution "IIM Calcutta", :country "India", :sessions (199926)}, 39404 {:firstname "Gerard", :lastname "Smit", :department "", :institution "University of Twente", :country "Netherlands", :sessions (68)}, 39406 {:firstname "Dennis", :lastname "Moeke", :department "Department of Mathematics", :institution "VU University Amsterdam", :country "Netherlands", :sessions (77)}, 39408 {:firstname "Christian", :lastname "Tilk", :department "Chair of Logistics Management", :institution "Gutenberg School of Management and Economics, Johannes Gutenberg University Mainz", :country "Germany", :sessions (199916)}, 39414 {:firstname "Fabian", :lastname "Kirchhoff", :department "", :institution "Clausthal University of Technology", :country "Germany", :sessions (54)}, 39419 {:firstname "Florian", :lastname "Denz", :department "", :institution "Chair of Business Administration, Production & Supply Chain Management, Augsburg University", :country "Germany", :sessions (63)}, 39420 {:firstname "Katrin", :lastname "Schulz", :department "Faculty of Management and Econcomics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199927)}, 39462 {:firstname "Matthias", :lastname "Schacht", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199927)}, 39468 {:firstname "Lara", :lastname "Wiesche", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199936)}, 39469 {:firstname "Christoph", :lastname "Meyer", :department "", :institution "Institute of Automotive Management and Industrial Production, Technische Universität Braunschweig", :country "Germany", :sessions (199932 99)}, 39472 {:firstname "Sonja", :lastname "Kalkowski", :department "", :institution "Business Administration, Production and Logistics, University of Dortmund", :country "Germany", :sessions (199849)}, 39482 {:firstname "Hannes", :lastname "Schwarz", :department "Chair of Energy Economics", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (55)}, 39493 {:firstname "Manuel", :lastname "Kutschka", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (42)}, 39494 {:firstname "Annika", :lastname "Thome", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (199880)}, 39525 {:firstname "Pietro", :lastname "belotti", :department "", :institution "Xpress Optimization, FICO", :country "United Kingdom", :sessions (199883)}, 39527 {:firstname "Mahesh", :lastname "Srinivasan", :department "Management", :institution "The University of Akron", :country "United States", :sessions (199955)}, 39528 {:firstname "Douglas", :lastname "Thomas", :department "", :institution "The Pennsylvania State Univetsity", :country "United States", :sessions (199955)}, 39533 {:firstname "Jean Francois", :lastname "Puget", :department "", :institution "IBM Software Group", :country "France", :sessions (199976)}, 39546 {:firstname "Wolfgang", :lastname "Ketter", :department "", :institution "Rotterdam School of Management, Erasmus University", :country "Netherlands", :sessions (10)}, 39552 {:firstname "Frank", :lastname "Gurski", :department "Institute of Computer Science", :institution "Heinrich Heine University Düsseldorf", :country "Germany", :sessions (199912)}, 39553 {:firstname "Thorsten", :lastname "Ederer", :department "Discrete Optimization", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (106 81)}, 39554 {:firstname "Ulf", :lastname "Lorenz", :department "Chair of Technology Management", :institution "Universitaet Siegen", :country "Germany", :sessions (199877 106)}, 39563 {:firstname "Egon", :lastname "Wanke", :department "Computer Sciences", :institution "Heinrich-Heine Universität", :country "Germany", :sessions (199912)}, 39566 {:firstname "Jochen", :lastname "Rethmann", :department "Faculty of Electrical Engineering and Computer Science", :institution "Niederrhein University of Applied Sciences", :country "Germany", :sessions (199912)}, 39622 {:firstname "Rakesh ", :lastname "Vohra", :department "Department of Managerial Economics and Decision Sciences", :institution "Northwestern University", :country "United States", :sessions (199978)}, 39743 {:firstname "Roman", :lastname "Rischke", :department "", :institution "Technische Universität Berlin", :country "Germany", :sessions (199880)}, 39834 {:firstname "Sebastian", :lastname "Vock", :department "", :institution "Opremic solutions GmbH", :country "Germany", :sessions (98)}, 39997 {:firstname "Jan-J", :lastname "Ruckmann", :department "Department of Informatics", :institution "University of Bergen", :country "Norway", :sessions (199960)}, 40073 {:firstname "Tai-yu", :lastname "Ma", :department "Urban Development and Mobility", :institution "Luxembourg Institute of Socio-Economic Research", :country "Luxembourg", :sessions (199942)}, 40357 {:firstname "Ilhana", :lastname "Mulic", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199933)}, 40456 {:firstname "Stef", :lastname "Lemmens", :department "Technology and Operations Management", :institution "INSEAD", :country "France", :sessions (37)}, 40497 {:firstname "Malte", :lastname "Fliedner", :department "", :institution "University of Hamburg", :country "Germany", :sessions (199942)}, 40500 {:firstname "Martim", :lastname "Joyce-Moniz", :department "", :institution "Polytechnique Montréal", :country "Canada", :sessions (199898)}, 40519 {:firstname "Frederik", :lastname "Fiand", :department "", :institution "GAMS Software GmbH", :country "Germany", :sessions (199943)}, 40522 {:firstname "Laura", :lastname "McLay", :department "", :institution "University of Wisconsin–Madison", :country "United States", :sessions (199975)}, 40593 {:firstname "Ramajothi", :lastname "Ramsundar", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199933)}, 40884 {:firstname "Nicolas", :lastname "Justus", :department "", :institution "TU Darmstadt", :country "Germany", :sessions (199859)}, 40907 {:firstname "Susara", :lastname "van den Heever", :department "", :institution "IBM", :country "France", :sessions (86813)}, 41108 {:firstname "Nicole", :lastname "Taheri", :department "", :institution "IBM Research Ireland", :country "Ireland", :sessions (69)}, 41121 {:firstname "Peter", :lastname "Rausch", :department "Fakultät Informatik ", :institution "Technische Hochschule Nürnberg Georg Simon Ohm", :country "Germany", :sessions (16)}, 41201 {:firstname "Maud", :lastname "Van den Broeke", :department "Operations and Supply Chain Management", :institution "Ieseg School of Management", :country "France", :sessions (37)}, 41203 {:firstname "Carlos", :lastname "Casorrán-Amilburu", :department "Informatique", :institution "Université Libre de Bruxelles", :country "Belgium", :sessions (199886)}, 41246 {:firstname "Erik", :lastname "Demeulemeester", :department "KBI", :institution "KU Leuven", :country "Belgium", :sessions (199872 199975 199937 102)}, 41267 {:firstname "Swetlana", :lastname "Dregert", :department "Controlling", :institution "RWTH Aachen", :country "Germany", :sessions (199964)}, 41376 {:firstname "Martin", :lastname "Hoefer", :department "Institute of Computer Science", :institution "Goethe University Frankfurt", :country "Germany", :sessions (199888 19)}, 41433 {:firstname "Kuan-Min", :lastname "Lin", :department "Management Science", :institution "Lancaster University", :country "United Kingdom", :sessions (199833)}, 41616 {:firstname "Frederic Theodor", :lastname "Stahl", :department "School of Systems Engineering", :institution "University of Reading", :country "United Kingdom", :sessions (22)}, 41718 {:firstname "Marion", :lastname "Ott", :department "School of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (76 199832 100)}, 41719 {:firstname "Marissa", :lastname "Beck", :department "Dept of Economics", :institution "Stanford University ", :country "United States", :sessions (100)}, 41756 {:firstname "Philipp", :lastname "Pöttgen", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (106)}, 41758 {:firstname "Lena Charlotte", :lastname "Altherr", :department "Chair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (106)}, 41874 {:firstname "Thomas", :lastname "Kallabis", :department "Chair for Management Science and Energy Economics", :institution "University Duisburg-Essen", :country "Germany", :sessions (55)}, 41876 {:firstname "Lenja", :lastname "Niesen", :department "Chair for Energy Economics", :institution "University Duisburg-Essen", :country "Germany", :sessions (199928)}, 41903 {:firstname "Paul", :lastname "Harrenstein", :department "Department of Computer Science", :institution " University of Oxford", :country "United Kingdom", :sessions (29)}, 41906 {:firstname "Angelina", :lastname "Vidali", :department "Computer Science", :institution "Duke University", :country "United States", :sessions (31)}, 41926 {:firstname "Sabrina", :lastname "Ried", :department "", :institution "Chair of Energy Economics and Project Competence-E, Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (199930 199932)}, 41942 {:firstname "Andre", :lastname "Berger", :department "", :institution "Quantitative Economics", :country "Netherlands", :sessions (33)}, 41995 {:firstname "Ismael Peruzzo", :lastname "Zamoner", :department "", :institution "Catalitica Consultoria de Gestão", :country "Brazil", :sessions (24)}, 42017 {:firstname "André", :lastname "Chassein", :department "Mathematics", :institution "Technische Universität Kaiserslautern", :country "Germany", :sessions (199878)}, 42054 {:firstname "Martin", :lastname "Tieves", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (199911)}, 42140 {:firstname "Torsten", :lastname "Buchwald", :department "", :institution "TU Dresden", :country "Germany", :sessions (199894)}, 42187 {:firstname "Peter", :lastname "Pelz", :department " \tChair of Fluid Systems", :institution "Technische Universität Darmstadt", :country "Germany", :sessions (106)}, 42315 {:firstname "Jonas", :lastname "Witt", :department "Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (199910)}, 42318 {:firstname "Peter", :lastname "Gluchowski", :department "Wirtschaftswissenschaften", :institution "TU Chemnitz", :country "Germany", :sessions (36)}, 42388 {:firstname "Jelena", :lastname "Stankovic", :department "Department of Accounting, Mathematics and Informatics", :institution "University of Nis, Faculty of Economics", :country "Serbia", :sessions (51)}, 42664 {:firstname "Elvin", :lastname "Coban", :department "Industrial Engineering", :institution "Ozyegin University", :country "Turkey", :sessions (89)}, 42667 {:firstname "Aliza R.", :lastname "Heching", :department "", :institution "IBM TJ Watson Research Center", :country "United States", :sessions (89)}, 42723 {:firstname "Lena", :lastname "Michailidis", :department "", :institution "RWTH Aachen", :country "Germany", :sessions (199959)}, 42734 {:firstname "Pascal", :lastname "Lenzner", :department "Department of Computer Science", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (39 199885)}, 42750 {:firstname "Michal", :lastname "Melamed", :department "Industrial Engineering and Management", :institution "Technion - Israel institute of technology", :country "Israel", :sessions (199852)}, 42755 {:firstname "Isabel", :lastname "Friedow", :department "Institute of Numerical Mathmatics", :institution "Dresden University of Technology", :country "Germany", :sessions (199894)}, 42850 {:firstname "Giorgos", :lastname "Christodoulou", :department "Computer Science", :institution "University of Liverpool", :country "United Kingdom", :sessions (8)}, 42895 {:firstname "Sebastien", :lastname "Lannez", :department "Xpress Optimization", :institution "FICO", :country "France", :sessions (199883)}, 42931 {:firstname "André", :lastname "Mangelsdorf", :department "Strategic Management and Organisation", :institution "Otto-von-Guericke-Universität Magdeburg", :country "Germany", :sessions (15)}, 42979 {:firstname "Tobias", :lastname "Lühn", :department "Chair of Production and Logistics", :institution "University of Goettingen", :country "Germany", :sessions (63)}, 43026 {:firstname "Brecht", :lastname "Cardoen", :department "", :institution "Vlerick Business School", :country "Belgium", :sessions (199937)}, 43053 {:firstname "Kim Lana", :lastname "Köhler", :department "", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (199933)}, 43180 {:firstname "Thomas", :lastname "Setzer", :department "Business Engineering and Management", :institution "KIT", :country "Germany", :sessions (91 105 86)}, 43221 {:firstname "Ryosuke", :lastname "Yabe", :department "Faculty of Science and Engineering", :institution "Waseda University", :country "Japan", :sessions (199940)}, 43231 {:firstname "Katerina", :lastname "Shapoval", :department "Department of Economics and Management", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (105)}, 43371 {:firstname "Stefan", :lastname "Seuring", :department "", :institution "University of Kassel", :country "Germany", :sessions (61)}, 43375 {:firstname "Daniel", :lastname "Thiel", :department "", :institution "Université Paris 13, Sorbonne Paris Cité", :country "France", :sessions (61)}, 43641 {:firstname "Zarko", :lastname "Popovic", :department "Faculty of Economics", :institution "University of Nis", :country "Serbia", :sessions (51)}, 43680 {:firstname "Philippe", :lastname "De Bruecker", :department "Research Center for Operations Management", :institution "KU Leuven", :country "Belgium", :sessions (199872)}, 44011 {:firstname "Oleg", :lastname "Baranov", :department "Economics", :institution "University of Colorado at Boulder", :country "United States", :sessions (100)}, 44036 {:firstname "Lawrence", :lastname "Ausubel", :department "Economics", :institution "University of Maryland", :country "United States", :sessions (100)}, 44056 {:firstname "Marjolein", :lastname "Harmsen - van Hout", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199903)}, 44261 {:firstname "Angelo", :lastname "Fanelli", :department "", :institution "CNRS", :country "France", :sessions (58)}, 44380 {:firstname "Marcus", :lastname "Schröter", :department "FB Wirtschaft", :institution "Hochschule Bochum", :country "Germany", :sessions (66 199933)}, 44403 {:firstname "Asma", :lastname "Ben Yaghlane", :department "Management", :institution "Institut Supérieur de Gestion Tunis", :country "Tunisia", :sessions (199842)}, 44404 {:firstname "Mohamed Naceur", :lastname "Azaiez", :department "", :institution "Tunis Business School, University of Tunis", :country "Tunisia", :sessions (199842)}, 44437 {:firstname "Joerg", :lastname "Rothe", :department "Institut für Informatik", :institution "HHU", :country "Germany", :sessions (67)}, 44469 {:firstname "Alexander", :lastname "Skopalik", :department "", :institution "University of Twente", :country "Netherlands", :sessions (8 58 199887)}, 44470 {:firstname "Nick", :lastname "Gravin", :department "", :institution "Microsoft Research", :country "United States", :sessions (58)}, 44516 {:firstname "assia", :lastname "Menni", :department "Operations Research", :institution "USTHB -Algeria-", :country "Algeria", :sessions (199835)}, 44543 {:firstname "Marlis", :lastname "Bärthel", :department "Institut für Mathematik", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (199889)}, 44697 {:firstname "Benjamin", :lastname "Weißing", :department "Institut für Mathematik", :institution "MLU Halle-Wittenberg", :country "Germany", :sessions (87 199893)}, 44744 {:firstname "Micha", :lastname "Kahlen", :department "", :institution "Erasmus University", :country "Netherlands", :sessions (10)}, 44745 {:firstname "Alexander", :lastname "Döge", :department "TUM School of Management", :institution "Technical University of Munich", :country "Germany", :sessions (199865)}, 44772 {:firstname "Marc-Andre", :lastname "Weber", :department "Faculty of Engineering", :institution "University of Duisburg-Essen", :country "Germany", :sessions (199846)}, 44795 {:firstname "Gero", :lastname "Szepannek", :department "", :institution "Santander", :country "Germany", :sessions (199890 73)}, 44819 {:firstname "Gerard", :lastname "Scallan", :department "", :institution "Scoreplus", :country "France", :sessions (73)}, 44822 {:firstname "Matthias", :lastname "Feldotto", :department "Heinz Nixdorf Institute", :institution "University of Paderborn", :country "Germany", :sessions (58)}, 44836 {:firstname "Martin", :lastname "Gairing", :department "", :institution "University of Liverpool", :country "United Kingdom", :sessions (8 58)}, 44839 {:firstname "Annette", :lastname "Chmielewski", :department "", :institution "4flow AG", :country "Germany", :sessions (26)}, 44845 {:firstname "Christian", :lastname "Ruf", :department "", :institution "TU München", :country "Germany", :sessions (95)}, 44851 {:firstname "Katharina", :lastname "Wachter", :department "Chair of Production and Logistics, Institute for Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (60 199928)}, 44863 {:firstname "Alexandra", :lastname "Schwartz", :department "Graduate School CE", :institution "TU Darmstadt", :country "Germany", :sessions (7)}, 44864 {:firstname "Martin", :lastname "Spann", :department "", :institution "Ludwig-Maximilians-Universität", :country "Germany", :sessions (98)}, 44865 {:firstname "Lucas", :lastname "Stich", :department "", :institution "Ludwig-Maximilians-Universität", :country "Germany", :sessions (98)}, 44869 {:firstname "Rahul", :lastname "Savani", :department "", :institution "University of Liverpool", :country "United Kingdom", :sessions (58)}, 44894 {:firstname "Karl-Martin", :lastname "Ehrhart", :department "", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (76)}, 44897 {:firstname "John ", :lastname "Fearnley", :department "", :institution "University of Liverpool", :country "United Kingdom", :sessions (58)}, 44900 {:firstname "Gilles", :lastname "Merckx", :department "Business Administration", :institution "University of Namur", :country "Belgium", :sessions (199862)}, 44911 {:firstname "Peiman", :lastname "Dabidian", :department "Mechanical Engineering", :institution "Institute of Transport Logistics", :country "Germany", :sessions (27)}, 44916 {:firstname "Christian", :lastname "Thies", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (60)}, 44928 {:firstname "Stefanie", :lastname "Wolff", :department "Faculty of Business and Economics / E.ON Energy Research Center", :institution "RWTH Aachen University", :country "Germany", :sessions (199920)}, 44954 {:firstname "Christoph", :lastname "Lehmann", :department "", :institution "TU Dresden", :country "Germany", :sessions (199890)}, 44955 {:firstname "Bart", :lastname "Vangerven", :department "Lehrstuhl für Produktion und Logistik", :institution "Bergische Universität Wuppertal", :country "Germany", :sessions (97)}, 44966 {:firstname "Jan", :lastname "Stutzki", :department "Institut für Theoretische Informatik, Mathematik und Operations Research", :institution "Universität der Bundeswehr München", :country "Germany", :sessions (84 86)}, 44978 {:firstname "Thomas", :lastname "Kittsteiner", :department "Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (199832 100)}, 44979 {:firstname "Matthias", :lastname "Claus", :department "Mathematik", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (90)}, 44983 {:firstname "Fernanda", :lastname "Christmann", :department "Department of Information Science", :institution "Federal University of Santa Catarina", :country "Brazil", :sessions (24)}, 44984 {:firstname "Daniel C.", :lastname "Pithan", :department "", :institution "TU Clausthal", :country "Germany", :sessions (65)}, 44985 {:firstname "Markus", :lastname "Peters", :department "", :institution "Erasmus University Rotterdam", :country "Netherlands", :sessions (10)}, 44986 {:firstname "Peter", :lastname "Hottum", :department "KSRI - Karlsruhe Service Research Institute", :institution "KIT", :country "Germany", :sessions (91)}, 44987 {:firstname "Hansjörg", :lastname "Fromm", :department "KSRI - Karlsruhe Service Research Institute", :institution "KIT", :country "Germany", :sessions (91)}, 44991 {:firstname "Anja", :lastname "Ohsenbruegge", :department "Computer Science", :institution "Uni Oldenburg", :country "Germany", :sessions (199931)}, 44992 {:firstname "Richard", :lastname "Steinberg", :department "Department of Management", :institution "London School of Economics and Political Science (LSE)", :country "United Kingdom", :sessions (199832)}, 44993 {:firstname "Ward", :lastname "Romeijnders", :department "Department of Operations", :institution "University of Groningen", :country "Netherlands", :sessions (90)}, 44995 {:firstname "Andreas", :lastname "Heidt", :department "Department Mathematik", :institution "FAU Erlangen-Nürnberg", :country "Germany", :sessions (199898)}, 44996 {:firstname "Johannes", :lastname "Kunze von Bischoffshausen", :department "Karlsruhe Service Research Institute (KSRI)", :institution "KIT", :country "Germany", :sessions (91)}, 44997 {:firstname "Peter", :lastname "Korevaar", :department "", :institution "IBM", :country "Germany", :sessions (91)}, 44998 {:firstname "Sebastian", :lastname "Blanc", :department "Institute of Information Systems and Marketing", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (91)}, 44999 {:firstname "Björn", :lastname "Felten", :department "Lehrstuhl für Energiewirtschaft", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (199932)}, 45000 {:firstname "Andor", :lastname "Goetzendorff", :department "Informatics", :institution "TU Munich", :country "Germany", :sessions (97)}, 45001 {:firstname "Jürgen", :lastname "Pannek", :department "Faculty of Production Engineering", :institution "University of Bremen", :country "Germany", :sessions (199863)}, 45009 {:firstname "Florian", :lastname "Isenberg", :department "DS&OR Lab", :institution "University of Paderborn", :country "Germany", :sessions (199847)}, 45010 {:firstname "Michael", :lastname "Vidalis", :department "Business Administration", :institution "University of the Aegean", :country "Greece", :sessions (199863)}, 45013 {:firstname "Martin", :lastname "Kumm", :department "", :institution "Universität Kassel", :country "Germany", :sessions (81)}, 45014 {:firstname "Kathrin", :lastname "Kühne", :department "", :institution "Leibniz University Hanover", :country "Germany", :sessions (199838 199840)}, 45016 {:firstname "Christian", :lastname "Derksen", :department "DAWIS - ICB", :institution "University of Duisburg Essen", :country "Germany", :sessions (10)}, 45017 {:firstname "Rainer", :lastname "Unland", :department "DAWIS - ICB", :institution "University Duisburg- Essen", :country "Germany", :sessions (10)}, 45018 {:firstname "Sandra", :lastname "Ifrim", :department "Chair of of Finance and Investment ", :institution "Faculty of Business Administration and Economics", :country "Germany", :sessions (105)}, 45021 {:firstname "Matej", :lastname "Belica", :department "", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (76)}, 45022 {:firstname "Sven", :lastname "Seuken", :department "Department of Informatics", :institution "University of Zurich", :country "Switzerland", :sessions (97)}, 45023 {:firstname "Cagin", :lastname "Ararat", :department "Industrial Engineering", :institution "Bilkent University", :country "Turkey", :sessions (199893)}, 45026 {:firstname "Torben", :lastname "Sens", :department "", :institution "University of Mannheim", :country "Germany", :sessions (32)}, 45027 {:firstname "Guido", :lastname "Schryen", :department "", :institution "Paderborn University", :country "Germany", :sessions (199874)}, 45028 {:firstname "Andreas", :lastname "Starzacher", :department "Operations Research and Engineering", :institution "Infineon Technologies AG", :country "Austria", :sessions (44)}, 45029 {:firstname "Gerhard", :lastname "Rauchecker", :department "", :institution "University of Regensburg", :country "Germany", :sessions (199874)}, 45033 {:firstname "Yoichi", :lastname "Izunaga", :department "Graduate School of Systems and Information Engineering", :institution "University of Tsukuba", :country "Japan", :sessions (199910 199867)}, 45034 {:firstname "Kotohumi", :lastname "Inaba", :department "Graduate School of Systems and Information Engineering", :institution "University of Tsukuba", :country "Japan", :sessions (199910)}, 45036 {:firstname "Alexander", :lastname "Frick", :department "", :institution "ABB AG", :country "Germany", :sessions (199932)}, 45037 {:firstname "Hans", :lastname "Schermeyer", :department "Institute for Industrial Production (IIP)", :institution "Karlsruhe Institute of Technology (KIT)", :country "Germany", :sessions (55)}, 45038 {:firstname "Matthias", :lastname "Feil", :department "Langfristfahrplan / Fahrwegkapazität", :institution "DB Netz AG", :country "Germany", :sessions (199939)}, 45044 {:firstname "Nadine", :lastname "Kumbartzky", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199931)}, 45046 {:firstname "Djamal", :lastname "Dris", :department "commercial sciences", :institution "Bejaia University", :country "Algeria", :sessions (199831)}, 45047 {:firstname "Felix", :lastname "Brandt", :department "Institut für Informatik", :institution "TU München", :country "Germany", :sessions (30)}, 45048 {:firstname "Marcus", :lastname "Wiens", :department "Institute for Industrial Production ", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (199886)}, 45052 {:firstname "Vincent", :lastname "Kreuzen", :department "Quantative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (92 199875)}, 45055 {:firstname "Sebastian", :lastname "Goderbauer", :department "Lehrstuhl für Operations Research", :institution "RWTH Aachen University", :country "Germany", :sessions (42 199948)}, 45057 {:firstname "Lisa", :lastname "Wagner", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199888 19)}, 45058 {:firstname "Rudolf", :lastname "Reinhard", :department "Institute of Information Management in Mechanical Engineering", :institution "RWTH Aachen University", :country "Germany", :sessions (199851)}, 45060 {:firstname "Tim", :lastname "Oosterwijk", :department "Departamento de Ingeniería Industrial", :institution "Universidad de Chile", :country "Chile", :sessions (199875)}, 45061 {:firstname "Can", :lastname "Sun", :department "Supply Chain Innovation", :institution "Infineon Technologies AG", :country "Germany", :sessions (44)}, 45062 {:firstname "José", :lastname "Correa", :department "Departamento de Ingenieria Industrial", :institution "Universidad de Chile", :country "Chile", :sessions (92)}, 45064 {:firstname "Anna", :lastname "Ryabokon", :department "Intelligent Systems and Business Informatics", :institution "Alpen-Adria Universitaet Klagenfurt", :country "Austria", :sessions (44)}, 45065 {:firstname "Andre", :lastname "Bardow", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (94)}, 45066 {:firstname "Lena Maria", :lastname "Hupp", :department "Lehrstuhl für Wirtschaftsmathematik", :institution "Friedrich-Alexander Universität Erlangen-Nürnberg", :country "Germany", :sessions (81)}, 45067 {:firstname "Aleksey", :lastname "Zakharov", :department "Control Theory", :institution "Saint Petersburg State University", :country "Russian Federation", :sessions (199841)}, 45068 {:firstname "Karl", :lastname "Schneeberger", :department "Production and Logistics Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (199848)}, 45069 {:firstname "Amelie", :lastname "Eilken", :department "Institut für Operations Management", :institution "Universität Hamburg", :country "Germany", :sessions (199942)}, 45070 {:firstname "Sönke", :lastname "Behrends", :department "Institut für Numerische und Angewandte Mathematik", :institution "Georg-August-Universität Göttingen", :country "Germany", :sessions (75)}, 45071 {:firstname "Lasse", :lastname "Kliemann", :department "Department of Computer Science", :institution "Kiel University", :country "Germany", :sessions (39)}, 45072 {:firstname "Isabel", :lastname "Beckenbach", :department "", :institution "Zuse Institut Berlin", :country "Germany", :sessions (199913)}, 45073 {:firstname "Markus", :lastname "Frey", :department "", :institution "TUM School of Management", :country "Germany", :sessions (199865 95)}, 45074 {:firstname "Sonja", :lastname "Mars", :department "", :institution "Gurobi Optimization", :country "Germany", :sessions (199884)}, 45075 {:firstname "Dennis", :lastname "Kraft", :department "Informatics", :institution "TU München", :country "Germany", :sessions (199832)}, 45076 {:firstname "Florian", :lastname "Knöll", :department "Institute of Information Systems and Marketing", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (86)}, 45077 {:firstname "Christoph", :lastname "Baumann", :department "", :institution "Institute of Power Systems and Power Economics", :country "Germany", :sessions (94)}, 45078 {:firstname "Maarten", :lastname "Janssen", :department "Economics", :institution "University of Vienna", :country "Austria", :sessions (100)}, 45082 {:firstname "Sven", :lastname "Woogt", :department "", :institution "Robert Bosch Korea Ltd.", :country "Korea, Republic of", :sessions (32)}, 45083 {:firstname "Svenja", :lastname "Hoffmann-Fölkersamb", :department "", :institution "University of Mannheim", :country "Germany", :sessions (32)}, 45084 {:firstname "Timothy L.", :lastname "Urban", :department "Operations Management", :institution "The University of Tulsa", :country "United States", :sessions (54)}, 45085 {:firstname "Ryo", :lastname "Nakahara", :department "", :institution "Waseda University", :country "Japan", :sessions (199957)}, 45086 {:firstname "Tatsuki", :lastname "Inoue", :department "", :institution "Waseda University", :country "Japan", :sessions (199957)}, 45087 {:firstname "Yann", :lastname "Disser", :department "Institut für Mathematik", :institution "TU Darmstadt", :country "Germany", :sessions (42 199873)}, 45088 {:firstname "Andreas", :lastname "Cord-Landwehr", :department "Department of Computer Science", :institution "University of Paderborn", :country "Germany", :sessions (199885)}, 45089 {:firstname "Takuya", :lastname "Hirota", :department "", :institution "Waseda University", :country "Japan", :sessions (199957)}, 45090 {:firstname "Daniel", :lastname "Rose", :department "Institut für Angewandte Mathematik", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (45)}, 45091 {:firstname "Alexander", :lastname "Mäcker", :department "Department of Computer Science", :institution "University of Paderborn", :country "Germany", :sessions (199885)}, 45092 {:firstname "Friedhelm", :lastname "Meyer auf der Heide", :department "Department of Computer Science & Heinz Nixdorf Institute", :institution "University of Paderborn", :country "Germany", :sessions (199885)}, 45095 {:firstname "Alexandru", :lastname "Dimitriu", :department "Software reliability", :institution "Google", :country "United Kingdom", :sessions (68)}, 45097 {:firstname "Roger", :lastname "Cremers", :department "", :institution "DNV-GL", :country "Netherlands", :sessions (68)}, 45098 {:firstname "Frederick", :lastname "Lange", :department "", :institution "Technical University of Applied Sciences Regensburg", :country "Germany", :sessions (32)}, 45099 {:firstname "Michael", :lastname "Zenker", :department "", :institution "Friedrich-Schiller-University Jena", :country "Germany", :sessions (71)}, 45100 {:firstname "Thomas", :lastname "Rose", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (44)}, 45101 {:firstname "Stefan", :lastname "Heilmayer", :department "", :institution "Infineon Technologies AG", :country "Germany", :sessions (44)}, 45103 {:firstname "Robert J.", :lastname "Vanderbei", :department "ORFE", :institution "Princeton University", :country "United States", :sessions (87)}, 45104 {:firstname "Hannes", :lastname "Lampe", :department "Institute for Public and Nonprofit Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (199964 199856)}, 45107 {:firstname "Takahiro", :lastname "Yurugi", :department "Industrial and Management Systems Engineering", :institution "Waseda University", :country "Japan", :sessions (199931)}, 45108 {:firstname "Jun", :lastname "Imaizumi", :department "Faculty of Business Administration", :institution "Toyo Univeresity", :country "Japan", :sessions (199931)}, 45115 {:firstname "Veerle", :lastname "Timmermans", :department "Management Science", :institution "RWTH Aachen", :country "Netherlands", :sessions (93)}, 45116 {:firstname "Małgorzata", :lastname "Grela", :department "Institute of Computing Science", :institution "Poznan University of Technology", :country "Poland", :sessions (199944)}, 45118 {:firstname "Gülnar", :lastname "Eren", :department "", :institution "Yasar University", :country "Turkey", :sessions (199869)}, 45119 {:firstname "Burcu", :lastname "Karaöz", :department "", :institution "Yasar University", :country "Turkey", :sessions (199869)}, 45120 {:firstname "Sevkinaz", :lastname "Gumusoglu", :department "", :institution "Yasar University", :country "Turkey", :sessions (199869)}, 45121 {:firstname "Manuel", :lastname "Kutschka", :department "Aviation Division", :institution "INFORM GmbH", :country "Germany", :sessions (28 199949)}, 45122 {:firstname "Eda", :lastname "Yilmaz", :department "Institute of Computer Science", :institution "University of Düsseldorf", :country "Germany", :sessions (199912)}, 45125 {:firstname "Benjamin", :lastname "Otto", :department "", :institution "Friedrich-Schiller-University Jena", :country "Germany", :sessions (71)}, 45130 {:firstname "Edwin", :lastname "van Dam", :department "", :institution "Tilburg Unniversity", :country "Netherlands", :sessions (81)}, 45131 {:firstname "Lin", :lastname "Chen", :department "Mathematics", :institution "TU Berlin", :country "Germany", :sessions (199880)}, 45132 {:firstname "Leen", :lastname "Stougie", :department "Operations Research", :institution "Vrije Universiteit Amsterdam and CWI", :country "Netherlands", :sessions (199880)}, 45133 {:firstname "Daniel ", :lastname "Tillich", :department "", :institution "TU Dresden", :country "Germany", :sessions (199890)}, 45134 {:firstname "Martin", :lastname "Bock", :department "", :institution "Chair of Operations Management", :country "Germany", :sessions (199934)}, 45135 {:firstname "Dennis", :lastname "Hilgers", :department "Institute for Public and Nonprofit Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (199964 199856)}, 45137 {:firstname "Daniela", :lastname "Guericke", :department "Applied Mathematics and Computer Science", :institution "Technical University of Denmark", :country "Denmark", :sessions (199938)}, 45138 {:firstname "Keisuke", :lastname "Sato", :department "Signalling and Transport Information Technology Division", :institution "Railway Technical Research Institute", :country "Japan", :sessions (199867)}, 45139 {:firstname "Robert", :lastname "Scheidweiler", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (199913)}, 45140 {:firstname "paul", :lastname "moraal", :department "Business Analytics", :institution "Ford Forschungszentrum Aachen", :country "Germany", :sessions (25)}, 45141 {:firstname "Verena", :lastname "Feld", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen University", :country "Germany", :sessions (77)}, 45142 {:firstname "Erich", :lastname "Teppan", :department "", :institution "University of Klagenfurt", :country "Austria", :sessions (44)}, 45143 {:firstname "Gilvan C.", :lastname "Souza", :department "Kelley School of Business", :institution "Indiana University", :country "United States", :sessions (61)}, 45144 {:firstname "Vera", :lastname "Mersheeva", :department "", :institution "Universität Klagenfurt", :country "Austria", :sessions (44)}, 45145 {:firstname "Melanie", :lastname "Frühstück", :department "", :institution "Universität Klagenfurt", :country "Austria", :sessions (44)}, 45146 {:firstname "Andre", :lastname "Schnabel", :department "Institut für Produktionswirtschaft", :institution "Universität Hannover", :country "Germany", :sessions (199871)}, 45147 {:firstname "Maria", :lastname "Sander", :department "", :institution "Infineon Technologies Austria AG", :country "Austria", :sessions (44)}, 45148 {:firstname "Gerhard", :lastname "Friedrich", :department "", :institution "Universitaet Klagenfurt", :country "Austria", :sessions (44)}, 45150 {:firstname "Chien-Chung", :lastname "Huang", :department "", :institution "Chalmers University of Technology", :country "Sweden", :sessions (19)}, 45151 {:firstname "Natalia Agata", :lastname "Stepien", :department "", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (101)}, 45152 {:firstname "Per", :lastname "Paulsen", :department "Department of Informatics (I18)", :institution "Technical University of Munich", :country "Germany", :sessions (76)}, 45153 {:firstname "Benjamin", :lastname "von Eicken", :department "Faculty of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (199849)}, 45154 {:firstname "Rabih", :lastname "Zakaria", :department "", :institution "Université de technologie Belfort-Montbéliard", :country "France", :sessions (199945)}, 45156 {:firstname "Joachim", :lastname "Kneis", :department "Manufacturing Logistics Division", :institution "INFORM", :country "Germany", :sessions (199945)}, 45157 {:firstname "Julia", :lastname "Buwaya", :department "Advanced Analytics", :institution "RWTH Aachen University", :country "Germany", :sessions (199918)}, 45158 {:firstname "Andreas", :lastname "Gebauer", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199876)}, 45159 {:firstname "Peter", :lastname "Bußwolder", :department "Chair of Management Accounting", :institution "RWTH Aachen University", :country "Germany", :sessions (199964)}, 45160 {:firstname "Cornelia", :lastname "Jetzinger", :department "Department of Production and Logistics Management", :institution "Johannes Kepler University Linz", :country "Austria", :sessions (199848)}, 45161 {:firstname "Chris", :lastname "Kuip", :department "Client Support", :institution "AIMMS", :country "Netherlands", :sessions (96)}, 45162 {:firstname "Jasper", :lastname "de Jong", :department "EEMCS", :institution "University of Twente", :country "Netherlands", :sessions (33)}, 45163 {:firstname "Martin", :lastname "Bücker", :department "", :institution "Friedrich-Schiller-Universität Jena", :country "Germany", :sessions (199959)}, 45164 {:firstname "Michael", :lastname "Zipf", :department "Chair of Energy Economics", :institution "Technische Universität Dresden", :country "Germany", :sessions (55)}, 45165 {:firstname "Kristian", :lastname "Schopka", :department "Department of Business Studies & Economics, Chair of Logistics", :institution "University of Bremen", :country "Germany", :sessions (199942)}, 45167 {:firstname "Jan", :lastname "Dornseifer", :department "Management Information Science", :institution "University of Siegen", :country "Germany", :sessions (89890)}, 45168 {:firstname "Marco", :lastname "Franz", :department "", :institution "Fraport AG", :country "Germany", :sessions (199980 199899)}, 45169 {:firstname "Lukas", :lastname "Berthold", :department "", :institution "Universität Hamburg", :country "Germany", :sessions (199872)}, 45170 {:firstname "Urs", :lastname "Eppelt", :department "Nonlinear Dynamics of Laser Processing", :institution "RWTH Aachen University", :country "Germany", :sessions (199851)}, 45171 {:firstname "Toufik", :lastname "Al Khawli", :department "Nonlinear Dynamics of Laser Processing (NLD)", :institution "RWTH Aachen", :country "Germany", :sessions (199851)}, 45175 {:firstname "Lena", :lastname "Schend", :department "Insitut fuer Informatik", :institution "HHU Duesseldorf", :country "Germany", :sessions (67)}, 45176 {:firstname "Anja", :lastname "Rey", :department "", :institution "Heinrich-Heine-Universitaet Duesseldorf", :country "Germany", :sessions (67)}, 45177 {:firstname "Tuomas", :lastname "Rintamäki", :department "", :institution "Aalto University", :country "Finland", :sessions (199928)}, 45181 {:firstname "Christian", :lastname "Doegen", :department "Institute for Mathematical Optimization", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (199889)}, 45184 {:firstname "Andreas", :lastname "Holzapfel", :department "Supply Chain Management & Operations", :institution "Catholic University of Eichstaett-Ingolstadt", :country "Germany", :sessions (199859)}, 45185 {:firstname "James", :lastname "Cussens", :department "Computer Science", :institution "University of York", :country "United Kingdom", :sessions (199867)}, 45186 {:firstname "Piotr", :lastname "Faliszewski", :department "", :institution "AGH University", :country "Poland", :sessions (67)}, 45187 {:firstname "Bertram", :lastname "Steininger", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199963)}, 45188 {:firstname "Dennis", :lastname "Michaels", :department "Mathematics", :institution "TU Dortmund", :country "Germany", :sessions (75)}, 45189 {:firstname "Carsten D.", :lastname "Prang", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199903)}, 45190 {:firstname "Dominique", :lastname "Brueser", :department "Department of Finance", :institution "RWTH Aachen University", :country "Germany", :sessions (199963)}, 45191 {:firstname "Michael", :lastname "Grottke", :department "Statistics and Econometrics", :institution "Friedrich-Alexander-Universität", :country "Germany", :sessions (199891)}, 45192 {:firstname "Eberhard", :lastname "Triesch", :department "Lehrstuhl II für Mathematik", :institution "RWTH Aachen University", :country "Germany", :sessions (199913)}, 45195 {:firstname "Britta", :lastname "Peis", :department "Management Science", :institution "RWTH Aachen", :country "Germany", :sessions (92 199917 69)}, 45197 {:firstname "Marika", :lastname "Karbstein", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (199896 199899 199949)}, 45198 {:firstname "Julika", :lastname "Mehrgardt", :department "Optimization", :institution "Zuse Institute Berlin", :country "Germany", :sessions (199899)}, 45199 {:firstname "Yannick", :lastname "Reisch", :department "", :institution "HHU Duesseldorf", :country "Germany", :sessions (67)}, 45200 {:firstname "Jens", :lastname "Tiekenheinrich", :department "Institut für Wirtschaftsinformatik", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (99)}, 45202 {:firstname "Lea", :lastname "Berg", :department "", :institution "Fraunhofer Institute for Systems and Innovation Research ISI", :country "Germany", :sessions (199934)}, 45203 {:firstname "Bernd", :lastname "Bischl", :department "Statistics", :institution "LMU Munich", :country "Germany", :sessions (73)}, 45207 {:firstname "Marina", :lastname "Fujita", :department "", :institution "Hitachi, Ltd.", :country "Japan", :sessions (199891)}, 45208 {:firstname "Kishiko", :lastname "Maruyama", :department "", :institution "Hitachi, Ltd.", :country "Japan", :sessions (199891)}, 45209 {:firstname "Toshiko", :lastname "Aizono", :department "", :institution "Hitachi, Ltd.", :country "Japan", :sessions (199891)}, 45210 {:firstname "Koji", :lastname "Ara", :department "", :institution "Hitachi, Ltd.", :country "Japan", :sessions (199891)}, 45211 {:firstname "Tom", :lastname "Rihm", :department "Department of Business Administration", :institution "University of Bern", :country "Switzerland", :sessions (199870)}, 45212 {:firstname "Lucas", :lastname "Baier", :department "", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (199932)}, 45214 {:firstname "Eike", :lastname "Nohdurft", :department "Kuehne Foundation Endowed Chair in Logistics Management", :institution "WHU - Otto Beisheim School of Management", :country "Germany", :sessions (199858)}, 45215 {:firstname "Renaud", :lastname "Lacour", :department "Lamsade", :institution "PSL, Université Paris-Dauphine, Lamsade", :country "France", :sessions (199837)}, 45216 {:firstname "Manoj", :lastname "Gupta", :department "", :institution "IIT Delhi", :country "India", :sessions (42)}, 45217 {:firstname "Sandeep", :lastname "Sen", :department "", :institution "IIT Delhi", :country "India", :sessions (42)}, 45218 {:firstname "Sören Christian", :lastname "Meyer", :department "Institut für Wirtschaftsinformatik", :institution "Leibniz Universität Hannover", :country "Germany", :sessions (199930 65)}, 45219 {:firstname "Christoph", :lastname "Hansknecht", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (8)}, 45220 {:firstname "Britta", :lastname "Schulze", :department "Department of Mathematics and Informatics", :institution "University of Wuppertal", :country "Germany", :sessions (199834)}, 45221 {:firstname "Fatemeh", :lastname "Movahedi", :department "Plannig", :institution "Transportation Research Institute", :country "Iran, Islamic Republic of", :sessions (199858)}, 45223 {:firstname "Chung-Shou", :lastname "Liao", :department "Dept. Industrial Engineering and Engineering Management", :institution "National Tsing Hua University", :country "Taiwan, Province of China", :sessions (199897 199900)}, 45224 {:firstname "Davide", :lastname "Bilò", :department "Scienze umanistiche e sociali", :institution "Università di Sassari", :country "Italy", :sessions (39)}, 45225 {:firstname "Benedikt", :lastname "Freiherr von Lüninck", :department "", :institution "Fraunhofer Institute for Systems and Innovation Research ISI", :country "Germany", :sessions (199934)}, 45226 {:firstname "Felix", :lastname "Tettenborn", :department "", :institution "Fraunhofer Institute for Systems and Innovation Research ISI", :country "Germany", :sessions (199934)}, 45227 {:firstname "Ping-Ting", :lastname "Lin", :department "Department of Industrial Engineering and Engineering Management", :institution "National Tsing Hua University, Taiwan", :country "Taiwan, Province of China", :sessions (199897 199900)}, 45228 {:firstname "Markus", :lastname "Grottke", :department "Accounting, Finance & Taxation", :institution "University of Passau", :country "Germany", :sessions (199843 199964)}, 45229 {:firstname "Hans-H.", :lastname "Schulz", :department "", :institution "Oracle Deutschland B.V.&Co KG", :country "Germany", :sessions (199859)}, 45230 {:firstname "Mustafa", :lastname "Yilmaz", :department "Industrial Engineering", :institution "Engineering Faculty", :country "Turkey", :sessions (199846)}, 45231 {:firstname "Tarik", :lastname "Aouam", :department "Department of Business Informatics and Operations Management", :institution "Ghent University", :country "Belgium", :sessions (199849)}, 45232 {:firstname "Andreas", :lastname "Wierz", :department "Chair of Management Science", :institution "RWTH Aachen University", :country "Germany", :sessions (199917)}, 45233 {:firstname "Mahir", :lastname "ATMIS", :department "", :institution "University of Yalova", :country "Turkey", :sessions (199837)}, 45234 {:firstname "Angela", :lastname "Pape", :department "", :institution "Fraunhofer-Institut für Energiewirtschaft und Energiesystemtechnik", :country "Germany", :sessions (94)}, 45235 {:firstname "Philip", :lastname "Voll", :department "Institute of Technical Thermodynamics", :institution "RWTH Aachen University", :country "Germany", :sessions (94)}, 45236 {:firstname "Bart", :lastname "de Keijzer", :department "", :institution "University of Essex", :country "United Kingdom", :sessions (199888)}, 45238 {:firstname "Andreas", :lastname "Baumgartner", :department "Chair for Communication Networks", :institution "University of Technology Chemnitz", :country "Germany", :sessions (199914)}, 45239 {:firstname "Eva Johanna", :lastname "Degel", :department "School of Business and Economics, Chair of Operations Management", :institution "RWTH Aachen", :country "Germany", :sessions (199933)}, 45240 {:firstname "Michael", :lastname "Tuchscherer", :department "", :institution "University Osnabrueck", :country "Germany", :sessions (199963)}, 45241 {:firstname "Benjamin", :lastname "Korth", :department "Information Logistics and Decision Support Systems", :institution "Fraunhofer IML", :country "Germany", :sessions (199854)}, 45242 {:firstname "Maike", :lastname "Hennen", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (94)}, 45244 {:firstname "Yuya", :lastname "Higashikawa", :department "", :institution "University of Hyogo", :country "Japan", :sessions (199916)}, 45245 {:firstname "Bastian", :lastname "Hechenrieder", :department "Faculty of Management and Econcomics, Chair of Operations and Research and Accounting", :institution "Ruhr-University Bochum", :country "Germany", :sessions (199927)}, 45246 {:firstname "Christian", :lastname "Schwede", :department "", :institution "Fraunhofer IML", :country "Germany", :sessions (199854)}, 45247 {:firstname "Julien", :lastname "Weierke", :department "", :institution "Fraunhofer IML", :country "Germany", :sessions (199854)}, 45248 {:firstname "Kamil", :lastname "Pliszka", :department "", :institution "Deutsche Bundesbank", :country "Germany", :sessions (199963)}, 45249 {:firstname "Johannes", :lastname "Lohmar", :department "Institute of Metal Forming", :institution "RWTH Aachen University", :country "Germany", :sessions (199959)}, 45250 {:firstname "Andreas", :lastname "Bublitz", :department "", :institution "KIT", :country "Germany", :sessions (65)}, 45252 {:firstname "Héctor", :lastname "Muñoz", :department "Centro de Domótica Integral (CEDInt)", :institution "Universidad Politécnica de Madrid", :country "Spain", :sessions (199830)}, 45253 {:firstname "manuel", :lastname "bojahr", :department "", :institution "Ford Forschungszentrum Aachen", :country "Germany", :sessions (25)}, 45254 {:firstname "Akaki ", :lastname "Mamageishvili", :department "Department of Computer Science", :institution "ETH Zurich", :country "Switzerland", :sessions (39 199885)}, 45255 {:firstname "Sara", :lastname "Modarres Razavi", :department "", :institution "SICS Swedish ICT", :country "Sweden", :sessions (199852)}, 45256 {:firstname "Mordecai", :lastname "GOLIN", :department "CSE", :institution "Hong Kong UST", :country "Hong Kong", :sessions (199916)}, 45257 {:firstname "Dominik", :lastname "Muller", :department "", :institution "ETH Zurich", :country "Switzerland", :sessions (39)}, 45258 {:firstname "Chi-Fen", :lastname "Chang", :department "Dept. Industrial Engineering and Engineering Management", :institution "National Tsing Hua University", :country "Taiwan, Province of China", :sessions (199897 199900)}, 45259 {:firstname "Maximilian", :lastname "Drees", :department "", :institution "Heinz-Nixdorf Institute", :country "Germany", :sessions (199887)}, 45261 {:firstname "Julia", :lastname "Schleibach", :department "", :institution "Institute of Power Systems and Power Economics", :country "Germany", :sessions (94)}, 45262 {:firstname "Andreas", :lastname "Schilling", :department "Faculty of Management and Economics", :institution "Ruhr University Bochum", :country "Germany", :sessions (199842)}, 45264 {:firstname "Josef", :lastname "Schosser", :department "Chair of Accounting and Control", :institution "University of Passau", :country "Germany", :sessions (199964)}, 45266 {:firstname "Giuseppe", :lastname "Sasso", :department "", :institution "University of Auckland", :country "New Zealand", :sessions (199833)}, 45267 {:firstname "Hartmut", :lastname "Helmke", :department "", :institution "Deutsches Zentrum für Luft- und Raumfahrt e.V. (DLR), German Aerospace Center", :country "Germany", :sessions (199898)}, 45268 {:firstname "John", :lastname "Simpson", :department "", :institution "Radiation Oncology Institute", :country "Australia", :sessions (199833)}, 45269 {:firstname "Rajiv ", :lastname "Srivastava", :department "Department of Technology", :institution "Pune University", :country "India", :sessions (199842)}, 45271 {:firstname "Stefan", :lastname "Kirschbaum", :department "", :institution "GFaI e.V.", :country "Germany", :sessions (94)}, 45273 {:firstname "Martin", :lastname "Schmelzle", :department "Chair of Statistics and Riskmanagement", :institution "Universität Regensburg", :country "Germany", :sessions (51)}, 45274 {:firstname "Daniel", :lastname "Schmand", :department "", :institution "Goethe University Frankfurt", :country "Germany", :sessions (199887)}, 45276 {:firstname "Daniel", :lastname "Rösch", :department "Chair of Statistics and Riskmanagement", :institution "Universität Regensburg", :country "Germany", :sessions (51)}, 45277 {:firstname "Andreas", :lastname "Brock", :department "", :institution "Oracle Deutschland B.V.&Co KG", :country "Germany", :sessions (199859)}, 45278 {:firstname "Robert", :lastname "Bredereck", :department "", :institution "TU Berlin", :country "Germany", :sessions (67)}, 45279 {:firstname "Ricardo", :lastname "Tejada", :department "", :institution "RWTH Aachen", :country "Germany", :sessions (199920)}, 45280 {:firstname "Girish", :lastname "Palshikar", :department "", :institution "Tata Consultancy Services Limited", :country "India", :sessions (199842)}, 45281 {:firstname "Jing", :lastname "Zhao", :department "", :institution "Harbin Engineering University", :country "China", :sessions (199891)}, 45282 {:firstname "Michael", :lastname "Zens", :department "", :institution "perpendo GmbH", :country "Germany", :sessions (94)}, 45283 {:firstname "Kishor", :lastname "Trivedi", :department "", :institution "Duke University", :country "United States", :sessions (199891)}, 45284 {:firstname "Javier", :lastname "Alonso", :department "", :institution "Duke University", :country "United States", :sessions (199891)}, 45285 {:firstname "Markus", :lastname "Bambach", :department "Institute of Metal Forming", :institution "RWTH Aachen University", :country "Germany", :sessions (199959)}, 45286 {:firstname "Yanbin", :lastname "Wang", :department "", :institution "Harbin Institute of Technology", :country "China", :sessions (199891)}, 45287 {:firstname "Helmut", :lastname "Lepple", :department "", :institution "Robert Bosch GmbH", :country "Germany", :sessions (94)}, 45288 {:firstname "Corinna", :lastname "Krüger", :department "Institute for Numerical and Applied Mathematics", :institution "Georg-August University Göttingen", :country "Germany", :sessions (199905)}, 45289 {:firstname "Christiane", :lastname "Rosen", :department "E.ON Energy Research Center, School of Business and Economics", :institution "RWTH Aachen University", :country "Germany", :sessions (199928)}, 45291 {:firstname "Maximilian", :lastname "Brock", :department "Research", :institution "4flow AG", :country "Germany", :sessions (26)}, 45292 {:firstname "Alena", :lastname "Klug", :department "itwm", :institution "Fraunhofer", :country "Germany", :sessions (199929)}, 45293 {:firstname "Halil", :lastname "Şen", :department "Industrial Engineering", :institution "Mehmet Akif Ersoy University", :country "Turkey", :sessions (199860)}, 45294 {:firstname "Ivana", :lastname "Veselinovic", :department "", :institution "University of Nis, Faculty of Economics", :country "Serbia", :sessions (51)}, 45295 {:firstname "Fernando", :lastname "Flores-Bazán", :department "", :institution "Universidad del Bío Bío", :country "Chile", :sessions (199837)}, 45296 {:firstname "Peter", :lastname "Lusk", :department "", :institution "Pro Capital LLC", :country "United States", :sessions (83)}, 45299 {:firstname "FRED", :lastname "MAYAMBALA", :department "MATHEMATICS", :institution "MAKERERE UNIVERSITY", :country "Uganda", :sessions (51)}, 45301 {:firstname "Maren", :lastname "Gäde", :department "Institute of Automotive Management and Industrial Production", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (199871)}, 45302 {:firstname "Simon", :lastname "Görtz", :department "", :institution "University of Wuppertal", :country "Germany", :sessions (199918)}, 45303 {:firstname "Pierre F", :lastname "Tiako", :department "", :institution "3Langston University  and CITDR,", :country "United States", :sessions (199875)}, 45304 {:firstname "Achim", :lastname "Brenner", :department "", :institution "Robert Bosch GmbH", :country "Germany", :sessions (94)}, 45305 {:firstname "Christoph", :lastname "Kausch", :department "", :institution "perpendo GmbH", :country "Germany", :sessions (94)}, 45306 {:firstname "Ina", :lastname "Schlei-Peters", :department "", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (99)}, 45307 {:firstname "Daniel", :lastname "Kaml", :department "", :institution "University of Vienna", :country "Germany", :sessions (26)}, 45308 {:firstname "Gerlind", :lastname "Plonka-Hoch", :department "", :institution "Universität Göttingen", :country "Germany", :sessions (199905)}, 45313 {:firstname "Andreas", :lastname "Nilsson", :department "", :institution "SICS", :country "Sweden", :sessions (199852)}, 45314 {:firstname "Per-Ola", :lastname "Larsson", :department "", :institution "Modelon AB", :country "Sweden", :sessions (199852)}, 45315 {:firstname "Stephane", :lastname "Velut", :department "", :institution "Modelon AB", :country "Sweden", :sessions (199852)}, 45316 {:firstname "Jonas", :lastname "Funkquist", :department "", :institution "Vattenfall AB", :country "Sweden", :sessions (199852)}, 45317 {:firstname "Sascha", :lastname "Meng", :department "Institute for Industrial Production", :institution "Karlsruhe Institute of Technology", :country "Germany", :sessions (199886)}, 45319 {:firstname "Rudolf", :lastname "Müller", :department "Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (33)}, 45326 {:firstname "Adrian", :lastname "Marple", :department "", :institution "Stanford University", :country "United States", :sessions (67)}, 45329 {:firstname "Daniel", :lastname "Müller", :department "", :institution "University of Cologne", :country "Germany", :sessions (28)}, 45335 {:firstname "Jörg", :lastname "Michels", :department "", :institution "Teamnet", :country "Germany", :sessions (199830)}, 45337 {:firstname "Alexandra", :lastname "Bernhardt", :department "Business School", :institution "Saarland University of Applied Sciences", :country "Germany", :sessions (199937)}, 45338 {:firstname "Grit", :lastname "Claßen", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199918)}, 45340 {:firstname "Fabian", :lastname "Sandau", :department "", :institution "Fraunhofer IWES", :country "Germany", :sessions (94)}, 45341 {:firstname "Andreas", :lastname "Elias", :department "Department of Technology and Operations Management, Mercator School of Management", :institution "Universität Duisburg-Essen", :country "Germany", :sessions (199858)}, 45342 {:firstname "Ernesto", :lastname "Garnier", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199930)}, 45345 {:firstname "Gergely", :lastname "Csapo", :department "Quantitative Economics", :institution "Maastricht University", :country "Netherlands", :sessions (33)}, 45346 {:firstname "Albert", :lastname "Steiner", :department "School of Engineering", :institution "ZHAW", :country "Switzerland", :sessions (199947)}, 45347 {:firstname "Anke", :lastname "Schmeink", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199918)}, 45348 {:firstname "Johannes", :lastname "Schäuble", :department "French-German Institute for Environmental Research", :institution "Karlsruhe Institut of Technology (KIT)", :country "Germany", :sessions (199930)}, 45350 {:firstname "Ferdinand", :lastname "Kiermaier", :department "", :institution "TUM School of Management", :country "Germany", :sessions (95)}, 45352 {:firstname "Andrew", :lastname "Ju", :department "", :institution "University of Limerick", :country "Ireland", :sessions (199903)}, 45356 {:firstname "Dimitris", :lastname "Souravlias", :department "Department of Computer Science & Engineering", :institution "University of Ioannina", :country "Greece", :sessions (47)}, 45357 {:firstname "Zhi", :lastname "Yuan", :department "Department of Mechanical Engineering", :institution "Helmut Schmidt University", :country "Germany", :sessions (199940)}, 45358 {:firstname "Nestor", :lastname "Parolya", :department "Institute of Empirical Economics (Econometrics)", :institution "Leibniz University Hannover", :country "Germany", :sessions (199890)}, 45359 {:firstname "Wolfgang", :lastname "Schmid", :department "Statistics", :institution "European-University Viadrina", :country "Germany", :sessions (199890)}, 45360 {:firstname "Kai", :lastname "Gutenschwager", :department "Computer Science", :institution "Ostfalia University of Applied Sciences", :country "Germany", :sessions (27)}, 45361 {:firstname "Gulsum", :lastname "Ozer", :department "Industrial Systems Engineering", :institution "Izmir University of Economics", :country "Turkey", :sessions (199854)}, 45362 {:firstname "Philipp", :lastname "Arnold", :department "", :institution "ZF Friedrichshafen AG", :country "Germany", :sessions (27)}, 45363 {:firstname "Cansel", :lastname "UZARAS", :department "Industrial system engineering", :institution "izmir ekonomi üniversitesi", :country "Turkey", :sessions (199854)}, 45364 {:firstname "cenk", :lastname "tasyurek", :department "Industrial Systems Engineering", :institution "Izmir University of Economics", :country "Turkey", :sessions (199854)}, 45365 {:firstname "Merve", :lastname "Ilbeyi", :department "Industrial Systems Engineering ", :institution "Izmir University of Economics", :country "Turkey", :sessions (199854)}, 45366 {:firstname "Jose", :lastname "Soto", :department "Mathematical Engineering", :institution "Universidad de Chile", :country "Chile", :sessions (199900)}, 45367 {:firstname "Utkan", :lastname "Eryilmaz", :department "", :institution "TED University", :country "Turkey", :sessions (199869)}, 45368 {:firstname "Swen", :lastname "Schlobach", :department "", :institution "Lufthansa Systems", :country "Germany", :sessions (199940)}, 45369 {:firstname "Anton", :lastname "Kaier", :department "", :institution "Lufthansa Systems", :country "Germany", :sessions (199940)}, 45372 {:firstname "Isa", :lastname "von Hoesslin", :department "Institut für Automobilwirtschaft und Industrielle Produktion", :institution "Technische Universität Braunschweig", :country "Germany", :sessions (101)}, 45377 {:firstname "Martin", :lastname "Tritschler", :department "TUM School of Management", :institution "Technische Universität München", :country "Germany", :sessions (199870)}, 45379 {:firstname "Olga", :lastname "Bock", :department "Deutsche Post Lehrstuhl für Optimierung von Distributionsnetzwerken", :institution "RWTH", :country "Germany", :sessions (199957)}, 45381 {:firstname "Andreas", :lastname "Braun", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199957)}, 45437 {:firstname "Ha", :lastname "Hoang", :department "Logistics Research Group", :institution "Hasselt University", :country "Belgium", :sessions (199946)}, 45501 {:firstname "gökhan", :lastname "çelik", :department "Industrial Engineering", :institution "kho", :country "Turkey", :sessions (199957)}, 45567 {:firstname "Andreas", :lastname "Wiehl", :department "Sustainable Operations and Logistics", :institution "Augsburg University", :country "Germany", :sessions (199948)}, 45568 {:firstname "Andreas", :lastname "Schütz", :department "Institut für Mathematik", :institution "TU Berlin", :country "Germany", :sessions (199948)}, 45572 {:firstname "Djilali", :lastname "Idoughi", :department "computer sciences", :institution "Bejaia University", :country "Algeria", :sessions (199831)}, 45634 {:firstname "David", :lastname "Barber", :department "Dept. of Computer Science", :institution "University College London", :country "United Kingdom", :sessions (199967)}, 45640 {:firstname "Edgar Augusto", :lastname "Lanzer", :department "", :institution "Sociedade Educacional de Santa Catarina", :country "Brazil", :sessions (24)}, 45641 {:firstname "Marcelo", :lastname "Azevedo", :department "", :institution "Universidade Federal de Minas Gerais", :country "Brazil", :sessions (24)}, 45659 {:firstname "Heide", :lastname "Hoppmann", :department "Optimierung", :institution "Zuse-Institute Berlin", :country "Germany", :sessions (199896)}, 45661 {:firstname "Nitin", :lastname "Ahuja", :department "", :institution "PTV Group", :country "Germany", :sessions (199980)}, 45671 {:firstname "Parastoo", :lastname "Hassani", :department "", :institution "Industrial Management Institution", :country "Iran, Islamic Republic of", :sessions (199858)}, 45693 {:firstname "Matthias", :lastname "Meisen", :department "", :institution "Deutsche Post AG", :country "Germany", :sessions (199980)}, 45697 {:firstname "Jochem", :lastname "Donkers", :department "", :institution "AbOvo", :country "Netherlands", :sessions (199981)}, 45698 {:firstname "Peter", :lastname "Lietz", :department "", :institution "Wincor Nixdorf International GmbH", :country "Germany", :sessions (199982)}, 45699 {:firstname "Günter", :lastname "Stock", :department "RMS", :institution "Kisters", :country "Germany", :sessions (199981)}, 45700 {:firstname "Ulrich", :lastname "Burges", :department "", :institution "SimPlan AG", :country "Germany", :sessions (199979)}, 45701 {:firstname "Alexander", :lastname "Aschauer", :department "", :institution "X-INTEGRATE Software & Consulting GmbH", :country "Germany", :sessions (199982)}, 45702 {:firstname "Christoph", :lastname "Moll", :department "", :institution "Siemens AG", :country "Germany", :sessions (199982)}, 45703 {:firstname "Frank", :lastname "Lüders", :department "", :institution "Air Liquide Deutschland GmbH", :country "Germany", :sessions (199981)}, 47085 {:firstname "Marcus", :lastname "Brandenburg", :department "Supply Chain Management", :institution "Flensburg University of Applied Sciences", :country "Germany", :sessions (61)}, 53033 {:firstname "José Rui", :lastname "Figueira", :department "", :institution "CEG-IST, Instituto Superior Técnico, Universidade de Lisboa", :country "Portugal", :sessions (199834)}, 55333 {:firstname "Martin", :lastname "Bichler", :department "", :institution "Technical University of Munich", :country "Germany", :sessions (97 76 199832)}, 55926 {:firstname "Gerhard", :lastname "Woeginger", :department "", :institution "RWTH Aachen", :country "Germany", :sessions (199912)}, 59838 {:firstname "Barbara", :lastname "Glensk", :department "", :institution "RWTH Aachen University", :country "Germany", :sessions (199928)}}}